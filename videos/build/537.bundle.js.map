{"version":3,"file":"537.bundle.js","mappings":";;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxDA;AACA;;;;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1RA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3CA;AACA;AACA;AACA;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5BA;AACA;AACA;AACA;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtVA;AACA;AACA;AACA;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AAWA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;;;;;;;;;ACrjHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;;;AC56GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;;;;;;;AC7gBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;AClFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC7NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACxFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACz7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC3IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC1+BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACrh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g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vkBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5dA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AC32DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC3SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAWA;;;ACviIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AAUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;;;;;;;;AC7y8CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACruCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5ZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjiBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["./node_modules/@remotion/media-utils/dist/audio-buffer/audio-buffer-to-wav.js","./node_modules/@remotion/media-utils/dist/audio-buffer/audio-url-helpers.js","./node_modules/@remotion/media-utils/dist/combine-float32-arrays.js","./node_modules/@remotion/media-utils/dist/create-smooth-svg-path.js","./node_modules/@remotion/media-utils/dist/fetch-with-cors-catch.js","./node_modules/@remotion/media-utils/dist/fft/complex.js","./node_modules/@remotion/media-utils/dist/fft/exponent.js","./node_modules/@remotion/media-utils/dist/fft/fft-accurate.js","./node_modules/@remotion/media-utils/dist/fft/fft-fast.js","./node_modules/@remotion/media-utils/dist/fft/get-visualization.js","./node_modules/@remotion/media-utils/dist/fft/mag.js","./node_modules/@remotion/media-utils/dist/fft/max-value-cached.js","./node_modules/@remotion/media-utils/dist/fft/smoothing.js","./node_modules/@remotion/media-utils/dist/fft/to-int-16.js","./node_modules/@remotion/media-utils/dist/get-audio-data.js","./node_modules/@remotion/media-utils/dist/get-audio-duration-in-seconds.js","./node_modules/@remotion/media-utils/dist/get-image-dimensions.js","./node_modules/@remotion/media-utils/dist/get-partial-audio-data.js","./node_modules/@remotion/media-utils/dist/get-video-metadata.js","./node_modules/@remotion/media-utils/dist/get-wave-form-samples.js","./node_modules/@remotion/media-utils/dist/get-waveform-portion.js","./node_modules/@remotion/media-utils/dist/index.js","./node_modules/@remotion/media-utils/dist/is-remote-asset.js","./node_modules/@remotion/media-utils/dist/media-tag-error-handling.js","./node_modules/@remotion/media-utils/dist/normalize-data.js","./node_modules/@remotion/media-utils/dist/p-limit.js","./node_modules/@remotion/media-utils/dist/types.js","./node_modules/@remotion/media-utils/dist/use-audio-data.js","./node_modules/@remotion/media-utils/dist/use-windowed-audio-data.js","./node_modules/@remotion/media-utils/dist/validate-channel.js","./node_modules/@remotion/media-utils/dist/visualize-audio-waveform.js","./node_modules/@remotion/media-utils/dist/visualize-audio.js","./node_modules/@remotion/studio-shared/dist/ansi.js","./node_modules/@remotion/studio-shared/dist/default-buffer-state-delay-in-milliseconds.js","./node_modules/@remotion/studio-shared/dist/format-bytes.js","./node_modules/@remotion/studio-shared/dist/get-default-out-name.js","./node_modules/@remotion/studio-shared/dist/get-location-from-build-error.js","./node_modules/@remotion/studio-shared/dist/get-project-name.js","./node_modules/@remotion/studio-shared/dist/hot-middleware.js","./node_modules/@remotion/studio-shared/dist/index.js","./node_modules/@remotion/studio-shared/dist/max-timeline-tracks.js","./node_modules/@remotion/studio-shared/dist/package-info.js","./node_modules/@remotion/studio-shared/dist/source-map-endpoint.js","./node_modules/@remotion/studio-shared/dist/stringify-default-props.js","./node_modules/@remotion/player/dist/esm/index.mjs","./node_modules/@remotion/renderer/dist/esm/client.mjs","./node_modules/@remotion/renderer/dist/esm/pure.mjs","./node_modules/mediabunny/dist/modules/src/muxer.js","./node_modules/mediabunny/dist/modules/src/adts/adts-misc.js","./node_modules/mediabunny/dist/modules/src/adts/adts-muxer.js","./node_modules/mediabunny/dist/modules/src/flac/flac-muxer.js","./node_modules/mediabunny/dist/modules/src/subtitles.js","./node_modules/mediabunny/dist/modules/src/isobmff/isobmff-boxes.js","./node_modules/mediabunny/dist/modules/src/writer.js","./node_modules/mediabunny/dist/modules/src/target.js","./node_modules/mediabunny/dist/modules/src/isobmff/isobmff-muxer.js","./node_modules/mediabunny/dist/modules/src/matroska/matroska-muxer.js","./node_modules/mediabunny/dist/modules/src/mp3/mp3-writer.js","./node_modules/mediabunny/dist/modules/src/mp3/mp3-muxer.js","./node_modules/mediabunny/dist/modules/src/ogg/ogg-muxer.js","./node_modules/mediabunny/dist/modules/src/mpeg-ts/mpeg-ts-muxer.js","./node_modules/mediabunny/dist/modules/src/wave/riff-writer.js","./node_modules/mediabunny/dist/modules/src/wave/wave-muxer.js","./node_modules/mediabunny/dist/modules/src/output-format.js","./node_modules/mediabunny/dist/modules/src/encode.js","./node_modules/mediabunny/dist/modules/src/media-source.js","./node_modules/mediabunny/dist/modules/src/output.js","./node_modules/@remotion/web-renderer/dist/esm/index.mjs","./node_modules/@remotion/studio/dist/esm/chunk-yhf0gvmn.js","./node_modules/source-map/lib/array-set.js","./node_modules/source-map/lib/base64-vlq.js","./node_modules/source-map/lib/base64.js","./node_modules/source-map/lib/binary-search.js","./node_modules/source-map/lib/mapping-list.js","./node_modules/source-map/lib/read-wasm.js","./node_modules/source-map/lib/source-map-consumer.js","./node_modules/source-map/lib/source-map-generator.js","./node_modules/source-map/lib/source-node.js","./node_modules/source-map/lib/util.js","./node_modules/source-map/lib/wasm.js","./node_modules/source-map/source-map.js","./node_modules/mediabunny/dist/bundles/mediabunny.cjs"],"sourcesContent":["\"use strict\";\n/**\n * Inlined from https://github.com/Jam3/audiobuffer-to-wav/commit/2272eb09bd46a05e50a6d684d908aa6f13c58f63#diff-e727e4bdf3657fd1d798edcd6b099d6e092f8573cba266154583a746bba0f346\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.audioBufferToWav = audioBufferToWav;\nfunction interleave(inputL, inputR) {\n    const length = inputL.length + inputR.length;\n    const result = new Float32Array(length);\n    let index = 0;\n    let inputIndex = 0;\n    while (index < length) {\n        result[index++] = inputL[inputIndex];\n        result[index++] = inputR[inputIndex];\n        inputIndex++;\n    }\n    return result;\n}\nfunction writeFloat32(output, offset, input) {\n    for (let i = 0; i < input.length; i++, offset += 4) {\n        output.setFloat32(offset, input[i], true);\n    }\n}\nfunction floatTo16BitPCM(output, offset, input) {\n    for (let i = 0; i < input.length; i++, offset += 2) {\n        const s = Math.max(-1, Math.min(1, input[i]));\n        output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);\n    }\n}\nfunction writeString(view, offset, string) {\n    for (let i = 0; i < string.length; i++) {\n        view.setUint8(offset + i, string.charCodeAt(i));\n    }\n}\nfunction encodeWAV({ samples, format, sampleRate, numChannels, bitDepth, }) {\n    const bytesPerSample = bitDepth / 8;\n    const blockAlign = numChannels * bytesPerSample;\n    const buffer = new ArrayBuffer(44 + samples.length * bytesPerSample);\n    const view = new DataView(buffer);\n    /* RIFF identifier */\n    writeString(view, 0, 'RIFF');\n    /* RIFF chunk length */\n    view.setUint32(4, 36 + samples.length * bytesPerSample, true);\n    /* RIFF type */\n    writeString(view, 8, 'WAVE');\n    /* format chunk identifier */\n    writeString(view, 12, 'fmt ');\n    /* format chunk length */\n    view.setUint32(16, 16, true);\n    /* sample format (raw) */\n    view.setUint16(20, format, true);\n    /* channel count */\n    view.setUint16(22, numChannels, true);\n    /* sample rate */\n    view.setUint32(24, sampleRate, true);\n    /* byte rate (sample rate * block align) */\n    view.setUint32(28, sampleRate * blockAlign, true);\n    /* block align (channel count * bytes per sample) */\n    view.setUint16(32, blockAlign, true);\n    /* bits per sample */\n    view.setUint16(34, bitDepth, true);\n    /* data chunk identifier */\n    writeString(view, 36, 'data');\n    /* data chunk length */\n    view.setUint32(40, samples.length * bytesPerSample, true);\n    if (format === 1) {\n        // Raw PCM\n        floatTo16BitPCM(view, 44, samples);\n    }\n    else {\n        writeFloat32(view, 44, samples);\n    }\n    return buffer;\n}\nfunction audioBufferToWav(buffer, opt) {\n    const numChannels = buffer.numberOfChannels;\n    const { sampleRate } = buffer;\n    const format = opt.float32 ? 3 : 1;\n    const bitDepth = format === 3 ? 32 : 16;\n    let result;\n    if (numChannels === 2) {\n        result = interleave(buffer.getChannelData(0), buffer.getChannelData(1));\n    }\n    else {\n        result = buffer.getChannelData(0);\n    }\n    return encodeWAV({\n        samples: result,\n        format,\n        sampleRate,\n        numChannels,\n        bitDepth,\n    });\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.audioBufferToDataUrl = void 0;\nconst audio_buffer_to_wav_1 = require(\"./audio-buffer-to-wav\");\n/*\n * @description Takes an AudioBuffer instance and converts it to a Base 64 Data URL so it can be passed to an <Html5Audio /> tag.\n * @see [Documentation](https://remotion.dev/docs/audio-buffer-to-data-url)\n */\nconst audioBufferToDataUrl = (buffer) => {\n    const wavAsArrayBuffer = (0, audio_buffer_to_wav_1.audioBufferToWav)(buffer, {\n        float32: true,\n    });\n    let binary = '';\n    const bytes = new Uint8Array(wavAsArrayBuffer);\n    const len = bytes.byteLength;\n    for (let i = 0; i < len; i++) {\n        binary += String.fromCharCode(bytes[i]);\n    }\n    return 'data:audio/wav;base64,' + window.btoa(binary);\n};\nexports.audioBufferToDataUrl = audioBufferToDataUrl;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.combineFloat32Arrays = void 0;\nconst combineFloat32Arrays = (arrays) => {\n    if (arrays.length === 0) {\n        return new Float32Array([]);\n    }\n    if (arrays.length === 1) {\n        return arrays[0];\n    }\n    let totalLength = 0;\n    for (const array of arrays) {\n        totalLength += array.length;\n    }\n    const result = new Float32Array(totalLength);\n    let offset = 0;\n    for (const array of arrays) {\n        result.set(array, offset);\n        offset += array.length;\n    }\n    return result;\n};\nexports.combineFloat32Arrays = combineFloat32Arrays;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createSmoothSvgPath = void 0;\nconst line = (pointA, pointB) => {\n    const lengthX = pointB.x - pointA.x;\n    const lengthY = pointB.y - pointA.y;\n    return {\n        length: Math.sqrt(lengthX ** 2 + lengthY ** 2),\n        angle: Math.atan2(lengthY, lengthX),\n    };\n};\nconst controlPoint = ({ current, previous, next, reverse, }) => {\n    const p = previous || current;\n    const n = next || current;\n    // The smoothing ratio\n    const smoothing = 0.2;\n    // Properties of the opposed-line\n    const o = line(p, n);\n    const angle = o.angle + (reverse ? Math.PI : 0);\n    const length = o.length * smoothing;\n    const x = current.x + Math.cos(angle) * length;\n    const y = current.y + Math.sin(angle) * length;\n    return { x, y };\n};\nconst createSmoothSvgPath = ({ points }) => {\n    return points.reduce((acc, current, i, a) => {\n        if (i === 0) {\n            return `M ${current.x},${current.y}`;\n        }\n        const { x, y } = current;\n        const previous = a[i - 1];\n        const twoPrevious = a[i - 2];\n        const next = a[i + 1];\n        const { x: cp1x, y: cp1y } = controlPoint({\n            current: previous,\n            previous: twoPrevious,\n            next: current,\n            reverse: false,\n        });\n        const { x: cp2x, y: cp2y } = controlPoint({\n            current,\n            previous,\n            next,\n            reverse: true,\n        });\n        return `${acc} C ${cp1x},${cp1y} ${cp2x},${cp2y} ${x},${y}`;\n    }, '');\n};\nexports.createSmoothSvgPath = createSmoothSvgPath;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fetchWithCorsCatch = void 0;\nconst fetchWithCorsCatch = async (src, init) => {\n    try {\n        const response = await fetch(src, {\n            mode: 'cors',\n            referrerPolicy: 'no-referrer-when-downgrade',\n            ...init,\n        });\n        return response;\n    }\n    catch (err) {\n        const error = err;\n        if (\n        // Chrome\n        error.message.includes('Failed to fetch') ||\n            // Safari\n            error.message.includes('Load failed') ||\n            // Firefox\n            error.message.includes('NetworkError when attempting to fetch resource')) {\n            throw new TypeError(`Failed to read from ${src}: ${error.message}. Does the resource support CORS?`);\n        }\n        throw err;\n    }\n};\nexports.fetchWithCorsCatch = fetchWithCorsCatch;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.complexMagnitude = exports.complexMultiply = exports.complexSubtract = exports.complexAdd = void 0;\nconst complexAdd = function (a, b) {\n    return [a[0] + b[0], a[1] + b[1]];\n};\nexports.complexAdd = complexAdd;\nconst complexSubtract = function (a, b) {\n    return [a[0] - b[0], a[1] - b[1]];\n};\nexports.complexSubtract = complexSubtract;\nconst complexMultiply = function (a, b) {\n    return [a[0] * b[0] - a[1] * b[1], a[0] * b[1] + a[1] * b[0]];\n};\nexports.complexMultiply = complexMultiply;\nconst complexMagnitude = function (c) {\n    return Math.sqrt(c[0] * c[0] + c[1] * c[1]);\n};\nexports.complexMagnitude = complexMagnitude;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.exponent = void 0;\nconst mapExponent = {};\nconst exponent = function (k, N) {\n    const x = -2 * Math.PI * (k / N);\n    mapExponent[N] = mapExponent[N] || {};\n    mapExponent[N][k] = mapExponent[N][k] || [Math.cos(x), Math.sin(x)]; // [Real, Imaginary]\n    return mapExponent[N][k];\n};\nexports.exponent = exponent;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fftAccurate = void 0;\nconst complex_1 = require(\"./complex\");\nconst exponent_1 = require(\"./exponent\");\nconst fftAccurate = function (vector) {\n    const X = [];\n    const N = vector.length;\n    // Base case is X = x + 0i since our input is assumed to be real only.\n    if (N === 1) {\n        if (Array.isArray(vector[0])) {\n            // If input vector contains complex numbers\n            return [[vector[0][0], vector[0][1]]];\n        }\n        return [[vector[0], 0]];\n    }\n    // Recurse: all even samples\n    const X_evens = (0, exports.fftAccurate)(vector.filter((_, ix) => ix % 2 === 0));\n    // Recurse: all odd samples\n    const X_odds = (0, exports.fftAccurate)(vector.filter((__, ix) => ix % 2 === 1));\n    // Now, perform N/2 operations!\n    for (let k = 0; k < N / 2; k++) {\n        // t is a complex number!\n        const t = X_evens[k];\n        const e = (0, complex_1.complexMultiply)((0, exponent_1.exponent)(k, N), X_odds[k]);\n        X[k] = (0, complex_1.complexAdd)(t, e);\n        X[k + N / 2] = (0, complex_1.complexSubtract)(t, e);\n    }\n    return X;\n};\nexports.fftAccurate = fftAccurate;\n","\"use strict\";\n// https://pastebin.com/raw/D42RbPe5\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fftFast = void 0;\n// Function to reverse bits in an integer\nfunction reverseBits(num, numBits) {\n    let result = 0;\n    for (let i = 0; i < numBits; i++) {\n        result = (result << 1) | ((num >> i) & 1);\n    }\n    return result;\n}\n// Hamming window function\nfunction hammingWindow(N) {\n    const win = new Array(N);\n    for (let i = 0; i < N; i++) {\n        win[i] = 0.8 - 0.46 * Math.cos((2 * Math.PI * i) / (N - 1));\n    }\n    return win;\n}\n// Function to calculate the bit-reversed permutation indices\nfunction bitReversePermutation(N) {\n    const bitReversed = new Array(N);\n    for (let i = 0; i < N; i++) {\n        bitReversed[i] = reverseBits(i, Math.log2(N));\n    }\n    return bitReversed;\n}\nconst fftFast = function (vector) {\n    const N = vector.length;\n    const X = new Array(N);\n    if (N <= 1) {\n        for (let i = 0; i < vector.length; i++) {\n            const value = vector[i];\n            X[i] = [value * 2, 0];\n        }\n        return X;\n    }\n    // Apply a windowing function to the input data\n    const window = hammingWindow(N); // You can choose a different window function if needed\n    for (let i = 0; i < N; i++) {\n        X[i] = [vector[i] * window[i], 0];\n    }\n    // Bit-Reversal Permutation\n    const bitReversed = bitReversePermutation(N);\n    for (let i = 0; i < N; i++) {\n        X[i] = [vector[bitReversed[i]], 0];\n    }\n    // Cooley-Tukey FFT\n    for (let s = 1; s <= Math.log2(N); s++) {\n        const m = 1 << s; // Number of elements in each subarray\n        const mHalf = m / 2; // Half the number of elements in each subarray\n        const angleIncrement = (2 * Math.PI) / m;\n        for (let k = 0; k < N; k += m) {\n            let omegaReal = 1.0;\n            let omegaImag = 0.0;\n            for (let j = 0; j < mHalf; j++) {\n                const tReal = omegaReal * X[k + j + mHalf][0] - omegaImag * X[k + j + mHalf][1];\n                const tImag = omegaReal * X[k + j + mHalf][1] + omegaImag * X[k + j + mHalf][0];\n                const uReal = X[k + j][0];\n                const uImag = X[k + j][1];\n                X[k + j] = [uReal + tReal, uImag + tImag];\n                X[k + j + mHalf] = [uReal - tReal, uImag - tImag];\n                // Twiddle factor update\n                const tempReal = omegaReal * Math.cos(angleIncrement) -\n                    omegaImag * Math.sin(angleIncrement);\n                omegaImag =\n                    omegaReal * Math.sin(angleIncrement) +\n                        omegaImag * Math.cos(angleIncrement);\n                omegaReal = tempReal;\n            }\n        }\n    }\n    return X;\n};\nexports.fftFast = fftFast;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getVisualization = void 0;\nconst fft_accurate_1 = require(\"./fft-accurate\");\nconst fft_fast_1 = require(\"./fft-fast\");\nconst mag_1 = require(\"./mag\");\nconst smoothing_1 = require(\"./smoothing\");\nconst to_int_16_1 = require(\"./to-int-16\");\nconst getVisualization = ({ sampleSize, data, sampleRate, frame, fps, maxInt, optimizeFor, dataOffsetInSeconds, }) => {\n    const isPowerOfTwo = sampleSize > 0 && (sampleSize & (sampleSize - 1)) === 0;\n    if (!isPowerOfTwo) {\n        throw new TypeError(`The argument \"bars\" must be a power of two. For example: 64, 128. Got instead: ${sampleSize}`);\n    }\n    if (!fps) {\n        throw new TypeError('The argument \"fps\" was not provided');\n    }\n    if (data.length < sampleSize) {\n        throw new TypeError('Audio data is not big enough to provide ' + sampleSize + ' bars.');\n    }\n    const start = Math.floor((frame / fps - dataOffsetInSeconds) * sampleRate);\n    const actualStart = Math.max(0, start - sampleSize / 2);\n    const ints = new Int16Array({\n        length: sampleSize,\n    });\n    ints.set(data.subarray(actualStart, actualStart + sampleSize).map((x) => (0, to_int_16_1.toInt16)(x)));\n    const alg = optimizeFor === 'accuracy' ? fft_accurate_1.fftAccurate : fft_fast_1.fftFast;\n    const phasors = alg(ints);\n    const magnitudes = (0, mag_1.fftMag)(phasors).map((p) => p);\n    return (0, smoothing_1.smoothen)(magnitudes).map((m) => m / (sampleSize / 2) / maxInt);\n};\nexports.getVisualization = getVisualization;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fftMag = void 0;\nconst complex_1 = require(\"./complex\");\nconst fftMag = function (fftBins) {\n    const ret = fftBins.map((f) => (0, complex_1.complexMagnitude)(f));\n    return ret.slice(0, ret.length / 2);\n};\nexports.fftMag = fftMag;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getMaxPossibleMagnitude = void 0;\nconst to_int_16_1 = require(\"./to-int-16\");\nconst getMax = (array) => {\n    let max = 0;\n    for (let i = 0; i < array.length; i++) {\n        const val = array[i];\n        if (val > max) {\n            max = val;\n        }\n    }\n    return max;\n};\nconst cache = {};\nconst getMaxPossibleMagnitude = (metadata) => {\n    if (cache[metadata.resultId]) {\n        return cache[metadata.resultId];\n    }\n    const result = (0, to_int_16_1.toInt16)(getMax(metadata.channelWaveforms[0]));\n    cache[metadata.resultId] = result;\n    return result;\n};\nexports.getMaxPossibleMagnitude = getMaxPossibleMagnitude;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.smoothen = void 0;\nconst smoothingPasses = 3;\nconst smoothingPoints = 3;\nconst smoothen = function (array) {\n    let lastArray = array;\n    const newArr = [];\n    for (let pass = 0; pass < smoothingPasses; pass++) {\n        const sidePoints = Math.floor(smoothingPoints / 2); // our window is centered so this is both nL and nR\n        const cn = 1 / (2 * sidePoints + 1); // constant\n        for (let i = 0; i < sidePoints; i++) {\n            newArr[i] = lastArray[i];\n            newArr[lastArray.length - i - 1] = lastArray[lastArray.length - i - 1];\n        }\n        for (let i = sidePoints; i < lastArray.length - sidePoints; i++) {\n            let sum = 0;\n            for (let n = -sidePoints; n <= sidePoints; n++) {\n                sum += cn * lastArray[i + n] + n;\n            }\n            newArr[i] = sum;\n        }\n        lastArray = newArr;\n    }\n    return newArr;\n};\nexports.smoothen = smoothen;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toInt16 = void 0;\nconst toInt16 = (x) => (x > 0 ? x * 0x7fff : x * 0x8000);\nexports.toInt16 = toInt16;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getAudioData = void 0;\nconst fetch_with_cors_catch_1 = require(\"./fetch-with-cors-catch\");\nconst is_remote_asset_1 = require(\"./is-remote-asset\");\nconst p_limit_1 = require(\"./p-limit\");\nconst metadataCache = {};\nconst limit = (0, p_limit_1.pLimit)(3);\nconst fn = async (src, options) => {\n    var _a;\n    if (metadataCache[src]) {\n        return metadataCache[src];\n    }\n    if (typeof document === 'undefined') {\n        throw new Error('getAudioData() is only available in the browser.');\n    }\n    const audioContext = new AudioContext({\n        sampleRate: (_a = options === null || options === void 0 ? void 0 : options.sampleRate) !== null && _a !== void 0 ? _a : 48000,\n    });\n    const response = await (0, fetch_with_cors_catch_1.fetchWithCorsCatch)(src);\n    if (!response.ok) {\n        throw new Error(`Failed to fetch audio data from ${src}: ${response.status} ${response.statusText}`);\n    }\n    const arrayBuffer = await response.arrayBuffer();\n    const wave = await audioContext.decodeAudioData(arrayBuffer);\n    const channelWaveforms = new Array(wave.numberOfChannels)\n        .fill(true)\n        .map((_, channel) => {\n        return wave.getChannelData(channel);\n    });\n    const metadata = {\n        channelWaveforms,\n        sampleRate: wave.sampleRate,\n        durationInSeconds: wave.duration,\n        numberOfChannels: wave.numberOfChannels,\n        resultId: String(Math.random()),\n        isRemote: (0, is_remote_asset_1.isRemoteAsset)(src),\n    };\n    metadataCache[src] = metadata;\n    return metadata;\n};\n/*\n * @description Takes an audio or video src, loads it and returns data and metadata for the specified source.\n * @see [Documentation](https://remotion.dev/docs/get-audio-data)\n */\nconst getAudioData = (src, options) => {\n    return limit(fn, src, options);\n};\nexports.getAudioData = getAudioData;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getAudioDuration = exports.getAudioDurationInSeconds = void 0;\n/* eslint-disable @typescript-eslint/no-use-before-define */\nconst media_tag_error_handling_1 = require(\"./media-tag-error-handling\");\nconst p_limit_1 = require(\"./p-limit\");\nconst limit = (0, p_limit_1.pLimit)(3);\nconst metadataCache = {};\nconst fn = (src) => {\n    if (metadataCache[src]) {\n        return Promise.resolve(metadataCache[src]);\n    }\n    if (typeof document === 'undefined') {\n        throw new Error('getAudioDuration() is only available in the browser.');\n    }\n    const audio = document.createElement('audio');\n    audio.src = src;\n    return new Promise((resolve, reject) => {\n        const onError = () => {\n            (0, media_tag_error_handling_1.onMediaError)({\n                error: audio.error,\n                src,\n                cleanup,\n                reject,\n                api: 'getAudioDurationInSeconds()',\n            });\n        };\n        const onLoadedMetadata = () => {\n            metadataCache[src] = audio.duration;\n            resolve(audio.duration);\n            cleanup();\n        };\n        const cleanup = () => {\n            audio.removeEventListener('loadedmetadata', onLoadedMetadata);\n            audio.removeEventListener('error', onError);\n            audio.remove();\n        };\n        audio.addEventListener('loadedmetadata', onLoadedMetadata, { once: true });\n        audio.addEventListener('error', onError, { once: true });\n    });\n};\n/**\n * @description Gets the duration in seconds of an audio source by creating an invisible `<audio>` tag, loading the audio, and returning the duration.\n * @see [Documentation](https://remotion.dev/docs/get-audio-duration-in-seconds)\n * @deprecated Use `parseMedia()` instead: https://www.remotion.dev/docs/media-parser/parse-media\n */\nconst getAudioDurationInSeconds = (src) => {\n    return limit(fn, src);\n};\nexports.getAudioDurationInSeconds = getAudioDurationInSeconds;\n/**\n * @deprecated Renamed to `getAudioDurationInSeconds`\n */\nconst getAudioDuration = (src) => (0, exports.getAudioDurationInSeconds)(src);\nexports.getAudioDuration = getAudioDuration;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getImageDimensions = getImageDimensions;\nconst p_limit_1 = require(\"./p-limit\");\nconst imageDimensionsCache = {};\nconst limit = (0, p_limit_1.pLimit)(3);\nconst fn = async (src) => {\n    if (imageDimensionsCache[src]) {\n        return imageDimensionsCache[src];\n    }\n    if (typeof document === 'undefined') {\n        throw new Error('getImageDimensions() is only available in the browser.');\n    }\n    const imageDimensions = await new Promise((resolved, reject) => {\n        const image = new Image();\n        image.onload = () => {\n            const { width, height } = image;\n            resolved({ width, height });\n        };\n        image.onerror = reject;\n        image.src = src;\n    });\n    imageDimensionsCache[src] = imageDimensions;\n    return imageDimensions;\n};\n/*\n * @description Takes an image src, retrieves the dimensions of an image.\n * @see [Documentation](https://remotion.dev/docs/get-image-dimensions)\n */\nfunction getImageDimensions(src) {\n    return limit(fn, src);\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getPartialAudioData = void 0;\nconst mediabunny_1 = require(\"mediabunny\");\n// Audio frames might have dependencies on previous and next frames so we need to decode a bit more and then discard it.\n// The worst case seems to be FLAC files with a 65'535 sample window, which would be 1486.0ms at 44.1Khz.\n// So let's set a threshold of 1.5 seconds.\nconst EXTRA_THRESHOLD_IN_SECONDS = 1.5;\nconst getPartialAudioData = async ({ track, fromSeconds, toSeconds, channelIndex, signal, isMatroska = false, }) => {\n    if (signal.aborted) {\n        throw new Error('Operation was aborted');\n    }\n    const audioSamples = [];\n    // matroska must be decoded from the start due to limitation\n    // https://www.remotion.dev/docs/media/support#matroska-limitation\n    // Also request extra data beforehand to handle audio frame dependencies\n    const actualFromSeconds = isMatroska\n        ? 0\n        : Math.max(0, fromSeconds - EXTRA_THRESHOLD_IN_SECONDS);\n    // mediabunny docs: constructing the sink is virtually free and does not perform any media data reads.\n    const sink = new mediabunny_1.AudioBufferSink(track);\n    const iterator = sink.buffers(actualFromSeconds, toSeconds);\n    for await (const { buffer, timestamp, duration } of iterator) {\n        if (signal.aborted) {\n            break;\n        }\n        const channelData = buffer.getChannelData(channelIndex);\n        const bufferStartSeconds = timestamp;\n        const bufferEndSeconds = timestamp + duration;\n        const overlapStartSecond = Math.max(bufferStartSeconds, fromSeconds);\n        const overlapEndSecond = Math.min(bufferEndSeconds, toSeconds);\n        if (overlapStartSecond >= overlapEndSecond) {\n            continue;\n        }\n        const startSampleInBuffer = Math.floor((overlapStartSecond - bufferStartSeconds) * buffer.sampleRate);\n        const endSampleInBuffer = Math.ceil((overlapEndSecond - bufferStartSeconds) * buffer.sampleRate);\n        const trimmedData = channelData.slice(startSampleInBuffer, endSampleInBuffer);\n        audioSamples.push(trimmedData);\n    }\n    await iterator.return();\n    const totalSamples = audioSamples.reduce((sum, sample) => sum + sample.length, 0);\n    const result = new Float32Array(totalSamples);\n    let offset = 0;\n    for (const audioSample of audioSamples) {\n        result.set(audioSample, offset);\n        offset += audioSample.length;\n    }\n    return result;\n};\nexports.getPartialAudioData = getPartialAudioData;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getVideoMetadata = void 0;\n/* eslint-disable @typescript-eslint/no-use-before-define */\nconst is_remote_asset_1 = require(\"./is-remote-asset\");\nconst media_tag_error_handling_1 = require(\"./media-tag-error-handling\");\nconst p_limit_1 = require(\"./p-limit\");\nconst cache = {};\nconst limit = (0, p_limit_1.pLimit)(3);\nconst fn = (src) => {\n    if (cache[src]) {\n        return Promise.resolve(cache[src]);\n    }\n    if (typeof document === 'undefined') {\n        throw new Error('getVideoMetadata() is only available in the browser.');\n    }\n    const video = document.createElement('video');\n    video.src = src;\n    return new Promise((resolve, reject) => {\n        const onError = () => {\n            (0, media_tag_error_handling_1.onMediaError)({\n                error: video.error,\n                src,\n                cleanup,\n                reject,\n                api: 'getVideoMetadata()',\n            });\n        };\n        const onLoadedMetadata = () => {\n            const pixels = video.videoHeight * video.videoWidth;\n            if (pixels === 0) {\n                reject(new Error(`Unable to determine video metadata for ${src}`));\n                return;\n            }\n            if (!Number.isFinite(video.duration)) {\n                reject(new Error(`Unable to determine video duration for ${src} - got Infinity. Re-encoding this video may fix this issue.`));\n                return;\n            }\n            const metadata = {\n                durationInSeconds: video.duration,\n                width: video.videoWidth,\n                height: video.videoHeight,\n                aspectRatio: video.videoWidth / video.videoHeight,\n                isRemote: (0, is_remote_asset_1.isRemoteAsset)(src),\n            };\n            resolve(metadata);\n            cache[src] = metadata;\n            cleanup();\n        };\n        const cleanup = () => {\n            video.removeEventListener('loadedmetadata', onLoadedMetadata);\n            video.removeEventListener('error', onError);\n            video.remove();\n        };\n        video.addEventListener('loadedmetadata', onLoadedMetadata, { once: true });\n        video.addEventListener('error', onError, { once: true });\n    });\n};\n/**\n * @description Takes a src to a video, loads it and returns metadata for the specified source.\n * @see [Documentation](https://remotion.dev/docs/get-video-metadata)\n * @deprecated Use `parseMedia()` instead: https://www.remotion.dev/docs/miscellaneous/parse-media-vs-get-video-metadata\n */\nconst getVideoMetadata = (src) => {\n    return limit(fn, src);\n};\nexports.getVideoMetadata = getVideoMetadata;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getWaveformSamples = void 0;\nconst normalize_data_1 = require(\"./normalize-data\");\nconst getWaveformSamples = ({ audioBuffer, numberOfSamples, outputRange, normalize, }) => {\n    const blockSize = Math.floor(audioBuffer.length / numberOfSamples); // the number of samples in each subdivision\n    if (blockSize === 0) {\n        return [];\n    }\n    const filteredData = [];\n    for (let i = 0; i < numberOfSamples; i++) {\n        const blockStart = blockSize * i; // the location of the first sample in the block\n        let sum = 0;\n        for (let j = 0; j < blockSize; j++) {\n            sum += Math.abs(audioBuffer[blockStart + j]); // find the sum of all the samples in the block\n        }\n        filteredData.push(sum / blockSize); // divide the sum by the block size to get the average\n    }\n    if (normalize) {\n        if (outputRange === 'minus-one-to-one') {\n            return (0, normalize_data_1.normalizeData)(filteredData).map((n, i) => {\n                if (i % 2 === 0) {\n                    return n * -1;\n                }\n                return n;\n            });\n        }\n        return (0, normalize_data_1.normalizeData)(filteredData);\n    }\n    if (outputRange === 'minus-one-to-one') {\n        return filteredData.map((n, i) => {\n            if (i % 2 === 0) {\n                return n * -1;\n            }\n            return n;\n        });\n    }\n    return filteredData;\n};\nexports.getWaveformSamples = getWaveformSamples;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getWaveformPortion = void 0;\nconst no_react_1 = require(\"remotion/no-react\");\nconst get_wave_form_samples_1 = require(\"./get-wave-form-samples\");\nconst validate_channel_1 = require(\"./validate-channel\");\nconst concatArrays = (arrays) => {\n    // sum of individual array lengths\n    const totalLength = arrays.reduce((acc, value) => acc + value.length, 0);\n    const result = new Float32Array(totalLength);\n    // for each array - copy it over result\n    // next array is copied right after the previous one\n    let length = 0;\n    for (const array of arrays) {\n        result.set(array, length);\n        length += array.length;\n    }\n    return result;\n};\n/*\n * @description Takes bulky waveform data (for example fetched by getAudioData()) and returns a trimmed and simplified version of it, for simpler visualization\n * @see [Documentation](https://remotion.dev/docs/get-waveform-portion)\n */\nconst getWaveformPortion = ({ audioData, startTimeInSeconds, durationInSeconds, numberOfSamples, channel = 0, outputRange = 'zero-to-one', dataOffsetInSeconds, normalize = true, }) => {\n    (0, validate_channel_1.validateChannel)(channel, audioData.numberOfChannels);\n    const waveform = audioData.channelWaveforms[channel];\n    const startSample = Math.floor((startTimeInSeconds - (dataOffsetInSeconds !== null && dataOffsetInSeconds !== void 0 ? dataOffsetInSeconds : 0)) * audioData.sampleRate);\n    const endSample = Math.floor((startTimeInSeconds - (dataOffsetInSeconds !== null && dataOffsetInSeconds !== void 0 ? dataOffsetInSeconds : 0) + durationInSeconds) *\n        audioData.sampleRate);\n    const samplesBeforeStart = 0 - startSample;\n    const samplesAfterEnd = endSample - waveform.length;\n    const clampedStart = Math.max(startSample, 0);\n    const clampedEnd = Math.min(waveform.length, endSample);\n    const padStart = samplesBeforeStart > 0\n        ? new Float32Array(samplesBeforeStart).fill(0)\n        : null;\n    const padEnd = samplesAfterEnd > 0 ? new Float32Array(samplesAfterEnd).fill(0) : null;\n    const arrs = [\n        padStart,\n        waveform.slice(clampedStart, clampedEnd),\n        padEnd,\n    ].filter(no_react_1.NoReactInternals.truthy);\n    const audioBuffer = arrs.length === 1 ? arrs[0] : concatArrays(arrs);\n    return (0, get_wave_form_samples_1.getWaveformSamples)({\n        audioBuffer,\n        numberOfSamples,\n        outputRange,\n        normalize,\n    }).map((w, i) => {\n        return {\n            index: i,\n            amplitude: w,\n        };\n    });\n};\nexports.getWaveformPortion = getWaveformPortion;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.visualizeAudioWaveform = exports.visualizeAudio = exports.useWindowedAudioData = exports.useAudioData = exports.getWaveformPortion = exports.getVideoMetadata = exports.getImageDimensions = exports.getAudioDurationInSeconds = exports.getAudioDuration = exports.getAudioData = exports.createSmoothSvgPath = exports.audioBufferToDataUrl = void 0;\nvar audio_url_helpers_1 = require(\"./audio-buffer/audio-url-helpers\");\nObject.defineProperty(exports, \"audioBufferToDataUrl\", { enumerable: true, get: function () { return audio_url_helpers_1.audioBufferToDataUrl; } });\nvar create_smooth_svg_path_1 = require(\"./create-smooth-svg-path\");\nObject.defineProperty(exports, \"createSmoothSvgPath\", { enumerable: true, get: function () { return create_smooth_svg_path_1.createSmoothSvgPath; } });\nvar get_audio_data_1 = require(\"./get-audio-data\");\nObject.defineProperty(exports, \"getAudioData\", { enumerable: true, get: function () { return get_audio_data_1.getAudioData; } });\nvar get_audio_duration_in_seconds_1 = require(\"./get-audio-duration-in-seconds\");\nObject.defineProperty(exports, \"getAudioDuration\", { enumerable: true, get: function () { return get_audio_duration_in_seconds_1.getAudioDuration; } });\nObject.defineProperty(exports, \"getAudioDurationInSeconds\", { enumerable: true, get: function () { return get_audio_duration_in_seconds_1.getAudioDurationInSeconds; } });\nvar get_image_dimensions_1 = require(\"./get-image-dimensions\");\nObject.defineProperty(exports, \"getImageDimensions\", { enumerable: true, get: function () { return get_image_dimensions_1.getImageDimensions; } });\nvar get_video_metadata_1 = require(\"./get-video-metadata\");\nObject.defineProperty(exports, \"getVideoMetadata\", { enumerable: true, get: function () { return get_video_metadata_1.getVideoMetadata; } });\nvar get_waveform_portion_1 = require(\"./get-waveform-portion\");\nObject.defineProperty(exports, \"getWaveformPortion\", { enumerable: true, get: function () { return get_waveform_portion_1.getWaveformPortion; } });\n__exportStar(require(\"./types\"), exports);\nvar use_audio_data_1 = require(\"./use-audio-data\");\nObject.defineProperty(exports, \"useAudioData\", { enumerable: true, get: function () { return use_audio_data_1.useAudioData; } });\nvar use_windowed_audio_data_1 = require(\"./use-windowed-audio-data\");\nObject.defineProperty(exports, \"useWindowedAudioData\", { enumerable: true, get: function () { return use_windowed_audio_data_1.useWindowedAudioData; } });\nvar visualize_audio_1 = require(\"./visualize-audio\");\nObject.defineProperty(exports, \"visualizeAudio\", { enumerable: true, get: function () { return visualize_audio_1.visualizeAudio; } });\nvar visualize_audio_waveform_1 = require(\"./visualize-audio-waveform\");\nObject.defineProperty(exports, \"visualizeAudioWaveform\", { enumerable: true, get: function () { return visualize_audio_waveform_1.visualizeAudioWaveform; } });\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.isRemoteAsset = void 0;\nconst isRemoteAsset = (asset) => !asset.startsWith(window.origin) && !asset.startsWith('data');\nexports.isRemoteAsset = isRemoteAsset;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.onMediaError = void 0;\nasync function fetchWithTimeout(url, options, timeout = 3000) {\n    const controller = new AbortController();\n    const id = setTimeout(() => controller.abort(), timeout);\n    options.signal = controller.signal;\n    try {\n        const response = await fetch(url, options);\n        clearTimeout(id);\n        return response;\n    }\n    catch (_a) {\n        clearTimeout(id);\n        throw new Error(`Fetch timed out after ${timeout}ms`);\n    }\n}\nconst checkFor404 = (src) => {\n    return fetchWithTimeout(src, {\n        method: 'HEAD',\n        mode: 'no-cors',\n    }).then((res) => res.status);\n};\nconst checkFor404OrSkip = async ({ suspecting404, sameOrigin, src, }) => {\n    if (!suspecting404) {\n        return Promise.resolve(null);\n    }\n    if (!sameOrigin) {\n        return Promise.resolve(null);\n    }\n    try {\n        return await checkFor404(src);\n    }\n    catch (_a) {\n        return Promise.resolve(null);\n    }\n};\nconst onMediaError = ({ error, src, reject, cleanup, api, }) => {\n    const suspecting404 = error.MEDIA_ERR_SRC_NOT_SUPPORTED === error.code;\n    const isSrcSameOriginAsCurrent = new URL(src, window.location.origin)\n        .toString()\n        .startsWith(window.location.origin);\n    checkFor404OrSkip({\n        suspecting404,\n        sameOrigin: isSrcSameOriginAsCurrent,\n        src,\n    })\n        .then((status) => {\n        const err = status === 404\n            ? new Error([\n                `Failed to execute ${api}: Received a 404 error loading \"${src}\".`,\n                'Correct the URL of the file.',\n            ].join(' '))\n            : new Error([\n                `Failed to execute ${api}, Received a MediaError loading \"${src}\". Consider using parseMedia() instead which supports more codecs: https://www.remotion.dev/docs/miscellaneous/parse-media-vs-get-video-metadata`,\n                status === null\n                    ? null\n                    : `HTTP Status code of the file: ${status}.`,\n                error.message\n                    ? `Browser error message: ${error.message}`\n                    : null,\n                'Check the path of the file and if it is a valid video.',\n            ]\n                .filter(Boolean)\n                .join(' '));\n        reject(err);\n        cleanup();\n    })\n        .catch((e) => {\n        reject(e);\n        cleanup();\n    });\n};\nexports.onMediaError = onMediaError;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.normalizeData = void 0;\nconst normalizeData = (filteredData) => {\n    const max = Math.max(...filteredData);\n    const multiplier = max === 0 ? 0 : max ** -1;\n    return filteredData.map((n) => n * multiplier);\n};\nexports.normalizeData = normalizeData;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.pLimit = void 0;\nconst pLimit = (concurrency) => {\n    const queue = [];\n    let activeCount = 0;\n    const next = () => {\n        var _a;\n        activeCount--;\n        if (queue.length > 0) {\n            (_a = queue.shift()) === null || _a === void 0 ? void 0 : _a();\n        }\n    };\n    const run = async (fn, resolve, ...args) => {\n        activeCount++;\n        // eslint-disable-next-line require-await\n        const result = (async () => fn(...args))();\n        resolve(result);\n        try {\n            await result;\n        }\n        catch (_a) { }\n        next();\n    };\n    const enqueue = (fn, resolve, ...args) => {\n        queue.push(() => run(fn, resolve, ...args));\n        (async () => {\n            var _a;\n            // This function needs to wait until the next microtask before comparing\n            // `activeCount` to `concurrency`, because `activeCount` is updated asynchronously\n            // when the run function is dequeued and called. The comparison in the if-statement\n            // needs to happen asynchronously as well to get an up-to-date value for `activeCount`.\n            await Promise.resolve();\n            if (activeCount < concurrency && queue.length > 0) {\n                (_a = queue.shift()) === null || _a === void 0 ? void 0 : _a();\n            }\n        })();\n    };\n    const generator = (fn, ...args) => new Promise((resolve) => {\n        enqueue(fn, resolve, ...args);\n    });\n    Object.defineProperties(generator, {\n        activeCount: {\n            get: () => activeCount,\n        },\n        pendingCount: {\n            get: () => queue.length,\n        },\n        clearQueue: {\n            value: () => {\n                queue.length = 0;\n            },\n        },\n    });\n    return generator;\n};\nexports.pLimit = pLimit;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.useAudioData = void 0;\nconst react_1 = require(\"react\");\nconst remotion_1 = require(\"remotion\");\nconst get_audio_data_1 = require(\"./get-audio-data\");\n/*\n * @description Wraps the getAudioData() function into a hook and does three things: keeps the audio data in a state, wraps the function in a delayRender() / continueRender() pattern, and handles the case where the component gets unmounted while fetching is in progress to prevent React errors.\n * @see [Documentation](https://www.remotion.dev/docs/use-audio-data)\n */\nconst useAudioData = (src) => {\n    if (!src) {\n        throw new TypeError(\"useAudioData requires a 'src' parameter\");\n    }\n    const mountState = (0, react_1.useRef)({ isMounted: true });\n    (0, react_1.useEffect)(() => {\n        const { current } = mountState;\n        current.isMounted = true;\n        return () => {\n            current.isMounted = false;\n        };\n    }, []);\n    const [metadata, setMetadata] = (0, react_1.useState)(null);\n    const { delayRender, continueRender } = (0, remotion_1.useDelayRender)();\n    const fetchMetadata = (0, react_1.useCallback)(async () => {\n        const handle = delayRender(`Waiting for audio metadata with src=\"${src}\" to be loaded`);\n        try {\n            const data = await (0, get_audio_data_1.getAudioData)(src);\n            if (mountState.current.isMounted) {\n                setMetadata(data);\n            }\n        }\n        catch (err) {\n            (0, remotion_1.cancelRender)(err);\n        }\n        continueRender(handle);\n    }, [src, delayRender, continueRender]);\n    (0, react_1.useLayoutEffect)(() => {\n        fetchMetadata();\n    }, [fetchMetadata]);\n    return metadata;\n};\nexports.useAudioData = useAudioData;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.useWindowedAudioData = void 0;\nconst mediabunny_1 = require(\"mediabunny\");\nconst react_1 = require(\"react\");\nconst remotion_1 = require(\"remotion\");\nconst combine_float32_arrays_1 = require(\"./combine-float32-arrays\");\nconst get_partial_audio_data_1 = require(\"./get-partial-audio-data\");\nconst is_remote_asset_1 = require(\"./is-remote-asset\");\nconst warnedMatroska = {};\nconst useWindowedAudioData = ({ src, frame, fps, windowInSeconds, channelIndex = 0, }) => {\n    const isMounted = (0, react_1.useRef)(true);\n    const [audioUtils, setAudioUtils] = (0, react_1.useState)(null);\n    const [waveFormMap, setWaveformMap] = (0, react_1.useState)({});\n    const requests = (0, react_1.useRef)({});\n    const [initialWindowInSeconds] = (0, react_1.useState)(windowInSeconds);\n    if (windowInSeconds !== initialWindowInSeconds) {\n        throw new Error('windowInSeconds cannot be changed dynamically');\n    }\n    (0, react_1.useEffect)(() => {\n        isMounted.current = true;\n        return () => {\n            isMounted.current = false;\n            Object.values(requests.current).forEach((controller) => {\n                if (controller) {\n                    controller.abort();\n                }\n            });\n            requests.current = {};\n            setWaveformMap({});\n            if (audioUtils) {\n                audioUtils.input.dispose();\n            }\n        };\n    }, [audioUtils]);\n    const { delayRender, continueRender } = (0, remotion_1.useDelayRender)();\n    const fetchMetadata = (0, react_1.useCallback)(async (signal) => {\n        const handle = delayRender(`Waiting for audio metadata with src=\"${src}\" to be loaded`);\n        const cont = () => {\n            continueRender(handle);\n        };\n        signal.addEventListener('abort', cont, { once: true });\n        const input = new mediabunny_1.Input({\n            formats: mediabunny_1.ALL_FORMATS,\n            source: new mediabunny_1.UrlSource(src),\n        });\n        const onAbort = () => {\n            input.dispose();\n        };\n        signal.addEventListener('abort', onAbort, { once: true });\n        try {\n            const durationInSeconds = await input.computeDuration();\n            const audioTrack = await input.getPrimaryAudioTrack();\n            if (!audioTrack) {\n                throw new Error('No audio track found');\n            }\n            const canDecode = await audioTrack.canDecode();\n            if (!canDecode) {\n                throw new Error('Audio track cannot be decoded');\n            }\n            if (channelIndex >= audioTrack.numberOfChannels || channelIndex < 0) {\n                throw new Error(`Invalid channel index ${channelIndex} for audio with ${audioTrack.numberOfChannels} channels`);\n            }\n            const { numberOfChannels, sampleRate } = audioTrack;\n            const format = await input.getFormat();\n            const isMatroska = format === mediabunny_1.MATROSKA || format === mediabunny_1.WEBM;\n            if (isMounted.current) {\n                setAudioUtils({\n                    input,\n                    track: audioTrack,\n                    metadata: {\n                        durationInSeconds,\n                        numberOfChannels,\n                        sampleRate,\n                    },\n                    isMatroska,\n                });\n            }\n            continueRender(handle);\n        }\n        catch (err) {\n            (0, remotion_1.cancelRender)(err);\n        }\n        finally {\n            signal.removeEventListener('abort', cont);\n            signal.removeEventListener('abort', onAbort);\n        }\n    }, [src, delayRender, continueRender, channelIndex]);\n    (0, react_1.useLayoutEffect)(() => {\n        const controller = new AbortController();\n        fetchMetadata(controller.signal);\n        return () => {\n            controller.abort();\n        };\n    }, [fetchMetadata]);\n    const currentTime = frame / fps;\n    const currentWindowIndex = Math.floor(currentTime / windowInSeconds);\n    const windowsToFetch = (0, react_1.useMemo)(() => {\n        if (!(audioUtils === null || audioUtils === void 0 ? void 0 : audioUtils.metadata)) {\n            return [];\n        }\n        const maxWindowIndex = Math.floor(\n        // If an audio is exactly divisible by windowInSeconds, we need to\n        // subtract 0.000000000001 to avoid fetching an extra window.\n        audioUtils.metadata.durationInSeconds / windowInSeconds - 0.000000000001);\n        // needs to be in order because we rely on the concatenation below\n        return [\n            currentWindowIndex === 0 ? null : currentWindowIndex - 1,\n            currentWindowIndex,\n            currentWindowIndex + 1 > maxWindowIndex ? null : currentWindowIndex + 1,\n        ]\n            .filter((i) => i !== null)\n            .filter((i) => i >= 0);\n    }, [currentWindowIndex, audioUtils, windowInSeconds]);\n    const fetchAndSetWaveformData = (0, react_1.useCallback)(async (windowIndex) => {\n        if (!(audioUtils === null || audioUtils === void 0 ? void 0 : audioUtils.metadata) || !audioUtils) {\n            throw new Error('MediaBunny context is not loaded yet');\n        }\n        // Cancel any existing request for this window, we don't want to over-fetch\n        const existingController = requests.current[windowIndex];\n        if (existingController) {\n            existingController.abort();\n        }\n        const controller = new AbortController();\n        requests.current[windowIndex] = controller;\n        if (controller.signal.aborted) {\n            return;\n        }\n        const fromSeconds = windowIndex * windowInSeconds;\n        const toSeconds = (windowIndex + 1) * windowInSeconds;\n        // if both fromSeconds and toSeconds are outside of the audio duration, skip fetching\n        if (fromSeconds >= audioUtils.metadata.durationInSeconds ||\n            toSeconds <= 0) {\n            return;\n        }\n        try {\n            const { isMatroska } = audioUtils;\n            if (isMatroska && !warnedMatroska[src]) {\n                warnedMatroska[src] = true;\n                remotion_1.Internals.Log.warn({ logLevel: 'info', tag: '@remotion/media-utils' }, `[useWindowedAudioData] Matroska/WebM file detected at \"${src}\".\\n\\nDue to format limitation, audio decoding must start from the beginning of the file, which may lead to increased memory usage and slower performance for large files. Consider converting the audio to a more suitable format like MP3 or AAC for better performance.`);\n            }\n            const partialWaveData = await (0, get_partial_audio_data_1.getPartialAudioData)({\n                track: audioUtils.track,\n                fromSeconds,\n                toSeconds,\n                channelIndex,\n                signal: controller.signal,\n                isMatroska,\n            });\n            if (!controller.signal.aborted) {\n                setWaveformMap((prev) => {\n                    const entries = Object.keys(prev);\n                    const windowsToClear = entries.filter((entry) => !windowsToFetch.includes(Number(entry)));\n                    return {\n                        ...prev,\n                        ...windowsToClear.reduce((acc, key) => {\n                            acc[key] = null;\n                            return acc;\n                        }, {}),\n                        [windowIndex]: partialWaveData,\n                    };\n                });\n            }\n        }\n        catch (err) {\n            if (controller.signal.aborted) {\n                return;\n            }\n            if (err instanceof mediabunny_1.InputDisposedError) {\n                return;\n            }\n            throw err;\n        }\n        finally {\n            if (requests.current[windowIndex] === controller) {\n                requests.current[windowIndex] = null;\n            }\n        }\n    }, [channelIndex, audioUtils, windowInSeconds, windowsToFetch, src]);\n    (0, react_1.useEffect)(() => {\n        if (!(audioUtils === null || audioUtils === void 0 ? void 0 : audioUtils.metadata)) {\n            return;\n        }\n        const windowsToClear = Object.keys(requests.current).filter((entry) => !windowsToFetch.includes(Number(entry)));\n        for (const windowIndex of windowsToClear) {\n            const controller = requests.current[windowIndex];\n            if (controller) {\n                controller.abort();\n                requests.current[windowIndex] = null;\n            }\n        }\n        // Only fetch windows that don't already exist\n        const windowsToActuallyFetch = windowsToFetch.filter((windowIndex) => !waveFormMap[windowIndex] && !requests.current[windowIndex]);\n        if (windowsToActuallyFetch.length === 0) {\n            return;\n        }\n        // Prioritize the current window where playback is at.\n        // On slow connections, this ensures the most important window loads first.\n        const currentWindowNeedsFetch = windowsToActuallyFetch.includes(currentWindowIndex);\n        const otherWindowsToFetch = windowsToActuallyFetch.filter((w) => w !== currentWindowIndex);\n        const fetchWindows = async () => {\n            // First, load the current window where playback is at\n            if (currentWindowNeedsFetch) {\n                await fetchAndSetWaveformData(currentWindowIndex);\n            }\n            // Then load the surrounding windows in parallel\n            if (otherWindowsToFetch.length > 0) {\n                await Promise.all(otherWindowsToFetch.map((windowIndex) => {\n                    return fetchAndSetWaveformData(windowIndex);\n                }));\n            }\n        };\n        fetchWindows().catch((err) => {\n            var _a, _b, _c, _d, _e;\n            if ((_a = err.stack) === null || _a === void 0 ? void 0 : _a.includes('Cancelled')) {\n                return;\n            }\n            if ((_c = (_b = err.stack) === null || _b === void 0 ? void 0 : _b.toLowerCase()) === null || _c === void 0 ? void 0 : _c.includes('aborted')) {\n                return;\n            }\n            // firefox\n            if ((_e = (_d = err.message) === null || _d === void 0 ? void 0 : _d.toLowerCase()) === null || _e === void 0 ? void 0 : _e.includes('aborted')) {\n                return;\n            }\n            (0, remotion_1.cancelRender)(err);\n        });\n    }, [\n        fetchAndSetWaveformData,\n        audioUtils,\n        windowsToFetch,\n        waveFormMap,\n        currentWindowIndex,\n    ]);\n    // Calculate available windows for reuse\n    const availableWindows = (0, react_1.useMemo)(() => {\n        return windowsToFetch.filter((i) => waveFormMap[i]);\n    }, [windowsToFetch, waveFormMap]);\n    const currentAudioData = (0, react_1.useMemo)(() => {\n        if (!(audioUtils === null || audioUtils === void 0 ? void 0 : audioUtils.metadata)) {\n            return null;\n        }\n        if (availableWindows.length === 0) {\n            return null;\n        }\n        const windows = availableWindows.map((i) => waveFormMap[i]);\n        const data = (0, combine_float32_arrays_1.combineFloat32Arrays)(windows);\n        return {\n            channelWaveforms: [data],\n            durationInSeconds: audioUtils.metadata.durationInSeconds,\n            isRemote: (0, is_remote_asset_1.isRemoteAsset)(src),\n            numberOfChannels: 1,\n            resultId: `${src}-windows-${availableWindows.join(',')}`,\n            sampleRate: audioUtils.metadata.sampleRate,\n        };\n    }, [src, waveFormMap, audioUtils, availableWindows]);\n    const isBeyondAudioDuration = audioUtils\n        ? currentTime >= audioUtils.metadata.durationInSeconds\n        : false;\n    (0, react_1.useLayoutEffect)(() => {\n        if (currentAudioData) {\n            return;\n        }\n        if (isBeyondAudioDuration) {\n            return;\n        }\n        const handle = delayRender(`Waiting for audio data with src=\"${src}\" to be loaded`);\n        return () => {\n            continueRender(handle);\n        };\n    }, [\n        currentAudioData,\n        src,\n        delayRender,\n        continueRender,\n        isBeyondAudioDuration,\n    ]);\n    const audioData = isBeyondAudioDuration ? null : currentAudioData;\n    return {\n        audioData,\n        dataOffsetInSeconds: availableWindows.length > 0 ? availableWindows[0] * windowInSeconds : 0,\n    };\n};\nexports.useWindowedAudioData = useWindowedAudioData;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.validateChannel = void 0;\nconst validateChannel = (channel, numberOfChannels) => {\n    if (typeof channel !== 'number') {\n        throw new TypeError(`\"channel\" must be a number`);\n    }\n    if (channel % 1 !== 0) {\n        throw new TypeError(`\"channel\" must an integer, got ${channel}`);\n    }\n    if (Number.isNaN(channel)) {\n        throw new TypeError(`The channel parameter is NaN.`);\n    }\n    if (channel < 0) {\n        throw new TypeError('\"channel\" cannot be negative');\n    }\n    if (channel > numberOfChannels - 1) {\n        throw new TypeError(`\"channel\" must be ${numberOfChannels - 1} or lower. The audio has ${numberOfChannels} channels`);\n    }\n};\nexports.validateChannel = validateChannel;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.visualizeAudioWaveform = void 0;\nconst get_waveform_portion_1 = require(\"./get-waveform-portion\");\nconst cache = {};\nconst visualizeAudioWaveformFrame = ({ audioData, frame, fps, numberOfSamples, windowInSeconds, channel, dataOffsetInSeconds, normalize = false, }) => {\n    if (windowInSeconds * audioData.sampleRate < numberOfSamples) {\n        throw new TypeError(windowInSeconds +\n            's audiodata does not have ' +\n            numberOfSamples +\n            ' bars. Increase windowInSeconds or decrease numberOfSamples');\n    }\n    const cacheKey = audioData.resultId +\n        frame +\n        fps +\n        numberOfSamples +\n        'waveform' +\n        dataOffsetInSeconds;\n    if (cache[cacheKey]) {\n        return cache[cacheKey];\n    }\n    const time = frame / fps;\n    const startTimeInSeconds = time - windowInSeconds / 2;\n    return (0, get_waveform_portion_1.getWaveformPortion)({\n        audioData,\n        startTimeInSeconds,\n        durationInSeconds: windowInSeconds,\n        numberOfSamples,\n        outputRange: 'minus-one-to-one',\n        channel,\n        dataOffsetInSeconds,\n        normalize,\n    });\n};\nconst visualizeAudioWaveform = (parameters) => {\n    const data = visualizeAudioWaveformFrame(parameters);\n    return data.map((value) => value.amplitude);\n};\nexports.visualizeAudioWaveform = visualizeAudioWaveform;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.visualizeAudio = void 0;\nconst no_react_1 = require(\"remotion/no-react\");\nconst get_visualization_1 = require(\"./fft/get-visualization\");\nconst max_value_cached_1 = require(\"./fft/max-value-cached\");\nconst cache = {};\n/**\n * @description Takes in AudioData (preferably fetched by the useAudioData() hook) and processes it in a way that makes visualizing the audio that is playing at the current frame easy.\n * @description part of @remotion/media-utils\n * @see [Documentation](https://www.remotion.dev/docs/visualize-audio)\n */\nconst visualizeAudioFrame = ({ audioData, frame, fps, numberOfSamples, optimizeFor, dataOffsetInSeconds, }) => {\n    const cacheKey = audioData.resultId + frame + fps + numberOfSamples;\n    if (cache[cacheKey]) {\n        return cache[cacheKey];\n    }\n    const maxInt = (0, max_value_cached_1.getMaxPossibleMagnitude)(audioData);\n    return (0, get_visualization_1.getVisualization)({\n        sampleSize: numberOfSamples * 2,\n        data: audioData.channelWaveforms[0],\n        frame,\n        fps,\n        sampleRate: audioData.sampleRate,\n        maxInt,\n        optimizeFor,\n        dataOffsetInSeconds,\n    });\n};\nconst visualizeAudio = ({ smoothing = true, optimizeFor = no_react_1.NoReactInternals.ENABLE_V5_BREAKING_CHANGES\n    ? 'speed'\n    : 'accuracy', dataOffsetInSeconds = 0, ...parameters }) => {\n    if (!smoothing) {\n        return visualizeAudioFrame({\n            ...parameters,\n            optimizeFor,\n            dataOffsetInSeconds,\n            smoothing,\n        });\n    }\n    const toSmooth = [\n        parameters.frame - 1,\n        parameters.frame,\n        parameters.frame + 1,\n    ];\n    const all = toSmooth.map((s) => {\n        return visualizeAudioFrame({\n            ...parameters,\n            frame: s,\n            dataOffsetInSeconds,\n            optimizeFor,\n            smoothing,\n        });\n    });\n    return new Array(parameters.numberOfSamples).fill(true).map((_x, i) => {\n        return (new Array(toSmooth.length)\n            .fill(true)\n            .map((_, j) => {\n            return all[j][i];\n        })\n            .reduce((a, b) => a + b, 0) / toSmooth.length);\n    });\n};\nexports.visualizeAudio = visualizeAudio;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.stripAnsi = void 0;\nexports.splitAnsi = splitAnsi;\nconst ansiRegex = () => {\n    const pattern = [\n        '[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\d]+(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]*)*)?\\\\u0007)',\n        '(?:(?:\\\\d{1,4}(?:;\\\\d{0,4})*)?[\\\\dA-PR-TZcf-nq-uy=><~]))',\n    ].join('|');\n    return new RegExp(pattern, 'g');\n};\nfunction splitAnsi(str) {\n    const parts = str.match(ansiRegex());\n    if (!parts)\n        return [str];\n    const result = [];\n    let offset = 0;\n    let ptr = 0;\n    for (let i = 0; i < parts.length; i++) {\n        offset = str.indexOf(parts[i], offset);\n        if (offset === -1)\n            throw new Error('Could not split string');\n        if (ptr !== offset)\n            result.push(str.slice(ptr, offset));\n        if (ptr === offset && result.length) {\n            result[result.length - 1] += parts[i];\n        }\n        else {\n            if (offset === 0)\n                result.push('');\n            result.push(parts[i]);\n        }\n        ptr = offset + parts[i].length;\n    }\n    result.push(str.slice(ptr));\n    return result;\n}\nconst stripAnsi = (str) => {\n    if (typeof str !== 'string') {\n        throw new TypeError(`Expected a \\`string\\`, got \\`${typeof str}\\``);\n    }\n    return str.replace(ansiRegex(), '');\n};\nexports.stripAnsi = stripAnsi;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.DEFAULT_BUFFER_STATE_DELAY_IN_MILLISECONDS = void 0;\nexports.DEFAULT_BUFFER_STATE_DELAY_IN_MILLISECONDS = 300;\n","'use strict';\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.formatBytes = void 0;\nconst BYTE_UNITS = ['B', 'kB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'];\nconst BIBYTE_UNITS = [\n    'B',\n    'kiB',\n    'MiB',\n    'GiB',\n    'TiB',\n    'PiB',\n    'EiB',\n    'ZiB',\n    'YiB',\n];\nconst BIT_UNITS = [\n    'b',\n    'kbit',\n    'Mbit',\n    'Gbit',\n    'Tbit',\n    'Pbit',\n    'Ebit',\n    'Zbit',\n    'Ybit',\n];\nconst BIBIT_UNITS = [\n    'b',\n    'kibit',\n    'Mibit',\n    'Gibit',\n    'Tibit',\n    'Pibit',\n    'Eibit',\n    'Zibit',\n    'Yibit',\n];\n/*\nFormats the given number using `Number#toLocaleString`.\n- If locale is a string, the value is expected to be a locale-key (for example: `de`).\n- If locale is true, the system default locale is used for translation.\n- If no value for locale is specified, the number is returned unmodified.\n*/\nconst toLocaleString = (number, locale, options) => {\n    if (typeof locale === 'string' || Array.isArray(locale)) {\n        return number.toLocaleString(locale, options);\n    }\n    if (locale === true || options !== undefined) {\n        return number.toLocaleString(undefined, options);\n    }\n    return String(number);\n};\nconst formatBytes = (number, options = {\n    locale: 'en-US',\n    signed: false,\n    maximumFractionDigits: 1,\n}) => {\n    if (!Number.isFinite(number)) {\n        throw new TypeError(`Expected a finite number, got ${typeof number}: ${number}`);\n    }\n    options = { bits: false, binary: false, ...options };\n    const UNITS = options.bits\n        ? options.binary\n            ? BIBIT_UNITS\n            : BIT_UNITS\n        : options.binary\n            ? BIBYTE_UNITS\n            : BYTE_UNITS;\n    if (options.signed && number === 0) {\n        return `0 $ {\n            UNITS[0]\n        }`;\n    }\n    const isNegative = number < 0;\n    const prefix = isNegative ? '-' : options.signed ? '+' : '';\n    if (isNegative) {\n        number = -number;\n    }\n    let localeOptions;\n    if (options.minimumFractionDigits !== undefined) {\n        localeOptions = {\n            minimumFractionDigits: options.minimumFractionDigits,\n        };\n    }\n    if (options.maximumFractionDigits !== undefined) {\n        localeOptions = {\n            maximumFractionDigits: options.maximumFractionDigits,\n            ...localeOptions,\n        };\n    }\n    if (number < 1) {\n        const numString = toLocaleString(number, options.locale, localeOptions);\n        return prefix + numString + ' ' + UNITS[0];\n    }\n    const exponent = Math.min(Math.floor(options.binary\n        ? Math.log(number) / Math.log(1024)\n        : Math.log10(number) / 3), UNITS.length - 1);\n    number /= (options.binary ? 1024 : 1000) ** exponent;\n    const numberString = toLocaleString(Number(number), options.locale, localeOptions);\n    const unit = UNITS[exponent];\n    return prefix + numberString + ' ' + unit;\n};\nexports.formatBytes = formatBytes;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getDefaultOutLocation = void 0;\nconst getDefaultOutLocation = ({ compositionName, defaultExtension, type, compositionDefaultOutName, clientSideRender, }) => {\n    const nameToUse = compositionDefaultOutName !== null && compositionDefaultOutName !== void 0 ? compositionDefaultOutName : compositionName;\n    if (type === 'sequence') {\n        if (clientSideRender) {\n            return nameToUse;\n        }\n        return `out/${nameToUse}`;\n    }\n    if (clientSideRender) {\n        return `${nameToUse}.${defaultExtension}`;\n    }\n    return `out/${nameToUse}.${defaultExtension}`;\n};\nexports.getDefaultOutLocation = getDefaultOutLocation;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getLocationFromBuildError = void 0;\nconst no_react_1 = require(\"remotion/no-react\");\nconst getLocationFromBuildError = (err) => {\n    var _a;\n    if (!err.stack) {\n        return null;\n    }\n    if (!err.stack.startsWith('Error: Module build failed') &&\n        !err.stack.startsWith('Error: Cannot find module')) {\n        return null;\n    }\n    const split = err.stack.split('\\n');\n    return ((_a = split\n        .map((s) => {\n        if (s.startsWith('Error')) {\n            return null;\n        }\n        const matchWebpackOrEsbuild = s.match(/(.*):([0-9]+):([0-9]+): (.*)/);\n        if (matchWebpackOrEsbuild) {\n            return {\n                fileName: matchWebpackOrEsbuild[1],\n                lineNumber: Number(matchWebpackOrEsbuild[2]),\n                columnNumber: Number(matchWebpackOrEsbuild[3]),\n                message: matchWebpackOrEsbuild[4],\n            };\n        }\n        const matchMissingModule = s.match(/\\s+at(.*)\\s\\((.*)\\)/);\n        if (!matchMissingModule) {\n            return null;\n        }\n        if (s.includes('webpackMissingModule')) {\n            return null;\n        }\n        const [, filename] = matchMissingModule;\n        return {\n            columnNumber: 0,\n            lineNumber: 1,\n            message: split[0],\n            fileName: filename.trim(),\n        };\n    })\n        .filter(no_react_1.NoReactInternals.truthy)[0]) !== null && _a !== void 0 ? _a : null);\n};\nexports.getLocationFromBuildError = getLocationFromBuildError;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getProjectName = void 0;\nconst getProjectName = ({ gitSource, resolvedRemotionRoot, basename, }) => {\n    // Directory name\n    if (!gitSource) {\n        return basename(resolvedRemotionRoot);\n    }\n    // Subfolder name of a Git repo, e.g `example`\n    if (gitSource.relativeFromGitRoot.trim()) {\n        return basename(gitSource.relativeFromGitRoot.trim());\n    }\n    // Name of the repo\n    return gitSource.name;\n};\nexports.getProjectName = getProjectName;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.hotMiddlewareOptions = void 0;\nexports.hotMiddlewareOptions = {\n    path: '/__webpack_hmr',\n    timeout: 20 * 1000,\n    reload: true,\n    warn: true,\n    heartbeat: 10 * 1000,\n};\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.stringifyDefaultProps = exports.SOURCE_MAP_ENDPOINT = exports.packages = exports.installableMap = exports.descriptions = exports.apiDocs = exports.DEFAULT_TIMELINE_TRACKS = exports.hotMiddlewareOptions = exports.getProjectName = exports.getLocationFromBuildError = exports.getDefaultOutLocation = exports.formatBytes = exports.DEFAULT_BUFFER_STATE_DELAY_IN_MILLISECONDS = exports.stripAnsi = exports.splitAnsi = void 0;\nvar ansi_1 = require(\"./ansi\");\nObject.defineProperty(exports, \"splitAnsi\", { enumerable: true, get: function () { return ansi_1.splitAnsi; } });\nObject.defineProperty(exports, \"stripAnsi\", { enumerable: true, get: function () { return ansi_1.stripAnsi; } });\nvar default_buffer_state_delay_in_milliseconds_1 = require(\"./default-buffer-state-delay-in-milliseconds\");\nObject.defineProperty(exports, \"DEFAULT_BUFFER_STATE_DELAY_IN_MILLISECONDS\", { enumerable: true, get: function () { return default_buffer_state_delay_in_milliseconds_1.DEFAULT_BUFFER_STATE_DELAY_IN_MILLISECONDS; } });\nvar format_bytes_1 = require(\"./format-bytes\");\nObject.defineProperty(exports, \"formatBytes\", { enumerable: true, get: function () { return format_bytes_1.formatBytes; } });\nvar get_default_out_name_1 = require(\"./get-default-out-name\");\nObject.defineProperty(exports, \"getDefaultOutLocation\", { enumerable: true, get: function () { return get_default_out_name_1.getDefaultOutLocation; } });\nvar get_location_from_build_error_1 = require(\"./get-location-from-build-error\");\nObject.defineProperty(exports, \"getLocationFromBuildError\", { enumerable: true, get: function () { return get_location_from_build_error_1.getLocationFromBuildError; } });\nvar get_project_name_1 = require(\"./get-project-name\");\nObject.defineProperty(exports, \"getProjectName\", { enumerable: true, get: function () { return get_project_name_1.getProjectName; } });\nvar hot_middleware_1 = require(\"./hot-middleware\");\nObject.defineProperty(exports, \"hotMiddlewareOptions\", { enumerable: true, get: function () { return hot_middleware_1.hotMiddlewareOptions; } });\nvar max_timeline_tracks_1 = require(\"./max-timeline-tracks\");\nObject.defineProperty(exports, \"DEFAULT_TIMELINE_TRACKS\", { enumerable: true, get: function () { return max_timeline_tracks_1.DEFAULT_TIMELINE_TRACKS; } });\nvar package_info_1 = require(\"./package-info\");\nObject.defineProperty(exports, \"apiDocs\", { enumerable: true, get: function () { return package_info_1.apiDocs; } });\nObject.defineProperty(exports, \"descriptions\", { enumerable: true, get: function () { return package_info_1.descriptions; } });\nObject.defineProperty(exports, \"installableMap\", { enumerable: true, get: function () { return package_info_1.installableMap; } });\nObject.defineProperty(exports, \"packages\", { enumerable: true, get: function () { return package_info_1.packages; } });\nvar source_map_endpoint_1 = require(\"./source-map-endpoint\");\nObject.defineProperty(exports, \"SOURCE_MAP_ENDPOINT\", { enumerable: true, get: function () { return source_map_endpoint_1.SOURCE_MAP_ENDPOINT; } });\nvar stringify_default_props_1 = require(\"./stringify-default-props\");\nObject.defineProperty(exports, \"stringifyDefaultProps\", { enumerable: true, get: function () { return stringify_default_props_1.stringifyDefaultProps; } });\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.DEFAULT_TIMELINE_TRACKS = void 0;\nexports.DEFAULT_TIMELINE_TRACKS = 90;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.apiDocs = exports.installableMap = exports.descriptions = exports.packages = void 0;\nexports.packages = [\n    'svg-3d-engine',\n    'ai-improvements',\n    'animation-utils',\n    'animated-emoji',\n    'astro-example',\n    'babel-loader',\n    'bugs',\n    'bundler',\n    'cli',\n    'cloudrun',\n    'compositor-darwin-arm64',\n    'compositor-darwin-x64',\n    'compositor-linux-arm64-gnu',\n    'compositor-linux-arm64-musl',\n    'compositor-linux-x64-gnu',\n    'compositor-linux-x64-musl',\n    'compositor-win32-x64-msvc',\n    'core',\n    'create-video',\n    'discord-poster',\n    'docusaurus-plugin',\n    'docs',\n    'enable-scss',\n    'eslint-config',\n    'eslint-config-flat',\n    'eslint-config-internal',\n    'eslint-plugin',\n    'example-without-zod',\n    'example',\n    'fonts',\n    'gif',\n    'google-fonts',\n    'install-whisper-cpp',\n    'it-tests',\n    'react18-tests',\n    'lambda-go-example',\n    'lambda-go',\n    'lambda-php',\n    'lambda-ruby',\n    'lambda-python',\n    'lambda',\n    'lambda-client',\n    'layout-utils',\n    'rounded-text-box',\n    'licensing',\n    'lottie',\n    'mcp',\n    'media-utils',\n    'motion-blur',\n    'noise',\n    'paths',\n    'player-example',\n    'player',\n    'preload',\n    'renderer',\n    'rive',\n    'shapes',\n    'skia',\n    'promo-pages',\n    'streaming',\n    'serverless',\n    'serverless-client',\n    'skills',\n    'studio-server',\n    'studio-shared',\n    'studio',\n    'tailwind',\n    'tailwind-v4',\n    'test-utils',\n    'three',\n    'transitions',\n    'media-parser',\n    'zod-types',\n    'webcodecs',\n    'convert',\n    'captions',\n    'openai-whisper',\n    'compositor',\n    'example-videos',\n    'whisper-web',\n    'media',\n    'web-renderer',\n    'design',\n];\nexports.descriptions = {\n    compositor: 'Rust binary for Remotion',\n    player: 'React component for embedding a Remotion preview into your app',\n    cloudrun: 'Render Remotion videos on Google Cloud Run',\n    renderer: 'Render Remotion videos using Node.js or Bun',\n    cli: 'Control Remotion features using the `npx remotion` command',\n    core: 'Make videos programmatically',\n    lambda: 'Render Remotion videos on AWS Lambda',\n    bundler: 'Bundle Remotion compositions using Webpack',\n    'studio-server': 'Run a Remotion Studio with a server backend',\n    'install-whisper-cpp': 'Helpers for installing and using Whisper.cpp',\n    'whisper-web': 'Helpers for using Whisper.cpp in browser using WASM',\n    'google-fonts': 'Use Google Fonts in Remotion',\n    mcp: \"Remotion's Model Context Protocol\",\n    'media-utils': 'Utilities for working with media files',\n    lottie: 'Include Lottie animations in Remotion',\n    licensing: 'Manage your Remotion.pro license',\n    'layout-utils': 'Utilities for working with layouts',\n    'rounded-text-box': 'Create a TikTok-like multiline text box SVG path with rounded corners',\n    noise: 'Noise generation functions',\n    'motion-blur': 'Motion blur effect for Remotion',\n    preload: 'Preloads assets for use in Remotion',\n    shapes: 'Generate SVG shapes',\n    'zod-types': 'Zod types for Remotion',\n    gif: 'Embed GIFs in a Remotion video',\n    'eslint-plugin': 'Rules for writing Remotion code',\n    'eslint-config': 'Default configuration for Remotion templates (ESLint <= 8)',\n    'eslint-config-flat': 'Default configuration for Remotion templates (ESLint >= 9)',\n    'compositor-linux-x64-gnu': 'Linux x64 binary for the Remotion Rust code',\n    'compositor-linux-x64-musl': 'Linux x64 binary for the Remotion Rust code',\n    'compositor-darwin-x64': 'MacOS x64 binary for the Remotion Rust code',\n    'compositor-darwin-arm64': 'MacOS Apple Silicon binary for the Remotion Rust code',\n    'compositor-linux-arm64-gnu': 'Linux ARM64 binary for the Remotion Rust code',\n    'compositor-linux-arm64-musl': 'Linux ARM64 binary for the Remotion Rust code',\n    'babel-loader': 'Babel loader for Remotion',\n    fonts: 'Helpers for loading local fonts into Remotion',\n    transitions: 'Library for creating transitions in Remotion',\n    'enable-scss': 'Enable SCSS support in Remotion',\n    'create-video': 'Create a new Remotion project',\n    'studio-shared': 'Internal package for shared objects between the Studio backend and frontend',\n    tailwind: 'Enable TailwindCSS support in Remotion (TailwindCSS v3)',\n    'tailwind-v4': 'Enable TailwindCSS support in Remotion (TailwindCSS v4)',\n    streaming: 'Utilities for streaming data between programs',\n    'media-parser': 'A pure JavaScript library for parsing video files',\n    rive: 'Embed Rive animations in a Remotion video',\n    paths: 'Utilities for working with SVG paths',\n    studio: 'APIs for interacting with the Remotion Studio',\n    skia: 'Include React Native Skia components in a Remotion video',\n    three: 'Include React Three Fiber components in a Remotion video',\n    'astro-example': null,\n    'lambda-go-example': null,\n    'compositor-win32-x64-msvc': null,\n    'animation-utils': 'Helpers for animating CSS properties',\n    'test-utils': null,\n    'example-without-zod': null,\n    'lambda-go': null,\n    example: null,\n    'lambda-php': null,\n    'lambda-client': null,\n    bugs: null,\n    docs: null,\n    'it-tests': null,\n    'react18-tests': null,\n    'lambda-python': null,\n    'lambda-ruby': null,\n    'player-example': null,\n    'ai-improvements': null,\n    skills: null,\n    'discord-poster': null,\n    'docusaurus-plugin': null,\n    'animated-emoji': 'Google Fonts Animated Emojis as Remotion components',\n    serverless: 'A runtime for distributed rendering',\n    webcodecs: 'Media conversion in the browser',\n    convert: 'Video conversion tool - convert.remotion.dev',\n    captions: 'Primitives for dealing with captions',\n    'openai-whisper': 'Work with the output of the OpenAI Whisper API',\n    'eslint-config-internal': \"ESLint condig for Remotion's internal packages\",\n    'example-videos': null,\n    'promo-pages': null,\n    'svg-3d-engine': '3D SVG extrusion effects',\n    'serverless-client': null,\n    media: 'Experimental WebCodecs-based media tags',\n    'web-renderer': 'Render videos in the browser (not yet released)',\n    design: 'Design system',\n};\nexports.installableMap = {\n    'svg-3d-engine': false,\n    'ai-improvements': false,\n    'animation-utils': true,\n    'animated-emoji': true,\n    'astro-example': false,\n    'babel-loader': false,\n    bugs: false,\n    bundler: false,\n    cli: false,\n    cloudrun: true,\n    'lambda-client': false,\n    'serverless-client': false,\n    'compositor-darwin-arm64': false,\n    'compositor-darwin-x64': false,\n    'compositor-linux-arm64-gnu': false,\n    'compositor-linux-arm64-musl': false,\n    'compositor-linux-x64-gnu': false,\n    'compositor-linux-x64-musl': false,\n    'compositor-win32-x64-msvc': false,\n    core: false,\n    'create-video': false,\n    'discord-poster': false,\n    'docusaurus-plugin': false,\n    docs: false,\n    'enable-scss': true,\n    'eslint-config': false,\n    'eslint-config-flat': false,\n    'eslint-config-internal': false,\n    'eslint-plugin': false,\n    'example-without-zod': false,\n    example: false,\n    fonts: true,\n    gif: true,\n    'google-fonts': true,\n    'install-whisper-cpp': true,\n    'whisper-web': true,\n    'it-tests': false,\n    'react18-tests': false,\n    'lambda-go-example': false,\n    'lambda-go': false,\n    'lambda-php': false,\n    'lambda-ruby': false,\n    'lambda-python': false,\n    lambda: true,\n    mcp: true,\n    'layout-utils': true,\n    'rounded-text-box': true,\n    licensing: true,\n    lottie: true,\n    'media-utils': true,\n    'motion-blur': true,\n    noise: true,\n    paths: true,\n    'player-example': false,\n    player: true,\n    preload: true,\n    renderer: true,\n    rive: true,\n    shapes: true,\n    skia: true,\n    skills: false,\n    'promo-pages': false,\n    streaming: false,\n    serverless: false,\n    'studio-server': false,\n    'studio-shared': false,\n    studio: true,\n    tailwind: true,\n    'tailwind-v4': true,\n    'test-utils': false,\n    three: true,\n    transitions: true,\n    'media-parser': true,\n    'zod-types': true,\n    webcodecs: true,\n    convert: false,\n    captions: true,\n    'openai-whisper': true,\n    compositor: false,\n    'example-videos': false,\n    media: true,\n    'web-renderer': false,\n    design: false,\n};\nexports.apiDocs = {\n    player: 'https://www.remotion.dev/docs/player',\n    cloudrun: 'https://www.remotion.dev/docs/cloudrun',\n    renderer: 'https://www.remotion.dev/docs/renderer',\n    cli: 'https://www.remotion.dev/docs/cli',\n    core: 'https://www.remotion.dev/docs/remotion',\n    lambda: 'https://www.remotion.dev/docs/lambda',\n    bundler: 'https://www.remotion.dev/docs/bundler',\n    'lambda-client': null,\n    'serverless-client': null,\n    'studio-server': null,\n    'install-whisper-cpp': 'https://www.remotion.dev/docs/install-whisper-cpp',\n    'whisper-web': 'https://www.remotion.dev/docs/whisper-web',\n    'google-fonts': 'https://www.remotion.dev/docs/google-fonts',\n    'media-utils': 'https://www.remotion.dev/docs/media-utils',\n    lottie: 'https://www.remotion.dev/docs/lottie',\n    licensing: 'https://www.remotion.dev/docs/licensing',\n    'layout-utils': 'https://www.remotion.dev/docs/layout-utils',\n    'rounded-text-box': 'https://www.remotion.dev/docs/rounded-text-box',\n    noise: 'https://www.remotion.dev/docs/noise',\n    mcp: 'https://www.remotion.dev/docs/ai/mcp',\n    'motion-blur': 'https://www.remotion.dev/docs/motion-blur',\n    preload: 'https://www.remotion.dev/docs/preload',\n    shapes: 'https://www.remotion.dev/docs/shapes',\n    'zod-types': 'https://www.remotion.dev/docs/zod-types',\n    gif: 'https://www.remotion.dev/docs/gif',\n    'eslint-plugin': 'https://www.remotion.dev/docs/brownfield#install-the-eslint-plugin',\n    'eslint-config': 'https://www.remotion.dev/docs/brownfield#install-the-eslint-plugin',\n    'eslint-config-flat': 'https://www.remotion.dev/docs/brownfield#install-the-eslint-plugin',\n    'compositor-linux-x64-gnu': null,\n    'compositor-linux-x64-musl': null,\n    'compositor-darwin-x64': null,\n    'ai-improvements': null,\n    'discord-poster': null,\n    'docusaurus-plugin': null,\n    'animation-utils': 'https://www.remotion.dev/docs/animation-utils/',\n    'example-without-zod': null,\n    'lambda-go': null,\n    example: null,\n    'lambda-php': null,\n    bugs: null,\n    docs: null,\n    'it-tests': null,\n    'react18-tests': null,\n    'lambda-python': null,\n    'lambda-ruby': 'https://www.remotion.dev/docs/lambda/ruby',\n    'player-example': null,\n    'astro-example': null,\n    'lambda-go-example': null,\n    'test-utils': null,\n    'babel-loader': 'https://www.remotion.dev/docs/legacy-babel',\n    'compositor-darwin-arm64': null,\n    'compositor-linux-arm64-gnu': null,\n    'compositor-linux-arm64-musl': null,\n    'compositor-win32-x64-msvc': null,\n    'enable-scss': 'https://www.remotion.dev/docs/enable-scss/overview',\n    'create-video': 'https://remotion.dev/templates',\n    'studio-shared': null,\n    'media-parser': 'https://www.remotion.dev/docs/media-parser',\n    fonts: 'https://www.remotion.dev/docs/fonts-api',\n    paths: 'https://www.remotion.dev/paths',\n    rive: 'https://www.remotion.dev/docs/rive',\n    tailwind: 'https://www.remotion.dev/docs/tailwind/tailwind',\n    'tailwind-v4': 'https://www.remotion.dev/docs/tailwind/tailwind',\n    skia: 'https://www.remotion.dev/docs/skia',\n    three: 'https://www.remotion.dev/docs/three',\n    streaming: null,\n    serverless: null,\n    skills: null,\n    studio: 'https://www.remotion.dev/docs/studio/api',\n    transitions: 'https://www.remotion.dev/transitions',\n    'animated-emoji': 'https://www.remotion.dev/docs/animated-emoji',\n    webcodecs: 'https://remotion.dev/webcodecs',\n    convert: 'https://convert.remotion.dev',\n    captions: 'https://remotion.dev/docs/captions/api',\n    'openai-whisper': 'https://www.remotion.dev/docs/openai-whisper',\n    'eslint-config-internal': null,\n    compositor: null,\n    'example-videos': null,\n    'promo-pages': null,\n    'svg-3d-engine': null,\n    media: 'https://remotion.dev/docs/media',\n    'web-renderer': 'https://www.remotion.dev/docs/web-renderer/',\n    design: 'https://www.remotion.dev/design',\n};\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.SOURCE_MAP_ENDPOINT = void 0;\nexports.SOURCE_MAP_ENDPOINT = '/source-map-helper.wasm';\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.stringifyDefaultProps = void 0;\nconst no_react_1 = require(\"remotion/no-react\");\nfunction replacerWithPath(replacer) {\n    const m = new Map();\n    return function (field, value) {\n        const path = [m.get(this), field].flat(1);\n        if (value === Object(value)) {\n            m.set(value, path);\n        }\n        return replacer.call(this, field, value, path.filter((item) => typeof item !== 'undefined' && item !== ''));\n    };\n}\nconst doesMatchPath = (path1, enumPaths) => {\n    return enumPaths.some((p) => \n    // especially 0 for root!\n    path1.length === p.length &&\n        path1.every((item, index) => {\n            if (p[index] === '[]' && !Number.isNaN(Number(item))) {\n                return true;\n            }\n            if (p[index] === '{}' && typeof item === 'string') {\n                return true;\n            }\n            return item === p[index];\n        }));\n};\nconst stringifyDefaultProps = ({ props, enumPaths, }) => {\n    return JSON.stringify(props, replacerWithPath(function (key, value, path) {\n        /* Don't replace with arrow function! This function uses `this` */\n        const item = this[key];\n        if (typeof item === 'string' && doesMatchPath(path, enumPaths)) {\n            return `${item}__ADD_AS_CONST__`;\n        }\n        // For zMatrix()\n        if (doesMatchPath(path, enumPaths)) {\n            return `__REMOVEQUOTE__${JSON.stringify(item)}__ADD_AS_LITERAL_CONST__`;\n        }\n        if (typeof item === 'string' &&\n            item.startsWith(no_react_1.NoReactInternals.FILE_TOKEN)) {\n            return `__REMOVEQUOTE____WRAP_IN_STATIC_FILE_START__${decodeURIComponent(item.replace(no_react_1.NoReactInternals.FILE_TOKEN, ''))}__WRAP_IN_STATIC_FILE_END____REMOVEQUOTE__`;\n        }\n        if (typeof item === 'string' &&\n            item.startsWith(no_react_1.NoReactInternals.DATE_TOKEN)) {\n            return `__REMOVEQUOTE____WRAP_IN_DATE_START__${decodeURIComponent(item.replace(no_react_1.NoReactInternals.DATE_TOKEN, ''))}__WRAP_IN_DATE_END____REMOVEQUOTE__`;\n        }\n        return value;\n    }))\n        .replace(/\"__REMOVEQUOTE__/g, '')\n        .replace(/__REMOVEQUOTE__\"/g, '')\n        .replace(/__ADD_AS_CONST__\"/g, '\" as const')\n        .replace(/__ADD_AS_LITERAL_CONST__\"/g, ' as const')\n        .replace(/__WRAP_IN_STATIC_FILE_START__/g, 'staticFile(\"')\n        .replace(/__WRAP_IN_STATIC_FILE_END__/g, '\")')\n        .replace(/__WRAP_IN_DATE_START__/g, 'new Date(\"')\n        .replace(/__WRAP_IN_DATE_END__/g, '\")');\n};\nexports.stringifyDefaultProps = stringifyDefaultProps;\n","\"use client\";\n// src/icons.tsx\nimport { jsx, jsxs } from \"react/jsx-runtime\";\nvar ICON_SIZE = 25;\nvar fullscreenIconSize = 16;\nvar PlayIcon = () => {\n  return /* @__PURE__ */ jsx(\"svg\", {\n    width: ICON_SIZE,\n    height: ICON_SIZE,\n    viewBox: \"0 0 25 25\",\n    fill: \"none\",\n    children: /* @__PURE__ */ jsx(\"path\", {\n      d: \"M8 6.375C7.40904 8.17576 7.06921 10.2486 7.01438 12.3871C6.95955 14.5255 7.19163 16.6547 7.6875 18.5625C9.95364 18.2995 12.116 17.6164 14.009 16.5655C15.902 15.5147 17.4755 14.124 18.6088 12.5C17.5158 10.8949 15.9949 9.51103 14.1585 8.45082C12.3222 7.3906 10.2174 6.68116 8 6.375Z\",\n      fill: \"white\",\n      stroke: \"white\",\n      strokeWidth: \"6.25\",\n      strokeLinejoin: \"round\"\n    })\n  });\n};\nvar PauseIcon = () => {\n  return /* @__PURE__ */ jsxs(\"svg\", {\n    viewBox: \"0 0 100 100\",\n    width: ICON_SIZE,\n    height: ICON_SIZE,\n    children: [\n      /* @__PURE__ */ jsx(\"rect\", {\n        x: \"25\",\n        y: \"20\",\n        width: \"20\",\n        height: \"60\",\n        fill: \"#fff\",\n        ry: \"5\",\n        rx: \"5\"\n      }),\n      /* @__PURE__ */ jsx(\"rect\", {\n        x: \"55\",\n        y: \"20\",\n        width: \"20\",\n        height: \"60\",\n        fill: \"#fff\",\n        ry: \"5\",\n        rx: \"5\"\n      })\n    ]\n  });\n};\nvar FullscreenIcon = ({\n  isFullscreen\n}) => {\n  const strokeWidth = 6;\n  const viewSize = 32;\n  const out = isFullscreen ? 0 : strokeWidth / 2;\n  const middleInset = isFullscreen ? strokeWidth * 1.6 : strokeWidth / 2;\n  const inset = isFullscreen ? strokeWidth * 1.6 : strokeWidth * 2;\n  return /* @__PURE__ */ jsxs(\"svg\", {\n    viewBox: `0 0 ${viewSize} ${viewSize}`,\n    height: fullscreenIconSize,\n    width: fullscreenIconSize,\n    children: [\n      /* @__PURE__ */ jsx(\"path\", {\n        d: `\n\t\t\t\tM ${out} ${inset}\n\t\t\t\tL ${middleInset} ${middleInset}\n\t\t\t\tL ${inset} ${out}\n\t\t\t\t`,\n        stroke: \"#fff\",\n        strokeWidth,\n        fill: \"none\"\n      }),\n      /* @__PURE__ */ jsx(\"path\", {\n        d: `\n\t\t\t\tM ${viewSize - out} ${inset}\n\t\t\t\tL ${viewSize - middleInset} ${middleInset}\n\t\t\t\tL ${viewSize - inset} ${out}\n\t\t\t\t`,\n        stroke: \"#fff\",\n        strokeWidth,\n        fill: \"none\"\n      }),\n      /* @__PURE__ */ jsx(\"path\", {\n        d: `\n\t\t\t\tM ${out} ${viewSize - inset}\n\t\t\t\tL ${middleInset} ${viewSize - middleInset}\n\t\t\t\tL ${inset} ${viewSize - out}\n\t\t\t\t`,\n        stroke: \"#fff\",\n        strokeWidth,\n        fill: \"none\"\n      }),\n      /* @__PURE__ */ jsx(\"path\", {\n        d: `\n\t\t\t\tM ${viewSize - out} ${viewSize - inset}\n\t\t\t\tL ${viewSize - middleInset} ${viewSize - middleInset}\n\t\t\t\tL ${viewSize - inset} ${viewSize - out}\n\t\t\t\t`,\n        stroke: \"#fff\",\n        strokeWidth,\n        fill: \"none\"\n      })\n    ]\n  });\n};\nvar VolumeOffIcon = () => {\n  return /* @__PURE__ */ jsx(\"svg\", {\n    width: ICON_SIZE,\n    height: ICON_SIZE,\n    viewBox: \"0 0 24 24\",\n    children: /* @__PURE__ */ jsx(\"path\", {\n      d: \"M3.63 3.63a.996.996 0 000 1.41L7.29 8.7 7 9H4c-.55 0-1 .45-1 1v4c0 .55.45 1 1 1h3l3.29 3.29c.63.63 1.71.18 1.71-.71v-4.17l4.18 4.18c-.49.37-1.02.68-1.6.91-.36.15-.58.53-.58.92 0 .72.73 1.18 1.39.91.8-.33 1.55-.77 2.22-1.31l1.34 1.34a.996.996 0 101.41-1.41L5.05 3.63c-.39-.39-1.02-.39-1.42 0zM19 12c0 .82-.15 1.61-.41 2.34l1.53 1.53c.56-1.17.88-2.48.88-3.87 0-3.83-2.4-7.11-5.78-8.4-.59-.23-1.22.23-1.22.86v.19c0 .38.25.71.61.85C17.18 6.54 19 9.06 19 12zm-8.71-6.29l-.17.17L12 7.76V6.41c0-.89-1.08-1.33-1.71-.7zM16.5 12A4.5 4.5 0 0014 7.97v1.79l2.48 2.48c.01-.08.02-.16.02-.24z\",\n      fill: \"#fff\"\n    })\n  });\n};\nvar VolumeOnIcon = () => {\n  return /* @__PURE__ */ jsx(\"svg\", {\n    width: ICON_SIZE,\n    height: ICON_SIZE,\n    viewBox: \"0 0 24 24\",\n    children: /* @__PURE__ */ jsx(\"path\", {\n      d: \"M3 10v4c0 .55.45 1 1 1h3l3.29 3.29c.63.63 1.71.18 1.71-.71V6.41c0-.89-1.08-1.34-1.71-.71L7 9H4c-.55 0-1 .45-1 1zm13.5 2A4.5 4.5 0 0014 7.97v8.05c1.48-.73 2.5-2.25 2.5-4.02zM14 4.45v.2c0 .38.25.71.6.85C17.18 6.53 19 9.06 19 12s-1.82 5.47-4.4 6.5c-.36.14-.6.47-.6.85v.2c0 .63.63 1.07 1.21.85C18.6 19.11 21 15.84 21 12s-2.4-7.11-5.79-8.4c-.58-.23-1.21.22-1.21.85z\",\n      fill: \"#fff\"\n    })\n  });\n};\n\n// src/BufferingIndicator.tsx\nimport { jsx as jsx2, jsxs as jsxs2, Fragment } from \"react/jsx-runtime\";\nvar className = \"__remotion_buffering_indicator\";\nvar remotionBufferingAnimation = \"__remotion_buffering_animation\";\nvar playerStyle = {\n  width: ICON_SIZE,\n  height: ICON_SIZE,\n  overflow: \"hidden\",\n  lineHeight: \"normal\",\n  fontSize: \"inherit\"\n};\nvar studioStyle = {\n  width: 14,\n  height: 14,\n  overflow: \"hidden\",\n  lineHeight: \"normal\",\n  fontSize: \"inherit\"\n};\nvar BufferingIndicator = ({ type }) => {\n  const style = type === \"player\" ? playerStyle : studioStyle;\n  return /* @__PURE__ */ jsxs2(Fragment, {\n    children: [\n      /* @__PURE__ */ jsx2(\"style\", {\n        type: \"text/css\",\n        children: `\n\t\t\t\t@keyframes ${remotionBufferingAnimation} {\n          0% {\n            rotate: 0deg;\n          }\n          100% {\n            rotate: 360deg;\n          }\n        }\n        \n        .${className} {\n            animation: ${remotionBufferingAnimation} 1s linear infinite;\n        }        \n\t\t\t`\n      }),\n      /* @__PURE__ */ jsx2(\"div\", {\n        style,\n        children: /* @__PURE__ */ jsx2(\"svg\", {\n          viewBox: type === \"player\" ? \"0 0 22 22\" : \"0 0 18 18\",\n          style,\n          className,\n          children: /* @__PURE__ */ jsx2(\"path\", {\n            d: type === \"player\" ? \"M 11 4 A 7 7 0 0 1 15.1145 16.66312\" : \"M 9 2 A 7 7 0 0 1 13.1145 14.66312\",\n            stroke: \"white\",\n            strokeLinecap: \"round\",\n            fill: \"none\",\n            strokeWidth: 3\n          })\n        })\n      })\n    ]\n  });\n};\n\n// src/calculate-scale.ts\nimport { Internals } from \"remotion\";\n\n// src/utils/calculate-player-size.ts\nvar calculatePlayerSize = ({\n  currentSize,\n  width,\n  height,\n  compositionWidth,\n  compositionHeight\n}) => {\n  if (width !== undefined && height === undefined) {\n    return {\n      aspectRatio: [compositionWidth, compositionHeight].join(\"/\")\n    };\n  }\n  if (height !== undefined && width === undefined) {\n    return {\n      aspectRatio: [compositionWidth, compositionHeight].join(\"/\")\n    };\n  }\n  if (!currentSize) {\n    return {\n      width: compositionWidth,\n      height: compositionHeight\n    };\n  }\n  return {\n    width: compositionWidth,\n    height: compositionHeight\n  };\n};\n\n// src/calculate-scale.ts\nvar calculateCanvasTransformation = ({\n  previewSize,\n  compositionWidth,\n  compositionHeight,\n  canvasSize\n}) => {\n  const scale = Internals.calculateScale({\n    canvasSize,\n    compositionHeight,\n    compositionWidth,\n    previewSize\n  });\n  const correction = 0 - (1 - scale) / 2;\n  const xCorrection = correction * compositionWidth;\n  const yCorrection = correction * compositionHeight;\n  const width = compositionWidth * scale;\n  const height = compositionHeight * scale;\n  const centerX = canvasSize.width / 2 - width / 2;\n  const centerY = canvasSize.height / 2 - height / 2;\n  return {\n    centerX,\n    centerY,\n    xCorrection,\n    yCorrection,\n    scale\n  };\n};\nvar calculateOuterStyle = ({\n  config,\n  style,\n  canvasSize,\n  overflowVisible,\n  layout\n}) => {\n  if (!config) {\n    return {};\n  }\n  return {\n    position: \"relative\",\n    overflow: overflowVisible ? \"visible\" : \"hidden\",\n    ...calculatePlayerSize({\n      compositionHeight: config.height,\n      compositionWidth: config.width,\n      currentSize: canvasSize,\n      height: style?.height,\n      width: style?.width\n    }),\n    opacity: layout ? 1 : 0,\n    ...style\n  };\n};\nvar calculateContainerStyle = ({\n  config,\n  layout,\n  scale,\n  overflowVisible\n}) => {\n  if (!config) {\n    return {};\n  }\n  if (!layout) {\n    return {\n      position: \"absolute\",\n      width: config.width,\n      height: config.height,\n      display: \"flex\",\n      transform: `scale(${scale})`,\n      overflow: overflowVisible ? \"visible\" : \"hidden\"\n    };\n  }\n  return {\n    position: \"absolute\",\n    width: config.width,\n    height: config.height,\n    display: \"flex\",\n    transform: `scale(${scale})`,\n    marginLeft: layout.xCorrection,\n    marginTop: layout.yCorrection,\n    overflow: overflowVisible ? \"visible\" : \"hidden\"\n  };\n};\nvar calculateOuter = ({\n  layout,\n  scale,\n  config,\n  overflowVisible\n}) => {\n  if (!config) {\n    return {};\n  }\n  if (!layout) {\n    return {\n      width: config.width * scale,\n      height: config.height * scale,\n      display: \"flex\",\n      flexDirection: \"column\",\n      position: \"absolute\",\n      overflow: overflowVisible ? \"visible\" : \"hidden\"\n    };\n  }\n  const { centerX, centerY } = layout;\n  return {\n    width: config.width * scale,\n    height: config.height * scale,\n    display: \"flex\",\n    flexDirection: \"column\",\n    position: \"absolute\",\n    left: centerX,\n    top: centerY,\n    overflow: overflowVisible ? \"visible\" : \"hidden\"\n  };\n};\n\n// src/emitter-context.ts\nimport React from \"react\";\nvar PlayerEventEmitterContext = React.createContext(undefined);\nvar ThumbnailEmitterContext = React.createContext(undefined);\n\n// src/EmitterProvider.tsx\nimport { useContext as useContext2, useEffect, useState } from \"react\";\nimport { Internals as Internals3 } from \"remotion\";\n\n// src/event-emitter.ts\nclass PlayerEmitter {\n  listeners = {\n    ended: [],\n    error: [],\n    pause: [],\n    play: [],\n    ratechange: [],\n    scalechange: [],\n    seeked: [],\n    timeupdate: [],\n    frameupdate: [],\n    fullscreenchange: [],\n    volumechange: [],\n    mutechange: [],\n    waiting: [],\n    resume: []\n  };\n  addEventListener(name, callback) {\n    this.listeners[name].push(callback);\n  }\n  removeEventListener(name, callback) {\n    this.listeners[name] = this.listeners[name].filter((l) => l !== callback);\n  }\n  dispatchEvent(dispatchName, context) {\n    this.listeners[dispatchName].forEach((callback) => {\n      callback({ detail: context });\n    });\n  }\n  dispatchSeek = (frame) => {\n    this.dispatchEvent(\"seeked\", {\n      frame\n    });\n  };\n  dispatchVolumeChange = (volume) => {\n    this.dispatchEvent(\"volumechange\", {\n      volume\n    });\n  };\n  dispatchPause = () => {\n    this.dispatchEvent(\"pause\", undefined);\n  };\n  dispatchPlay = () => {\n    this.dispatchEvent(\"play\", undefined);\n  };\n  dispatchEnded = () => {\n    this.dispatchEvent(\"ended\", undefined);\n  };\n  dispatchRateChange = (playbackRate) => {\n    this.dispatchEvent(\"ratechange\", {\n      playbackRate\n    });\n  };\n  dispatchScaleChange = (scale) => {\n    this.dispatchEvent(\"scalechange\", {\n      scale\n    });\n  };\n  dispatchError = (error) => {\n    this.dispatchEvent(\"error\", {\n      error\n    });\n  };\n  dispatchTimeUpdate = (event) => {\n    this.dispatchEvent(\"timeupdate\", event);\n  };\n  dispatchFrameUpdate = (event) => {\n    this.dispatchEvent(\"frameupdate\", event);\n  };\n  dispatchFullscreenChange = (event) => {\n    this.dispatchEvent(\"fullscreenchange\", event);\n  };\n  dispatchMuteChange = (event) => {\n    this.dispatchEvent(\"mutechange\", event);\n  };\n  dispatchWaiting = (event) => {\n    this.dispatchEvent(\"waiting\", event);\n  };\n  dispatchResume = (event) => {\n    this.dispatchEvent(\"resume\", event);\n  };\n}\n\nclass ThumbnailEmitter {\n  listeners = {\n    error: [],\n    waiting: [],\n    resume: []\n  };\n  addEventListener(name, callback) {\n    this.listeners[name].push(callback);\n  }\n  removeEventListener(name, callback) {\n    this.listeners[name] = this.listeners[name].filter((l) => l !== callback);\n  }\n  dispatchEvent(dispatchName, context) {\n    this.listeners[dispatchName].forEach((callback) => {\n      callback({ detail: context });\n    });\n  }\n  dispatchError = (error) => {\n    this.dispatchEvent(\"error\", {\n      error\n    });\n  };\n  dispatchWaiting = (event) => {\n    this.dispatchEvent(\"waiting\", event);\n  };\n  dispatchResume = (event) => {\n    this.dispatchEvent(\"resume\", event);\n  };\n}\n\n// src/use-buffer-state-emitter.ts\nimport { useContext, useLayoutEffect } from \"react\";\nimport { Internals as Internals2 } from \"remotion\";\nvar useBufferStateEmitter = (emitter) => {\n  const bufferManager = useContext(Internals2.BufferingContextReact);\n  if (!bufferManager) {\n    throw new Error(\"BufferingContextReact not found\");\n  }\n  useLayoutEffect(() => {\n    const clear1 = bufferManager.listenForBuffering(() => {\n      bufferManager.buffering.current = true;\n      emitter.dispatchWaiting({});\n    });\n    const clear2 = bufferManager.listenForResume(() => {\n      bufferManager.buffering.current = false;\n      emitter.dispatchResume({});\n    });\n    return () => {\n      clear1.remove();\n      clear2.remove();\n    };\n  }, [bufferManager, emitter]);\n};\n\n// src/EmitterProvider.tsx\nimport { jsx as jsx3 } from \"react/jsx-runtime\";\nvar PlayerEmitterProvider = ({ children, currentPlaybackRate }) => {\n  const [emitter] = useState(() => new PlayerEmitter);\n  const bufferManager = useContext2(Internals3.BufferingContextReact);\n  if (!bufferManager) {\n    throw new Error(\"BufferingContextReact not found\");\n  }\n  useEffect(() => {\n    if (currentPlaybackRate) {\n      emitter.dispatchRateChange(currentPlaybackRate);\n    }\n  }, [emitter, currentPlaybackRate]);\n  useBufferStateEmitter(emitter);\n  return /* @__PURE__ */ jsx3(PlayerEventEmitterContext.Provider, {\n    value: emitter,\n    children\n  });\n};\n\n// src/use-frame-imperative.ts\nimport { useCallback, useRef } from \"react\";\nimport { Internals as Internals4 } from \"remotion\";\nvar useFrameImperative = () => {\n  const frame = Internals4.Timeline.useTimelinePosition();\n  const frameRef = useRef(frame);\n  frameRef.current = frame;\n  const getCurrentFrame = useCallback(() => {\n    return frameRef.current;\n  }, []);\n  return getCurrentFrame;\n};\n\n// src/use-hover-state.ts\nimport { useEffect as useEffect2, useState as useState2 } from \"react\";\nvar useHoverState = (ref, hideControlsWhenPointerDoesntMove) => {\n  const [hovered, setHovered] = useState2(false);\n  useEffect2(() => {\n    const { current } = ref;\n    if (!current) {\n      return;\n    }\n    let hoverTimeout;\n    const addHoverTimeout = () => {\n      if (hideControlsWhenPointerDoesntMove) {\n        clearTimeout(hoverTimeout);\n        hoverTimeout = setTimeout(() => {\n          setHovered(false);\n        }, hideControlsWhenPointerDoesntMove === true ? 3000 : hideControlsWhenPointerDoesntMove);\n      }\n    };\n    const onHover = () => {\n      setHovered(true);\n      addHoverTimeout();\n    };\n    const onLeave = () => {\n      setHovered(false);\n      clearTimeout(hoverTimeout);\n    };\n    const onMove = () => {\n      setHovered(true);\n      addHoverTimeout();\n    };\n    current.addEventListener(\"mouseenter\", onHover);\n    current.addEventListener(\"mouseleave\", onLeave);\n    current.addEventListener(\"mousemove\", onMove);\n    return () => {\n      current.removeEventListener(\"mouseenter\", onHover);\n      current.removeEventListener(\"mouseleave\", onLeave);\n      current.removeEventListener(\"mousemove\", onMove);\n      clearTimeout(hoverTimeout);\n    };\n  }, [hideControlsWhenPointerDoesntMove, ref]);\n  return hovered;\n};\n\n// src/use-playback.ts\nimport { useContext as useContext4, useEffect as useEffect5, useRef as useRef4 } from \"react\";\nimport { Internals as Internals6 } from \"remotion\";\n\n// src/browser-mediasession.ts\nimport { useEffect as useEffect3 } from \"react\";\n\n// src/use-player.ts\nimport { useCallback as useCallback2, useContext as useContext3, useMemo, useRef as useRef2, useState as useState3 } from \"react\";\nimport { Internals as Internals5 } from \"remotion\";\nvar usePlayer = () => {\n  const [playing, setPlaying, imperativePlaying] = Internals5.Timeline.usePlayingState();\n  const [hasPlayed, setHasPlayed] = useState3(false);\n  const frame = Internals5.Timeline.useTimelinePosition();\n  const playStart = useRef2(frame);\n  const setFrame = Internals5.Timeline.useTimelineSetFrame();\n  const setTimelinePosition = Internals5.Timeline.useTimelineSetFrame();\n  const audioContext = useContext3(Internals5.SharedAudioContext);\n  const { audioAndVideoTags } = useContext3(Internals5.TimelineContext);\n  const frameRef = useRef2(frame);\n  frameRef.current = frame;\n  const video = Internals5.useVideo();\n  const config = Internals5.useUnsafeVideoConfig();\n  const emitter = useContext3(PlayerEventEmitterContext);\n  const lastFrame = (config?.durationInFrames ?? 1) - 1;\n  const isLastFrame = frame === lastFrame;\n  const isFirstFrame = frame === 0;\n  if (!emitter) {\n    throw new TypeError(\"Expected Player event emitter context\");\n  }\n  const bufferingContext = useContext3(Internals5.BufferingContextReact);\n  if (!bufferingContext) {\n    throw new Error(\"Missing the buffering context. Most likely you have a Remotion version mismatch.\");\n  }\n  const { buffering } = bufferingContext;\n  const seek = useCallback2((newFrame) => {\n    if (video?.id) {\n      setTimelinePosition((c) => ({ ...c, [video.id]: newFrame }));\n    }\n    frameRef.current = newFrame;\n    emitter.dispatchSeek(newFrame);\n  }, [emitter, setTimelinePosition, video?.id]);\n  const play = useCallback2((e) => {\n    if (imperativePlaying.current) {\n      return;\n    }\n    setHasPlayed(true);\n    if (isLastFrame) {\n      seek(0);\n    }\n    audioContext?.audioContext?.resume();\n    if (audioContext && audioContext.numberOfAudioTags > 0 && e) {\n      audioContext.playAllAudios();\n    }\n    audioAndVideoTags.current.forEach((a) => a.play(\"player play() was called and playing audio from a click\"));\n    imperativePlaying.current = true;\n    setPlaying(true);\n    playStart.current = frameRef.current;\n    emitter.dispatchPlay();\n  }, [\n    imperativePlaying,\n    isLastFrame,\n    audioContext,\n    setPlaying,\n    emitter,\n    seek,\n    audioAndVideoTags\n  ]);\n  const pause = useCallback2(() => {\n    if (imperativePlaying.current) {\n      imperativePlaying.current = false;\n      setPlaying(false);\n      emitter.dispatchPause();\n      audioContext?.audioContext?.suspend();\n    }\n  }, [emitter, imperativePlaying, setPlaying, audioContext]);\n  const pauseAndReturnToPlayStart = useCallback2(() => {\n    if (imperativePlaying.current) {\n      imperativePlaying.current = false;\n      frameRef.current = playStart.current;\n      if (config) {\n        setTimelinePosition((c) => ({\n          ...c,\n          [config.id]: playStart.current\n        }));\n        setPlaying(false);\n        emitter.dispatchPause();\n      }\n    }\n  }, [config, emitter, imperativePlaying, setPlaying, setTimelinePosition]);\n  const videoId = video?.id;\n  const frameBack = useCallback2((frames) => {\n    if (!videoId) {\n      return null;\n    }\n    if (imperativePlaying.current) {\n      return;\n    }\n    setFrame((c) => {\n      const prevFrame = c[videoId] ?? window.remotion_initialFrame ?? 0;\n      const newFrame = Math.max(0, prevFrame - frames);\n      if (prevFrame === newFrame) {\n        return c;\n      }\n      return {\n        ...c,\n        [videoId]: newFrame\n      };\n    });\n  }, [imperativePlaying, setFrame, videoId]);\n  const frameForward = useCallback2((frames) => {\n    if (!videoId) {\n      return null;\n    }\n    if (imperativePlaying.current) {\n      return;\n    }\n    setFrame((c) => {\n      const prevFrame = c[videoId] ?? window.remotion_initialFrame ?? 0;\n      const newFrame = Math.min(lastFrame, prevFrame + frames);\n      if (prevFrame === newFrame) {\n        return c;\n      }\n      return {\n        ...c,\n        [videoId]: newFrame\n      };\n    });\n  }, [videoId, imperativePlaying, lastFrame, setFrame]);\n  const toggle = useCallback2((e) => {\n    if (imperativePlaying.current) {\n      pause();\n    } else {\n      play(e);\n    }\n  }, [imperativePlaying, pause, play]);\n  const isPlaying = useCallback2(() => {\n    return imperativePlaying.current;\n  }, [imperativePlaying]);\n  const getCurrentFrame = useCallback2(() => {\n    return frameRef.current;\n  }, [frameRef]);\n  const isBuffering = useCallback2(() => {\n    return buffering.current;\n  }, [buffering]);\n  const returnValue = useMemo(() => {\n    return {\n      frameBack,\n      frameForward,\n      isLastFrame,\n      emitter,\n      playing,\n      play,\n      pause,\n      seek,\n      isFirstFrame,\n      getCurrentFrame,\n      isPlaying,\n      isBuffering,\n      pauseAndReturnToPlayStart,\n      hasPlayed,\n      toggle\n    };\n  }, [\n    emitter,\n    frameBack,\n    frameForward,\n    hasPlayed,\n    isFirstFrame,\n    isLastFrame,\n    getCurrentFrame,\n    pause,\n    pauseAndReturnToPlayStart,\n    play,\n    playing,\n    seek,\n    toggle,\n    isPlaying,\n    isBuffering\n  ]);\n  return returnValue;\n};\n\n// src/browser-mediasession.ts\nvar useBrowserMediaSession = ({\n  browserMediaControlsBehavior,\n  videoConfig,\n  playbackRate\n}) => {\n  const { playing, pause, play, emitter, getCurrentFrame, seek } = usePlayer();\n  useEffect3(() => {\n    if (!navigator.mediaSession) {\n      return;\n    }\n    if (browserMediaControlsBehavior.mode === \"do-nothing\") {\n      return;\n    }\n    if (playing) {\n      navigator.mediaSession.playbackState = \"playing\";\n    } else {\n      navigator.mediaSession.playbackState = \"paused\";\n    }\n  }, [browserMediaControlsBehavior.mode, playing]);\n  useEffect3(() => {\n    if (!navigator.mediaSession) {\n      return;\n    }\n    if (browserMediaControlsBehavior.mode === \"do-nothing\") {\n      return;\n    }\n    const onTimeUpdate = () => {\n      if (!videoConfig) {\n        return;\n      }\n      if (navigator.mediaSession) {\n        navigator.mediaSession.setPositionState({\n          duration: videoConfig.durationInFrames / videoConfig.fps,\n          playbackRate,\n          position: getCurrentFrame() / videoConfig.fps\n        });\n      }\n    };\n    emitter.addEventListener(\"timeupdate\", onTimeUpdate);\n    return () => {\n      emitter.removeEventListener(\"timeupdate\", onTimeUpdate);\n    };\n  }, [\n    browserMediaControlsBehavior.mode,\n    emitter,\n    getCurrentFrame,\n    playbackRate,\n    videoConfig\n  ]);\n  useEffect3(() => {\n    if (!navigator.mediaSession) {\n      return;\n    }\n    if (browserMediaControlsBehavior.mode === \"do-nothing\") {\n      return;\n    }\n    navigator.mediaSession.setActionHandler(\"play\", () => {\n      if (browserMediaControlsBehavior.mode === \"register-media-session\") {\n        play();\n      }\n    });\n    navigator.mediaSession.setActionHandler(\"pause\", () => {\n      if (browserMediaControlsBehavior.mode === \"register-media-session\") {\n        pause();\n      }\n    });\n    navigator.mediaSession.setActionHandler(\"seekto\", (event) => {\n      if (browserMediaControlsBehavior.mode === \"register-media-session\" && event.seekTime !== undefined && videoConfig) {\n        seek(Math.round(event.seekTime * videoConfig.fps));\n      }\n    });\n    navigator.mediaSession.setActionHandler(\"seekbackward\", () => {\n      if (browserMediaControlsBehavior.mode === \"register-media-session\" && videoConfig) {\n        seek(Math.max(0, Math.round((getCurrentFrame() - 10) * videoConfig.fps)));\n      }\n    });\n    navigator.mediaSession.setActionHandler(\"seekforward\", () => {\n      if (browserMediaControlsBehavior.mode === \"register-media-session\" && videoConfig) {\n        seek(Math.max(videoConfig.durationInFrames - 1, Math.round((getCurrentFrame() + 10) * videoConfig.fps)));\n      }\n    });\n    navigator.mediaSession.setActionHandler(\"previoustrack\", () => {\n      if (browserMediaControlsBehavior.mode === \"register-media-session\") {\n        seek(0);\n      }\n    });\n    return () => {\n      navigator.mediaSession.metadata = null;\n      navigator.mediaSession.setActionHandler(\"play\", null);\n      navigator.mediaSession.setActionHandler(\"pause\", null);\n      navigator.mediaSession.setActionHandler(\"seekto\", null);\n      navigator.mediaSession.setActionHandler(\"seekbackward\", null);\n      navigator.mediaSession.setActionHandler(\"seekforward\", null);\n      navigator.mediaSession.setActionHandler(\"previoustrack\", null);\n    };\n  }, [\n    browserMediaControlsBehavior.mode,\n    getCurrentFrame,\n    pause,\n    play,\n    seek,\n    videoConfig\n  ]);\n};\n\n// src/calculate-next-frame.ts\nvar calculateNextFrame = ({\n  time,\n  currentFrame: startFrame,\n  playbackSpeed,\n  fps,\n  actualLastFrame,\n  actualFirstFrame,\n  framesAdvanced,\n  shouldLoop\n}) => {\n  const op = playbackSpeed < 0 ? Math.ceil : Math.floor;\n  const framesToAdvance = op(time * playbackSpeed / (1000 / fps)) - framesAdvanced;\n  const nextFrame = framesToAdvance + startFrame;\n  const isCurrentFrameOutside = startFrame > actualLastFrame || startFrame < actualFirstFrame;\n  const isNextFrameOutside = nextFrame > actualLastFrame || nextFrame < actualFirstFrame;\n  const hasEnded = !shouldLoop && isNextFrameOutside && !isCurrentFrameOutside;\n  if (playbackSpeed > 0) {\n    if (isNextFrameOutside) {\n      return {\n        nextFrame: actualFirstFrame,\n        framesToAdvance,\n        hasEnded\n      };\n    }\n    return { nextFrame, framesToAdvance, hasEnded };\n  }\n  if (isNextFrameOutside) {\n    return { nextFrame: actualLastFrame, framesToAdvance, hasEnded };\n  }\n  return { nextFrame, framesToAdvance, hasEnded };\n};\n\n// src/is-backgrounded.ts\nimport { useEffect as useEffect4, useRef as useRef3 } from \"react\";\nvar getIsBackgrounded = () => {\n  if (typeof document === \"undefined\") {\n    return false;\n  }\n  return document.visibilityState === \"hidden\";\n};\nvar useIsBackgrounded = () => {\n  const isBackgrounded = useRef3(getIsBackgrounded());\n  useEffect4(() => {\n    const onVisibilityChange = () => {\n      isBackgrounded.current = getIsBackgrounded();\n    };\n    document.addEventListener(\"visibilitychange\", onVisibilityChange);\n    return () => {\n      document.removeEventListener(\"visibilitychange\", onVisibilityChange);\n    };\n  }, []);\n  return isBackgrounded;\n};\n\n// src/use-playback.ts\nvar usePlayback = ({\n  loop,\n  playbackRate,\n  moveToBeginningWhenEnded,\n  inFrame,\n  outFrame,\n  browserMediaControlsBehavior,\n  getCurrentFrame\n}) => {\n  const config = Internals6.useUnsafeVideoConfig();\n  const frame = Internals6.Timeline.useTimelinePosition();\n  const { playing, pause, emitter, isPlaying } = usePlayer();\n  const setFrame = Internals6.Timeline.useTimelineSetFrame();\n  const isBackgroundedRef = useIsBackgrounded();\n  const lastTimeUpdateEvent = useRef4(null);\n  const context = useContext4(Internals6.BufferingContextReact);\n  if (!context) {\n    throw new Error(\"Missing the buffering context. Most likely you have a Remotion version mismatch.\");\n  }\n  useBrowserMediaSession({\n    browserMediaControlsBehavior,\n    playbackRate,\n    videoConfig: config\n  });\n  useEffect5(() => {\n    if (!config) {\n      return;\n    }\n    if (!playing) {\n      return;\n    }\n    let hasBeenStopped = false;\n    let reqAnimFrameCall = null;\n    let startedTime = performance.now();\n    let framesAdvanced = 0;\n    const cancelQueuedFrame = () => {\n      if (reqAnimFrameCall !== null) {\n        if (reqAnimFrameCall.type === \"raf\") {\n          cancelAnimationFrame(reqAnimFrameCall.id);\n        } else {\n          clearTimeout(reqAnimFrameCall.id);\n        }\n      }\n    };\n    const stop = () => {\n      hasBeenStopped = true;\n      cancelQueuedFrame();\n    };\n    const callback = () => {\n      if (hasBeenStopped) {\n        return;\n      }\n      if (!isPlaying()) {\n        return;\n      }\n      const time = performance.now() - startedTime;\n      const actualLastFrame = outFrame ?? config.durationInFrames - 1;\n      const actualFirstFrame = inFrame ?? 0;\n      const currentFrame = getCurrentFrame();\n      const { nextFrame, framesToAdvance, hasEnded } = calculateNextFrame({\n        time,\n        currentFrame,\n        playbackSpeed: playbackRate,\n        fps: config.fps,\n        actualFirstFrame,\n        actualLastFrame,\n        framesAdvanced,\n        shouldLoop: loop\n      });\n      framesAdvanced += framesToAdvance;\n      if (nextFrame !== getCurrentFrame() && (!hasEnded || moveToBeginningWhenEnded)) {\n        setFrame((c) => ({ ...c, [config.id]: nextFrame }));\n      }\n      if (hasEnded) {\n        stop();\n        pause();\n        emitter.dispatchEnded();\n        return;\n      }\n      queueNextFrame();\n    };\n    const queueNextFrame = () => {\n      if (context.buffering.current) {\n        const stopListening = context.listenForResume(() => {\n          stopListening.remove();\n          startedTime = performance.now();\n          framesAdvanced = 0;\n          queueNextFrame();\n        });\n        return;\n      }\n      if (isBackgroundedRef.current) {\n        reqAnimFrameCall = {\n          type: \"timeout\",\n          id: setTimeout(callback, 1000 / config.fps)\n        };\n        return;\n      }\n      reqAnimFrameCall = { type: \"raf\", id: requestAnimationFrame(callback) };\n    };\n    queueNextFrame();\n    const onVisibilityChange = () => {\n      if (document.visibilityState === \"visible\") {\n        return;\n      }\n      cancelQueuedFrame();\n      callback();\n    };\n    window.addEventListener(\"visibilitychange\", onVisibilityChange);\n    return () => {\n      window.removeEventListener(\"visibilitychange\", onVisibilityChange);\n      stop();\n    };\n  }, [\n    config,\n    loop,\n    pause,\n    playing,\n    setFrame,\n    emitter,\n    playbackRate,\n    inFrame,\n    outFrame,\n    moveToBeginningWhenEnded,\n    isBackgroundedRef,\n    getCurrentFrame,\n    context,\n    isPlaying\n  ]);\n  useEffect5(() => {\n    const interval = setInterval(() => {\n      if (lastTimeUpdateEvent.current === getCurrentFrame()) {\n        return;\n      }\n      emitter.dispatchTimeUpdate({ frame: getCurrentFrame() });\n      lastTimeUpdateEvent.current = getCurrentFrame();\n    }, 250);\n    return () => clearInterval(interval);\n  }, [emitter, getCurrentFrame]);\n  useEffect5(() => {\n    emitter.dispatchFrameUpdate({ frame });\n  }, [emitter, frame]);\n};\n\n// src/utils/use-element-size.ts\nimport { useCallback as useCallback3, useEffect as useEffect6, useMemo as useMemo2, useState as useState4 } from \"react\";\nvar elementSizeHooks = [];\nvar updateAllElementsSizes = () => {\n  for (const listener of elementSizeHooks) {\n    listener();\n  }\n};\nvar useElementSize = (ref, options) => {\n  const [size, setSize] = useState4(() => {\n    if (!ref.current) {\n      return null;\n    }\n    const rect = ref.current.getClientRects();\n    if (!rect[0]) {\n      return null;\n    }\n    return {\n      width: rect[0].width,\n      height: rect[0].height,\n      left: rect[0].x,\n      top: rect[0].y,\n      windowSize: {\n        height: window.innerHeight,\n        width: window.innerWidth\n      }\n    };\n  });\n  const observer = useMemo2(() => {\n    if (typeof ResizeObserver === \"undefined\") {\n      return null;\n    }\n    return new ResizeObserver((entries) => {\n      const { contentRect, target } = entries[0];\n      const newSize = target.getClientRects();\n      if (!newSize?.[0]) {\n        setSize(null);\n        return;\n      }\n      const probableCssParentScale = contentRect.width === 0 ? 1 : newSize[0].width / contentRect.width;\n      const width = options.shouldApplyCssTransforms || probableCssParentScale === 0 ? newSize[0].width : newSize[0].width * (1 / probableCssParentScale);\n      const height = options.shouldApplyCssTransforms || probableCssParentScale === 0 ? newSize[0].height : newSize[0].height * (1 / probableCssParentScale);\n      setSize((prevState) => {\n        const isSame = prevState && prevState.width === width && prevState.height === height && prevState.left === newSize[0].x && prevState.top === newSize[0].y && prevState.windowSize.height === window.innerHeight && prevState.windowSize.width === window.innerWidth;\n        if (isSame) {\n          return prevState;\n        }\n        return {\n          width,\n          height,\n          left: newSize[0].x,\n          top: newSize[0].y,\n          windowSize: {\n            height: window.innerHeight,\n            width: window.innerWidth\n          }\n        };\n      });\n    });\n  }, [options.shouldApplyCssTransforms]);\n  const updateSize = useCallback3(() => {\n    if (!ref.current) {\n      return;\n    }\n    const rect = ref.current.getClientRects();\n    if (!rect[0]) {\n      setSize(null);\n      return;\n    }\n    setSize((prevState) => {\n      const isSame = prevState && prevState.width === rect[0].width && prevState.height === rect[0].height && prevState.left === rect[0].x && prevState.top === rect[0].y && prevState.windowSize.height === window.innerHeight && prevState.windowSize.width === window.innerWidth;\n      if (isSame) {\n        return prevState;\n      }\n      return {\n        width: rect[0].width,\n        height: rect[0].height,\n        left: rect[0].x,\n        top: rect[0].y,\n        windowSize: {\n          height: window.innerHeight,\n          width: window.innerWidth\n        }\n      };\n    });\n  }, [ref]);\n  useEffect6(() => {\n    if (!observer) {\n      return;\n    }\n    const { current } = ref;\n    if (current) {\n      observer.observe(current);\n    }\n    return () => {\n      if (current) {\n        observer.unobserve(current);\n      }\n    };\n  }, [observer, ref, updateSize]);\n  useEffect6(() => {\n    if (!options.triggerOnWindowResize) {\n      return;\n    }\n    window.addEventListener(\"resize\", updateSize);\n    return () => {\n      window.removeEventListener(\"resize\", updateSize);\n    };\n  }, [options.triggerOnWindowResize, updateSize]);\n  useEffect6(() => {\n    elementSizeHooks.push(updateSize);\n    return () => {\n      elementSizeHooks = elementSizeHooks.filter((e) => e !== updateSize);\n    };\n  }, [updateSize]);\n  return useMemo2(() => {\n    if (!size) {\n      return null;\n    }\n    return { ...size, refresh: updateSize };\n  }, [size, updateSize]);\n};\n\n// src/Player.tsx\nimport {\n  forwardRef as forwardRef2,\n  useEffect as useEffect13,\n  useImperativeHandle as useImperativeHandle2,\n  useLayoutEffect as useLayoutEffect2,\n  useMemo as useMemo14,\n  useRef as useRef11,\n  useState as useState13\n} from \"react\";\nimport { Composition, Internals as Internals15 } from \"remotion\";\n\n// src/PlayerUI.tsx\nimport React10, {\n  Suspense,\n  forwardRef,\n  useCallback as useCallback11,\n  useContext as useContext6,\n  useEffect as useEffect12,\n  useImperativeHandle,\n  useMemo as useMemo12,\n  useRef as useRef10,\n  useState as useState11\n} from \"react\";\nimport { Internals as Internals11 } from \"remotion\";\n\n// src/PlayerControls.tsx\nimport { useCallback as useCallback8, useEffect as useEffect10, useMemo as useMemo9, useRef as useRef8, useState as useState10 } from \"react\";\n\n// src/DefaultPlayPauseButton.tsx\nimport { jsx as jsx4 } from \"react/jsx-runtime\";\nvar DefaultPlayPauseButton = ({ playing, buffering }) => {\n  if (playing && buffering) {\n    return /* @__PURE__ */ jsx4(BufferingIndicator, {\n      type: \"player\"\n    });\n  }\n  if (playing) {\n    return /* @__PURE__ */ jsx4(PauseIcon, {});\n  }\n  return /* @__PURE__ */ jsx4(PlayIcon, {});\n};\n\n// src/MediaVolumeSlider.tsx\nimport { useCallback as useCallback5, useMemo as useMemo4, useRef as useRef5, useState as useState6 } from \"react\";\nimport { Internals as Internals7 } from \"remotion\";\n\n// src/render-volume-slider.tsx\nimport React3, { useCallback as useCallback4, useMemo as useMemo3, useState as useState5 } from \"react\";\nimport { random } from \"remotion\";\nimport { jsx as jsx5, jsxs as jsxs3 } from \"react/jsx-runtime\";\nvar KNOB_SIZE = 12;\nvar BAR_HEIGHT = 5;\nvar DefaultVolumeSlider = ({\n  volume,\n  isVertical,\n  onBlur,\n  inputRef,\n  setVolume\n}) => {\n  const sliderContainer = useMemo3(() => {\n    const paddingLeft = 5;\n    const common = {\n      paddingLeft,\n      height: ICON_SIZE,\n      width: VOLUME_SLIDER_WIDTH,\n      display: \"inline-flex\",\n      alignItems: \"center\"\n    };\n    if (isVertical) {\n      return {\n        ...common,\n        position: \"absolute\",\n        transform: `rotate(-90deg) translateX(${VOLUME_SLIDER_WIDTH / 2 + ICON_SIZE / 2}px)`\n      };\n    }\n    return {\n      ...common\n    };\n  }, [isVertical]);\n  const randomId = typeof React3.useId === \"undefined\" ? \"volume-slider\" : React3.useId();\n  const [randomClass] = useState5(() => `__remotion-volume-slider-${random(randomId)}`.replace(\".\", \"\"));\n  const onVolumeChange = useCallback4((e) => {\n    setVolume(parseFloat(e.target.value));\n  }, [setVolume]);\n  const inputStyle = useMemo3(() => {\n    const commonStyle = {\n      WebkitAppearance: \"none\",\n      backgroundColor: \"rgba(255, 255, 255, 0.5)\",\n      borderRadius: BAR_HEIGHT / 2,\n      cursor: \"pointer\",\n      height: BAR_HEIGHT,\n      width: VOLUME_SLIDER_WIDTH,\n      backgroundImage: `linear-gradient(\n\t\t\t\tto right,\n\t\t\t\twhite ${volume * 100}%, rgba(255, 255, 255, 0) ${volume * 100}%\n\t\t\t)`\n    };\n    if (isVertical) {\n      return {\n        ...commonStyle,\n        bottom: ICON_SIZE + VOLUME_SLIDER_WIDTH / 2\n      };\n    }\n    return commonStyle;\n  }, [isVertical, volume]);\n  const sliderStyle = `\n\t.${randomClass}::-webkit-slider-thumb {\n\t\t-webkit-appearance: none;\n\t\tbackground-color: white;\n\t\tborder-radius: ${KNOB_SIZE / 2}px;\n\t\tbox-shadow: 0 0 2px black;\n\t\theight: ${KNOB_SIZE}px;\n\t\twidth: ${KNOB_SIZE}px;\n\t}\n\n\t.${randomClass}::-moz-range-thumb {\n\t\t-webkit-appearance: none;\n\t\tbackground-color: white;\n\t\tborder-radius: ${KNOB_SIZE / 2}px;\n\t\tbox-shadow: 0 0 2px black;\n\t\theight: ${KNOB_SIZE}px;\n\t\twidth: ${KNOB_SIZE}px;\n\t}\n`;\n  return /* @__PURE__ */ jsxs3(\"div\", {\n    style: sliderContainer,\n    children: [\n      /* @__PURE__ */ jsx5(\"style\", {\n        dangerouslySetInnerHTML: {\n          __html: sliderStyle\n        }\n      }),\n      /* @__PURE__ */ jsx5(\"input\", {\n        ref: inputRef,\n        \"aria-label\": \"Change volume\",\n        className: randomClass,\n        max: 1,\n        min: 0,\n        onBlur,\n        onChange: onVolumeChange,\n        step: 0.01,\n        type: \"range\",\n        value: volume,\n        style: inputStyle\n      })\n    ]\n  });\n};\nvar renderDefaultVolumeSlider = (props) => {\n  return /* @__PURE__ */ jsx5(DefaultVolumeSlider, {\n    ...props\n  });\n};\n\n// src/MediaVolumeSlider.tsx\nimport { jsx as jsx6, jsxs as jsxs4 } from \"react/jsx-runtime\";\nvar VOLUME_SLIDER_WIDTH = 100;\nvar MediaVolumeSlider = ({ displayVerticalVolumeSlider, renderMuteButton, renderVolumeSlider }) => {\n  const [mediaMuted, setMediaMuted] = Internals7.useMediaMutedState();\n  const [mediaVolume, setMediaVolume] = Internals7.useMediaVolumeState();\n  const [focused, setFocused] = useState6(false);\n  const parentDivRef = useRef5(null);\n  const inputRef = useRef5(null);\n  const hover = useHoverState(parentDivRef, false);\n  const onBlur = useCallback5(() => {\n    setTimeout(() => {\n      if (inputRef.current && document.activeElement !== inputRef.current) {\n        setFocused(false);\n      }\n    }, 10);\n  }, []);\n  const isVolume0 = mediaVolume === 0;\n  const onClick = useCallback5(() => {\n    if (isVolume0) {\n      setMediaVolume(1);\n      setMediaMuted(false);\n      return;\n    }\n    setMediaMuted((mute) => !mute);\n  }, [isVolume0, setMediaMuted, setMediaVolume]);\n  const parentDivStyle = useMemo4(() => {\n    return {\n      display: \"inline-flex\",\n      background: \"none\",\n      border: \"none\",\n      justifyContent: \"center\",\n      alignItems: \"center\",\n      touchAction: \"none\",\n      ...displayVerticalVolumeSlider && { position: \"relative\" }\n    };\n  }, [displayVerticalVolumeSlider]);\n  const volumeContainer = useMemo4(() => {\n    return {\n      display: \"inline\",\n      width: ICON_SIZE,\n      height: ICON_SIZE,\n      cursor: \"pointer\",\n      appearance: \"none\",\n      background: \"none\",\n      border: \"none\",\n      padding: 0\n    };\n  }, []);\n  const renderDefaultMuteButton = useCallback5(({ muted, volume }) => {\n    const isMutedOrZero = muted || volume === 0;\n    return /* @__PURE__ */ jsx6(\"button\", {\n      \"aria-label\": isMutedOrZero ? \"Unmute sound\" : \"Mute sound\",\n      title: isMutedOrZero ? \"Unmute sound\" : \"Mute sound\",\n      onClick,\n      onBlur,\n      onFocus: () => setFocused(true),\n      style: volumeContainer,\n      type: \"button\",\n      children: isMutedOrZero ? /* @__PURE__ */ jsx6(VolumeOffIcon, {}) : /* @__PURE__ */ jsx6(VolumeOnIcon, {})\n    });\n  }, [onBlur, onClick, volumeContainer]);\n  const muteButton = useMemo4(() => {\n    return renderMuteButton ? renderMuteButton({ muted: mediaMuted, volume: mediaVolume }) : renderDefaultMuteButton({ muted: mediaMuted, volume: mediaVolume });\n  }, [mediaMuted, mediaVolume, renderDefaultMuteButton, renderMuteButton]);\n  const volumeSlider = useMemo4(() => {\n    return (focused || hover) && !mediaMuted && !Internals7.isIosSafari() ? (renderVolumeSlider ?? renderDefaultVolumeSlider)({\n      isVertical: displayVerticalVolumeSlider,\n      volume: mediaVolume,\n      onBlur: () => setFocused(false),\n      inputRef,\n      setVolume: setMediaVolume\n    }) : null;\n  }, [\n    displayVerticalVolumeSlider,\n    focused,\n    hover,\n    mediaMuted,\n    mediaVolume,\n    renderVolumeSlider,\n    setMediaVolume\n  ]);\n  return /* @__PURE__ */ jsxs4(\"div\", {\n    ref: parentDivRef,\n    style: parentDivStyle,\n    children: [\n      muteButton,\n      volumeSlider\n    ]\n  });\n};\n\n// src/PlaybackrateControl.tsx\nimport {\n  useCallback as useCallback6,\n  useContext as useContext5,\n  useEffect as useEffect8,\n  useMemo as useMemo5,\n  useState as useState8\n} from \"react\";\nimport { Internals as Internals8 } from \"remotion\";\n\n// src/utils/use-component-visible.ts\nimport { useEffect as useEffect7, useRef as useRef6, useState as useState7 } from \"react\";\nfunction useComponentVisible(initialIsVisible) {\n  const [isComponentVisible, setIsComponentVisible] = useState7(initialIsVisible);\n  const ref = useRef6(null);\n  useEffect7(() => {\n    const handleClickOutside = (event) => {\n      if (ref.current && !ref.current.contains(event.target)) {\n        setIsComponentVisible(false);\n      }\n    };\n    document.addEventListener(\"pointerup\", handleClickOutside, true);\n    return () => {\n      document.removeEventListener(\"pointerup\", handleClickOutside, true);\n    };\n  }, []);\n  return { ref, isComponentVisible, setIsComponentVisible };\n}\n\n// src/PlaybackrateControl.tsx\nimport { jsx as jsx7, jsxs as jsxs5 } from \"react/jsx-runtime\";\nvar BOTTOM = 35;\nvar THRESHOLD = 70;\nvar rateDiv = {\n  height: 30,\n  paddingRight: 15,\n  paddingLeft: 12,\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar checkmarkContainer = {\n  width: 22,\n  display: \"flex\",\n  alignItems: \"center\"\n};\nvar checkmarkStyle = {\n  width: 14,\n  height: 14,\n  color: \"black\"\n};\nvar Checkmark = () => /* @__PURE__ */ jsx7(\"svg\", {\n  viewBox: \"0 0 512 512\",\n  style: checkmarkStyle,\n  children: /* @__PURE__ */ jsx7(\"path\", {\n    fill: \"currentColor\",\n    d: \"M435.848 83.466L172.804 346.51l-96.652-96.652c-4.686-4.686-12.284-4.686-16.971 0l-28.284 28.284c-4.686 4.686-4.686 12.284 0 16.971l133.421 133.421c4.686 4.686 12.284 4.686 16.971 0l299.813-299.813c4.686-4.686 4.686-12.284 0-16.971l-28.284-28.284c-4.686-4.686-12.284-4.686-16.97 0z\"\n  })\n});\nvar formatPlaybackRate = (rate) => {\n  const str = rate.toString();\n  return str.includes(\".\") ? str : str + \".0\";\n};\nvar PlaybackrateOption = ({ rate, onSelect, selectedRate, keyboardSelectedRate }) => {\n  const onClick = useCallback6((e) => {\n    e.stopPropagation();\n    e.preventDefault();\n    onSelect(rate);\n  }, [onSelect, rate]);\n  const [hovered, setHovered] = useState8(false);\n  const onMouseEnter = useCallback6(() => {\n    setHovered(true);\n  }, []);\n  const onMouseLeave = useCallback6(() => {\n    setHovered(false);\n  }, []);\n  const isFocused = keyboardSelectedRate === rate;\n  const actualStyle = useMemo5(() => {\n    return {\n      ...rateDiv,\n      backgroundColor: hovered || isFocused ? \"#eee\" : \"transparent\"\n    };\n  }, [hovered, isFocused]);\n  return /* @__PURE__ */ jsxs5(\"div\", {\n    onPointerEnter: onMouseEnter,\n    onPointerLeave: onMouseLeave,\n    tabIndex: 0,\n    style: actualStyle,\n    onClick,\n    children: [\n      /* @__PURE__ */ jsx7(\"div\", {\n        style: checkmarkContainer,\n        children: rate === selectedRate ? /* @__PURE__ */ jsx7(Checkmark, {}) : null\n      }),\n      formatPlaybackRate(rate),\n      \"x\"\n    ]\n  }, rate);\n};\nvar PlaybackPopup = ({ setIsComponentVisible, playbackRates, canvasSize }) => {\n  const { setPlaybackRate, playbackRate } = useContext5(Internals8.TimelineContext);\n  const [keyboardSelectedRate, setKeyboardSelectedRate] = useState8(playbackRate);\n  useEffect8(() => {\n    const listener = (e) => {\n      e.preventDefault();\n      if (e.key === \"ArrowUp\") {\n        const currentIndex = playbackRates.findIndex((rate) => rate === keyboardSelectedRate);\n        if (currentIndex === 0) {\n          return;\n        }\n        if (currentIndex === -1) {\n          setKeyboardSelectedRate(playbackRates[0]);\n        } else {\n          setKeyboardSelectedRate(playbackRates[currentIndex - 1]);\n        }\n      } else if (e.key === \"ArrowDown\") {\n        const currentIndex = playbackRates.findIndex((rate) => rate === keyboardSelectedRate);\n        if (currentIndex === playbackRates.length - 1) {\n          return;\n        }\n        if (currentIndex === -1) {\n          setKeyboardSelectedRate(playbackRates[playbackRates.length - 1]);\n        } else {\n          setKeyboardSelectedRate(playbackRates[currentIndex + 1]);\n        }\n      } else if (e.key === \"Enter\") {\n        setPlaybackRate(keyboardSelectedRate);\n        setIsComponentVisible(false);\n      }\n    };\n    window.addEventListener(\"keydown\", listener);\n    return () => {\n      window.removeEventListener(\"keydown\", listener);\n    };\n  }, [\n    playbackRates,\n    keyboardSelectedRate,\n    setPlaybackRate,\n    setIsComponentVisible\n  ]);\n  const onSelect = useCallback6((rate) => {\n    setPlaybackRate(rate);\n    setIsComponentVisible(false);\n  }, [setIsComponentVisible, setPlaybackRate]);\n  const playbackPopup = useMemo5(() => {\n    return {\n      position: \"absolute\",\n      right: 0,\n      width: 125,\n      maxHeight: canvasSize.height - THRESHOLD - BOTTOM,\n      bottom: 35,\n      background: \"#fff\",\n      borderRadius: 4,\n      overflow: \"auto\",\n      color: \"black\",\n      textAlign: \"left\"\n    };\n  }, [canvasSize.height]);\n  return /* @__PURE__ */ jsx7(\"div\", {\n    style: playbackPopup,\n    children: playbackRates.map((rate) => {\n      return /* @__PURE__ */ jsx7(PlaybackrateOption, {\n        selectedRate: playbackRate,\n        onSelect,\n        rate,\n        keyboardSelectedRate\n      }, rate);\n    })\n  });\n};\nvar label = {\n  fontSize: 13,\n  fontWeight: \"bold\",\n  color: \"white\",\n  border: \"2px solid white\",\n  borderRadius: 20,\n  paddingLeft: 8,\n  paddingRight: 8,\n  paddingTop: 2,\n  paddingBottom: 2\n};\nvar playerButtonStyle = {\n  appearance: \"none\",\n  backgroundColor: \"transparent\",\n  border: \"none\",\n  cursor: \"pointer\",\n  paddingLeft: 0,\n  paddingRight: 0,\n  paddingTop: 6,\n  paddingBottom: 6,\n  height: 37,\n  display: \"inline-flex\",\n  marginBottom: 0,\n  marginTop: 0,\n  alignItems: \"center\"\n};\nvar button = {\n  ...playerButtonStyle,\n  position: \"relative\"\n};\nvar PlaybackrateControl = ({ playbackRates, canvasSize }) => {\n  const { ref, isComponentVisible, setIsComponentVisible } = useComponentVisible(false);\n  const { playbackRate } = useContext5(Internals8.TimelineContext);\n  const onClick = useCallback6((e) => {\n    e.stopPropagation();\n    e.preventDefault();\n    setIsComponentVisible((prevIsComponentVisible) => !prevIsComponentVisible);\n  }, [setIsComponentVisible]);\n  return /* @__PURE__ */ jsx7(\"div\", {\n    ref,\n    children: /* @__PURE__ */ jsxs5(\"button\", {\n      type: \"button\",\n      \"aria-label\": \"Change playback rate\",\n      style: button,\n      onClick,\n      children: [\n        /* @__PURE__ */ jsxs5(\"div\", {\n          style: label,\n          children: [\n            playbackRate,\n            \"x\"\n          ]\n        }),\n        isComponentVisible && /* @__PURE__ */ jsx7(PlaybackPopup, {\n          canvasSize,\n          playbackRates,\n          setIsComponentVisible\n        })\n      ]\n    })\n  });\n};\n\n// src/PlayerSeekBar.tsx\nimport { useCallback as useCallback7, useEffect as useEffect9, useMemo as useMemo6, useRef as useRef7, useState as useState9 } from \"react\";\nimport { Internals as Internals9, interpolate } from \"remotion\";\nimport { jsx as jsx8, jsxs as jsxs6 } from \"react/jsx-runtime\";\nvar getFrameFromX = (clientX, durationInFrames, width) => {\n  const pos = clientX;\n  const frame = Math.round(interpolate(pos, [0, width], [0, durationInFrames - 1], {\n    extrapolateLeft: \"clamp\",\n    extrapolateRight: \"clamp\"\n  }));\n  return frame;\n};\nvar BAR_HEIGHT2 = 5;\nvar KNOB_SIZE2 = 12;\nvar VERTICAL_PADDING = 4;\nvar containerStyle = {\n  userSelect: \"none\",\n  WebkitUserSelect: \"none\",\n  paddingTop: VERTICAL_PADDING,\n  paddingBottom: VERTICAL_PADDING,\n  boxSizing: \"border-box\",\n  cursor: \"pointer\",\n  position: \"relative\",\n  touchAction: \"none\"\n};\nvar barBackground = {\n  height: BAR_HEIGHT2,\n  backgroundColor: \"rgba(255, 255, 255, 0.25)\",\n  width: \"100%\",\n  borderRadius: BAR_HEIGHT2 / 2\n};\nvar findBodyInWhichDivIsLocated = (div) => {\n  let current = div;\n  while (current.parentElement) {\n    current = current.parentElement;\n  }\n  return current;\n};\nvar PlayerSeekBar = ({ durationInFrames, onSeekEnd, onSeekStart, inFrame, outFrame }) => {\n  const containerRef = useRef7(null);\n  const barHovered = useHoverState(containerRef, false);\n  const size = useElementSize(containerRef, {\n    triggerOnWindowResize: true,\n    shouldApplyCssTransforms: true\n  });\n  const { seek, play, pause, playing } = usePlayer();\n  const frame = Internals9.Timeline.useTimelinePosition();\n  const [dragging, setDragging] = useState9({\n    dragging: false\n  });\n  const width = size?.width ?? 0;\n  const onPointerDown = useCallback7((e) => {\n    if (e.button !== 0) {\n      return;\n    }\n    const posLeft = containerRef.current?.getBoundingClientRect().left;\n    const _frame = getFrameFromX(e.clientX - posLeft, durationInFrames, width);\n    pause();\n    seek(_frame);\n    setDragging({\n      dragging: true,\n      wasPlaying: playing\n    });\n    onSeekStart();\n  }, [durationInFrames, width, pause, seek, playing, onSeekStart]);\n  const onPointerMove = useCallback7((e) => {\n    if (!size) {\n      throw new Error(\"Player has no size\");\n    }\n    if (!dragging.dragging) {\n      return;\n    }\n    const posLeft = containerRef.current?.getBoundingClientRect().left;\n    const _frame = getFrameFromX(e.clientX - posLeft, durationInFrames, size.width);\n    seek(_frame);\n  }, [dragging.dragging, durationInFrames, seek, size]);\n  const onPointerUp = useCallback7(() => {\n    setDragging({\n      dragging: false\n    });\n    if (!dragging.dragging) {\n      return;\n    }\n    if (dragging.wasPlaying) {\n      play();\n    } else {\n      pause();\n    }\n    onSeekEnd();\n  }, [dragging, onSeekEnd, pause, play]);\n  useEffect9(() => {\n    if (!dragging.dragging) {\n      return;\n    }\n    const body = findBodyInWhichDivIsLocated(containerRef.current);\n    body.addEventListener(\"pointermove\", onPointerMove);\n    body.addEventListener(\"pointerup\", onPointerUp);\n    return () => {\n      body.removeEventListener(\"pointermove\", onPointerMove);\n      body.removeEventListener(\"pointerup\", onPointerUp);\n    };\n  }, [dragging.dragging, onPointerMove, onPointerUp]);\n  const knobStyle = useMemo6(() => {\n    return {\n      height: KNOB_SIZE2,\n      width: KNOB_SIZE2,\n      borderRadius: KNOB_SIZE2 / 2,\n      position: \"absolute\",\n      top: VERTICAL_PADDING - KNOB_SIZE2 / 2 + 5 / 2,\n      backgroundColor: \"white\",\n      left: Math.max(0, frame / Math.max(1, durationInFrames - 1) * width - KNOB_SIZE2 / 2),\n      boxShadow: \"0 0 2px black\",\n      opacity: Number(barHovered || dragging.dragging)\n    };\n  }, [barHovered, dragging.dragging, durationInFrames, frame, width]);\n  const fillStyle = useMemo6(() => {\n    return {\n      height: BAR_HEIGHT2,\n      backgroundColor: \"rgba(255, 255, 255, 1)\",\n      width: (frame - (inFrame ?? 0)) / (durationInFrames - 1) * width,\n      marginLeft: (inFrame ?? 0) / (durationInFrames - 1) * width,\n      borderRadius: BAR_HEIGHT2 / 2\n    };\n  }, [durationInFrames, frame, inFrame, width]);\n  const active = useMemo6(() => {\n    return {\n      height: BAR_HEIGHT2,\n      backgroundColor: \"rgba(255, 255, 255, 0.25)\",\n      width: ((outFrame ?? durationInFrames - 1) - (inFrame ?? 0)) / (durationInFrames - 1) * 100 + \"%\",\n      marginLeft: (inFrame ?? 0) / (durationInFrames - 1) * 100 + \"%\",\n      borderRadius: BAR_HEIGHT2 / 2,\n      position: \"absolute\"\n    };\n  }, [durationInFrames, inFrame, outFrame]);\n  return /* @__PURE__ */ jsxs6(\"div\", {\n    ref: containerRef,\n    onPointerDown,\n    style: containerStyle,\n    children: [\n      /* @__PURE__ */ jsxs6(\"div\", {\n        style: barBackground,\n        children: [\n          /* @__PURE__ */ jsx8(\"div\", {\n            style: active\n          }),\n          /* @__PURE__ */ jsx8(\"div\", {\n            style: fillStyle\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx8(\"div\", {\n        style: knobStyle\n      })\n    ]\n  });\n};\n\n// src/PlayerTimeLabel.tsx\nimport { useMemo as useMemo7 } from \"react\";\nimport { Internals as Internals10 } from \"remotion\";\n\n// src/format-time.ts\nvar formatTime = (timeInSeconds) => {\n  const minutes = Math.floor(timeInSeconds / 60);\n  const seconds = Math.floor(timeInSeconds - minutes * 60);\n  return `${String(minutes)}:${String(seconds).padStart(2, \"0\")}`;\n};\n\n// src/PlayerTimeLabel.tsx\nimport { jsxs as jsxs7 } from \"react/jsx-runtime\";\nvar PlayerTimeLabel = ({ durationInFrames, maxTimeLabelWidth, fps }) => {\n  const frame = Internals10.Timeline.useTimelinePosition();\n  const timeLabel = useMemo7(() => {\n    return {\n      color: \"white\",\n      fontFamily: \"sans-serif\",\n      fontSize: 14,\n      maxWidth: maxTimeLabelWidth === null ? undefined : maxTimeLabelWidth,\n      overflow: \"hidden\",\n      textOverflow: \"ellipsis\"\n    };\n  }, [maxTimeLabelWidth]);\n  const isLastFrame = frame === durationInFrames - 1;\n  const frameToDisplay = isLastFrame ? frame + 1 : frame;\n  return /* @__PURE__ */ jsxs7(\"div\", {\n    style: timeLabel,\n    children: [\n      formatTime(frameToDisplay / fps),\n      \" / \",\n      formatTime(durationInFrames / fps)\n    ]\n  });\n};\n\n// src/use-video-controls-resize.ts\nimport { useMemo as useMemo8 } from \"react\";\nvar X_SPACER = 10;\nvar X_PADDING = 12;\nvar useVideoControlsResize = ({\n  allowFullscreen: allowFullScreen,\n  playerWidth\n}) => {\n  const resizeInfo = useMemo8(() => {\n    const playPauseIconSize = ICON_SIZE;\n    const volumeIconSize = ICON_SIZE;\n    const _fullscreenIconSize = allowFullScreen ? fullscreenIconSize : 0;\n    const elementsSize = volumeIconSize + playPauseIconSize + _fullscreenIconSize + X_PADDING * 2 + X_SPACER * 2;\n    const maxTimeLabelWidth = playerWidth - elementsSize;\n    const maxTimeLabelWidthWithoutNegativeValue = Math.max(maxTimeLabelWidth, 0);\n    const availableTimeLabelWidthIfVolumeOpen = maxTimeLabelWidthWithoutNegativeValue - VOLUME_SLIDER_WIDTH;\n    const computedLabelWidth = availableTimeLabelWidthIfVolumeOpen < VOLUME_SLIDER_WIDTH ? maxTimeLabelWidthWithoutNegativeValue : availableTimeLabelWidthIfVolumeOpen;\n    const minWidthForHorizontalDisplay = computedLabelWidth + elementsSize + VOLUME_SLIDER_WIDTH;\n    const displayVerticalVolumeSlider = playerWidth < minWidthForHorizontalDisplay;\n    return {\n      maxTimeLabelWidth: maxTimeLabelWidthWithoutNegativeValue === 0 ? null : maxTimeLabelWidthWithoutNegativeValue,\n      displayVerticalVolumeSlider\n    };\n  }, [allowFullScreen, playerWidth]);\n  return resizeInfo;\n};\n\n// src/PlayerControls.tsx\nimport { jsx as jsx9, jsxs as jsxs8, Fragment as Fragment2 } from \"react/jsx-runtime\";\nvar gradientSteps = [\n  0,\n  0.013,\n  0.049,\n  0.104,\n  0.175,\n  0.259,\n  0.352,\n  0.45,\n  0.55,\n  0.648,\n  0.741,\n  0.825,\n  0.896,\n  0.951,\n  0.987\n];\nvar gradientOpacities = [\n  0,\n  8.1,\n  15.5,\n  22.5,\n  29,\n  35.3,\n  41.2,\n  47.1,\n  52.9,\n  58.8,\n  64.7,\n  71,\n  77.5,\n  84.5,\n  91.9\n];\nvar globalGradientOpacity = 1 / 0.7;\nvar containerStyle2 = {\n  boxSizing: \"border-box\",\n  position: \"absolute\",\n  bottom: 0,\n  width: \"100%\",\n  paddingTop: 40,\n  paddingBottom: 10,\n  backgroundImage: `linear-gradient(to bottom,${gradientSteps.map((g, i) => {\n    return `hsla(0, 0%, 0%, ${g}) ${gradientOpacities[i] * globalGradientOpacity}%`;\n  }).join(\", \")}, hsl(0, 0%, 0%) 100%)`,\n  backgroundSize: \"auto 145px\",\n  display: \"flex\",\n  paddingRight: X_PADDING,\n  paddingLeft: X_PADDING,\n  flexDirection: \"column\",\n  transition: \"opacity 0.3s\"\n};\nvar controlsRow = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  width: \"100%\",\n  alignItems: \"center\",\n  justifyContent: \"center\",\n  userSelect: \"none\",\n  WebkitUserSelect: \"none\"\n};\nvar leftPartStyle = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  userSelect: \"none\",\n  WebkitUserSelect: \"none\",\n  alignItems: \"center\"\n};\nvar xSpacer = {\n  width: 12\n};\nvar ySpacer = {\n  height: 8\n};\nvar flex1 = {\n  flex: 1\n};\nvar fullscreen = {};\nvar Controls = ({\n  durationInFrames,\n  isFullscreen,\n  fps,\n  showVolumeControls,\n  onFullscreenButtonClick,\n  allowFullscreen,\n  onExitFullscreenButtonClick,\n  spaceKeyToPlayOrPause,\n  onSeekEnd,\n  onSeekStart,\n  inFrame,\n  outFrame,\n  initiallyShowControls,\n  canvasSize,\n  renderPlayPauseButton,\n  renderFullscreenButton,\n  alwaysShowControls,\n  showPlaybackRateControl,\n  containerRef,\n  buffering,\n  hideControlsWhenPointerDoesntMove,\n  onPointerDown,\n  onDoubleClick,\n  renderMuteButton,\n  renderVolumeSlider,\n  playing,\n  toggle\n}) => {\n  const playButtonRef = useRef8(null);\n  const [supportsFullscreen, setSupportsFullscreen] = useState10(false);\n  const hovered = useHoverState(containerRef, hideControlsWhenPointerDoesntMove);\n  const { maxTimeLabelWidth, displayVerticalVolumeSlider } = useVideoControlsResize({\n    allowFullscreen,\n    playerWidth: canvasSize?.width ?? 0\n  });\n  const [shouldShowInitially, setInitiallyShowControls] = useState10(() => {\n    if (typeof initiallyShowControls === \"boolean\") {\n      return initiallyShowControls;\n    }\n    if (typeof initiallyShowControls === \"number\") {\n      if (initiallyShowControls % 1 !== 0) {\n        throw new Error(\"initiallyShowControls must be an integer or a boolean\");\n      }\n      if (Number.isNaN(initiallyShowControls)) {\n        throw new Error(\"initiallyShowControls must not be NaN\");\n      }\n      if (!Number.isFinite(initiallyShowControls)) {\n        throw new Error(\"initiallyShowControls must be finite\");\n      }\n      if (initiallyShowControls <= 0) {\n        throw new Error(\"initiallyShowControls must be a positive integer\");\n      }\n      return initiallyShowControls;\n    }\n    throw new TypeError(\"initiallyShowControls must be a number or a boolean\");\n  });\n  const containerCss = useMemo9(() => {\n    const shouldShow = hovered || !playing || shouldShowInitially || alwaysShowControls;\n    return {\n      ...containerStyle2,\n      opacity: Number(shouldShow)\n    };\n  }, [hovered, shouldShowInitially, playing, alwaysShowControls]);\n  useEffect10(() => {\n    if (playButtonRef.current && spaceKeyToPlayOrPause) {\n      playButtonRef.current.focus({\n        preventScroll: true\n      });\n    }\n  }, [playing, spaceKeyToPlayOrPause]);\n  useEffect10(() => {\n    setSupportsFullscreen((typeof document !== \"undefined\" && (document.fullscreenEnabled || document.webkitFullscreenEnabled)) ?? false);\n  }, []);\n  useEffect10(() => {\n    if (shouldShowInitially === false) {\n      return;\n    }\n    const time = shouldShowInitially === true ? 2000 : shouldShowInitially;\n    const timeout = setTimeout(() => {\n      setInitiallyShowControls(false);\n    }, time);\n    return () => {\n      clearInterval(timeout);\n    };\n  }, [shouldShowInitially]);\n  const playbackRates = useMemo9(() => {\n    if (showPlaybackRateControl === true) {\n      return [0.5, 0.8, 1, 1.2, 1.5, 1.8, 2, 2.5, 3];\n    }\n    if (Array.isArray(showPlaybackRateControl)) {\n      for (const rate of showPlaybackRateControl) {\n        if (typeof rate !== \"number\") {\n          throw new Error(\"Every item in showPlaybackRateControl must be a number\");\n        }\n        if (rate <= 0) {\n          throw new Error(\"Every item in showPlaybackRateControl must be positive\");\n        }\n      }\n      return showPlaybackRateControl;\n    }\n    return null;\n  }, [showPlaybackRateControl]);\n  const ref = useRef8(null);\n  const flexRef = useRef8(null);\n  const onPointerDownIfContainer = useCallback8((e) => {\n    if (e.target === ref.current || e.target === flexRef.current) {\n      onPointerDown?.(e);\n    }\n  }, [onPointerDown]);\n  const onDoubleClickIfContainer = useCallback8((e) => {\n    if (e.target === ref.current || e.target === flexRef.current) {\n      onDoubleClick?.(e);\n    }\n  }, [onDoubleClick]);\n  return /* @__PURE__ */ jsxs8(\"div\", {\n    ref,\n    style: containerCss,\n    onPointerDown: onPointerDownIfContainer,\n    onDoubleClick: onDoubleClickIfContainer,\n    children: [\n      /* @__PURE__ */ jsxs8(\"div\", {\n        ref: flexRef,\n        style: controlsRow,\n        children: [\n          /* @__PURE__ */ jsxs8(\"div\", {\n            style: leftPartStyle,\n            children: [\n              /* @__PURE__ */ jsx9(\"button\", {\n                ref: playButtonRef,\n                type: \"button\",\n                style: playerButtonStyle,\n                onClick: toggle,\n                \"aria-label\": playing ? \"Pause video\" : \"Play video\",\n                title: playing ? \"Pause video\" : \"Play video\",\n                children: renderPlayPauseButton === null ? /* @__PURE__ */ jsx9(DefaultPlayPauseButton, {\n                  buffering,\n                  playing\n                }) : renderPlayPauseButton({\n                  playing,\n                  isBuffering: buffering\n                }) ?? /* @__PURE__ */ jsx9(DefaultPlayPauseButton, {\n                  buffering,\n                  playing\n                })\n              }),\n              showVolumeControls ? /* @__PURE__ */ jsxs8(Fragment2, {\n                children: [\n                  /* @__PURE__ */ jsx9(\"div\", {\n                    style: xSpacer\n                  }),\n                  /* @__PURE__ */ jsx9(MediaVolumeSlider, {\n                    renderMuteButton,\n                    renderVolumeSlider,\n                    displayVerticalVolumeSlider\n                  })\n                ]\n              }) : null,\n              /* @__PURE__ */ jsx9(\"div\", {\n                style: xSpacer\n              }),\n              /* @__PURE__ */ jsx9(PlayerTimeLabel, {\n                durationInFrames,\n                fps,\n                maxTimeLabelWidth\n              }),\n              /* @__PURE__ */ jsx9(\"div\", {\n                style: xSpacer\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx9(\"div\", {\n            style: flex1\n          }),\n          playbackRates && canvasSize && /* @__PURE__ */ jsx9(PlaybackrateControl, {\n            canvasSize,\n            playbackRates\n          }),\n          playbackRates && supportsFullscreen && allowFullscreen ? /* @__PURE__ */ jsx9(\"div\", {\n            style: xSpacer\n          }) : null,\n          /* @__PURE__ */ jsx9(\"div\", {\n            style: fullscreen,\n            children: supportsFullscreen && allowFullscreen ? /* @__PURE__ */ jsx9(\"button\", {\n              type: \"button\",\n              \"aria-label\": isFullscreen ? \"Exit fullscreen\" : \"Enter Fullscreen\",\n              title: isFullscreen ? \"Exit fullscreen\" : \"Enter Fullscreen\",\n              style: playerButtonStyle,\n              onClick: isFullscreen ? onExitFullscreenButtonClick : onFullscreenButtonClick,\n              children: renderFullscreenButton === null ? /* @__PURE__ */ jsx9(FullscreenIcon, {\n                isFullscreen\n              }) : renderFullscreenButton({ isFullscreen })\n            }) : null\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx9(\"div\", {\n        style: ySpacer\n      }),\n      /* @__PURE__ */ jsx9(PlayerSeekBar, {\n        onSeekEnd,\n        onSeekStart,\n        durationInFrames,\n        inFrame,\n        outFrame\n      })\n    ]\n  });\n};\n\n// src/error-boundary.tsx\nimport React8 from \"react\";\nimport { jsx as jsx10 } from \"react/jsx-runtime\";\nvar errorStyle = {\n  display: \"flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  flex: 1,\n  height: \"100%\",\n  width: \"100%\"\n};\n\nclass ErrorBoundary extends React8.Component {\n  state = { hasError: null };\n  static getDerivedStateFromError(error) {\n    return { hasError: error };\n  }\n  componentDidCatch(error) {\n    this.props.onError(error);\n  }\n  render() {\n    if (this.state.hasError) {\n      return /* @__PURE__ */ jsx10(\"div\", {\n        style: errorStyle,\n        children: this.props.errorFallback({\n          error: this.state.hasError\n        })\n      });\n    }\n    return this.props.children;\n  }\n}\n\n// src/license-blacklist.tsx\nimport React9, { useEffect as useEffect11 } from \"react\";\nimport { jsx as jsx11 } from \"react/jsx-runtime\";\nvar getHashOfDomain = async () => {\n  if (typeof window === \"undefined\") {\n    return null;\n  }\n  if (typeof window.crypto === \"undefined\") {\n    return null;\n  }\n  if (typeof window.crypto.subtle === \"undefined\") {\n    return null;\n  }\n  try {\n    const hashBuffer = await crypto.subtle.digest(\"SHA-256\", new TextEncoder().encode(window.location.hostname));\n    return Array.from(new Uint8Array(hashBuffer)).map((b) => b.toString(16).padStart(2, \"0\")).join(\"\");\n  } catch {\n    return null;\n  }\n};\nvar style = {\n  backgroundColor: \"red\",\n  position: \"absolute\",\n  padding: 12,\n  fontFamily: \"Arial\"\n};\nvar DOMAIN_BLACKLIST = [\n  \"28d262b44cc61fa750f1686b16ad0604dabfe193fbc263eec05c89b7ad4c2cd6\",\n  \"4db1b0a94be33165dfefcb3ba03d04c7a2666dd27c496d3dc9fa41858e94925e\",\n  \"fbc48530bbf245da790f63675e84e06bab38c3b114fab07eb350025119922bdc\",\n  \"7baf10a8932757b1b3a22b3fce10a048747ac2f8eaf638603487e3705b07eb83\",\n  \"8a6c21a598d8c667272b5207c051b85997bf5b45d5fb712378be3f27cd72c6a6\",\n  \"a2f7aaac9c50a9255e7fc376110c4e0bfe153722dc66ed3c5d3bf2a135f65518\"\n];\nvar ran = false;\nvar RenderWarningIfBlacklist = () => {\n  const [unlicensed, setUnlicensed] = React9.useState(false);\n  useEffect11(() => {\n    if (ran) {\n      return;\n    }\n    ran = true;\n    getHashOfDomain().then((hash) => {\n      if (hash && DOMAIN_BLACKLIST.includes(hash)) {\n        setUnlicensed(true);\n      }\n    }).catch(() => {});\n  }, []);\n  useEffect11(() => {\n    if (!unlicensed) {\n      return;\n    }\n    const ensureBanner = () => {\n      const banner = document.querySelector(\".warning-banner\");\n      if (!banner) {\n        const div = document.createElement(\"div\");\n        div.className = \"warning-banner\";\n        Object.assign(div.style, style, {\n          zIndex: \"9999\",\n          cssText: `${style.cssText} !important;`\n        });\n        div.innerHTML = `\n\t        <a href=\"https://github.com/remotion-dev/remotion/pull/4589\" style=\"color: white;\">\n\t          Remotion Unlicensed  Contact hi@remotion.dev\n\t        </a>\n\t      `;\n        document.body.appendChild(div);\n      }\n    };\n    const observer = new MutationObserver(() => ensureBanner());\n    observer.observe(document.body, { childList: true, subtree: true });\n    return () => {\n      observer.disconnect();\n    };\n  }, [unlicensed]);\n  if (!unlicensed) {\n    return null;\n  }\n  return /* @__PURE__ */ jsx11(\"div\", {\n    style,\n    className: \"warning-banner\",\n    children: /* @__PURE__ */ jsx11(\"a\", {\n      style: { color: \"white\" },\n      href: \"https://github.com/remotion-dev/remotion/pull/4589\",\n      children: \"Remotion Unlicensed  Contact hi@remotion.dev\"\n    })\n  });\n};\n\n// src/player-css-classname.ts\nvar playerCssClassname = (override) => {\n  return override ?? \"__remotion-player\";\n};\n\n// src/utils/is-node.ts\nvar IS_NODE = typeof document === \"undefined\";\n\n// src/utils/use-click-prevention-on-double-click.ts\nimport { useCallback as useCallback10, useMemo as useMemo11 } from \"react\";\n\n// src/utils/cancellable-promise.ts\nvar cancellablePromise = (promise) => {\n  let isCanceled = false;\n  const wrappedPromise = new Promise((resolve, reject) => {\n    promise.then((value) => {\n      if (isCanceled) {\n        reject({ isCanceled, value });\n        return;\n      }\n      resolve(value);\n    }).catch((error) => {\n      reject({ isCanceled, error });\n    });\n  });\n  return {\n    promise: wrappedPromise,\n    cancel: () => {\n      isCanceled = true;\n    }\n  };\n};\n\n// src/utils/delay.ts\nvar delay = (n) => new Promise((resolve) => setTimeout(resolve, n));\n\n// src/utils/use-cancellable-promises.ts\nimport { useCallback as useCallback9, useMemo as useMemo10, useRef as useRef9 } from \"react\";\nvar useCancellablePromises = () => {\n  const pendingPromises = useRef9([]);\n  const appendPendingPromise = useCallback9((promise) => {\n    pendingPromises.current = [...pendingPromises.current, promise];\n  }, []);\n  const removePendingPromise = useCallback9((promise) => {\n    pendingPromises.current = pendingPromises.current.filter((p) => p !== promise);\n  }, []);\n  const clearPendingPromises = useCallback9(() => pendingPromises.current.map((p) => p.cancel()), []);\n  const api = useMemo10(() => ({\n    appendPendingPromise,\n    removePendingPromise,\n    clearPendingPromises\n  }), [appendPendingPromise, clearPendingPromises, removePendingPromise]);\n  return api;\n};\n\n// src/utils/use-click-prevention-on-double-click.ts\nvar useClickPreventionOnDoubleClick = (onClick, onDoubleClick, doubleClickToFullscreen) => {\n  const api = useCancellablePromises();\n  const handleClick = useCallback10(async (e) => {\n    if (e instanceof PointerEvent ? e.pointerType === \"touch\" : e.nativeEvent.pointerType === \"touch\") {\n      onClick(e);\n      return;\n    }\n    api.clearPendingPromises();\n    const waitForClick = cancellablePromise(delay(200));\n    api.appendPendingPromise(waitForClick);\n    try {\n      await waitForClick.promise;\n      api.removePendingPromise(waitForClick);\n      onClick(e);\n    } catch (errorInfo) {\n      const info = errorInfo;\n      api.removePendingPromise(waitForClick);\n      if (!info.isCanceled) {\n        throw info.error;\n      }\n    }\n  }, [api, onClick]);\n  const handlePointerDown = useCallback10(() => {\n    document.addEventListener(\"pointerup\", (newEvt) => {\n      handleClick(newEvt);\n    }, {\n      once: true\n    });\n  }, [handleClick]);\n  const handleDoubleClick = useCallback10(() => {\n    api.clearPendingPromises();\n    onDoubleClick();\n  }, [api, onDoubleClick]);\n  const returnValue = useMemo11(() => {\n    if (!doubleClickToFullscreen) {\n      return { handlePointerDown: onClick, handleDoubleClick: () => {\n        return;\n      } };\n    }\n    return { handlePointerDown, handleDoubleClick };\n  }, [doubleClickToFullscreen, handleDoubleClick, handlePointerDown, onClick]);\n  return returnValue;\n};\n\n// src/PlayerUI.tsx\nimport { jsx as jsx12, jsxs as jsxs9, Fragment as Fragment3 } from \"react/jsx-runtime\";\nvar reactVersion = React10.version.split(\".\")[0];\nif (reactVersion === \"0\") {\n  throw new Error(`Version ${reactVersion} of \"react\" is not supported by Remotion`);\n}\nvar doesReactVersionSupportSuspense = parseInt(reactVersion, 10) >= 18;\nvar PlayerUI = ({\n  controls,\n  style: style2,\n  loop,\n  autoPlay,\n  allowFullscreen,\n  inputProps,\n  clickToPlay,\n  showVolumeControls,\n  doubleClickToFullscreen,\n  spaceKeyToPlayOrPause,\n  errorFallback,\n  playbackRate,\n  renderLoading,\n  renderPoster,\n  className: className2,\n  moveToBeginningWhenEnded,\n  showPosterWhenUnplayed,\n  showPosterWhenEnded,\n  showPosterWhenPaused,\n  showPosterWhenBuffering,\n  showPosterWhenBufferingAndPaused,\n  inFrame,\n  outFrame,\n  initiallyShowControls,\n  renderFullscreen: renderFullscreenButton,\n  renderPlayPauseButton,\n  renderMuteButton,\n  renderVolumeSlider,\n  alwaysShowControls,\n  showPlaybackRateControl,\n  posterFillMode,\n  bufferStateDelayInMilliseconds,\n  hideControlsWhenPointerDoesntMove,\n  overflowVisible,\n  browserMediaControlsBehavior,\n  overrideInternalClassName,\n  noSuspense\n}, ref) => {\n  const config = Internals11.useUnsafeVideoConfig();\n  const video = Internals11.useVideo();\n  const container = useRef10(null);\n  const canvasSize = useElementSize(container, {\n    triggerOnWindowResize: false,\n    shouldApplyCssTransforms: false\n  });\n  const [hasPausedToResume, setHasPausedToResume] = useState11(false);\n  const [shouldAutoplay, setShouldAutoPlay] = useState11(autoPlay);\n  const [isFullscreen, setIsFullscreen] = useState11(() => false);\n  const [seeking, setSeeking] = useState11(false);\n  const supportsFullScreen = useMemo12(() => {\n    if (typeof document === \"undefined\") {\n      return false;\n    }\n    return Boolean(document.fullscreenEnabled || document.webkitFullscreenEnabled);\n  }, []);\n  const player = usePlayer();\n  const playerToggle = player.toggle;\n  usePlayback({\n    loop,\n    playbackRate,\n    moveToBeginningWhenEnded,\n    inFrame,\n    outFrame,\n    getCurrentFrame: player.getCurrentFrame,\n    browserMediaControlsBehavior\n  });\n  useEffect12(() => {\n    if (hasPausedToResume && !player.playing) {\n      setHasPausedToResume(false);\n      player.play();\n    }\n  }, [hasPausedToResume, player]);\n  useEffect12(() => {\n    const { current } = container;\n    if (!current) {\n      return;\n    }\n    const onFullscreenChange = () => {\n      const newValue = document.fullscreenElement === current || document.webkitFullscreenElement === current;\n      setIsFullscreen(newValue);\n    };\n    document.addEventListener(\"fullscreenchange\", onFullscreenChange);\n    document.addEventListener(\"webkitfullscreenchange\", onFullscreenChange);\n    return () => {\n      document.removeEventListener(\"fullscreenchange\", onFullscreenChange);\n      document.removeEventListener(\"webkitfullscreenchange\", onFullscreenChange);\n    };\n  }, []);\n  const toggle = useCallback11((e) => {\n    playerToggle(e);\n  }, [playerToggle]);\n  const requestFullscreen = useCallback11(() => {\n    if (!allowFullscreen) {\n      throw new Error(\"allowFullscreen is false\");\n    }\n    if (!supportsFullScreen) {\n      throw new Error(\"Browser doesnt support fullscreen\");\n    }\n    if (!container.current) {\n      throw new Error(\"No player ref found\");\n    }\n    if (container.current.webkitRequestFullScreen) {\n      container.current.webkitRequestFullScreen();\n    } else {\n      container.current.requestFullscreen();\n    }\n  }, [allowFullscreen, supportsFullScreen]);\n  const exitFullscreen = useCallback11(() => {\n    if (document.webkitExitFullscreen) {\n      document.webkitExitFullscreen();\n    } else {\n      document.exitFullscreen();\n    }\n  }, []);\n  useEffect12(() => {\n    const { current } = container;\n    if (!current) {\n      return;\n    }\n    const fullscreenChange = () => {\n      const element = document.webkitFullscreenElement ?? document.fullscreenElement;\n      if (element && element === container.current) {\n        player.emitter.dispatchFullscreenChange({\n          isFullscreen: true\n        });\n      } else {\n        player.emitter.dispatchFullscreenChange({\n          isFullscreen: false\n        });\n      }\n    };\n    current.addEventListener(\"webkitfullscreenchange\", fullscreenChange);\n    current.addEventListener(\"fullscreenchange\", fullscreenChange);\n    return () => {\n      current.removeEventListener(\"webkitfullscreenchange\", fullscreenChange);\n      current.removeEventListener(\"fullscreenchange\", fullscreenChange);\n    };\n  }, [player.emitter]);\n  const durationInFrames = config?.durationInFrames ?? 1;\n  const layout = useMemo12(() => {\n    if (!config || !canvasSize) {\n      return null;\n    }\n    return calculateCanvasTransformation({\n      canvasSize,\n      compositionHeight: config.height,\n      compositionWidth: config.width,\n      previewSize: \"auto\"\n    });\n  }, [canvasSize, config]);\n  const scale = layout?.scale ?? 1;\n  const initialScaleIgnored = useRef10(false);\n  useEffect12(() => {\n    if (!initialScaleIgnored.current) {\n      initialScaleIgnored.current = true;\n      return;\n    }\n    player.emitter.dispatchScaleChange(scale);\n  }, [player.emitter, scale]);\n  const { setMediaVolume, setMediaMuted } = useContext6(Internals11.SetMediaVolumeContext);\n  const { mediaMuted, mediaVolume } = useContext6(Internals11.MediaVolumeContext);\n  useEffect12(() => {\n    player.emitter.dispatchVolumeChange(mediaVolume);\n  }, [player.emitter, mediaVolume]);\n  const isMuted = mediaMuted || mediaVolume === 0;\n  useEffect12(() => {\n    player.emitter.dispatchMuteChange({\n      isMuted\n    });\n  }, [player.emitter, isMuted]);\n  const [showBufferIndicator, setShowBufferState] = useState11(false);\n  useEffect12(() => {\n    let timeout = null;\n    let stopped = false;\n    const onBuffer = () => {\n      stopped = false;\n      requestAnimationFrame(() => {\n        if (bufferStateDelayInMilliseconds === 0) {\n          setShowBufferState(true);\n        } else {\n          timeout = setTimeout(() => {\n            if (!stopped) {\n              setShowBufferState(true);\n            }\n          }, bufferStateDelayInMilliseconds);\n        }\n      });\n    };\n    const onResume = () => {\n      requestAnimationFrame(() => {\n        stopped = true;\n        setShowBufferState(false);\n        if (timeout) {\n          clearTimeout(timeout);\n        }\n      });\n    };\n    player.emitter.addEventListener(\"waiting\", onBuffer);\n    player.emitter.addEventListener(\"resume\", onResume);\n    return () => {\n      player.emitter.removeEventListener(\"waiting\", onBuffer);\n      player.emitter.removeEventListener(\"resume\", onResume);\n      setShowBufferState(false);\n      if (timeout) {\n        clearTimeout(timeout);\n      }\n      stopped = true;\n    };\n  }, [bufferStateDelayInMilliseconds, player.emitter]);\n  useImperativeHandle(ref, () => {\n    const methods = {\n      play: player.play,\n      pause: () => {\n        setHasPausedToResume(false);\n        player.pause();\n      },\n      toggle,\n      getContainerNode: () => container.current,\n      getCurrentFrame: player.getCurrentFrame,\n      isPlaying: player.isPlaying,\n      seekTo: (f) => {\n        const lastFrame = durationInFrames - 1;\n        const frameToSeekTo = Math.max(0, Math.min(lastFrame, f));\n        if (player.isPlaying()) {\n          const pauseToResume = frameToSeekTo !== lastFrame || loop;\n          setHasPausedToResume(pauseToResume);\n          player.pause();\n        }\n        if (frameToSeekTo === lastFrame && !loop) {\n          player.emitter.dispatchEnded();\n        }\n        player.seek(frameToSeekTo);\n      },\n      isFullscreen: () => {\n        const { current } = container;\n        if (!current) {\n          return false;\n        }\n        return document.fullscreenElement === current || document.webkitFullscreenElement === current;\n      },\n      requestFullscreen,\n      exitFullscreen,\n      getVolume: () => {\n        if (mediaMuted) {\n          return 0;\n        }\n        return mediaVolume;\n      },\n      setVolume: (vol) => {\n        if (typeof vol !== \"number\") {\n          throw new TypeError(`setVolume() takes a number, got value of type ${typeof vol}`);\n        }\n        if (isNaN(vol)) {\n          throw new TypeError(`setVolume() got a number that is NaN. Volume must be between 0 and 1.`);\n        }\n        if (vol < 0 || vol > 1) {\n          throw new TypeError(`setVolume() got a number that is out of range. Must be between 0 and 1, got ${typeof vol}`);\n        }\n        setMediaVolume(vol);\n      },\n      isMuted: () => isMuted,\n      mute: () => {\n        setMediaMuted(true);\n      },\n      unmute: () => {\n        setMediaMuted(false);\n      },\n      getScale: () => scale,\n      pauseAndReturnToPlayStart: () => {\n        player.pauseAndReturnToPlayStart();\n      }\n    };\n    return Object.assign(player.emitter, methods);\n  }, [\n    durationInFrames,\n    exitFullscreen,\n    loop,\n    mediaMuted,\n    isMuted,\n    mediaVolume,\n    player,\n    requestFullscreen,\n    setMediaMuted,\n    setMediaVolume,\n    toggle,\n    scale\n  ]);\n  const VideoComponent = video ? video.component : null;\n  const outerStyle = useMemo12(() => {\n    return calculateOuterStyle({\n      canvasSize,\n      config,\n      style: style2,\n      overflowVisible,\n      layout\n    });\n  }, [canvasSize, config, layout, overflowVisible, style2]);\n  const outer = useMemo12(() => {\n    return calculateOuter({ config, layout, scale, overflowVisible });\n  }, [config, layout, overflowVisible, scale]);\n  const containerStyle3 = useMemo12(() => {\n    return calculateContainerStyle({\n      config,\n      layout,\n      scale,\n      overflowVisible\n    });\n  }, [config, layout, overflowVisible, scale]);\n  const playerPause = player.pause;\n  const playerDispatchError = player.emitter.dispatchError;\n  const onError = useCallback11((error) => {\n    playerPause();\n    playerDispatchError(error);\n  }, [playerDispatchError, playerPause]);\n  const onFullscreenButtonClick = useCallback11((e) => {\n    e.stopPropagation();\n    requestFullscreen();\n  }, [requestFullscreen]);\n  const onExitFullscreenButtonClick = useCallback11((e) => {\n    e.stopPropagation();\n    exitFullscreen();\n  }, [exitFullscreen]);\n  const onSingleClick = useCallback11((e) => {\n    const rightClick = e instanceof MouseEvent ? e.button === 2 : e.nativeEvent.button;\n    if (rightClick) {\n      return;\n    }\n    toggle(e);\n  }, [toggle]);\n  const onSeekStart = useCallback11(() => {\n    setSeeking(true);\n  }, []);\n  const onSeekEnd = useCallback11(() => {\n    setSeeking(false);\n  }, []);\n  const onDoubleClick = useCallback11(() => {\n    if (isFullscreen) {\n      exitFullscreen();\n    } else {\n      requestFullscreen();\n    }\n  }, [exitFullscreen, isFullscreen, requestFullscreen]);\n  const { handlePointerDown, handleDoubleClick } = useClickPreventionOnDoubleClick(onSingleClick, onDoubleClick, doubleClickToFullscreen && allowFullscreen && supportsFullScreen);\n  useEffect12(() => {\n    if (shouldAutoplay) {\n      player.play();\n      setShouldAutoPlay(false);\n    }\n  }, [shouldAutoplay, player]);\n  const loadingMarkup = useMemo12(() => {\n    return renderLoading ? renderLoading({\n      height: outerStyle.height,\n      width: outerStyle.width,\n      isBuffering: showBufferIndicator\n    }) : null;\n  }, [outerStyle.height, outerStyle.width, renderLoading, showBufferIndicator]);\n  const currentScale = useMemo12(() => {\n    return {\n      type: \"scale\",\n      scale\n    };\n  }, [scale]);\n  if (!config) {\n    return null;\n  }\n  const poster = renderPoster ? renderPoster({\n    height: posterFillMode === \"player-size\" ? outerStyle.height : config.height,\n    width: posterFillMode === \"player-size\" ? outerStyle.width : config.width,\n    isBuffering: showBufferIndicator\n  }) : null;\n  if (poster === undefined) {\n    throw new TypeError(\"renderPoster() must return a React element, but undefined was returned\");\n  }\n  const shouldShowPoster = poster && [\n    showPosterWhenPaused && !player.isPlaying() && !seeking,\n    showPosterWhenEnded && player.isLastFrame && !player.isPlaying(),\n    showPosterWhenUnplayed && !player.hasPlayed && !player.isPlaying(),\n    showPosterWhenBuffering && showBufferIndicator && player.isPlaying(),\n    showPosterWhenBufferingAndPaused && showBufferIndicator && !player.isPlaying()\n  ].some(Boolean);\n  const { left, top, width, height, ...outerWithoutScale } = outer;\n  const content = /* @__PURE__ */ jsxs9(Fragment3, {\n    children: [\n      /* @__PURE__ */ jsxs9(\"div\", {\n        style: outer,\n        onPointerDown: clickToPlay ? handlePointerDown : undefined,\n        onDoubleClick: doubleClickToFullscreen ? handleDoubleClick : undefined,\n        children: [\n          /* @__PURE__ */ jsxs9(\"div\", {\n            style: containerStyle3,\n            className: playerCssClassname(overrideInternalClassName),\n            children: [\n              VideoComponent ? /* @__PURE__ */ jsx12(ErrorBoundary, {\n                onError,\n                errorFallback,\n                children: /* @__PURE__ */ jsx12(Internals11.CurrentScaleContext.Provider, {\n                  value: currentScale,\n                  children: /* @__PURE__ */ jsx12(VideoComponent, {\n                    ...video?.props ?? {},\n                    ...inputProps ?? {}\n                  })\n                })\n              }) : null,\n              shouldShowPoster && posterFillMode === \"composition-size\" ? /* @__PURE__ */ jsx12(\"div\", {\n                style: {\n                  ...outerWithoutScale,\n                  width: config.width,\n                  height: config.height\n                },\n                onPointerDown: clickToPlay ? handlePointerDown : undefined,\n                onDoubleClick: doubleClickToFullscreen ? handleDoubleClick : undefined,\n                children: poster\n              }) : null\n            ]\n          }),\n          /* @__PURE__ */ jsx12(RenderWarningIfBlacklist, {})\n        ]\n      }),\n      shouldShowPoster && posterFillMode === \"player-size\" ? /* @__PURE__ */ jsx12(\"div\", {\n        style: outer,\n        onPointerDown: clickToPlay ? handlePointerDown : undefined,\n        onDoubleClick: doubleClickToFullscreen ? handleDoubleClick : undefined,\n        children: poster\n      }) : null,\n      controls ? /* @__PURE__ */ jsx12(Controls, {\n        fps: config.fps,\n        playing: player.playing,\n        toggle: player.toggle,\n        durationInFrames: config.durationInFrames,\n        containerRef: container,\n        onFullscreenButtonClick,\n        isFullscreen,\n        allowFullscreen,\n        showVolumeControls,\n        onExitFullscreenButtonClick,\n        spaceKeyToPlayOrPause,\n        onSeekEnd,\n        onSeekStart,\n        inFrame,\n        outFrame,\n        initiallyShowControls,\n        canvasSize,\n        renderFullscreenButton,\n        renderPlayPauseButton,\n        alwaysShowControls,\n        showPlaybackRateControl,\n        buffering: showBufferIndicator,\n        hideControlsWhenPointerDoesntMove,\n        onDoubleClick: doubleClickToFullscreen ? handleDoubleClick : undefined,\n        onPointerDown: clickToPlay ? handlePointerDown : undefined,\n        renderMuteButton,\n        renderVolumeSlider\n      }) : null\n    ]\n  });\n  if (noSuspense || IS_NODE && !doesReactVersionSupportSuspense) {\n    return /* @__PURE__ */ jsx12(\"div\", {\n      ref: container,\n      style: outerStyle,\n      className: className2,\n      children: content\n    });\n  }\n  return /* @__PURE__ */ jsx12(\"div\", {\n    ref: container,\n    style: outerStyle,\n    className: className2,\n    children: /* @__PURE__ */ jsx12(Suspense, {\n      fallback: loadingMarkup,\n      children: content\n    })\n  });\n};\nvar PlayerUI_default = forwardRef(PlayerUI);\n\n// src/SharedPlayerContext.tsx\nimport { useCallback as useCallback12, useMemo as useMemo13, useState as useState12 } from \"react\";\nimport { Internals as Internals13 } from \"remotion\";\n\n// src/volume-persistance.ts\nimport { Internals as Internals12 } from \"remotion\";\nvar DEFAULT_VOLUME_PERSISTANCE_KEY = \"remotion.volumePreference\";\nvar persistVolume = (volume, logLevel, volumePersistenceKey) => {\n  if (typeof window === \"undefined\") {\n    return;\n  }\n  try {\n    window.localStorage.setItem(volumePersistenceKey ?? DEFAULT_VOLUME_PERSISTANCE_KEY, String(volume));\n  } catch (e) {\n    Internals12.Log.error({ logLevel, tag: null }, \"Could not persist volume\", e);\n  }\n};\nvar getPreferredVolume = (volumePersistenceKey) => {\n  if (typeof window === \"undefined\") {\n    return 1;\n  }\n  try {\n    const val = window.localStorage.getItem(volumePersistenceKey ?? DEFAULT_VOLUME_PERSISTANCE_KEY);\n    return val ? Number(val) : 1;\n  } catch {\n    return 1;\n  }\n};\n\n// src/SharedPlayerContext.tsx\nimport { jsx as jsx13 } from \"react/jsx-runtime\";\nvar PLAYER_COMP_ID = \"player-comp\";\nvar SharedPlayerContexts = ({\n  children,\n  timelineContext,\n  fps,\n  compositionHeight,\n  compositionWidth,\n  durationInFrames,\n  component,\n  numberOfSharedAudioTags,\n  initiallyMuted,\n  logLevel,\n  audioLatencyHint,\n  volumePersistenceKey,\n  inputProps,\n  audioEnabled\n}) => {\n  const compositionManagerContext = useMemo13(() => {\n    const context = {\n      compositions: [\n        {\n          component,\n          durationInFrames,\n          height: compositionHeight,\n          width: compositionWidth,\n          fps,\n          id: PLAYER_COMP_ID,\n          nonce: 777,\n          folderName: null,\n          parentFolderName: null,\n          schema: null,\n          calculateMetadata: null\n        }\n      ],\n      folders: [],\n      currentCompositionMetadata: {\n        defaultCodec: null,\n        defaultOutName: null,\n        defaultPixelFormat: null,\n        defaultProResProfile: null,\n        defaultVideoImageFormat: null,\n        durationInFrames,\n        fps,\n        height: compositionHeight,\n        width: compositionWidth,\n        props: inputProps\n      },\n      canvasContent: { type: \"composition\", compositionId: \"player-comp\" }\n    };\n    return context;\n  }, [\n    component,\n    durationInFrames,\n    compositionHeight,\n    compositionWidth,\n    fps,\n    inputProps\n  ]);\n  const [mediaMuted, setMediaMuted] = useState12(() => initiallyMuted);\n  const [mediaVolume, setMediaVolume] = useState12(() => getPreferredVolume(volumePersistenceKey ?? null));\n  const mediaVolumeContextValue = useMemo13(() => {\n    return {\n      mediaMuted,\n      mediaVolume\n    };\n  }, [mediaMuted, mediaVolume]);\n  const setMediaVolumeAndPersist = useCallback12((vol) => {\n    setMediaVolume(vol);\n    persistVolume(vol, logLevel, volumePersistenceKey ?? null);\n  }, [logLevel, volumePersistenceKey]);\n  const setMediaVolumeContextValue = useMemo13(() => {\n    return {\n      setMediaMuted,\n      setMediaVolume: setMediaVolumeAndPersist\n    };\n  }, [setMediaVolumeAndPersist]);\n  const logLevelContext = useMemo13(() => {\n    return {\n      logLevel,\n      mountTime: Date.now()\n    };\n  }, [logLevel]);\n  const env = useMemo13(() => {\n    return {\n      isPlayer: true,\n      isRendering: false,\n      isStudio: false,\n      isClientSideRendering: false,\n      isReadOnlyStudio: false\n    };\n  }, []);\n  return /* @__PURE__ */ jsx13(Internals13.RemotionEnvironmentContext.Provider, {\n    value: env,\n    children: /* @__PURE__ */ jsx13(Internals13.LogLevelContext.Provider, {\n      value: logLevelContext,\n      children: /* @__PURE__ */ jsx13(Internals13.CanUseRemotionHooksProvider, {\n        children: /* @__PURE__ */ jsx13(Internals13.TimelineContext.Provider, {\n          value: timelineContext,\n          children: /* @__PURE__ */ jsx13(Internals13.CompositionManager.Provider, {\n            value: compositionManagerContext,\n            children: /* @__PURE__ */ jsx13(Internals13.PrefetchProvider, {\n              children: /* @__PURE__ */ jsx13(Internals13.DurationsContextProvider, {\n                children: /* @__PURE__ */ jsx13(Internals13.MediaVolumeContext.Provider, {\n                  value: mediaVolumeContextValue,\n                  children: /* @__PURE__ */ jsx13(Internals13.SetMediaVolumeContext.Provider, {\n                    value: setMediaVolumeContextValue,\n                    children: /* @__PURE__ */ jsx13(Internals13.SharedAudioContextProvider, {\n                      numberOfAudioTags: numberOfSharedAudioTags,\n                      audioLatencyHint,\n                      audioEnabled,\n                      children: /* @__PURE__ */ jsx13(Internals13.BufferingProvider, {\n                        children\n                      })\n                    })\n                  })\n                })\n              })\n            })\n          })\n        })\n      })\n    })\n  });\n};\n\n// src/use-remotion-license-acknowledge.ts\nimport { Internals as Internals14 } from \"remotion\";\nvar warningShown = false;\nvar acknowledgeRemotionLicenseMessage = (acknowledge, logLevel) => {\n  if (acknowledge) {\n    return;\n  }\n  if (warningShown) {\n    return;\n  }\n  warningShown = true;\n  Internals14.Log.warn({ logLevel, tag: null }, \"Note: Some companies are required to obtain a license to use Remotion. See: https://remotion.dev/license\\nPass the `acknowledgeRemotionLicense` prop to `<Player />` function to make this message disappear.\");\n};\n\n// src/utils/validate-in-out-frame.ts\nvar validateSingleFrame = (frame, variableName) => {\n  if (typeof frame === \"undefined\" || frame === null) {\n    return frame ?? null;\n  }\n  if (typeof frame !== \"number\") {\n    throw new TypeError(`\"${variableName}\" must be a number, but is ${JSON.stringify(frame)}`);\n  }\n  if (Number.isNaN(frame)) {\n    throw new TypeError(`\"${variableName}\" must not be NaN, but is ${JSON.stringify(frame)}`);\n  }\n  if (!Number.isFinite(frame)) {\n    throw new TypeError(`\"${variableName}\" must be finite, but is ${JSON.stringify(frame)}`);\n  }\n  if (frame % 1 !== 0) {\n    throw new TypeError(`\"${variableName}\" must be an integer, but is ${JSON.stringify(frame)}`);\n  }\n  return frame;\n};\nvar validateInOutFrames = ({\n  inFrame,\n  durationInFrames,\n  outFrame\n}) => {\n  const validatedInFrame = validateSingleFrame(inFrame, \"inFrame\");\n  const validatedOutFrame = validateSingleFrame(outFrame, \"outFrame\");\n  if (validatedInFrame === null && validatedOutFrame === null) {\n    return;\n  }\n  if (validatedInFrame !== null && validatedInFrame > durationInFrames - 1) {\n    throw new Error(\"inFrame must be less than (durationInFrames - 1), but is \" + validatedInFrame);\n  }\n  if (validatedOutFrame !== null && validatedOutFrame > durationInFrames - 1) {\n    throw new Error(\"outFrame must be less than (durationInFrames - 1), but is \" + validatedOutFrame);\n  }\n  if (validatedInFrame !== null && validatedInFrame < 0) {\n    throw new Error(\"inFrame must be greater than 0, but is \" + validatedInFrame);\n  }\n  if (validatedOutFrame !== null && validatedOutFrame <= 0) {\n    throw new Error(`outFrame must be greater than 0, but is ${validatedOutFrame}. If you want to render a single frame, use <Thumbnail /> instead.`);\n  }\n  if (validatedOutFrame !== null && validatedInFrame !== null && validatedOutFrame <= validatedInFrame) {\n    throw new Error(\"outFrame must be greater than inFrame, but is \" + validatedOutFrame + \" <= \" + validatedInFrame);\n  }\n};\n\n// src/utils/validate-initial-frame.ts\nvar validateInitialFrame = ({\n  initialFrame,\n  durationInFrames\n}) => {\n  if (typeof durationInFrames !== \"number\") {\n    throw new Error(`\\`durationInFrames\\` must be a number, but is ${JSON.stringify(durationInFrames)}`);\n  }\n  if (typeof initialFrame === \"undefined\") {\n    return;\n  }\n  if (typeof initialFrame !== \"number\") {\n    throw new Error(`\\`initialFrame\\` must be a number, but is ${JSON.stringify(initialFrame)}`);\n  }\n  if (Number.isNaN(initialFrame)) {\n    throw new Error(`\\`initialFrame\\` must be a number, but is NaN`);\n  }\n  if (!Number.isFinite(initialFrame)) {\n    throw new Error(`\\`initialFrame\\` must be a number, but is Infinity`);\n  }\n  if (initialFrame % 1 !== 0) {\n    throw new Error(`\\`initialFrame\\` must be an integer, but is ${JSON.stringify(initialFrame)}`);\n  }\n  if (initialFrame > durationInFrames - 1) {\n    throw new Error(`\\`initialFrame\\` must be less or equal than \\`durationInFrames - 1\\`, but is ${JSON.stringify(initialFrame)}`);\n  }\n};\n\n// src/utils/validate-playbackrate.ts\nvar validatePlaybackRate = (playbackRate) => {\n  if (playbackRate === undefined) {\n    return;\n  }\n  if (playbackRate > 4) {\n    throw new Error(`The highest possible playback rate is 4. You passed: ${playbackRate}`);\n  }\n  if (playbackRate < -4) {\n    throw new Error(`The lowest possible playback rate is -4. You passed: ${playbackRate}`);\n  }\n  if (playbackRate === 0) {\n    throw new Error(`A playback rate of 0 is not supported.`);\n  }\n};\n\n// src/validate.ts\nimport { NoReactInternals } from \"remotion/no-react\";\nvar validateFps = NoReactInternals.validateFps;\nvar validateDimension = NoReactInternals.validateDimension;\nvar validateDurationInFrames = NoReactInternals.validateDurationInFrames;\nvar validateDefaultAndInputProps = NoReactInternals.validateDefaultAndInputProps;\n\n// src/Player.tsx\nimport { jsx as jsx14 } from \"react/jsx-runtime\";\nvar componentOrNullIfLazy = (props) => {\n  if (\"component\" in props) {\n    return props.component;\n  }\n  return null;\n};\nvar PlayerFn = ({\n  durationInFrames,\n  compositionHeight,\n  compositionWidth,\n  fps,\n  inputProps,\n  style: style2,\n  controls = false,\n  loop = false,\n  autoPlay = false,\n  showVolumeControls = true,\n  allowFullscreen = true,\n  clickToPlay,\n  doubleClickToFullscreen = false,\n  spaceKeyToPlayOrPause = true,\n  moveToBeginningWhenEnded = true,\n  numberOfSharedAudioTags = 5,\n  errorFallback = () => \"\",\n  playbackRate = 1,\n  renderLoading,\n  className: className2,\n  showPosterWhenUnplayed,\n  showPosterWhenEnded,\n  showPosterWhenPaused,\n  showPosterWhenBuffering,\n  showPosterWhenBufferingAndPaused,\n  initialFrame,\n  renderPoster,\n  inFrame,\n  outFrame,\n  initiallyShowControls,\n  renderFullscreenButton,\n  renderPlayPauseButton,\n  renderVolumeSlider,\n  alwaysShowControls = false,\n  initiallyMuted = false,\n  showPlaybackRateControl = false,\n  posterFillMode = \"player-size\",\n  bufferStateDelayInMilliseconds,\n  hideControlsWhenPointerDoesntMove = true,\n  overflowVisible = false,\n  renderMuteButton,\n  browserMediaControlsBehavior: passedBrowserMediaControlsBehavior,\n  overrideInternalClassName,\n  logLevel = \"info\",\n  noSuspense,\n  acknowledgeRemotionLicense,\n  audioLatencyHint = \"interactive\",\n  volumePersistenceKey,\n  ...componentProps\n}, ref) => {\n  if (typeof window !== \"undefined\") {\n    window.remotion_isPlayer = true;\n  }\n  if (componentProps.defaultProps !== undefined) {\n    throw new Error(\"The <Player /> component does not accept `defaultProps`, but some were passed. Use `inputProps` instead.\");\n  }\n  const componentForValidation = componentOrNullIfLazy(componentProps);\n  if (componentForValidation?.type === Composition) {\n    throw new TypeError(`'component' should not be an instance of <Composition/>. Pass the React component directly, and set the duration, fps and dimensions as separate props. See https://www.remotion.dev/docs/player/examples for an example.`);\n  }\n  if (componentForValidation === Composition) {\n    throw new TypeError(`'component' must not be the 'Composition' component. Pass your own React component directly, and set the duration, fps and dimensions as separate props. See https://www.remotion.dev/docs/player/examples for an example.`);\n  }\n  useState13(() => acknowledgeRemotionLicenseMessage(Boolean(acknowledgeRemotionLicense), logLevel));\n  const component = Internals15.useLazyComponent({\n    compProps: componentProps,\n    componentName: \"Player\",\n    noSuspense: Boolean(noSuspense)\n  });\n  validateInitialFrame({ initialFrame, durationInFrames });\n  const [frame, setFrame] = useState13(() => ({\n    [PLAYER_COMP_ID]: initialFrame ?? 0\n  }));\n  const [playing, setPlaying] = useState13(false);\n  const [rootId] = useState13(\"player-comp\");\n  const rootRef = useRef11(null);\n  const audioAndVideoTags = useRef11([]);\n  const imperativePlaying = useRef11(false);\n  const [currentPlaybackRate, setCurrentPlaybackRate] = useState13(playbackRate);\n  if (typeof compositionHeight !== \"number\") {\n    throw new TypeError(`'compositionHeight' must be a number but got '${typeof compositionHeight}' instead`);\n  }\n  if (typeof compositionWidth !== \"number\") {\n    throw new TypeError(`'compositionWidth' must be a number but got '${typeof compositionWidth}' instead`);\n  }\n  validateDimension(compositionHeight, \"compositionHeight\", \"of the <Player /> component\");\n  validateDimension(compositionWidth, \"compositionWidth\", \"of the <Player /> component\");\n  validateDurationInFrames(durationInFrames, {\n    component: \"of the <Player/> component\",\n    allowFloats: false\n  });\n  validateFps(fps, \"as a prop of the <Player/> component\", false);\n  validateDefaultAndInputProps(inputProps, \"inputProps\", null);\n  validateInOutFrames({\n    durationInFrames,\n    inFrame,\n    outFrame\n  });\n  if (typeof controls !== \"boolean\" && typeof controls !== \"undefined\") {\n    throw new TypeError(`'controls' must be a boolean or undefined but got '${typeof controls}' instead`);\n  }\n  if (typeof autoPlay !== \"boolean\" && typeof autoPlay !== \"undefined\") {\n    throw new TypeError(`'autoPlay' must be a boolean or undefined but got '${typeof autoPlay}' instead`);\n  }\n  if (typeof loop !== \"boolean\" && typeof loop !== \"undefined\") {\n    throw new TypeError(`'loop' must be a boolean or undefined but got '${typeof loop}' instead`);\n  }\n  if (typeof doubleClickToFullscreen !== \"boolean\" && typeof doubleClickToFullscreen !== \"undefined\") {\n    throw new TypeError(`'doubleClickToFullscreen' must be a boolean or undefined but got '${typeof doubleClickToFullscreen}' instead`);\n  }\n  if (typeof showVolumeControls !== \"boolean\" && typeof showVolumeControls !== \"undefined\") {\n    throw new TypeError(`'showVolumeControls' must be a boolean or undefined but got '${typeof showVolumeControls}' instead`);\n  }\n  if (typeof allowFullscreen !== \"boolean\" && typeof allowFullscreen !== \"undefined\") {\n    throw new TypeError(`'allowFullscreen' must be a boolean or undefined but got '${typeof allowFullscreen}' instead`);\n  }\n  if (typeof clickToPlay !== \"boolean\" && typeof clickToPlay !== \"undefined\") {\n    throw new TypeError(`'clickToPlay' must be a boolean or undefined but got '${typeof clickToPlay}' instead`);\n  }\n  if (typeof spaceKeyToPlayOrPause !== \"boolean\" && typeof spaceKeyToPlayOrPause !== \"undefined\") {\n    throw new TypeError(`'spaceKeyToPlayOrPause' must be a boolean or undefined but got '${typeof spaceKeyToPlayOrPause}' instead`);\n  }\n  if (typeof numberOfSharedAudioTags !== \"number\" || numberOfSharedAudioTags % 1 !== 0 || !Number.isFinite(numberOfSharedAudioTags) || Number.isNaN(numberOfSharedAudioTags) || numberOfSharedAudioTags < 0) {\n    throw new TypeError(`'numberOfSharedAudioTags' must be an integer but got '${numberOfSharedAudioTags}' instead`);\n  }\n  validatePlaybackRate(currentPlaybackRate);\n  useEffect13(() => {\n    setCurrentPlaybackRate(playbackRate);\n  }, [playbackRate]);\n  useImperativeHandle2(ref, () => rootRef.current, []);\n  useState13(() => {\n    Internals15.playbackLogging({\n      logLevel,\n      message: `[player] Mounting <Player>. User agent = ${typeof navigator === \"undefined\" ? \"server\" : navigator.userAgent}`,\n      tag: \"player\",\n      mountTime: Date.now()\n    });\n  });\n  const timelineContextValue = useMemo14(() => {\n    return {\n      frame,\n      playing,\n      rootId,\n      playbackRate: currentPlaybackRate,\n      imperativePlaying,\n      setPlaybackRate: (rate) => {\n        setCurrentPlaybackRate(rate);\n      },\n      audioAndVideoTags\n    };\n  }, [frame, currentPlaybackRate, playing, rootId]);\n  const setTimelineContextValue = useMemo14(() => {\n    return {\n      setFrame,\n      setPlaying\n    };\n  }, [setFrame]);\n  if (typeof window !== \"undefined\") {\n    useLayoutEffect2(() => {\n      Internals15.CSSUtils.injectCSS(Internals15.CSSUtils.makeDefaultPreviewCSS(`.${playerCssClassname(overrideInternalClassName)}`, \"#fff\"));\n    }, [overrideInternalClassName]);\n  }\n  const actualInputProps = useMemo14(() => inputProps ?? {}, [inputProps]);\n  const browserMediaControlsBehavior = useMemo14(() => {\n    return passedBrowserMediaControlsBehavior ?? {\n      mode: \"prevent-media-session\"\n    };\n  }, [passedBrowserMediaControlsBehavior]);\n  return /* @__PURE__ */ jsx14(Internals15.IsPlayerContextProvider, {\n    children: /* @__PURE__ */ jsx14(SharedPlayerContexts, {\n      timelineContext: timelineContextValue,\n      component,\n      compositionHeight,\n      compositionWidth,\n      durationInFrames,\n      fps,\n      numberOfSharedAudioTags,\n      initiallyMuted,\n      logLevel,\n      audioLatencyHint,\n      volumePersistenceKey,\n      inputProps: actualInputProps,\n      audioEnabled: true,\n      children: /* @__PURE__ */ jsx14(Internals15.SetTimelineContext.Provider, {\n        value: setTimelineContextValue,\n        children: /* @__PURE__ */ jsx14(PlayerEmitterProvider, {\n          currentPlaybackRate,\n          children: /* @__PURE__ */ jsx14(PlayerUI_default, {\n            ref: rootRef,\n            posterFillMode,\n            renderLoading,\n            autoPlay: Boolean(autoPlay),\n            loop: Boolean(loop),\n            controls: Boolean(controls),\n            errorFallback,\n            style: style2,\n            inputProps: actualInputProps,\n            allowFullscreen: Boolean(allowFullscreen),\n            moveToBeginningWhenEnded: Boolean(moveToBeginningWhenEnded),\n            clickToPlay: typeof clickToPlay === \"boolean\" ? clickToPlay : Boolean(controls),\n            showVolumeControls: Boolean(showVolumeControls),\n            doubleClickToFullscreen: Boolean(doubleClickToFullscreen),\n            spaceKeyToPlayOrPause: Boolean(spaceKeyToPlayOrPause),\n            playbackRate: currentPlaybackRate,\n            className: className2 ?? undefined,\n            showPosterWhenUnplayed: Boolean(showPosterWhenUnplayed),\n            showPosterWhenEnded: Boolean(showPosterWhenEnded),\n            showPosterWhenPaused: Boolean(showPosterWhenPaused),\n            showPosterWhenBuffering: Boolean(showPosterWhenBuffering),\n            showPosterWhenBufferingAndPaused: Boolean(showPosterWhenBufferingAndPaused),\n            renderPoster,\n            inFrame: inFrame ?? null,\n            outFrame: outFrame ?? null,\n            initiallyShowControls: initiallyShowControls ?? true,\n            renderFullscreen: renderFullscreenButton ?? null,\n            renderPlayPauseButton: renderPlayPauseButton ?? null,\n            renderMuteButton: renderMuteButton ?? null,\n            renderVolumeSlider: renderVolumeSlider ?? null,\n            alwaysShowControls,\n            showPlaybackRateControl,\n            bufferStateDelayInMilliseconds: bufferStateDelayInMilliseconds ?? 300,\n            hideControlsWhenPointerDoesntMove,\n            overflowVisible,\n            browserMediaControlsBehavior,\n            overrideInternalClassName: overrideInternalClassName ?? undefined,\n            noSuspense: Boolean(noSuspense)\n          })\n        })\n      })\n    })\n  });\n};\nvar forward = forwardRef2;\nvar Player = forward(PlayerFn);\n// src/Thumbnail.tsx\nimport {\n  forwardRef as forwardRef4,\n  useImperativeHandle as useImperativeHandle4,\n  useLayoutEffect as useLayoutEffect3,\n  useMemo as useMemo17,\n  useRef as useRef13,\n  useState as useState14\n} from \"react\";\nimport { Internals as Internals17, random as random2 } from \"remotion\";\n\n// src/ThumbnailUI.tsx\nimport React13, {\n  forwardRef as forwardRef3,\n  Suspense as Suspense2,\n  useCallback as useCallback13,\n  useImperativeHandle as useImperativeHandle3,\n  useMemo as useMemo16,\n  useRef as useRef12\n} from \"react\";\nimport { Internals as Internals16 } from \"remotion\";\n\n// src/use-thumbnail.ts\nimport { useContext as useContext7, useMemo as useMemo15 } from \"react\";\nvar useThumbnail = () => {\n  const emitter = useContext7(ThumbnailEmitterContext);\n  if (!emitter) {\n    throw new TypeError(\"Expected Player event emitter context\");\n  }\n  const returnValue = useMemo15(() => {\n    return {\n      emitter\n    };\n  }, [emitter]);\n  return returnValue;\n};\n\n// src/ThumbnailUI.tsx\nimport { jsx as jsx15 } from \"react/jsx-runtime\";\nvar reactVersion2 = React13.version.split(\".\")[0];\nif (reactVersion2 === \"0\") {\n  throw new Error(`Version ${reactVersion2} of \"react\" is not supported by Remotion`);\n}\nvar doesReactVersionSupportSuspense2 = parseInt(reactVersion2, 10) >= 18;\nvar ThumbnailUI = ({\n  style: style2,\n  inputProps,\n  errorFallback,\n  renderLoading,\n  className: className2,\n  overflowVisible,\n  noSuspense,\n  overrideInternalClassName\n}, ref) => {\n  const config = Internals16.useUnsafeVideoConfig();\n  const video = Internals16.useVideo();\n  const container = useRef12(null);\n  const canvasSize = useElementSize(container, {\n    triggerOnWindowResize: false,\n    shouldApplyCssTransforms: false\n  });\n  const layout = useMemo16(() => {\n    if (!config || !canvasSize) {\n      return null;\n    }\n    return calculateCanvasTransformation({\n      canvasSize,\n      compositionHeight: config.height,\n      compositionWidth: config.width,\n      previewSize: \"auto\"\n    });\n  }, [canvasSize, config]);\n  const scale = layout?.scale ?? 1;\n  const thumbnail = useThumbnail();\n  useBufferStateEmitter(thumbnail.emitter);\n  useImperativeHandle3(ref, () => {\n    const methods = {\n      getContainerNode: () => container.current,\n      getScale: () => scale\n    };\n    return Object.assign(thumbnail.emitter, methods);\n  }, [scale, thumbnail.emitter]);\n  const VideoComponent = video ? video.component : null;\n  const outerStyle = useMemo16(() => {\n    return calculateOuterStyle({\n      config,\n      style: style2,\n      canvasSize,\n      overflowVisible,\n      layout\n    });\n  }, [canvasSize, config, layout, overflowVisible, style2]);\n  const outer = useMemo16(() => {\n    return calculateOuter({ config, layout, scale, overflowVisible });\n  }, [config, layout, overflowVisible, scale]);\n  const containerStyle3 = useMemo16(() => {\n    return calculateContainerStyle({\n      config,\n      layout,\n      scale,\n      overflowVisible\n    });\n  }, [config, layout, overflowVisible, scale]);\n  const onError = useCallback13((error) => {\n    thumbnail.emitter.dispatchError(error);\n  }, [thumbnail.emitter]);\n  const loadingMarkup = useMemo16(() => {\n    return renderLoading ? renderLoading({\n      height: outerStyle.height,\n      width: outerStyle.width,\n      isBuffering: false\n    }) : null;\n  }, [outerStyle.height, outerStyle.width, renderLoading]);\n  const currentScaleContext = useMemo16(() => {\n    return {\n      type: \"scale\",\n      scale\n    };\n  }, [scale]);\n  if (!config) {\n    return null;\n  }\n  const content = /* @__PURE__ */ jsx15(\"div\", {\n    style: outer,\n    children: /* @__PURE__ */ jsx15(\"div\", {\n      style: containerStyle3,\n      className: playerCssClassname(overrideInternalClassName),\n      children: VideoComponent ? /* @__PURE__ */ jsx15(ErrorBoundary, {\n        onError,\n        errorFallback,\n        children: /* @__PURE__ */ jsx15(Internals16.CurrentScaleContext.Provider, {\n          value: currentScaleContext,\n          children: /* @__PURE__ */ jsx15(VideoComponent, {\n            ...video?.props ?? {},\n            ...inputProps ?? {}\n          })\n        })\n      }) : null\n    })\n  });\n  if (noSuspense || IS_NODE && !doesReactVersionSupportSuspense2) {\n    return /* @__PURE__ */ jsx15(\"div\", {\n      ref: container,\n      style: outerStyle,\n      className: className2,\n      children: content\n    });\n  }\n  return /* @__PURE__ */ jsx15(\"div\", {\n    ref: container,\n    style: outerStyle,\n    className: className2,\n    children: /* @__PURE__ */ jsx15(Suspense2, {\n      fallback: loadingMarkup,\n      children: content\n    })\n  });\n};\nvar ThumbnailUI_default = forwardRef3(ThumbnailUI);\n\n// src/Thumbnail.tsx\nimport { jsx as jsx16 } from \"react/jsx-runtime\";\nvar ThumbnailFn = ({\n  frameToDisplay,\n  style: style2,\n  inputProps,\n  compositionHeight,\n  compositionWidth,\n  durationInFrames,\n  fps,\n  className: className2,\n  errorFallback = () => \"\",\n  renderLoading,\n  overflowVisible = false,\n  overrideInternalClassName,\n  logLevel = \"info\",\n  noSuspense,\n  ...componentProps\n}, ref) => {\n  if (typeof window !== \"undefined\") {\n    useLayoutEffect3(() => {\n      window.remotion_isPlayer = true;\n    }, []);\n  }\n  const [thumbnailId] = useState14(() => String(random2(null)));\n  const rootRef = useRef13(null);\n  const timelineState = useMemo17(() => {\n    const value = {\n      playing: false,\n      frame: {\n        [PLAYER_COMP_ID]: frameToDisplay\n      },\n      rootId: thumbnailId,\n      imperativePlaying: {\n        current: false\n      },\n      playbackRate: 1,\n      setPlaybackRate: () => {\n        throw new Error(\"thumbnail\");\n      },\n      audioAndVideoTags: { current: [] }\n    };\n    return value;\n  }, [frameToDisplay, thumbnailId]);\n  useImperativeHandle4(ref, () => rootRef.current, []);\n  const Component = Internals17.useLazyComponent({\n    compProps: componentProps,\n    componentName: \"Thumbnail\",\n    noSuspense: Boolean(noSuspense)\n  });\n  const [emitter] = useState14(() => new ThumbnailEmitter);\n  const passedInputProps = useMemo17(() => {\n    return inputProps ?? {};\n  }, [inputProps]);\n  return /* @__PURE__ */ jsx16(Internals17.IsPlayerContextProvider, {\n    children: /* @__PURE__ */ jsx16(SharedPlayerContexts, {\n      timelineContext: timelineState,\n      component: Component,\n      compositionHeight,\n      compositionWidth,\n      durationInFrames,\n      fps,\n      numberOfSharedAudioTags: 0,\n      initiallyMuted: true,\n      logLevel,\n      audioLatencyHint: \"playback\",\n      inputProps: passedInputProps,\n      audioEnabled: false,\n      children: /* @__PURE__ */ jsx16(ThumbnailEmitterContext.Provider, {\n        value: emitter,\n        children: /* @__PURE__ */ jsx16(ThumbnailUI_default, {\n          ref: rootRef,\n          className: className2,\n          errorFallback,\n          inputProps: passedInputProps,\n          renderLoading,\n          style: style2,\n          overflowVisible,\n          overrideInternalClassName,\n          noSuspense: Boolean(noSuspense)\n        })\n      })\n    })\n  });\n};\nvar forward2 = forwardRef4;\nvar Thumbnail = forward2(ThumbnailFn);\n\n// src/index.ts\nvar PlayerInternals = {\n  PlayerEventEmitterContext,\n  PlayerEmitter,\n  usePlayer,\n  usePlayback,\n  useElementSize,\n  calculateCanvasTransformation,\n  useHoverState,\n  updateAllElementsSizes,\n  PlayerEmitterProvider,\n  BufferingIndicator,\n  useFrameImperative\n};\nexport {\n  Thumbnail,\n  PlayerInternals,\n  Player\n};\n","// src/client.ts\nimport { NoReactInternals as NoReactInternals2 } from \"remotion/no-react\";\n\n// src/browser/TimeoutSettings.ts\nvar DEFAULT_TIMEOUT = 30000;\n\nclass TimeoutSettings {\n  #defaultTimeout;\n  #defaultNavigationTimeout;\n  constructor() {\n    this.#defaultTimeout = null;\n    this.#defaultNavigationTimeout = null;\n  }\n  setDefaultTimeout(timeout) {\n    this.#defaultTimeout = timeout;\n  }\n  setDefaultNavigationTimeout(timeout) {\n    this.#defaultNavigationTimeout = timeout;\n  }\n  navigationTimeout() {\n    if (this.#defaultNavigationTimeout !== null) {\n      return this.#defaultNavigationTimeout;\n    }\n    if (this.#defaultTimeout !== null) {\n      return this.#defaultTimeout;\n    }\n    return DEFAULT_TIMEOUT;\n  }\n  timeout() {\n    if (this.#defaultTimeout !== null) {\n      return this.#defaultTimeout;\n    }\n    return DEFAULT_TIMEOUT;\n  }\n}\n\n// src/codec.ts\nvar validCodecs = [\n  \"h264\",\n  \"h265\",\n  \"vp8\",\n  \"vp9\",\n  \"mp3\",\n  \"aac\",\n  \"wav\",\n  \"prores\",\n  \"h264-mkv\",\n  \"h264-ts\",\n  \"gif\"\n];\nvar DEFAULT_CODEC = \"h264\";\n\n// src/crf.ts\nvar defaultCrfMap = {\n  h264: 18,\n  h265: 23,\n  vp8: 9,\n  vp9: 28,\n  prores: null,\n  gif: null,\n  \"h264-mkv\": 18,\n  \"h264-ts\": 18,\n  aac: null,\n  mp3: null,\n  wav: null\n};\nvar getDefaultCrfForCodec = (codec) => {\n  const val = defaultCrfMap[codec];\n  if (val === undefined) {\n    throw new TypeError(`Got unexpected codec \"${codec}\"`);\n  }\n  return val;\n};\nvar crfRanges = {\n  h264: [1, 51],\n  h265: [0, 51],\n  vp8: [4, 63],\n  vp9: [0, 63],\n  prores: [0, 0],\n  gif: [0, 0],\n  \"h264-mkv\": [1, 51],\n  \"h264-ts\": [1, 51],\n  aac: [0, 0],\n  mp3: [0, 0],\n  wav: [0, 0]\n};\nvar getValidCrfRanges = (codec) => {\n  const val = crfRanges[codec];\n  if (val === undefined) {\n    throw new TypeError(`Got unexpected codec \"${codec}\"`);\n  }\n  return val;\n};\n\n// src/codec-supports-media.ts\nvar codecSupportsVideoBitrateMap = {\n  \"h264-mkv\": true,\n  \"h264-ts\": true,\n  aac: false,\n  gif: false,\n  h264: true,\n  h265: true,\n  mp3: false,\n  prores: false,\n  vp8: true,\n  vp9: true,\n  wav: false\n};\nvar codecSupportsCrf = (codec) => {\n  const range = getValidCrfRanges(codec);\n  return range[0] !== range[1];\n};\nvar codecSupportsVideoBitrate = (codec) => {\n  return codecSupportsVideoBitrateMap[codec];\n};\n\n// src/file-extensions.ts\nvar defaultFileExtensionMap = {\n  \"h264-mkv\": {\n    default: \"mkv\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"mkv\"], default: \"mkv\" },\n      mp3: { possible: [\"mkv\"], default: \"mkv\" }\n    }\n  },\n  \"h264-ts\": {\n    default: \"ts\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"ts\"], default: \"ts\" },\n      aac: { possible: [\"ts\"], default: \"ts\" }\n    }\n  },\n  aac: {\n    default: \"aac\",\n    forAudioCodec: {\n      aac: {\n        possible: [\"aac\", \"3gp\", \"m4a\", \"m4b\", \"mpg\", \"mpeg\"],\n        default: \"aac\"\n      },\n      \"pcm-16\": {\n        possible: [\"wav\"],\n        default: \"wav\"\n      }\n    }\n  },\n  gif: {\n    default: \"gif\",\n    forAudioCodec: {}\n  },\n  h264: {\n    default: \"mp4\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"mkv\", \"mov\"], default: \"mkv\" },\n      aac: { possible: [\"mp4\", \"mkv\", \"mov\"], default: \"mp4\" },\n      mp3: { possible: [\"mp4\", \"mkv\", \"mov\"], default: \"mp4\" }\n    }\n  },\n  h265: {\n    default: \"mp4\",\n    forAudioCodec: {\n      aac: { possible: [\"mp4\", \"mkv\", \"hevc\"], default: \"mp4\" },\n      \"pcm-16\": { possible: [\"mkv\"], default: \"mkv\" }\n    }\n  },\n  mp3: {\n    default: \"mp3\",\n    forAudioCodec: {\n      mp3: { possible: [\"mp3\"], default: \"mp3\" },\n      \"pcm-16\": { possible: [\"wav\"], default: \"wav\" }\n    }\n  },\n  prores: {\n    default: \"mov\",\n    forAudioCodec: {\n      aac: { possible: [\"mov\", \"mkv\", \"mxf\"], default: \"mov\" },\n      \"pcm-16\": { possible: [\"mov\", \"mkv\", \"mxf\"], default: \"mov\" }\n    }\n  },\n  vp8: {\n    default: \"webm\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"mkv\"], default: \"mkv\" },\n      opus: { possible: [\"webm\"], default: \"webm\" }\n    }\n  },\n  vp9: {\n    default: \"webm\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"mkv\"], default: \"mkv\" },\n      opus: { possible: [\"webm\"], default: \"webm\" }\n    }\n  },\n  wav: {\n    default: \"wav\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"wav\"], default: \"wav\" }\n    }\n  }\n};\n\n// src/get-extension-from-codec.ts\nvar getFileExtensionFromCodec = (codec, audioCodec) => {\n  if (!validCodecs.includes(codec)) {\n    throw new Error(`Codec must be one of the following: ${validCodecs.join(\", \")}, but got ${codec}`);\n  }\n  const map = defaultFileExtensionMap[codec];\n  if (audioCodec === null) {\n    return map.default;\n  }\n  const typedAudioCodec = audioCodec;\n  if (!(typedAudioCodec in map.forAudioCodec)) {\n    throw new Error(`Audio codec ${typedAudioCodec} is not supported for codec ${codec}`);\n  }\n  return map.forAudioCodec[audioCodec].default;\n};\nvar makeFileExtensionMap = () => {\n  const map = {};\n  Object.keys(defaultFileExtensionMap).forEach((_codec) => {\n    const codec = _codec;\n    const fileExtMap = defaultFileExtensionMap[codec];\n    const audioCodecs = Object.keys(fileExtMap.forAudioCodec);\n    const possibleExtensionsForAudioCodec = audioCodecs.map((audioCodec) => fileExtMap.forAudioCodec[audioCodec].possible);\n    const allPossibleExtensions = [\n      fileExtMap.default,\n      ...possibleExtensionsForAudioCodec.flat(1)\n    ];\n    for (const extension of allPossibleExtensions) {\n      if (!map[extension]) {\n        map[extension] = [];\n      }\n      if (!map[extension].includes(codec)) {\n        map[extension].push(codec);\n      }\n    }\n  });\n  return map;\n};\nvar defaultCodecsForFileExtension = {\n  \"3gp\": \"aac\",\n  aac: \"aac\",\n  gif: \"gif\",\n  hevc: \"h265\",\n  m4a: \"aac\",\n  m4b: \"aac\",\n  mkv: \"h264-mkv\",\n  mov: \"prores\",\n  mp3: \"mp3\",\n  mp4: \"h264\",\n  mpeg: \"aac\",\n  mpg: \"aac\",\n  mxf: \"prores\",\n  wav: \"wav\",\n  webm: \"vp8\",\n  ts: \"h264-ts\"\n};\n\n// src/image-format.ts\nvar validVideoImageFormats = [\"png\", \"jpeg\", \"none\"];\nvar validStillImageFormats = [\"png\", \"jpeg\", \"pdf\", \"webp\"];\n\n// src/jpeg-quality.ts\nvar DEFAULT_JPEG_QUALITY = 80;\nvar validateJpegQuality = (q) => {\n  if (typeof q !== \"undefined\" && typeof q !== \"number\") {\n    throw new Error(`JPEG Quality option must be a number or undefined. Got ${typeof q} (${JSON.stringify(q)})`);\n  }\n  if (typeof q === \"undefined\") {\n    return;\n  }\n  if (!Number.isFinite(q)) {\n    throw new RangeError(`JPEG Quality must be a finite number, but is ${q}`);\n  }\n  if (Number.isNaN(q)) {\n    throw new RangeError(`JPEG Quality is NaN, but must be a real number`);\n  }\n  if (q > 100 || q < 0) {\n    throw new RangeError(\"JPEG Quality option must be between 0 and 100.\");\n  }\n};\n\n// src/log-level.ts\nvar logLevels = [\"trace\", \"verbose\", \"info\", \"warn\", \"error\"];\nvar getNumberForLogLevel = (level) => {\n  return logLevels.indexOf(level);\n};\nvar isValidLogLevel = (level) => {\n  return getNumberForLogLevel(level) > -1;\n};\n\n// src/options/api-key.tsx\nimport { jsx, jsxs, Fragment } from \"react/jsx-runtime\";\nvar currentApiKey = null;\nvar cliFlag = \"api-key\";\nvar apiKeyOption = {\n  name: \"API key\",\n  cliFlag,\n  description: () => /* @__PURE__ */ jsxs(Fragment, {\n    children: [\n      \"API key for sending a usage event using \",\n      /* @__PURE__ */ jsx(\"code\", {\n        children: \"@remotion/licensing\"\n      }),\n      \".\"\n    ]\n  }),\n  ssrName: \"apiKey\",\n  docLink: \"https://www.remotion.dev/docs/licensing\",\n  type: null,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag]\n      };\n    }\n    return {\n      source: \"default\",\n      value: currentApiKey\n    };\n  },\n  setConfig: (value) => {\n    currentApiKey = value;\n  }\n};\n\n// src/options/ask-ai.tsx\nimport { jsx as jsx2, Fragment as Fragment2 } from \"react/jsx-runtime\";\nvar askAIEnabled = true;\nvar cliFlag2 = \"disable-ask-ai\";\nvar askAIOption = {\n  name: \"Disable or Enable the Ask AI option\",\n  cliFlag: cliFlag2,\n  description: () => /* @__PURE__ */ jsx2(Fragment2, {\n    children: \"If the Cmd + I shortcut of the Ask AI modal conflicts with your Studio, you can disable it using this.\"\n  }),\n  ssrName: null,\n  docLink: \"https://www.remotion.dev/docs/config#setaskaienabled\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag2] !== undefined) {\n      askAIEnabled = false;\n      return {\n        value: askAIEnabled,\n        source: \"cli\"\n      };\n    }\n    return {\n      value: askAIEnabled,\n      source: \"config\"\n    };\n  },\n  setConfig(value) {\n    askAIEnabled = value;\n  }\n};\n\n// src/options/audio-bitrate.tsx\nimport { jsx as jsx3, jsxs as jsxs2, Fragment as Fragment3 } from \"react/jsx-runtime\";\nvar cliFlag3 = \"audio-bitrate\";\nvar audioBitrate = null;\nvar audioBitrateOption = {\n  name: \"Audio Bitrate\",\n  cliFlag: cliFlag3,\n  description: () => /* @__PURE__ */ jsxs2(Fragment3, {\n    children: [\n      \"Specify the target bitrate for the generated video. The syntax for FFmpeg\",\n      \"'\",\n      \"s \",\n      /* @__PURE__ */ jsx3(\"code\", {\n        children: \"-b:a\"\n      }),\n      \" parameter should be used. FFmpeg may encode the video in a way that will not result in the exact audio bitrate specified. Example values: \",\n      /* @__PURE__ */ jsx3(\"code\", {\n        children: \"512K\"\n      }),\n      \" for 512 kbps, \",\n      /* @__PURE__ */ jsx3(\"code\", {\n        children: \"1M\"\n      }),\n      \" for 1 Mbps. Default: \",\n      /* @__PURE__ */ jsx3(\"code\", {\n        children: \"320k\"\n      })\n    ]\n  }),\n  ssrName: \"audioBitrate\",\n  docLink: \"https://www.remotion.dev/docs/renderer/render-media#audiobitrate-\",\n  type: \"0\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag3]) {\n      return {\n        value: commandLine[cliFlag3],\n        source: \"cli\"\n      };\n    }\n    if (audioBitrate) {\n      return {\n        value: audioBitrate,\n        source: \"config file\"\n      };\n    }\n    return {\n      value: null,\n      source: \"default\"\n    };\n  },\n  setConfig: (value) => {\n    audioBitrate = value;\n  }\n};\n\n// src/options/separate-audio.tsx\nvar DEFAULT = null;\nvar cliFlag4 = \"separate-audio-to\";\nvar separateAudioOption = {\n  cliFlag: cliFlag4,\n  description: () => `If set, the audio will not be included in the main output but rendered as a separate file at the location you pass. It is recommended to use an absolute path. If a relative path is passed, it is relative to the Remotion Root.`,\n  docLink: \"https://remotion.dev/docs/renderer/render-media\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag4]) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag4]\n      };\n    }\n    return {\n      source: \"default\",\n      value: DEFAULT\n    };\n  },\n  name: \"Separate audio to\",\n  setConfig: () => {\n    throw new Error(\"Not implemented\");\n  },\n  ssrName: \"separateAudioTo\",\n  type: \"string\"\n};\n\n// src/options/audio-codec.tsx\nvar validAudioCodecs = [\"pcm-16\", \"aac\", \"mp3\", \"opus\"];\nvar supportedAudioCodecs = {\n  h264: [\"aac\", \"pcm-16\", \"mp3\"],\n  \"h264-mkv\": [\"pcm-16\", \"mp3\"],\n  \"h264-ts\": [\"pcm-16\", \"aac\"],\n  aac: [\"aac\", \"pcm-16\"],\n  avi: [],\n  gif: [],\n  h265: [\"aac\", \"pcm-16\"],\n  mp3: [\"mp3\", \"pcm-16\"],\n  prores: [\"aac\", \"pcm-16\"],\n  vp8: [\"opus\", \"pcm-16\"],\n  vp9: [\"opus\", \"pcm-16\"],\n  wav: [\"pcm-16\"]\n};\nvar _satisfies = supportedAudioCodecs;\nif (_satisfies) {}\nvar cliFlag5 = \"audio-codec\";\nvar ssrName = \"audioCodec\";\nvar defaultAudioCodecs = {\n  \"h264-mkv\": {\n    lossless: \"pcm-16\",\n    compressed: \"pcm-16\"\n  },\n  \"h264-ts\": {\n    lossless: \"pcm-16\",\n    compressed: \"aac\"\n  },\n  aac: {\n    lossless: \"pcm-16\",\n    compressed: \"aac\"\n  },\n  gif: {\n    lossless: null,\n    compressed: null\n  },\n  h264: {\n    lossless: \"pcm-16\",\n    compressed: \"aac\"\n  },\n  h265: {\n    lossless: \"pcm-16\",\n    compressed: \"aac\"\n  },\n  mp3: {\n    lossless: \"pcm-16\",\n    compressed: \"mp3\"\n  },\n  prores: {\n    lossless: \"pcm-16\",\n    compressed: \"pcm-16\"\n  },\n  vp8: {\n    lossless: \"pcm-16\",\n    compressed: \"opus\"\n  },\n  vp9: {\n    lossless: \"pcm-16\",\n    compressed: \"opus\"\n  },\n  wav: {\n    lossless: \"pcm-16\",\n    compressed: \"pcm-16\"\n  }\n};\nvar extensionMap = {\n  aac: \"aac\",\n  mp3: \"mp3\",\n  opus: \"opus\",\n  \"pcm-16\": \"wav\"\n};\nvar getExtensionFromAudioCodec = (audioCodec) => {\n  if (extensionMap[audioCodec]) {\n    return extensionMap[audioCodec];\n  }\n  throw new Error(`Unsupported audio codec: ${audioCodec}`);\n};\nvar resolveAudioCodec = ({\n  codec,\n  setting,\n  preferLossless,\n  separateAudioTo\n}) => {\n  let derivedFromSeparateAudioToExtension = null;\n  if (separateAudioTo) {\n    const extension = separateAudioTo.split(\".\").pop();\n    for (const [key, value] of Object.entries(extensionMap)) {\n      if (value === extension) {\n        derivedFromSeparateAudioToExtension = key;\n        if (!supportedAudioCodecs[codec].includes(derivedFromSeparateAudioToExtension) && derivedFromSeparateAudioToExtension) {\n          throw new Error(`The codec is ${codec} but the audio codec derived from --${separateAudioOption.cliFlag} is ${derivedFromSeparateAudioToExtension}. The only supported codecs are: ${supportedAudioCodecs[codec].join(\", \")}`);\n        }\n      }\n    }\n  }\n  if (preferLossless) {\n    const selected = getDefaultAudioCodec({ codec, preferLossless });\n    if (derivedFromSeparateAudioToExtension && selected !== derivedFromSeparateAudioToExtension) {\n      throw new Error(`The audio codec derived from --${separateAudioOption.cliFlag} is ${derivedFromSeparateAudioToExtension}, but does not match the audio codec derived from the \"Prefer lossless\" option (${selected}). Remove any conflicting options.`);\n    }\n    return selected;\n  }\n  if (setting === null) {\n    if (derivedFromSeparateAudioToExtension) {\n      return derivedFromSeparateAudioToExtension;\n    }\n    return getDefaultAudioCodec({ codec, preferLossless });\n  }\n  if (derivedFromSeparateAudioToExtension !== setting && derivedFromSeparateAudioToExtension) {\n    throw new Error(`The audio codec derived from --${separateAudioOption.cliFlag} is ${derivedFromSeparateAudioToExtension}, but does not match the audio codec derived from your ${audioCodecOption.name} setting (${setting}). Remove any conflicting options.`);\n  }\n  return setting;\n};\nvar getDefaultAudioCodec = ({\n  codec,\n  preferLossless\n}) => {\n  return defaultAudioCodecs[codec][preferLossless ? \"lossless\" : \"compressed\"];\n};\nvar _audioCodec = null;\nvar audioCodecOption = {\n  cliFlag: cliFlag5,\n  setConfig: (audioCodec) => {\n    if (audioCodec === null) {\n      _audioCodec = null;\n      return;\n    }\n    if (!validAudioCodecs.includes(audioCodec)) {\n      throw new Error(`Audio codec must be one of the following: ${validAudioCodecs.join(\", \")}, but got ${audioCodec}`);\n    }\n    _audioCodec = audioCodec;\n  },\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag5]) {\n      const codec = commandLine[cliFlag5];\n      if (!validAudioCodecs.includes(commandLine[cliFlag5])) {\n        throw new Error(`Audio codec must be one of the following: ${validAudioCodecs.join(\", \")}, but got ${codec}`);\n      }\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag5]\n      };\n    }\n    if (_audioCodec !== null) {\n      return {\n        source: \"config\",\n        value: _audioCodec\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  description: () => `Set the format of the audio that is embedded in the video. Not all codec and audio codec combinations are supported and certain combinations require a certain file extension and container format. See the table in the docs to see possible combinations.`,\n  docLink: \"https://www.remotion.dev/docs/encoding/#audio-codec\",\n  name: \"Audio Codec\",\n  ssrName,\n  type: \"aac\"\n};\n\n// src/options/beep-on-finish.tsx\nimport { jsx as jsx4, Fragment as Fragment4 } from \"react/jsx-runtime\";\nvar beepOnFinish = false;\nvar cliFlag6 = \"beep-on-finish\";\nvar beepOnFinishOption = {\n  name: \"Beep on finish\",\n  cliFlag: cliFlag6,\n  description: () => /* @__PURE__ */ jsx4(Fragment4, {\n    children: \"Whether the Remotion Studio tab should beep when the render is finished.\"\n  }),\n  ssrName: null,\n  docLink: \"https://www.remotion.dev/docs/config#setbeeponfinish\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag6] !== undefined) {\n      return {\n        value: commandLine[cliFlag6],\n        source: \"cli\"\n      };\n    }\n    if (beepOnFinish !== false) {\n      return {\n        value: beepOnFinish,\n        source: \"config\"\n      };\n    }\n    return {\n      value: false,\n      source: \"default\"\n    };\n  },\n  setConfig(value) {\n    beepOnFinish = value;\n  }\n};\n\n// src/options/binaries-directory.tsx\nimport { jsx as jsx5, jsxs as jsxs3, Fragment as Fragment5 } from \"react/jsx-runtime\";\nvar cliFlag7 = \"binaries-directory\";\nvar currentDirectory = null;\nvar binariesDirectoryOption = {\n  name: \"Binaries Directory\",\n  cliFlag: cliFlag7,\n  description: () => /* @__PURE__ */ jsxs3(Fragment5, {\n    children: [\n      \"The directory where the platform-specific binaries and libraries that Remotion needs are located. Those include an \",\n      /* @__PURE__ */ jsx5(\"code\", {\n        children: \"ffmpeg\"\n      }),\n      \" and\",\n      \" \",\n      /* @__PURE__ */ jsx5(\"code\", {\n        children: \"ffprobe\"\n      }),\n      \" binary, a Rust binary for various tasks, and various shared libraries. If the value is set to \",\n      /* @__PURE__ */ jsx5(\"code\", {\n        children: \"null\"\n      }),\n      \", which is the default, then the path of a platform-specific package located at\",\n      \" \",\n      /* @__PURE__ */ jsx5(\"code\", {\n        children: \"node_modules/@remotion/compositor-*\"\n      }),\n      \" is selected.\",\n      /* @__PURE__ */ jsx5(\"br\", {}),\n      \"This option is useful in environments where Remotion is not officially supported to run like bundled serverless functions or Electron.\"\n    ]\n  }),\n  ssrName: \"binariesDirectory\",\n  docLink: \"https://www.remotion.dev/docs/renderer\",\n  type: \"\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag7] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag7]\n      };\n    }\n    if (currentDirectory !== null) {\n      return {\n        source: \"config\",\n        value: currentDirectory\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  setConfig: (value) => {\n    currentDirectory = value;\n  }\n};\n\n// src/options/chrome-mode.tsx\nimport { jsx as jsx6, jsxs as jsxs4, Fragment as Fragment6 } from \"react/jsx-runtime\";\nvar validChromeModeOptions = [\n  \"headless-shell\",\n  \"chrome-for-testing\"\n];\nvar cliFlag8 = \"chrome-mode\";\nvar configSelection = null;\nvar chromeModeOption = {\n  cliFlag: cliFlag8,\n  name: \"Chrome Mode\",\n  ssrName: \"chromeMode\",\n  description: () => {\n    return /* @__PURE__ */ jsxs4(Fragment6, {\n      children: [\n        \"One of\",\n        \" \",\n        validChromeModeOptions.map((option, i) => /* @__PURE__ */ jsxs4(\"code\", {\n          children: [\n            option,\n            i === validChromeModeOptions.length - 1 ? \"\" : \", \"\n          ]\n        }, option)),\n        \". Default \",\n        /* @__PURE__ */ jsx6(\"code\", {\n          children: \"headless-shell\"\n        }),\n        \".\",\n        \" \",\n        /* @__PURE__ */ jsxs4(\"a\", {\n          href: \"https://remotion.dev/docs/miscellaneous/chrome-headless-shell\",\n          children: [\n            \"Use \",\n            /* @__PURE__ */ jsx6(\"code\", {\n              children: \"chrome-for-testing\"\n            }),\n            \" to take advantage of GPU drivers on Linux.\"\n          ]\n        })\n      ]\n    });\n  },\n  docLink: \"https://www.remotion.dev/chrome-for-testing\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag8]) {\n      if (!validChromeModeOptions.includes(commandLine[cliFlag8])) {\n        throw new Error(`Invalid \\`--${cliFlag8}\\` value passed. Accepted values: ${validChromeModeOptions.map((l) => `'${l}'`).join(\", \")}.`);\n      }\n      return {\n        value: commandLine[cliFlag8],\n        source: \"cli\"\n      };\n    }\n    if (configSelection !== null) {\n      return {\n        value: configSelection,\n        source: \"config\"\n      };\n    }\n    return {\n      value: \"headless-shell\",\n      source: \"default\"\n    };\n  },\n  setConfig: (newChromeMode) => {\n    configSelection = newChromeMode;\n  },\n  type: \"headless-shell\"\n};\n\n// src/options/color-space.tsx\nimport { NoReactInternals } from \"remotion/no-react\";\nimport { jsx as jsx7, jsxs as jsxs5, Fragment as Fragment7 } from \"react/jsx-runtime\";\nvar validV4ColorSpaces = [\"default\", \"bt709\", \"bt2020-ncl\"];\nvar validV5ColorSpaces = [\"bt601\", \"bt709\", \"bt2020-ncl\"];\nvar validColorSpaces = NoReactInternals.ENABLE_V5_BREAKING_CHANGES ? validV5ColorSpaces : validV4ColorSpaces;\nvar DEFAULT_COLOR_SPACE = NoReactInternals.ENABLE_V5_BREAKING_CHANGES ? \"bt709\" : \"default\";\nvar colorSpace = DEFAULT_COLOR_SPACE;\nvar cliFlag9 = \"color-space\";\nvar colorSpaceOption = {\n  name: \"Color space\",\n  cliFlag: \"color-space\",\n  description: () => /* @__PURE__ */ jsxs5(Fragment7, {\n    children: [\n      \"Color space to use for the video. Acceptable values:\",\n      \" \",\n      /* @__PURE__ */ jsxs5(\"code\", {\n        children: [\n          '\"',\n          DEFAULT_COLOR_SPACE,\n          '\"'\n        ]\n      }),\n      \"(default since 5.0),\",\n      \" \",\n      NoReactInternals.ENABLE_V5_BREAKING_CHANGES ? /* @__PURE__ */ jsxs5(\"code\", {\n        children: [\n          '\"',\n          \"bt601\",\n          '\"',\n          \", \"\n        ]\n      }) : /* @__PURE__ */ jsxs5(Fragment7, {\n        children: [\n          /* @__PURE__ */ jsxs5(\"code\", {\n            children: [\n              '\"',\n              \"bt709\",\n              '\"'\n            ]\n          }),\n          \" \",\n          \"(since v4.0.28),\",\n          \" \"\n        ]\n      }),\n      /* @__PURE__ */ jsxs5(\"code\", {\n        children: [\n          '\"',\n          \"bt2020-ncl\",\n          '\"'\n        ]\n      }),\n      \" \",\n      \"(since v4.0.88),\",\n      \" \",\n      /* @__PURE__ */ jsxs5(\"code\", {\n        children: [\n          '\"',\n          \"bt2020-cl\",\n          '\"'\n        ]\n      }),\n      \" \",\n      \"(since v4.0.88), .\",\n      /* @__PURE__ */ jsx7(\"br\", {}),\n      \"For best color accuracy, it is recommended to also use\",\n      \" \",\n      /* @__PURE__ */ jsxs5(\"code\", {\n        children: [\n          '\"',\n          \"png\",\n          '\"'\n        ]\n      }),\n      \" \",\n      \"as the image format to have accurate color transformations throughout.\",\n      /* @__PURE__ */ jsx7(\"br\", {}),\n      \"Only since v4.0.83, colorspace conversion is actually performed, previously it would only tag the metadata of the video.\"\n    ]\n  }),\n  docLink: \"https://www.remotion.dev/docs/renderer/render-media#colorspace\",\n  ssrName: \"colorSpace\",\n  type: DEFAULT_COLOR_SPACE,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag9] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag9]\n      };\n    }\n    if (colorSpace !== DEFAULT_COLOR_SPACE) {\n      return {\n        source: \"config\",\n        value: colorSpace\n      };\n    }\n    return {\n      source: \"default\",\n      value: DEFAULT_COLOR_SPACE\n    };\n  },\n  setConfig: (value) => {\n    colorSpace = value ?? DEFAULT_COLOR_SPACE;\n  }\n};\n\n// src/options/crf.tsx\nimport { jsx as jsx8, Fragment as Fragment8 } from \"react/jsx-runtime\";\nvar currentCrf;\nvar validateCrf = (newCrf) => {\n  if (typeof newCrf !== \"number\" && newCrf !== undefined) {\n    throw new TypeError(\"The CRF must be a number or undefined.\");\n  }\n};\nvar cliFlag10 = \"crf\";\nvar crfOption = {\n  name: \"CRF\",\n  cliFlag: cliFlag10,\n  description: () => /* @__PURE__ */ jsx8(Fragment8, {\n    children: \"No matter which codec you end up using, there's always a tradeoff between file size and video quality. You can control it by setting the CRF (Constant Rate Factor). The lower the number, the better the quality, the higher the number, the smaller the file is  of course at the cost of quality.\"\n  }),\n  ssrName: \"crf\",\n  docLink: \"https://www.remotion.dev/docs/encoding/#controlling-quality-using-the-crf-setting\",\n  type: 0,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag10] !== undefined) {\n      validateCrf(commandLine[cliFlag10]);\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag10]\n      };\n    }\n    if (currentCrf !== null) {\n      return {\n        source: \"config\",\n        value: currentCrf\n      };\n    }\n    return {\n      source: \"default\",\n      value: undefined\n    };\n  },\n  setConfig: (crf) => {\n    validateCrf(crf);\n    currentCrf = crf;\n  }\n};\n\n// src/options/cross-site-isolation.tsx\nimport { jsx as jsx9, jsxs as jsxs6, Fragment as Fragment9 } from \"react/jsx-runtime\";\nvar enableCrossSiteIsolation = false;\nvar cliFlag11 = \"cross-site-isolation\";\nvar enableCrossSiteIsolationOption = {\n  name: \"Enable Cross-Site Isolation\",\n  cliFlag: cliFlag11,\n  description: () => /* @__PURE__ */ jsxs6(Fragment9, {\n    children: [\n      \"Enable Cross-Site Isolation in the Studio (sets Cross-Origin-Opener-Policy and Cross-Origin-Embedder-Policy HTTP headers, required for\",\n      \" \",\n      /* @__PURE__ */ jsx9(\"code\", {\n        children: \"@remotion/whisper-web\"\n      }),\n      \").\"\n    ]\n  }),\n  ssrName: null,\n  docLink: \"https://www.remotion.dev/docs/config#setenablecrosssiteisolation\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag11] !== undefined) {\n      return {\n        value: commandLine[cliFlag11],\n        source: \"cli\"\n      };\n    }\n    return {\n      value: enableCrossSiteIsolation,\n      source: \"config\"\n    };\n  },\n  setConfig(value) {\n    enableCrossSiteIsolation = value;\n  }\n};\n\n// src/options/dark-mode.tsx\nimport { jsx as jsx10, jsxs as jsxs7, Fragment as Fragment10 } from \"react/jsx-runtime\";\nvar DEFAULT_VALUE = false;\nvar darkMode = DEFAULT_VALUE;\nvar cliFlag12 = \"dark-mode\";\nvar darkModeOption = {\n  name: \"Dark Mode\",\n  cliFlag: cliFlag12,\n  description: () => /* @__PURE__ */ jsxs7(Fragment10, {\n    children: [\n      \"Whether Chromium should pretend to be in dark mode by emulating the media feature 'prefers-color-scheme: dark'. Default is\",\n      \" \",\n      /* @__PURE__ */ jsx10(\"code\", {\n        children: String(DEFAULT_VALUE)\n      }),\n      \".\"\n    ]\n  }),\n  ssrName: \"darkMode\",\n  docLink: \"https://www.remotion.dev/docs/chromium-flags#--dark-mode\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag12] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag12]\n      };\n    }\n    if (darkMode !== DEFAULT_VALUE) {\n      return {\n        source: \"config\",\n        value: darkMode\n      };\n    }\n    return {\n      source: \"default\",\n      value: DEFAULT_VALUE\n    };\n  },\n  setConfig: (value) => {\n    darkMode = value;\n  }\n};\n\n// src/options/delete-after.tsx\nimport { jsx as jsx11, jsxs as jsxs8, Fragment as Fragment11 } from \"react/jsx-runtime\";\nvar cliFlag13 = \"delete-after\";\nvar deleteAfter = null;\nvar deleteAfterOption = {\n  name: \"Lambda render expiration\",\n  cliFlag: cliFlag13,\n  description: () => {\n    return /* @__PURE__ */ jsxs8(Fragment11, {\n      children: [\n        \"Automatically delete the render after a certain period. Accepted values are \",\n        /* @__PURE__ */ jsx11(\"code\", {\n          children: \"1-day\"\n        }),\n        \", \",\n        /* @__PURE__ */ jsx11(\"code\", {\n          children: \"3-days\"\n        }),\n        \", \",\n        /* @__PURE__ */ jsx11(\"code\", {\n          children: \"7-days\"\n        }),\n        \" and\",\n        \" \",\n        /* @__PURE__ */ jsx11(\"code\", {\n          children: \"30-days\"\n        }),\n        \".\",\n        /* @__PURE__ */ jsx11(\"br\", {}),\n        \" For this to work, your bucket needs to have\",\n        \" \",\n        /* @__PURE__ */ jsx11(\"a\", {\n          href: \"/docs/lambda/autodelete\",\n          children: \"lifecycles enabled\"\n        }),\n        \".\"\n      ]\n    });\n  },\n  ssrName: \"deleteAfter\",\n  docLink: \"https://www.remotion.dev/docs/lambda/autodelete\",\n  type: \"1-day\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag13] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag13]\n      };\n    }\n    if (deleteAfter !== null) {\n      return {\n        source: \"config\",\n        value: deleteAfter\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  setConfig: (value) => {\n    deleteAfter = value;\n  }\n};\n\n// src/options/disable-git-source.tsx\nvar DEFAULT2 = false;\nvar cliFlag14 = \"disable-git-source\";\nvar disableGitSourceOption = {\n  cliFlag: cliFlag14,\n  description: () => `Disables the Git Source being connected to the Remotion Studio. Clicking on stack traces and certain menu items will be disabled.`,\n  docLink: \"https://remotion.dev/docs/bundle\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag14]) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag14]\n      };\n    }\n    return {\n      source: \"default\",\n      value: DEFAULT2\n    };\n  },\n  name: \"Disable Git source\",\n  setConfig: () => {\n    throw new Error(\"Not implemented\");\n  },\n  ssrName: \"disableGitSource\",\n  type: false\n};\n\n// src/options/disallow-parallel-encoding.tsx\nimport { jsx as jsx12, Fragment as Fragment12 } from \"react/jsx-runtime\";\nvar disallowParallelEncoding = false;\nvar cliFlag15 = \"disallow-parallel-encoding\";\nvar disallowParallelEncodingOption = {\n  name: \"Disallow parallel encoding\",\n  cliFlag: cliFlag15,\n  description: () => /* @__PURE__ */ jsx12(Fragment12, {\n    children: \"Disallows the renderer from doing rendering frames and encoding at the same time. This makes the rendering process more memory-efficient, but possibly slower.\"\n  }),\n  ssrName: \"disallowParallelEncoding\",\n  docLink: \"https://www.remotion.dev/docs/config#setdisallowparallelencoding\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag15] !== undefined) {\n      return {\n        value: commandLine[cliFlag15],\n        source: \"cli\"\n      };\n    }\n    if (disallowParallelEncoding !== false) {\n      return {\n        value: disallowParallelEncoding,\n        source: \"config\"\n      };\n    }\n    return {\n      value: false,\n      source: \"default\"\n    };\n  },\n  setConfig(value) {\n    disallowParallelEncoding = value;\n  }\n};\n\n// src/options/enable-lambda-insights.tsx\nimport { jsx as jsx13, jsxs as jsxs9, Fragment as Fragment13 } from \"react/jsx-runtime\";\nvar cliFlag16 = \"enable-lambda-insights\";\nvar option = false;\nvar enableLambdaInsights = {\n  name: \"Enable Lambda Insights\",\n  cliFlag: cliFlag16,\n  description: () => /* @__PURE__ */ jsxs9(Fragment13, {\n    children: [\n      \"Enable\",\n      \" \",\n      /* @__PURE__ */ jsx13(\"a\", {\n        href: \"https://remotion.dev/docs/lambda/insights\",\n        children: \"Lambda Insights in AWS CloudWatch\"\n      }),\n      \". For this to work, you may have to update your role permission.\"\n    ]\n  }),\n  ssrName: \"enableLambdaInsights\",\n  docLink: \"https://www.remotion.dev/docs/lambda/insights\",\n  type: false,\n  setConfig: (value) => {\n    option = value;\n  },\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag16] !== undefined) {\n      return {\n        value: commandLine[cliFlag16],\n        source: \"cli\"\n      };\n    }\n    if (option) {\n      return {\n        value: option,\n        source: \"config\"\n      };\n    }\n    return {\n      value: false,\n      source: \"default\"\n    };\n  }\n};\n\n// src/options/enable-multiprocess-on-linux.tsx\nimport { jsx as jsx14, jsxs as jsxs10, Fragment as Fragment14 } from \"react/jsx-runtime\";\nvar DEFAULT_VALUE2 = true;\nvar multiProcessOnLinux = DEFAULT_VALUE2;\nvar cliFlag17 = \"enable-multiprocess-on-linux\";\nvar enableMultiprocessOnLinuxOption = {\n  name: \"Enable Multiprocess on Linux\",\n  cliFlag: cliFlag17,\n  description: () => /* @__PURE__ */ jsxs10(Fragment14, {\n    children: [\n      \"Removes the \",\n      /* @__PURE__ */ jsx14(\"code\", {\n        children: \"--single-process\"\n      }),\n      \" flag that gets passed to Chromium on Linux by default. This will make the render faster because multiple processes can be used, but may cause issues with some Linux distributions or if window server libraries are missing.\",\n      /* @__PURE__ */ jsx14(\"br\", {}),\n      \"Default: \",\n      /* @__PURE__ */ jsx14(\"code\", {\n        children: \"false\"\n      }),\n      \" until v4.0.136, then \",\n      /* @__PURE__ */ jsx14(\"code\", {\n        children: \"true\"\n      }),\n      \" from v4.0.137 on because newer Chrome versions \",\n      \"don't\",\n      \" allow rendering with the \",\n      /* @__PURE__ */ jsx14(\"code\", {\n        children: \"--single-process\"\n      }),\n      \" flag. \",\n      /* @__PURE__ */ jsx14(\"br\", {}),\n      \"This flag will be removed in Remotion v5.0.\"\n    ]\n  }),\n  ssrName: \"chromiumOptions.enableMultiprocessOnLinux\",\n  docLink: \"https://www.remotion.dev/docs/chromium-flags\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag17] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag17]\n      };\n    }\n    if (multiProcessOnLinux !== false) {\n      return {\n        source: \"config\",\n        value: multiProcessOnLinux\n      };\n    }\n    return {\n      source: \"default\",\n      value: DEFAULT_VALUE2\n    };\n  },\n  setConfig: (value) => {\n    multiProcessOnLinux = value;\n  }\n};\n\n// src/options/encoding-buffer-size.tsx\nimport { jsx as jsx15, jsxs as jsxs11, Fragment as Fragment15 } from \"react/jsx-runtime\";\nvar encodingBufferSize = null;\nvar setEncodingBufferSize = (bitrate) => {\n  encodingBufferSize = bitrate;\n};\nvar cliFlag18 = \"buffer-size\";\nvar encodingBufferSizeOption = {\n  name: \"FFmpeg -bufsize flag\",\n  cliFlag: cliFlag18,\n  description: () => /* @__PURE__ */ jsxs11(Fragment15, {\n    children: [\n      \"The value for the \",\n      /* @__PURE__ */ jsx15(\"code\", {\n        children: \"-bufsize\"\n      }),\n      \" flag of FFmpeg. Should be used in conjunction with the encoding max rate flag.\"\n    ]\n  }),\n  ssrName: \"encodingBufferSize\",\n  docLink: \"https://www.remotion.dev/docs/renderer/render-media#encodingbuffersize\",\n  type: \"\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag18] !== undefined) {\n      return {\n        value: commandLine[cliFlag18],\n        source: \"cli\"\n      };\n    }\n    if (encodingBufferSize !== null) {\n      return {\n        value: encodingBufferSize,\n        source: \"config\"\n      };\n    }\n    return {\n      value: null,\n      source: \"default\"\n    };\n  },\n  setConfig: setEncodingBufferSize\n};\n\n// src/options/encoding-max-rate.tsx\nimport { jsx as jsx16, jsxs as jsxs12, Fragment as Fragment16 } from \"react/jsx-runtime\";\nvar encodingMaxRate = null;\nvar cliFlag19 = \"max-rate\";\nvar encodingMaxRateOption = {\n  name: \"FFmpeg -maxrate flag\",\n  cliFlag: cliFlag19,\n  description: () => /* @__PURE__ */ jsxs12(Fragment16, {\n    children: [\n      \"The value for the \",\n      /* @__PURE__ */ jsx16(\"code\", {\n        children: \"-maxrate\"\n      }),\n      \" flag of FFmpeg. Should be used in conjunction with the encoding buffer size flag.\"\n    ]\n  }),\n  ssrName: \"encodingMaxRate\",\n  docLink: \"https://www.remotion.dev/docs/renderer/render-media#encodingmaxrate\",\n  type: \"\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag19] !== undefined) {\n      return {\n        value: commandLine[cliFlag19],\n        source: \"cli\"\n      };\n    }\n    if (encodingMaxRate !== null) {\n      return {\n        value: encodingMaxRate,\n        source: \"config\"\n      };\n    }\n    return {\n      value: null,\n      source: \"default\"\n    };\n  },\n  setConfig: (newMaxRate) => {\n    encodingMaxRate = newMaxRate;\n  }\n};\n\n// src/options/enforce-audio.tsx\nimport { jsx as jsx17, Fragment as Fragment17 } from \"react/jsx-runtime\";\nvar DEFAULT_ENFORCE_AUDIO_TRACK = false;\nvar enforceAudioTrackState = DEFAULT_ENFORCE_AUDIO_TRACK;\nvar cliFlag20 = \"enforce-audio-track\";\nvar enforceAudioOption = {\n  name: \"Enforce Audio Track\",\n  cliFlag: cliFlag20,\n  description: () => /* @__PURE__ */ jsx17(Fragment17, {\n    children: \"Render a silent audio track if there would be none otherwise.\"\n  }),\n  ssrName: \"enforceAudioTrack\",\n  docLink: \"https://www.remotion.dev/docs/config#setenforceaudiotrack-\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag20]) {\n      return {\n        source: \"cli\",\n        value: true\n      };\n    }\n    if (enforceAudioTrackState !== DEFAULT_ENFORCE_AUDIO_TRACK) {\n      return {\n        source: \"config\",\n        value: enforceAudioTrackState\n      };\n    }\n    return {\n      source: \"default\",\n      value: DEFAULT_ENFORCE_AUDIO_TRACK\n    };\n  },\n  setConfig: (value) => {\n    enforceAudioTrackState = value;\n  }\n};\n\n// src/options/experimental-client-side-rendering.tsx\nimport { jsx as jsx18, Fragment as Fragment18 } from \"react/jsx-runtime\";\nvar experimentalClientSideRenderingEnabled = false;\nvar cliFlag21 = \"enable-experimental-client-side-rendering\";\nvar experimentalClientSideRenderingOption = {\n  name: \"Enable Experimental Client-Side Rendering\",\n  cliFlag: cliFlag21,\n  description: () => /* @__PURE__ */ jsx18(Fragment18, {\n    children: \"Enable WIP client-side rendering in the Remotion Studio. See https://www.remotion.dev/docs/client-side-rendering/ for notes.\"\n  }),\n  ssrName: null,\n  docLink: \"https://www.remotion.dev/docs/client-side-rendering\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag21] !== undefined) {\n      experimentalClientSideRenderingEnabled = true;\n      return {\n        value: experimentalClientSideRenderingEnabled,\n        source: \"cli\"\n      };\n    }\n    return {\n      value: experimentalClientSideRenderingEnabled,\n      source: \"config\"\n    };\n  },\n  setConfig(value) {\n    experimentalClientSideRenderingEnabled = value;\n  }\n};\n\n// src/options/folder-expiry.tsx\nimport { jsx as jsx19, jsxs as jsxs13, Fragment as Fragment19 } from \"react/jsx-runtime\";\nvar enableFolderExpiry = null;\nvar cliFlag22 = \"enable-folder-expiry\";\nvar folderExpiryOption = {\n  name: \"Lambda render expiration\",\n  cliFlag: cliFlag22,\n  description: () => {\n    return /* @__PURE__ */ jsxs13(Fragment19, {\n      children: [\n        \"When deploying sites, enable or disable S3 Lifecycle policies which allow for renders to auto-delete after a certain time. Default is\",\n        \" \",\n        /* @__PURE__ */ jsx19(\"code\", {\n          children: \"null\"\n        }),\n        \", which does not change any lifecycle policies of the S3 bucket. See: \",\n        /* @__PURE__ */ jsx19(\"a\", {\n          href: \"/docs/lambda/autodelete\",\n          children: \"Lambda autodelete\"\n        }),\n        \".\"\n      ]\n    });\n  },\n  ssrName: \"enableFolderExpiry\",\n  docLink: \"https://www.remotion.dev/docs/lambda/autodelete\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag22] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag22]\n      };\n    }\n    if (enableFolderExpiry !== null) {\n      return {\n        source: \"config\",\n        value: enableFolderExpiry\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  setConfig: (value) => {\n    enableFolderExpiry = value;\n  }\n};\n\n// src/options/for-seamless-aac-concatenation.tsx\nimport { jsx as jsx20, jsxs as jsxs14, Fragment as Fragment20 } from \"react/jsx-runtime\";\nvar DEFAULT3 = false;\nvar forSeamlessAacConcatenation = DEFAULT3;\nvar cliFlag23 = \"for-seamless-aac-concatenation\";\nvar forSeamlessAacConcatenationOption = {\n  name: \"For seamless AAC concatenation\",\n  cliFlag: cliFlag23,\n  description: () => /* @__PURE__ */ jsxs14(Fragment20, {\n    children: [\n      \"If enabled, the audio is trimmed to the nearest AAC frame, which is required for seamless concatenation of AAC files. This is a requirement if you later want to combine multiple video snippets seamlessly.\",\n      /* @__PURE__ */ jsx20(\"br\", {}),\n      /* @__PURE__ */ jsx20(\"br\", {}),\n      \" This option is used internally. There is currently no documentation yet for to concatenate the audio chunks.\"\n    ]\n  }),\n  docLink: \"https://remotion.dev/docs/renderer\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag23]) {\n      return {\n        source: \"cli\",\n        value: true\n      };\n    }\n    if (forSeamlessAacConcatenation !== DEFAULT3) {\n      return {\n        source: \"config\",\n        value: forSeamlessAacConcatenation\n      };\n    }\n    return {\n      source: \"default\",\n      value: DEFAULT3\n    };\n  },\n  setConfig: (value) => {\n    forSeamlessAacConcatenation = value;\n  },\n  ssrName: \"forSeamlessAacConcatenation\",\n  type: false\n};\n\n// src/options/gl.tsx\nimport { jsx as jsx21, jsxs as jsxs15, Fragment as Fragment21 } from \"react/jsx-runtime\";\nvar validOpenGlRenderers = [\n  \"swangle\",\n  \"angle\",\n  \"egl\",\n  \"swiftshader\",\n  \"vulkan\",\n  \"angle-egl\"\n];\nvar DEFAULT_OPENGL_RENDERER = null;\nvar openGlRenderer = DEFAULT_OPENGL_RENDERER;\nvar AngleChangelog = () => {\n  return /* @__PURE__ */ jsxs15(\"details\", {\n    style: { fontSize: \"0.9em\", marginBottom: \"1em\" },\n    children: [\n      /* @__PURE__ */ jsx21(\"summary\", {\n        children: \"Changelog\"\n      }),\n      /* @__PURE__ */ jsxs15(\"ul\", {\n        children: [\n          /* @__PURE__ */ jsxs15(\"li\", {\n            children: [\n              \"From Remotion v2.6.7 until v3.0.7, the default for Remotion Lambda was\",\n              \" \",\n              /* @__PURE__ */ jsx21(\"code\", {\n                children: \"swiftshader\"\n              }),\n              \", but from v3.0.8 the default is\",\n              \" \",\n              /* @__PURE__ */ jsx21(\"code\", {\n                children: \"swangle\"\n              }),\n              \" (Swiftshader on Angle) since Chrome 101 added support for it.\"\n            ]\n          }),\n          /* @__PURE__ */ jsxs15(\"li\", {\n            children: [\n              \"From Remotion v2.4.3 until v2.6.6, the default was \",\n              /* @__PURE__ */ jsx21(\"code\", {\n                children: \"angle\"\n              }),\n              \", however it turns out to have a small memory leak that could crash long Remotion renders.\"\n            ]\n          })\n        ]\n      })\n    ]\n  });\n};\nvar cliFlag24 = \"gl\";\nvar glOption = {\n  cliFlag: cliFlag24,\n  docLink: \"https://www.remotion.dev/docs/chromium-flags#--gl\",\n  name: \"OpenGL renderer\",\n  type: \"angle\",\n  ssrName: \"gl\",\n  description: () => {\n    return /* @__PURE__ */ jsxs15(Fragment21, {\n      children: [\n        /* @__PURE__ */ jsx21(AngleChangelog, {}),\n        /* @__PURE__ */ jsxs15(\"p\", {\n          children: [\n            \"Select the OpenGL renderer backend for Chromium. \",\n            /* @__PURE__ */ jsx21(\"br\", {}),\n            \"Accepted values:\"\n          ]\n        }),\n        /* @__PURE__ */ jsxs15(\"ul\", {\n          children: [\n            /* @__PURE__ */ jsx21(\"li\", {\n              children: /* @__PURE__ */ jsx21(\"code\", {\n                children: '\"angle\"'\n              })\n            }),\n            /* @__PURE__ */ jsx21(\"li\", {\n              children: /* @__PURE__ */ jsx21(\"code\", {\n                children: '\"egl\"'\n              })\n            }),\n            /* @__PURE__ */ jsx21(\"li\", {\n              children: /* @__PURE__ */ jsx21(\"code\", {\n                children: '\"swiftshader\"'\n              })\n            }),\n            /* @__PURE__ */ jsx21(\"li\", {\n              children: /* @__PURE__ */ jsx21(\"code\", {\n                children: '\"swangle\"'\n              })\n            }),\n            /* @__PURE__ */ jsxs15(\"li\", {\n              children: [\n                /* @__PURE__ */ jsx21(\"code\", {\n                  children: '\"vulkan\"'\n                }),\n                \" (\",\n                /* @__PURE__ */ jsx21(\"em\", {\n                  children: \"from Remotion v4.0.41\"\n                }),\n                \")\"\n              ]\n            }),\n            /* @__PURE__ */ jsxs15(\"li\", {\n              children: [\n                /* @__PURE__ */ jsx21(\"code\", {\n                  children: '\"angle-egl\"'\n                }),\n                \" (\",\n                /* @__PURE__ */ jsx21(\"em\", {\n                  children: \"from Remotion v4.0.51\"\n                }),\n                \")\"\n              ]\n            })\n          ]\n        }),\n        /* @__PURE__ */ jsxs15(\"p\", {\n          children: [\n            \"The default is \",\n            /* @__PURE__ */ jsx21(\"code\", {\n              children: \"null\"\n            }),\n            \", letting Chrome decide, except on Lambda where the default is \",\n            /* @__PURE__ */ jsx21(\"code\", {\n              children: '\"swangle\"'\n            })\n          ]\n        })\n      ]\n    });\n  },\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag24]) {\n      validateOpenGlRenderer(commandLine[cliFlag24]);\n      return {\n        value: commandLine[cliFlag24],\n        source: \"cli\"\n      };\n    }\n    if (openGlRenderer !== DEFAULT_OPENGL_RENDERER) {\n      return {\n        value: openGlRenderer,\n        source: \"config\"\n      };\n    }\n    return {\n      value: DEFAULT_OPENGL_RENDERER,\n      source: \"default\"\n    };\n  },\n  setConfig: (value) => {\n    validateOpenGlRenderer(value);\n    openGlRenderer = value;\n  }\n};\nvar validateOpenGlRenderer = (option2) => {\n  if (option2 === null) {\n    return null;\n  }\n  if (!validOpenGlRenderers.includes(option2)) {\n    throw new TypeError(`${option2} is not a valid GL backend. Accepted values: ${validOpenGlRenderers.join(\", \")}`);\n  }\n  return option2;\n};\n\n// src/options/hardware-acceleration.tsx\nvar hardwareAccelerationOptions = [\n  \"disable\",\n  \"if-possible\",\n  \"required\"\n];\nvar cliFlag25 = \"hardware-acceleration\";\nvar currentValue = null;\nvar hardwareAccelerationOption = {\n  name: \"Hardware Acceleration\",\n  cliFlag: cliFlag25,\n  description: () => `\n\t\t\tOne of\n\t\t\t${new Intl.ListFormat(\"en\", { type: \"disjunction\" }).format(hardwareAccelerationOptions.map((a) => JSON.stringify(a)))}\n\t\t\t. Default \"disable\". Encode using a hardware-accelerated encoder if\n\t\t\tavailable. If set to \"required\" and no hardware-accelerated encoder is\n\t\t\tavailable, then the render will fail.\n\t\t`,\n  ssrName: \"hardwareAcceleration\",\n  docLink: \"https://www.remotion.dev/docs/encoding\",\n  type: \"disable\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag25] !== undefined) {\n      const value = commandLine[cliFlag25];\n      if (!hardwareAccelerationOptions.includes(value)) {\n        throw new Error(`Invalid value for --${cliFlag25}: ${value}`);\n      }\n      return {\n        source: \"cli\",\n        value\n      };\n    }\n    if (currentValue !== null) {\n      return {\n        source: \"config\",\n        value: currentValue\n      };\n    }\n    return {\n      source: \"default\",\n      value: \"disable\"\n    };\n  },\n  setConfig: (value) => {\n    if (!hardwareAccelerationOptions.includes(value)) {\n      throw new Error(`Invalid value for --${cliFlag25}: ${value}`);\n    }\n    currentValue = value;\n  }\n};\n\n// src/options/headless.tsx\nimport { jsx as jsx22, jsxs as jsxs16, Fragment as Fragment22 } from \"react/jsx-runtime\";\nvar DEFAULT4 = true;\nvar headlessMode = DEFAULT4;\nvar cliFlag26 = \"disable-headless\";\nvar headlessOption = {\n  name: \"Disable Headless Mode\",\n  cliFlag: cliFlag26,\n  description: () => /* @__PURE__ */ jsxs16(Fragment22, {\n    children: [\n      \"Deprecated - will be removed in 5.0.0. With the migration to\",\n      \" \",\n      /* @__PURE__ */ jsx22(\"a\", {\n        href: \"/docs/miscellaneous/chrome-headless-shell\",\n        children: \"Chrome Headless Shell\"\n      }),\n      \", this option is not functional anymore.\",\n      /* @__PURE__ */ jsx22(\"br\", {}),\n      /* @__PURE__ */ jsx22(\"br\", {}),\n      \" If disabled, the render will open an actual Chrome window where you can see the render happen. The default is headless mode.\"\n    ]\n  }),\n  ssrName: \"headless\",\n  docLink: \"https://www.remotion.dev/docs/chromium-flags#--disable-headless\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag26] !== undefined) {\n      return {\n        source: \"cli\",\n        value: !commandLine[cliFlag26]\n      };\n    }\n    if (headlessMode !== DEFAULT4) {\n      return {\n        source: \"config\",\n        value: headlessMode\n      };\n    }\n    return {\n      source: \"default\",\n      value: headlessMode\n    };\n  },\n  setConfig: (value) => {\n    headlessMode = value;\n  }\n};\n\n// src/options/image-sequence-pattern.tsx\nimport { jsx as jsx23, jsxs as jsxs17, Fragment as Fragment23 } from \"react/jsx-runtime\";\nvar cliFlag27 = \"image-sequence-pattern\";\nvar currentImageSequencePattern = null;\nvar imageSequencePatternOption = {\n  name: \"Image Sequence Pattern\",\n  cliFlag: cliFlag27,\n  ssrName: \"imageSequencePattern\",\n  description: () => /* @__PURE__ */ jsxs17(Fragment23, {\n    children: [\n      \"Pattern for naming image sequence files. Supports \",\n      /* @__PURE__ */ jsx23(\"code\", {\n        children: \"[frame]\"\n      }),\n      \" for the zero-padded frame number and \",\n      /* @__PURE__ */ jsx23(\"code\", {\n        children: \"[ext]\"\n      }),\n      \" for the file extension.\"\n    ]\n  }),\n  docLink: null,\n  type: \"string\",\n  getValue: ({ commandLine }) => {\n    if (currentImageSequencePattern !== null) {\n      return {\n        value: currentImageSequencePattern,\n        source: \"config\"\n      };\n    }\n    return {\n      value: commandLine[cliFlag27],\n      source: \"cli\"\n    };\n  },\n  setConfig: (pattern) => {\n    currentImageSequencePattern = pattern;\n  }\n};\n\n// src/options/jpeg-quality.tsx\nimport { jsx as jsx24, Fragment as Fragment24 } from \"react/jsx-runtime\";\nvar defaultValue = DEFAULT_JPEG_QUALITY;\nvar quality = defaultValue;\nvar setJpegQuality = (q) => {\n  validateJpegQuality(q);\n  if (q === 0 || q === undefined) {\n    quality = defaultValue;\n    return;\n  }\n  quality = q;\n};\nvar cliFlag28 = \"jpeg-quality\";\nvar jpegQualityOption = {\n  name: \"JPEG Quality\",\n  cliFlag: cliFlag28,\n  description: () => /* @__PURE__ */ jsx24(Fragment24, {\n    children: \"Sets the quality of the generated JPEG images. Must be an integer between 0 and 100. Default: 80.\"\n  }),\n  ssrName: \"jpegQuality\",\n  docLink: \"https://www.remotion.dev/docs/renderer/render-media#jpeg-quality\",\n  type: 0,\n  setConfig: setJpegQuality,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag28] !== undefined) {\n      validateJpegQuality(commandLine[cliFlag28]);\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag28]\n      };\n    }\n    if (quality !== defaultValue) {\n      return {\n        source: \"config\",\n        value: quality\n      };\n    }\n    return {\n      source: \"default\",\n      value: defaultValue\n    };\n  }\n};\n\n// src/options/keyboard-shortcuts.tsx\nimport { jsx as jsx25, Fragment as Fragment25 } from \"react/jsx-runtime\";\nvar keyboardShortcutsEnabled = true;\nvar cliFlag29 = \"disable-keyboard-shortcuts\";\nvar keyboardShortcutsOption = {\n  name: \"Disable or Enable keyboard shortcuts\",\n  cliFlag: cliFlag29,\n  description: () => /* @__PURE__ */ jsx25(Fragment25, {\n    children: \"Enable or disable keyboard shortcuts in the Remotion Studio.\"\n  }),\n  ssrName: null,\n  docLink: \"https://www.remotion.dev/docs/config#setkeyboardshortcutsenabled\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag29] !== undefined) {\n      keyboardShortcutsEnabled = commandLine[cliFlag29] === false;\n      return {\n        value: keyboardShortcutsEnabled,\n        source: \"cli\"\n      };\n    }\n    return {\n      value: keyboardShortcutsEnabled,\n      source: \"config\"\n    };\n  },\n  setConfig(value) {\n    keyboardShortcutsEnabled = value;\n  }\n};\n\n// src/options/latency-hint.tsx\nimport { jsx as jsx26, jsxs as jsxs18, Fragment as Fragment26 } from \"react/jsx-runtime\";\nvar cliFlag30 = \"audio-latency-hint\";\nvar value = null;\nvar audioLatencyHintOption = {\n  name: \"Audio Latency Hint\",\n  cliFlag: cliFlag30,\n  description: () => /* @__PURE__ */ jsxs18(Fragment26, {\n    children: [\n      \"Sets the\",\n      \" \",\n      /* @__PURE__ */ jsx26(\"a\", {\n        href: \"https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/AudioContext\",\n        children: \"audio latency\"\n      }),\n      \" \",\n      \"hint for the global \",\n      /* @__PURE__ */ jsx26(\"code\", {\n        children: \"AudioContext\"\n      }),\n      \" context that Remotion uses to play audio.\",\n      /* @__PURE__ */ jsx26(\"br\", {}),\n      \"Possible values: \",\n      /* @__PURE__ */ jsx26(\"code\", {\n        children: \"interactive\"\n      }),\n      \", \",\n      /* @__PURE__ */ jsx26(\"code\", {\n        children: \"balanced\"\n      }),\n      \",\",\n      \" \",\n      /* @__PURE__ */ jsx26(\"code\", {\n        children: \"playback\"\n      })\n    ]\n  }),\n  ssrName: \"audioLatencyHint\",\n  docLink: \"https://www.remotion.dev/docs/renderer/render-media\",\n  type: \"interactive\",\n  getValue: ({ commandLine }) => {\n    const val = commandLine[cliFlag30];\n    if (typeof val !== \"undefined\") {\n      return { value: val, source: \"cli\" };\n    }\n    if (value !== null) {\n      return { value, source: \"config\" };\n    }\n    return { value: null, source: \"default\" };\n  },\n  setConfig: (profile) => {\n    value = profile;\n  }\n};\n\n// src/options/license-key.tsx\nimport { jsx as jsx27, jsxs as jsxs19, Fragment as Fragment27 } from \"react/jsx-runtime\";\nvar currentLicenseKey = null;\nvar cliFlag31 = \"licenseKey-key\";\nvar licenseKeyOption = {\n  name: \"License key\",\n  cliFlag: cliFlag31,\n  description: () => /* @__PURE__ */ jsxs19(Fragment27, {\n    children: [\n      \"License key for sending a usage event using\",\n      \" \",\n      /* @__PURE__ */ jsx27(\"code\", {\n        children: \"@remotion/licensing\"\n      }),\n      \".\"\n    ]\n  }),\n  ssrName: \"licenseKey\",\n  docLink: \"https://www.remotion.dev/docs/licensing\",\n  type: null,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag31] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag31]\n      };\n    }\n    return {\n      source: \"default\",\n      value: currentLicenseKey\n    };\n  },\n  setConfig: (value2) => {\n    currentLicenseKey = value2;\n  }\n};\n\n// src/options/log-level.tsx\nimport { jsx as jsx28, jsxs as jsxs20, Fragment as Fragment28 } from \"react/jsx-runtime\";\nvar logLevel = \"info\";\nvar cliFlag32 = \"log\";\nvar logLevelOption = {\n  cliFlag: cliFlag32,\n  name: \"Log Level\",\n  ssrName: \"logLevel\",\n  description: () => /* @__PURE__ */ jsxs20(Fragment28, {\n    children: [\n      \"One of \",\n      /* @__PURE__ */ jsx28(\"code\", {\n        children: \"trace\"\n      }),\n      \", \",\n      /* @__PURE__ */ jsx28(\"code\", {\n        children: \"verbose\"\n      }),\n      \", \",\n      /* @__PURE__ */ jsx28(\"code\", {\n        children: \"info\"\n      }),\n      \",\",\n      \" \",\n      /* @__PURE__ */ jsx28(\"code\", {\n        children: \"warn\"\n      }),\n      \", \",\n      /* @__PURE__ */ jsx28(\"code\", {\n        children: \"error\"\n      }),\n      \".\",\n      /* @__PURE__ */ jsx28(\"br\", {}),\n      \" Determines how much info is being logged to the console.\",\n      /* @__PURE__ */ jsx28(\"br\", {}),\n      /* @__PURE__ */ jsx28(\"br\", {}),\n      \" Default \",\n      /* @__PURE__ */ jsx28(\"code\", {\n        children: \"info\"\n      }),\n      \".\"\n    ]\n  }),\n  docLink: \"https://www.remotion.dev/docs/troubleshooting/debug-failed-render\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag32]) {\n      if (!isValidLogLevel(commandLine[cliFlag32])) {\n        throw new Error(`Invalid \\`--log\\` value passed. Accepted values: ${logLevels.map((l) => `'${l}'`).join(\", \")}.`);\n      }\n      return { value: commandLine[cliFlag32], source: \"cli\" };\n    }\n    if (logLevel !== \"info\") {\n      return { value: logLevel, source: \"config\" };\n    }\n    return { value: \"info\", source: \"default\" };\n  },\n  setConfig: (newLogLevel) => {\n    logLevel = newLogLevel;\n  },\n  type: \"error\"\n};\n\n// src/options/metadata.tsx\nimport { jsx as jsx29, jsxs as jsxs21, Fragment as Fragment29 } from \"react/jsx-runtime\";\nvar metadata = {};\nvar cliFlag33 = \"metadata\";\nvar metadataOption = {\n  name: \"Metadata\",\n  cliFlag: cliFlag33,\n  description: (mode) => {\n    if (mode === \"ssr\") {\n      return /* @__PURE__ */ jsxs21(Fragment29, {\n        children: [\n          \"An object containing metadata to be embedded in the video. See\",\n          \" \",\n          /* @__PURE__ */ jsx29(\"a\", {\n            href: \"/docs/metadata\",\n            children: \"here\"\n          }),\n          \" for which metadata is accepted.\"\n        ]\n      });\n    }\n    return /* @__PURE__ */ jsxs21(Fragment29, {\n      children: [\n        \"Metadata to be embedded in the video. See\",\n        \" \",\n        /* @__PURE__ */ jsx29(\"a\", {\n          href: \"/docs/metadata\",\n          children: \"here\"\n        }),\n        \" for which metadata is accepted.\",\n        /* @__PURE__ */ jsx29(\"br\", {}),\n        \"The parameter must be in the format of \",\n        /* @__PURE__ */ jsx29(\"code\", {\n          children: \"--metadata key=value\"\n        }),\n        \" \",\n        \"and can be passed multiple times.\"\n      ]\n    });\n  },\n  docLink: \"https://www.remotion.dev/docs/metadata\",\n  type: {},\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag33] !== undefined) {\n      const val = commandLine[cliFlag33];\n      const array = typeof val === \"string\" ? [val] : val;\n      const keyValues = array.map((a) => {\n        if (!a.includes(\"=\")) {\n          throw new Error(`\"metadata\" must be in the format of key=value, but got ${a}`);\n        }\n        const splitted = a.split(\"=\");\n        if (splitted.length !== 2) {\n          throw new Error(`\"metadata\" must be in the format of key=value, but got ${a}`);\n        }\n        return [splitted[0], splitted[1]];\n      });\n      const value2 = Object.fromEntries(keyValues);\n      return {\n        source: \"config\",\n        value: value2\n      };\n    }\n    return {\n      source: \"config\",\n      value: metadata\n    };\n  },\n  setConfig: (newMetadata) => {\n    metadata = newMetadata;\n  },\n  ssrName: \"metadata\"\n};\n\n// src/options/mute.tsx\nimport { jsx as jsx30, Fragment as Fragment30 } from \"react/jsx-runtime\";\nvar DEFAULT_MUTED_STATE = false;\nvar mutedState = DEFAULT_MUTED_STATE;\nvar cliFlag34 = \"muted\";\nvar mutedOption = {\n  name: \"Muted\",\n  cliFlag: cliFlag34,\n  description: () => /* @__PURE__ */ jsx30(Fragment30, {\n    children: \"The Audio of the video will be omitted.\"\n  }),\n  ssrName: \"muted\",\n  docLink: \"https://www.remotion.dev/docs/audio/muting\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag34] !== null) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag34]\n      };\n    }\n    if (mutedState !== DEFAULT_MUTED_STATE) {\n      return {\n        source: \"config\",\n        value: mutedState\n      };\n    }\n    return {\n      source: \"config\",\n      value: mutedState\n    };\n  },\n  setConfig: () => {\n    mutedState = true;\n  }\n};\n\n// src/options/number-of-gif-loops.tsx\nimport { jsx as jsx31, jsxs as jsxs22, Fragment as Fragment31 } from \"react/jsx-runtime\";\nvar currentLoop = null;\nvar validate = (newLoop) => {\n  if (newLoop !== null && typeof newLoop !== \"number\") {\n    throw new Error(\"--number-of-gif-loops flag must be a number.\");\n  }\n};\nvar cliFlag35 = \"number-of-gif-loops\";\nvar numberOfGifLoopsOption = {\n  name: \"Number of GIF loops\",\n  cliFlag: cliFlag35,\n  description: () => {\n    return /* @__PURE__ */ jsxs22(Fragment31, {\n      children: [\n        \"Allows you to set the number of loops as follows:\",\n        /* @__PURE__ */ jsxs22(\"ul\", {\n          children: [\n            /* @__PURE__ */ jsxs22(\"li\", {\n              children: [\n                /* @__PURE__ */ jsx31(\"code\", {\n                  children: \"null\"\n                }),\n                \" (or omitting in the CLI) plays the GIF indefinitely.\"\n              ]\n            }),\n            /* @__PURE__ */ jsxs22(\"li\", {\n              children: [\n                /* @__PURE__ */ jsx31(\"code\", {\n                  children: \"0\"\n                }),\n                \" disables looping\"\n              ]\n            }),\n            /* @__PURE__ */ jsxs22(\"li\", {\n              children: [\n                /* @__PURE__ */ jsx31(\"code\", {\n                  children: \"1\"\n                }),\n                \" loops the GIF once (plays twice in total)\"\n              ]\n            }),\n            /* @__PURE__ */ jsxs22(\"li\", {\n              children: [\n                /* @__PURE__ */ jsx31(\"code\", {\n                  children: \"2\"\n                }),\n                \" loops the GIF twice (plays three times in total) and so on.\"\n              ]\n            })\n          ]\n        })\n      ]\n    });\n  },\n  ssrName: \"numberOfGifLoops\",\n  docLink: \"https://www.remotion.dev/docs/render-as-gif#changing-the-number-of-loops\",\n  type: 0,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag35] !== undefined) {\n      validate(commandLine[cliFlag35]);\n      return {\n        value: commandLine[cliFlag35],\n        source: \"cli\"\n      };\n    }\n    if (currentLoop !== null) {\n      return {\n        value: currentLoop,\n        source: \"config\"\n      };\n    }\n    return {\n      value: null,\n      source: \"default\"\n    };\n  },\n  setConfig: (newLoop) => {\n    validate(newLoop);\n    currentLoop = newLoop;\n  }\n};\n\n// src/options/offthreadvideo-cache-size.tsx\nimport { jsx as jsx32, jsxs as jsxs23, Fragment as Fragment32 } from \"react/jsx-runtime\";\nvar offthreadVideoCacheSizeInBytes = null;\nvar cliFlag36 = \"offthreadvideo-cache-size-in-bytes\";\nvar offthreadVideoCacheSizeInBytesOption = {\n  name: \"OffthreadVideo cache size\",\n  cliFlag: cliFlag36,\n  description: () => /* @__PURE__ */ jsxs23(Fragment32, {\n    children: [\n      \"From v4.0, Remotion has a cache for\",\n      \" \",\n      /* @__PURE__ */ jsx32(\"a\", {\n        href: \"https://remotion.dev/docs/offthreadvideo\",\n        children: /* @__PURE__ */ jsx32(\"code\", {\n          children: \"<OffthreadVideo>\"\n        })\n      }),\n      \" \",\n      \"frames. The default is \",\n      /* @__PURE__ */ jsx32(\"code\", {\n        children: \"null\"\n      }),\n      \", corresponding to half of the system memory available when the render starts.\",\n      /* @__PURE__ */ jsx32(\"br\", {}),\n      \" This option allows to override the size of the cache. The higher it is, the faster the render will be, but the more memory will be used.\",\n      /* @__PURE__ */ jsx32(\"br\", {}),\n      \"The used value will be printed when running in verbose mode.\",\n      /* @__PURE__ */ jsx32(\"br\", {}),\n      \"Default: \",\n      /* @__PURE__ */ jsx32(\"code\", {\n        children: \"null\"\n      })\n    ]\n  }),\n  ssrName: \"offthreadVideoCacheSizeInBytes\",\n  docLink: \"https://www.remotion.dev/docs/offthreadvideo\",\n  type: 0,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag36] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag36]\n      };\n    }\n    if (offthreadVideoCacheSizeInBytes !== null) {\n      return {\n        source: \"config\",\n        value: offthreadVideoCacheSizeInBytes\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  setConfig: (size) => {\n    offthreadVideoCacheSizeInBytes = size ?? null;\n  }\n};\n\n// src/options/offthreadvideo-threads.tsx\nimport { jsx as jsx33, jsxs as jsxs24, Fragment as Fragment33 } from \"react/jsx-runtime\";\nvar value2 = null;\nvar cliFlag37 = \"offthreadvideo-video-threads\";\nvar offthreadVideoThreadsOption = {\n  name: \"OffthreadVideo threads\",\n  cliFlag: cliFlag37,\n  description: () => /* @__PURE__ */ jsxs24(Fragment33, {\n    children: [\n      \"The number of threads that\",\n      /* @__PURE__ */ jsx33(\"a\", {\n        href: \"https://remotion.dev/docs/offthreadvideo\",\n        children: /* @__PURE__ */ jsx33(\"code\", {\n          children: \"<OffthreadVideo>\"\n        })\n      }),\n      \" \",\n      \"can start to extract frames. The default is\",\n      \" \",\n      DEFAULT_RENDER_FRAMES_OFFTHREAD_VIDEO_THREADS,\n      \". Increase carefully, as too many threads may cause instability.\"\n    ]\n  }),\n  ssrName: \"offthreadVideoThreads\",\n  docLink: \"https://www.remotion.dev/docs/offthreadvideo\",\n  type: 0,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag37] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag37]\n      };\n    }\n    if (value2 !== null) {\n      return {\n        source: \"config\",\n        value: value2\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  setConfig: (size) => {\n    value2 = size ?? null;\n  }\n};\nvar DEFAULT_RENDER_FRAMES_OFFTHREAD_VIDEO_THREADS = 2;\n\n// src/options/on-browser-download.tsx\nimport { jsx as jsx34, jsxs as jsxs25, Fragment as Fragment34 } from \"react/jsx-runtime\";\nvar cliFlag38 = \"on-browser-download\";\nvar onBrowserDownloadOption = {\n  name: \"Browser download callback function\",\n  cliFlag: cliFlag38,\n  description: () => /* @__PURE__ */ jsxs25(Fragment34, {\n    children: [\n      \"Gets called when no compatible local browser is detected on the system and this API needs to download a browser. Return a callback to observe progress.\",\n      \" \",\n      /* @__PURE__ */ jsx34(\"a\", {\n        href: \"/docs/renderer/ensure-browser#onbrowserdownload\",\n        children: \"See here for how to use this option.\"\n      })\n    ]\n  }),\n  ssrName: \"onBrowserDownload\",\n  docLink: \"https://www.remotion.dev/docs/renderer/ensure-browser\",\n  type: undefined,\n  getValue: () => {\n    throw new Error(\"does not support config file\");\n  },\n  setConfig: () => {\n    throw new Error(\"does not support config file\");\n  }\n};\n\n// src/options/overwrite.tsx\nimport { jsx as jsx35, jsxs as jsxs26, Fragment as Fragment35 } from \"react/jsx-runtime\";\nvar shouldOverwrite = null;\nvar cliFlag39 = \"overwrite\";\nvar validate2 = (value3) => {\n  if (typeof value3 !== \"boolean\") {\n    throw new Error(`overwriteExisting must be a boolean but got ${typeof value3} (${value3})`);\n  }\n};\nvar overwriteOption = {\n  name: \"Overwrite output\",\n  cliFlag: cliFlag39,\n  description: () => /* @__PURE__ */ jsxs26(Fragment35, {\n    children: [\n      \"If set to \",\n      /* @__PURE__ */ jsx35(\"code\", {\n        children: \"false\"\n      }),\n      \", will prevent rendering to a path that already exists. Default is \",\n      /* @__PURE__ */ jsx35(\"code\", {\n        children: \"true\"\n      }),\n      \".\"\n    ]\n  }),\n  ssrName: \"overwrite\",\n  docLink: \"https://www.remotion.dev/docs/config#setoverwriteoutput\",\n  type: false,\n  getValue: ({ commandLine }, defaultValue2) => {\n    if (commandLine[cliFlag39] !== undefined) {\n      validate2(commandLine[cliFlag39]);\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag39]\n      };\n    }\n    if (shouldOverwrite !== null) {\n      return {\n        source: \"config\",\n        value: shouldOverwrite\n      };\n    }\n    return {\n      source: \"default\",\n      value: defaultValue2\n    };\n  },\n  setConfig: (value3) => {\n    validate2(value3);\n    shouldOverwrite = value3;\n  }\n};\n\n// src/options/prefer-lossless.tsx\nimport { jsx as jsx36, jsxs as jsxs27, Fragment as Fragment36 } from \"react/jsx-runtime\";\nvar cliFlag40 = \"prefer-lossless\";\nvar input = false;\nvar preferLosslessAudioOption = {\n  name: \"Prefer lossless\",\n  cliFlag: cliFlag40,\n  description: () => /* @__PURE__ */ jsxs27(Fragment36, {\n    children: [\n      \"Uses a lossless audio codec, if one is available for the codec. If you set\",\n      /* @__PURE__ */ jsx36(\"code\", {\n        children: \"audioCodec\"\n      }),\n      \", it takes priority over\",\n      \" \",\n      /* @__PURE__ */ jsx36(\"code\", {\n        children: \"preferLossless\"\n      }),\n      \".\"\n    ]\n  }),\n  docLink: \"https://www.remotion.dev/docs/encoding\",\n  type: false,\n  ssrName: \"preferLossless\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag40]) {\n      return { value: true, source: \"cli\" };\n    }\n    if (input === true) {\n      return { value: true, source: \"config\" };\n    }\n    return { value: false, source: \"default\" };\n  },\n  setConfig: (val) => {\n    input = val;\n  }\n};\n\n// src/options/public-dir.tsx\nimport { jsx as jsx37, jsxs as jsxs28, Fragment as Fragment37 } from \"react/jsx-runtime\";\nvar cliFlag41 = \"public-dir\";\nvar currentPublicDir = null;\nvar publicDirOption = {\n  name: \"Public Directory\",\n  cliFlag: cliFlag41,\n  description: () => {\n    return /* @__PURE__ */ jsxs28(Fragment37, {\n      children: [\n        \"Define the location of the\",\n        \" \",\n        /* @__PURE__ */ jsx37(\"a\", {\n          href: \"/docs/terminology/public-dir\",\n          children: /* @__PURE__ */ jsx37(\"code\", {\n            children: \"public/ directory\"\n          })\n        }),\n        \". If not defined, Remotion will assume the location is the `public` folder in your Remotion root.\"\n      ]\n    });\n  },\n  ssrName: \"publicDir\",\n  docLink: \"https://www.remotion.dev/docs/terminology/public-dir\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag41] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag41]\n      };\n    }\n    if (currentPublicDir !== null) {\n      return {\n        source: \"config\",\n        value: currentPublicDir\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  setConfig: (value3) => {\n    currentPublicDir = value3;\n  },\n  type: \"\"\n};\n\n// src/options/public-license-key.tsx\nimport { jsx as jsx38, jsxs as jsxs29, Fragment as Fragment38 } from \"react/jsx-runtime\";\nvar cliFlag42 = \"public-license-key\";\nvar currentPublicLicenseKey = null;\nvar publicLicenseKeyOption = {\n  name: \"Public License Key\",\n  cliFlag: cliFlag42,\n  description: () => /* @__PURE__ */ jsxs29(Fragment38, {\n    children: [\n      'The public license key for your company license, obtained from the \"Usage\" tab on ',\n      /* @__PURE__ */ jsx38(\"a\", {\n        href: \"https://remotion.pro/dashboard\",\n        children: \"remotion.pro\"\n      }),\n      '. If you are eligible for the free license, pass \"free-license\".'\n    ]\n  }),\n  ssrName: \"publicLicenseKey\",\n  docLink: \"https://www.remotion.dev/docs/licensing\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag42] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag42]\n      };\n    }\n    if (currentPublicLicenseKey !== null) {\n      return {\n        source: \"config\",\n        value: currentPublicLicenseKey\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  setConfig: (value3) => {\n    if (value3 && value3 !== \"free-license\" && !value3.startsWith(\"rm_pub_\")) {\n      throw new Error('Invalid public license key. It must start with \"rm_pub_\" or be \"free-license\".');\n    }\n    currentPublicLicenseKey = value3;\n  },\n  type: null\n};\n\n// src/options/public-path.tsx\nimport { jsx as jsx39, jsxs as jsxs30, Fragment as Fragment39 } from \"react/jsx-runtime\";\nvar cliFlag43 = \"public-path\";\nvar currentPublicPath = null;\nvar publicPathOption = {\n  name: \"Public Path\",\n  cliFlag: cliFlag43,\n  description: () => {\n    return /* @__PURE__ */ jsxs30(Fragment39, {\n      children: [\n        \"The path of the URL where the bundle is going to be hosted. By default it is \",\n        /* @__PURE__ */ jsx39(\"code\", {\n          children: \"/\"\n        }),\n        \", meaning that the bundle is going to be hosted at the root of the domain (e.g. \",\n        /* @__PURE__ */ jsx39(\"code\", {\n          children: \"https://localhost:3000/\"\n        }),\n        \"). If you are deploying to a subdirectory (e.g. \",\n        /* @__PURE__ */ jsx39(\"code\", {\n          children: \"/sites/my-site/\"\n        }),\n        \"), you should set this to the subdirectory.\"\n      ]\n    });\n  },\n  ssrName: \"publicPath\",\n  docLink: \"https://www.remotion.dev/docs/renderer\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag43] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag43]\n      };\n    }\n    if (currentPublicPath !== null) {\n      return {\n        source: \"config\",\n        value: currentPublicPath\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  setConfig: (value3) => {\n    currentPublicPath = value3;\n  },\n  type: \"\"\n};\n\n// src/options/repro.tsx\nimport { jsx as jsx40, Fragment as Fragment40 } from \"react/jsx-runtime\";\nvar enableRepro = false;\nvar setRepro = (should) => {\n  enableRepro = should;\n};\nvar cliFlag44 = \"repro\";\nvar reproOption = {\n  name: \"Create reproduction\",\n  cliFlag: cliFlag44,\n  description: () => /* @__PURE__ */ jsx40(Fragment40, {\n    children: \"Create a ZIP that you can submit to Remotion if asked for a reproduction.\"\n  }),\n  ssrName: \"repro\",\n  docLink: \"https://www.remotion.dev/docs/render-media#repro\",\n  type: false,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag44] !== undefined) {\n      return {\n        value: commandLine[cliFlag44],\n        source: \"cli\"\n      };\n    }\n    if (enableRepro) {\n      return {\n        value: enableRepro,\n        source: \"config\"\n      };\n    }\n    return {\n      value: false,\n      source: \"default\"\n    };\n  },\n  setConfig: setRepro\n};\n\n// src/options/scale.tsx\nimport { jsx as jsx41, jsxs as jsxs31, Fragment as Fragment41 } from \"react/jsx-runtime\";\nvar currentScale = 1;\nvar cliFlag45 = \"scale\";\nvar validateScale = (value3) => {\n  if (typeof value3 !== \"number\") {\n    throw new Error(\"scale must be a number.\");\n  }\n};\nvar scaleOption = {\n  name: \"Scale\",\n  cliFlag: cliFlag45,\n  description: () => /* @__PURE__ */ jsxs31(Fragment41, {\n    children: [\n      \"Scales the output dimensions by a factor. For example, a 1280x720px frame will become a 1920x1080px frame with a scale factor of \",\n      /* @__PURE__ */ jsx41(\"code\", {\n        children: \"1.5\"\n      }),\n      \". See \",\n      /* @__PURE__ */ jsx41(\"a\", {\n        href: \"https://www.remotion.dev/docs/scaling\",\n        children: \"Scaling\"\n      }),\n      \" for more details.\"\n    ]\n  }),\n  ssrName: \"scale\",\n  docLink: \"https://www.remotion.dev/docs/scaling\",\n  type: 0,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag45] !== undefined) {\n      validateScale(commandLine[cliFlag45]);\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag45]\n      };\n    }\n    if (currentScale !== null) {\n      return {\n        source: \"config\",\n        value: currentScale\n      };\n    }\n    return {\n      source: \"default\",\n      value: 1\n    };\n  },\n  setConfig: (scale) => {\n    currentScale = scale;\n  }\n};\n\n// src/options/throw-if-site-exists.tsx\nvar DEFAULT5 = false;\nvar cliFlag46 = \"throw-if-site-exists\";\nvar throwIfSiteExistsOption = {\n  cliFlag: cliFlag46,\n  description: () => `Prevents accidential update of an existing site. If there are any files in the subfolder where the site should be placed, the function will throw.`,\n  docLink: \"https://remotion.dev/docs/lambda/deploy-site\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag46]) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag46]\n      };\n    }\n    return {\n      source: \"default\",\n      value: DEFAULT5\n    };\n  },\n  name: \"Throw if site exists\",\n  setConfig: () => {\n    throw new Error(\"Not implemented\");\n  },\n  ssrName: \"throwIfSiteExists\",\n  type: false\n};\n\n// src/options/timeout.tsx\nimport { jsx as jsx42, jsxs as jsxs32, Fragment as Fragment42 } from \"react/jsx-runtime\";\nvar currentTimeout = DEFAULT_TIMEOUT;\nvar validate3 = (value3) => {\n  if (typeof value3 !== \"number\") {\n    throw new Error(\"--timeout flag / setDelayRenderTimeoutInMilliseconds() must be a number, but got \" + JSON.stringify(value3));\n  }\n};\nvar cliFlag47 = \"timeout\";\nvar delayRenderTimeoutInMillisecondsOption = {\n  name: \"delayRender() timeout\",\n  cliFlag: cliFlag47,\n  description: () => /* @__PURE__ */ jsxs32(Fragment42, {\n    children: [\n      \"A number describing how long the render may take to resolve all\",\n      \" \",\n      /* @__PURE__ */ jsx42(\"a\", {\n        href: \"https://remotion.dev/docs/delay-render\",\n        children: /* @__PURE__ */ jsx42(\"code\", {\n          children: \"delayRender()\"\n        })\n      }),\n      \" \",\n      \"calls\",\n      \" \",\n      /* @__PURE__ */ jsx42(\"a\", {\n        style: { fontSize: \"inherit\" },\n        href: \"https://remotion.dev/docs/timeout\",\n        children: \"before it times out\"\n      }),\n      \". Default: \",\n      /* @__PURE__ */ jsx42(\"code\", {\n        children: \"30000\"\n      })\n    ]\n  }),\n  ssrName: \"timeoutInMilliseconds\",\n  docLink: \"https://www.remotion.dev/docs/timeout\",\n  type: 0,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag47] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag47]\n      };\n    }\n    if (currentTimeout !== null) {\n      validate3(currentTimeout);\n      return {\n        source: \"config\",\n        value: currentTimeout\n      };\n    }\n    return {\n      source: \"default\",\n      value: DEFAULT_TIMEOUT\n    };\n  },\n  setConfig: (value3) => {\n    validate3(value3);\n    currentTimeout = value3;\n  }\n};\n\n// src/options/video-bitrate.tsx\nimport { jsx as jsx43, jsxs as jsxs33, Fragment as Fragment43 } from \"react/jsx-runtime\";\nvar videoBitrate = null;\nvar cliFlag48 = \"video-bitrate\";\nvar videoBitrateOption = {\n  name: \"Video Bitrate\",\n  cliFlag: cliFlag48,\n  description: () => /* @__PURE__ */ jsxs33(Fragment43, {\n    children: [\n      \"Specify the target bitrate for the generated video. The syntax for FFmpeg\",\n      \"'\",\n      \"s\",\n      /* @__PURE__ */ jsx43(\"code\", {\n        children: \"-b:v\"\n      }),\n      \" parameter should be used. FFmpeg may encode the video in a way that will not result in the exact video bitrate specified. Example values: \",\n      /* @__PURE__ */ jsx43(\"code\", {\n        children: \"512K\"\n      }),\n      \" for 512 kbps, \",\n      /* @__PURE__ */ jsx43(\"code\", {\n        children: \"1M\"\n      }),\n      \" for 1 Mbps.\"\n    ]\n  }),\n  ssrName: \"videoBitrate\",\n  docLink: \"https://www.remotion.dev/docs/renderer/render-media#videobitrate\",\n  type: \"\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag48] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag48]\n      };\n    }\n    if (videoBitrate !== null) {\n      return {\n        source: \"config\",\n        value: videoBitrate\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  setConfig: (bitrate) => {\n    videoBitrate = bitrate;\n  }\n};\n\n// src/options/video-cache-size.tsx\nimport { jsx as jsx44, jsxs as jsxs34, Fragment as Fragment44 } from \"react/jsx-runtime\";\nvar mediaCacheSizeInBytes = null;\nvar cliFlag49 = \"media-cache-size-in-bytes\";\nvar mediaCacheSizeInBytesOption = {\n  name: \"@remotion/media cache size\",\n  cliFlag: cliFlag49,\n  description: () => /* @__PURE__ */ jsxs34(Fragment44, {\n    children: [\n      \"Specify the maximum size of the cache that \",\n      /* @__PURE__ */ jsx44(\"code\", {\n        children: \"<Video>\"\n      }),\n      \" and\",\n      \" \",\n      /* @__PURE__ */ jsx44(\"code\", {\n        children: \"<Audio>\"\n      }),\n      \" from \",\n      /* @__PURE__ */ jsx44(\"code\", {\n        children: \"@remotion/media\"\n      }),\n      \" may use combined, in bytes. \",\n      /* @__PURE__ */ jsx44(\"br\", {}),\n      \"The default is half of the available system memory when the render starts.\"\n    ]\n  }),\n  ssrName: \"mediaCacheSizeInBytes\",\n  docLink: \"https://www.remotion.dev/docs/media/video#setting-the-cache-size\",\n  type: 0,\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag49] !== undefined) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag49]\n      };\n    }\n    if (mediaCacheSizeInBytes !== null) {\n      return {\n        source: \"config\",\n        value: mediaCacheSizeInBytes\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  setConfig: (size) => {\n    mediaCacheSizeInBytes = size ?? null;\n  }\n};\n\n// src/path-normalize.ts\nvar SLASH = 47;\nvar DOT = 46;\nvar assertPath = (path) => {\n  const t = typeof path;\n  if (t !== \"string\") {\n    throw new TypeError(`Expected a string, got a ${t}`);\n  }\n};\nvar posixNormalize = (path, allowAboveRoot) => {\n  let res = \"\";\n  let lastSegmentLength = 0;\n  let lastSlash = -1;\n  let dots = 0;\n  let code;\n  for (let i = 0;i <= path.length; ++i) {\n    if (i < path.length) {\n      code = path.charCodeAt(i);\n    } else if (code === SLASH) {\n      break;\n    } else {\n      code = SLASH;\n    }\n    if (code === SLASH) {\n      if (lastSlash === i - 1 || dots === 1) {} else if (lastSlash !== i - 1 && dots === 2) {\n        if (res.length < 2 || lastSegmentLength !== 2 || res.charCodeAt(res.length - 1) !== DOT || res.charCodeAt(res.length - 2) !== DOT) {\n          if (res.length > 2) {\n            const lastSlashIndex = res.lastIndexOf(\"/\");\n            if (lastSlashIndex !== res.length - 1) {\n              if (lastSlashIndex === -1) {\n                res = \"\";\n                lastSegmentLength = 0;\n              } else {\n                res = res.slice(0, lastSlashIndex);\n                lastSegmentLength = res.length - 1 - res.lastIndexOf(\"/\");\n              }\n              lastSlash = i;\n              dots = 0;\n              continue;\n            }\n          } else if (res.length === 2 || res.length === 1) {\n            res = \"\";\n            lastSegmentLength = 0;\n            lastSlash = i;\n            dots = 0;\n            continue;\n          }\n        }\n        if (allowAboveRoot) {\n          if (res.length > 0) {\n            res += \"/..\";\n          } else {\n            res = \"..\";\n          }\n          lastSegmentLength = 2;\n        }\n      } else {\n        if (res.length > 0) {\n          res += \"/\" + path.slice(lastSlash + 1, i);\n        } else {\n          res = path.slice(lastSlash + 1, i);\n        }\n        lastSegmentLength = i - lastSlash - 1;\n      }\n      lastSlash = i;\n      dots = 0;\n    } else if (code === DOT && dots !== -1) {\n      ++dots;\n    } else {\n      dots = -1;\n    }\n  }\n  return res;\n};\nvar decode = (s) => {\n  try {\n    return decodeURIComponent(s);\n  } catch {\n    return s;\n  }\n};\nvar pathNormalize = (p) => {\n  assertPath(p);\n  let path = p;\n  if (path.length === 0) {\n    return \".\";\n  }\n  const isAbsolute = path.charCodeAt(0) === SLASH;\n  const trailingSeparator = path.charCodeAt(path.length - 1) === SLASH;\n  path = decode(path);\n  path = posixNormalize(path, !isAbsolute);\n  if (path.length === 0 && !isAbsolute) {\n    path = \".\";\n  }\n  if (path.length > 0 && trailingSeparator) {\n    path += \"/\";\n  }\n  if (isAbsolute) {\n    return \"/\" + path;\n  }\n  return path;\n};\n\n// src/get-extension-of-filename.ts\nvar getExtensionOfFilename = (filename) => {\n  if (filename === null) {\n    return null;\n  }\n  const filenameArr = pathNormalize(filename).split(\".\");\n  const hasExtension = filenameArr.length >= 2;\n  const filenameArrLength = filenameArr.length;\n  const extension = hasExtension ? filenameArr[filenameArrLength - 1] : null;\n  return extension;\n};\n\n// src/options/video-codec.tsx\nimport { jsx as jsx45, Fragment as Fragment45 } from \"react/jsx-runtime\";\nvar codec;\nvar setCodec = (newCodec) => {\n  if (newCodec === undefined) {\n    codec = undefined;\n    return;\n  }\n  if (!validCodecs.includes(newCodec)) {\n    throw new Error(`Codec must be one of the following: ${validCodecs.join(\", \")}, but got ${newCodec}`);\n  }\n  codec = newCodec;\n};\nvar getOutputCodecOrUndefined = () => {\n  return codec;\n};\nvar deriveCodecsFromFilename = (extension) => {\n  if (extension === null) {\n    return { possible: [], default: null };\n  }\n  return {\n    default: defaultCodecsForFileExtension[extension] ?? null,\n    possible: makeFileExtensionMap()[extension] ?? []\n  };\n};\nvar cliFlag50 = \"codec\";\nvar videoCodecOption = {\n  name: \"Codec\",\n  cliFlag: cliFlag50,\n  description: () => /* @__PURE__ */ jsx45(Fragment45, {\n    children: \"H264 works well in most cases, but sometimes it's worth going for a different codec. WebM achieves higher compression but is slower to render. WebM, GIF and ProRes support transparency.\"\n  }),\n  ssrName: \"codec\",\n  docLink: \"https://www.remotion.dev/docs/encoding/#choosing-a-codec\",\n  type: \"\",\n  getValue: ({ commandLine }, {\n    compositionCodec,\n    configFile,\n    downloadName,\n    outName,\n    uiCodec\n  }) => {\n    if (uiCodec) {\n      return { value: uiCodec, source: \"via UI\" };\n    }\n    const downloadNameExtension = getExtensionOfFilename(downloadName);\n    const outNameExtension = getExtensionOfFilename(outName);\n    const derivedDownloadCodecs = deriveCodecsFromFilename(downloadNameExtension);\n    const derivedOutNameCodecs = deriveCodecsFromFilename(outNameExtension);\n    if (derivedDownloadCodecs.possible.length > 0 && derivedOutNameCodecs.possible.length > 0 && derivedDownloadCodecs.possible.join(\"\") !== derivedOutNameCodecs.possible.join(\"\")) {\n      throw new TypeError(`The download name is ${downloadName} but the output name is ${outName}. The file extensions must match`);\n    }\n    const cliArgument = commandLine[cliFlag50];\n    if (cliArgument) {\n      if (derivedDownloadCodecs.possible.length > 0 && derivedDownloadCodecs.possible.indexOf(cliArgument) === -1) {\n        throw new TypeError(`The download name is ${downloadName} but --codec=${cliArgument} was passed. The download name implies a codec of ${derivedDownloadCodecs.possible.join(\" or \")} which does not align with the --codec flag.`);\n      }\n      if (derivedOutNameCodecs.possible.length > 0 && derivedOutNameCodecs.possible.indexOf(cliArgument) === -1) {\n        throw new TypeError(`The out name is ${outName} but --codec=${cliArgument} was passed. The out name implies a codec of ${derivedOutNameCodecs.possible.join(\" or \")} which does not align with the --codec flag.`);\n      }\n      return { value: cliArgument, source: \"from --codec flag\" };\n    }\n    if (derivedDownloadCodecs.possible.length > 0) {\n      return {\n        value: derivedDownloadCodecs.default,\n        source: \"derived from download name\"\n      };\n    }\n    if (derivedOutNameCodecs.possible.length > 0) {\n      if (compositionCodec && derivedOutNameCodecs.possible.includes(compositionCodec)) {\n        return {\n          value: compositionCodec,\n          source: \"derived from out name + compositionCodec from calculateMetadata\"\n        };\n      }\n      if (configFile && derivedOutNameCodecs.possible.includes(configFile)) {\n        return {\n          value: configFile,\n          source: \"derived from out name + config file\"\n        };\n      }\n      return {\n        value: derivedOutNameCodecs.default,\n        source: \"derived from out name\"\n      };\n    }\n    if (compositionCodec) {\n      return { value: compositionCodec, source: \"via calculateMetadata\" };\n    }\n    if (configFile) {\n      return {\n        value: configFile,\n        source: \"Config file\"\n      };\n    }\n    return { value: DEFAULT_CODEC, source: \"default\" };\n  },\n  setConfig: setCodec\n};\n\n// src/options/webhook-custom-data.tsx\nimport { jsxs as jsxs35, Fragment as Fragment46 } from \"react/jsx-runtime\";\nvar cliFlag51 = \"webhook-custom-data\";\nvar webhookCustomDataOption = {\n  name: \"Webhook custom data\",\n  cliFlag: cliFlag51,\n  description: (type) => /* @__PURE__ */ jsxs35(Fragment46, {\n    children: [\n      \"Pass up to 1,024 bytes of a JSON-serializable object to the webhook. This data will be included in the webhook payload.\",\n      \" \",\n      type === \"cli\" ? \"Alternatively, pass a file path pointing to a JSON file\" : null\n    ]\n  }),\n  ssrName: \"customData\",\n  docLink: \"https://www.remotion.dev/docs/lambda/webhooks\",\n  type: {},\n  getValue: () => {\n    throw new Error(\"Option resolution not implemented\");\n  },\n  setConfig: () => {\n    throw new Error(\"Not implemented\");\n  }\n};\n\n// src/options/x264-preset.tsx\nimport { jsx as jsx46, jsxs as jsxs36, Fragment as Fragment47 } from \"react/jsx-runtime\";\nvar x264PresetOptions = [\n  \"ultrafast\",\n  \"superfast\",\n  \"veryfast\",\n  \"faster\",\n  \"fast\",\n  \"medium\",\n  \"slow\",\n  \"slower\",\n  \"veryslow\",\n  \"placebo\"\n];\nvar preset = null;\nvar cliFlag52 = \"x264-preset\";\nvar DEFAULT_PRESET = \"medium\";\nvar x264Option = {\n  name: \"x264 Preset\",\n  cliFlag: cliFlag52,\n  description: () => /* @__PURE__ */ jsxs36(Fragment47, {\n    children: [\n      \"Sets a x264 preset profile. Only applies to videos rendered with\",\n      \" \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: \"h264\"\n      }),\n      \" codec.\",\n      /* @__PURE__ */ jsx46(\"br\", {}),\n      \"Possible values: \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: \"superfast\"\n      }),\n      \", \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: \"veryfast\"\n      }),\n      \",\",\n      \" \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: \"faster\"\n      }),\n      \", \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: \"fast\"\n      }),\n      \", \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: \"medium\"\n      }),\n      \",\",\n      \" \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: \"slow\"\n      }),\n      \", \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: \"slower\"\n      }),\n      \", \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: \"veryslow\"\n      }),\n      \",\",\n      \" \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: \"placebo\"\n      }),\n      \".\",\n      /* @__PURE__ */ jsx46(\"br\", {}),\n      \"Default: \",\n      /* @__PURE__ */ jsx46(\"code\", {\n        children: DEFAULT_PRESET\n      })\n    ]\n  }),\n  ssrName: \"x264Preset\",\n  docLink: \"https://www.remotion.dev/docs/renderer/render-media\",\n  type: \"fast\",\n  getValue: ({ commandLine }) => {\n    const value3 = commandLine[cliFlag52];\n    if (typeof value3 !== \"undefined\") {\n      return { value: value3, source: \"cli\" };\n    }\n    if (preset !== null) {\n      return { value: preset, source: \"config\" };\n    }\n    return { value: null, source: \"default\" };\n  },\n  setConfig: (profile) => {\n    preset = profile;\n  }\n};\n\n// src/options/index.tsx\nvar allOptions = {\n  audioCodecOption,\n  scaleOption,\n  crfOption,\n  jpegQualityOption,\n  videoBitrateOption,\n  audioBitrateOption,\n  enforceAudioOption,\n  mutedOption,\n  videoCodecOption,\n  offthreadVideoCacheSizeInBytesOption,\n  offthreadVideoThreadsOption,\n  webhookCustomDataOption,\n  colorSpaceOption,\n  deleteAfterOption,\n  disallowParallelEncodingOption,\n  folderExpiryOption,\n  enableMultiprocessOnLinuxOption,\n  glOption,\n  enableLambdaInsights,\n  encodingMaxRateOption,\n  encodingBufferSizeOption,\n  beepOnFinishOption,\n  numberOfGifLoopsOption,\n  reproOption,\n  preferLosslessOption: preferLosslessAudioOption,\n  x264Option,\n  logLevelOption,\n  delayRenderTimeoutInMillisecondsOption,\n  headlessOption,\n  overwriteOption,\n  binariesDirectoryOption,\n  forSeamlessAacConcatenationOption,\n  separateAudioOption,\n  publicPathOption,\n  publicDirOption,\n  onBrowserDownloadOption,\n  throwIfSiteExistsOption,\n  disableGitSourceOption,\n  metadataOption,\n  hardwareAccelerationOption,\n  chromeModeOption,\n  apiKeyOption,\n  licenseKeyOption,\n  audioLatencyHintOption,\n  enableCrossSiteIsolationOption,\n  imageSequencePatternOption,\n  mediaCacheSizeInBytesOption,\n  darkModeOption,\n  publicLicenseKeyOption,\n  askAIOption,\n  experimentalClientSideRenderingOption,\n  keyboardShortcutsOption\n};\n\n// src/options/options-map.ts\nvar optionsMap = {\n  renderMedia: {\n    mediaCacheSizeInBytes: mediaCacheSizeInBytesOption,\n    offthreadVideoCacheSizeInBytes: offthreadVideoCacheSizeInBytesOption,\n    offthreadVideoThreads: offthreadVideoThreadsOption,\n    videoBitrate: videoBitrateOption,\n    numberOfGifLoops: numberOfGifLoopsOption,\n    repro: reproOption,\n    x264Preset: x264Option,\n    audioBitrate: audioBitrateOption,\n    colorSpace: colorSpaceOption,\n    codec: videoCodecOption,\n    disallowParallelEncoding: disallowParallelEncodingOption,\n    jpegQuality: jpegQualityOption,\n    encodingMaxRate: encodingMaxRateOption,\n    encodingBufferSize: encodingBufferSizeOption,\n    muted: mutedOption,\n    logLevel: logLevelOption,\n    timeoutInMilliseconds: delayRenderTimeoutInMillisecondsOption,\n    binariesDirectory: binariesDirectoryOption,\n    forSeamlessAacConcatenation: forSeamlessAacConcatenationOption,\n    separateAudioTo: separateAudioOption,\n    audioCodec: audioCodecOption,\n    onBrowserDownload: onBrowserDownloadOption,\n    hardwareAcceleration: hardwareAccelerationOption,\n    chromeMode: chromeModeOption,\n    licenseKey: licenseKeyOption\n  },\n  stitchFramesToVideo: {\n    separateAudioTo: separateAudioOption,\n    hardwareAcceleration: hardwareAccelerationOption\n  },\n  renderStill: {\n    mediaCacheSizeInBytes: mediaCacheSizeInBytesOption,\n    offthreadVideoCacheSizeInBytes: offthreadVideoCacheSizeInBytesOption,\n    offthreadVideoThreads: offthreadVideoThreadsOption,\n    jpegQuality: jpegQualityOption,\n    logLevel: logLevelOption,\n    timeoutInMilliseconds: delayRenderTimeoutInMillisecondsOption,\n    binariesDirectory: binariesDirectoryOption,\n    onBrowserDownload: onBrowserDownloadOption,\n    chromeMode: chromeModeOption,\n    apiKey: apiKeyOption,\n    licenseKey: licenseKeyOption\n  },\n  getCompositions: {\n    mediaCacheSizeInBytes: mediaCacheSizeInBytesOption,\n    offthreadVideoCacheSizeInBytes: offthreadVideoCacheSizeInBytesOption,\n    offthreadVideoThreads: offthreadVideoThreadsOption,\n    logLevel: logLevelOption,\n    timeoutInMilliseconds: delayRenderTimeoutInMillisecondsOption,\n    binariesDirectory: binariesDirectoryOption,\n    onBrowserDownload: onBrowserDownloadOption,\n    chromeMode: chromeModeOption\n  },\n  selectComposition: {\n    mediaCacheSizeInBytes: mediaCacheSizeInBytesOption,\n    offthreadVideoCacheSizeInBytes: offthreadVideoCacheSizeInBytesOption,\n    offthreadVideoThreads: offthreadVideoThreadsOption,\n    logLevel: logLevelOption,\n    timeoutInMilliseconds: delayRenderTimeoutInMillisecondsOption,\n    binariesDirectory: binariesDirectoryOption,\n    onBrowserDownload: onBrowserDownloadOption,\n    chromeMode: chromeModeOption\n  },\n  renderFrames: {\n    mediaCacheSizeInBytes: mediaCacheSizeInBytesOption,\n    forSeamlessAacConcatenation: forSeamlessAacConcatenationOption,\n    offthreadVideoCacheSizeInBytes: offthreadVideoCacheSizeInBytesOption,\n    offthreadVideoThreads: offthreadVideoThreadsOption,\n    jpegQuality: jpegQualityOption,\n    logLevel: logLevelOption,\n    timeoutInMilliseconds: delayRenderTimeoutInMillisecondsOption,\n    binariesDirectory: binariesDirectoryOption,\n    onBrowserDownload: onBrowserDownloadOption,\n    chromeMode: chromeModeOption,\n    imageSequencePattern: imageSequencePatternOption\n  },\n  renderMediaOnLambda: {\n    mediaCacheSizeInBytes: mediaCacheSizeInBytesOption,\n    offthreadVideoCacheSizeInBytes: offthreadVideoCacheSizeInBytesOption,\n    offthreadVideoThreads: offthreadVideoThreadsOption,\n    videoBitrate: videoBitrateOption,\n    numberOfGifLoops: numberOfGifLoopsOption,\n    preferLossless: preferLosslessAudioOption,\n    audioBitrate: audioBitrateOption,\n    deleteAfter: deleteAfterOption,\n    x264Preset: x264Option,\n    encodingMaxRate: encodingMaxRateOption,\n    encodingBufferSize: encodingBufferSizeOption,\n    colorSpace: colorSpaceOption,\n    muted: mutedOption,\n    logLevel: logLevelOption,\n    timeoutInMilliseconds: delayRenderTimeoutInMillisecondsOption,\n    apiKey: apiKeyOption,\n    licenseKey: licenseKeyOption\n  },\n  renderStillOnLambda: {\n    mediaCacheSizeInBytes: mediaCacheSizeInBytesOption,\n    offthreadVideoCacheSizeInBytes: offthreadVideoCacheSizeInBytesOption,\n    offthreadVideoThreads: offthreadVideoThreadsOption,\n    jpegQuality: jpegQualityOption,\n    logLevel: logLevelOption,\n    deleteAfter: deleteAfterOption,\n    scale: scaleOption,\n    timeoutInMilliseconds: delayRenderTimeoutInMillisecondsOption,\n    apiKey: apiKeyOption,\n    licenseKey: licenseKeyOption\n  },\n  getCompositionsOnLambda: {\n    mediaCacheSizeInBytes: mediaCacheSizeInBytesOption,\n    offthreadVideoCacheSizeInBytes: offthreadVideoCacheSizeInBytesOption,\n    logLevel: logLevelOption,\n    timeoutInMilliseconds: delayRenderTimeoutInMillisecondsOption\n  },\n  renderMediaOnCloudRun: {\n    mediaCacheSizeInBytes: mediaCacheSizeInBytesOption,\n    offthreadVideoCacheSizeInBytes: offthreadVideoCacheSizeInBytesOption,\n    offthreadVideoThreads: offthreadVideoThreadsOption,\n    numberOfGifLoops: numberOfGifLoopsOption,\n    preferLossless: preferLosslessAudioOption,\n    colorSpace: colorSpaceOption,\n    audioBitrate: audioBitrateOption,\n    videoBitrate: videoBitrateOption,\n    x264Preset: x264Option,\n    encodingMaxRate: encodingMaxRateOption,\n    encodingBufferSize: encodingBufferSizeOption,\n    muted: mutedOption,\n    logLevel: logLevelOption,\n    delayRenderTimeoutInMilliseconds: delayRenderTimeoutInMillisecondsOption,\n    enforceAudioTrack: enforceAudioOption,\n    scale: scaleOption,\n    crf: crfOption,\n    jpegQuality: jpegQualityOption\n  },\n  renderStillOnCloudRun: {\n    mediaCacheSizeInBytes: mediaCacheSizeInBytesOption,\n    offthreadVideoCacheSizeInBytes: offthreadVideoCacheSizeInBytesOption,\n    offthreadVideoThreads: offthreadVideoThreadsOption,\n    logLevel: logLevelOption,\n    scale: scaleOption,\n    jpegQuality: jpegQualityOption,\n    delayRenderTimeoutInMilliseconds: delayRenderTimeoutInMillisecondsOption\n  },\n  ensureBrowser: {\n    logLevel: logLevelOption,\n    onBrowserDownload: onBrowserDownloadOption,\n    chromeMode: chromeModeOption\n  },\n  openBrowser: {\n    logLevel: logLevelOption,\n    onBrowserDownload: onBrowserDownloadOption,\n    chromeMode: chromeModeOption\n  },\n  deploySiteLambda: {\n    logLevel: logLevelOption,\n    throwIfSiteExists: throwIfSiteExistsOption\n  },\n  deploySiteCloudRun: {\n    logLevel: logLevelOption\n  }\n};\n\n// src/pixel-format.ts\nvar validPixelFormats = [\n  \"yuv420p\",\n  \"yuva420p\",\n  \"yuv422p\",\n  \"yuv444p\",\n  \"yuv420p10le\",\n  \"yuv422p10le\",\n  \"yuv444p10le\",\n  \"yuva444p10le\"\n];\nvar DEFAULT_PIXEL_FORMAT = \"yuv420p\";\nvar validPixelFormatsForCodec = (codec2) => {\n  if (codec2 === \"vp8\" || codec2 === \"vp9\") {\n    return validPixelFormats;\n  }\n  return validPixelFormats.filter((format) => format !== \"yuva420p\");\n};\n\n// src/validate-output-filename.ts\nvar validateOutputFilename = ({\n  codec: codec2,\n  audioCodecSetting,\n  extension,\n  preferLossless,\n  separateAudioTo\n}) => {\n  if (!defaultFileExtensionMap[codec2]) {\n    throw new TypeError(`The codec \"${codec2}\" is not supported. Supported codecs are: ${Object.keys(defaultFileExtensionMap).join(\", \")}`);\n  }\n  const map = defaultFileExtensionMap[codec2];\n  const resolvedAudioCodec = resolveAudioCodec({\n    codec: codec2,\n    preferLossless,\n    setting: audioCodecSetting,\n    separateAudioTo\n  });\n  if (resolvedAudioCodec === null) {\n    if (extension !== map.default) {\n      throw new TypeError(`When using the ${codec2} codec, the output filename must end in .${map.default}.`);\n    }\n    return;\n  }\n  if (!(resolvedAudioCodec in map.forAudioCodec)) {\n    throw new Error(`Audio codec ${resolvedAudioCodec} is not supported for codec ${codec2}`);\n  }\n  const acceptableExtensions = map.forAudioCodec[resolvedAudioCodec].possible;\n  if (!acceptableExtensions.includes(extension) && !separateAudioTo) {\n    throw new TypeError(`When using the ${codec2} codec with the ${resolvedAudioCodec} audio codec, the output filename must end in one of the following: ${acceptableExtensions.join(\", \")}.`);\n  }\n};\n\n// src/client.ts\nvar BrowserSafeApis = {\n  getFileExtensionFromCodec,\n  validCodecs,\n  validAudioCodecs,\n  getDefaultCrfForCodec,\n  getValidCrfRanges,\n  proResProfileOptions: NoReactInternals2.proResProfileOptions,\n  x264PresetOptions,\n  hardwareAccelerationOptions,\n  validPixelFormats,\n  validOpenGlRenderers,\n  validPixelFormatsForCodec,\n  validVideoImageFormats,\n  validStillImageFormats,\n  DEFAULT_PIXEL_FORMAT,\n  DEFAULT_TIMEOUT,\n  DEFAULT_JPEG_QUALITY,\n  DEFAULT_COLOR_SPACE,\n  supportedAudioCodecs,\n  defaultFileExtensionMap,\n  defaultAudioCodecs,\n  defaultCodecsForFileExtension,\n  validateOutputFilename,\n  options: allOptions,\n  validColorSpaces,\n  optionsMap,\n  codecSupportsCrf,\n  codecSupportsVideoBitrate,\n  logLevels,\n  getOutputCodecOrUndefined,\n  getExtensionFromAudioCodec,\n  validChromeModeOptions\n};\nexport {\n  BrowserSafeApis\n};\n","// src/is-audio-codec.ts\nvar isAudioCodec = (codec) => {\n  return codec === \"mp3\" || codec === \"aac\" || codec === \"wav\";\n};\n\n// src/codec-supports-media.ts\nvar support = {\n  \"h264-mkv\": {\n    audio: true,\n    video: true\n  },\n  aac: {\n    audio: true,\n    video: false\n  },\n  gif: {\n    video: true,\n    audio: false\n  },\n  h264: {\n    video: true,\n    audio: true\n  },\n  \"h264-ts\": {\n    video: true,\n    audio: true\n  },\n  h265: {\n    video: true,\n    audio: true\n  },\n  mp3: {\n    audio: true,\n    video: false\n  },\n  prores: {\n    audio: true,\n    video: true\n  },\n  vp8: {\n    audio: true,\n    video: true\n  },\n  vp9: {\n    audio: true,\n    video: true\n  },\n  wav: {\n    audio: true,\n    video: false\n  }\n};\nvar codecSupportsMedia = (codec) => {\n  return support[codec];\n};\n\n// src/get-duration-from-frame-range.ts\nvar getFramesToRender = (frameRange, everyNthFrame) => {\n  if (everyNthFrame === 0) {\n    throw new Error(\"everyNthFrame cannot be 0\");\n  }\n  return new Array(frameRange[1] - frameRange[0] + 1).fill(true).map((_, index) => {\n    return index + frameRange[0];\n  }).filter((index) => {\n    return index % everyNthFrame === 0;\n  });\n};\n\n// src/codec.ts\nvar validCodecs = [\n  \"h264\",\n  \"h265\",\n  \"vp8\",\n  \"vp9\",\n  \"mp3\",\n  \"aac\",\n  \"wav\",\n  \"prores\",\n  \"h264-mkv\",\n  \"h264-ts\",\n  \"gif\"\n];\n\n// src/file-extensions.ts\nvar defaultFileExtensionMap = {\n  \"h264-mkv\": {\n    default: \"mkv\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"mkv\"], default: \"mkv\" },\n      mp3: { possible: [\"mkv\"], default: \"mkv\" }\n    }\n  },\n  \"h264-ts\": {\n    default: \"ts\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"ts\"], default: \"ts\" },\n      aac: { possible: [\"ts\"], default: \"ts\" }\n    }\n  },\n  aac: {\n    default: \"aac\",\n    forAudioCodec: {\n      aac: {\n        possible: [\"aac\", \"3gp\", \"m4a\", \"m4b\", \"mpg\", \"mpeg\"],\n        default: \"aac\"\n      },\n      \"pcm-16\": {\n        possible: [\"wav\"],\n        default: \"wav\"\n      }\n    }\n  },\n  gif: {\n    default: \"gif\",\n    forAudioCodec: {}\n  },\n  h264: {\n    default: \"mp4\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"mkv\", \"mov\"], default: \"mkv\" },\n      aac: { possible: [\"mp4\", \"mkv\", \"mov\"], default: \"mp4\" },\n      mp3: { possible: [\"mp4\", \"mkv\", \"mov\"], default: \"mp4\" }\n    }\n  },\n  h265: {\n    default: \"mp4\",\n    forAudioCodec: {\n      aac: { possible: [\"mp4\", \"mkv\", \"hevc\"], default: \"mp4\" },\n      \"pcm-16\": { possible: [\"mkv\"], default: \"mkv\" }\n    }\n  },\n  mp3: {\n    default: \"mp3\",\n    forAudioCodec: {\n      mp3: { possible: [\"mp3\"], default: \"mp3\" },\n      \"pcm-16\": { possible: [\"wav\"], default: \"wav\" }\n    }\n  },\n  prores: {\n    default: \"mov\",\n    forAudioCodec: {\n      aac: { possible: [\"mov\", \"mkv\", \"mxf\"], default: \"mov\" },\n      \"pcm-16\": { possible: [\"mov\", \"mkv\", \"mxf\"], default: \"mov\" }\n    }\n  },\n  vp8: {\n    default: \"webm\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"mkv\"], default: \"mkv\" },\n      opus: { possible: [\"webm\"], default: \"webm\" }\n    }\n  },\n  vp9: {\n    default: \"webm\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"mkv\"], default: \"mkv\" },\n      opus: { possible: [\"webm\"], default: \"webm\" }\n    }\n  },\n  wav: {\n    default: \"wav\",\n    forAudioCodec: {\n      \"pcm-16\": { possible: [\"wav\"], default: \"wav\" }\n    }\n  }\n};\n\n// src/get-extension-from-codec.ts\nvar getFileExtensionFromCodec = (codec, audioCodec) => {\n  if (!validCodecs.includes(codec)) {\n    throw new Error(`Codec must be one of the following: ${validCodecs.join(\", \")}, but got ${codec}`);\n  }\n  const map = defaultFileExtensionMap[codec];\n  if (audioCodec === null) {\n    return map.default;\n  }\n  const typedAudioCodec = audioCodec;\n  if (!(typedAudioCodec in map.forAudioCodec)) {\n    throw new Error(`Audio codec ${typedAudioCodec} is not supported for codec ${codec}`);\n  }\n  return map.forAudioCodec[audioCodec].default;\n};\n\n// src/path-normalize.ts\nvar SLASH = 47;\nvar DOT = 46;\nvar assertPath = (path) => {\n  const t = typeof path;\n  if (t !== \"string\") {\n    throw new TypeError(`Expected a string, got a ${t}`);\n  }\n};\nvar posixNormalize = (path, allowAboveRoot) => {\n  let res = \"\";\n  let lastSegmentLength = 0;\n  let lastSlash = -1;\n  let dots = 0;\n  let code;\n  for (let i = 0;i <= path.length; ++i) {\n    if (i < path.length) {\n      code = path.charCodeAt(i);\n    } else if (code === SLASH) {\n      break;\n    } else {\n      code = SLASH;\n    }\n    if (code === SLASH) {\n      if (lastSlash === i - 1 || dots === 1) {} else if (lastSlash !== i - 1 && dots === 2) {\n        if (res.length < 2 || lastSegmentLength !== 2 || res.charCodeAt(res.length - 1) !== DOT || res.charCodeAt(res.length - 2) !== DOT) {\n          if (res.length > 2) {\n            const lastSlashIndex = res.lastIndexOf(\"/\");\n            if (lastSlashIndex !== res.length - 1) {\n              if (lastSlashIndex === -1) {\n                res = \"\";\n                lastSegmentLength = 0;\n              } else {\n                res = res.slice(0, lastSlashIndex);\n                lastSegmentLength = res.length - 1 - res.lastIndexOf(\"/\");\n              }\n              lastSlash = i;\n              dots = 0;\n              continue;\n            }\n          } else if (res.length === 2 || res.length === 1) {\n            res = \"\";\n            lastSegmentLength = 0;\n            lastSlash = i;\n            dots = 0;\n            continue;\n          }\n        }\n        if (allowAboveRoot) {\n          if (res.length > 0) {\n            res += \"/..\";\n          } else {\n            res = \"..\";\n          }\n          lastSegmentLength = 2;\n        }\n      } else {\n        if (res.length > 0) {\n          res += \"/\" + path.slice(lastSlash + 1, i);\n        } else {\n          res = path.slice(lastSlash + 1, i);\n        }\n        lastSegmentLength = i - lastSlash - 1;\n      }\n      lastSlash = i;\n      dots = 0;\n    } else if (code === DOT && dots !== -1) {\n      ++dots;\n    } else {\n      dots = -1;\n    }\n  }\n  return res;\n};\nvar decode = (s) => {\n  try {\n    return decodeURIComponent(s);\n  } catch {\n    return s;\n  }\n};\nvar pathNormalize = (p) => {\n  assertPath(p);\n  let path = p;\n  if (path.length === 0) {\n    return \".\";\n  }\n  const isAbsolute = path.charCodeAt(0) === SLASH;\n  const trailingSeparator = path.charCodeAt(path.length - 1) === SLASH;\n  path = decode(path);\n  path = posixNormalize(path, !isAbsolute);\n  if (path.length === 0 && !isAbsolute) {\n    path = \".\";\n  }\n  if (path.length > 0 && trailingSeparator) {\n    path += \"/\";\n  }\n  if (isAbsolute) {\n    return \"/\" + path;\n  }\n  return path;\n};\n\n// src/get-extension-of-filename.ts\nvar getExtensionOfFilename = (filename) => {\n  if (filename === null) {\n    return null;\n  }\n  const filenameArr = pathNormalize(filename).split(\".\");\n  const hasExtension = filenameArr.length >= 2;\n  const filenameArrLength = filenameArr.length;\n  const extension = hasExtension ? filenameArr[filenameArrLength - 1] : null;\n  return extension;\n};\n\n// src/options/separate-audio.tsx\nvar DEFAULT = null;\nvar cliFlag = \"separate-audio-to\";\nvar separateAudioOption = {\n  cliFlag,\n  description: () => `If set, the audio will not be included in the main output but rendered as a separate file at the location you pass. It is recommended to use an absolute path. If a relative path is passed, it is relative to the Remotion Root.`,\n  docLink: \"https://remotion.dev/docs/renderer/render-media\",\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag]) {\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag]\n      };\n    }\n    return {\n      source: \"default\",\n      value: DEFAULT\n    };\n  },\n  name: \"Separate audio to\",\n  setConfig: () => {\n    throw new Error(\"Not implemented\");\n  },\n  ssrName: \"separateAudioTo\",\n  type: \"string\"\n};\n\n// src/options/audio-codec.tsx\nvar validAudioCodecs = [\"pcm-16\", \"aac\", \"mp3\", \"opus\"];\nvar supportedAudioCodecs = {\n  h264: [\"aac\", \"pcm-16\", \"mp3\"],\n  \"h264-mkv\": [\"pcm-16\", \"mp3\"],\n  \"h264-ts\": [\"pcm-16\", \"aac\"],\n  aac: [\"aac\", \"pcm-16\"],\n  avi: [],\n  gif: [],\n  h265: [\"aac\", \"pcm-16\"],\n  mp3: [\"mp3\", \"pcm-16\"],\n  prores: [\"aac\", \"pcm-16\"],\n  vp8: [\"opus\", \"pcm-16\"],\n  vp9: [\"opus\", \"pcm-16\"],\n  wav: [\"pcm-16\"]\n};\nvar _satisfies = supportedAudioCodecs;\nif (_satisfies) {}\nvar cliFlag2 = \"audio-codec\";\nvar ssrName = \"audioCodec\";\nvar defaultAudioCodecs = {\n  \"h264-mkv\": {\n    lossless: \"pcm-16\",\n    compressed: \"pcm-16\"\n  },\n  \"h264-ts\": {\n    lossless: \"pcm-16\",\n    compressed: \"aac\"\n  },\n  aac: {\n    lossless: \"pcm-16\",\n    compressed: \"aac\"\n  },\n  gif: {\n    lossless: null,\n    compressed: null\n  },\n  h264: {\n    lossless: \"pcm-16\",\n    compressed: \"aac\"\n  },\n  h265: {\n    lossless: \"pcm-16\",\n    compressed: \"aac\"\n  },\n  mp3: {\n    lossless: \"pcm-16\",\n    compressed: \"mp3\"\n  },\n  prores: {\n    lossless: \"pcm-16\",\n    compressed: \"pcm-16\"\n  },\n  vp8: {\n    lossless: \"pcm-16\",\n    compressed: \"opus\"\n  },\n  vp9: {\n    lossless: \"pcm-16\",\n    compressed: \"opus\"\n  },\n  wav: {\n    lossless: \"pcm-16\",\n    compressed: \"pcm-16\"\n  }\n};\nvar extensionMap = {\n  aac: \"aac\",\n  mp3: \"mp3\",\n  opus: \"opus\",\n  \"pcm-16\": \"wav\"\n};\nvar resolveAudioCodec = ({\n  codec,\n  setting,\n  preferLossless,\n  separateAudioTo\n}) => {\n  let derivedFromSeparateAudioToExtension = null;\n  if (separateAudioTo) {\n    const extension = separateAudioTo.split(\".\").pop();\n    for (const [key, value] of Object.entries(extensionMap)) {\n      if (value === extension) {\n        derivedFromSeparateAudioToExtension = key;\n        if (!supportedAudioCodecs[codec].includes(derivedFromSeparateAudioToExtension) && derivedFromSeparateAudioToExtension) {\n          throw new Error(`The codec is ${codec} but the audio codec derived from --${separateAudioOption.cliFlag} is ${derivedFromSeparateAudioToExtension}. The only supported codecs are: ${supportedAudioCodecs[codec].join(\", \")}`);\n        }\n      }\n    }\n  }\n  if (preferLossless) {\n    const selected = getDefaultAudioCodec({ codec, preferLossless });\n    if (derivedFromSeparateAudioToExtension && selected !== derivedFromSeparateAudioToExtension) {\n      throw new Error(`The audio codec derived from --${separateAudioOption.cliFlag} is ${derivedFromSeparateAudioToExtension}, but does not match the audio codec derived from the \"Prefer lossless\" option (${selected}). Remove any conflicting options.`);\n    }\n    return selected;\n  }\n  if (setting === null) {\n    if (derivedFromSeparateAudioToExtension) {\n      return derivedFromSeparateAudioToExtension;\n    }\n    return getDefaultAudioCodec({ codec, preferLossless });\n  }\n  if (derivedFromSeparateAudioToExtension !== setting && derivedFromSeparateAudioToExtension) {\n    throw new Error(`The audio codec derived from --${separateAudioOption.cliFlag} is ${derivedFromSeparateAudioToExtension}, but does not match the audio codec derived from your ${audioCodecOption.name} setting (${setting}). Remove any conflicting options.`);\n  }\n  return setting;\n};\nvar getDefaultAudioCodec = ({\n  codec,\n  preferLossless\n}) => {\n  return defaultAudioCodecs[codec][preferLossless ? \"lossless\" : \"compressed\"];\n};\nvar _audioCodec = null;\nvar audioCodecOption = {\n  cliFlag: cliFlag2,\n  setConfig: (audioCodec) => {\n    if (audioCodec === null) {\n      _audioCodec = null;\n      return;\n    }\n    if (!validAudioCodecs.includes(audioCodec)) {\n      throw new Error(`Audio codec must be one of the following: ${validAudioCodecs.join(\", \")}, but got ${audioCodec}`);\n    }\n    _audioCodec = audioCodec;\n  },\n  getValue: ({ commandLine }) => {\n    if (commandLine[cliFlag2]) {\n      const codec = commandLine[cliFlag2];\n      if (!validAudioCodecs.includes(commandLine[cliFlag2])) {\n        throw new Error(`Audio codec must be one of the following: ${validAudioCodecs.join(\", \")}, but got ${codec}`);\n      }\n      return {\n        source: \"cli\",\n        value: commandLine[cliFlag2]\n      };\n    }\n    if (_audioCodec !== null) {\n      return {\n        source: \"config\",\n        value: _audioCodec\n      };\n    }\n    return {\n      source: \"default\",\n      value: null\n    };\n  },\n  description: () => `Set the format of the audio that is embedded in the video. Not all codec and audio codec combinations are supported and certain combinations require a certain file extension and container format. See the table in the docs to see possible combinations.`,\n  docLink: \"https://www.remotion.dev/docs/encoding/#audio-codec\",\n  name: \"Audio Codec\",\n  ssrName,\n  type: \"aac\"\n};\n\n// src/validate-output-filename.ts\nvar validateOutputFilename = ({\n  codec,\n  audioCodecSetting,\n  extension,\n  preferLossless,\n  separateAudioTo\n}) => {\n  if (!defaultFileExtensionMap[codec]) {\n    throw new TypeError(`The codec \"${codec}\" is not supported. Supported codecs are: ${Object.keys(defaultFileExtensionMap).join(\", \")}`);\n  }\n  const map = defaultFileExtensionMap[codec];\n  const resolvedAudioCodec = resolveAudioCodec({\n    codec,\n    preferLossless,\n    setting: audioCodecSetting,\n    separateAudioTo\n  });\n  if (resolvedAudioCodec === null) {\n    if (extension !== map.default) {\n      throw new TypeError(`When using the ${codec} codec, the output filename must end in .${map.default}.`);\n    }\n    return;\n  }\n  if (!(resolvedAudioCodec in map.forAudioCodec)) {\n    throw new Error(`Audio codec ${resolvedAudioCodec} is not supported for codec ${codec}`);\n  }\n  const acceptableExtensions = map.forAudioCodec[resolvedAudioCodec].possible;\n  if (!acceptableExtensions.includes(extension) && !separateAudioTo) {\n    throw new TypeError(`When using the ${codec} codec with the ${resolvedAudioCodec} audio codec, the output filename must end in one of the following: ${acceptableExtensions.join(\", \")}.`);\n  }\n};\n\n// src/pure.ts\nvar NoReactAPIs = {\n  getExtensionOfFilename,\n  getFileExtensionFromCodec,\n  validateOutputFilename,\n  getFramesToRender,\n  codecSupportsMedia,\n  isAudioCodec\n};\nexport {\n  NoReactAPIs\n};\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { AsyncMutex } from './misc.js';\nexport class Muxer {\n    constructor(output) {\n        this.mutex = new AsyncMutex();\n        /**\n         * This field is used to synchronize multiple MediaStreamTracks. They use the same time coordinate system across\n         * tracks, and to ensure correct audio-video sync, we must use the same offset for all of them. The reason an offset\n         * is needed at all is because the timestamps typically don't start at zero.\n         */\n        this.firstMediaStreamTimestamp = null;\n        this.trackTimestampInfo = new WeakMap();\n        this.output = output;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    onTrackClose(track) { }\n    validateAndNormalizeTimestamp(track, timestampInSeconds, isKeyPacket) {\n        timestampInSeconds += track.source._timestampOffset;\n        let timestampInfo = this.trackTimestampInfo.get(track);\n        if (!timestampInfo) {\n            if (!isKeyPacket) {\n                throw new Error('First packet must be a key packet.');\n            }\n            timestampInfo = {\n                maxTimestamp: timestampInSeconds,\n                maxTimestampBeforeLastKeyPacket: timestampInSeconds,\n            };\n            this.trackTimestampInfo.set(track, timestampInfo);\n        }\n        if (timestampInSeconds < 0) {\n            throw new Error(`Timestamps must be non-negative (got ${timestampInSeconds}s).`);\n        }\n        if (isKeyPacket) {\n            timestampInfo.maxTimestampBeforeLastKeyPacket = timestampInfo.maxTimestamp;\n        }\n        if (timestampInSeconds < timestampInfo.maxTimestampBeforeLastKeyPacket) {\n            throw new Error(`Timestamps cannot be smaller than the largest timestamp of the previous GOP (a GOP begins with a key`\n                + ` packet and ends right before the next key packet). Got ${timestampInSeconds}s, but largest`\n                + ` timestamp is ${timestampInfo.maxTimestampBeforeLastKeyPacket}s.`);\n        }\n        timestampInfo.maxTimestamp = Math.max(timestampInfo.maxTimestamp, timestampInSeconds);\n        return timestampInSeconds;\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { Bitstream } from '../misc.js';\nexport const buildAdtsHeaderTemplate = (config) => {\n    const header = new Uint8Array(7);\n    const bitstream = new Bitstream(header);\n    const { objectType, frequencyIndex, channelConfiguration } = config;\n    const profile = objectType - 1;\n    bitstream.writeBits(12, 0b1111_11111111); // Syncword\n    bitstream.writeBits(1, 0); // MPEG Version\n    bitstream.writeBits(2, 0); // Layer\n    bitstream.writeBits(1, 1); // Protection absence\n    bitstream.writeBits(2, profile); // Profile\n    bitstream.writeBits(4, frequencyIndex); // MPEG-4 Sampling Frequency Index\n    bitstream.writeBits(1, 0); // Private bit\n    bitstream.writeBits(3, channelConfiguration); // MPEG-4 Channel Configuration\n    bitstream.writeBits(1, 0); // Originality\n    bitstream.writeBits(1, 0); // Home\n    bitstream.writeBits(1, 0); // Copyright ID bit\n    bitstream.writeBits(1, 0); // Copyright ID start\n    bitstream.skipBits(13); // Frame length (to be filled per packet)\n    bitstream.writeBits(11, 0x7ff); // Buffer fullness\n    bitstream.writeBits(2, 0); // Number of AAC frames minus 1\n    // Omit CRC check\n    return { header, bitstream };\n};\nexport const writeAdtsFrameLength = (bitstream, frameLength) => {\n    bitstream.pos = 30;\n    bitstream.writeBits(13, frameLength);\n};\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { parseAacAudioSpecificConfig, validateAudioChunkMetadata } from '../codec.js';\nimport { assert, toUint8Array } from '../misc.js';\nimport { Muxer } from '../muxer.js';\nimport { buildAdtsHeaderTemplate, writeAdtsFrameLength } from './adts-misc.js';\nexport class AdtsMuxer extends Muxer {\n    constructor(output, format) {\n        super(output);\n        this.header = null;\n        this.headerBitstream = null;\n        this.inputIsAdts = null;\n        this.format = format;\n        this.writer = output._writer;\n    }\n    async start() {\n        // Nothing needed here\n    }\n    async getMimeType() {\n        return 'audio/aac';\n    }\n    async addEncodedVideoPacket() {\n        throw new Error('ADTS does not support video.');\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === 'key');\n            // First packet - determine input format from metadata\n            if (this.inputIsAdts === null) {\n                validateAudioChunkMetadata(meta);\n                const description = meta?.decoderConfig?.description;\n                // From the WebCodecs Codec Registry:\n                // \"If description is present, it is assumed to a AudioSpecificConfig as defined in [iso14496-3] section\n                // 1.6.2.1, Table 1.15, and the bitstream is assumed to be in aac.\n                // If the description is not present, the bitstream is assumed to be in adts format.\"\n                this.inputIsAdts = !description;\n                if (!this.inputIsAdts) {\n                    const config = parseAacAudioSpecificConfig(toUint8Array(description));\n                    const template = buildAdtsHeaderTemplate(config);\n                    this.header = template.header;\n                    this.headerBitstream = template.bitstream;\n                }\n            }\n            if (this.inputIsAdts) {\n                // Packets are already ADTS frames, write them directly\n                const startPos = this.writer.getPos();\n                this.writer.write(packet.data);\n                if (this.format._options.onFrame) {\n                    this.format._options.onFrame(packet.data, startPos);\n                }\n            }\n            else {\n                assert(this.header);\n                // Packets are raw AAC, we gotta turn it into ADTS\n                const frameLength = packet.data.byteLength + this.header.byteLength;\n                writeAdtsFrameLength(this.headerBitstream, frameLength);\n                const startPos = this.writer.getPos();\n                this.writer.write(this.header);\n                this.writer.write(packet.data);\n                if (this.format._options.onFrame) {\n                    const frameBytes = new Uint8Array(frameLength);\n                    frameBytes.set(this.header, 0);\n                    frameBytes.set(packet.data, this.header.byteLength);\n                    this.format._options.onFrame(frameBytes, startPos);\n                }\n            }\n            await this.writer.flush();\n        }\n        finally {\n            release();\n        }\n    }\n    async addSubtitleCue() {\n        throw new Error('ADTS does not support subtitles.');\n    }\n    async finalize() { }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { validateAudioChunkMetadata } from '../codec.js';\nimport { createVorbisComments, FlacBlockType } from '../codec-data.js';\nimport { assert, Bitstream, textEncoder, toDataView, toUint8Array, } from '../misc.js';\nimport { Muxer } from '../muxer.js';\nimport { FileSlice, readBytes } from '../reader.js';\nimport { metadataTagsAreEmpty } from '../metadata.js';\nimport { readBlockSize, getBlockSizeOrUncommon, readCodedNumber, } from './flac-misc.js';\nconst FLAC_HEADER = /* #__PURE__ */ new Uint8Array([0x66, 0x4c, 0x61, 0x43]); // 'fLaC'\nconst STREAMINFO_SIZE = 38;\nconst STREAMINFO_BLOCK_SIZE = 34;\nexport class FlacMuxer extends Muxer {\n    constructor(output, format) {\n        super(output);\n        this.metadataWritten = false;\n        this.blockSizes = [];\n        this.frameSizes = [];\n        this.sampleRate = null;\n        this.channels = null;\n        this.bitsPerSample = null;\n        this.writer = output._writer;\n        this.format = format;\n    }\n    async start() {\n        this.writer.write(FLAC_HEADER);\n    }\n    writeHeader({ bitsPerSample, minimumBlockSize, maximumBlockSize, minimumFrameSize, maximumFrameSize, sampleRate, channels, totalSamples, }) {\n        assert(this.writer.getPos() === 4);\n        const hasMetadata = !metadataTagsAreEmpty(this.output._metadataTags);\n        const headerBitstream = new Bitstream(new Uint8Array(4));\n        headerBitstream.writeBits(1, Number(!hasMetadata)); // isLastMetadata\n        headerBitstream.writeBits(7, FlacBlockType.STREAMINFO); // metaBlockType = streaminfo\n        headerBitstream.writeBits(24, STREAMINFO_BLOCK_SIZE); // size\n        this.writer.write(headerBitstream.bytes);\n        const contentBitstream = new Bitstream(new Uint8Array(18));\n        contentBitstream.writeBits(16, minimumBlockSize);\n        contentBitstream.writeBits(16, maximumBlockSize);\n        contentBitstream.writeBits(24, minimumFrameSize);\n        contentBitstream.writeBits(24, maximumFrameSize);\n        contentBitstream.writeBits(20, sampleRate);\n        contentBitstream.writeBits(3, channels - 1);\n        contentBitstream.writeBits(5, bitsPerSample - 1);\n        // Bitstream operations are only safe until 32bit, breaks when using 36 bits\n        // Splitting up into writing 4 0 bits and then 32 bits is safe\n        // This is safe for audio up to (2 ** 32 / 44100 / 3600) -> 27 hours\n        // Not implementing support for more than 32 bits now\n        if (totalSamples >= 2 ** 32) {\n            throw new Error('This muxer only supports writing up to 2 ** 32 samples');\n        }\n        contentBitstream.writeBits(4, 0);\n        contentBitstream.writeBits(32, totalSamples);\n        this.writer.write(contentBitstream.bytes);\n        // The MD5 hash is calculated from decoded audio data, but we do not have access\n        // to it here. We are allowed to set 0:\n        // \"A value of 0 signifies that the value is not known.\"\n        // https://www.rfc-editor.org/rfc/rfc9639.html#name-streaminfo\n        this.writer.write(new Uint8Array(16));\n    }\n    writePictureBlock(picture) {\n        // Header size:\n        // 4 bytes: picture type\n        // 4 bytes: media type length\n        // x bytes: media type\n        // 4 bytes: description length\n        // y bytes: description\n        // 1 bytes: width\n        // 1 bytes: height\n        // 1 bytes: color depth\n        // 1 bytes: number of indexed colors\n        // 4 bytes: picture data length\n        // z bytes: picture data\n        // Total: 20 + x + y + z\n        const headerSize = 32\n            + picture.mimeType.length\n            + (picture.description?.length ?? 0)\n            + picture.data.length;\n        const header = new Uint8Array(headerSize);\n        let offset = 0;\n        const dataView = toDataView(header);\n        dataView.setUint32(offset, picture.kind === 'coverFront' ? 3 : picture.kind === 'coverBack' ? 4 : 0);\n        offset += 4;\n        dataView.setUint32(offset, picture.mimeType.length);\n        offset += 4;\n        header.set(textEncoder.encode(picture.mimeType), 8);\n        offset += picture.mimeType.length;\n        dataView.setUint32(offset, picture.description?.length ?? 0);\n        offset += 4;\n        header.set(textEncoder.encode(picture.description ?? ''), offset);\n        offset += picture.description?.length ?? 0;\n        offset += 4 + 4 + 4 + 4; // setting width, height, color depth, number of indexed colors to 0\n        dataView.setUint32(offset, picture.data.length);\n        offset += 4;\n        header.set(picture.data, offset);\n        offset += picture.data.length;\n        assert(offset === headerSize);\n        const headerBitstream = new Bitstream(new Uint8Array(4));\n        headerBitstream.writeBits(1, 0); // Last metadata block -> false, will be continued by vorbis comment\n        headerBitstream.writeBits(7, FlacBlockType.PICTURE); // Type -> Picture\n        headerBitstream.writeBits(24, headerSize);\n        this.writer.write(headerBitstream.bytes);\n        this.writer.write(header);\n    }\n    writeVorbisCommentAndPictureBlock() {\n        this.writer.seek(STREAMINFO_SIZE + FLAC_HEADER.byteLength);\n        if (metadataTagsAreEmpty(this.output._metadataTags)) {\n            this.metadataWritten = true;\n            return;\n        }\n        const pictures = this.output._metadataTags.images ?? [];\n        for (const picture of pictures) {\n            this.writePictureBlock(picture);\n        }\n        const vorbisComment = createVorbisComments(new Uint8Array(0), this.output._metadataTags, false);\n        const headerBitstream = new Bitstream(new Uint8Array(4));\n        headerBitstream.writeBits(1, 1); // Last metadata block -> true\n        headerBitstream.writeBits(7, FlacBlockType.VORBIS_COMMENT); // Type -> Vorbis comment\n        headerBitstream.writeBits(24, vorbisComment.length);\n        this.writer.write(headerBitstream.bytes);\n        this.writer.write(vorbisComment);\n        this.metadataWritten = true;\n    }\n    async getMimeType() {\n        return 'audio/flac';\n    }\n    async addEncodedVideoPacket() {\n        throw new Error('FLAC does not support video.');\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n        const release = await this.mutex.acquire();\n        validateAudioChunkMetadata(meta);\n        assert(meta);\n        assert(meta.decoderConfig);\n        assert(meta.decoderConfig.description);\n        try {\n            this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === 'key');\n            if (this.sampleRate === null) {\n                this.sampleRate = meta.decoderConfig.sampleRate;\n            }\n            if (this.channels === null) {\n                this.channels = meta.decoderConfig.numberOfChannels;\n            }\n            if (this.bitsPerSample === null) {\n                const descriptionBitstream = new Bitstream(toUint8Array(meta.decoderConfig.description));\n                // skip 'fLaC' + block size + frame size + sample rate + number of channels\n                // See demuxer for the exact structure\n                descriptionBitstream.skipBits(103 + 64);\n                const bitsPerSample = descriptionBitstream.readBits(5) + 1;\n                this.bitsPerSample = bitsPerSample;\n            }\n            if (!this.metadataWritten) {\n                this.writeVorbisCommentAndPictureBlock();\n            }\n            const slice = FileSlice.tempFromBytes(packet.data);\n            readBytes(slice, 2);\n            const bytes = readBytes(slice, 2);\n            const bitstream = new Bitstream(bytes);\n            const blockSizeOrUncommon = getBlockSizeOrUncommon(bitstream.readBits(4));\n            if (blockSizeOrUncommon === null) {\n                throw new Error('Invalid FLAC frame: Invalid block size.');\n            }\n            readCodedNumber(slice); // num\n            const blockSize = readBlockSize(slice, blockSizeOrUncommon);\n            this.blockSizes.push(blockSize);\n            this.frameSizes.push(packet.data.length);\n            const startPos = this.writer.getPos();\n            this.writer.write(packet.data);\n            if (this.format._options.onFrame) {\n                this.format._options.onFrame(packet.data, startPos);\n            }\n            await this.writer.flush();\n        }\n        finally {\n            release();\n        }\n    }\n    addSubtitleCue() {\n        throw new Error('FLAC does not support subtitles.');\n    }\n    async finalize() {\n        const release = await this.mutex.acquire();\n        let minimumBlockSize = Infinity;\n        let maximumBlockSize = 0;\n        let minimumFrameSize = Infinity;\n        let maximumFrameSize = 0;\n        let totalSamples = 0;\n        for (let i = 0; i < this.blockSizes.length; i++) {\n            minimumFrameSize = Math.min(minimumFrameSize, this.frameSizes[i]);\n            maximumFrameSize = Math.max(maximumFrameSize, this.frameSizes[i]);\n            maximumBlockSize = Math.max(maximumBlockSize, this.blockSizes[i]);\n            totalSamples += this.blockSizes[i];\n            // Excluding the last frame from block size calculation\n            // https://www.rfc-editor.org/rfc/rfc9639.html#name-streaminfo\n            // \"The minimum block size (in samples) used in the stream, excluding the last block.\"\n            const isLastFrame = i === this.blockSizes.length - 1;\n            if (isLastFrame) {\n                continue;\n            }\n            minimumBlockSize = Math.min(minimumBlockSize, this.blockSizes[i]);\n        }\n        assert(this.sampleRate !== null);\n        assert(this.channels !== null);\n        assert(this.bitsPerSample !== null);\n        this.writer.seek(4);\n        this.writeHeader({\n            minimumBlockSize,\n            maximumBlockSize,\n            minimumFrameSize,\n            maximumFrameSize,\n            sampleRate: this.sampleRate,\n            channels: this.channels,\n            bitsPerSample: this.bitsPerSample,\n            totalSamples,\n        });\n        release();\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nconst cueBlockHeaderRegex = /(?:(.+?)\\n)?((?:\\d{2}:)?\\d{2}:\\d{2}.\\d{3})\\s+-->\\s+((?:\\d{2}:)?\\d{2}:\\d{2}.\\d{3})/g;\nconst preambleStartRegex = /^WEBVTT(.|\\n)*?\\n{2}/;\nexport const inlineTimestampRegex = /<(?:(\\d{2}):)?(\\d{2}):(\\d{2}).(\\d{3})>/g;\nexport class SubtitleParser {\n    constructor(options) {\n        this.preambleText = null;\n        this.preambleEmitted = false;\n        this.options = options;\n    }\n    parse(text) {\n        text = text.replaceAll('\\r\\n', '\\n').replaceAll('\\r', '\\n');\n        cueBlockHeaderRegex.lastIndex = 0;\n        let match;\n        if (!this.preambleText) {\n            if (!preambleStartRegex.test(text)) {\n                throw new Error('WebVTT preamble incorrect.');\n            }\n            match = cueBlockHeaderRegex.exec(text);\n            const preamble = text.slice(0, match?.index ?? text.length).trimEnd();\n            if (!preamble) {\n                throw new Error('No WebVTT preamble provided.');\n            }\n            this.preambleText = preamble;\n            if (match) {\n                text = text.slice(match.index);\n                cueBlockHeaderRegex.lastIndex = 0;\n            }\n        }\n        while ((match = cueBlockHeaderRegex.exec(text))) {\n            const notes = text.slice(0, match.index);\n            const cueIdentifier = match[1];\n            const matchEnd = match.index + match[0].length;\n            const bodyStart = text.indexOf('\\n', matchEnd) + 1;\n            const cueSettings = text.slice(matchEnd, bodyStart).trim();\n            let bodyEnd = text.indexOf('\\n\\n', matchEnd);\n            if (bodyEnd === -1)\n                bodyEnd = text.length;\n            const startTime = parseSubtitleTimestamp(match[2]);\n            const endTime = parseSubtitleTimestamp(match[3]);\n            const duration = endTime - startTime;\n            const body = text.slice(bodyStart, bodyEnd).trim();\n            text = text.slice(bodyEnd).trimStart();\n            cueBlockHeaderRegex.lastIndex = 0;\n            const cue = {\n                timestamp: startTime / 1000,\n                duration: duration / 1000,\n                text: body,\n                identifier: cueIdentifier,\n                settings: cueSettings,\n                notes,\n            };\n            const meta = {};\n            if (!this.preambleEmitted) {\n                meta.config = {\n                    description: this.preambleText,\n                };\n                this.preambleEmitted = true;\n            }\n            this.options.output(cue, meta);\n        }\n    }\n}\nconst timestampRegex = /(?:(\\d{2}):)?(\\d{2}):(\\d{2}).(\\d{3})/;\nexport const parseSubtitleTimestamp = (string) => {\n    const match = timestampRegex.exec(string);\n    if (!match)\n        throw new Error('Expected match.');\n    return 60 * 60 * 1000 * Number(match[1] || '0')\n        + 60 * 1000 * Number(match[2])\n        + 1000 * Number(match[3])\n        + Number(match[4]);\n};\nexport const formatSubtitleTimestamp = (timestamp) => {\n    const hours = Math.floor(timestamp / (60 * 60 * 1000));\n    const minutes = Math.floor((timestamp % (60 * 60 * 1000)) / (60 * 1000));\n    const seconds = Math.floor((timestamp % (60 * 1000)) / 1000);\n    const milliseconds = timestamp % 1000;\n    return hours.toString().padStart(2, '0') + ':'\n        + minutes.toString().padStart(2, '0') + ':'\n        + seconds.toString().padStart(2, '0') + '.'\n        + milliseconds.toString().padStart(3, '0');\n};\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { toUint8Array, assert, isU32, last, textEncoder, COLOR_PRIMARIES_MAP, TRANSFER_CHARACTERISTICS_MAP, MATRIX_COEFFICIENTS_MAP, colorSpaceIsComplete, UNDETERMINED_LANGUAGE, assertNever, keyValueIterator, } from '../misc.js';\nimport { generateAv1CodecConfigurationFromCodecString, parsePcmCodec, PCM_AUDIO_CODECS, } from '../codec.js';\nimport { formatSubtitleTimestamp } from '../subtitles.js';\nimport { getTrackMetadata, GLOBAL_TIMESCALE, intoTimescale, } from './isobmff-muxer.js';\nimport { parseOpusIdentificationHeader } from '../codec-data.js';\nimport { RichImageData } from '../metadata.js';\nexport class IsobmffBoxWriter {\n    constructor(writer) {\n        this.writer = writer;\n        this.helper = new Uint8Array(8);\n        this.helperView = new DataView(this.helper.buffer);\n        /**\n         * Stores the position from the start of the file to where boxes elements have been written. This is used to\n         * rewrite/edit elements that were already added before, and to measure sizes of things.\n         */\n        this.offsets = new WeakMap();\n    }\n    writeU32(value) {\n        this.helperView.setUint32(0, value, false);\n        this.writer.write(this.helper.subarray(0, 4));\n    }\n    writeU64(value) {\n        this.helperView.setUint32(0, Math.floor(value / 2 ** 32), false);\n        this.helperView.setUint32(4, value, false);\n        this.writer.write(this.helper.subarray(0, 8));\n    }\n    writeAscii(text) {\n        for (let i = 0; i < text.length; i++) {\n            this.helperView.setUint8(i % 8, text.charCodeAt(i));\n            if (i % 8 === 7)\n                this.writer.write(this.helper);\n        }\n        if (text.length % 8 !== 0) {\n            this.writer.write(this.helper.subarray(0, text.length % 8));\n        }\n    }\n    writeBox(box) {\n        this.offsets.set(box, this.writer.getPos());\n        if (box.contents && !box.children) {\n            this.writeBoxHeader(box, box.size ?? box.contents.byteLength + 8);\n            this.writer.write(box.contents);\n        }\n        else {\n            const startPos = this.writer.getPos();\n            this.writeBoxHeader(box, 0);\n            if (box.contents)\n                this.writer.write(box.contents);\n            if (box.children)\n                for (const child of box.children)\n                    if (child)\n                        this.writeBox(child);\n            const endPos = this.writer.getPos();\n            const size = box.size ?? endPos - startPos;\n            this.writer.seek(startPos);\n            this.writeBoxHeader(box, size);\n            this.writer.seek(endPos);\n        }\n    }\n    writeBoxHeader(box, size) {\n        this.writeU32(box.largeSize ? 1 : size);\n        this.writeAscii(box.type);\n        if (box.largeSize)\n            this.writeU64(size);\n    }\n    measureBoxHeader(box) {\n        return 8 + (box.largeSize ? 8 : 0);\n    }\n    patchBox(box) {\n        const boxOffset = this.offsets.get(box);\n        assert(boxOffset !== undefined);\n        const endPos = this.writer.getPos();\n        this.writer.seek(boxOffset);\n        this.writeBox(box);\n        this.writer.seek(endPos);\n    }\n    measureBox(box) {\n        if (box.contents && !box.children) {\n            const headerSize = this.measureBoxHeader(box);\n            return headerSize + box.contents.byteLength;\n        }\n        else {\n            let result = this.measureBoxHeader(box);\n            if (box.contents)\n                result += box.contents.byteLength;\n            if (box.children)\n                for (const child of box.children)\n                    if (child)\n                        result += this.measureBox(child);\n            return result;\n        }\n    }\n}\nconst bytes = /* #__PURE__ */ new Uint8Array(8);\nconst view = /* #__PURE__ */ new DataView(bytes.buffer);\nconst u8 = (value) => {\n    return [(value % 0x100 + 0x100) % 0x100];\n};\nconst u16 = (value) => {\n    view.setUint16(0, value, false);\n    return [bytes[0], bytes[1]];\n};\nconst i16 = (value) => {\n    view.setInt16(0, value, false);\n    return [bytes[0], bytes[1]];\n};\nconst u24 = (value) => {\n    view.setUint32(0, value, false);\n    return [bytes[1], bytes[2], bytes[3]];\n};\nconst u32 = (value) => {\n    view.setUint32(0, value, false);\n    return [bytes[0], bytes[1], bytes[2], bytes[3]];\n};\nconst i32 = (value) => {\n    view.setInt32(0, value, false);\n    return [bytes[0], bytes[1], bytes[2], bytes[3]];\n};\nconst u64 = (value) => {\n    view.setUint32(0, Math.floor(value / 2 ** 32), false);\n    view.setUint32(4, value, false);\n    return [bytes[0], bytes[1], bytes[2], bytes[3], bytes[4], bytes[5], bytes[6], bytes[7]];\n};\nconst fixed_8_8 = (value) => {\n    view.setInt16(0, 2 ** 8 * value, false);\n    return [bytes[0], bytes[1]];\n};\nconst fixed_16_16 = (value) => {\n    view.setInt32(0, 2 ** 16 * value, false);\n    return [bytes[0], bytes[1], bytes[2], bytes[3]];\n};\nconst fixed_2_30 = (value) => {\n    view.setInt32(0, 2 ** 30 * value, false);\n    return [bytes[0], bytes[1], bytes[2], bytes[3]];\n};\nconst variableUnsignedInt = (value, byteLength) => {\n    const bytes = [];\n    let remaining = value;\n    do {\n        let byte = remaining & 0x7f;\n        remaining >>= 7;\n        // If this isn't the first byte we're adding (meaning there will be more bytes after it\n        // when we reverse the array), set the continuation bit\n        if (bytes.length > 0) {\n            byte |= 0x80;\n        }\n        bytes.push(byte);\n        if (byteLength !== undefined) {\n            byteLength--;\n        }\n    } while (remaining > 0 || byteLength);\n    // Reverse the array since we built it backwards\n    return bytes.reverse();\n};\nconst ascii = (text, nullTerminated = false) => {\n    const bytes = Array(text.length).fill(null).map((_, i) => text.charCodeAt(i));\n    if (nullTerminated)\n        bytes.push(0x00);\n    return bytes;\n};\nconst lastPresentedSample = (samples) => {\n    let result = null;\n    for (const sample of samples) {\n        if (!result || sample.timestamp > result.timestamp) {\n            result = sample;\n        }\n    }\n    return result;\n};\nconst rotationMatrix = (rotationInDegrees) => {\n    const theta = rotationInDegrees * (Math.PI / 180);\n    const cosTheta = Math.round(Math.cos(theta));\n    const sinTheta = Math.round(Math.sin(theta));\n    // Matrices are post-multiplied in ISOBMFF, meaning this is the transpose of your typical rotation matrix\n    return [\n        cosTheta, sinTheta, 0,\n        -sinTheta, cosTheta, 0,\n        0, 0, 1,\n    ];\n};\nconst IDENTITY_MATRIX = /* #__PURE__ */ rotationMatrix(0);\nconst matrixToBytes = (matrix) => {\n    return [\n        fixed_16_16(matrix[0]), fixed_16_16(matrix[1]), fixed_2_30(matrix[2]),\n        fixed_16_16(matrix[3]), fixed_16_16(matrix[4]), fixed_2_30(matrix[5]),\n        fixed_16_16(matrix[6]), fixed_16_16(matrix[7]), fixed_2_30(matrix[8]),\n    ];\n};\nexport const box = (type, contents, children) => ({\n    type,\n    contents: contents && new Uint8Array(contents.flat(10)),\n    children,\n});\n/** A FullBox always starts with a version byte, followed by three flag bytes. */\nexport const fullBox = (type, version, flags, contents, children) => box(type, [u8(version), u24(flags), contents ?? []], children);\n/**\n * File Type Compatibility Box: Allows the reader to determine whether this is a type of file that the\n * reader understands.\n */\nexport const ftyp = (details) => {\n    // You can find the full logic for this at\n    // https://github.com/FFmpeg/FFmpeg/blob/de2fb43e785773738c660cdafb9309b1ef1bc80d/libavformat/movenc.c#L5518\n    // Obviously, this lib only needs a small subset of that logic.\n    const minorVersion = 0x200;\n    if (details.isQuickTime) {\n        return box('ftyp', [\n            ascii('qt  '), // Major brand\n            u32(minorVersion), // Minor version\n            // Compatible brands\n            ascii('qt  '),\n        ]);\n    }\n    if (details.fragmented) {\n        return box('ftyp', [\n            ascii('iso5'), // Major brand\n            u32(minorVersion), // Minor version\n            // Compatible brands\n            ascii('iso5'),\n            ascii('iso6'),\n            ascii('mp41'),\n        ]);\n    }\n    return box('ftyp', [\n        ascii('isom'), // Major brand\n        u32(minorVersion), // Minor version\n        // Compatible brands\n        ascii('isom'),\n        details.holdsAvc ? ascii('avc1') : [],\n        ascii('mp41'),\n    ]);\n};\n/** Movie Sample Data Box. Contains the actual frames/samples of the media. */\nexport const mdat = (reserveLargeSize) => ({ type: 'mdat', largeSize: reserveLargeSize });\n/** Free Space Box: A box that designates unused space in the movie data file. */\nexport const free = (size) => ({ type: 'free', size });\n/**\n * Movie Box: Used to specify the information that defines a movie - that is, the information that allows\n * an application to interpret the sample data that is stored elsewhere.\n */\nexport const moov = (muxer) => box('moov', undefined, [\n    mvhd(muxer.creationTime, muxer.trackDatas),\n    ...muxer.trackDatas.map(x => trak(x, muxer.creationTime)),\n    muxer.isFragmented ? mvex(muxer.trackDatas) : null,\n    udta(muxer),\n]);\n/** Movie Header Box: Used to specify the characteristics of the entire movie, such as timescale and duration. */\nexport const mvhd = (creationTime, trackDatas) => {\n    const duration = intoTimescale(Math.max(0, ...trackDatas\n        .filter(x => x.samples.length > 0)\n        .map((x) => {\n        const lastSample = lastPresentedSample(x.samples);\n        return lastSample.timestamp + lastSample.duration;\n    })), GLOBAL_TIMESCALE);\n    const nextTrackId = Math.max(0, ...trackDatas.map(x => x.track.id)) + 1;\n    // Conditionally use u64 if u32 isn't enough\n    const needsU64 = !isU32(creationTime) || !isU32(duration);\n    const u32OrU64 = needsU64 ? u64 : u32;\n    return fullBox('mvhd', +needsU64, 0, [\n        u32OrU64(creationTime), // Creation time\n        u32OrU64(creationTime), // Modification time\n        u32(GLOBAL_TIMESCALE), // Timescale\n        u32OrU64(duration), // Duration\n        fixed_16_16(1), // Preferred rate\n        fixed_8_8(1), // Preferred volume\n        Array(10).fill(0), // Reserved\n        matrixToBytes(IDENTITY_MATRIX), // Matrix\n        Array(24).fill(0), // Pre-defined\n        u32(nextTrackId), // Next track ID\n    ]);\n};\n/**\n * Track Box: Defines a single track of a movie. A movie may consist of one or more tracks. Each track is\n * independent of the other tracks in the movie and carries its own temporal and spatial information. Each Track Box\n * contains its associated Media Box.\n */\nexport const trak = (trackData, creationTime) => {\n    const trackMetadata = getTrackMetadata(trackData);\n    return box('trak', undefined, [\n        tkhd(trackData, creationTime),\n        mdia(trackData, creationTime),\n        trackMetadata.name !== undefined\n            ? box('udta', undefined, [\n                box('name', [\n                    ...textEncoder.encode(trackMetadata.name),\n                ]),\n            ])\n            : null,\n    ]);\n};\n/** Track Header Box: Specifies the characteristics of a single track within a movie. */\nexport const tkhd = (trackData, creationTime) => {\n    const lastSample = lastPresentedSample(trackData.samples);\n    const durationInGlobalTimescale = intoTimescale(lastSample ? lastSample.timestamp + lastSample.duration : 0, GLOBAL_TIMESCALE);\n    const needsU64 = !isU32(creationTime) || !isU32(durationInGlobalTimescale);\n    const u32OrU64 = needsU64 ? u64 : u32;\n    let matrix;\n    if (trackData.type === 'video') {\n        const rotation = trackData.track.metadata.rotation;\n        matrix = rotationMatrix(rotation ?? 0);\n    }\n    else {\n        matrix = IDENTITY_MATRIX;\n    }\n    let flags = 0x2; // Track in movie\n    if (trackData.track.metadata.disposition?.default !== false) {\n        flags |= 0x1; // Track enabled\n    }\n    return fullBox('tkhd', +needsU64, flags, [\n        u32OrU64(creationTime), // Creation time\n        u32OrU64(creationTime), // Modification time\n        u32(trackData.track.id), // Track ID\n        u32(0), // Reserved\n        u32OrU64(durationInGlobalTimescale), // Duration\n        Array(8).fill(0), // Reserved\n        u16(0), // Layer\n        u16(trackData.track.id), // Alternate group\n        fixed_8_8(trackData.type === 'audio' ? 1 : 0), // Volume\n        u16(0), // Reserved\n        matrixToBytes(matrix), // Matrix\n        fixed_16_16(trackData.type === 'video' ? trackData.info.width : 0), // Track width\n        fixed_16_16(trackData.type === 'video' ? trackData.info.height : 0), // Track height\n    ]);\n};\n/** Media Box: Describes and define a track's media type and sample data. */\nexport const mdia = (trackData, creationTime) => box('mdia', undefined, [\n    mdhd(trackData, creationTime),\n    hdlr(true, TRACK_TYPE_TO_COMPONENT_SUBTYPE[trackData.type], TRACK_TYPE_TO_HANDLER_NAME[trackData.type]),\n    minf(trackData),\n]);\n/** Media Header Box: Specifies the characteristics of a media, including timescale and duration. */\nexport const mdhd = (trackData, creationTime) => {\n    const lastSample = lastPresentedSample(trackData.samples);\n    const localDuration = intoTimescale(lastSample ? lastSample.timestamp + lastSample.duration : 0, trackData.timescale);\n    const needsU64 = !isU32(creationTime) || !isU32(localDuration);\n    const u32OrU64 = needsU64 ? u64 : u32;\n    return fullBox('mdhd', +needsU64, 0, [\n        u32OrU64(creationTime), // Creation time\n        u32OrU64(creationTime), // Modification time\n        u32(trackData.timescale), // Timescale\n        u32OrU64(localDuration), // Duration\n        u16(getLanguageCodeInt(trackData.track.metadata.languageCode ?? UNDETERMINED_LANGUAGE)), // Language\n        u16(0), // Quality\n    ]);\n};\nconst TRACK_TYPE_TO_COMPONENT_SUBTYPE = {\n    video: 'vide',\n    audio: 'soun',\n    subtitle: 'text',\n};\nconst TRACK_TYPE_TO_HANDLER_NAME = {\n    video: 'MediabunnyVideoHandler',\n    audio: 'MediabunnySoundHandler',\n    subtitle: 'MediabunnyTextHandler',\n};\n/** Handler Reference Box. */\nexport const hdlr = (hasComponentType, handlerType, name, manufacturer = '\\0\\0\\0\\0') => fullBox('hdlr', 0, 0, [\n    hasComponentType ? ascii('mhlr') : u32(0), // Component type\n    ascii(handlerType), // Component subtype\n    ascii(manufacturer), // Component manufacturer\n    u32(0), // Component flags\n    u32(0), // Component flags mask\n    ascii(name, true), // Component name\n]);\n/**\n * Media Information Box: Stores handler-specific information for a track's media data. The media handler uses this\n * information to map from media time to media data and to process the media data.\n */\nexport const minf = (trackData) => box('minf', undefined, [\n    TRACK_TYPE_TO_HEADER_BOX[trackData.type](),\n    dinf(),\n    stbl(trackData),\n]);\n/** Video Media Information Header Box: Defines specific color and graphics mode information. */\nexport const vmhd = () => fullBox('vmhd', 0, 1, [\n    u16(0), // Graphics mode\n    u16(0), // Opcolor R\n    u16(0), // Opcolor G\n    u16(0), // Opcolor B\n]);\n/** Sound Media Information Header Box: Stores the sound media's control information, such as balance. */\nexport const smhd = () => fullBox('smhd', 0, 0, [\n    u16(0), // Balance\n    u16(0), // Reserved\n]);\n/** Null Media Header Box. */\nexport const nmhd = () => fullBox('nmhd', 0, 0);\nconst TRACK_TYPE_TO_HEADER_BOX = {\n    video: vmhd,\n    audio: smhd,\n    subtitle: nmhd,\n};\n/**\n * Data Information Box: Contains information specifying the data handler component that provides access to the\n * media data. The data handler component uses the Data Information Box to interpret the media's data.\n */\nexport const dinf = () => box('dinf', undefined, [\n    dref(),\n]);\n/**\n * Data Reference Box: Contains tabular data that instructs the data handler component how to access the media's data.\n */\nexport const dref = () => fullBox('dref', 0, 0, [\n    u32(1), // Entry count\n], [\n    url(),\n]);\nexport const url = () => fullBox('url ', 0, 1); // Self-reference flag enabled\n/**\n * Sample Table Box: Contains information for converting from media time to sample number to sample location. This box\n * also indicates how to interpret the sample (for example, whether to decompress the video data and, if so, how).\n */\nexport const stbl = (trackData) => {\n    const needsCtts = trackData.compositionTimeOffsetTable.length > 1\n        || trackData.compositionTimeOffsetTable.some(x => x.sampleCompositionTimeOffset !== 0);\n    return box('stbl', undefined, [\n        stsd(trackData),\n        stts(trackData),\n        needsCtts ? ctts(trackData) : null,\n        needsCtts ? cslg(trackData) : null,\n        stsc(trackData),\n        stsz(trackData),\n        stco(trackData),\n        stss(trackData),\n    ]);\n};\n/**\n * Sample Description Box: Stores information that allows you to decode samples in the media. The data stored in the\n * sample description varies, depending on the media type.\n */\nexport const stsd = (trackData) => {\n    let sampleDescription;\n    if (trackData.type === 'video') {\n        sampleDescription = videoSampleDescription(videoCodecToBoxName(trackData.track.source._codec, trackData.info.decoderConfig.codec), trackData);\n    }\n    else if (trackData.type === 'audio') {\n        const boxName = audioCodecToBoxName(trackData.track.source._codec, trackData.muxer.isQuickTime);\n        assert(boxName);\n        sampleDescription = soundSampleDescription(boxName, trackData);\n    }\n    else if (trackData.type === 'subtitle') {\n        sampleDescription = subtitleSampleDescription(SUBTITLE_CODEC_TO_BOX_NAME[trackData.track.source._codec], trackData);\n    }\n    assert(sampleDescription);\n    return fullBox('stsd', 0, 0, [\n        u32(1), // Entry count\n    ], [\n        sampleDescription,\n    ]);\n};\n/** Video Sample Description Box: Contains information that defines how to interpret video media data. */\nexport const videoSampleDescription = (compressionType, trackData) => box(compressionType, [\n    Array(6).fill(0), // Reserved\n    u16(1), // Data reference index\n    u16(0), // Pre-defined\n    u16(0), // Reserved\n    Array(12).fill(0), // Pre-defined\n    u16(trackData.info.width), // Width\n    u16(trackData.info.height), // Height\n    u32(0x00480000), // Horizontal resolution\n    u32(0x00480000), // Vertical resolution\n    u32(0), // Reserved\n    u16(1), // Frame count\n    Array(32).fill(0), // Compressor name\n    u16(0x0018), // Depth\n    i16(0xffff), // Pre-defined\n], [\n    VIDEO_CODEC_TO_CONFIGURATION_BOX[trackData.track.source._codec](trackData),\n    colorSpaceIsComplete(trackData.info.decoderConfig.colorSpace) ? colr(trackData) : null,\n]);\n/** Colour Information Box: Specifies the color space of the video. */\nexport const colr = (trackData) => box('colr', [\n    ascii('nclx'), // Colour type\n    u16(COLOR_PRIMARIES_MAP[trackData.info.decoderConfig.colorSpace.primaries]), // Colour primaries\n    u16(TRANSFER_CHARACTERISTICS_MAP[trackData.info.decoderConfig.colorSpace.transfer]), // Transfer characteristics\n    u16(MATRIX_COEFFICIENTS_MAP[trackData.info.decoderConfig.colorSpace.matrix]), // Matrix coefficients\n    u8((trackData.info.decoderConfig.colorSpace.fullRange ? 1 : 0) << 7), // Full range flag\n]);\n/** AVC Configuration Box: Provides additional information to the decoder. */\nexport const avcC = (trackData) => trackData.info.decoderConfig && box('avcC', [\n    // For AVC, description is an AVCDecoderConfigurationRecord, so nothing else to do here\n    ...toUint8Array(trackData.info.decoderConfig.description),\n]);\n/** HEVC Configuration Box: Provides additional information to the decoder. */\nexport const hvcC = (trackData) => trackData.info.decoderConfig && box('hvcC', [\n    // For HEVC, description is an HEVCDecoderConfigurationRecord, so nothing else to do here\n    ...toUint8Array(trackData.info.decoderConfig.description),\n]);\n/** VP Configuration Box: Provides additional information to the decoder. */\nexport const vpcC = (trackData) => {\n    // Reference: https://www.webmproject.org/vp9/mp4/\n    if (!trackData.info.decoderConfig) {\n        return null;\n    }\n    const decoderConfig = trackData.info.decoderConfig;\n    const parts = decoderConfig.codec.split('.'); // We can derive the required values from the codec string\n    const profile = Number(parts[1]);\n    const level = Number(parts[2]);\n    const bitDepth = Number(parts[3]);\n    const chromaSubsampling = parts[4] ? Number(parts[4]) : 1; // 4:2:0 colocated with luma (0,0)\n    const videoFullRangeFlag = parts[8] ? Number(parts[8]) : Number(decoderConfig.colorSpace?.fullRange ?? 0);\n    const thirdByte = (bitDepth << 4) + (chromaSubsampling << 1) + videoFullRangeFlag;\n    const colourPrimaries = parts[5]\n        ? Number(parts[5])\n        : decoderConfig.colorSpace?.primaries\n            ? COLOR_PRIMARIES_MAP[decoderConfig.colorSpace.primaries]\n            : 2; // Default to undetermined\n    const transferCharacteristics = parts[6]\n        ? Number(parts[6])\n        : decoderConfig.colorSpace?.transfer\n            ? TRANSFER_CHARACTERISTICS_MAP[decoderConfig.colorSpace.transfer]\n            : 2;\n    const matrixCoefficients = parts[7]\n        ? Number(parts[7])\n        : decoderConfig.colorSpace?.matrix\n            ? MATRIX_COEFFICIENTS_MAP[decoderConfig.colorSpace.matrix]\n            : 2;\n    return fullBox('vpcC', 1, 0, [\n        u8(profile), // Profile\n        u8(level), // Level\n        u8(thirdByte), // Bit depth, chroma subsampling, full range\n        u8(colourPrimaries), // Colour primaries\n        u8(transferCharacteristics), // Transfer characteristics\n        u8(matrixCoefficients), // Matrix coefficients\n        u16(0), // Codec initialization data size\n    ]);\n};\n/** AV1 Configuration Box: Provides additional information to the decoder. */\nexport const av1C = (trackData) => {\n    return box('av1C', generateAv1CodecConfigurationFromCodecString(trackData.info.decoderConfig.codec));\n};\n/** Sound Sample Description Box: Contains information that defines how to interpret sound media data. */\nexport const soundSampleDescription = (compressionType, trackData) => {\n    let version = 0;\n    let contents;\n    let sampleSizeInBits = 16;\n    if (PCM_AUDIO_CODECS.includes(trackData.track.source._codec)) {\n        const codec = trackData.track.source._codec;\n        const { sampleSize } = parsePcmCodec(codec);\n        sampleSizeInBits = 8 * sampleSize;\n        if (sampleSizeInBits > 16) {\n            version = 1;\n        }\n    }\n    if (version === 0) {\n        contents = [\n            Array(6).fill(0), // Reserved\n            u16(1), // Data reference index\n            u16(version), // Version\n            u16(0), // Revision level\n            u32(0), // Vendor\n            u16(trackData.info.numberOfChannels), // Number of channels\n            u16(sampleSizeInBits), // Sample size (bits)\n            u16(0), // Compression ID\n            u16(0), // Packet size\n            u16(trackData.info.sampleRate < 2 ** 16 ? trackData.info.sampleRate : 0), // Sample rate (upper)\n            u16(0), // Sample rate (lower)\n        ];\n    }\n    else {\n        contents = [\n            Array(6).fill(0), // Reserved\n            u16(1), // Data reference index\n            u16(version), // Version\n            u16(0), // Revision level\n            u32(0), // Vendor\n            u16(trackData.info.numberOfChannels), // Number of channels\n            u16(Math.min(sampleSizeInBits, 16)), // Sample size (bits)\n            u16(0), // Compression ID\n            u16(0), // Packet size\n            u16(trackData.info.sampleRate < 2 ** 16 ? trackData.info.sampleRate : 0), // Sample rate (upper)\n            u16(0), // Sample rate (lower)\n            u32(1), // Samples per packet (must be 1 for uncompressed formats)\n            u32(sampleSizeInBits / 8), // Bytes per packet\n            u32(trackData.info.numberOfChannels * sampleSizeInBits / 8), // Bytes per frame\n            u32(2), // Bytes per sample (constant in FFmpeg)\n        ];\n    }\n    return box(compressionType, contents, [\n        audioCodecToConfigurationBox(trackData.track.source._codec, trackData.muxer.isQuickTime)?.(trackData) ?? null,\n    ]);\n};\n/** MPEG-4 Elementary Stream Descriptor Box. */\nexport const esds = (trackData) => {\n    // We build up the bytes in a layered way which reflects the nested structure\n    let objectTypeIndication;\n    switch (trackData.track.source._codec) {\n        case 'aac':\n            {\n                objectTypeIndication = 0x40;\n            }\n            ;\n            break;\n        case 'mp3':\n            {\n                objectTypeIndication = 0x6b;\n            }\n            ;\n            break;\n        case 'vorbis':\n            {\n                objectTypeIndication = 0xdd;\n            }\n            ;\n            break;\n        default: throw new Error(`Unhandled audio codec: ${trackData.track.source._codec}`);\n    }\n    let bytes = [\n        ...u8(objectTypeIndication), // Object type indication\n        ...u8(0x15), // stream type(6bits)=5 audio, flags(2bits)=1\n        ...u24(0), // 24bit buffer size\n        ...u32(0), // max bitrate\n        ...u32(0), // avg bitrate\n    ];\n    if (trackData.info.decoderConfig.description) {\n        const description = toUint8Array(trackData.info.decoderConfig.description);\n        // Add the decoder description to the end\n        bytes = [\n            ...bytes,\n            ...u8(0x05), // TAG(5) = DecoderSpecificInfo\n            ...variableUnsignedInt(description.byteLength),\n            ...description,\n        ];\n    }\n    bytes = [\n        ...u16(1), // ES_ID = 1\n        ...u8(0x00), // flags etc = 0\n        ...u8(0x04), // TAG(4) = ES Descriptor\n        ...variableUnsignedInt(bytes.length),\n        ...bytes,\n        ...u8(0x06), // TAG(6)\n        ...u8(0x01), // length\n        ...u8(0x02), // data\n    ];\n    bytes = [\n        ...u8(0x03), // TAG(3) = Object Descriptor\n        ...variableUnsignedInt(bytes.length),\n        ...bytes,\n    ];\n    return fullBox('esds', 0, 0, bytes);\n};\nexport const wave = (trackData) => {\n    return box('wave', undefined, [\n        frma(trackData),\n        enda(trackData),\n        box('\\x00\\x00\\x00\\x00'), // NULL tag at the end\n    ]);\n};\nexport const frma = (trackData) => {\n    return box('frma', [\n        ascii(audioCodecToBoxName(trackData.track.source._codec, trackData.muxer.isQuickTime)),\n    ]);\n};\n// This box specifies PCM endianness\nexport const enda = (trackData) => {\n    const { littleEndian } = parsePcmCodec(trackData.track.source._codec);\n    return box('enda', [\n        u16(+littleEndian),\n    ]);\n};\n/** Opus Specific Box. */\nexport const dOps = (trackData) => {\n    let outputChannelCount = trackData.info.numberOfChannels;\n    // Default PreSkip, should be at least 80 milliseconds worth of playback, measured in 48000 Hz samples\n    let preSkip = 3840;\n    let inputSampleRate = trackData.info.sampleRate;\n    let outputGain = 0;\n    let channelMappingFamily = 0;\n    let channelMappingTable = new Uint8Array(0);\n    // Read preskip and from codec private data from the encoder\n    // https://www.rfc-editor.org/rfc/rfc7845#section-5\n    const description = trackData.info.decoderConfig?.description;\n    if (description) {\n        assert(description.byteLength >= 18);\n        const bytes = toUint8Array(description);\n        const header = parseOpusIdentificationHeader(bytes);\n        outputChannelCount = header.outputChannelCount;\n        preSkip = header.preSkip;\n        inputSampleRate = header.inputSampleRate;\n        outputGain = header.outputGain;\n        channelMappingFamily = header.channelMappingFamily;\n        if (header.channelMappingTable) {\n            channelMappingTable = header.channelMappingTable;\n        }\n    }\n    // https://www.opus-codec.org/docs/opus_in_isobmff.html\n    return box('dOps', [\n        u8(0), // Version\n        u8(outputChannelCount), // OutputChannelCount\n        u16(preSkip), // PreSkip\n        u32(inputSampleRate), // InputSampleRate\n        i16(outputGain), // OutputGain\n        u8(channelMappingFamily), // ChannelMappingFamily\n        ...channelMappingTable,\n    ]);\n};\n/** FLAC specific box. */\nexport const dfLa = (trackData) => {\n    const description = trackData.info.decoderConfig?.description;\n    assert(description);\n    const bytes = toUint8Array(description);\n    return fullBox('dfLa', 0, 0, [\n        ...bytes.subarray(4),\n    ]);\n};\n/** PCM Configuration Box, ISO/IEC 23003-5. */\nconst pcmC = (trackData) => {\n    const { littleEndian, sampleSize } = parsePcmCodec(trackData.track.source._codec);\n    const formatFlags = +littleEndian;\n    return fullBox('pcmC', 0, 0, [\n        u8(formatFlags),\n        u8(8 * sampleSize),\n    ]);\n};\nexport const subtitleSampleDescription = (compressionType, trackData) => box(compressionType, [\n    Array(6).fill(0), // Reserved\n    u16(1), // Data reference index\n], [\n    SUBTITLE_CODEC_TO_CONFIGURATION_BOX[trackData.track.source._codec](trackData),\n]);\nexport const vttC = (trackData) => box('vttC', [\n    ...textEncoder.encode(trackData.info.config.description),\n]);\nexport const txtC = (textConfig) => fullBox('txtC', 0, 0, [\n    ...textConfig, 0, // Text config (null-terminated)\n]);\n/**\n * Time-To-Sample Box: Stores duration information for a media's samples, providing a mapping from a time in a media\n * to the corresponding data sample. The table is compact, meaning that consecutive samples with the same time delta\n * will be grouped.\n */\nexport const stts = (trackData) => {\n    return fullBox('stts', 0, 0, [\n        u32(trackData.timeToSampleTable.length), // Number of entries\n        trackData.timeToSampleTable.map(x => [\n            u32(x.sampleCount), // Sample count\n            u32(x.sampleDelta), // Sample duration\n        ]),\n    ]);\n};\n/** Sync Sample Box: Identifies the key frames in the media, marking the random access points within a stream. */\nexport const stss = (trackData) => {\n    if (trackData.samples.every(x => x.type === 'key'))\n        return null; // No stss box -> every frame is a key frame\n    const keySamples = [...trackData.samples.entries()].filter(([, sample]) => sample.type === 'key');\n    return fullBox('stss', 0, 0, [\n        u32(keySamples.length), // Number of entries\n        keySamples.map(([index]) => u32(index + 1)), // Sync sample table\n    ]);\n};\n/**\n * Sample-To-Chunk Box: As samples are added to a media, they are collected into chunks that allow optimized data\n * access. A chunk contains one or more samples. Chunks in a media may have different sizes, and the samples within a\n * chunk may have different sizes. The Sample-To-Chunk Box stores chunk information for the samples in a media, stored\n * in a compactly-coded fashion.\n */\nexport const stsc = (trackData) => {\n    return fullBox('stsc', 0, 0, [\n        u32(trackData.compactlyCodedChunkTable.length), // Number of entries\n        trackData.compactlyCodedChunkTable.map(x => [\n            u32(x.firstChunk), // First chunk\n            u32(x.samplesPerChunk), // Samples per chunk\n            u32(1), // Sample description index\n        ]),\n    ]);\n};\n/** Sample Size Box: Specifies the byte size of each sample in the media. */\nexport const stsz = (trackData) => {\n    if (trackData.type === 'audio' && trackData.info.requiresPcmTransformation) {\n        const { sampleSize } = parsePcmCodec(trackData.track.source._codec);\n        // With PCM, every sample has the same size\n        return fullBox('stsz', 0, 0, [\n            u32(sampleSize * trackData.info.numberOfChannels), // Sample size\n            u32(trackData.samples.reduce((acc, x) => acc + intoTimescale(x.duration, trackData.timescale), 0)),\n        ]);\n    }\n    return fullBox('stsz', 0, 0, [\n        u32(0), // Sample size (0 means non-constant size)\n        u32(trackData.samples.length), // Number of entries\n        trackData.samples.map(x => u32(x.size)), // Sample size table\n    ]);\n};\n/** Chunk Offset Box: Identifies the location of each chunk of data in the media's data stream, relative to the file. */\nexport const stco = (trackData) => {\n    if (trackData.finalizedChunks.length > 0 && last(trackData.finalizedChunks).offset >= 2 ** 32) {\n        // If the file is large, use the co64 box\n        return fullBox('co64', 0, 0, [\n            u32(trackData.finalizedChunks.length), // Number of entries\n            trackData.finalizedChunks.map(x => u64(x.offset)), // Chunk offset table\n        ]);\n    }\n    return fullBox('stco', 0, 0, [\n        u32(trackData.finalizedChunks.length), // Number of entries\n        trackData.finalizedChunks.map(x => u32(x.offset)), // Chunk offset table\n    ]);\n};\n/**\n * Composition Time to Sample Box: Stores composition time offset information (PTS-DTS) for a\n * media's samples. The table is compact, meaning that consecutive samples with the same time\n * composition time offset will be grouped.\n */\nexport const ctts = (trackData) => {\n    return fullBox('ctts', 1, 0, [\n        u32(trackData.compositionTimeOffsetTable.length), // Number of entries\n        trackData.compositionTimeOffsetTable.map(x => [\n            u32(x.sampleCount), // Sample count\n            i32(x.sampleCompositionTimeOffset), // Sample offset\n        ]),\n    ]);\n};\n/**\n * Composition to Decode Box: Stores information about the composition and display times of the media samples.\n */\nexport const cslg = (trackData) => {\n    let leastDecodeToDisplayDelta = Infinity;\n    let greatestDecodeToDisplayDelta = -Infinity;\n    let compositionStartTime = Infinity;\n    let compositionEndTime = -Infinity;\n    assert(trackData.compositionTimeOffsetTable.length > 0);\n    assert(trackData.samples.length > 0);\n    for (let i = 0; i < trackData.compositionTimeOffsetTable.length; i++) {\n        const entry = trackData.compositionTimeOffsetTable[i];\n        leastDecodeToDisplayDelta = Math.min(leastDecodeToDisplayDelta, entry.sampleCompositionTimeOffset);\n        greatestDecodeToDisplayDelta = Math.max(greatestDecodeToDisplayDelta, entry.sampleCompositionTimeOffset);\n    }\n    for (let i = 0; i < trackData.samples.length; i++) {\n        const sample = trackData.samples[i];\n        compositionStartTime = Math.min(compositionStartTime, intoTimescale(sample.timestamp, trackData.timescale));\n        compositionEndTime = Math.max(compositionEndTime, intoTimescale(sample.timestamp + sample.duration, trackData.timescale));\n    }\n    const compositionToDtsShift = Math.max(-leastDecodeToDisplayDelta, 0);\n    if (compositionEndTime >= 2 ** 31) {\n        // For very large files, the composition end time can't be represented in i32, so let's just scrap the box in\n        // that case. QuickTime fails to read the file if there's a cslg box with version 1, so that's sadly not an\n        // option.\n        return null;\n    }\n    return fullBox('cslg', 0, 0, [\n        i32(compositionToDtsShift), // Composition to DTS shift\n        i32(leastDecodeToDisplayDelta), // Least decode to display delta\n        i32(greatestDecodeToDisplayDelta), // Greatest decode to display delta\n        i32(compositionStartTime), // Composition start time\n        i32(compositionEndTime), // Composition end time\n    ]);\n};\n/**\n * Movie Extends Box: This box signals to readers that the file is fragmented. Contains a single Track Extends Box\n * for each track in the movie.\n */\nexport const mvex = (trackDatas) => {\n    return box('mvex', undefined, trackDatas.map(trex));\n};\n/** Track Extends Box: Contains the default values used by the movie fragments. */\nexport const trex = (trackData) => {\n    return fullBox('trex', 0, 0, [\n        u32(trackData.track.id), // Track ID\n        u32(1), // Default sample description index\n        u32(0), // Default sample duration\n        u32(0), // Default sample size\n        u32(0), // Default sample flags\n    ]);\n};\n/**\n * Movie Fragment Box: The movie fragments extend the presentation in time. They provide the information that would\n * previously have been\tin the Movie Box.\n */\nexport const moof = (sequenceNumber, trackDatas) => {\n    return box('moof', undefined, [\n        mfhd(sequenceNumber),\n        ...trackDatas.map(traf),\n    ]);\n};\n/** Movie Fragment Header Box: Contains a sequence number as a safety check. */\nexport const mfhd = (sequenceNumber) => {\n    return fullBox('mfhd', 0, 0, [\n        u32(sequenceNumber), // Sequence number\n    ]);\n};\nconst fragmentSampleFlags = (sample) => {\n    let byte1 = 0;\n    let byte2 = 0;\n    const byte3 = 0;\n    const byte4 = 0;\n    const sampleIsDifferenceSample = sample.type === 'delta';\n    byte2 |= +sampleIsDifferenceSample;\n    if (sampleIsDifferenceSample) {\n        byte1 |= 1; // There is redundant coding in this sample\n    }\n    else {\n        byte1 |= 2; // There is no redundant coding in this sample\n    }\n    // Note that there are a lot of other flags to potentially set here, but most are irrelevant / non-necessary\n    return byte1 << 24 | byte2 << 16 | byte3 << 8 | byte4;\n};\n/** Track Fragment Box */\nexport const traf = (trackData) => {\n    return box('traf', undefined, [\n        tfhd(trackData),\n        tfdt(trackData),\n        trun(trackData),\n    ]);\n};\n/** Track Fragment Header Box: Provides a reference to the extended track, and flags. */\nexport const tfhd = (trackData) => {\n    assert(trackData.currentChunk);\n    let tfFlags = 0;\n    tfFlags |= 0x00008; // Default sample duration present\n    tfFlags |= 0x00010; // Default sample size present\n    tfFlags |= 0x00020; // Default sample flags present\n    tfFlags |= 0x20000; // Default base is moof\n    // Prefer the second sample over the first one, as the first one is a sync sample and therefore the \"odd one out\"\n    const referenceSample = trackData.currentChunk.samples[1] ?? trackData.currentChunk.samples[0];\n    const referenceSampleInfo = {\n        duration: referenceSample.timescaleUnitsToNextSample,\n        size: referenceSample.size,\n        flags: fragmentSampleFlags(referenceSample),\n    };\n    return fullBox('tfhd', 0, tfFlags, [\n        u32(trackData.track.id), // Track ID\n        u32(referenceSampleInfo.duration), // Default sample duration\n        u32(referenceSampleInfo.size), // Default sample size\n        u32(referenceSampleInfo.flags), // Default sample flags\n    ]);\n};\n/**\n * Track Fragment Decode Time Box: Provides the absolute decode time of the first sample of the fragment. This is\n * useful for performing random access on the media file.\n */\nexport const tfdt = (trackData) => {\n    assert(trackData.currentChunk);\n    return fullBox('tfdt', 1, 0, [\n        u64(intoTimescale(trackData.currentChunk.startTimestamp, trackData.timescale)), // Base Media Decode Time\n    ]);\n};\n/** Track Run Box: Specifies a run of contiguous samples for a given track. */\nexport const trun = (trackData) => {\n    assert(trackData.currentChunk);\n    const allSampleDurations = trackData.currentChunk.samples.map(x => x.timescaleUnitsToNextSample);\n    const allSampleSizes = trackData.currentChunk.samples.map(x => x.size);\n    const allSampleFlags = trackData.currentChunk.samples.map(fragmentSampleFlags);\n    const allSampleCompositionTimeOffsets = trackData.currentChunk.samples\n        .map(x => intoTimescale(x.timestamp - x.decodeTimestamp, trackData.timescale));\n    const uniqueSampleDurations = new Set(allSampleDurations);\n    const uniqueSampleSizes = new Set(allSampleSizes);\n    const uniqueSampleFlags = new Set(allSampleFlags);\n    const uniqueSampleCompositionTimeOffsets = new Set(allSampleCompositionTimeOffsets);\n    const firstSampleFlagsPresent = uniqueSampleFlags.size === 2 && allSampleFlags[0] !== allSampleFlags[1];\n    const sampleDurationPresent = uniqueSampleDurations.size > 1;\n    const sampleSizePresent = uniqueSampleSizes.size > 1;\n    const sampleFlagsPresent = !firstSampleFlagsPresent && uniqueSampleFlags.size > 1;\n    const sampleCompositionTimeOffsetsPresent = uniqueSampleCompositionTimeOffsets.size > 1 || [...uniqueSampleCompositionTimeOffsets].some(x => x !== 0);\n    let flags = 0;\n    flags |= 0x0001; // Data offset present\n    flags |= 0x0004 * +firstSampleFlagsPresent; // First sample flags present\n    flags |= 0x0100 * +sampleDurationPresent; // Sample duration present\n    flags |= 0x0200 * +sampleSizePresent; // Sample size present\n    flags |= 0x0400 * +sampleFlagsPresent; // Sample flags present\n    flags |= 0x0800 * +sampleCompositionTimeOffsetsPresent; // Sample composition time offsets present\n    return fullBox('trun', 1, flags, [\n        u32(trackData.currentChunk.samples.length), // Sample count\n        u32(trackData.currentChunk.offset - trackData.currentChunk.moofOffset || 0), // Data offset\n        firstSampleFlagsPresent ? u32(allSampleFlags[0]) : [],\n        trackData.currentChunk.samples.map((_, i) => [\n            sampleDurationPresent ? u32(allSampleDurations[i]) : [], // Sample duration\n            sampleSizePresent ? u32(allSampleSizes[i]) : [], // Sample size\n            sampleFlagsPresent ? u32(allSampleFlags[i]) : [], // Sample flags\n            // Sample composition time offsets\n            sampleCompositionTimeOffsetsPresent ? i32(allSampleCompositionTimeOffsets[i]) : [],\n        ]),\n    ]);\n};\n/**\n * Movie Fragment Random Access Box: For each track, provides pointers to sync samples within the file\n * for random access.\n */\nexport const mfra = (trackDatas) => {\n    return box('mfra', undefined, [\n        ...trackDatas.map(tfra),\n        mfro(),\n    ]);\n};\n/** Track Fragment Random Access Box: Provides pointers to sync samples within the file for random access. */\nexport const tfra = (trackData, trackIndex) => {\n    const version = 1; // Using this version allows us to use 64-bit time and offset values\n    return fullBox('tfra', version, 0, [\n        u32(trackData.track.id), // Track ID\n        u32(0b111111), // This specifies that traf number, trun number and sample number are 32-bit ints\n        u32(trackData.finalizedChunks.length), // Number of entries\n        trackData.finalizedChunks.map(chunk => [\n            u64(intoTimescale(chunk.samples[0].timestamp, trackData.timescale)), // Time (in presentation time)\n            u64(chunk.moofOffset), // moof offset\n            u32(trackIndex + 1), // traf number\n            u32(1), // trun number\n            u32(1), // Sample number\n        ]),\n    ]);\n};\n/**\n * Movie Fragment Random Access Offset Box: Provides the size of the enclosing mfra box. This box can be used by readers\n * to quickly locate the mfra box by searching from the end of the file.\n */\nexport const mfro = () => {\n    return fullBox('mfro', 0, 0, [\n        // This value needs to be overwritten manually from the outside, where the actual size of the enclosing mfra box\n        // is known\n        u32(0), // Size\n    ]);\n};\n/** VTT Empty Cue Box */\nexport const vtte = () => box('vtte');\n/** VTT Cue Box */\nexport const vttc = (payload, timestamp, identifier, settings, sourceId) => box('vttc', undefined, [\n    sourceId !== null ? box('vsid', [i32(sourceId)]) : null,\n    identifier !== null ? box('iden', [...textEncoder.encode(identifier)]) : null,\n    timestamp !== null ? box('ctim', [...textEncoder.encode(formatSubtitleTimestamp(timestamp))]) : null,\n    settings !== null ? box('sttg', [...textEncoder.encode(settings)]) : null,\n    box('payl', [...textEncoder.encode(payload)]),\n]);\n/** VTT Additional Text Box */\nexport const vtta = (notes) => box('vtta', [...textEncoder.encode(notes)]);\n/** User Data Box */\nconst udta = (muxer) => {\n    const boxes = [];\n    const metadataFormat = muxer.format._options.metadataFormat ?? 'auto';\n    const metadataTags = muxer.output._metadataTags;\n    // Depending on the format, metadata tags are written differently\n    if (metadataFormat === 'mdir' || (metadataFormat === 'auto' && !muxer.isQuickTime)) {\n        const metaBox = metaMdir(metadataTags);\n        if (metaBox)\n            boxes.push(metaBox);\n    }\n    else if (metadataFormat === 'mdta') {\n        const metaBox = metaMdta(metadataTags);\n        if (metaBox)\n            boxes.push(metaBox);\n    }\n    else if (metadataFormat === 'udta' || (metadataFormat === 'auto' && muxer.isQuickTime)) {\n        addQuickTimeMetadataTagBoxes(boxes, muxer.output._metadataTags);\n    }\n    if (boxes.length === 0) {\n        return null;\n    }\n    return box('udta', undefined, boxes);\n};\nconst addQuickTimeMetadataTagBoxes = (boxes, tags) => {\n    // https://exiftool.org/TagNames/QuickTime.html (QuickTime UserData Tags)\n    // For QuickTime files, metadata tags are dumped into the udta box\n    for (const { key, value } of keyValueIterator(tags)) {\n        switch (key) {\n            case 'title':\n                {\n                    boxes.push(metadataTagStringBoxShort('nam', value));\n                }\n                ;\n                break;\n            case 'description':\n                {\n                    boxes.push(metadataTagStringBoxShort('des', value));\n                }\n                ;\n                break;\n            case 'artist':\n                {\n                    boxes.push(metadataTagStringBoxShort('ART', value));\n                }\n                ;\n                break;\n            case 'album':\n                {\n                    boxes.push(metadataTagStringBoxShort('alb', value));\n                }\n                ;\n                break;\n            case 'albumArtist':\n                {\n                    boxes.push(metadataTagStringBoxShort('albr', value));\n                }\n                ;\n                break;\n            case 'genre':\n                {\n                    boxes.push(metadataTagStringBoxShort('gen', value));\n                }\n                ;\n                break;\n            case 'date':\n                {\n                    boxes.push(metadataTagStringBoxShort('day', value.toISOString().slice(0, 10)));\n                }\n                ;\n                break;\n            case 'comment':\n                {\n                    boxes.push(metadataTagStringBoxShort('cmt', value));\n                }\n                ;\n                break;\n            case 'lyrics':\n                {\n                    boxes.push(metadataTagStringBoxShort('lyr', value));\n                }\n                ;\n                break;\n            case 'raw':\n                {\n                    // Handled later\n                }\n                ;\n                break;\n            case 'discNumber':\n            case 'discsTotal':\n            case 'trackNumber':\n            case 'tracksTotal':\n            case 'images':\n                {\n                    // Not written for QuickTime (common Apple L)\n                }\n                ;\n                break;\n            default: assertNever(key);\n        }\n    }\n    if (tags.raw) {\n        for (const key in tags.raw) {\n            const value = tags.raw[key];\n            if (value == null || key.length !== 4 || boxes.some(x => x.type === key)) {\n                continue;\n            }\n            if (typeof value === 'string') {\n                boxes.push(metadataTagStringBoxShort(key, value));\n            }\n            else if (value instanceof Uint8Array) {\n                boxes.push(box(key, Array.from(value)));\n            }\n        }\n    }\n};\nconst metadataTagStringBoxShort = (name, value) => {\n    const encoded = textEncoder.encode(value);\n    return box(name, [\n        u16(encoded.length),\n        u16(getLanguageCodeInt('und')),\n        Array.from(encoded),\n    ]);\n};\nconst DATA_BOX_MIME_TYPE_MAP = {\n    'image/jpeg': 13,\n    'image/png': 14,\n    'image/bmp': 27,\n};\n/**\n * Generates key-value metadata for inclusion in the \"meta\" box.\n */\nconst generateMetadataPairs = (tags, isMdta) => {\n    const pairs = [];\n    // https://exiftool.org/TagNames/QuickTime.html (QuickTime ItemList Tags)\n    // This is the metadata format used for MP4 files\n    for (const { key, value } of keyValueIterator(tags)) {\n        switch (key) {\n            case 'title':\n                {\n                    pairs.push({ key: isMdta ? 'title' : 'nam', value: dataStringBoxLong(value) });\n                }\n                ;\n                break;\n            case 'description':\n                {\n                    pairs.push({ key: isMdta ? 'description' : 'des', value: dataStringBoxLong(value) });\n                }\n                ;\n                break;\n            case 'artist':\n                {\n                    pairs.push({ key: isMdta ? 'artist' : 'ART', value: dataStringBoxLong(value) });\n                }\n                ;\n                break;\n            case 'album':\n                {\n                    pairs.push({ key: isMdta ? 'album' : 'alb', value: dataStringBoxLong(value) });\n                }\n                ;\n                break;\n            case 'albumArtist':\n                {\n                    pairs.push({ key: isMdta ? 'album_artist' : 'aART', value: dataStringBoxLong(value) });\n                }\n                ;\n                break;\n            case 'comment':\n                {\n                    pairs.push({ key: isMdta ? 'comment' : 'cmt', value: dataStringBoxLong(value) });\n                }\n                ;\n                break;\n            case 'genre':\n                {\n                    pairs.push({ key: isMdta ? 'genre' : 'gen', value: dataStringBoxLong(value) });\n                }\n                ;\n                break;\n            case 'lyrics':\n                {\n                    pairs.push({ key: isMdta ? 'lyrics' : 'lyr', value: dataStringBoxLong(value) });\n                }\n                ;\n                break;\n            case 'date':\n                {\n                    pairs.push({\n                        key: isMdta ? 'date' : 'day',\n                        value: dataStringBoxLong(value.toISOString().slice(0, 10)),\n                    });\n                }\n                ;\n                break;\n            case 'images':\n                {\n                    for (const image of value) {\n                        if (image.kind !== 'coverFront') {\n                            continue;\n                        }\n                        pairs.push({ key: 'covr', value: box('data', [\n                                u32(DATA_BOX_MIME_TYPE_MAP[image.mimeType] ?? 0), // Type indicator\n                                u32(0), // Locale indicator\n                                Array.from(image.data), // Kinda slow, hopefully temp\n                            ]) });\n                    }\n                }\n                ;\n                break;\n            case 'trackNumber':\n                {\n                    if (isMdta) {\n                        const string = tags.tracksTotal !== undefined\n                            ? `${value}/${tags.tracksTotal}`\n                            : value.toString();\n                        pairs.push({ key: 'track', value: dataStringBoxLong(string) });\n                    }\n                    else {\n                        pairs.push({ key: 'trkn', value: box('data', [\n                                u32(0), // 8 bytes empty\n                                u32(0),\n                                u16(0), // Empty\n                                u16(value),\n                                u16(tags.tracksTotal ?? 0),\n                                u16(0), // Empty\n                            ]) });\n                    }\n                }\n                ;\n                break;\n            case 'discNumber':\n                {\n                    if (!isMdta) {\n                        // Only written for mdir\n                        pairs.push({ key: 'disc', value: box('data', [\n                                u32(0), // 8 bytes empty\n                                u32(0),\n                                u16(0), // Empty\n                                u16(value),\n                                u16(tags.discsTotal ?? 0),\n                                u16(0), // Empty\n                            ]) });\n                    }\n                }\n                ;\n                break;\n            case 'tracksTotal':\n            case 'discsTotal':\n                {\n                    // These are included with 'trackNumber' and 'discNumber' respectively\n                }\n                ;\n                break;\n            case 'raw':\n                {\n                    // Handled later\n                }\n                ;\n                break;\n            default: assertNever(key);\n        }\n    }\n    if (tags.raw) {\n        for (const key in tags.raw) {\n            const value = tags.raw[key];\n            if (value == null || (!isMdta && key.length !== 4) || pairs.some(x => x.key === key)) {\n                continue;\n            }\n            if (typeof value === 'string') {\n                pairs.push({ key, value: dataStringBoxLong(value) });\n            }\n            else if (value instanceof Uint8Array) {\n                pairs.push({ key, value: box('data', [\n                        u32(0), // Type indicator\n                        u32(0), // Locale indicator\n                        Array.from(value),\n                    ]) });\n            }\n            else if (value instanceof RichImageData) {\n                pairs.push({ key, value: box('data', [\n                        u32(DATA_BOX_MIME_TYPE_MAP[value.mimeType] ?? 0), // Type indicator\n                        u32(0), // Locale indicator\n                        Array.from(value.data), // Kinda slow, hopefully temp\n                    ]) });\n            }\n        }\n    }\n    return pairs;\n};\n/** Metadata Box (mdir format) */\nconst metaMdir = (tags) => {\n    const pairs = generateMetadataPairs(tags, false);\n    if (pairs.length === 0) {\n        return null;\n    }\n    // fullBox format\n    return fullBox('meta', 0, 0, undefined, [\n        hdlr(false, 'mdir', '', 'appl'), // mdir handler\n        box('ilst', undefined, pairs.map(pair => box(pair.key, undefined, [pair.value]))), // Item list without keys box\n    ]);\n};\n/** Metadata Box (mdta format with keys box) */\nconst metaMdta = (tags) => {\n    const pairs = generateMetadataPairs(tags, true);\n    if (pairs.length === 0) {\n        return null;\n    }\n    // box without version and flags\n    return box('meta', undefined, [\n        hdlr(false, 'mdta', ''), // mdta handler\n        fullBox('keys', 0, 0, [\n            u32(pairs.length),\n        ], pairs.map(pair => box('mdta', [\n            ...textEncoder.encode(pair.key),\n        ]))),\n        box('ilst', undefined, pairs.map((pair, i) => {\n            const boxName = String.fromCharCode(...u32(i + 1));\n            return box(boxName, undefined, [pair.value]);\n        })),\n    ]);\n};\nconst dataStringBoxLong = (value) => {\n    return box('data', [\n        u32(1), // Type indicator (UTF-8)\n        u32(0), // Locale indicator\n        ...textEncoder.encode(value),\n    ]);\n};\nconst videoCodecToBoxName = (codec, fullCodecString) => {\n    switch (codec) {\n        case 'avc': return fullCodecString.startsWith('avc3') ? 'avc3' : 'avc1';\n        case 'hevc': return 'hvc1';\n        case 'vp8': return 'vp08';\n        case 'vp9': return 'vp09';\n        case 'av1': return 'av01';\n    }\n};\nconst VIDEO_CODEC_TO_CONFIGURATION_BOX = {\n    avc: avcC,\n    hevc: hvcC,\n    vp8: vpcC,\n    vp9: vpcC,\n    av1: av1C,\n};\nconst audioCodecToBoxName = (codec, isQuickTime) => {\n    switch (codec) {\n        case 'aac': return 'mp4a';\n        case 'mp3': return 'mp4a';\n        case 'opus': return 'Opus';\n        case 'vorbis': return 'mp4a';\n        case 'flac': return 'fLaC';\n        case 'ulaw': return 'ulaw';\n        case 'alaw': return 'alaw';\n        case 'pcm-u8': return 'raw ';\n        case 'pcm-s8': return 'sowt';\n    }\n    // Logic diverges here\n    if (isQuickTime) {\n        switch (codec) {\n            case 'pcm-s16': return 'sowt';\n            case 'pcm-s16be': return 'twos';\n            case 'pcm-s24': return 'in24';\n            case 'pcm-s24be': return 'in24';\n            case 'pcm-s32': return 'in32';\n            case 'pcm-s32be': return 'in32';\n            case 'pcm-f32': return 'fl32';\n            case 'pcm-f32be': return 'fl32';\n            case 'pcm-f64': return 'fl64';\n            case 'pcm-f64be': return 'fl64';\n        }\n    }\n    else {\n        switch (codec) {\n            case 'pcm-s16': return 'ipcm';\n            case 'pcm-s16be': return 'ipcm';\n            case 'pcm-s24': return 'ipcm';\n            case 'pcm-s24be': return 'ipcm';\n            case 'pcm-s32': return 'ipcm';\n            case 'pcm-s32be': return 'ipcm';\n            case 'pcm-f32': return 'fpcm';\n            case 'pcm-f32be': return 'fpcm';\n            case 'pcm-f64': return 'fpcm';\n            case 'pcm-f64be': return 'fpcm';\n        }\n    }\n};\nconst audioCodecToConfigurationBox = (codec, isQuickTime) => {\n    switch (codec) {\n        case 'aac': return esds;\n        case 'mp3': return esds;\n        case 'opus': return dOps;\n        case 'vorbis': return esds;\n        case 'flac': return dfLa;\n    }\n    // Logic diverges here\n    if (isQuickTime) {\n        switch (codec) {\n            case 'pcm-s24': return wave;\n            case 'pcm-s24be': return wave;\n            case 'pcm-s32': return wave;\n            case 'pcm-s32be': return wave;\n            case 'pcm-f32': return wave;\n            case 'pcm-f32be': return wave;\n            case 'pcm-f64': return wave;\n            case 'pcm-f64be': return wave;\n        }\n    }\n    else {\n        switch (codec) {\n            case 'pcm-s16': return pcmC;\n            case 'pcm-s16be': return pcmC;\n            case 'pcm-s24': return pcmC;\n            case 'pcm-s24be': return pcmC;\n            case 'pcm-s32': return pcmC;\n            case 'pcm-s32be': return pcmC;\n            case 'pcm-f32': return pcmC;\n            case 'pcm-f32be': return pcmC;\n            case 'pcm-f64': return pcmC;\n            case 'pcm-f64be': return pcmC;\n        }\n    }\n    return null;\n};\nconst SUBTITLE_CODEC_TO_BOX_NAME = {\n    webvtt: 'wvtt',\n};\nconst SUBTITLE_CODEC_TO_CONFIGURATION_BOX = {\n    webvtt: vttC,\n};\nconst getLanguageCodeInt = (code) => {\n    assert(code.length === 3);\n    ;\n    let language = 0;\n    for (let i = 0; i < 3; i++) {\n        language <<= 5;\n        language += code.charCodeAt(i) - 0x60;\n    }\n    return language;\n};\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { assert } from './misc.js';\nexport class Writer {\n    constructor() {\n        /** Setting this to true will cause the writer to ensure data is written in a strictly monotonic, streamable way. */\n        this.ensureMonotonicity = false;\n        this.trackedWrites = null;\n        this.trackedStart = -1;\n        this.trackedEnd = -1;\n    }\n    start() { }\n    maybeTrackWrites(data) {\n        if (!this.trackedWrites) {\n            return;\n        }\n        // Handle negative relative write positions\n        let pos = this.getPos();\n        if (pos < this.trackedStart) {\n            if (pos + data.byteLength <= this.trackedStart) {\n                return;\n            }\n            data = data.subarray(this.trackedStart - pos);\n            pos = 0;\n        }\n        const neededSize = pos + data.byteLength - this.trackedStart;\n        let newLength = this.trackedWrites.byteLength;\n        while (newLength < neededSize) {\n            newLength *= 2;\n        }\n        // Check if we need to resize the buffer\n        if (newLength !== this.trackedWrites.byteLength) {\n            const copy = new Uint8Array(newLength);\n            copy.set(this.trackedWrites, 0);\n            this.trackedWrites = copy;\n        }\n        this.trackedWrites.set(data, pos - this.trackedStart);\n        this.trackedEnd = Math.max(this.trackedEnd, pos + data.byteLength);\n    }\n    startTrackingWrites() {\n        this.trackedWrites = new Uint8Array(2 ** 10);\n        this.trackedStart = this.getPos();\n        this.trackedEnd = this.trackedStart;\n    }\n    stopTrackingWrites() {\n        if (!this.trackedWrites) {\n            throw new Error('Internal error: Can\\'t get tracked writes since nothing was tracked.');\n        }\n        const slice = this.trackedWrites.subarray(0, this.trackedEnd - this.trackedStart);\n        const result = {\n            data: slice,\n            start: this.trackedStart,\n            end: this.trackedEnd,\n        };\n        this.trackedWrites = null;\n        return result;\n    }\n}\nconst ARRAY_BUFFER_INITIAL_SIZE = 2 ** 16;\nconst ARRAY_BUFFER_MAX_SIZE = 2 ** 32;\nexport class BufferTargetWriter extends Writer {\n    constructor(target) {\n        super();\n        this.pos = 0;\n        this.maxPos = 0;\n        this.target = target;\n        this.supportsResize = 'resize' in new ArrayBuffer(0);\n        if (this.supportsResize) {\n            try {\n                // @ts-expect-error Don't want to bump \"lib\" in tsconfig\n                this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE, { maxByteLength: ARRAY_BUFFER_MAX_SIZE });\n            }\n            catch {\n                this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE);\n                this.supportsResize = false;\n            }\n        }\n        else {\n            this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE);\n        }\n        this.bytes = new Uint8Array(this.buffer);\n    }\n    ensureSize(size) {\n        let newLength = this.buffer.byteLength;\n        while (newLength < size)\n            newLength *= 2;\n        if (newLength === this.buffer.byteLength)\n            return;\n        if (newLength > ARRAY_BUFFER_MAX_SIZE) {\n            throw new Error(`ArrayBuffer exceeded maximum size of ${ARRAY_BUFFER_MAX_SIZE} bytes. Please consider using another`\n                + ` target.`);\n        }\n        if (this.supportsResize) {\n            // Use resize if it exists\n            // @ts-expect-error Don't want to bump \"lib\" in tsconfig\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-call\n            this.buffer.resize(newLength);\n            // The Uint8Array scales automatically\n        }\n        else {\n            const newBuffer = new ArrayBuffer(newLength);\n            const newBytes = new Uint8Array(newBuffer);\n            newBytes.set(this.bytes, 0);\n            this.buffer = newBuffer;\n            this.bytes = newBytes;\n        }\n    }\n    write(data) {\n        this.maybeTrackWrites(data);\n        this.ensureSize(this.pos + data.byteLength);\n        this.bytes.set(data, this.pos);\n        this.target.onwrite?.(this.pos, this.pos + data.byteLength);\n        this.pos += data.byteLength;\n        this.maxPos = Math.max(this.maxPos, this.pos);\n    }\n    seek(newPos) {\n        this.pos = newPos;\n    }\n    getPos() {\n        return this.pos;\n    }\n    async flush() { }\n    async finalize() {\n        this.ensureSize(this.pos);\n        this.target.buffer = this.buffer.slice(0, Math.max(this.maxPos, this.pos));\n    }\n    async close() { }\n    getSlice(start, end) {\n        return this.bytes.slice(start, end);\n    }\n}\nconst DEFAULT_CHUNK_SIZE = 2 ** 24;\nconst MAX_CHUNKS_AT_ONCE = 2;\n/**\n * Writes to a StreamTarget every time it is flushed, sending out all of the new data written since the\n * last flush. This is useful for streaming applications, like piping the output to disk. When using the chunked mode,\n * data will first be accumulated in larger chunks, and then the entire chunk will be flushed out at once when ready.\n */\nexport class StreamTargetWriter extends Writer {\n    constructor(target) {\n        super();\n        this.pos = 0;\n        this.sections = [];\n        this.lastWriteEnd = 0;\n        this.lastFlushEnd = 0;\n        this.writer = null;\n        /**\n         * The data is divided up into fixed-size chunks, whose contents are first filled in RAM and then flushed out.\n         * A chunk is flushed if all of its contents have been written.\n         */\n        this.chunks = [];\n        this.target = target;\n        this.chunked = target._options.chunked ?? false;\n        this.chunkSize = target._options.chunkSize ?? DEFAULT_CHUNK_SIZE;\n    }\n    start() {\n        this.writer = this.target._writable.getWriter();\n    }\n    write(data) {\n        if (this.pos > this.lastWriteEnd) {\n            const paddingBytesNeeded = this.pos - this.lastWriteEnd;\n            this.pos = this.lastWriteEnd;\n            this.write(new Uint8Array(paddingBytesNeeded));\n        }\n        this.maybeTrackWrites(data);\n        this.sections.push({\n            data: data.slice(),\n            start: this.pos,\n        });\n        this.target.onwrite?.(this.pos, this.pos + data.byteLength);\n        this.pos += data.byteLength;\n        this.lastWriteEnd = Math.max(this.lastWriteEnd, this.pos);\n    }\n    seek(newPos) {\n        this.pos = newPos;\n    }\n    getPos() {\n        return this.pos;\n    }\n    async flush() {\n        if (this.pos > this.lastWriteEnd) {\n            // There's a \"void\" between the last written byte and the next byte we're about to write. Let's pad that\n            // void with zeroes explicitly.\n            const paddingBytesNeeded = this.pos - this.lastWriteEnd;\n            this.pos = this.lastWriteEnd;\n            this.write(new Uint8Array(paddingBytesNeeded));\n        }\n        assert(this.writer);\n        if (this.sections.length === 0)\n            return;\n        const chunks = [];\n        const sorted = [...this.sections].sort((a, b) => a.start - b.start);\n        chunks.push({\n            start: sorted[0].start,\n            size: sorted[0].data.byteLength,\n        });\n        // Figure out how many contiguous chunks we have\n        for (let i = 1; i < sorted.length; i++) {\n            const lastChunk = chunks[chunks.length - 1];\n            const section = sorted[i];\n            if (section.start <= lastChunk.start + lastChunk.size) {\n                lastChunk.size = Math.max(lastChunk.size, section.start + section.data.byteLength - lastChunk.start);\n            }\n            else {\n                chunks.push({\n                    start: section.start,\n                    size: section.data.byteLength,\n                });\n            }\n        }\n        for (const chunk of chunks) {\n            chunk.data = new Uint8Array(chunk.size);\n            // Make sure to write the data in the correct order for correct overwriting\n            for (const section of this.sections) {\n                // Check if the section is in the chunk\n                if (chunk.start <= section.start && section.start < chunk.start + chunk.size) {\n                    chunk.data.set(section.data, section.start - chunk.start);\n                }\n            }\n            if (this.writer.desiredSize !== null && this.writer.desiredSize <= 0) {\n                await this.writer.ready; // Allow the writer to apply backpressure\n            }\n            if (this.chunked) {\n                // Let's first gather the data into bigger chunks before writing it\n                this.writeDataIntoChunks(chunk.data, chunk.start);\n                this.tryToFlushChunks();\n            }\n            else {\n                if (this.ensureMonotonicity && chunk.start !== this.lastFlushEnd) {\n                    throw new Error('Internal error: Monotonicity violation.');\n                }\n                // Write out the data immediately\n                void this.writer.write({\n                    type: 'write',\n                    data: chunk.data,\n                    position: chunk.start,\n                });\n                this.lastFlushEnd = chunk.start + chunk.data.byteLength;\n            }\n        }\n        this.sections.length = 0;\n    }\n    writeDataIntoChunks(data, position) {\n        // First, find the chunk to write the data into, or create one if none exists\n        let chunkIndex = this.chunks.findIndex(x => x.start <= position && position < x.start + this.chunkSize);\n        if (chunkIndex === -1)\n            chunkIndex = this.createChunk(position);\n        const chunk = this.chunks[chunkIndex];\n        // Figure out how much to write to the chunk, and then write to the chunk\n        const relativePosition = position - chunk.start;\n        const toWrite = data.subarray(0, Math.min(this.chunkSize - relativePosition, data.byteLength));\n        chunk.data.set(toWrite, relativePosition);\n        // Create a section describing the region of data that was just written to\n        const section = {\n            start: relativePosition,\n            end: relativePosition + toWrite.byteLength,\n        };\n        this.insertSectionIntoChunk(chunk, section);\n        // Queue chunk for flushing to target if it has been fully written to\n        if (chunk.written[0].start === 0 && chunk.written[0].end === this.chunkSize) {\n            chunk.shouldFlush = true;\n        }\n        // Make sure we don't hold too many chunks in memory at once to keep memory usage down\n        if (this.chunks.length > MAX_CHUNKS_AT_ONCE) {\n            // Flush all but the last chunk\n            for (let i = 0; i < this.chunks.length - 1; i++) {\n                this.chunks[i].shouldFlush = true;\n            }\n            this.tryToFlushChunks();\n        }\n        // If the data didn't fit in one chunk, recurse with the remaining data\n        if (toWrite.byteLength < data.byteLength) {\n            this.writeDataIntoChunks(data.subarray(toWrite.byteLength), position + toWrite.byteLength);\n        }\n    }\n    insertSectionIntoChunk(chunk, section) {\n        let low = 0;\n        let high = chunk.written.length - 1;\n        let index = -1;\n        // Do a binary search to find the last section with a start not larger than `section`'s start\n        while (low <= high) {\n            const mid = Math.floor(low + (high - low + 1) / 2);\n            if (chunk.written[mid].start <= section.start) {\n                low = mid + 1;\n                index = mid;\n            }\n            else {\n                high = mid - 1;\n            }\n        }\n        // Insert the new section\n        chunk.written.splice(index + 1, 0, section);\n        if (index === -1 || chunk.written[index].end < section.start)\n            index++;\n        // Merge overlapping sections\n        while (index < chunk.written.length - 1 && chunk.written[index].end >= chunk.written[index + 1].start) {\n            chunk.written[index].end = Math.max(chunk.written[index].end, chunk.written[index + 1].end);\n            chunk.written.splice(index + 1, 1);\n        }\n    }\n    createChunk(includesPosition) {\n        const start = Math.floor(includesPosition / this.chunkSize) * this.chunkSize;\n        const chunk = {\n            start,\n            data: new Uint8Array(this.chunkSize),\n            written: [],\n            shouldFlush: false,\n        };\n        this.chunks.push(chunk);\n        this.chunks.sort((a, b) => a.start - b.start);\n        return this.chunks.indexOf(chunk);\n    }\n    tryToFlushChunks(force = false) {\n        assert(this.writer);\n        for (let i = 0; i < this.chunks.length; i++) {\n            const chunk = this.chunks[i];\n            if (!chunk.shouldFlush && !force)\n                continue;\n            for (const section of chunk.written) {\n                const position = chunk.start + section.start;\n                if (this.ensureMonotonicity && position !== this.lastFlushEnd) {\n                    throw new Error('Internal error: Monotonicity violation.');\n                }\n                void this.writer.write({\n                    type: 'write',\n                    data: chunk.data.subarray(section.start, section.end),\n                    position,\n                });\n                this.lastFlushEnd = chunk.start + section.end;\n            }\n            this.chunks.splice(i--, 1);\n        }\n    }\n    finalize() {\n        if (this.chunked) {\n            this.tryToFlushChunks(true);\n        }\n        assert(this.writer);\n        return this.writer.close();\n    }\n    async close() {\n        return this.writer?.close();\n    }\n}\nexport class NullTargetWriter extends Writer {\n    constructor(target) {\n        super();\n        this.target = target;\n        this.pos = 0;\n    }\n    write(data) {\n        this.maybeTrackWrites(data);\n        this.target.onwrite?.(this.pos, this.pos + data.byteLength);\n        this.pos += data.byteLength;\n    }\n    getPos() {\n        return this.pos;\n    }\n    seek(newPos) {\n        this.pos = newPos;\n    }\n    async flush() { }\n    async finalize() { }\n    async close() { }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { BufferTargetWriter, NullTargetWriter, StreamTargetWriter } from './writer.js';\nimport * as nodeAlias from './node.js';\nimport { assert } from './misc.js';\nconst node = typeof nodeAlias !== 'undefined'\n    ? nodeAlias // Aliasing it prevents some bundler warnings\n    : undefined;\n/**\n * Base class for targets, specifying where output files are written.\n * @group Output targets\n * @public\n */\nexport class Target {\n    constructor() {\n        /** @internal */\n        this._output = null;\n        /**\n         * Called each time data is written to the target. Will be called with the byte range into which data was written.\n         *\n         * Use this callback to track the size of the output file as it grows. But be warned, this function is chatty and\n         * gets called *extremely* often.\n         */\n        this.onwrite = null;\n    }\n}\n/**\n * A target that writes data directly into an ArrayBuffer in memory. Great for performance, but not suitable for very\n * large files. The buffer will be available once the output has been finalized.\n * @group Output targets\n * @public\n */\nexport class BufferTarget extends Target {\n    constructor() {\n        super(...arguments);\n        /** Stores the final output buffer. Until the output is finalized, this will be `null`. */\n        this.buffer = null;\n    }\n    /** @internal */\n    _createWriter() {\n        return new BufferTargetWriter(this);\n    }\n}\n/**\n * This target writes data to a [`WritableStream`](https://developer.mozilla.org/en-US/docs/Web/API/WritableStream),\n * making it a general-purpose target for writing data anywhere. It is also compatible with\n * [`FileSystemWritableFileStream`](https://developer.mozilla.org/en-US/docs/Web/API/FileSystemWritableFileStream) for\n * use with the [File System Access API](https://developer.mozilla.org/en-US/docs/Web/API/File_System_API). The\n * `WritableStream` can also apply backpressure, which will propagate to the output and throttle the encoders.\n * @group Output targets\n * @public\n */\nexport class StreamTarget extends Target {\n    /** Creates a new {@link StreamTarget} which writes to the specified `writable`. */\n    constructor(writable, options = {}) {\n        super();\n        if (!(writable instanceof WritableStream)) {\n            throw new TypeError('StreamTarget requires a WritableStream instance.');\n        }\n        if (options != null && typeof options !== 'object') {\n            throw new TypeError('StreamTarget options, when provided, must be an object.');\n        }\n        if (options.chunked !== undefined && typeof options.chunked !== 'boolean') {\n            throw new TypeError('options.chunked, when provided, must be a boolean.');\n        }\n        if (options.chunkSize !== undefined && (!Number.isInteger(options.chunkSize) || options.chunkSize < 1024)) {\n            throw new TypeError('options.chunkSize, when provided, must be an integer and not smaller than 1024.');\n        }\n        this._writable = writable;\n        this._options = options;\n    }\n    /** @internal */\n    _createWriter() {\n        return new StreamTargetWriter(this);\n    }\n}\n/**\n * A target that writes to a file at the specified path. Intended for server-side usage in Node, Bun, or Deno.\n *\n * Writing is chunked by default. The internally held file handle will be closed when `.finalize()` or `.cancel()` are\n * called on the corresponding {@link Output}.\n * @group Output targets\n * @public\n */\nexport class FilePathTarget extends Target {\n    /** Creates a new {@link FilePathTarget} that writes to the file at the specified file path. */\n    constructor(filePath, options = {}) {\n        if (typeof filePath !== 'string') {\n            throw new TypeError('filePath must be a string.');\n        }\n        if (!options || typeof options !== 'object') {\n            throw new TypeError('options must be an object.');\n        }\n        super();\n        /** @internal */\n        this._fileHandle = null;\n        // Let's back this target with a StreamTarget, makes the implementation very simple\n        const writable = new WritableStream({\n            start: async () => {\n                this._fileHandle = await node.fs.open(filePath, 'w');\n            },\n            write: async (chunk) => {\n                assert(this._fileHandle);\n                await this._fileHandle.write(chunk.data, 0, chunk.data.byteLength, chunk.position);\n            },\n            close: async () => {\n                if (this._fileHandle) {\n                    await this._fileHandle.close();\n                    this._fileHandle = null;\n                }\n            },\n        });\n        this._streamTarget = new StreamTarget(writable, {\n            chunked: true,\n            ...options,\n        });\n        this._streamTarget._output = this._output;\n    }\n    /** @internal */\n    _createWriter() {\n        return this._streamTarget._createWriter();\n    }\n}\n/**\n * This target just discards all incoming data. It is useful for when you need an {@link Output} but extract data from\n * it differently, for example through format-specific callbacks (`onMoof`, `onMdat`, ...) or encoder events.\n * @group Output targets\n * @public\n */\nexport class NullTarget extends Target {\n    /** @internal */\n    _createWriter() {\n        return new NullTargetWriter(this);\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { free, ftyp, IsobmffBoxWriter, mdat, mfra, moof, moov, vtta, vttc, vtte } from './isobmff-boxes.js';\nimport { Muxer } from '../muxer.js';\nimport { BufferTargetWriter } from '../writer.js';\nimport { assert, computeRationalApproximation, last, promiseWithResolvers } from '../misc.js';\nimport { MovOutputFormat } from '../output-format.js';\nimport { inlineTimestampRegex } from '../subtitles.js';\nimport { aacChannelMap, aacFrequencyTable, buildAacAudioSpecificConfig, parsePcmCodec, PCM_AUDIO_CODECS, validateAudioChunkMetadata, validateSubtitleMetadata, validateVideoChunkMetadata, } from '../codec.js';\nimport { MAX_ADTS_FRAME_HEADER_SIZE, MIN_ADTS_FRAME_HEADER_SIZE, readAdtsFrameHeader } from '../adts/adts-reader.js';\nimport { FileSlice } from '../reader.js';\nimport { BufferTarget } from '../target.js';\nimport { concatNalUnitsInLengthPrefixed, extractAvcDecoderConfigurationRecord, extractHevcDecoderConfigurationRecord, iterateNalUnitsInAnnexB, serializeAvcDecoderConfigurationRecord, serializeHevcDecoderConfigurationRecord, } from '../codec-data.js';\nimport { buildIsobmffMimeType } from './isobmff-misc.js';\nimport { MAX_BOX_HEADER_SIZE, MIN_BOX_HEADER_SIZE } from './isobmff-reader.js';\nexport const GLOBAL_TIMESCALE = 1000;\nconst TIMESTAMP_OFFSET = 2_082_844_800; // Seconds between Jan 1 1904 and Jan 1 1970\nexport const getTrackMetadata = (trackData) => {\n    const metadata = {};\n    const track = trackData.track;\n    if (track.metadata.name !== undefined) {\n        metadata.name = track.metadata.name;\n    }\n    return metadata;\n};\nexport const intoTimescale = (timeInSeconds, timescale, round = true) => {\n    const value = timeInSeconds * timescale;\n    return round ? Math.round(value) : value;\n};\nexport class IsobmffMuxer extends Muxer {\n    constructor(output, format) {\n        super(output);\n        this.auxTarget = new BufferTarget();\n        this.auxWriter = this.auxTarget._createWriter();\n        this.auxBoxWriter = new IsobmffBoxWriter(this.auxWriter);\n        this.mdat = null;\n        this.ftypSize = null;\n        this.trackDatas = [];\n        this.allTracksKnown = promiseWithResolvers();\n        this.creationTime = Math.floor(Date.now() / 1000) + TIMESTAMP_OFFSET;\n        this.finalizedChunks = [];\n        this.nextFragmentNumber = 1;\n        // Only relevant for fragmented files, to make sure new fragments start with the highest timestamp seen so far\n        this.maxWrittenTimestamp = -Infinity;\n        this.format = format;\n        this.writer = output._writer;\n        this.boxWriter = new IsobmffBoxWriter(this.writer);\n        this.isQuickTime = format instanceof MovOutputFormat;\n        // If the fastStart option isn't defined, enable in-memory fast start if the target is an ArrayBuffer, as the\n        // memory usage remains identical\n        const fastStartDefault = this.writer instanceof BufferTargetWriter ? 'in-memory' : false;\n        this.fastStart = format._options.fastStart ?? fastStartDefault;\n        this.isFragmented = this.fastStart === 'fragmented';\n        if (this.fastStart === 'in-memory' || this.isFragmented) {\n            this.writer.ensureMonotonicity = true;\n        }\n        this.minimumFragmentDuration = format._options.minimumFragmentDuration ?? 1;\n    }\n    async start() {\n        const release = await this.mutex.acquire();\n        const holdsAvc = this.output._tracks.some(x => x.type === 'video' && x.source._codec === 'avc');\n        // Write the header\n        {\n            if (this.format._options.onFtyp) {\n                this.writer.startTrackingWrites();\n            }\n            this.boxWriter.writeBox(ftyp({\n                isQuickTime: this.isQuickTime,\n                holdsAvc: holdsAvc,\n                fragmented: this.isFragmented,\n            }));\n            if (this.format._options.onFtyp) {\n                const { data, start } = this.writer.stopTrackingWrites();\n                this.format._options.onFtyp(data, start);\n            }\n        }\n        this.ftypSize = this.writer.getPos();\n        if (this.fastStart === 'in-memory') {\n            // We're write at finalization\n        }\n        else if (this.fastStart === 'reserve') {\n            // Validate that all tracks have set maximumPacketCount\n            for (const track of this.output._tracks) {\n                if (track.metadata.maximumPacketCount === undefined) {\n                    throw new Error('All tracks must specify maximumPacketCount in their metadata when using'\n                        + ' fastStart: \\'reserve\\'.');\n                }\n            }\n            // We'll start writing once we know all tracks\n        }\n        else if (this.isFragmented) {\n            // We write the moov box once we write out the first fragment to make sure we get the decoder configs\n        }\n        else {\n            if (this.format._options.onMdat) {\n                this.writer.startTrackingWrites();\n            }\n            this.mdat = mdat(true); // Reserve large size by default, can refine this when finalizing.\n            this.boxWriter.writeBox(this.mdat);\n        }\n        await this.writer.flush();\n        release();\n    }\n    allTracksAreKnown() {\n        for (const track of this.output._tracks) {\n            if (!track.source._closed && !this.trackDatas.some(x => x.track === track)) {\n                return false; // We haven't seen a sample from this open track yet\n            }\n        }\n        return true;\n    }\n    async getMimeType() {\n        await this.allTracksKnown.promise;\n        const codecStrings = this.trackDatas.map((trackData) => {\n            if (trackData.type === 'video') {\n                return trackData.info.decoderConfig.codec;\n            }\n            else if (trackData.type === 'audio') {\n                return trackData.info.decoderConfig.codec;\n            }\n            else {\n                const map = {\n                    webvtt: 'wvtt',\n                };\n                return map[trackData.track.source._codec];\n            }\n        });\n        return buildIsobmffMimeType({\n            isQuickTime: this.isQuickTime,\n            hasVideo: this.trackDatas.some(x => x.type === 'video'),\n            hasAudio: this.trackDatas.some(x => x.type === 'audio'),\n            codecStrings,\n        });\n    }\n    getVideoTrackData(track, packet, meta) {\n        const existingTrackData = this.trackDatas.find(x => x.track === track);\n        if (existingTrackData) {\n            return existingTrackData;\n        }\n        validateVideoChunkMetadata(meta);\n        assert(meta);\n        assert(meta.decoderConfig);\n        const decoderConfig = { ...meta.decoderConfig };\n        assert(decoderConfig.codedWidth !== undefined);\n        assert(decoderConfig.codedHeight !== undefined);\n        let requiresAnnexBTransformation = false;\n        if (track.source._codec === 'avc' && !decoderConfig.description) {\n            // ISOBMFF can only hold AVC in the AVCC format, not in Annex B, but the missing description indicates\n            // Annex B. This means we'll need to do some converterino.\n            const decoderConfigurationRecord = extractAvcDecoderConfigurationRecord(packet.data);\n            if (!decoderConfigurationRecord) {\n                throw new Error('Couldn\\'t extract an AVCDecoderConfigurationRecord from the AVC packet. Make sure the packets are'\n                    + ' in Annex B format (as specified in ITU-T-REC-H.264) when not providing a description, or'\n                    + ' provide a description (must be an AVCDecoderConfigurationRecord as specified in ISO 14496-15)'\n                    + ' and ensure the packets are in AVCC format.');\n            }\n            decoderConfig.description = serializeAvcDecoderConfigurationRecord(decoderConfigurationRecord);\n            requiresAnnexBTransformation = true;\n        }\n        else if (track.source._codec === 'hevc' && !decoderConfig.description) {\n            // ISOBMFF can only hold HEVC in the HEVC format, not in Annex B, but the missing description indicates\n            // Annex B. This means we'll need to do some converterino.\n            const decoderConfigurationRecord = extractHevcDecoderConfigurationRecord(packet.data);\n            if (!decoderConfigurationRecord) {\n                throw new Error('Couldn\\'t extract an HEVCDecoderConfigurationRecord from the HEVC packet. Make sure the packets'\n                    + ' are in Annex B format (as specified in ITU-T-REC-H.265) when not providing a description, or'\n                    + ' provide a description (must be an HEVCDecoderConfigurationRecord as specified in ISO 14496-15)'\n                    + ' and ensure the packets are in HEVC format.');\n            }\n            decoderConfig.description = serializeHevcDecoderConfigurationRecord(decoderConfigurationRecord);\n            requiresAnnexBTransformation = true;\n        }\n        // The frame rate set by the user may not be an integer. Since timescale is an integer, we'll approximate the\n        // frame time (inverse of frame rate) with a rational number, then use that approximation's denominator\n        // as the timescale.\n        const timescale = computeRationalApproximation(1 / (track.metadata.frameRate ?? 57600), 1e6).denominator;\n        const newTrackData = {\n            muxer: this,\n            track,\n            type: 'video',\n            info: {\n                width: decoderConfig.codedWidth,\n                height: decoderConfig.codedHeight,\n                decoderConfig: decoderConfig,\n                requiresAnnexBTransformation,\n            },\n            timescale,\n            samples: [],\n            sampleQueue: [],\n            timestampProcessingQueue: [],\n            timeToSampleTable: [],\n            compositionTimeOffsetTable: [],\n            lastTimescaleUnits: null,\n            lastSample: null,\n            finalizedChunks: [],\n            currentChunk: null,\n            compactlyCodedChunkTable: [],\n        };\n        this.trackDatas.push(newTrackData);\n        this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        return newTrackData;\n    }\n    getAudioTrackData(track, packet, meta) {\n        const existingTrackData = this.trackDatas.find(x => x.track === track);\n        if (existingTrackData) {\n            return existingTrackData;\n        }\n        validateAudioChunkMetadata(meta);\n        assert(meta);\n        assert(meta.decoderConfig);\n        const decoderConfig = { ...meta.decoderConfig };\n        let requiresAdtsStripping = false;\n        if (track.source._codec === 'aac' && !decoderConfig.description) {\n            // ISOBMFF can only hold AAC in raw format, not ADTS, but the missing description indicates ADTS.\n            // Parse the first packet to extract the AudioSpecificConfig.\n            const adtsFrame = readAdtsFrameHeader(FileSlice.tempFromBytes(packet.data));\n            if (!adtsFrame) {\n                throw new Error('Couldn\\'t parse ADTS header from the AAC packet. Make sure the packets are in ADTS format'\n                    + ' (as specified in ISO 13818-7) when not providing a description, or provide a description'\n                    + ' (must be an AudioSpecificConfig as specified in ISO 14496-3) and ensure the packets'\n                    + ' are raw AAC data.');\n            }\n            const sampleRate = aacFrequencyTable[adtsFrame.samplingFrequencyIndex];\n            const numberOfChannels = aacChannelMap[adtsFrame.channelConfiguration];\n            if (sampleRate === undefined || numberOfChannels === undefined) {\n                throw new Error('Invalid ADTS frame header.');\n            }\n            decoderConfig.description = buildAacAudioSpecificConfig({\n                objectType: adtsFrame.objectType,\n                sampleRate,\n                numberOfChannels,\n            });\n            requiresAdtsStripping = true;\n        }\n        const newTrackData = {\n            muxer: this,\n            track,\n            type: 'audio',\n            info: {\n                numberOfChannels: meta.decoderConfig.numberOfChannels,\n                sampleRate: meta.decoderConfig.sampleRate,\n                decoderConfig,\n                requiresPcmTransformation: !this.isFragmented\n                    && PCM_AUDIO_CODECS.includes(track.source._codec),\n                requiresAdtsStripping,\n            },\n            timescale: meta.decoderConfig.sampleRate,\n            samples: [],\n            sampleQueue: [],\n            timestampProcessingQueue: [],\n            timeToSampleTable: [],\n            compositionTimeOffsetTable: [],\n            lastTimescaleUnits: null,\n            lastSample: null,\n            finalizedChunks: [],\n            currentChunk: null,\n            compactlyCodedChunkTable: [],\n        };\n        this.trackDatas.push(newTrackData);\n        this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        return newTrackData;\n    }\n    getSubtitleTrackData(track, meta) {\n        const existingTrackData = this.trackDatas.find(x => x.track === track);\n        if (existingTrackData) {\n            return existingTrackData;\n        }\n        validateSubtitleMetadata(meta);\n        assert(meta);\n        assert(meta.config);\n        const newTrackData = {\n            muxer: this,\n            track,\n            type: 'subtitle',\n            info: {\n                config: meta.config,\n            },\n            timescale: 1000, // Reasonable\n            samples: [],\n            sampleQueue: [],\n            timestampProcessingQueue: [],\n            timeToSampleTable: [],\n            compositionTimeOffsetTable: [],\n            lastTimescaleUnits: null,\n            lastSample: null,\n            finalizedChunks: [],\n            currentChunk: null,\n            compactlyCodedChunkTable: [],\n            lastCueEndTimestamp: 0,\n            cueQueue: [],\n            nextSourceId: 0,\n            cueToSourceId: new WeakMap(),\n        };\n        this.trackDatas.push(newTrackData);\n        this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        return newTrackData;\n    }\n    async addEncodedVideoPacket(track, packet, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            const trackData = this.getVideoTrackData(track, packet, meta);\n            let packetData = packet.data;\n            if (trackData.info.requiresAnnexBTransformation) {\n                const nalUnits = [...iterateNalUnitsInAnnexB(packetData)]\n                    .map(loc => packetData.subarray(loc.offset, loc.offset + loc.length));\n                if (nalUnits.length === 0) {\n                    // It's not valid Annex B data\n                    throw new Error('Failed to transform packet data. Make sure all packets are provided in Annex B format, as'\n                        + ' specified in ITU-T-REC-H.264 and ITU-T-REC-H.265.');\n                }\n                // We don't strip things like SPS or PPS NALUs here, mainly because they can also appear in the middle\n                // of a stream and potentially modify the parameters of it. So, let's just leave them in to be sure.\n                packetData = concatNalUnitsInLengthPrefixed(nalUnits, 4);\n            }\n            const timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, packet.type === 'key');\n            const internalSample = this.createSampleForTrack(trackData, packetData, timestamp, packet.duration, packet.type);\n            await this.registerSample(trackData, internalSample);\n        }\n        finally {\n            release();\n        }\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            const trackData = this.getAudioTrackData(track, packet, meta);\n            let packetData = packet.data;\n            if (trackData.info.requiresAdtsStripping) {\n                const adtsFrame = readAdtsFrameHeader(FileSlice.tempFromBytes(packetData));\n                if (!adtsFrame) {\n                    throw new Error('Expected ADTS frame, didn\\'t get one.');\n                }\n                const headerLength = adtsFrame.crcCheck === null\n                    ? MIN_ADTS_FRAME_HEADER_SIZE\n                    : MAX_ADTS_FRAME_HEADER_SIZE;\n                packetData = packetData.subarray(headerLength);\n            }\n            const timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, packet.type === 'key');\n            const internalSample = this.createSampleForTrack(trackData, packetData, timestamp, packet.duration, packet.type);\n            if (trackData.info.requiresPcmTransformation) {\n                await this.maybePadWithSilence(trackData, timestamp);\n            }\n            await this.registerSample(trackData, internalSample);\n        }\n        finally {\n            release();\n        }\n    }\n    async maybePadWithSilence(trackData, untilTimestamp) {\n        // The PCM transformation assumes that all samples are contiguous. This is not something that is enforced, so\n        // we need to pad the \"holes\" in between samples (and before the first sample) with additional\n        // \"silence samples\".\n        const lastSample = last(trackData.samples);\n        const lastEndTimestamp = lastSample\n            ? lastSample.timestamp + lastSample.duration\n            : 0;\n        const delta = untilTimestamp - lastEndTimestamp;\n        const deltaInTimescale = intoTimescale(delta, trackData.timescale);\n        if (deltaInTimescale > 0) {\n            const { sampleSize, silentValue } = parsePcmCodec(trackData.info.decoderConfig.codec);\n            const samplesNeeded = deltaInTimescale * trackData.info.numberOfChannels;\n            const data = new Uint8Array(sampleSize * samplesNeeded).fill(silentValue);\n            const paddingSample = this.createSampleForTrack(trackData, new Uint8Array(data.buffer), lastEndTimestamp, delta, 'key');\n            await this.registerSample(trackData, paddingSample);\n        }\n    }\n    async addSubtitleCue(track, cue, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            const trackData = this.getSubtitleTrackData(track, meta);\n            this.validateAndNormalizeTimestamp(trackData.track, cue.timestamp, true);\n            if (track.source._codec === 'webvtt') {\n                trackData.cueQueue.push(cue);\n                await this.processWebVTTCues(trackData, cue.timestamp);\n            }\n            else {\n                // TODO\n            }\n        }\n        finally {\n            release();\n        }\n    }\n    async processWebVTTCues(trackData, until) {\n        // WebVTT cues need to undergo special processing as empty sections need to be padded out with samples, and\n        // overlapping samples require special logic. The algorithm produces the format specified in ISO 14496-30.\n        while (trackData.cueQueue.length > 0) {\n            const timestamps = new Set([]);\n            for (const cue of trackData.cueQueue) {\n                assert(cue.timestamp <= until);\n                assert(trackData.lastCueEndTimestamp <= cue.timestamp + cue.duration);\n                timestamps.add(Math.max(cue.timestamp, trackData.lastCueEndTimestamp)); // Start timestamp\n                timestamps.add(cue.timestamp + cue.duration); // End timestamp\n            }\n            const sortedTimestamps = [...timestamps].sort((a, b) => a - b);\n            // These are the timestamps of the next sample we'll create:\n            const sampleStart = sortedTimestamps[0];\n            const sampleEnd = sortedTimestamps[1] ?? sampleStart;\n            if (until < sampleEnd) {\n                break;\n            }\n            // We may need to pad out empty space with an vtte box\n            if (trackData.lastCueEndTimestamp < sampleStart) {\n                this.auxWriter.seek(0);\n                const box = vtte();\n                this.auxBoxWriter.writeBox(box);\n                const body = this.auxWriter.getSlice(0, this.auxWriter.getPos());\n                const sample = this.createSampleForTrack(trackData, body, trackData.lastCueEndTimestamp, sampleStart - trackData.lastCueEndTimestamp, 'key');\n                await this.registerSample(trackData, sample);\n                trackData.lastCueEndTimestamp = sampleStart;\n            }\n            this.auxWriter.seek(0);\n            for (let i = 0; i < trackData.cueQueue.length; i++) {\n                const cue = trackData.cueQueue[i];\n                if (cue.timestamp >= sampleEnd) {\n                    break;\n                }\n                inlineTimestampRegex.lastIndex = 0;\n                const containsTimestamp = inlineTimestampRegex.test(cue.text);\n                const endTimestamp = cue.timestamp + cue.duration;\n                let sourceId = trackData.cueToSourceId.get(cue);\n                if (sourceId === undefined && sampleEnd < endTimestamp) {\n                    // We know this cue will appear in more than one sample, therefore we need to mark it with a\n                    // unique ID\n                    sourceId = trackData.nextSourceId++;\n                    trackData.cueToSourceId.set(cue, sourceId);\n                }\n                if (cue.notes) {\n                    // Any notes/comments are included in a special vtta box\n                    const box = vtta(cue.notes);\n                    this.auxBoxWriter.writeBox(box);\n                }\n                const box = vttc(cue.text, containsTimestamp ? sampleStart : null, cue.identifier ?? null, cue.settings ?? null, sourceId ?? null);\n                this.auxBoxWriter.writeBox(box);\n                if (endTimestamp === sampleEnd) {\n                    // The cue won't appear in any future sample, so we're done with it\n                    trackData.cueQueue.splice(i--, 1);\n                }\n            }\n            const body = this.auxWriter.getSlice(0, this.auxWriter.getPos());\n            const sample = this.createSampleForTrack(trackData, body, sampleStart, sampleEnd - sampleStart, 'key');\n            await this.registerSample(trackData, sample);\n            trackData.lastCueEndTimestamp = sampleEnd;\n        }\n    }\n    createSampleForTrack(trackData, data, timestamp, duration, type) {\n        const sample = {\n            timestamp,\n            decodeTimestamp: timestamp, // This may be refined later\n            duration,\n            data,\n            size: data.byteLength,\n            type,\n            timescaleUnitsToNextSample: intoTimescale(duration, trackData.timescale), // Will be refined\n        };\n        return sample;\n    }\n    processTimestamps(trackData, nextSample) {\n        if (trackData.timestampProcessingQueue.length === 0) {\n            return;\n        }\n        if (trackData.type === 'audio' && trackData.info.requiresPcmTransformation) {\n            let totalDuration = 0;\n            // Compute the total duration in the track timescale (which is equal to the amount of PCM audio samples)\n            // and simply say that's how many new samples there are.\n            for (let i = 0; i < trackData.timestampProcessingQueue.length; i++) {\n                const sample = trackData.timestampProcessingQueue[i];\n                const duration = intoTimescale(sample.duration, trackData.timescale);\n                totalDuration += duration;\n            }\n            if (trackData.timeToSampleTable.length === 0) {\n                trackData.timeToSampleTable.push({\n                    sampleCount: totalDuration,\n                    sampleDelta: 1,\n                });\n            }\n            else {\n                const lastEntry = last(trackData.timeToSampleTable);\n                lastEntry.sampleCount += totalDuration;\n            }\n            trackData.timestampProcessingQueue.length = 0;\n            return;\n        }\n        const sortedTimestamps = trackData.timestampProcessingQueue.map(x => x.timestamp).sort((a, b) => a - b);\n        for (let i = 0; i < trackData.timestampProcessingQueue.length; i++) {\n            const sample = trackData.timestampProcessingQueue[i];\n            // Since the user only supplies presentation time, but these may be out of order, we reverse-engineer from\n            // that a sensible decode timestamp. The notion of a decode timestamp doesn't really make sense\n            // (presentation timestamp & decode order are all you need), but it is a concept in ISOBMFF so we need to\n            // model it.\n            sample.decodeTimestamp = sortedTimestamps[i];\n            if (!this.isFragmented && trackData.lastTimescaleUnits === null) {\n                // In non-fragmented files, the first decode timestamp is always zero. If the first presentation\n                // timestamp isn't zero, we'll simply use the composition time offset to achieve it.\n                sample.decodeTimestamp = 0;\n            }\n            const sampleCompositionTimeOffset = intoTimescale(sample.timestamp - sample.decodeTimestamp, trackData.timescale);\n            const durationInTimescale = intoTimescale(sample.duration, trackData.timescale);\n            if (trackData.lastTimescaleUnits !== null) {\n                assert(trackData.lastSample);\n                const timescaleUnits = intoTimescale(sample.decodeTimestamp, trackData.timescale, false);\n                const delta = Math.round(timescaleUnits - trackData.lastTimescaleUnits);\n                assert(delta >= 0);\n                trackData.lastTimescaleUnits += delta;\n                trackData.lastSample.timescaleUnitsToNextSample = delta;\n                if (!this.isFragmented) {\n                    let lastTableEntry = last(trackData.timeToSampleTable);\n                    assert(lastTableEntry);\n                    if (lastTableEntry.sampleCount === 1) {\n                        lastTableEntry.sampleDelta = delta;\n                        const entryBefore = trackData.timeToSampleTable[trackData.timeToSampleTable.length - 2];\n                        if (entryBefore && entryBefore.sampleDelta === delta) {\n                            // If the delta is the same as the previous one, merge the two entries\n                            entryBefore.sampleCount++;\n                            trackData.timeToSampleTable.pop();\n                            lastTableEntry = entryBefore;\n                        }\n                    }\n                    else if (lastTableEntry.sampleDelta !== delta) {\n                        // The delta has changed, so we need a new entry to reach the current sample\n                        lastTableEntry.sampleCount--;\n                        trackData.timeToSampleTable.push(lastTableEntry = {\n                            sampleCount: 1,\n                            sampleDelta: delta,\n                        });\n                    }\n                    if (lastTableEntry.sampleDelta === durationInTimescale) {\n                        // The sample's duration matches the delta, so we can increment the count\n                        lastTableEntry.sampleCount++;\n                    }\n                    else {\n                        // Add a new entry in order to maintain the last sample's true duration\n                        trackData.timeToSampleTable.push({\n                            sampleCount: 1,\n                            sampleDelta: durationInTimescale,\n                        });\n                    }\n                    const lastCompositionTimeOffsetTableEntry = last(trackData.compositionTimeOffsetTable);\n                    assert(lastCompositionTimeOffsetTableEntry);\n                    if (lastCompositionTimeOffsetTableEntry.sampleCompositionTimeOffset === sampleCompositionTimeOffset) {\n                        // Simply increment the count\n                        lastCompositionTimeOffsetTableEntry.sampleCount++;\n                    }\n                    else {\n                        // The composition time offset has changed, so create a new entry with the new composition time\n                        // offset\n                        trackData.compositionTimeOffsetTable.push({\n                            sampleCount: 1,\n                            sampleCompositionTimeOffset: sampleCompositionTimeOffset,\n                        });\n                    }\n                }\n            }\n            else {\n                // Decode timestamp of the first sample\n                trackData.lastTimescaleUnits = intoTimescale(sample.decodeTimestamp, trackData.timescale, false);\n                if (!this.isFragmented) {\n                    trackData.timeToSampleTable.push({\n                        sampleCount: 1,\n                        sampleDelta: durationInTimescale,\n                    });\n                    trackData.compositionTimeOffsetTable.push({\n                        sampleCount: 1,\n                        sampleCompositionTimeOffset: sampleCompositionTimeOffset,\n                    });\n                }\n            }\n            trackData.lastSample = sample;\n        }\n        trackData.timestampProcessingQueue.length = 0;\n        assert(trackData.lastSample);\n        assert(trackData.lastTimescaleUnits !== null);\n        if (nextSample !== undefined && trackData.lastSample.timescaleUnitsToNextSample === 0) {\n            assert(nextSample.type === 'key');\n            // Given the next sample, we can make a guess about the duration of the last sample. This avoids having\n            // the last sample's duration in each fragment be \"0\" for fragmented files. The guess we make here is\n            // actually correct most of the time, since typically, no delta frame with a lower timestamp follows the key\n            // frame (although it can happen).\n            const timescaleUnits = intoTimescale(nextSample.timestamp, trackData.timescale, false);\n            const delta = Math.round(timescaleUnits - trackData.lastTimescaleUnits);\n            trackData.lastSample.timescaleUnitsToNextSample = delta;\n        }\n    }\n    async registerSample(trackData, sample) {\n        if (sample.type === 'key') {\n            this.processTimestamps(trackData, sample);\n        }\n        trackData.timestampProcessingQueue.push(sample);\n        if (this.isFragmented) {\n            trackData.sampleQueue.push(sample);\n            await this.interleaveSamples();\n        }\n        else if (this.fastStart === 'reserve') {\n            await this.registerSampleFastStartReserve(trackData, sample);\n        }\n        else {\n            await this.addSampleToTrack(trackData, sample);\n        }\n    }\n    async addSampleToTrack(trackData, sample) {\n        if (!this.isFragmented) {\n            trackData.samples.push(sample);\n            if (this.fastStart === 'reserve') {\n                const maximumPacketCount = trackData.track.metadata.maximumPacketCount;\n                assert(maximumPacketCount !== undefined);\n                if (trackData.samples.length > maximumPacketCount) {\n                    throw new Error(`Track #${trackData.track.id} has already reached the maximum packet count`\n                        + ` (${maximumPacketCount}). Either add less packets or increase the maximum packet count.`);\n                }\n            }\n        }\n        let beginNewChunk = false;\n        if (!trackData.currentChunk) {\n            beginNewChunk = true;\n        }\n        else {\n            // Timestamp don't need to be monotonic (think B-frames), so we may need to update the start timestamp of\n            // the chunk\n            trackData.currentChunk.startTimestamp = Math.min(trackData.currentChunk.startTimestamp, sample.timestamp);\n            const currentChunkDuration = sample.timestamp - trackData.currentChunk.startTimestamp;\n            if (this.isFragmented) {\n                // We can only finalize this fragment (and begin a new one) if we know that each track will be able to\n                // start the new one with a key frame.\n                const keyFrameQueuedEverywhere = this.trackDatas.every((otherTrackData) => {\n                    if (trackData === otherTrackData) {\n                        return sample.type === 'key';\n                    }\n                    const firstQueuedSample = otherTrackData.sampleQueue[0];\n                    if (firstQueuedSample) {\n                        return firstQueuedSample.type === 'key';\n                    }\n                    return otherTrackData.track.source._closed;\n                });\n                if (currentChunkDuration >= this.minimumFragmentDuration\n                    && keyFrameQueuedEverywhere\n                    && sample.timestamp > this.maxWrittenTimestamp) {\n                    beginNewChunk = true;\n                    await this.finalizeFragment();\n                }\n            }\n            else {\n                beginNewChunk = currentChunkDuration >= 0.5; // Chunk is long enough, we need a new one\n            }\n        }\n        if (beginNewChunk) {\n            if (trackData.currentChunk) {\n                await this.finalizeCurrentChunk(trackData);\n            }\n            trackData.currentChunk = {\n                startTimestamp: sample.timestamp,\n                samples: [],\n                offset: null,\n                moofOffset: null,\n            };\n        }\n        assert(trackData.currentChunk);\n        trackData.currentChunk.samples.push(sample);\n        if (this.isFragmented) {\n            this.maxWrittenTimestamp = Math.max(this.maxWrittenTimestamp, sample.timestamp);\n        }\n    }\n    async finalizeCurrentChunk(trackData) {\n        assert(!this.isFragmented);\n        if (!trackData.currentChunk)\n            return;\n        trackData.finalizedChunks.push(trackData.currentChunk);\n        this.finalizedChunks.push(trackData.currentChunk);\n        let sampleCount = trackData.currentChunk.samples.length;\n        if (trackData.type === 'audio' && trackData.info.requiresPcmTransformation) {\n            sampleCount = trackData.currentChunk.samples\n                .reduce((acc, sample) => acc + intoTimescale(sample.duration, trackData.timescale), 0);\n        }\n        if (trackData.compactlyCodedChunkTable.length === 0\n            || last(trackData.compactlyCodedChunkTable).samplesPerChunk !== sampleCount) {\n            trackData.compactlyCodedChunkTable.push({\n                firstChunk: trackData.finalizedChunks.length, // 1-indexed\n                samplesPerChunk: sampleCount,\n            });\n        }\n        if (this.fastStart === 'in-memory') {\n            trackData.currentChunk.offset = 0; // We'll compute the proper offset when finalizing\n            return;\n        }\n        // Write out the data\n        trackData.currentChunk.offset = this.writer.getPos();\n        for (const sample of trackData.currentChunk.samples) {\n            assert(sample.data);\n            this.writer.write(sample.data);\n            sample.data = null; // Can be GC'd\n        }\n        await this.writer.flush();\n    }\n    async interleaveSamples(isFinalCall = false) {\n        assert(this.isFragmented);\n        if (!isFinalCall && !this.allTracksAreKnown()) {\n            return; // We can't interleave yet as we don't yet know how many tracks we'll truly have\n        }\n        outer: while (true) {\n            let trackWithMinTimestamp = null;\n            let minTimestamp = Infinity;\n            for (const trackData of this.trackDatas) {\n                if (!isFinalCall && trackData.sampleQueue.length === 0 && !trackData.track.source._closed) {\n                    break outer;\n                }\n                if (trackData.sampleQueue.length > 0 && trackData.sampleQueue[0].timestamp < minTimestamp) {\n                    trackWithMinTimestamp = trackData;\n                    minTimestamp = trackData.sampleQueue[0].timestamp;\n                }\n            }\n            if (!trackWithMinTimestamp) {\n                break;\n            }\n            const sample = trackWithMinTimestamp.sampleQueue.shift();\n            await this.addSampleToTrack(trackWithMinTimestamp, sample);\n        }\n    }\n    async finalizeFragment(flushWriter = true) {\n        assert(this.isFragmented);\n        const fragmentNumber = this.nextFragmentNumber++;\n        if (fragmentNumber === 1) {\n            if (this.format._options.onMoov) {\n                this.writer.startTrackingWrites();\n            }\n            // Write the moov box now that we have all decoder configs\n            const movieBox = moov(this);\n            this.boxWriter.writeBox(movieBox);\n            if (this.format._options.onMoov) {\n                const { data, start } = this.writer.stopTrackingWrites();\n                this.format._options.onMoov(data, start);\n            }\n        }\n        // Not all tracks need to be present in every fragment\n        const tracksInFragment = this.trackDatas.filter(x => x.currentChunk);\n        // Create an initial moof box and measure it; we need this to know where the following mdat box will begin\n        const moofBox = moof(fragmentNumber, tracksInFragment);\n        const moofOffset = this.writer.getPos();\n        const mdatStartPos = moofOffset + this.boxWriter.measureBox(moofBox);\n        let currentPos = mdatStartPos + MIN_BOX_HEADER_SIZE;\n        let fragmentStartTimestamp = Infinity;\n        for (const trackData of tracksInFragment) {\n            trackData.currentChunk.offset = currentPos;\n            trackData.currentChunk.moofOffset = moofOffset;\n            for (const sample of trackData.currentChunk.samples) {\n                currentPos += sample.size;\n            }\n            fragmentStartTimestamp = Math.min(fragmentStartTimestamp, trackData.currentChunk.startTimestamp);\n        }\n        const mdatSize = currentPos - mdatStartPos;\n        const needsLargeMdatSize = mdatSize >= 2 ** 32;\n        if (needsLargeMdatSize) {\n            // Shift all offsets by 8. Previously, all chunks were shifted assuming the large box size, but due to what\n            // I suspect is a bug in WebKit, it failed in Safari (when livestreaming with MSE, not for static playback).\n            for (const trackData of tracksInFragment) {\n                trackData.currentChunk.offset += MAX_BOX_HEADER_SIZE - MIN_BOX_HEADER_SIZE;\n            }\n        }\n        if (this.format._options.onMoof) {\n            this.writer.startTrackingWrites();\n        }\n        const newMoofBox = moof(fragmentNumber, tracksInFragment);\n        this.boxWriter.writeBox(newMoofBox);\n        if (this.format._options.onMoof) {\n            const { data, start } = this.writer.stopTrackingWrites();\n            this.format._options.onMoof(data, start, fragmentStartTimestamp);\n        }\n        assert(this.writer.getPos() === mdatStartPos);\n        if (this.format._options.onMdat) {\n            this.writer.startTrackingWrites();\n        }\n        const mdatBox = mdat(needsLargeMdatSize);\n        mdatBox.size = mdatSize;\n        this.boxWriter.writeBox(mdatBox);\n        this.writer.seek(mdatStartPos + (needsLargeMdatSize ? MAX_BOX_HEADER_SIZE : MIN_BOX_HEADER_SIZE));\n        // Write sample data\n        for (const trackData of tracksInFragment) {\n            for (const sample of trackData.currentChunk.samples) {\n                this.writer.write(sample.data);\n                sample.data = null; // Can be GC'd\n            }\n        }\n        if (this.format._options.onMdat) {\n            const { data, start } = this.writer.stopTrackingWrites();\n            this.format._options.onMdat(data, start);\n        }\n        for (const trackData of tracksInFragment) {\n            trackData.finalizedChunks.push(trackData.currentChunk);\n            this.finalizedChunks.push(trackData.currentChunk);\n            trackData.currentChunk = null;\n        }\n        if (flushWriter) {\n            await this.writer.flush();\n        }\n    }\n    async registerSampleFastStartReserve(trackData, sample) {\n        if (this.allTracksAreKnown()) {\n            if (!this.mdat) {\n                // We finally know all tracks, let's reserve space for the moov box\n                const moovBox = moov(this);\n                const moovSize = this.boxWriter.measureBox(moovBox);\n                const reservedSize = moovSize\n                    + this.computeSampleTableSizeUpperBound()\n                    + 4096; // Just a little extra headroom\n                assert(this.ftypSize !== null);\n                this.writer.seek(this.ftypSize + reservedSize);\n                if (this.format._options.onMdat) {\n                    this.writer.startTrackingWrites();\n                }\n                this.mdat = mdat(true);\n                this.boxWriter.writeBox(this.mdat);\n                // Now write everything that was queued\n                for (const trackData of this.trackDatas) {\n                    for (const sample of trackData.sampleQueue) {\n                        await this.addSampleToTrack(trackData, sample);\n                    }\n                    trackData.sampleQueue.length = 0;\n                }\n            }\n            await this.addSampleToTrack(trackData, sample);\n        }\n        else {\n            // Queue it for when we know all tracks\n            trackData.sampleQueue.push(sample);\n        }\n    }\n    computeSampleTableSizeUpperBound() {\n        assert(this.fastStart === 'reserve');\n        let upperBound = 0;\n        for (const trackData of this.trackDatas) {\n            const n = trackData.track.metadata.maximumPacketCount;\n            assert(n !== undefined); // We validated this earlier\n            // Given the max allowed packet count, compute the space they'll take up in the Sample Table Box, assuming\n            // the worst case for each individual box:\n            // stts box - since it is compactly coded, the maximum length of this table will be 2/3n\n            upperBound += (4 + 4) * Math.ceil(2 / 3 * n);\n            // stss box - 1 entry per sample\n            upperBound += 4 * n;\n            // ctts box - since it is compactly coded, the maximum length of this table will be 2/3n\n            upperBound += (4 + 4) * Math.ceil(2 / 3 * n);\n            // stsc box - since it is compactly coded, the maximum length of this table will be 2/3n\n            upperBound += (4 + 4 + 4) * Math.ceil(2 / 3 * n);\n            // stsz box - 1 entry per sample\n            upperBound += 4 * n;\n            // co64 box - we assume 1 sample per chunk and 64-bit chunk offsets (co64 instead of stco)\n            upperBound += 8 * n;\n        }\n        return upperBound;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-misused-promises\n    async onTrackClose(track) {\n        const release = await this.mutex.acquire();\n        if (track.type === 'subtitle' && track.source._codec === 'webvtt') {\n            const trackData = this.trackDatas.find(x => x.track === track);\n            if (trackData) {\n                await this.processWebVTTCues(trackData, Infinity);\n            }\n        }\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        if (this.isFragmented) {\n            // Since a track is now closed, we may be able to write out chunks that were previously waiting\n            await this.interleaveSamples();\n        }\n        release();\n    }\n    /** Finalizes the file, making it ready for use. Must be called after all video and audio chunks have been added. */\n    async finalize() {\n        const release = await this.mutex.acquire();\n        this.allTracksKnown.resolve();\n        for (const trackData of this.trackDatas) {\n            if (trackData.type === 'subtitle' && trackData.track.source._codec === 'webvtt') {\n                await this.processWebVTTCues(trackData, Infinity);\n            }\n        }\n        if (this.isFragmented) {\n            await this.interleaveSamples(true);\n            for (const trackData of this.trackDatas) {\n                this.processTimestamps(trackData);\n            }\n            await this.finalizeFragment(false); // Don't flush the last fragment as we will flush it with the mfra box\n        }\n        else {\n            for (const trackData of this.trackDatas) {\n                this.processTimestamps(trackData);\n                await this.finalizeCurrentChunk(trackData);\n            }\n        }\n        if (this.fastStart === 'in-memory') {\n            this.mdat = mdat(false);\n            let mdatSize;\n            // We know how many chunks there are, but computing the chunk positions requires an iterative approach:\n            // In order to know where the first chunk should go, we first need to know the size of the moov box. But we\n            // cannot write a proper moov box without first knowing all chunk positions. So, we generate a tentative\n            // moov box with placeholder values (0) for the chunk offsets to be able to compute its size. If it then\n            // turns out that appending all chunks exceeds 4 GiB, we need to repeat this process, now with the co64 box\n            // being used in the moov box instead, which will make it larger. After that, we definitely know the final\n            // size of the moov box and can compute the proper chunk positions.\n            for (let i = 0; i < 2; i++) {\n                const movieBox = moov(this);\n                const movieBoxSize = this.boxWriter.measureBox(movieBox);\n                mdatSize = this.boxWriter.measureBox(this.mdat);\n                let currentChunkPos = this.writer.getPos() + movieBoxSize + mdatSize;\n                for (const chunk of this.finalizedChunks) {\n                    chunk.offset = currentChunkPos;\n                    for (const { data } of chunk.samples) {\n                        assert(data);\n                        currentChunkPos += data.byteLength;\n                        mdatSize += data.byteLength;\n                    }\n                }\n                if (currentChunkPos < 2 ** 32)\n                    break;\n                if (mdatSize >= 2 ** 32)\n                    this.mdat.largeSize = true;\n            }\n            if (this.format._options.onMoov) {\n                this.writer.startTrackingWrites();\n            }\n            const movieBox = moov(this);\n            this.boxWriter.writeBox(movieBox);\n            if (this.format._options.onMoov) {\n                const { data, start } = this.writer.stopTrackingWrites();\n                this.format._options.onMoov(data, start);\n            }\n            if (this.format._options.onMdat) {\n                this.writer.startTrackingWrites();\n            }\n            this.mdat.size = mdatSize;\n            this.boxWriter.writeBox(this.mdat);\n            for (const chunk of this.finalizedChunks) {\n                for (const sample of chunk.samples) {\n                    assert(sample.data);\n                    this.writer.write(sample.data);\n                    sample.data = null;\n                }\n            }\n            if (this.format._options.onMdat) {\n                const { data, start } = this.writer.stopTrackingWrites();\n                this.format._options.onMdat(data, start);\n            }\n        }\n        else if (this.isFragmented) {\n            // Append the mfra box to the end of the file for better random access\n            const startPos = this.writer.getPos();\n            const mfraBox = mfra(this.trackDatas);\n            this.boxWriter.writeBox(mfraBox);\n            // Patch the 'size' field of the mfro box at the end of the mfra box now that we know its actual size\n            const mfraBoxSize = this.writer.getPos() - startPos;\n            this.writer.seek(this.writer.getPos() - 4);\n            this.boxWriter.writeU32(mfraBoxSize);\n        }\n        else {\n            assert(this.mdat);\n            const mdatPos = this.boxWriter.offsets.get(this.mdat);\n            assert(mdatPos !== undefined);\n            const mdatSize = this.writer.getPos() - mdatPos;\n            this.mdat.size = mdatSize;\n            this.mdat.largeSize = mdatSize >= 2 ** 32; // Only use the large size if we need it\n            this.boxWriter.patchBox(this.mdat);\n            if (this.format._options.onMdat) {\n                const { data, start } = this.writer.stopTrackingWrites();\n                this.format._options.onMdat(data, start);\n            }\n            const movieBox = moov(this);\n            if (this.fastStart === 'reserve') {\n                assert(this.ftypSize !== null);\n                this.writer.seek(this.ftypSize);\n                if (this.format._options.onMoov) {\n                    this.writer.startTrackingWrites();\n                }\n                this.boxWriter.writeBox(movieBox);\n                // Fill the remaining space with a free box. If there are less than 8 bytes left, sucks I guess\n                const remainingSpace = this.boxWriter.offsets.get(this.mdat) - this.writer.getPos();\n                this.boxWriter.writeBox(free(remainingSpace));\n            }\n            else {\n                if (this.format._options.onMoov) {\n                    this.writer.startTrackingWrites();\n                }\n                this.boxWriter.writeBox(movieBox);\n            }\n            if (this.format._options.onMoov) {\n                const { data, start } = this.writer.stopTrackingWrites();\n                this.format._options.onMoov(data, start);\n            }\n        }\n        release();\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { Bitstream, COLOR_PRIMARIES_MAP, MATRIX_COEFFICIENTS_MAP, TRANSFER_CHARACTERISTICS_MAP, UNDETERMINED_LANGUAGE, assert, assertNever, colorSpaceIsComplete, imageMimeTypeToExtension, keyValueIterator, normalizeRotation, promiseWithResolvers, roundToMultiple, textEncoder, toUint8Array, uint8ArraysAreEqual, writeBits, } from '../misc.js';\nimport { CODEC_STRING_MAP, EBMLFloat32, EBMLFloat64, EBMLId, EBMLSignedInt, EBMLUnicodeString, EBMLWriter, } from './ebml.js';\nimport { buildMatroskaMimeType } from './matroska-misc.js';\nimport { WebMOutputFormat } from '../output-format.js';\nimport { formatSubtitleTimestamp, inlineTimestampRegex, parseSubtitleTimestamp, } from '../subtitles.js';\nimport { aacChannelMap, aacFrequencyTable, buildAacAudioSpecificConfig, OPUS_SAMPLE_RATE, PCM_AUDIO_CODECS, generateAv1CodecConfigurationFromCodecString, generateVp9CodecConfigurationFromCodecString, parsePcmCodec, validateAudioChunkMetadata, validateSubtitleMetadata, validateVideoChunkMetadata, } from '../codec.js';\nimport { MAX_ADTS_FRAME_HEADER_SIZE, MIN_ADTS_FRAME_HEADER_SIZE, readAdtsFrameHeader } from '../adts/adts-reader.js';\nimport { FileSlice } from '../reader.js';\nimport { Muxer } from '../muxer.js';\nimport { parseOpusIdentificationHeader } from '../codec-data.js';\nimport { AttachedFile } from '../metadata.js';\nconst MIN_CLUSTER_TIMESTAMP_MS = -(2 ** 15);\nconst MAX_CLUSTER_TIMESTAMP_MS = 2 ** 15 - 1;\nconst APP_NAME = 'Mediabunny';\nconst SEGMENT_SIZE_BYTES = 6;\nconst CLUSTER_SIZE_BYTES = 5;\nconst TRACK_TYPE_MAP = {\n    video: 1,\n    audio: 2,\n    subtitle: 17,\n};\nexport class MatroskaMuxer extends Muxer {\n    constructor(output, format) {\n        super(output);\n        this.trackDatas = [];\n        this.allTracksKnown = promiseWithResolvers();\n        this.segment = null;\n        this.segmentInfo = null;\n        this.seekHead = null;\n        this.tracksElement = null;\n        this.tagsElement = null;\n        this.attachmentsElement = null;\n        this.segmentDuration = null;\n        this.cues = null;\n        this.currentCluster = null;\n        this.currentClusterStartMsTimestamp = null;\n        this.currentClusterMaxMsTimestamp = null;\n        this.trackDatasInCurrentCluster = new Map();\n        this.duration = 0;\n        this.writer = output._writer;\n        this.format = format;\n        this.ebmlWriter = new EBMLWriter(this.writer);\n        if (this.format._options.appendOnly) {\n            this.writer.ensureMonotonicity = true;\n        }\n    }\n    async start() {\n        const release = await this.mutex.acquire();\n        this.writeEBMLHeader();\n        this.createSegmentInfo();\n        this.createCues();\n        await this.writer.flush();\n        release();\n    }\n    writeEBMLHeader() {\n        if (this.format._options.onEbmlHeader) {\n            this.writer.startTrackingWrites();\n        }\n        const ebmlHeader = { id: EBMLId.EBML, data: [\n                { id: EBMLId.EBMLVersion, data: 1 },\n                { id: EBMLId.EBMLReadVersion, data: 1 },\n                { id: EBMLId.EBMLMaxIDLength, data: 4 },\n                { id: EBMLId.EBMLMaxSizeLength, data: 8 },\n                { id: EBMLId.DocType, data: this.format instanceof WebMOutputFormat ? 'webm' : 'matroska' },\n                { id: EBMLId.DocTypeVersion, data: 2 },\n                { id: EBMLId.DocTypeReadVersion, data: 2 },\n            ] };\n        this.ebmlWriter.writeEBML(ebmlHeader);\n        if (this.format._options.onEbmlHeader) {\n            const { data, start } = this.writer.stopTrackingWrites(); // start should be 0\n            this.format._options.onEbmlHeader(data, start);\n        }\n    }\n    /**\n     * Creates a SeekHead element which is positioned near the start of the file and allows the media player to seek to\n     * relevant sections more easily. Since we don't know the positions of those sections yet, we'll set them later.\n     */\n    maybeCreateSeekHead(writeOffsets) {\n        if (this.format._options.appendOnly) {\n            return;\n        }\n        const kaxCues = new Uint8Array([0x1c, 0x53, 0xbb, 0x6b]);\n        const kaxInfo = new Uint8Array([0x15, 0x49, 0xa9, 0x66]);\n        const kaxTracks = new Uint8Array([0x16, 0x54, 0xae, 0x6b]);\n        const kaxAttachments = new Uint8Array([0x19, 0x41, 0xa4, 0x69]);\n        const kaxTags = new Uint8Array([0x12, 0x54, 0xc3, 0x67]);\n        const seekHead = { id: EBMLId.SeekHead, data: [\n                { id: EBMLId.Seek, data: [\n                        { id: EBMLId.SeekID, data: kaxCues },\n                        {\n                            id: EBMLId.SeekPosition,\n                            size: 5,\n                            data: writeOffsets\n                                ? this.ebmlWriter.offsets.get(this.cues) - this.segmentDataOffset\n                                : 0,\n                        },\n                    ] },\n                { id: EBMLId.Seek, data: [\n                        { id: EBMLId.SeekID, data: kaxInfo },\n                        {\n                            id: EBMLId.SeekPosition,\n                            size: 5,\n                            data: writeOffsets\n                                ? this.ebmlWriter.offsets.get(this.segmentInfo) - this.segmentDataOffset\n                                : 0,\n                        },\n                    ] },\n                { id: EBMLId.Seek, data: [\n                        { id: EBMLId.SeekID, data: kaxTracks },\n                        {\n                            id: EBMLId.SeekPosition,\n                            size: 5,\n                            data: writeOffsets\n                                ? this.ebmlWriter.offsets.get(this.tracksElement) - this.segmentDataOffset\n                                : 0,\n                        },\n                    ] },\n                this.attachmentsElement\n                    ? { id: EBMLId.Seek, data: [\n                            { id: EBMLId.SeekID, data: kaxAttachments },\n                            {\n                                id: EBMLId.SeekPosition,\n                                size: 5,\n                                data: writeOffsets\n                                    ? this.ebmlWriter.offsets.get(this.attachmentsElement) - this.segmentDataOffset\n                                    : 0,\n                            },\n                        ] }\n                    : null,\n                this.tagsElement\n                    ? { id: EBMLId.Seek, data: [\n                            { id: EBMLId.SeekID, data: kaxTags },\n                            {\n                                id: EBMLId.SeekPosition,\n                                size: 5,\n                                data: writeOffsets\n                                    ? this.ebmlWriter.offsets.get(this.tagsElement) - this.segmentDataOffset\n                                    : 0,\n                            },\n                        ] }\n                    : null,\n            ] };\n        this.seekHead = seekHead;\n    }\n    createSegmentInfo() {\n        const segmentDuration = { id: EBMLId.Duration, data: new EBMLFloat64(0) };\n        this.segmentDuration = segmentDuration;\n        const segmentInfo = { id: EBMLId.Info, data: [\n                { id: EBMLId.TimestampScale, data: 1e6 },\n                { id: EBMLId.MuxingApp, data: APP_NAME },\n                { id: EBMLId.WritingApp, data: APP_NAME },\n                !this.format._options.appendOnly ? segmentDuration : null,\n            ] };\n        this.segmentInfo = segmentInfo;\n    }\n    createTracks() {\n        const tracksElement = { id: EBMLId.Tracks, data: [] };\n        this.tracksElement = tracksElement;\n        for (const trackData of this.trackDatas) {\n            const codecId = CODEC_STRING_MAP[trackData.track.source._codec];\n            assert(codecId);\n            let seekPreRollNs = 0;\n            if (trackData.type === 'audio' && trackData.track.source._codec === 'opus') {\n                seekPreRollNs = 1e6 * 80; // In \"Matroska ticks\" (nanoseconds)\n                const description = trackData.info.decoderConfig.description;\n                if (description) {\n                    const bytes = toUint8Array(description);\n                    const header = parseOpusIdentificationHeader(bytes);\n                    // Use the preSkip value from the header\n                    seekPreRollNs = Math.round(1e9 * (header.preSkip / OPUS_SAMPLE_RATE));\n                }\n            }\n            tracksElement.data.push({ id: EBMLId.TrackEntry, data: [\n                    { id: EBMLId.TrackNumber, data: trackData.track.id },\n                    { id: EBMLId.TrackUID, data: trackData.track.id },\n                    { id: EBMLId.TrackType, data: TRACK_TYPE_MAP[trackData.type] },\n                    trackData.track.metadata.disposition?.default === false\n                        ? { id: EBMLId.FlagDefault, data: 0 }\n                        : null,\n                    trackData.track.metadata.disposition?.forced\n                        ? { id: EBMLId.FlagForced, data: 1 }\n                        : null,\n                    trackData.track.metadata.disposition?.hearingImpaired\n                        ? { id: EBMLId.FlagHearingImpaired, data: 1 }\n                        : null,\n                    trackData.track.metadata.disposition?.visuallyImpaired\n                        ? { id: EBMLId.FlagVisualImpaired, data: 1 }\n                        : null,\n                    trackData.track.metadata.disposition?.original\n                        ? { id: EBMLId.FlagOriginal, data: 1 }\n                        : null,\n                    trackData.track.metadata.disposition?.commentary\n                        ? { id: EBMLId.FlagCommentary, data: 1 }\n                        : null,\n                    { id: EBMLId.FlagLacing, data: 0 },\n                    { id: EBMLId.Language, data: trackData.track.metadata.languageCode ?? UNDETERMINED_LANGUAGE },\n                    { id: EBMLId.CodecID, data: codecId },\n                    { id: EBMLId.CodecDelay, data: 0 },\n                    { id: EBMLId.SeekPreRoll, data: seekPreRollNs },\n                    trackData.track.metadata.name !== undefined\n                        ? { id: EBMLId.Name, data: new EBMLUnicodeString(trackData.track.metadata.name) }\n                        : null,\n                    (trackData.type === 'video' ? this.videoSpecificTrackInfo(trackData) : null),\n                    (trackData.type === 'audio' ? this.audioSpecificTrackInfo(trackData) : null),\n                    (trackData.type === 'subtitle' ? this.subtitleSpecificTrackInfo(trackData) : null),\n                ] });\n        }\n    }\n    videoSpecificTrackInfo(trackData) {\n        const { frameRate, rotation } = trackData.track.metadata;\n        const elements = [\n            (trackData.info.decoderConfig.description\n                ? {\n                    id: EBMLId.CodecPrivate,\n                    data: toUint8Array(trackData.info.decoderConfig.description),\n                }\n                : null),\n            (frameRate\n                ? {\n                    id: EBMLId.DefaultDuration,\n                    data: 1e9 / frameRate,\n                }\n                : null),\n        ];\n        // Convert from clockwise to counter-clockwise\n        const flippedRotation = rotation ? normalizeRotation(-rotation) : 0;\n        const colorSpace = trackData.info.decoderConfig.colorSpace;\n        const videoElement = { id: EBMLId.Video, data: [\n                { id: EBMLId.PixelWidth, data: trackData.info.width },\n                { id: EBMLId.PixelHeight, data: trackData.info.height },\n                trackData.info.alphaMode ? { id: EBMLId.AlphaMode, data: 1 } : null,\n                (colorSpaceIsComplete(colorSpace)\n                    ? {\n                        id: EBMLId.Colour,\n                        data: [\n                            {\n                                id: EBMLId.MatrixCoefficients,\n                                data: MATRIX_COEFFICIENTS_MAP[colorSpace.matrix],\n                            },\n                            {\n                                id: EBMLId.TransferCharacteristics,\n                                data: TRANSFER_CHARACTERISTICS_MAP[colorSpace.transfer],\n                            },\n                            {\n                                id: EBMLId.Primaries,\n                                data: COLOR_PRIMARIES_MAP[colorSpace.primaries],\n                            },\n                            {\n                                id: EBMLId.Range,\n                                data: colorSpace.fullRange ? 2 : 1,\n                            },\n                        ],\n                    }\n                    : null),\n                (flippedRotation\n                    ? {\n                        id: EBMLId.Projection,\n                        data: [\n                            {\n                                id: EBMLId.ProjectionType,\n                                data: 0, // rectangular\n                            },\n                            {\n                                id: EBMLId.ProjectionPoseRoll,\n                                data: new EBMLFloat32((flippedRotation + 180) % 360 - 180), // [0, 270] -> [-180, 90]\n                            },\n                        ],\n                    }\n                    : null),\n            ] };\n        elements.push(videoElement);\n        return elements;\n    }\n    audioSpecificTrackInfo(trackData) {\n        const pcmInfo = PCM_AUDIO_CODECS.includes(trackData.track.source._codec)\n            ? parsePcmCodec(trackData.track.source._codec)\n            : null;\n        return [\n            (trackData.info.decoderConfig.description\n                ? {\n                    id: EBMLId.CodecPrivate,\n                    data: toUint8Array(trackData.info.decoderConfig.description),\n                }\n                : null),\n            { id: EBMLId.Audio, data: [\n                    { id: EBMLId.SamplingFrequency, data: new EBMLFloat32(trackData.info.sampleRate) },\n                    { id: EBMLId.Channels, data: trackData.info.numberOfChannels },\n                    pcmInfo ? { id: EBMLId.BitDepth, data: 8 * pcmInfo.sampleSize } : null,\n                ] },\n        ];\n    }\n    subtitleSpecificTrackInfo(trackData) {\n        return [\n            { id: EBMLId.CodecPrivate, data: textEncoder.encode(trackData.info.config.description) },\n        ];\n    }\n    maybeCreateTags() {\n        const simpleTags = [];\n        const addSimpleTag = (key, value) => {\n            simpleTags.push({ id: EBMLId.SimpleTag, data: [\n                    { id: EBMLId.TagName, data: new EBMLUnicodeString(key) },\n                    typeof value === 'string'\n                        ? { id: EBMLId.TagString, data: new EBMLUnicodeString(value) }\n                        : { id: EBMLId.TagBinary, data: value },\n                ] });\n        };\n        const metadataTags = this.output._metadataTags;\n        const writtenTags = new Set();\n        for (const { key, value } of keyValueIterator(metadataTags)) {\n            switch (key) {\n                case 'title':\n                    {\n                        addSimpleTag('TITLE', value);\n                        writtenTags.add('TITLE');\n                    }\n                    ;\n                    break;\n                case 'description':\n                    {\n                        addSimpleTag('DESCRIPTION', value);\n                        writtenTags.add('DESCRIPTION');\n                    }\n                    ;\n                    break;\n                case 'artist':\n                    {\n                        addSimpleTag('ARTIST', value);\n                        writtenTags.add('ARTIST');\n                    }\n                    ;\n                    break;\n                case 'album':\n                    {\n                        addSimpleTag('ALBUM', value);\n                        writtenTags.add('ALBUM');\n                    }\n                    ;\n                    break;\n                case 'albumArtist':\n                    {\n                        addSimpleTag('ALBUM_ARTIST', value);\n                        writtenTags.add('ALBUM_ARTIST');\n                    }\n                    ;\n                    break;\n                case 'genre':\n                    {\n                        addSimpleTag('GENRE', value);\n                        writtenTags.add('GENRE');\n                    }\n                    ;\n                    break;\n                case 'comment':\n                    {\n                        addSimpleTag('COMMENT', value);\n                        writtenTags.add('COMMENT');\n                    }\n                    ;\n                    break;\n                case 'lyrics':\n                    {\n                        addSimpleTag('LYRICS', value);\n                        writtenTags.add('LYRICS');\n                    }\n                    ;\n                    break;\n                case 'date':\n                    {\n                        addSimpleTag('DATE', value.toISOString().slice(0, 10));\n                        writtenTags.add('DATE');\n                    }\n                    ;\n                    break;\n                case 'trackNumber':\n                    {\n                        const string = metadataTags.tracksTotal !== undefined\n                            ? `${value}/${metadataTags.tracksTotal}`\n                            : value.toString();\n                        addSimpleTag('PART_NUMBER', string);\n                        writtenTags.add('PART_NUMBER');\n                    }\n                    ;\n                    break;\n                case 'discNumber':\n                    {\n                        const string = metadataTags.discsTotal !== undefined\n                            ? `${value}/${metadataTags.discsTotal}`\n                            : value.toString();\n                        addSimpleTag('DISC', string);\n                        writtenTags.add('DISC');\n                    }\n                    ;\n                    break;\n                case 'tracksTotal':\n                case 'discsTotal':\n                    {\n                        // Handled with trackNumber and discNumber respectively\n                    }\n                    ;\n                    break;\n                case 'images':\n                case 'raw':\n                    {\n                        // Handled elsewhere\n                    }\n                    ;\n                    break;\n                default: assertNever(key);\n            }\n        }\n        if (metadataTags.raw) {\n            for (const key in metadataTags.raw) {\n                const value = metadataTags.raw[key];\n                if (value == null || writtenTags.has(key)) {\n                    continue;\n                }\n                if (typeof value === 'string' || value instanceof Uint8Array) {\n                    addSimpleTag(key, value);\n                }\n            }\n        }\n        if (simpleTags.length === 0) {\n            return;\n        }\n        this.tagsElement = {\n            id: EBMLId.Tags,\n            data: [{ id: EBMLId.Tag, data: [\n                        { id: EBMLId.Targets, data: [\n                                { id: EBMLId.TargetTypeValue, data: 50 },\n                                { id: EBMLId.TargetType, data: 'MOVIE' },\n                            ] },\n                        ...simpleTags,\n                    ] }],\n        };\n    }\n    maybeCreateAttachments() {\n        const metadataTags = this.output._metadataTags;\n        const elements = [];\n        const existingFileUids = new Set();\n        const images = metadataTags.images ?? [];\n        for (const image of images) {\n            let imageName = image.name;\n            if (imageName === undefined) {\n                const baseName = image.kind === 'coverFront' ? 'cover' : image.kind === 'coverBack' ? 'back' : 'image';\n                imageName = baseName + (imageMimeTypeToExtension(image.mimeType) ?? '');\n            }\n            let fileUid;\n            while (true) {\n                // Generate a random 64-bit unsigned integer\n                fileUid = 0n;\n                for (let i = 0; i < 8; i++) {\n                    fileUid <<= 8n;\n                    fileUid |= BigInt(Math.floor(Math.random() * 256));\n                }\n                if (fileUid !== 0n && !existingFileUids.has(fileUid)) {\n                    break;\n                }\n            }\n            existingFileUids.add(fileUid);\n            elements.push({\n                id: EBMLId.AttachedFile,\n                data: [\n                    image.description !== undefined\n                        ? { id: EBMLId.FileDescription, data: new EBMLUnicodeString(image.description) }\n                        : null,\n                    { id: EBMLId.FileName, data: new EBMLUnicodeString(imageName) },\n                    { id: EBMLId.FileMediaType, data: image.mimeType },\n                    { id: EBMLId.FileData, data: image.data },\n                    { id: EBMLId.FileUID, data: fileUid },\n                ],\n            });\n        }\n        // Add all AttachedFiles from the raw metadata\n        for (const [key, value] of Object.entries(metadataTags.raw ?? {})) {\n            if (!(value instanceof AttachedFile)) {\n                continue;\n            }\n            const keyIsNumeric = /^\\d+$/.test(key);\n            if (!keyIsNumeric) {\n                continue;\n            }\n            if (images.find(x => x.mimeType === value.mimeType && uint8ArraysAreEqual(x.data, value.data))) {\n                // This attached file has very likely already been added as an image above\n                // (happens when remuxing Matroska)\n                continue;\n            }\n            elements.push({\n                id: EBMLId.AttachedFile,\n                data: [\n                    value.description !== undefined\n                        ? { id: EBMLId.FileDescription, data: new EBMLUnicodeString(value.description) }\n                        : null,\n                    { id: EBMLId.FileName, data: new EBMLUnicodeString(value.name ?? '') },\n                    { id: EBMLId.FileMediaType, data: value.mimeType ?? '' },\n                    { id: EBMLId.FileData, data: value.data },\n                    { id: EBMLId.FileUID, data: BigInt(key) },\n                ],\n            });\n        }\n        if (elements.length === 0) {\n            return;\n        }\n        this.attachmentsElement = { id: EBMLId.Attachments, data: elements };\n    }\n    createSegment() {\n        this.createTracks();\n        this.maybeCreateTags();\n        this.maybeCreateAttachments();\n        this.maybeCreateSeekHead(false);\n        const segment = {\n            id: EBMLId.Segment,\n            size: this.format._options.appendOnly ? -1 : SEGMENT_SIZE_BYTES,\n            data: [\n                this.seekHead, // null if append-only\n                this.segmentInfo,\n                this.tracksElement,\n                // Matroska spec says put this at the end of the file, but I think placing it before the first cluster\n                // makes more sense, and FFmpeg agrees (argumentum ad ffmpegum fallacy)\n                this.attachmentsElement,\n                this.tagsElement,\n            ],\n        };\n        this.segment = segment;\n        if (this.format._options.onSegmentHeader) {\n            this.writer.startTrackingWrites();\n        }\n        this.ebmlWriter.writeEBML(segment);\n        if (this.format._options.onSegmentHeader) {\n            const { data, start } = this.writer.stopTrackingWrites();\n            this.format._options.onSegmentHeader(data, start);\n        }\n    }\n    createCues() {\n        this.cues = { id: EBMLId.Cues, data: [] };\n    }\n    get segmentDataOffset() {\n        assert(this.segment);\n        return this.ebmlWriter.dataOffsets.get(this.segment);\n    }\n    allTracksAreKnown() {\n        for (const track of this.output._tracks) {\n            if (!track.source._closed && !this.trackDatas.some(x => x.track === track)) {\n                return false; // We haven't seen a sample from this open track yet\n            }\n        }\n        return true;\n    }\n    async getMimeType() {\n        await this.allTracksKnown.promise;\n        const codecStrings = this.trackDatas.map((trackData) => {\n            if (trackData.type === 'video') {\n                return trackData.info.decoderConfig.codec;\n            }\n            else if (trackData.type === 'audio') {\n                return trackData.info.decoderConfig.codec;\n            }\n            else {\n                const map = {\n                    webvtt: 'wvtt',\n                };\n                return map[trackData.track.source._codec];\n            }\n        });\n        return buildMatroskaMimeType({\n            isWebM: this.format instanceof WebMOutputFormat,\n            hasVideo: this.trackDatas.some(x => x.type === 'video'),\n            hasAudio: this.trackDatas.some(x => x.type === 'audio'),\n            codecStrings,\n        });\n    }\n    getVideoTrackData(track, packet, meta) {\n        const existingTrackData = this.trackDatas.find(x => x.track === track);\n        if (existingTrackData) {\n            return existingTrackData;\n        }\n        validateVideoChunkMetadata(meta);\n        assert(meta);\n        assert(meta.decoderConfig);\n        assert(meta.decoderConfig.codedWidth !== undefined);\n        assert(meta.decoderConfig.codedHeight !== undefined);\n        const newTrackData = {\n            track,\n            type: 'video',\n            info: {\n                width: meta.decoderConfig.codedWidth,\n                height: meta.decoderConfig.codedHeight,\n                decoderConfig: meta.decoderConfig,\n                alphaMode: !!packet.sideData.alpha, // The first packet determines if this track has alpha or not\n            },\n            chunkQueue: [],\n            lastWrittenMsTimestamp: null,\n        };\n        if (track.source._codec === 'vp9') {\n            // https://www.webmproject.org/docs/container specifies that VP9 \"SHOULD\" make use of the CodecPrivate\n            // field. Since WebCodecs makes no use of the description field for VP9, we need to derive it ourselves:\n            newTrackData.info.decoderConfig = {\n                ...newTrackData.info.decoderConfig,\n                description: new Uint8Array(generateVp9CodecConfigurationFromCodecString(newTrackData.info.decoderConfig.codec)),\n            };\n        }\n        else if (track.source._codec === 'av1') {\n            // Per https://github.com/ietf-wg-cellar/matroska-specification/blob/master/codec/av1.md, AV1 requires\n            // CodecPrivate to be set, but WebCodecs makes no use of the description field for AV1. Thus, let's derive\n            // it ourselves:\n            newTrackData.info.decoderConfig = {\n                ...newTrackData.info.decoderConfig,\n                description: new Uint8Array(generateAv1CodecConfigurationFromCodecString(newTrackData.info.decoderConfig.codec)),\n            };\n        }\n        this.trackDatas.push(newTrackData);\n        this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        return newTrackData;\n    }\n    getAudioTrackData(track, packet, meta) {\n        const existingTrackData = this.trackDatas.find(x => x.track === track);\n        if (existingTrackData) {\n            return existingTrackData;\n        }\n        validateAudioChunkMetadata(meta);\n        assert(meta);\n        assert(meta.decoderConfig);\n        const decoderConfig = { ...meta.decoderConfig };\n        let requiresAdtsStripping = false;\n        if (track.source._codec === 'aac' && !decoderConfig.description) {\n            // Matroska stores raw AAC with AudioSpecificConfig in CodecPrivate, not ADTS-wrapped data.\n            // Parse the first packet to extract the AudioSpecificConfig.\n            const adtsFrame = readAdtsFrameHeader(FileSlice.tempFromBytes(packet.data));\n            if (!adtsFrame) {\n                throw new Error('Couldn\\'t parse ADTS header from the AAC packet. Make sure the packets are in ADTS format'\n                    + ' (as specified in ISO 13818-7) when not providing a description, or provide a description'\n                    + ' (must be an AudioSpecificConfig as specified in ISO 14496-3) and ensure the packets'\n                    + ' are raw AAC data.');\n            }\n            const sampleRate = aacFrequencyTable[adtsFrame.samplingFrequencyIndex];\n            const numberOfChannels = aacChannelMap[adtsFrame.channelConfiguration];\n            if (sampleRate === undefined || numberOfChannels === undefined) {\n                throw new Error('Invalid ADTS frame header.');\n            }\n            decoderConfig.description = buildAacAudioSpecificConfig({\n                objectType: adtsFrame.objectType,\n                sampleRate,\n                numberOfChannels,\n            });\n            requiresAdtsStripping = true;\n        }\n        const newTrackData = {\n            track,\n            type: 'audio',\n            info: {\n                numberOfChannels: meta.decoderConfig.numberOfChannels,\n                sampleRate: meta.decoderConfig.sampleRate,\n                decoderConfig,\n                requiresAdtsStripping,\n            },\n            chunkQueue: [],\n            lastWrittenMsTimestamp: null,\n        };\n        this.trackDatas.push(newTrackData);\n        this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        return newTrackData;\n    }\n    getSubtitleTrackData(track, meta) {\n        const existingTrackData = this.trackDatas.find(x => x.track === track);\n        if (existingTrackData) {\n            return existingTrackData;\n        }\n        validateSubtitleMetadata(meta);\n        assert(meta);\n        assert(meta.config);\n        const newTrackData = {\n            track,\n            type: 'subtitle',\n            info: {\n                config: meta.config,\n            },\n            chunkQueue: [],\n            lastWrittenMsTimestamp: null,\n        };\n        this.trackDatas.push(newTrackData);\n        this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        return newTrackData;\n    }\n    async addEncodedVideoPacket(track, packet, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            const trackData = this.getVideoTrackData(track, packet, meta);\n            const isKeyFrame = packet.type === 'key';\n            let timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, isKeyFrame);\n            let duration = packet.duration;\n            if (track.metadata.frameRate !== undefined) {\n                // Constrain the time values to the frame rate\n                timestamp = roundToMultiple(timestamp, 1 / track.metadata.frameRate);\n                duration = roundToMultiple(duration, 1 / track.metadata.frameRate);\n            }\n            const additions = trackData.info.alphaMode\n                ? packet.sideData.alpha ?? null\n                : null;\n            const videoChunk = this.createInternalChunk(packet.data, timestamp, duration, packet.type, additions);\n            if (track.source._codec === 'vp9')\n                this.fixVP9ColorSpace(trackData, videoChunk);\n            trackData.chunkQueue.push(videoChunk);\n            await this.interleaveChunks();\n        }\n        finally {\n            release();\n        }\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            const trackData = this.getAudioTrackData(track, packet, meta);\n            let packetData = packet.data;\n            if (trackData.info.requiresAdtsStripping) {\n                const adtsFrame = readAdtsFrameHeader(FileSlice.tempFromBytes(packetData));\n                if (!adtsFrame) {\n                    throw new Error('Expected ADTS frame, didn\\'t get one.');\n                }\n                const headerLength = adtsFrame.crcCheck === null\n                    ? MIN_ADTS_FRAME_HEADER_SIZE\n                    : MAX_ADTS_FRAME_HEADER_SIZE;\n                packetData = packetData.subarray(headerLength);\n            }\n            const isKeyFrame = packet.type === 'key';\n            const timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, isKeyFrame);\n            const audioChunk = this.createInternalChunk(packetData, timestamp, packet.duration, packet.type);\n            trackData.chunkQueue.push(audioChunk);\n            await this.interleaveChunks();\n        }\n        finally {\n            release();\n        }\n    }\n    async addSubtitleCue(track, cue, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            const trackData = this.getSubtitleTrackData(track, meta);\n            const timestamp = this.validateAndNormalizeTimestamp(trackData.track, cue.timestamp, true);\n            let bodyText = cue.text;\n            const timestampMs = Math.round(timestamp * 1000);\n            // Replace in-body timestamps so that they're relative to the cue start time\n            inlineTimestampRegex.lastIndex = 0;\n            bodyText = bodyText.replace(inlineTimestampRegex, (match) => {\n                const time = parseSubtitleTimestamp(match.slice(1, -1));\n                const offsetTime = time - timestampMs;\n                return `<${formatSubtitleTimestamp(offsetTime)}>`;\n            });\n            const body = textEncoder.encode(bodyText);\n            const additions = `${cue.settings ?? ''}\\n${cue.identifier ?? ''}\\n${cue.notes ?? ''}`;\n            const subtitleChunk = this.createInternalChunk(body, timestamp, cue.duration, 'key', additions.trim() ? textEncoder.encode(additions) : null);\n            trackData.chunkQueue.push(subtitleChunk);\n            await this.interleaveChunks();\n        }\n        finally {\n            release();\n        }\n    }\n    async interleaveChunks(isFinalCall = false) {\n        if (!isFinalCall && !this.allTracksAreKnown()) {\n            return; // We can't interleave yet as we don't yet know how many tracks we'll truly have\n        }\n        outer: while (true) {\n            let trackWithMinTimestamp = null;\n            let minTimestamp = Infinity;\n            for (const trackData of this.trackDatas) {\n                if (!isFinalCall && trackData.chunkQueue.length === 0 && !trackData.track.source._closed) {\n                    break outer;\n                }\n                if (trackData.chunkQueue.length > 0 && trackData.chunkQueue[0].timestamp < minTimestamp) {\n                    trackWithMinTimestamp = trackData;\n                    minTimestamp = trackData.chunkQueue[0].timestamp;\n                }\n            }\n            if (!trackWithMinTimestamp) {\n                break;\n            }\n            const chunk = trackWithMinTimestamp.chunkQueue.shift();\n            this.writeBlock(trackWithMinTimestamp, chunk);\n        }\n        if (!isFinalCall) {\n            await this.writer.flush();\n        }\n    }\n    /**\n     * Due to [a bug in Chromium](https://bugs.chromium.org/p/chromium/issues/detail?id=1377842), VP9 streams often\n     * lack color space information. This method patches in that information.\n     */\n    fixVP9ColorSpace(trackData, chunk) {\n        // http://downloads.webmproject.org/docs/vp9/vp9-bitstream_superframe-and-uncompressed-header_v1.0.pdf\n        if (chunk.type !== 'key')\n            return;\n        if (!trackData.info.decoderConfig.colorSpace || !trackData.info.decoderConfig.colorSpace.matrix)\n            return;\n        const bitstream = new Bitstream(chunk.data);\n        bitstream.skipBits(2);\n        const profileLowBit = bitstream.readBits(1);\n        const profileHighBit = bitstream.readBits(1);\n        const profile = (profileHighBit << 1) + profileLowBit;\n        if (profile === 3)\n            bitstream.skipBits(1);\n        const showExistingFrame = bitstream.readBits(1);\n        if (showExistingFrame)\n            return;\n        const frameType = bitstream.readBits(1);\n        if (frameType !== 0)\n            return; // Just to be sure\n        bitstream.skipBits(2);\n        const syncCode = bitstream.readBits(24);\n        if (syncCode !== 0x498342)\n            return;\n        if (profile >= 2)\n            bitstream.skipBits(1);\n        const colorSpaceID = {\n            rgb: 7,\n            bt709: 2,\n            bt470bg: 1,\n            smpte170m: 3,\n        }[trackData.info.decoderConfig.colorSpace.matrix];\n        // The bitstream position is now at the start of the color space bits.\n        // We can use the global writeBits function here as requested.\n        writeBits(chunk.data, bitstream.pos, bitstream.pos + 3, colorSpaceID);\n    }\n    /** Converts a read-only external chunk into an internal one for easier use. */\n    createInternalChunk(data, timestamp, duration, type, additions = null) {\n        const internalChunk = {\n            data,\n            type,\n            timestamp,\n            duration,\n            additions,\n        };\n        return internalChunk;\n    }\n    /** Writes a block containing media data to the file. */\n    writeBlock(trackData, chunk) {\n        // Due to the interlacing algorithm, this code will be run once we've seen one chunk from every media track.\n        if (!this.segment) {\n            this.createSegment();\n        }\n        const msTimestamp = Math.round(1000 * chunk.timestamp);\n        // We wanna only finalize this cluster (and begin a new one) if we know that each track will be able to\n        // start the new one with a key frame.\n        const keyFrameQueuedEverywhere = this.trackDatas.every((otherTrackData) => {\n            if (trackData === otherTrackData) {\n                return chunk.type === 'key';\n            }\n            const firstQueuedSample = otherTrackData.chunkQueue[0];\n            if (firstQueuedSample) {\n                return firstQueuedSample.type === 'key';\n            }\n            return otherTrackData.track.source._closed;\n        });\n        let shouldCreateNewCluster = false;\n        if (!this.currentCluster) {\n            shouldCreateNewCluster = true;\n        }\n        else {\n            assert(this.currentClusterStartMsTimestamp !== null);\n            assert(this.currentClusterMaxMsTimestamp !== null);\n            const relativeTimestamp = msTimestamp - this.currentClusterStartMsTimestamp;\n            shouldCreateNewCluster = (keyFrameQueuedEverywhere\n                // This check is required because that means there is already a block with this timestamp in the\n                // CURRENT chunk, meaning that starting the next cluster at the same timestamp is forbidden (since\n                // the already-written block would belong into it instead).\n                && msTimestamp > this.currentClusterMaxMsTimestamp\n                && relativeTimestamp >= 1000 * (this.format._options.minimumClusterDuration ?? 1))\n                // The cluster would exceed its maximum allowed length. This puts us in an unfortunate position and forces\n                // us to begin the next cluster with a delta frame. Although this is undesirable, it is not forbidden by the\n                // spec and is supported by players.\n                || relativeTimestamp > MAX_CLUSTER_TIMESTAMP_MS;\n        }\n        if (shouldCreateNewCluster) {\n            this.createNewCluster(msTimestamp);\n        }\n        const relativeTimestamp = msTimestamp - this.currentClusterStartMsTimestamp;\n        if (relativeTimestamp < MIN_CLUSTER_TIMESTAMP_MS) {\n            // The block lies too far in the past, it's not representable within this cluster\n            return;\n        }\n        const prelude = new Uint8Array(4);\n        const view = new DataView(prelude.buffer);\n        // 0x80 to indicate it's the last byte of a multi-byte number\n        view.setUint8(0, 0x80 | trackData.track.id);\n        view.setInt16(1, relativeTimestamp, false);\n        const msDuration = Math.round(1000 * chunk.duration);\n        if (!chunk.additions) {\n            // No additions, we can write out a SimpleBlock\n            view.setUint8(3, Number(chunk.type === 'key') << 7); // Flags (keyframe flag only present for SimpleBlock)\n            const simpleBlock = { id: EBMLId.SimpleBlock, data: [\n                    prelude,\n                    chunk.data,\n                ] };\n            this.ebmlWriter.writeEBML(simpleBlock);\n        }\n        else {\n            const blockGroup = { id: EBMLId.BlockGroup, data: [\n                    { id: EBMLId.Block, data: [\n                            prelude,\n                            chunk.data,\n                        ] },\n                    chunk.type === 'delta'\n                        ? {\n                            id: EBMLId.ReferenceBlock,\n                            data: new EBMLSignedInt(trackData.lastWrittenMsTimestamp - msTimestamp),\n                        }\n                        : null,\n                    chunk.additions\n                        ? { id: EBMLId.BlockAdditions, data: [\n                                { id: EBMLId.BlockMore, data: [\n                                        { id: EBMLId.BlockAddID, data: 1 }, // Some players expect BlockAddID to come first\n                                        { id: EBMLId.BlockAdditional, data: chunk.additions },\n                                    ] },\n                            ] }\n                        : null,\n                    msDuration > 0 ? { id: EBMLId.BlockDuration, data: msDuration } : null,\n                ] };\n            this.ebmlWriter.writeEBML(blockGroup);\n        }\n        this.duration = Math.max(this.duration, msTimestamp + msDuration);\n        trackData.lastWrittenMsTimestamp = msTimestamp;\n        if (!this.trackDatasInCurrentCluster.has(trackData)) {\n            this.trackDatasInCurrentCluster.set(trackData, {\n                firstMsTimestamp: msTimestamp,\n            });\n        }\n        this.currentClusterMaxMsTimestamp = Math.max(this.currentClusterMaxMsTimestamp, msTimestamp);\n    }\n    /** Creates a new Cluster element to contain media chunks. */\n    createNewCluster(msTimestamp) {\n        if (this.currentCluster) {\n            this.finalizeCurrentCluster();\n        }\n        if (this.format._options.onCluster) {\n            this.writer.startTrackingWrites();\n        }\n        this.currentCluster = {\n            id: EBMLId.Cluster,\n            size: this.format._options.appendOnly ? -1 : CLUSTER_SIZE_BYTES,\n            data: [\n                { id: EBMLId.Timestamp, data: msTimestamp },\n            ],\n        };\n        this.ebmlWriter.writeEBML(this.currentCluster);\n        this.currentClusterStartMsTimestamp = msTimestamp;\n        this.currentClusterMaxMsTimestamp = msTimestamp;\n        this.trackDatasInCurrentCluster.clear();\n    }\n    finalizeCurrentCluster() {\n        assert(this.currentCluster);\n        if (!this.format._options.appendOnly) {\n            const clusterSize = this.writer.getPos() - this.ebmlWriter.dataOffsets.get(this.currentCluster);\n            const endPos = this.writer.getPos();\n            // Write the size now that we know it\n            this.writer.seek(this.ebmlWriter.offsets.get(this.currentCluster) + 4);\n            this.ebmlWriter.writeVarInt(clusterSize, CLUSTER_SIZE_BYTES);\n            this.writer.seek(endPos);\n        }\n        if (this.format._options.onCluster) {\n            assert(this.currentClusterStartMsTimestamp !== null);\n            const { data, start } = this.writer.stopTrackingWrites();\n            this.format._options.onCluster(data, start, this.currentClusterStartMsTimestamp / 1000);\n        }\n        const clusterOffsetFromSegment = this.ebmlWriter.offsets.get(this.currentCluster) - this.segmentDataOffset;\n        // Group tracks by their first timestamp and create a CuePoint for each unique timestamp\n        const groupedByTimestamp = new Map();\n        for (const [trackData, { firstMsTimestamp }] of this.trackDatasInCurrentCluster) {\n            if (!groupedByTimestamp.has(firstMsTimestamp)) {\n                groupedByTimestamp.set(firstMsTimestamp, []);\n            }\n            groupedByTimestamp.get(firstMsTimestamp).push(trackData);\n        }\n        const groupedAndSortedByTimestamp = [...groupedByTimestamp.entries()].sort((a, b) => a[0] - b[0]);\n        // Add CuePoints to the Cues element for better seeking\n        for (const [msTimestamp, trackDatas] of groupedAndSortedByTimestamp) {\n            assert(this.cues);\n            this.cues.data.push({ id: EBMLId.CuePoint, data: [\n                    { id: EBMLId.CueTime, data: msTimestamp },\n                    // Create CueTrackPositions for each track that starts at this timestamp\n                    ...trackDatas.map((trackData) => {\n                        return { id: EBMLId.CueTrackPositions, data: [\n                                { id: EBMLId.CueTrack, data: trackData.track.id },\n                                { id: EBMLId.CueClusterPosition, data: clusterOffsetFromSegment },\n                            ] };\n                    }),\n                ] });\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-misused-promises\n    async onTrackClose() {\n        const release = await this.mutex.acquire();\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        // Since a track is now closed, we may be able to write out chunks that were previously waiting\n        await this.interleaveChunks();\n        release();\n    }\n    /** Finalizes the file, making it ready for use. Must be called after all media chunks have been added. */\n    async finalize() {\n        const release = await this.mutex.acquire();\n        this.allTracksKnown.resolve();\n        if (!this.segment) {\n            this.createSegment();\n        }\n        // Flush any remaining queued chunks to the file\n        await this.interleaveChunks(true);\n        if (this.currentCluster) {\n            this.finalizeCurrentCluster();\n        }\n        assert(this.cues);\n        this.ebmlWriter.writeEBML(this.cues);\n        if (!this.format._options.appendOnly) {\n            const endPos = this.writer.getPos();\n            // Write the Segment size\n            const segmentSize = this.writer.getPos() - this.segmentDataOffset;\n            this.writer.seek(this.ebmlWriter.offsets.get(this.segment) + 4);\n            this.ebmlWriter.writeVarInt(segmentSize, SEGMENT_SIZE_BYTES);\n            // Write the duration of the media to the Segment\n            this.segmentDuration.data = new EBMLFloat64(this.duration);\n            this.writer.seek(this.ebmlWriter.offsets.get(this.segmentDuration));\n            this.ebmlWriter.writeEBML(this.segmentDuration);\n            // Fill in SeekHead position data and write it again\n            assert(this.seekHead);\n            this.writer.seek(this.ebmlWriter.offsets.get(this.seekHead));\n            this.maybeCreateSeekHead(true);\n            this.ebmlWriter.writeEBML(this.seekHead);\n            this.writer.seek(endPos);\n        }\n        release();\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { computeMp3FrameSize, getXingOffset, KILOBIT_RATES, XING, } from '../../shared/mp3-misc.js';\nexport class Mp3Writer {\n    constructor(writer) {\n        this.writer = writer;\n        this.helper = new Uint8Array(8);\n        this.helperView = new DataView(this.helper.buffer);\n    }\n    writeU32(value) {\n        this.helperView.setUint32(0, value, false);\n        this.writer.write(this.helper.subarray(0, 4));\n    }\n    writeXingFrame(data) {\n        const startPos = this.writer.getPos();\n        const firstByte = 0xff;\n        const secondByte = 0xe0 | (data.mpegVersionId << 3) | (data.layer << 1);\n        let lowSamplingFrequency;\n        if (data.mpegVersionId & 2) {\n            lowSamplingFrequency = (data.mpegVersionId & 1) ? 0 : 1;\n        }\n        else {\n            lowSamplingFrequency = 1;\n        }\n        const padding = 0;\n        const neededBytes = 155;\n        let bitrateIndex = -1;\n        const bitrateOffset = lowSamplingFrequency * 16 * 4 + data.layer * 16;\n        // Let's find the lowest bitrate for which the frame size is sufficiently large to fit all the data\n        for (let i = 0; i < 16; i++) {\n            const kbr = KILOBIT_RATES[bitrateOffset + i];\n            const size = computeMp3FrameSize(lowSamplingFrequency, data.layer, 1000 * kbr, data.sampleRate, padding);\n            if (size >= neededBytes) {\n                bitrateIndex = i;\n                break;\n            }\n        }\n        if (bitrateIndex === -1) {\n            throw new Error('No suitable bitrate found.');\n        }\n        const thirdByte = (bitrateIndex << 4) | (data.frequencyIndex << 2) | padding << 1;\n        const fourthByte = (data.channel << 6)\n            | (data.modeExtension << 4)\n            | (data.copyright << 3)\n            | (data.original << 2)\n            | data.emphasis;\n        this.helper[0] = firstByte;\n        this.helper[1] = secondByte;\n        this.helper[2] = thirdByte;\n        this.helper[3] = fourthByte;\n        this.writer.write(this.helper.subarray(0, 4));\n        const xingOffset = getXingOffset(data.mpegVersionId, data.channel);\n        this.writer.seek(startPos + xingOffset);\n        this.writeU32(XING);\n        let flags = 0;\n        if (data.frameCount !== null) {\n            flags |= 1;\n        }\n        if (data.fileSize !== null) {\n            flags |= 2;\n        }\n        if (data.toc !== null) {\n            flags |= 4;\n        }\n        this.writeU32(flags);\n        this.writeU32(data.frameCount ?? 0);\n        this.writeU32(data.fileSize ?? 0);\n        this.writer.write(data.toc ?? new Uint8Array(100));\n        const kilobitRate = KILOBIT_RATES[bitrateOffset + bitrateIndex];\n        const frameSize = computeMp3FrameSize(lowSamplingFrequency, data.layer, 1000 * kilobitRate, data.sampleRate, padding);\n        this.writer.seek(startPos + frameSize);\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { assert, toDataView } from '../misc.js';\nimport { metadataTagsAreEmpty } from '../metadata.js';\nimport { Muxer } from '../muxer.js';\nimport { getXingOffset, INFO, readMp3FrameHeader, XING } from '../../shared/mp3-misc.js';\nimport { Mp3Writer } from './mp3-writer.js';\nimport { Id3V2Writer } from '../id3.js';\nexport class Mp3Muxer extends Muxer {\n    constructor(output, format) {\n        super(output);\n        this.xingFrameData = null;\n        this.frameCount = 0;\n        this.framePositions = [];\n        this.xingFramePos = null;\n        this.format = format;\n        this.writer = output._writer;\n        this.mp3Writer = new Mp3Writer(output._writer);\n    }\n    async start() {\n        if (!metadataTagsAreEmpty(this.output._metadataTags)) {\n            const id3Writer = new Id3V2Writer(this.writer);\n            id3Writer.writeId3V2Tag(this.output._metadataTags);\n        }\n    }\n    async getMimeType() {\n        return 'audio/mpeg';\n    }\n    async addEncodedVideoPacket() {\n        throw new Error('MP3 does not support video.');\n    }\n    async addEncodedAudioPacket(track, packet) {\n        const release = await this.mutex.acquire();\n        try {\n            const writeXingHeader = this.format._options.xingHeader !== false;\n            if (!this.xingFrameData && writeXingHeader) {\n                const view = toDataView(packet.data);\n                if (view.byteLength < 4) {\n                    throw new Error('Invalid MP3 header in sample.');\n                }\n                const word = view.getUint32(0, false);\n                const header = readMp3FrameHeader(word, null).header;\n                if (!header) {\n                    throw new Error('Invalid MP3 header in sample.');\n                }\n                const xingOffset = getXingOffset(header.mpegVersionId, header.channel);\n                if (view.byteLength >= xingOffset + 4) {\n                    const word = view.getUint32(xingOffset, false);\n                    const isXing = word === XING || word === INFO;\n                    if (isXing) {\n                        // This is not a data frame, so let's completely ignore this sample\n                        return;\n                    }\n                }\n                this.xingFrameData = {\n                    mpegVersionId: header.mpegVersionId,\n                    layer: header.layer,\n                    frequencyIndex: header.frequencyIndex,\n                    sampleRate: header.sampleRate,\n                    channel: header.channel,\n                    modeExtension: header.modeExtension,\n                    copyright: header.copyright,\n                    original: header.original,\n                    emphasis: header.emphasis,\n                    frameCount: null,\n                    fileSize: null,\n                    toc: null,\n                };\n                // Write a Xing frame because this muxer doesn't make any bitrate constraints, meaning we don't know if\n                // this will be a constant or variable bitrate file. Therefore, always write the Xing frame.\n                this.xingFramePos = this.writer.getPos();\n                this.mp3Writer.writeXingFrame(this.xingFrameData);\n                this.frameCount++;\n            }\n            this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === 'key');\n            this.writer.write(packet.data);\n            this.frameCount++;\n            await this.writer.flush();\n            if (writeXingHeader) {\n                this.framePositions.push(this.writer.getPos());\n            }\n        }\n        finally {\n            release();\n        }\n    }\n    async addSubtitleCue() {\n        throw new Error('MP3 does not support subtitles.');\n    }\n    async finalize() {\n        if (!this.xingFrameData || this.xingFramePos === null) {\n            return;\n        }\n        const release = await this.mutex.acquire();\n        const endPos = this.writer.getPos();\n        this.writer.seek(this.xingFramePos);\n        const toc = new Uint8Array(100);\n        for (let i = 0; i < 100; i++) {\n            const index = Math.floor(this.framePositions.length * (i / 100));\n            assert(index !== -1 && index < this.framePositions.length);\n            const byteOffset = this.framePositions[index];\n            toc[i] = 256 * (byteOffset / endPos);\n        }\n        this.xingFrameData.frameCount = this.frameCount;\n        this.xingFrameData.fileSize = endPos;\n        this.xingFrameData.toc = toc;\n        if (this.format._options.onXingFrame) {\n            this.writer.startTrackingWrites();\n        }\n        this.mp3Writer.writeXingFrame(this.xingFrameData);\n        if (this.format._options.onXingFrame) {\n            const { data, start } = this.writer.stopTrackingWrites();\n            this.format._options.onXingFrame(data, start);\n        }\n        this.writer.seek(endPos);\n        release();\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { OPUS_SAMPLE_RATE, validateAudioChunkMetadata } from '../codec.js';\nimport { createVorbisComments, parseModesFromVorbisSetupPacket, parseOpusIdentificationHeader } from '../codec-data.js';\nimport { assert, promiseWithResolvers, setInt64, toDataView, toUint8Array, } from '../misc.js';\nimport { Muxer } from '../muxer.js';\nimport { buildOggMimeType, computeOggPageCrc, extractSampleMetadata, OGGS, } from './ogg-misc.js';\nimport { MAX_PAGE_SIZE } from './ogg-reader.js';\nconst PAGE_SIZE_TARGET = 8192;\nexport class OggMuxer extends Muxer {\n    constructor(output, format) {\n        super(output);\n        this.trackDatas = [];\n        this.bosPagesWritten = false;\n        this.allTracksKnown = promiseWithResolvers();\n        this.pageBytes = new Uint8Array(MAX_PAGE_SIZE);\n        this.pageView = new DataView(this.pageBytes.buffer);\n        this.format = format;\n        this.writer = output._writer;\n        this.writer.ensureMonotonicity = true; // Ogg is always monotonically written!\n    }\n    async start() {\n        // Nothin'\n    }\n    async getMimeType() {\n        await this.allTracksKnown.promise;\n        return buildOggMimeType({\n            codecStrings: this.trackDatas.map(x => x.codecInfo.codec),\n        });\n    }\n    addEncodedVideoPacket() {\n        throw new Error('Video tracks are not supported.');\n    }\n    getTrackData(track, meta) {\n        const existingTrackData = this.trackDatas.find(td => td.track === track);\n        if (existingTrackData) {\n            return existingTrackData;\n        }\n        // Give the track a unique random serial number\n        let serialNumber;\n        do {\n            serialNumber = Math.floor(2 ** 32 * Math.random());\n        } while (this.trackDatas.some(td => td.serialNumber === serialNumber));\n        assert(track.source._codec === 'vorbis' || track.source._codec === 'opus');\n        validateAudioChunkMetadata(meta);\n        assert(meta);\n        assert(meta.decoderConfig);\n        const newTrackData = {\n            track,\n            serialNumber,\n            internalSampleRate: track.source._codec === 'opus'\n                ? OPUS_SAMPLE_RATE\n                : meta.decoderConfig.sampleRate,\n            codecInfo: {\n                codec: track.source._codec,\n                vorbisInfo: null,\n                opusInfo: null,\n            },\n            vorbisLastBlocksize: null,\n            packetQueue: [],\n            currentTimestampInSamples: 0,\n            pagesWritten: 0,\n            currentGranulePosition: 0,\n            currentLacingValues: [],\n            currentPageData: [],\n            currentPageSize: 27,\n            currentPageStartsWithFreshPacket: true,\n            currentPageStartTimestampInSamples: 0,\n        };\n        this.queueHeaderPackets(newTrackData, meta);\n        this.trackDatas.push(newTrackData);\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        return newTrackData;\n    }\n    queueHeaderPackets(trackData, meta) {\n        assert(meta.decoderConfig);\n        if (trackData.track.source._codec === 'vorbis') {\n            assert(meta.decoderConfig.description);\n            const bytes = toUint8Array(meta.decoderConfig.description);\n            if (bytes[0] !== 2) {\n                throw new TypeError('First byte of Vorbis decoder description must be 2.');\n            }\n            let pos = 1;\n            const readPacketLength = () => {\n                let length = 0;\n                while (true) {\n                    const value = bytes[pos++];\n                    if (value === undefined) {\n                        throw new TypeError('Vorbis decoder description is too short.');\n                    }\n                    length += value;\n                    if (value < 255) {\n                        return length;\n                    }\n                }\n            };\n            const identificationHeaderLength = readPacketLength();\n            const commentHeaderLength = readPacketLength();\n            const setupHeaderLength = bytes.length - pos; // Setup header fills the remaining bytes\n            if (setupHeaderLength <= 0) {\n                throw new TypeError('Vorbis decoder description is too short.');\n            }\n            const identificationHeader = bytes.subarray(pos, pos += identificationHeaderLength);\n            pos += commentHeaderLength; // Skip the comment header, we'll build our own\n            const setupHeader = bytes.subarray(pos);\n            const commentHeaderHeader = new Uint8Array(7);\n            commentHeaderHeader[0] = 3; // Packet type\n            commentHeaderHeader[1] = 0x76; // 'v'\n            commentHeaderHeader[2] = 0x6f; // 'o'\n            commentHeaderHeader[3] = 0x72; // 'r'\n            commentHeaderHeader[4] = 0x62; // 'b'\n            commentHeaderHeader[5] = 0x69; // 'i'\n            commentHeaderHeader[6] = 0x73; // 's'\n            const commentHeader = createVorbisComments(commentHeaderHeader, this.output._metadataTags, true);\n            trackData.packetQueue.push({\n                data: identificationHeader,\n                timestampInSamples: 0,\n                durationInSamples: 0,\n                forcePageFlush: true,\n            }, {\n                data: commentHeader,\n                timestampInSamples: 0,\n                durationInSamples: 0,\n                forcePageFlush: false,\n            }, {\n                data: setupHeader,\n                timestampInSamples: 0,\n                durationInSamples: 0,\n                forcePageFlush: true, // The last header packet must flush the page\n            });\n            const view = toDataView(identificationHeader);\n            const blockSizeByte = view.getUint8(28);\n            trackData.codecInfo.vorbisInfo = {\n                blocksizes: [\n                    1 << (blockSizeByte & 0xf),\n                    1 << (blockSizeByte >> 4),\n                ],\n                modeBlockflags: parseModesFromVorbisSetupPacket(setupHeader).modeBlockflags,\n            };\n        }\n        else if (trackData.track.source._codec === 'opus') {\n            if (!meta.decoderConfig.description) {\n                throw new TypeError('For Ogg, Opus decoder description is required.');\n            }\n            const identificationHeader = toUint8Array(meta.decoderConfig.description);\n            const commentHeaderHeader = new Uint8Array(8);\n            const commentHeaderHeaderView = toDataView(commentHeaderHeader);\n            commentHeaderHeaderView.setUint32(0, 0x4f707573, false); // 'Opus'\n            commentHeaderHeaderView.setUint32(4, 0x54616773, false); // 'Tags'\n            const commentHeader = createVorbisComments(commentHeaderHeader, this.output._metadataTags, true);\n            trackData.packetQueue.push({\n                data: identificationHeader,\n                timestampInSamples: 0,\n                durationInSamples: 0,\n                forcePageFlush: true,\n            }, {\n                data: commentHeader,\n                timestampInSamples: 0,\n                durationInSamples: 0,\n                forcePageFlush: true, // The last header packet must flush the page\n            });\n            trackData.codecInfo.opusInfo = {\n                preSkip: parseOpusIdentificationHeader(identificationHeader).preSkip,\n            };\n        }\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            const trackData = this.getTrackData(track, meta);\n            this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, packet.type === 'key');\n            const currentTimestampInSamples = trackData.currentTimestampInSamples;\n            const { durationInSamples, vorbisBlockSize } = extractSampleMetadata(packet.data, trackData.codecInfo, trackData.vorbisLastBlocksize);\n            trackData.currentTimestampInSamples += durationInSamples;\n            trackData.vorbisLastBlocksize = vorbisBlockSize;\n            trackData.packetQueue.push({\n                data: packet.data,\n                timestampInSamples: currentTimestampInSamples,\n                durationInSamples,\n                forcePageFlush: false,\n            });\n            await this.interleavePages();\n        }\n        finally {\n            release();\n        }\n    }\n    addSubtitleCue() {\n        throw new Error('Subtitle tracks are not supported.');\n    }\n    allTracksAreKnown() {\n        for (const track of this.output._tracks) {\n            if (!track.source._closed && !this.trackDatas.some(x => x.track === track)) {\n                return false; // We haven't seen a sample from this open track yet\n            }\n        }\n        return true;\n    }\n    async interleavePages(isFinalCall = false) {\n        if (!this.bosPagesWritten) {\n            if (!this.allTracksAreKnown() && !isFinalCall) {\n                return; // We can't interleave yet as we don't yet know how many tracks we'll truly have\n            }\n            // Write the header page for all bitstreams\n            for (const trackData of this.trackDatas) {\n                while (trackData.packetQueue.length > 0) {\n                    const packet = trackData.packetQueue.shift();\n                    this.writePacket(trackData, packet, false);\n                    if (packet.forcePageFlush) {\n                        // We say the header page ends once the first packet is encountered that forces a page flush\n                        break;\n                    }\n                }\n            }\n            this.bosPagesWritten = true;\n        }\n        outer: while (true) {\n            let trackWithMinTimestamp = null;\n            let minTimestamp = Infinity;\n            for (const trackData of this.trackDatas) {\n                if (!isFinalCall\n                    && trackData.packetQueue.length <= 1 // Limit is 1, not 0, for correct EOS flag logic\n                    && !trackData.track.source._closed) {\n                    break outer;\n                }\n                if (trackData.packetQueue.length > 0\n                    && trackData.packetQueue[0].timestampInSamples < minTimestamp) {\n                    trackWithMinTimestamp = trackData;\n                    minTimestamp = trackData.packetQueue[0].timestampInSamples;\n                }\n            }\n            if (!trackWithMinTimestamp) {\n                break;\n            }\n            const packet = trackWithMinTimestamp.packetQueue.shift();\n            const isFinalPacket = trackWithMinTimestamp.packetQueue.length === 0;\n            this.writePacket(trackWithMinTimestamp, packet, isFinalPacket);\n        }\n        if (!isFinalCall) {\n            await this.writer.flush();\n        }\n    }\n    writePacket(trackData, packet, isFinalPacket) {\n        const packetEndTimestampInSamples = packet.timestampInSamples + packet.durationInSamples;\n        if (this.format._options.maximumPageDuration !== undefined) {\n            const maxDurationInSamples = this.format._options.maximumPageDuration * trackData.internalSampleRate;\n            if (trackData.currentLacingValues.length > 0\n                && packetEndTimestampInSamples - trackData.currentPageStartTimestampInSamples > maxDurationInSamples) {\n                // Flush the current page early to avoid exceeding the maximum page duration\n                this.writePage(trackData, false);\n            }\n        }\n        let remainingLength = packet.data.length;\n        let dataStartOffset = 0;\n        let dataOffset = 0;\n        while (true) {\n            if (trackData.currentLacingValues.length === 0 && dataStartOffset > 0) {\n                // This is a packet spanning multiple pages\n                trackData.currentPageStartsWithFreshPacket = false;\n            }\n            const segmentSize = Math.min(255, remainingLength);\n            trackData.currentLacingValues.push(segmentSize);\n            trackData.currentPageSize++;\n            dataOffset += segmentSize;\n            const segmentIsLastOfPacket = remainingLength < 255;\n            if (trackData.currentLacingValues.length === 255) {\n                // The page is full, we need to add part of the packet data and then flush the page\n                const slice = packet.data.subarray(dataStartOffset, dataOffset);\n                dataStartOffset = dataOffset;\n                trackData.currentPageData.push(slice);\n                trackData.currentPageSize += slice.length;\n                this.writePage(trackData, isFinalPacket && segmentIsLastOfPacket);\n                if (segmentIsLastOfPacket) {\n                    return;\n                }\n            }\n            if (segmentIsLastOfPacket) {\n                break;\n            }\n            remainingLength -= 255;\n        }\n        const slice = packet.data.subarray(dataStartOffset);\n        trackData.currentPageData.push(slice);\n        trackData.currentPageSize += slice.length;\n        trackData.currentGranulePosition = packetEndTimestampInSamples;\n        if (trackData.currentPageSize >= PAGE_SIZE_TARGET || packet.forcePageFlush) {\n            this.writePage(trackData, isFinalPacket);\n        }\n    }\n    writePage(trackData, isEos) {\n        this.pageView.setUint32(0, OGGS, true); // Capture pattern\n        this.pageView.setUint8(4, 0); // Version\n        let headerType = 0;\n        if (!trackData.currentPageStartsWithFreshPacket) {\n            headerType |= 1;\n        }\n        if (trackData.pagesWritten === 0) {\n            headerType |= 2; // Beginning of stream\n        }\n        if (isEos) {\n            headerType |= 4; // End of stream\n        }\n        this.pageView.setUint8(5, headerType); // Header type\n        const granulePosition = trackData.currentLacingValues.every(x => x === 255)\n            ? -1 // No packets end on this page\n            : trackData.currentGranulePosition;\n        setInt64(this.pageView, 6, granulePosition, true); // Granule position\n        this.pageView.setUint32(14, trackData.serialNumber, true); // Serial number\n        this.pageView.setUint32(18, trackData.pagesWritten, true); // Page sequence number\n        this.pageView.setUint32(22, 0, true); // Checksum placeholder\n        this.pageView.setUint8(26, trackData.currentLacingValues.length); // Number of page segments\n        this.pageBytes.set(trackData.currentLacingValues, 27);\n        let pos = 27 + trackData.currentLacingValues.length;\n        for (const data of trackData.currentPageData) {\n            this.pageBytes.set(data, pos);\n            pos += data.length;\n        }\n        const slice = this.pageBytes.subarray(0, pos);\n        const crc = computeOggPageCrc(slice);\n        this.pageView.setUint32(22, crc, true); // Checksum\n        trackData.pagesWritten++;\n        trackData.currentLacingValues.length = 0;\n        trackData.currentPageData.length = 0;\n        trackData.currentPageSize = 27;\n        trackData.currentPageStartsWithFreshPacket = true;\n        trackData.currentPageStartTimestampInSamples = trackData.currentGranulePosition;\n        if (this.format._options.onPage) {\n            this.writer.startTrackingWrites();\n        }\n        this.writer.write(slice);\n        if (this.format._options.onPage) {\n            const { data, start } = this.writer.stopTrackingWrites();\n            this.format._options.onPage(data, start, trackData.track.source);\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-misused-promises\n    async onTrackClose() {\n        const release = await this.mutex.acquire();\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        // Since a track is now closed, we may be able to write out chunks that were previously waiting\n        await this.interleavePages();\n        release();\n    }\n    async finalize() {\n        const release = await this.mutex.acquire();\n        this.allTracksKnown.resolve();\n        await this.interleavePages(true);\n        for (const trackData of this.trackDatas) {\n            if (trackData.currentLacingValues.length > 0) {\n                this.writePage(trackData, true);\n            }\n        }\n        release();\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { parseAacAudioSpecificConfig, validateAudioChunkMetadata, validateVideoChunkMetadata } from '../codec.js';\nimport { buildAdtsHeaderTemplate, writeAdtsFrameLength } from '../adts/adts-misc.js';\nimport { AvcNalUnitType, concatNalUnitsInAnnexB, deserializeAvcDecoderConfigurationRecord, deserializeHevcDecoderConfigurationRecord, extractNalUnitTypeForAvc, extractNalUnitTypeForHevc, HevcNalUnitType, iterateNalUnitsInAnnexB, iterateNalUnitsInLengthPrefixed, } from '../codec-data.js';\nimport { assert, Bitstream, promiseWithResolvers, setUint24, toDataView, toUint8Array } from '../misc.js';\nimport { Muxer } from '../muxer.js';\nimport { buildMpegTsMimeType, TIMESCALE, TS_PACKET_SIZE } from './mpeg-ts-misc.js';\nconst PAT_PID = 0x0000;\nconst PMT_PID = 0x1000;\nconst FIRST_TRACK_PID = 0x0100;\nconst VIDEO_STREAM_ID_BASE = 0xE0;\nconst AUDIO_STREAM_ID_BASE = 0xC0;\nconst AVC_AUD_NAL = new Uint8Array([0x09, 0xF0]);\nconst HEVC_AUD_NAL = new Uint8Array([0x46, 0x01]);\nexport class MpegTsMuxer extends Muxer {\n    constructor(output, format) {\n        super(output);\n        this.trackDatas = [];\n        this.tablesWritten = false;\n        this.continuityCounters = new Map();\n        this.packetBuffer = new Uint8Array(TS_PACKET_SIZE);\n        this.packetView = toDataView(this.packetBuffer);\n        this.allTracksKnown = promiseWithResolvers();\n        this.videoTrackIndex = 0;\n        this.audioTrackIndex = 0;\n        this.pesHeaderBuffer = new Uint8Array(14);\n        this.pesHeaderView = toDataView(this.pesHeaderBuffer);\n        this.ptsBitstream = new Bitstream(this.pesHeaderBuffer.subarray(9, 14));\n        this.adaptationFieldBuffer = new Uint8Array(184);\n        this.payloadBuffer = new Uint8Array(184);\n        this.format = format;\n        this.writer = output._writer;\n        this.writer.ensureMonotonicity = true;\n    }\n    async start() {\n        // Nothing to do here\n    }\n    async getMimeType() {\n        await this.allTracksKnown.promise;\n        return buildMpegTsMimeType(this.trackDatas.map(x => x.codecString));\n    }\n    getVideoTrackData(track, meta) {\n        const existingTrackData = this.trackDatas.find(x => x.track === track);\n        if (existingTrackData) {\n            return existingTrackData;\n        }\n        validateVideoChunkMetadata(meta);\n        assert(meta?.decoderConfig);\n        const codec = track.source._codec;\n        assert(codec === 'avc' || codec === 'hevc');\n        const streamType = codec === 'avc'\n            ? 27 /* MpegTsStreamType.AVC */\n            : 36 /* MpegTsStreamType.HEVC */;\n        const pid = FIRST_TRACK_PID + this.trackDatas.length;\n        const streamId = VIDEO_STREAM_ID_BASE + this.videoTrackIndex++;\n        const newTrackData = {\n            track,\n            pid,\n            streamType,\n            streamId,\n            codecString: meta.decoderConfig.codec,\n            packetQueue: [],\n            inputIsAnnexB: null,\n            inputIsAdts: null,\n            avcDecoderConfig: null,\n            hevcDecoderConfig: null,\n            adtsHeader: null,\n            adtsHeaderBitstream: null,\n            firstPacketWritten: false,\n        };\n        this.trackDatas.push(newTrackData);\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        return newTrackData;\n    }\n    getAudioTrackData(track, meta) {\n        const existingTrackData = this.trackDatas.find(x => x.track === track);\n        if (existingTrackData) {\n            return existingTrackData;\n        }\n        validateAudioChunkMetadata(meta);\n        assert(meta?.decoderConfig);\n        const codec = track.source._codec;\n        assert(codec === 'aac' || codec === 'mp3');\n        const streamType = codec === 'aac' ? 15 /* MpegTsStreamType.AAC */ : 3 /* MpegTsStreamType.MP3_MPEG1 */;\n        const pid = FIRST_TRACK_PID + this.trackDatas.length;\n        const streamId = AUDIO_STREAM_ID_BASE + this.audioTrackIndex++;\n        const newTrackData = {\n            track,\n            pid,\n            streamType,\n            streamId,\n            codecString: meta.decoderConfig.codec,\n            packetQueue: [],\n            inputIsAnnexB: null,\n            inputIsAdts: null,\n            avcDecoderConfig: null,\n            hevcDecoderConfig: null,\n            adtsHeader: null,\n            adtsHeaderBitstream: null,\n            firstPacketWritten: false,\n        };\n        this.trackDatas.push(newTrackData);\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        return newTrackData;\n    }\n    async addEncodedVideoPacket(track, packet, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            const trackData = this.getVideoTrackData(track, meta);\n            const timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, packet.type === 'key');\n            const preparedData = this.prepareVideoPacket(trackData, packet, meta);\n            trackData.packetQueue.push({\n                data: preparedData,\n                timestamp,\n                isKeyframe: packet.type === 'key',\n            });\n            await this.interleavePackets();\n        }\n        finally {\n            release();\n        }\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            const trackData = this.getAudioTrackData(track, meta);\n            const timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, packet.type === 'key');\n            const preparedData = this.prepareAudioPacket(trackData, packet, meta);\n            trackData.packetQueue.push({\n                data: preparedData,\n                timestamp,\n                isKeyframe: packet.type === 'key',\n            });\n            await this.interleavePackets();\n        }\n        finally {\n            release();\n        }\n    }\n    async addSubtitleCue() {\n        throw new Error('MPEG-TS does not support subtitles.');\n    }\n    prepareVideoPacket(trackData, packet, meta) {\n        const codec = trackData.track.source._codec;\n        if (trackData.inputIsAnnexB === null) {\n            // This is the first packet\n            const description = meta?.decoderConfig?.description;\n            trackData.inputIsAnnexB = !description;\n            if (!trackData.inputIsAnnexB) {\n                const bytes = toUint8Array(description);\n                if (codec === 'avc') {\n                    trackData.avcDecoderConfig = deserializeAvcDecoderConfigurationRecord(bytes);\n                }\n                else {\n                    trackData.hevcDecoderConfig = deserializeHevcDecoderConfigurationRecord(bytes);\n                }\n            }\n        }\n        if (trackData.inputIsAnnexB) {\n            return this.prepareAnnexBVideoPacket(packet.data, codec);\n        }\n        else {\n            return this.prepareLengthPrefixedVideoPacket(trackData, packet, codec);\n        }\n    }\n    prepareAnnexBVideoPacket(data, codec) {\n        const nalUnits = [];\n        for (const loc of iterateNalUnitsInAnnexB(data)) {\n            const nalUnit = data.subarray(loc.offset, loc.offset + loc.length);\n            const isAud = codec === 'avc'\n                ? extractNalUnitTypeForAvc(nalUnit[0]) === AvcNalUnitType.AUD\n                : extractNalUnitTypeForHevc(nalUnit[0]) === HevcNalUnitType.AUD_NUT;\n            if (!isAud) {\n                nalUnits.push(nalUnit);\n            }\n        }\n        // Pretend the AUD\n        const aud = codec === 'avc'\n            ? AVC_AUD_NAL\n            : HEVC_AUD_NAL;\n        nalUnits.unshift(aud);\n        return concatNalUnitsInAnnexB(nalUnits);\n    }\n    prepareLengthPrefixedVideoPacket(trackData, packet, codec) {\n        const data = packet.data;\n        const lengthSize = codec === 'avc'\n            ? (trackData.avcDecoderConfig.lengthSizeMinusOne + 1)\n            : (trackData.hevcDecoderConfig.lengthSizeMinusOne + 1);\n        const nalUnits = [];\n        for (const loc of iterateNalUnitsInLengthPrefixed(data, lengthSize)) {\n            const nalUnit = data.subarray(loc.offset, loc.offset + loc.length);\n            const isAud = codec === 'avc'\n                ? extractNalUnitTypeForAvc(nalUnit[0]) === AvcNalUnitType.AUD\n                : extractNalUnitTypeForHevc(nalUnit[0]) === HevcNalUnitType.AUD_NUT;\n            if (!isAud) {\n                nalUnits.push(nalUnit);\n            }\n        }\n        if (packet.type === 'key') {\n            // Add whichever NALUs are missing\n            if (codec === 'avc') {\n                const config = trackData.avcDecoderConfig;\n                for (const pps of config.pictureParameterSets) {\n                    nalUnits.unshift(pps);\n                }\n                for (const sps of config.sequenceParameterSets) {\n                    nalUnits.unshift(sps);\n                }\n            }\n            else {\n                const config = trackData.hevcDecoderConfig;\n                for (const arr of config.arrays) {\n                    if (arr.nalUnitType === HevcNalUnitType.PPS_NUT) {\n                        for (const nal of arr.nalUnits) {\n                            nalUnits.unshift(nal);\n                        }\n                    }\n                }\n                for (const arr of config.arrays) {\n                    if (arr.nalUnitType === HevcNalUnitType.SPS_NUT) {\n                        for (const nal of arr.nalUnits) {\n                            nalUnits.unshift(nal);\n                        }\n                    }\n                }\n                for (const arr of config.arrays) {\n                    if (arr.nalUnitType === HevcNalUnitType.VPS_NUT) {\n                        for (const nal of arr.nalUnits) {\n                            nalUnits.unshift(nal);\n                        }\n                    }\n                }\n            }\n        }\n        // Prepend the AUD\n        const aud = codec === 'avc'\n            ? AVC_AUD_NAL\n            : HEVC_AUD_NAL;\n        nalUnits.unshift(aud);\n        return concatNalUnitsInAnnexB(nalUnits);\n    }\n    prepareAudioPacket(trackData, packet, meta) {\n        const codec = trackData.track.source._codec;\n        if (codec === 'mp3') {\n            // We're good\n            return packet.data;\n        }\n        if (trackData.inputIsAdts === null) {\n            // It's the first packet\n            const description = meta?.decoderConfig?.description;\n            trackData.inputIsAdts = !description;\n            if (!trackData.inputIsAdts) {\n                const config = parseAacAudioSpecificConfig(toUint8Array(description));\n                const template = buildAdtsHeaderTemplate(config);\n                trackData.adtsHeader = template.header;\n                trackData.adtsHeaderBitstream = template.bitstream;\n            }\n        }\n        if (trackData.inputIsAdts) {\n            return packet.data;\n        }\n        assert(trackData.adtsHeader);\n        assert(trackData.adtsHeaderBitstream);\n        const header = trackData.adtsHeader;\n        const frameLength = packet.data.byteLength + header.byteLength;\n        writeAdtsFrameLength(trackData.adtsHeaderBitstream, frameLength);\n        const result = new Uint8Array(frameLength);\n        result.set(header, 0);\n        result.set(packet.data, header.byteLength);\n        return result;\n    }\n    allTracksAreKnown() {\n        for (const track of this.output._tracks) {\n            if (!track.source._closed && !this.trackDatas.some(x => x.track === track)) {\n                return false;\n            }\n        }\n        return true;\n    }\n    async interleavePackets(isFinalCall = false) {\n        if (!this.tablesWritten) {\n            if (!this.allTracksAreKnown() && !isFinalCall) {\n                return;\n            }\n            this.writeTables();\n        }\n        outer: while (true) {\n            let trackWithMinTimestamp = null;\n            let minTimestamp = Infinity;\n            for (const trackData of this.trackDatas) {\n                if (!isFinalCall\n                    && trackData.packetQueue.length === 0\n                    && !trackData.track.source._closed) {\n                    break outer;\n                }\n                if (trackData.packetQueue.length > 0\n                    && trackData.packetQueue[0].timestamp < minTimestamp) {\n                    trackWithMinTimestamp = trackData;\n                    minTimestamp = trackData.packetQueue[0].timestamp;\n                }\n            }\n            if (!trackWithMinTimestamp) {\n                break;\n            }\n            const queuedPacket = trackWithMinTimestamp.packetQueue.shift();\n            this.writePesPacket(trackWithMinTimestamp, queuedPacket);\n        }\n        if (!isFinalCall) {\n            await this.writer.flush();\n        }\n    }\n    writeTables() {\n        assert(!this.tablesWritten);\n        this.writePsiSection(PAT_PID, PAT_SECTION);\n        this.writePsiSection(PMT_PID, buildPmt(this.trackDatas));\n        this.tablesWritten = true;\n    }\n    writePsiSection(pid, section) {\n        let offset = 0;\n        let isFirst = true;\n        // Long PSI sections might span more than one TS packet\n        while (offset < section.length) {\n            const pointerFieldSize = isFirst ? 1 : 0;\n            const availablePayload = 184 - pointerFieldSize;\n            const remainingData = section.length - offset;\n            const chunkSize = Math.min(availablePayload, remainingData);\n            let payload;\n            if (isFirst) {\n                payload = this.payloadBuffer.subarray(0, 1 + chunkSize);\n                payload[0] = 0x00; // pointer_field\n                payload.set(section.subarray(offset, offset + chunkSize), 1);\n            }\n            else {\n                payload = section.subarray(offset, offset + chunkSize);\n            }\n            this.writeTsPacket(pid, isFirst, null, payload);\n            offset += chunkSize;\n            isFirst = false;\n        }\n    }\n    writePesPacket(trackData, queuedPacket) {\n        const pesView = this.pesHeaderView;\n        setUint24(pesView, 0, 0x000001, false); // packet_start_code_prefix\n        this.pesHeaderBuffer[3] = trackData.streamId; // stream_id\n        const pesPacketLength = trackData.track.type === 'video'\n            ? 0 // Unbounded\n            : Math.min(8 + queuedPacket.data.length, 0xFFFF); // Required for audio for some reason\n        pesView.setUint16(4, pesPacketLength, false);\n        // '10' marker, PES_scrambling_control=0, PES_priority=0,\n        // data_alignment_indicator=1, copyright=0, original_or_copy=0\n        pesView.setUint8(6, 0x84);\n        pesView.setUint8(7, 0x80); // PTS_DTS_flags=10 (PTS only), other flags=0\n        pesView.setUint8(8, 5); // PES_header_data_length (5 bytes for PTS)\n        const pts = Math.round(queuedPacket.timestamp * TIMESCALE);\n        this.ptsBitstream.pos = 0;\n        this.ptsBitstream.writeBits(4, 0b0010); // marker\n        this.ptsBitstream.writeBits(3, (pts >>> 30) & 0x7); // PTS[32:30]\n        this.ptsBitstream.writeBits(1, 1); // marker_bit\n        this.ptsBitstream.writeBits(15, (pts >>> 15) & 0x7FFF); // PTS[29:15]\n        this.ptsBitstream.writeBits(1, 1); // marker_bit\n        this.ptsBitstream.writeBits(15, pts & 0x7FFF); // PTS[14:0]\n        this.ptsBitstream.writeBits(1, 1); // marker_bit\n        const totalLength = this.pesHeaderBuffer.length + queuedPacket.data.length;\n        let offset = 0;\n        let isFirstTsPacket = true;\n        while (offset < totalLength) {\n            const pusi = isFirstTsPacket;\n            const remainingData = totalLength - offset;\n            const randomAccessIndicator = isFirstTsPacket && queuedPacket.isKeyframe;\n            const discontinuityIndicator = isFirstTsPacket && !trackData.firstPacketWritten;\n            const basePaddingNeeded = Math.max(0, 184 - remainingData);\n            let adaptationFieldSize;\n            if (randomAccessIndicator || discontinuityIndicator) {\n                // We need at least two bytes\n                adaptationFieldSize = Math.max(2, basePaddingNeeded);\n            }\n            else {\n                adaptationFieldSize = basePaddingNeeded;\n            }\n            let adaptationField = null;\n            if (adaptationFieldSize > 0) {\n                const buf = this.adaptationFieldBuffer;\n                if (adaptationFieldSize === 1) {\n                    buf[0] = 0; // adaptation_field_length\n                }\n                else {\n                    buf[0] = adaptationFieldSize - 1; // adaptation_field_length\n                    buf[1]\n                        = (Number(discontinuityIndicator) << 7) // discontinuity_indicator\n                            | (Number(randomAccessIndicator) << 6); // random_access_indicator\n                    buf.fill(0xFF, 2, adaptationFieldSize); // stuffing_bytes\n                }\n                adaptationField = buf.subarray(0, adaptationFieldSize);\n            }\n            const payloadSize = Math.min(184 - adaptationFieldSize, remainingData);\n            const payload = this.payloadBuffer.subarray(0, payloadSize);\n            let payloadOffset = 0;\n            if (offset < this.pesHeaderBuffer.length) {\n                const headerBytes = Math.min(this.pesHeaderBuffer.length - offset, payloadSize);\n                payload.set(this.pesHeaderBuffer.subarray(offset, offset + headerBytes), 0);\n                payloadOffset = headerBytes;\n            }\n            const dataStart = Math.max(0, offset - this.pesHeaderBuffer.length);\n            const dataEnd = dataStart + (payloadSize - payloadOffset);\n            if (payloadOffset < payloadSize) {\n                payload.set(queuedPacket.data.subarray(dataStart, dataEnd), payloadOffset);\n            }\n            this.writeTsPacket(trackData.pid, pusi, adaptationField, payload);\n            offset += payloadSize;\n            isFirstTsPacket = false;\n        }\n        trackData.firstPacketWritten = true;\n    }\n    writeTsPacket(pid, pusi, adaptationField, payload) {\n        const cc = this.continuityCounters.get(pid) ?? 0;\n        const hasPayload = payload.length > 0;\n        const adaptCtrl = adaptationField\n            ? (hasPayload ? 0b11 : 0b10)\n            : (hasPayload ? 0b01 : 0b00);\n        this.packetBuffer[0] = 0x47; // sync_byte\n        this.packetView.setUint16(1, (pusi ? 0x4000 : 0) | (pid & 0x1FFF), false); // TEI=0, PUSI, priority=0, PID\n        // scrambling=0, adaptation_field_control, continuity_counter\n        this.packetBuffer[3] = (adaptCtrl << 4) | (cc & 0x0F);\n        if (hasPayload) {\n            this.continuityCounters.set(pid, (cc + 1) & 0x0F);\n        }\n        let offset = 4;\n        if (adaptationField) {\n            this.packetBuffer.set(adaptationField, offset);\n            offset += adaptationField.length;\n        }\n        this.packetBuffer.set(payload, offset);\n        offset += payload.length;\n        if (offset < TS_PACKET_SIZE) {\n            this.packetBuffer.fill(0xFF, offset); // stuffing_bytes\n        }\n        const startPos = this.writer.getPos();\n        this.writer.write(this.packetBuffer);\n        if (this.format._options.onPacket) {\n            this.format._options.onPacket(this.packetBuffer.slice(), startPos);\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-misused-promises\n    async onTrackClose() {\n        const release = await this.mutex.acquire();\n        if (this.allTracksAreKnown()) {\n            this.allTracksKnown.resolve();\n        }\n        await this.interleavePackets();\n        release();\n    }\n    async finalize() {\n        const release = await this.mutex.acquire();\n        this.allTracksKnown.resolve();\n        await this.interleavePackets(true);\n        release();\n    }\n}\n// CRC-32 for MPEG-TS (polynomial 0x04C11DB7, initial value 0xFFFFFFFF)\nconst MPEG_TS_CRC_POLYNOMIAL = 0x04c11db7;\nconst MPEG_TS_CRC_TABLE = new Uint32Array(256);\nfor (let n = 0; n < 256; n++) {\n    let crc = n << 24;\n    for (let k = 0; k < 8; k++) {\n        crc = (crc & 0x80000000)\n            ? ((crc << 1) ^ MPEG_TS_CRC_POLYNOMIAL)\n            : (crc << 1);\n    }\n    MPEG_TS_CRC_TABLE[n] = (crc >>> 0) & 0xffffffff;\n}\nconst computeMpegTsCrc32 = (data) => {\n    let crc = 0xFFFFFFFF;\n    for (let i = 0; i < data.length; i++) {\n        const byte = data[i];\n        crc = ((crc << 8) ^ MPEG_TS_CRC_TABLE[(crc >>> 24) ^ byte]) >>> 0;\n    }\n    return crc;\n};\nconst PAT_SECTION = new Uint8Array(16);\n{\n    const view = toDataView(PAT_SECTION);\n    PAT_SECTION[0] = 0x00; // table_id\n    view.setUint16(1, 0xB00D, false); // section_syntax_indicator=1, '0', reserved=11, section_length=13\n    view.setUint16(3, 0x0001, false); // transport_stream_id\n    PAT_SECTION[5] = 0xC1; // reserved=11, version_number=0, current_next_indicator=1\n    PAT_SECTION[6] = 0x00; // section_number\n    PAT_SECTION[7] = 0x00; // last_section_number\n    view.setUint16(8, 0x0001, false); // program_number\n    view.setUint16(10, 0xE000 | (PMT_PID & 0x1FFF), false); // reserved=111, program_map_PID\n    view.setUint32(12, computeMpegTsCrc32(PAT_SECTION.subarray(0, 12)), false); // CRC_32\n}\nconst buildPmt = (trackDatas) => {\n    const sectionLength = 9 + trackDatas.length * 5 + 4;\n    const section = new Uint8Array(3 + sectionLength - 4);\n    const view = toDataView(section);\n    section[0] = 0x02; // table_id\n    // section_syntax_indicator=1, '0', reserved=11, section_length\n    view.setUint16(1, 0xB000 | (sectionLength & 0x0FFF), false);\n    view.setUint16(3, 0x0001, false); // program_number\n    section[5] = 0xC1; // reserved=11, version_number=0, current_next_indicator=1\n    section[6] = 0x00; // section_number\n    section[7] = 0x00; // last_section_number\n    view.setUint16(8, 0xE000 | 0x1FFF, false); // reserved=111, PCR_PID=0x1FFF (none)\n    view.setUint16(10, 0xF000, false); // reserved=1111, program_info_length=0\n    let offset = 12;\n    for (const trackData of trackDatas) {\n        section[offset++] = trackData.streamType; // stream_type\n        view.setUint16(offset, 0xE000 | (trackData.pid & 0x1FFF), false); // reserved=111, elementary_PID\n        offset += 2;\n        view.setUint16(offset, 0xF000, false); // reserved=1111, ES_info_length=0\n        offset += 2;\n    }\n    const crc = computeMpegTsCrc32(section);\n    const result = new Uint8Array(section.length + 4);\n    result.set(section, 0);\n    toDataView(result).setUint32(section.length, crc, false); // CRC_32\n    return result;\n};\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nexport class RiffWriter {\n    constructor(writer) {\n        this.writer = writer;\n        this.helper = new Uint8Array(8);\n        this.helperView = new DataView(this.helper.buffer);\n    }\n    writeU16(value) {\n        this.helperView.setUint16(0, value, true);\n        this.writer.write(this.helper.subarray(0, 2));\n    }\n    writeU32(value) {\n        this.helperView.setUint32(0, value, true);\n        this.writer.write(this.helper.subarray(0, 4));\n    }\n    writeU64(value) {\n        this.helperView.setUint32(0, value, true);\n        this.helperView.setUint32(4, Math.floor(value / 2 ** 32), true);\n        this.writer.write(this.helper);\n    }\n    writeAscii(text) {\n        this.writer.write(new TextEncoder().encode(text));\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { Muxer } from '../muxer.js';\nimport { parsePcmCodec, validateAudioChunkMetadata } from '../codec.js';\nimport { WaveFormat } from './wave-demuxer.js';\nimport { RiffWriter } from './riff-writer.js';\nimport { assert, assertNever, isIso88591Compatible, keyValueIterator } from '../misc.js';\nimport { metadataTagsAreEmpty } from '../metadata.js';\nimport { Id3V2Writer } from '../id3.js';\nexport class WaveMuxer extends Muxer {\n    constructor(output, format) {\n        super(output);\n        this.headerWritten = false;\n        this.dataSize = 0;\n        this.sampleRate = null;\n        this.sampleCount = 0;\n        this.riffSizePos = null;\n        this.dataSizePos = null;\n        this.ds64RiffSizePos = null;\n        this.ds64DataSizePos = null;\n        this.ds64SampleCountPos = null;\n        this.format = format;\n        this.writer = output._writer;\n        this.riffWriter = new RiffWriter(output._writer);\n        this.isRf64 = !!format._options.large;\n    }\n    async start() {\n        // Nothing needed here - we'll write the header with the first sample\n    }\n    async getMimeType() {\n        return 'audio/wav';\n    }\n    async addEncodedVideoPacket() {\n        throw new Error('WAVE does not support video.');\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n        const release = await this.mutex.acquire();\n        try {\n            if (!this.headerWritten) {\n                validateAudioChunkMetadata(meta);\n                assert(meta);\n                assert(meta.decoderConfig);\n                this.writeHeader(track, meta.decoderConfig);\n                this.sampleRate = meta.decoderConfig.sampleRate;\n                this.headerWritten = true;\n            }\n            this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === 'key');\n            if (!this.isRf64 && this.writer.getPos() + packet.data.byteLength >= 2 ** 32) {\n                throw new Error('Adding more audio data would exceed the maximum RIFF size of 4 GiB. To write larger files, use'\n                    + ' RF64 by setting `large: true` in the WavOutputFormatOptions.');\n            }\n            this.writer.write(packet.data);\n            this.dataSize += packet.data.byteLength;\n            this.sampleCount += Math.round(packet.duration * this.sampleRate);\n            await this.writer.flush();\n        }\n        finally {\n            release();\n        }\n    }\n    async addSubtitleCue() {\n        throw new Error('WAVE does not support subtitles.');\n    }\n    writeHeader(track, config) {\n        if (this.format._options.onHeader) {\n            this.writer.startTrackingWrites();\n        }\n        let format;\n        const codec = track.source._codec;\n        const pcmInfo = parsePcmCodec(codec);\n        if (pcmInfo.dataType === 'ulaw') {\n            format = WaveFormat.MULAW;\n        }\n        else if (pcmInfo.dataType === 'alaw') {\n            format = WaveFormat.ALAW;\n        }\n        else if (pcmInfo.dataType === 'float') {\n            format = WaveFormat.IEEE_FLOAT;\n        }\n        else {\n            format = WaveFormat.PCM;\n        }\n        const channels = config.numberOfChannels;\n        const sampleRate = config.sampleRate;\n        const blockSize = pcmInfo.sampleSize * channels;\n        // RIFF header\n        this.riffWriter.writeAscii(this.isRf64 ? 'RF64' : 'RIFF');\n        if (this.isRf64) {\n            this.riffWriter.writeU32(0xffffffff); // Not used in RF64\n        }\n        else {\n            this.riffSizePos = this.writer.getPos();\n            this.riffWriter.writeU32(0); // File size placeholder\n        }\n        this.riffWriter.writeAscii('WAVE');\n        if (this.isRf64) {\n            this.riffWriter.writeAscii('ds64');\n            this.riffWriter.writeU32(28); // Chunk size\n            this.ds64RiffSizePos = this.writer.getPos();\n            this.riffWriter.writeU64(0); // RIFF size placeholder\n            this.ds64DataSizePos = this.writer.getPos();\n            this.riffWriter.writeU64(0); // Data size placeholder\n            this.ds64SampleCountPos = this.writer.getPos();\n            this.riffWriter.writeU64(0); // Sample count placeholder\n            this.riffWriter.writeU32(0); // Table length\n            // Empty table\n        }\n        // fmt chunk\n        this.riffWriter.writeAscii('fmt ');\n        this.riffWriter.writeU32(16); // Chunk size\n        this.riffWriter.writeU16(format);\n        this.riffWriter.writeU16(channels);\n        this.riffWriter.writeU32(sampleRate);\n        this.riffWriter.writeU32(sampleRate * blockSize); // Bytes per second\n        this.riffWriter.writeU16(blockSize);\n        this.riffWriter.writeU16(8 * pcmInfo.sampleSize);\n        // Metadata tags\n        if (!metadataTagsAreEmpty(this.output._metadataTags)) {\n            const metadataFormat = this.format._options.metadataFormat ?? 'info';\n            if (metadataFormat === 'info') {\n                this.writeInfoChunk(this.output._metadataTags);\n            }\n            else if (metadataFormat === 'id3') {\n                this.writeId3Chunk(this.output._metadataTags);\n            }\n            else {\n                assertNever(metadataFormat);\n            }\n        }\n        // data chunk\n        this.riffWriter.writeAscii('data');\n        if (this.isRf64) {\n            this.riffWriter.writeU32(0xffffffff); // Not used in RF64\n        }\n        else {\n            this.dataSizePos = this.writer.getPos();\n            this.riffWriter.writeU32(0); // Data size placeholder\n        }\n        if (this.format._options.onHeader) {\n            const { data, start } = this.writer.stopTrackingWrites();\n            this.format._options.onHeader(data, start);\n        }\n    }\n    writeInfoChunk(metadata) {\n        const startPos = this.writer.getPos();\n        this.riffWriter.writeAscii('LIST');\n        this.riffWriter.writeU32(0); // Size placeholder\n        this.riffWriter.writeAscii('INFO');\n        const writtenTags = new Set();\n        const writeInfoTag = (tag, value) => {\n            if (!isIso88591Compatible(value)) {\n                // No Unicode supported here\n                console.warn(`Didn't write tag '${tag}' because '${value}' is not ISO 8859-1-compatible.`);\n                return;\n            }\n            const size = value.length + 1; // +1 for null terminator\n            const bytes = new Uint8Array(size);\n            for (let i = 0; i < value.length; i++) {\n                bytes[i] = value.charCodeAt(i);\n            }\n            this.riffWriter.writeAscii(tag);\n            this.riffWriter.writeU32(size);\n            this.writer.write(bytes);\n            // Add padding byte if size is odd\n            if (size & 1) {\n                this.writer.write(new Uint8Array(1));\n            }\n            writtenTags.add(tag);\n        };\n        for (const { key, value } of keyValueIterator(metadata)) {\n            switch (key) {\n                case 'title':\n                    {\n                        writeInfoTag('INAM', value);\n                        writtenTags.add('INAM');\n                    }\n                    ;\n                    break;\n                case 'artist':\n                    {\n                        writeInfoTag('IART', value);\n                        writtenTags.add('IART');\n                    }\n                    ;\n                    break;\n                case 'album':\n                    {\n                        writeInfoTag('IPRD', value);\n                        writtenTags.add('IPRD');\n                    }\n                    ;\n                    break;\n                case 'trackNumber':\n                    {\n                        const string = metadata.tracksTotal !== undefined\n                            ? `${value}/${metadata.tracksTotal}`\n                            : value.toString();\n                        writeInfoTag('ITRK', string);\n                        writtenTags.add('ITRK');\n                    }\n                    ;\n                    break;\n                case 'genre':\n                    {\n                        writeInfoTag('IGNR', value);\n                        writtenTags.add('IGNR');\n                    }\n                    ;\n                    break;\n                case 'date':\n                    {\n                        writeInfoTag('ICRD', value.toISOString().slice(0, 10));\n                        writtenTags.add('ICRD');\n                    }\n                    ;\n                    break;\n                case 'comment':\n                    {\n                        writeInfoTag('ICMT', value);\n                        writtenTags.add('ICMT');\n                    }\n                    ;\n                    break;\n                case 'albumArtist':\n                case 'discNumber':\n                case 'tracksTotal':\n                case 'discsTotal':\n                case 'description':\n                case 'lyrics':\n                case 'images':\n                    {\n                        // Not supported in RIFF INFO\n                    }\n                    ;\n                    break;\n                case 'raw':\n                    {\n                        // Handled later\n                    }\n                    ;\n                    break;\n                default: assertNever(key);\n            }\n        }\n        if (metadata.raw) {\n            for (const key in metadata.raw) {\n                const value = metadata.raw[key];\n                if (value == null || key.length !== 4 || writtenTags.has(key)) {\n                    continue;\n                }\n                if (typeof value === 'string') {\n                    writeInfoTag(key, value);\n                }\n            }\n        }\n        const endPos = this.writer.getPos();\n        const chunkSize = endPos - startPos - 8;\n        this.writer.seek(startPos + 4);\n        this.riffWriter.writeU32(chunkSize);\n        this.writer.seek(endPos);\n        // Add padding byte if chunk size is odd\n        if (chunkSize & 1) {\n            this.writer.write(new Uint8Array(1));\n        }\n    }\n    writeId3Chunk(metadata) {\n        const startPos = this.writer.getPos();\n        // Write RIFF chunk header\n        this.riffWriter.writeAscii('ID3 ');\n        this.riffWriter.writeU32(0); // Size placeholder\n        const id3Writer = new Id3V2Writer(this.writer);\n        const id3TagSize = id3Writer.writeId3V2Tag(metadata);\n        const endPos = this.writer.getPos();\n        // Update RIFF chunk size\n        this.writer.seek(startPos + 4);\n        this.riffWriter.writeU32(id3TagSize);\n        this.writer.seek(endPos);\n        // Add padding byte if chunk size is odd\n        if (id3TagSize & 1) {\n            this.writer.write(new Uint8Array(1));\n        }\n    }\n    async finalize() {\n        const release = await this.mutex.acquire();\n        const endPos = this.writer.getPos();\n        if (this.isRf64) {\n            // Write riff size\n            assert(this.ds64RiffSizePos !== null);\n            this.writer.seek(this.ds64RiffSizePos);\n            this.riffWriter.writeU64(endPos - 8);\n            // Write data size\n            assert(this.ds64DataSizePos !== null);\n            this.writer.seek(this.ds64DataSizePos);\n            this.riffWriter.writeU64(this.dataSize);\n            // Write sample count\n            assert(this.ds64SampleCountPos !== null);\n            this.writer.seek(this.ds64SampleCountPos);\n            this.riffWriter.writeU64(this.sampleCount);\n        }\n        else {\n            // Write file size\n            assert(this.riffSizePos !== null);\n            this.writer.seek(this.riffSizePos);\n            this.riffWriter.writeU32(endPos - 8);\n            // Write data chunk size\n            assert(this.dataSizePos !== null);\n            this.writer.seek(this.dataSizePos);\n            this.riffWriter.writeU32(this.dataSize);\n        }\n        this.writer.seek(endPos);\n        release();\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { AdtsMuxer } from './adts/adts-muxer.js';\nimport { AUDIO_CODECS, NON_PCM_AUDIO_CODECS, PCM_AUDIO_CODECS, SUBTITLE_CODECS, VIDEO_CODECS, } from './codec.js';\nimport { FlacMuxer } from './flac/flac-muxer.js';\nimport { IsobmffMuxer } from './isobmff/isobmff-muxer.js';\nimport { MatroskaMuxer } from './matroska/matroska-muxer.js';\nimport { Mp3Muxer } from './mp3/mp3-muxer.js';\nimport { OggMuxer } from './ogg/ogg-muxer.js';\nimport { MpegTsMuxer } from './mpeg-ts/mpeg-ts-muxer.js';\nimport { WaveMuxer } from './wave/wave-muxer.js';\n/**\n * Base class representing an output media file format.\n * @group Output formats\n * @public\n */\nexport class OutputFormat {\n    /** Returns a list of video codecs that this output format can contain. */\n    getSupportedVideoCodecs() {\n        return this.getSupportedCodecs()\n            .filter(codec => VIDEO_CODECS.includes(codec));\n    }\n    /** Returns a list of audio codecs that this output format can contain. */\n    getSupportedAudioCodecs() {\n        return this.getSupportedCodecs()\n            .filter(codec => AUDIO_CODECS.includes(codec));\n    }\n    /** Returns a list of subtitle codecs that this output format can contain. */\n    getSupportedSubtitleCodecs() {\n        return this.getSupportedCodecs()\n            .filter(codec => SUBTITLE_CODECS.includes(codec));\n    }\n    /** @internal */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    _codecUnsupportedHint(codec) {\n        return '';\n    }\n}\n/**\n * Format representing files compatible with the ISO base media file format (ISOBMFF), like MP4 or MOV files.\n * @group Output formats\n * @public\n */\nexport class IsobmffOutputFormat extends OutputFormat {\n    /** Internal constructor. */\n    constructor(options = {}) {\n        if (!options || typeof options !== 'object') {\n            throw new TypeError('options must be an object.');\n        }\n        if (options.fastStart !== undefined\n            && ![false, 'in-memory', 'reserve', 'fragmented'].includes(options.fastStart)) {\n            throw new TypeError('options.fastStart, when provided, must be false, \\'in-memory\\', \\'reserve\\', or \\'fragmented\\'.');\n        }\n        if (options.minimumFragmentDuration !== undefined\n            && (!Number.isFinite(options.minimumFragmentDuration) || options.minimumFragmentDuration < 0)) {\n            throw new TypeError('options.minimumFragmentDuration, when provided, must be a non-negative number.');\n        }\n        if (options.onFtyp !== undefined && typeof options.onFtyp !== 'function') {\n            throw new TypeError('options.onFtyp, when provided, must be a function.');\n        }\n        if (options.onMoov !== undefined && typeof options.onMoov !== 'function') {\n            throw new TypeError('options.onMoov, when provided, must be a function.');\n        }\n        if (options.onMdat !== undefined && typeof options.onMdat !== 'function') {\n            throw new TypeError('options.onMdat, when provided, must be a function.');\n        }\n        if (options.onMoof !== undefined && typeof options.onMoof !== 'function') {\n            throw new TypeError('options.onMoof, when provided, must be a function.');\n        }\n        if (options.metadataFormat !== undefined\n            && !['mdir', 'mdta', 'udta', 'auto'].includes(options.metadataFormat)) {\n            throw new TypeError('options.metadataFormat, when provided, must be either \\'auto\\', \\'mdir\\', \\'mdta\\', or \\'udta\\'.');\n        }\n        super();\n        this._options = options;\n    }\n    getSupportedTrackCounts() {\n        const max = 2 ** 32 - 1; // Have fun reaching this one\n        return {\n            video: { min: 0, max },\n            audio: { min: 0, max },\n            subtitle: { min: 0, max },\n            total: { min: 1, max },\n        };\n    }\n    get supportsVideoRotationMetadata() {\n        return true;\n    }\n    /** @internal */\n    _createMuxer(output) {\n        return new IsobmffMuxer(output, this);\n    }\n}\n/**\n * MPEG-4 Part 14 (MP4) file format. Supports most codecs.\n * @group Output formats\n * @public\n */\nexport class Mp4OutputFormat extends IsobmffOutputFormat {\n    /** Creates a new {@link Mp4OutputFormat} configured with the specified `options`. */\n    constructor(options) {\n        super(options);\n    }\n    /** @internal */\n    get _name() {\n        return 'MP4';\n    }\n    get fileExtension() {\n        return '.mp4';\n    }\n    get mimeType() {\n        return 'video/mp4';\n    }\n    getSupportedCodecs() {\n        return [\n            ...VIDEO_CODECS,\n            ...NON_PCM_AUDIO_CODECS,\n            // These are supported via ISO/IEC 23003-5\n            'pcm-s16',\n            'pcm-s16be',\n            'pcm-s24',\n            'pcm-s24be',\n            'pcm-s32',\n            'pcm-s32be',\n            'pcm-f32',\n            'pcm-f32be',\n            'pcm-f64',\n            'pcm-f64be',\n            ...SUBTITLE_CODECS,\n        ];\n    }\n    /** @internal */\n    _codecUnsupportedHint(codec) {\n        if (new MovOutputFormat().getSupportedCodecs().includes(codec)) {\n            return ' Switching to MOV will grant support for this codec.';\n        }\n        return '';\n    }\n}\n/**\n * QuickTime File Format (QTFF), often called MOV. Supports all video and audio codecs, but not subtitle codecs.\n * @group Output formats\n * @public\n */\nexport class MovOutputFormat extends IsobmffOutputFormat {\n    /** Creates a new {@link MovOutputFormat} configured with the specified `options`. */\n    constructor(options) {\n        super(options);\n    }\n    /** @internal */\n    get _name() {\n        return 'MOV';\n    }\n    get fileExtension() {\n        return '.mov';\n    }\n    get mimeType() {\n        return 'video/quicktime';\n    }\n    getSupportedCodecs() {\n        return [\n            ...VIDEO_CODECS,\n            ...AUDIO_CODECS,\n        ];\n    }\n    /** @internal */\n    _codecUnsupportedHint(codec) {\n        if (new Mp4OutputFormat().getSupportedCodecs().includes(codec)) {\n            return ' Switching to MP4 will grant support for this codec.';\n        }\n        return '';\n    }\n}\n/**\n * Matroska file format.\n *\n * Supports writing transparent video. For a video track to be marked as transparent, the first packet added must\n * contain alpha side data.\n *\n * @group Output formats\n * @public\n */\nexport class MkvOutputFormat extends OutputFormat {\n    /** Creates a new {@link MkvOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n        if (!options || typeof options !== 'object') {\n            throw new TypeError('options must be an object.');\n        }\n        if (options.appendOnly !== undefined && typeof options.appendOnly !== 'boolean') {\n            throw new TypeError('options.appendOnly, when provided, must be a boolean.');\n        }\n        if (options.minimumClusterDuration !== undefined\n            && (!Number.isFinite(options.minimumClusterDuration) || options.minimumClusterDuration < 0)) {\n            throw new TypeError('options.minimumClusterDuration, when provided, must be a non-negative number.');\n        }\n        if (options.onEbmlHeader !== undefined && typeof options.onEbmlHeader !== 'function') {\n            throw new TypeError('options.onEbmlHeader, when provided, must be a function.');\n        }\n        if (options.onSegmentHeader !== undefined && typeof options.onSegmentHeader !== 'function') {\n            throw new TypeError('options.onHeader, when provided, must be a function.');\n        }\n        if (options.onCluster !== undefined && typeof options.onCluster !== 'function') {\n            throw new TypeError('options.onCluster, when provided, must be a function.');\n        }\n        super();\n        this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n        return new MatroskaMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n        return 'Matroska';\n    }\n    getSupportedTrackCounts() {\n        const max = 127;\n        return {\n            video: { min: 0, max },\n            audio: { min: 0, max },\n            subtitle: { min: 0, max },\n            total: { min: 1, max },\n        };\n    }\n    get fileExtension() {\n        return '.mkv';\n    }\n    get mimeType() {\n        return 'video/x-matroska';\n    }\n    getSupportedCodecs() {\n        return [\n            ...VIDEO_CODECS,\n            ...NON_PCM_AUDIO_CODECS,\n            ...PCM_AUDIO_CODECS.filter(codec => !['pcm-s8', 'pcm-f32be', 'pcm-f64be', 'ulaw', 'alaw'].includes(codec)),\n            ...SUBTITLE_CODECS,\n        ];\n    }\n    get supportsVideoRotationMetadata() {\n        // While it technically does support it with ProjectionPoseRoll, many players appear to ignore this value\n        return false;\n    }\n}\n/**\n * WebM file format, based on Matroska.\n *\n * Supports writing transparent video. For a video track to be marked as transparent, the first packet added must\n * contain alpha side data.\n *\n * @group Output formats\n * @public\n */\nexport class WebMOutputFormat extends MkvOutputFormat {\n    /** Creates a new {@link WebMOutputFormat} configured with the specified `options`. */\n    constructor(options) {\n        super(options);\n    }\n    getSupportedCodecs() {\n        return [\n            ...VIDEO_CODECS.filter(codec => ['vp8', 'vp9', 'av1'].includes(codec)),\n            ...AUDIO_CODECS.filter(codec => ['opus', 'vorbis'].includes(codec)),\n            ...SUBTITLE_CODECS,\n        ];\n    }\n    /** @internal */\n    get _name() {\n        return 'WebM';\n    }\n    get fileExtension() {\n        return '.webm';\n    }\n    get mimeType() {\n        return 'video/webm';\n    }\n    /** @internal */\n    _codecUnsupportedHint(codec) {\n        if (new MkvOutputFormat().getSupportedCodecs().includes(codec)) {\n            return ' Switching to MKV will grant support for this codec.';\n        }\n        return '';\n    }\n}\n/**\n * MP3 file format.\n * @group Output formats\n * @public\n */\nexport class Mp3OutputFormat extends OutputFormat {\n    /** Creates a new {@link Mp3OutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n        if (!options || typeof options !== 'object') {\n            throw new TypeError('options must be an object.');\n        }\n        if (options.xingHeader !== undefined && typeof options.xingHeader !== 'boolean') {\n            throw new TypeError('options.xingHeader, when provided, must be a boolean.');\n        }\n        if (options.onXingFrame !== undefined && typeof options.onXingFrame !== 'function') {\n            throw new TypeError('options.onXingFrame, when provided, must be a function.');\n        }\n        super();\n        this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n        return new Mp3Muxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n        return 'MP3';\n    }\n    getSupportedTrackCounts() {\n        return {\n            video: { min: 0, max: 0 },\n            audio: { min: 1, max: 1 },\n            subtitle: { min: 0, max: 0 },\n            total: { min: 1, max: 1 },\n        };\n    }\n    get fileExtension() {\n        return '.mp3';\n    }\n    get mimeType() {\n        return 'audio/mpeg';\n    }\n    getSupportedCodecs() {\n        return ['mp3'];\n    }\n    get supportsVideoRotationMetadata() {\n        return false;\n    }\n}\n/**\n * WAVE file format, based on RIFF.\n * @group Output formats\n * @public\n */\nexport class WavOutputFormat extends OutputFormat {\n    /** Creates a new {@link WavOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n        if (!options || typeof options !== 'object') {\n            throw new TypeError('options must be an object.');\n        }\n        if (options.large !== undefined && typeof options.large !== 'boolean') {\n            throw new TypeError('options.large, when provided, must be a boolean.');\n        }\n        if (options.metadataFormat !== undefined && !['info', 'id3'].includes(options.metadataFormat)) {\n            throw new TypeError('options.metadataFormat, when provided, must be either \\'info\\' or \\'id3\\'.');\n        }\n        if (options.onHeader !== undefined && typeof options.onHeader !== 'function') {\n            throw new TypeError('options.onHeader, when provided, must be a function.');\n        }\n        super();\n        this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n        return new WaveMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n        return 'WAVE';\n    }\n    getSupportedTrackCounts() {\n        return {\n            video: { min: 0, max: 0 },\n            audio: { min: 1, max: 1 },\n            subtitle: { min: 0, max: 0 },\n            total: { min: 1, max: 1 },\n        };\n    }\n    get fileExtension() {\n        return '.wav';\n    }\n    get mimeType() {\n        return 'audio/wav';\n    }\n    getSupportedCodecs() {\n        return [\n            ...PCM_AUDIO_CODECS.filter(codec => ['pcm-s16', 'pcm-s24', 'pcm-s32', 'pcm-f32', 'pcm-u8', 'ulaw', 'alaw'].includes(codec)),\n        ];\n    }\n    get supportsVideoRotationMetadata() {\n        return false;\n    }\n}\n/**\n * Ogg file format.\n * @group Output formats\n * @public\n */\nexport class OggOutputFormat extends OutputFormat {\n    /** Creates a new {@link OggOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n        if (!options || typeof options !== 'object') {\n            throw new TypeError('options must be an object.');\n        }\n        if (options.maximumPageDuration !== undefined\n            && (!Number.isFinite(options.maximumPageDuration) || options.maximumPageDuration <= 0)) {\n            throw new TypeError('options.maximumPageDuration, when provided, must be a positive number.');\n        }\n        if (options.onPage !== undefined && typeof options.onPage !== 'function') {\n            throw new TypeError('options.onPage, when provided, must be a function.');\n        }\n        super();\n        this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n        return new OggMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n        return 'Ogg';\n    }\n    getSupportedTrackCounts() {\n        const max = 2 ** 32; // Have fun reaching this one\n        return {\n            video: { min: 0, max: 0 },\n            audio: { min: 0, max },\n            subtitle: { min: 0, max: 0 },\n            total: { min: 1, max },\n        };\n    }\n    get fileExtension() {\n        return '.ogg';\n    }\n    get mimeType() {\n        return 'application/ogg';\n    }\n    getSupportedCodecs() {\n        return [\n            ...AUDIO_CODECS.filter(codec => ['vorbis', 'opus'].includes(codec)),\n        ];\n    }\n    get supportsVideoRotationMetadata() {\n        return false;\n    }\n}\n/**\n * ADTS file format.\n * @group Output formats\n * @public\n */\nexport class AdtsOutputFormat extends OutputFormat {\n    /** Creates a new {@link AdtsOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n        if (!options || typeof options !== 'object') {\n            throw new TypeError('options must be an object.');\n        }\n        if (options.onFrame !== undefined && typeof options.onFrame !== 'function') {\n            throw new TypeError('options.onFrame, when provided, must be a function.');\n        }\n        super();\n        this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n        return new AdtsMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n        return 'ADTS';\n    }\n    getSupportedTrackCounts() {\n        return {\n            video: { min: 0, max: 0 },\n            audio: { min: 1, max: 1 },\n            subtitle: { min: 0, max: 0 },\n            total: { min: 1, max: 1 },\n        };\n    }\n    get fileExtension() {\n        return '.aac';\n    }\n    get mimeType() {\n        return 'audio/aac';\n    }\n    getSupportedCodecs() {\n        return ['aac'];\n    }\n    get supportsVideoRotationMetadata() {\n        return false;\n    }\n}\n/**\n * FLAC file format.\n * @group Output formats\n * @public\n */\nexport class FlacOutputFormat extends OutputFormat {\n    /** Creates a new {@link FlacOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n        if (!options || typeof options !== 'object') {\n            throw new TypeError('options must be an object.');\n        }\n        super();\n        this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n        return new FlacMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n        return 'FLAC';\n    }\n    getSupportedTrackCounts() {\n        return {\n            video: { min: 0, max: 0 },\n            audio: { min: 1, max: 1 },\n            subtitle: { min: 0, max: 0 },\n            total: { min: 1, max: 1 },\n        };\n    }\n    get fileExtension() {\n        return '.flac';\n    }\n    get mimeType() {\n        return 'audio/flac';\n    }\n    getSupportedCodecs() {\n        return ['flac'];\n    }\n    get supportsVideoRotationMetadata() {\n        return false;\n    }\n}\n/**\n * MPEG Transport Stream file format.\n * @group Output formats\n * @public\n */\nexport class MpegTsOutputFormat extends OutputFormat {\n    /** Creates a new {@link MpegTsOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n        if (!options || typeof options !== 'object') {\n            throw new TypeError('options must be an object.');\n        }\n        if (options.onPacket !== undefined && typeof options.onPacket !== 'function') {\n            throw new TypeError('options.onPacket, when provided, must be a function.');\n        }\n        super();\n        this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n        return new MpegTsMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n        return 'MPEG-TS';\n    }\n    getSupportedTrackCounts() {\n        const maxVideo = 16; // Stream IDs 0xE0-0xEF\n        const maxAudio = 32;\n        const maxTotal = maxVideo + maxAudio;\n        return {\n            video: { min: 0, max: maxVideo },\n            audio: { min: 0, max: maxAudio },\n            subtitle: { min: 0, max: 0 },\n            total: { min: 1, max: maxTotal },\n        };\n    }\n    get fileExtension() {\n        return '.ts';\n    }\n    get mimeType() {\n        return 'video/MP2T';\n    }\n    getSupportedCodecs() {\n        return [\n            ...VIDEO_CODECS.filter(codec => ['avc', 'hevc'].includes(codec)),\n            ...AUDIO_CODECS.filter(codec => ['aac', 'mp3'].includes(codec)),\n        ];\n    }\n    get supportsVideoRotationMetadata() {\n        return false;\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { AUDIO_CODECS, buildAudioCodecString, buildVideoCodecString, getAudioEncoderConfigExtension, getVideoEncoderConfigExtension, inferCodecFromCodecString, PCM_AUDIO_CODECS, SUBTITLE_CODECS, VIDEO_CODECS, } from './codec.js';\nimport { customAudioEncoders, customVideoEncoders } from './custom-coder.js';\nimport { isFirefox } from './misc.js';\nexport const validateVideoEncodingConfig = (config) => {\n    if (!config || typeof config !== 'object') {\n        throw new TypeError('Encoding config must be an object.');\n    }\n    if (!VIDEO_CODECS.includes(config.codec)) {\n        throw new TypeError(`Invalid video codec '${config.codec}'. Must be one of: ${VIDEO_CODECS.join(', ')}.`);\n    }\n    if (!(config.bitrate instanceof Quality) && (!Number.isInteger(config.bitrate) || config.bitrate <= 0)) {\n        throw new TypeError('config.bitrate must be a positive integer or a quality.');\n    }\n    if (config.keyFrameInterval !== undefined\n        && (!Number.isFinite(config.keyFrameInterval) || config.keyFrameInterval < 0)) {\n        throw new TypeError('config.keyFrameInterval, when provided, must be a non-negative number.');\n    }\n    if (config.sizeChangeBehavior !== undefined\n        && !['deny', 'passThrough', 'fill', 'contain', 'cover'].includes(config.sizeChangeBehavior)) {\n        throw new TypeError('config.sizeChangeBehavior, when provided, must be \\'deny\\', \\'passThrough\\', \\'fill\\', \\'contain\\''\n            + ' or \\'cover\\'.');\n    }\n    if (config.onEncodedPacket !== undefined && typeof config.onEncodedPacket !== 'function') {\n        throw new TypeError('config.onEncodedChunk, when provided, must be a function.');\n    }\n    if (config.onEncoderConfig !== undefined && typeof config.onEncoderConfig !== 'function') {\n        throw new TypeError('config.onEncoderConfig, when provided, must be a function.');\n    }\n    validateVideoEncodingAdditionalOptions(config.codec, config);\n};\nexport const validateVideoEncodingAdditionalOptions = (codec, options) => {\n    if (!options || typeof options !== 'object') {\n        throw new TypeError('Encoding options must be an object.');\n    }\n    if (options.alpha !== undefined && !['discard', 'keep'].includes(options.alpha)) {\n        throw new TypeError('options.alpha, when provided, must be \\'discard\\' or \\'keep\\'.');\n    }\n    if (options.bitrateMode !== undefined && !['constant', 'variable'].includes(options.bitrateMode)) {\n        throw new TypeError('bitrateMode, when provided, must be \\'constant\\' or \\'variable\\'.');\n    }\n    if (options.latencyMode !== undefined && !['quality', 'realtime'].includes(options.latencyMode)) {\n        throw new TypeError('latencyMode, when provided, must be \\'quality\\' or \\'realtime\\'.');\n    }\n    if (options.fullCodecString !== undefined && typeof options.fullCodecString !== 'string') {\n        throw new TypeError('fullCodecString, when provided, must be a string.');\n    }\n    if (options.fullCodecString !== undefined && inferCodecFromCodecString(options.fullCodecString) !== codec) {\n        throw new TypeError(`fullCodecString, when provided, must be a string that matches the specified codec (${codec}).`);\n    }\n    if (options.hardwareAcceleration !== undefined\n        && !['no-preference', 'prefer-hardware', 'prefer-software'].includes(options.hardwareAcceleration)) {\n        throw new TypeError('hardwareAcceleration, when provided, must be \\'no-preference\\', \\'prefer-hardware\\' or'\n            + ' \\'prefer-software\\'.');\n    }\n    if (options.scalabilityMode !== undefined && typeof options.scalabilityMode !== 'string') {\n        throw new TypeError('scalabilityMode, when provided, must be a string.');\n    }\n    if (options.contentHint !== undefined && typeof options.contentHint !== 'string') {\n        throw new TypeError('contentHint, when provided, must be a string.');\n    }\n};\nexport const buildVideoEncoderConfig = (options) => {\n    const resolvedBitrate = options.bitrate instanceof Quality\n        ? options.bitrate._toVideoBitrate(options.codec, options.width, options.height)\n        : options.bitrate;\n    return {\n        codec: options.fullCodecString ?? buildVideoCodecString(options.codec, options.width, options.height, resolvedBitrate),\n        width: options.width,\n        height: options.height,\n        bitrate: resolvedBitrate,\n        bitrateMode: options.bitrateMode,\n        alpha: options.alpha ?? 'discard',\n        framerate: options.framerate,\n        latencyMode: options.latencyMode,\n        hardwareAcceleration: options.hardwareAcceleration,\n        scalabilityMode: options.scalabilityMode,\n        contentHint: options.contentHint,\n        ...getVideoEncoderConfigExtension(options.codec),\n    };\n};\nexport const validateAudioEncodingConfig = (config) => {\n    if (!config || typeof config !== 'object') {\n        throw new TypeError('Encoding config must be an object.');\n    }\n    if (!AUDIO_CODECS.includes(config.codec)) {\n        throw new TypeError(`Invalid audio codec '${config.codec}'. Must be one of: ${AUDIO_CODECS.join(', ')}.`);\n    }\n    if (config.bitrate === undefined\n        && (!PCM_AUDIO_CODECS.includes(config.codec) || config.codec === 'flac')) {\n        throw new TypeError('config.bitrate must be provided for compressed audio codecs.');\n    }\n    if (config.bitrate !== undefined\n        && !(config.bitrate instanceof Quality)\n        && (!Number.isInteger(config.bitrate) || config.bitrate <= 0)) {\n        throw new TypeError('config.bitrate, when provided, must be a positive integer or a quality.');\n    }\n    if (config.onEncodedPacket !== undefined && typeof config.onEncodedPacket !== 'function') {\n        throw new TypeError('config.onEncodedChunk, when provided, must be a function.');\n    }\n    if (config.onEncoderConfig !== undefined && typeof config.onEncoderConfig !== 'function') {\n        throw new TypeError('config.onEncoderConfig, when provided, must be a function.');\n    }\n    validateAudioEncodingAdditionalOptions(config.codec, config);\n};\nexport const validateAudioEncodingAdditionalOptions = (codec, options) => {\n    if (!options || typeof options !== 'object') {\n        throw new TypeError('Encoding options must be an object.');\n    }\n    if (options.bitrateMode !== undefined && !['constant', 'variable'].includes(options.bitrateMode)) {\n        throw new TypeError('bitrateMode, when provided, must be \\'constant\\' or \\'variable\\'.');\n    }\n    if (options.fullCodecString !== undefined && typeof options.fullCodecString !== 'string') {\n        throw new TypeError('fullCodecString, when provided, must be a string.');\n    }\n    if (options.fullCodecString !== undefined && inferCodecFromCodecString(options.fullCodecString) !== codec) {\n        throw new TypeError(`fullCodecString, when provided, must be a string that matches the specified codec (${codec}).`);\n    }\n};\nexport const buildAudioEncoderConfig = (options) => {\n    const resolvedBitrate = options.bitrate instanceof Quality\n        ? options.bitrate._toAudioBitrate(options.codec)\n        : options.bitrate;\n    return {\n        codec: options.fullCodecString ?? buildAudioCodecString(options.codec, options.numberOfChannels, options.sampleRate),\n        numberOfChannels: options.numberOfChannels,\n        sampleRate: options.sampleRate,\n        bitrate: resolvedBitrate,\n        bitrateMode: options.bitrateMode,\n        ...getAudioEncoderConfigExtension(options.codec),\n    };\n};\n/**\n * Represents a subjective media quality level.\n * @group Encoding\n * @public\n */\nexport class Quality {\n    /** @internal */\n    constructor(factor) {\n        this._factor = factor;\n    }\n    /** @internal */\n    _toVideoBitrate(codec, width, height) {\n        const pixels = width * height;\n        const codecEfficiencyFactors = {\n            avc: 1.0, // H.264/AVC (baseline)\n            hevc: 0.6, // H.265/HEVC (~40% more efficient than AVC)\n            vp9: 0.6, // Similar to HEVC\n            av1: 0.4, // ~60% more efficient than AVC\n            vp8: 1.2, // Slightly less efficient than AVC\n        };\n        const referencePixels = 1920 * 1080;\n        const referenceBitrate = 3000000;\n        const scaleFactor = Math.pow(pixels / referencePixels, 0.95); // Slight non-linear scaling\n        const baseBitrate = referenceBitrate * scaleFactor;\n        const codecAdjustedBitrate = baseBitrate * codecEfficiencyFactors[codec];\n        const finalBitrate = codecAdjustedBitrate * this._factor;\n        return Math.ceil(finalBitrate / 1000) * 1000;\n    }\n    /** @internal */\n    _toAudioBitrate(codec) {\n        if (PCM_AUDIO_CODECS.includes(codec) || codec === 'flac') {\n            return undefined;\n        }\n        const baseRates = {\n            aac: 128000, // 128kbps base for AAC\n            opus: 64000, // 64kbps base for Opus\n            mp3: 160000, // 160kbps base for MP3\n            vorbis: 64000, // 64kbps base for Vorbis\n        };\n        const baseBitrate = baseRates[codec];\n        if (!baseBitrate) {\n            throw new Error(`Unhandled codec: ${codec}`);\n        }\n        let finalBitrate = baseBitrate * this._factor;\n        if (codec === 'aac') {\n            // AAC only works with specific bitrates, let's find the closest\n            const validRates = [96000, 128000, 160000, 192000];\n            finalBitrate = validRates.reduce((prev, curr) => Math.abs(curr - finalBitrate) < Math.abs(prev - finalBitrate) ? curr : prev);\n        }\n        else if (codec === 'opus' || codec === 'vorbis') {\n            finalBitrate = Math.max(6000, finalBitrate);\n        }\n        else if (codec === 'mp3') {\n            const validRates = [\n                8000, 16000, 24000, 32000, 40000, 48000, 64000, 80000,\n                96000, 112000, 128000, 160000, 192000, 224000, 256000, 320000,\n            ];\n            finalBitrate = validRates.reduce((prev, curr) => Math.abs(curr - finalBitrate) < Math.abs(prev - finalBitrate) ? curr : prev);\n        }\n        return Math.round(finalBitrate / 1000) * 1000;\n    }\n}\n/**\n * Represents a very low media quality.\n * @group Encoding\n * @public\n */\nexport const QUALITY_VERY_LOW = /* #__PURE__ */ new Quality(0.3);\n/**\n * Represents a low media quality.\n * @group Encoding\n * @public\n */\nexport const QUALITY_LOW = /* #__PURE__ */ new Quality(0.6);\n/**\n * Represents a medium media quality.\n * @group Encoding\n * @public\n */\nexport const QUALITY_MEDIUM = /* #__PURE__ */ new Quality(1);\n/**\n * Represents a high media quality.\n * @group Encoding\n * @public\n */\nexport const QUALITY_HIGH = /* #__PURE__ */ new Quality(2);\n/**\n * Represents a very high media quality.\n * @group Encoding\n * @public\n */\nexport const QUALITY_VERY_HIGH = /* #__PURE__ */ new Quality(4);\n/**\n * Checks if the browser is able to encode the given codec.\n * @group Encoding\n * @public\n */\nexport const canEncode = (codec) => {\n    if (VIDEO_CODECS.includes(codec)) {\n        return canEncodeVideo(codec);\n    }\n    else if (AUDIO_CODECS.includes(codec)) {\n        return canEncodeAudio(codec);\n    }\n    else if (SUBTITLE_CODECS.includes(codec)) {\n        return canEncodeSubtitles(codec);\n    }\n    throw new TypeError(`Unknown codec '${codec}'.`);\n};\n/**\n * Checks if the browser is able to encode the given video codec with the given parameters.\n * @group Encoding\n * @public\n */\nexport const canEncodeVideo = async (codec, options = {}) => {\n    const { width = 1280, height = 720, bitrate = 1e6, ...restOptions } = options;\n    if (!VIDEO_CODECS.includes(codec)) {\n        return false;\n    }\n    if (!Number.isInteger(width) || width <= 0) {\n        throw new TypeError('width must be a positive integer.');\n    }\n    if (!Number.isInteger(height) || height <= 0) {\n        throw new TypeError('height must be a positive integer.');\n    }\n    if (!(bitrate instanceof Quality) && (!Number.isInteger(bitrate) || bitrate <= 0)) {\n        throw new TypeError('bitrate must be a positive integer or a quality.');\n    }\n    validateVideoEncodingAdditionalOptions(codec, restOptions);\n    let encoderConfig = null;\n    if (customVideoEncoders.length > 0) {\n        encoderConfig ??= buildVideoEncoderConfig({\n            codec,\n            width,\n            height,\n            bitrate,\n            framerate: undefined,\n            ...restOptions,\n        });\n        if (customVideoEncoders.some(x => x.supports(codec, encoderConfig))) {\n            // There's a custom encoder\n            return true;\n        }\n    }\n    if (typeof VideoEncoder === 'undefined') {\n        return false;\n    }\n    const hasOddDimension = width % 2 === 1 || height % 2 === 1;\n    if (hasOddDimension\n        && (codec === 'avc' || codec === 'hevc')) {\n        // Disallow odd dimensions for certain codecs\n        return false;\n    }\n    encoderConfig ??= buildVideoEncoderConfig({\n        codec,\n        width,\n        height,\n        bitrate,\n        framerate: undefined,\n        ...restOptions,\n        alpha: 'discard', // Since we handle alpha ourselves\n    });\n    const support = await VideoEncoder.isConfigSupported(encoderConfig);\n    if (!support.supported) {\n        return false;\n    }\n    if (isFirefox()) {\n        // isConfigSupported on Firefox appears to unreliably indicate if encoding will actually succeed. Therefore, we\n        // just try encoding a frame to see if it actually works.\n        // https://github.com/Vanilagy/mediabunny/issues/222\n        // eslint-disable-next-line @typescript-eslint/no-misused-promises, no-async-promise-executor\n        return new Promise(async (resolve) => {\n            try {\n                const encoder = new VideoEncoder({\n                    output: () => { },\n                    error: () => resolve(false),\n                });\n                encoder.configure(encoderConfig);\n                const frameData = new Uint8Array(width * height * 4);\n                const frame = new VideoFrame(frameData, {\n                    format: 'RGBA',\n                    codedWidth: width,\n                    codedHeight: height,\n                    timestamp: 0,\n                });\n                encoder.encode(frame);\n                frame.close();\n                await encoder.flush();\n                resolve(true);\n            }\n            catch {\n                resolve(false);\n            }\n        });\n    }\n    else {\n        return true;\n    }\n};\n/**\n * Checks if the browser is able to encode the given audio codec with the given parameters.\n * @group Encoding\n * @public\n */\nexport const canEncodeAudio = async (codec, options = {}) => {\n    const { numberOfChannels = 2, sampleRate = 48000, bitrate = 128e3, ...restOptions } = options;\n    if (!AUDIO_CODECS.includes(codec)) {\n        return false;\n    }\n    if (!Number.isInteger(numberOfChannels) || numberOfChannels <= 0) {\n        throw new TypeError('numberOfChannels must be a positive integer.');\n    }\n    if (!Number.isInteger(sampleRate) || sampleRate <= 0) {\n        throw new TypeError('sampleRate must be a positive integer.');\n    }\n    if (!(bitrate instanceof Quality) && (!Number.isInteger(bitrate) || bitrate <= 0)) {\n        throw new TypeError('bitrate must be a positive integer.');\n    }\n    validateAudioEncodingAdditionalOptions(codec, restOptions);\n    let encoderConfig = null;\n    if (customAudioEncoders.length > 0) {\n        encoderConfig ??= buildAudioEncoderConfig({\n            codec,\n            numberOfChannels,\n            sampleRate,\n            bitrate,\n            ...restOptions,\n        });\n        if (customAudioEncoders.some(x => x.supports(codec, encoderConfig))) {\n            // There's a custom encoder\n            return true;\n        }\n    }\n    if (PCM_AUDIO_CODECS.includes(codec)) {\n        return true; // Because we encode these ourselves\n    }\n    if (typeof AudioEncoder === 'undefined') {\n        return false;\n    }\n    encoderConfig ??= buildAudioEncoderConfig({\n        codec,\n        numberOfChannels,\n        sampleRate,\n        bitrate,\n        ...restOptions,\n    });\n    const support = await AudioEncoder.isConfigSupported(encoderConfig);\n    return support.supported === true;\n};\n/**\n * Checks if the browser is able to encode the given subtitle codec.\n * @group Encoding\n * @public\n */\nexport const canEncodeSubtitles = async (codec) => {\n    if (!SUBTITLE_CODECS.includes(codec)) {\n        return false;\n    }\n    return true;\n};\n/**\n * Returns the list of all media codecs that can be encoded by the browser.\n * @group Encoding\n * @public\n */\nexport const getEncodableCodecs = async () => {\n    const [videoCodecs, audioCodecs, subtitleCodecs] = await Promise.all([\n        getEncodableVideoCodecs(),\n        getEncodableAudioCodecs(),\n        getEncodableSubtitleCodecs(),\n    ]);\n    return [...videoCodecs, ...audioCodecs, ...subtitleCodecs];\n};\n/**\n * Returns the list of all video codecs that can be encoded by the browser.\n * @group Encoding\n * @public\n */\nexport const getEncodableVideoCodecs = async (checkedCodecs = VIDEO_CODECS, options) => {\n    const bools = await Promise.all(checkedCodecs.map(codec => canEncodeVideo(codec, options)));\n    return checkedCodecs.filter((_, i) => bools[i]);\n};\n/**\n * Returns the list of all audio codecs that can be encoded by the browser.\n * @group Encoding\n * @public\n */\nexport const getEncodableAudioCodecs = async (checkedCodecs = AUDIO_CODECS, options) => {\n    const bools = await Promise.all(checkedCodecs.map(codec => canEncodeAudio(codec, options)));\n    return checkedCodecs.filter((_, i) => bools[i]);\n};\n/**\n * Returns the list of all subtitle codecs that can be encoded by the browser.\n * @group Encoding\n * @public\n */\nexport const getEncodableSubtitleCodecs = async (checkedCodecs = SUBTITLE_CODECS) => {\n    const bools = await Promise.all(checkedCodecs.map(canEncodeSubtitles));\n    return checkedCodecs.filter((_, i) => bools[i]);\n};\n/**\n * Returns the first video codec from the given list that can be encoded by the browser.\n * @group Encoding\n * @public\n */\nexport const getFirstEncodableVideoCodec = async (checkedCodecs, options) => {\n    for (const codec of checkedCodecs) {\n        if (await canEncodeVideo(codec, options)) {\n            return codec;\n        }\n    }\n    return null;\n};\n/**\n * Returns the first audio codec from the given list that can be encoded by the browser.\n * @group Encoding\n * @public\n */\nexport const getFirstEncodableAudioCodec = async (checkedCodecs, options) => {\n    for (const codec of checkedCodecs) {\n        if (await canEncodeAudio(codec, options)) {\n            return codec;\n        }\n    }\n    return null;\n};\n/**\n * Returns the first subtitle codec from the given list that can be encoded by the browser.\n * @group Encoding\n * @public\n */\nexport const getFirstEncodableSubtitleCodec = async (checkedCodecs) => {\n    for (const codec of checkedCodecs) {\n        if (await canEncodeSubtitles(codec)) {\n            return codec;\n        }\n    }\n    return null;\n};\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { AUDIO_CODECS, buildAacAudioSpecificConfig, parseAacAudioSpecificConfig, parsePcmCodec, PCM_AUDIO_CODECS, SUBTITLE_CODECS, VIDEO_CODECS, } from './codec.js';\nimport { assert, assertNever, CallSerializer, clamp, isFirefox, last, promiseWithResolvers, setInt24, setUint24, toUint8Array, } from './misc.js';\nimport { SubtitleParser } from './subtitles.js';\nimport { toAlaw, toUlaw } from './pcm.js';\nimport { customVideoEncoders, customAudioEncoders, } from './custom-coder.js';\nimport { EncodedPacket } from './packet.js';\nimport { AudioSample, VideoSample } from './sample.js';\nimport { buildAudioEncoderConfig, buildVideoEncoderConfig, validateAudioEncodingConfig, validateVideoEncodingConfig, } from './encode.js';\n/**\n * Base class for media sources. Media sources are used to add media samples to an output file.\n * @group Media sources\n * @public\n */\nexport class MediaSource {\n    constructor() {\n        /** @internal */\n        this._connectedTrack = null;\n        /** @internal */\n        this._closingPromise = null;\n        /** @internal */\n        this._closed = false;\n        /**\n         * @internal\n         * A time offset in seconds that is added to all timestamps generated by this source.\n         */\n        this._timestampOffset = 0;\n    }\n    /** @internal */\n    _ensureValidAdd() {\n        if (!this._connectedTrack) {\n            throw new Error('Source is not connected to an output track.');\n        }\n        if (this._connectedTrack.output.state === 'canceled') {\n            throw new Error('Output has been canceled.');\n        }\n        if (this._connectedTrack.output.state === 'finalizing' || this._connectedTrack.output.state === 'finalized') {\n            throw new Error('Output has been finalized.');\n        }\n        if (this._connectedTrack.output.state === 'pending') {\n            throw new Error('Output has not started.');\n        }\n        if (this._closed) {\n            throw new Error('Source is closed.');\n        }\n    }\n    /** @internal */\n    async _start() { }\n    /** @internal */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async _flushAndClose(forceClose) { }\n    /**\n     * Closes this source. This prevents future samples from being added and signals to the output file that no further\n     * samples will come in for this track. Calling `.close()` is optional but recommended after adding the\n     * last sample - for improved performance and reduced memory usage.\n     */\n    close() {\n        if (this._closingPromise) {\n            return;\n        }\n        const connectedTrack = this._connectedTrack;\n        if (!connectedTrack) {\n            throw new Error('Cannot call close without connecting the source to an output track.');\n        }\n        if (connectedTrack.output.state === 'pending') {\n            throw new Error('Cannot call close before output has been started.');\n        }\n        this._closingPromise = (async () => {\n            await this._flushAndClose(false);\n            this._closed = true;\n            if (connectedTrack.output.state === 'finalizing' || connectedTrack.output.state === 'finalized') {\n                return;\n            }\n            connectedTrack.output._muxer.onTrackClose(connectedTrack);\n        })();\n    }\n    /** @internal */\n    async _flushOrWaitForOngoingClose(forceClose) {\n        return this._closingPromise ??= (async () => {\n            await this._flushAndClose(forceClose);\n            this._closed = true;\n        })();\n    }\n}\n/**\n * Base class for video sources - sources for video tracks.\n * @group Media sources\n * @public\n */\nexport class VideoSource extends MediaSource {\n    /** Internal constructor. */\n    constructor(codec) {\n        super();\n        /** @internal */\n        this._connectedTrack = null;\n        if (!VIDEO_CODECS.includes(codec)) {\n            throw new TypeError(`Invalid video codec '${codec}'. Must be one of: ${VIDEO_CODECS.join(', ')}.`);\n        }\n        this._codec = codec;\n    }\n}\n/**\n * The most basic video source; can be used to directly pipe encoded packets into the output file.\n * @group Media sources\n * @public\n */\nexport class EncodedVideoPacketSource extends VideoSource {\n    /** Creates a new {@link EncodedVideoPacketSource} whose packets are encoded using `codec`. */\n    constructor(codec) {\n        super(codec);\n    }\n    /**\n     * Adds an encoded packet to the output video track. Packets must be added in *decode order*, while a packet's\n     * timestamp must be its *presentation timestamp*. B-frames are handled automatically.\n     *\n     * @param meta - Additional metadata from the encoder. You should pass this for the first call, including a valid\n     * decoder config.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(packet, meta) {\n        if (!(packet instanceof EncodedPacket)) {\n            throw new TypeError('packet must be an EncodedPacket.');\n        }\n        if (packet.isMetadataOnly) {\n            throw new TypeError('Metadata-only packets cannot be added.');\n        }\n        if (meta !== undefined && (!meta || typeof meta !== 'object')) {\n            throw new TypeError('meta, when provided, must be an object.');\n        }\n        this._ensureValidAdd();\n        return this._connectedTrack.output._muxer.addEncodedVideoPacket(this._connectedTrack, packet, meta);\n    }\n}\nclass VideoEncoderWrapper {\n    constructor(source, encodingConfig) {\n        this.source = source;\n        this.encodingConfig = encodingConfig;\n        this.ensureEncoderPromise = null;\n        this.encoderInitialized = false;\n        this.encoder = null;\n        this.muxer = null;\n        this.lastMultipleOfKeyFrameInterval = -1;\n        this.codedWidth = null;\n        this.codedHeight = null;\n        this.resizeCanvas = null;\n        this.customEncoder = null;\n        this.customEncoderCallSerializer = new CallSerializer();\n        this.customEncoderQueueSize = 0;\n        // Alpha stuff\n        this.alphaEncoder = null;\n        this.splitter = null;\n        this.splitterCreationFailed = false;\n        this.alphaFrameQueue = [];\n        /**\n         * Encoders typically throw their errors \"out of band\", meaning asynchronously in some other execution context.\n         * However, we want to surface these errors to the user within the normal control flow, so they don't go uncaught.\n         * So, we keep track of the encoder error and throw it as soon as we get the chance.\n         */\n        this.error = null;\n        this.errorNeedsNewStack = true;\n    }\n    async add(videoSample, shouldClose, encodeOptions) {\n        try {\n            this.checkForEncoderError();\n            this.source._ensureValidAdd();\n            // Ensure video sample size remains constant\n            if (this.codedWidth !== null && this.codedHeight !== null) {\n                if (videoSample.codedWidth !== this.codedWidth || videoSample.codedHeight !== this.codedHeight) {\n                    const sizeChangeBehavior = this.encodingConfig.sizeChangeBehavior ?? 'deny';\n                    if (sizeChangeBehavior === 'passThrough') {\n                        // Do nada\n                    }\n                    else if (sizeChangeBehavior === 'deny') {\n                        throw new Error(`Video sample size must remain constant. Expected ${this.codedWidth}x${this.codedHeight},`\n                            + ` got ${videoSample.codedWidth}x${videoSample.codedHeight}. To allow the sample size to`\n                            + ` change over time, set \\`sizeChangeBehavior\\` to a value other than 'strict' in the`\n                            + ` encoding options.`);\n                    }\n                    else {\n                        let canvasIsNew = false;\n                        if (!this.resizeCanvas) {\n                            if (typeof document !== 'undefined') {\n                                // Prefer an HTMLCanvasElement\n                                this.resizeCanvas = document.createElement('canvas');\n                                this.resizeCanvas.width = this.codedWidth;\n                                this.resizeCanvas.height = this.codedHeight;\n                            }\n                            else {\n                                this.resizeCanvas = new OffscreenCanvas(this.codedWidth, this.codedHeight);\n                            }\n                            canvasIsNew = true;\n                        }\n                        const context = this.resizeCanvas.getContext('2d', {\n                            alpha: isFirefox(), // Firefox has VideoFrame glitches with opaque canvases\n                        });\n                        assert(context);\n                        if (!canvasIsNew) {\n                            if (isFirefox()) {\n                                context.fillStyle = 'black';\n                                context.fillRect(0, 0, this.codedWidth, this.codedHeight);\n                            }\n                            else {\n                                context.clearRect(0, 0, this.codedWidth, this.codedHeight);\n                            }\n                        }\n                        videoSample.drawWithFit(context, { fit: sizeChangeBehavior });\n                        if (shouldClose) {\n                            videoSample.close();\n                        }\n                        videoSample = new VideoSample(this.resizeCanvas, {\n                            timestamp: videoSample.timestamp,\n                            duration: videoSample.duration,\n                            rotation: videoSample.rotation,\n                        });\n                        shouldClose = true;\n                    }\n                }\n            }\n            else {\n                this.codedWidth = videoSample.codedWidth;\n                this.codedHeight = videoSample.codedHeight;\n            }\n            if (!this.encoderInitialized) {\n                if (!this.ensureEncoderPromise) {\n                    this.ensureEncoder(videoSample);\n                }\n                // No, this \"if\" statement is not useless. Sometimes, the above call to `ensureEncoder` might have\n                // synchronously completed and the encoder is already initialized. In this case, we don't need to await\n                // the promise anymore. This also fixes nasty async race condition bugs when multiple code paths are\n                // calling this method: It's important that the call that initialized the encoder go through this\n                // code first.\n                if (!this.encoderInitialized) {\n                    await this.ensureEncoderPromise;\n                }\n            }\n            assert(this.encoderInitialized);\n            const keyFrameInterval = this.encodingConfig.keyFrameInterval ?? 5;\n            const multipleOfKeyFrameInterval = Math.floor(videoSample.timestamp / keyFrameInterval);\n            // Ensure a key frame every keyFrameInterval seconds. It is important that all video tracks follow the same\n            // \"key frame\" rhythm, because aligned key frames are required to start new fragments in ISOBMFF or clusters\n            // in Matroska (or at least desirable).\n            const finalEncodeOptions = {\n                ...encodeOptions,\n                keyFrame: encodeOptions?.keyFrame\n                    || keyFrameInterval === 0\n                    || multipleOfKeyFrameInterval !== this.lastMultipleOfKeyFrameInterval,\n            };\n            this.lastMultipleOfKeyFrameInterval = multipleOfKeyFrameInterval;\n            if (this.customEncoder) {\n                this.customEncoderQueueSize++;\n                // We clone the sample so it cannot be closed on us from the outside before it reaches the encoder\n                const clonedSample = videoSample.clone();\n                const promise = this.customEncoderCallSerializer\n                    .call(() => this.customEncoder.encode(clonedSample, finalEncodeOptions))\n                    .then(() => this.customEncoderQueueSize--)\n                    .catch((error) => this.error ??= error)\n                    .finally(() => {\n                    clonedSample.close();\n                    // `videoSample` gets closed in the finally block at the end of the method\n                });\n                if (this.customEncoderQueueSize >= 4) {\n                    await promise;\n                }\n            }\n            else {\n                assert(this.encoder);\n                const videoFrame = videoSample.toVideoFrame();\n                if (!this.alphaEncoder) {\n                    // No alpha encoder, simple case\n                    this.encoder.encode(videoFrame, finalEncodeOptions);\n                    videoFrame.close();\n                }\n                else {\n                    // We're expected to encode alpha as well\n                    const frameDefinitelyHasNoAlpha = !!videoFrame.format && !videoFrame.format.includes('A');\n                    if (frameDefinitelyHasNoAlpha || this.splitterCreationFailed) {\n                        this.alphaFrameQueue.push(null);\n                        this.encoder.encode(videoFrame, finalEncodeOptions);\n                        videoFrame.close();\n                    }\n                    else {\n                        const width = videoFrame.displayWidth;\n                        const height = videoFrame.displayHeight;\n                        if (!this.splitter) {\n                            try {\n                                this.splitter = new ColorAlphaSplitter(width, height);\n                            }\n                            catch (error) {\n                                console.error('Due to an error, only color data will be encoded.', error);\n                                this.splitterCreationFailed = true;\n                                this.alphaFrameQueue.push(null);\n                                this.encoder.encode(videoFrame, finalEncodeOptions);\n                                videoFrame.close();\n                            }\n                        }\n                        if (this.splitter) {\n                            const colorFrame = this.splitter.extractColor(videoFrame);\n                            const alphaFrame = this.splitter.extractAlpha(videoFrame);\n                            this.alphaFrameQueue.push(alphaFrame);\n                            this.encoder.encode(colorFrame, finalEncodeOptions);\n                            colorFrame.close();\n                            videoFrame.close();\n                        }\n                    }\n                }\n                if (shouldClose) {\n                    videoSample.close();\n                }\n                // We need to do this after sending the frame to the encoder as the frame otherwise might be closed\n                if (this.encoder.encodeQueueSize >= 4) {\n                    await new Promise(resolve => this.encoder.addEventListener('dequeue', resolve, { once: true }));\n                }\n            }\n            await this.muxer.mutex.currentPromise; // Allow the writer to apply backpressure\n        }\n        finally {\n            if (shouldClose) {\n                // Make sure it's always closed, even if there was an error\n                videoSample.close();\n            }\n        }\n    }\n    ensureEncoder(videoSample) {\n        const encoderError = new Error();\n        this.ensureEncoderPromise = (async () => {\n            const encoderConfig = buildVideoEncoderConfig({\n                width: videoSample.codedWidth,\n                height: videoSample.codedHeight,\n                ...this.encodingConfig,\n                framerate: this.source._connectedTrack?.metadata.frameRate,\n            });\n            this.encodingConfig.onEncoderConfig?.(encoderConfig);\n            const MatchingCustomEncoder = customVideoEncoders.find(x => x.supports(this.encodingConfig.codec, encoderConfig));\n            if (MatchingCustomEncoder) {\n                // @ts-expect-error \"Can't create instance of abstract class \"\n                this.customEncoder = new MatchingCustomEncoder();\n                // @ts-expect-error It's technically readonly\n                this.customEncoder.codec = this.encodingConfig.codec;\n                // @ts-expect-error It's technically readonly\n                this.customEncoder.config = encoderConfig;\n                // @ts-expect-error It's technically readonly\n                this.customEncoder.onPacket = (packet, meta) => {\n                    if (!(packet instanceof EncodedPacket)) {\n                        throw new TypeError('The first argument passed to onPacket must be an EncodedPacket.');\n                    }\n                    if (meta !== undefined && (!meta || typeof meta !== 'object')) {\n                        throw new TypeError('The second argument passed to onPacket must be an object or undefined.');\n                    }\n                    this.encodingConfig.onEncodedPacket?.(packet, meta);\n                    void this.muxer.addEncodedVideoPacket(this.source._connectedTrack, packet, meta)\n                        .catch((error) => {\n                        this.error ??= error;\n                        this.errorNeedsNewStack = false;\n                    });\n                };\n                await this.customEncoder.init();\n            }\n            else {\n                if (typeof VideoEncoder === 'undefined') {\n                    throw new Error('VideoEncoder is not supported by this browser.');\n                }\n                encoderConfig.alpha = 'discard'; // Since we handle alpha ourselves\n                if (this.encodingConfig.alpha === 'keep') {\n                    // Encoding alpha requires using two parallel encoders, so we need to make sure they stay in sync\n                    // and that neither of them drops frames. Setting latencyMode to 'quality' achieves this, because\n                    // \"User Agents MUST not drop frames to achieve the target bitrate and/or framerate.\"\n                    encoderConfig.latencyMode = 'quality';\n                }\n                const hasOddDimension = encoderConfig.width % 2 === 1 || encoderConfig.height % 2 === 1;\n                if (hasOddDimension\n                    && (this.encodingConfig.codec === 'avc' || this.encodingConfig.codec === 'hevc')) {\n                    // Throw a special error for this case as it gets hit often\n                    throw new Error(`The dimensions ${encoderConfig.width}x${encoderConfig.height} are not supported for codec`\n                        + ` '${this.encodingConfig.codec}'; both width and height must be even numbers. Make sure to`\n                        + ` round your dimensions to the nearest even number.`);\n                }\n                const support = await VideoEncoder.isConfigSupported(encoderConfig);\n                if (!support.supported) {\n                    throw new Error(`This specific encoder configuration (${encoderConfig.codec}, ${encoderConfig.bitrate} bps,`\n                        + ` ${encoderConfig.width}x${encoderConfig.height}, hardware acceleration:`\n                        + ` ${encoderConfig.hardwareAcceleration ?? 'no-preference'}) is not supported by this browser.`\n                        + ` Consider using another codec or changing your video parameters.`);\n                }\n                /** Queue of color chunks waiting for their alpha counterpart. */\n                const colorChunkQueue = [];\n                /** Each value is the number of encoded alpha chunks at which a null alpha chunk should be added. */\n                const nullAlphaChunkQueue = [];\n                let encodedAlphaChunkCount = 0;\n                let alphaEncoderQueue = 0;\n                const addPacket = (colorChunk, alphaChunk, meta) => {\n                    const sideData = {};\n                    if (alphaChunk) {\n                        const alphaData = new Uint8Array(alphaChunk.byteLength);\n                        alphaChunk.copyTo(alphaData);\n                        sideData.alpha = alphaData;\n                    }\n                    const packet = EncodedPacket.fromEncodedChunk(colorChunk, sideData);\n                    this.encodingConfig.onEncodedPacket?.(packet, meta);\n                    void this.muxer.addEncodedVideoPacket(this.source._connectedTrack, packet, meta)\n                        .catch((error) => {\n                        this.error ??= error;\n                        this.errorNeedsNewStack = false;\n                    });\n                };\n                this.encoder = new VideoEncoder({\n                    output: (chunk, meta) => {\n                        if (!this.alphaEncoder) {\n                            // We're done\n                            addPacket(chunk, null, meta);\n                            return;\n                        }\n                        const alphaFrame = this.alphaFrameQueue.shift();\n                        assert(alphaFrame !== undefined);\n                        if (alphaFrame) {\n                            this.alphaEncoder.encode(alphaFrame, {\n                                // Crucial: The alpha frame is forced to be a key frame whenever the color frame\n                                // also is. Without this, playback can glitch and even crash in some browsers.\n                                // This is the reason why the two encoders are wired in series and not in parallel.\n                                keyFrame: chunk.type === 'key',\n                            });\n                            alphaEncoderQueue++;\n                            alphaFrame.close();\n                            colorChunkQueue.push({ chunk, meta });\n                        }\n                        else {\n                            // There was no alpha component for this frame\n                            if (alphaEncoderQueue === 0) {\n                                // No pending alpha encodes either, so we're done\n                                addPacket(chunk, null, meta);\n                            }\n                            else {\n                                // There are still alpha encodes pending, so we can't add the packet immediately since\n                                // we'd end up with out-of-order packets. Instead, let's queue a null alpha chunk to be\n                                // added in the future, after the current encoder workload has completed:\n                                nullAlphaChunkQueue.push(encodedAlphaChunkCount + alphaEncoderQueue);\n                                colorChunkQueue.push({ chunk, meta });\n                            }\n                        }\n                    },\n                    error: (error) => {\n                        error.stack = encoderError.stack; // Provide a more useful stack trace\n                        this.error ??= error;\n                    },\n                });\n                this.encoder.configure(encoderConfig);\n                if (this.encodingConfig.alpha === 'keep') {\n                    // We need to encode alpha as well, which we do with a separate encoder\n                    this.alphaEncoder = new VideoEncoder({\n                        // We ignore the alpha chunk's metadata\n                        // eslint-disable-next-line @typescript-eslint/no-unused-vars\n                        output: (chunk, meta) => {\n                            alphaEncoderQueue--;\n                            // There has to be a color chunk because the encoders are wired in series\n                            const colorChunk = colorChunkQueue.shift();\n                            assert(colorChunk !== undefined);\n                            addPacket(colorChunk.chunk, chunk, colorChunk.meta);\n                            // See if there are any null alpha chunks queued up\n                            encodedAlphaChunkCount++;\n                            while (nullAlphaChunkQueue.length > 0\n                                && nullAlphaChunkQueue[0] === encodedAlphaChunkCount) {\n                                nullAlphaChunkQueue.shift();\n                                const colorChunk = colorChunkQueue.shift();\n                                assert(colorChunk !== undefined);\n                                addPacket(colorChunk.chunk, null, colorChunk.meta);\n                            }\n                        },\n                        error: (error) => {\n                            error.stack = encoderError.stack; // Provide a more useful stack trace\n                            this.error ??= error;\n                        },\n                    });\n                    this.alphaEncoder.configure(encoderConfig);\n                }\n            }\n            assert(this.source._connectedTrack);\n            this.muxer = this.source._connectedTrack.output._muxer;\n            this.encoderInitialized = true;\n        })();\n    }\n    async flushAndClose(forceClose) {\n        if (!forceClose)\n            this.checkForEncoderError();\n        if (this.customEncoder) {\n            if (!forceClose) {\n                void this.customEncoderCallSerializer.call(() => this.customEncoder.flush());\n            }\n            await this.customEncoderCallSerializer.call(() => this.customEncoder.close());\n        }\n        else if (this.encoder) {\n            if (!forceClose) {\n                // These are wired in series, therefore they must also be flushed in series\n                await this.encoder.flush();\n                await this.alphaEncoder?.flush();\n            }\n            if (this.encoder.state !== 'closed') {\n                this.encoder.close();\n            }\n            if (this.alphaEncoder && this.alphaEncoder.state !== 'closed') {\n                this.alphaEncoder.close();\n            }\n            this.alphaFrameQueue.forEach(x => x?.close());\n            this.splitter?.close();\n        }\n        if (!forceClose)\n            this.checkForEncoderError();\n    }\n    getQueueSize() {\n        if (this.customEncoder) {\n            return this.customEncoderQueueSize;\n        }\n        else {\n            // Because the color and alpha encoders are wired in series, there's no need to also include the alpha\n            // encoder's queue size here\n            return this.encoder?.encodeQueueSize ?? 0;\n        }\n    }\n    checkForEncoderError() {\n        if (this.error) {\n            if (this.errorNeedsNewStack) {\n                this.error.stack = new Error().stack; // Provide an even more useful stack trace\n            }\n            throw this.error;\n        }\n    }\n}\n/** Utility class for splitting a composite frame into separate color and alpha components. */\nclass ColorAlphaSplitter {\n    constructor(initialWidth, initialHeight) {\n        this.lastFrame = null;\n        if (typeof OffscreenCanvas !== 'undefined') {\n            this.canvas = new OffscreenCanvas(initialWidth, initialHeight);\n        }\n        else {\n            this.canvas = document.createElement('canvas');\n            this.canvas.width = initialWidth;\n            this.canvas.height = initialHeight;\n        }\n        const gl = this.canvas.getContext('webgl2', {\n            alpha: true, // Needed due to the YUV thing we do for alpha\n        }); // Casting because of some TypeScript weirdness\n        if (!gl) {\n            throw new Error('Couldn\\'t acquire WebGL 2 context.');\n        }\n        this.gl = gl;\n        this.colorProgram = this.createColorProgram();\n        this.alphaProgram = this.createAlphaProgram();\n        this.vao = this.createVAO();\n        this.sourceTexture = this.createTexture();\n        this.alphaResolutionLocation = this.gl.getUniformLocation(this.alphaProgram, 'u_resolution');\n        this.gl.useProgram(this.colorProgram);\n        this.gl.uniform1i(this.gl.getUniformLocation(this.colorProgram, 'u_sourceTexture'), 0);\n        this.gl.useProgram(this.alphaProgram);\n        this.gl.uniform1i(this.gl.getUniformLocation(this.alphaProgram, 'u_sourceTexture'), 0);\n    }\n    createVertexShader() {\n        return this.createShader(this.gl.VERTEX_SHADER, `#version 300 es\n\t\t\tin vec2 a_position;\n\t\t\tin vec2 a_texCoord;\n\t\t\tout vec2 v_texCoord;\n\t\t\t\n\t\t\tvoid main() {\n\t\t\t\tgl_Position = vec4(a_position, 0.0, 1.0);\n\t\t\t\tv_texCoord = a_texCoord;\n\t\t\t}\n\t\t`);\n    }\n    createColorProgram() {\n        const vertexShader = this.createVertexShader();\n        // This shader is simple, simply copy the color information while setting alpha to 1\n        const fragmentShader = this.createShader(this.gl.FRAGMENT_SHADER, `#version 300 es\n\t\t\tprecision highp float;\n\t\t\t\n\t\t\tuniform sampler2D u_sourceTexture;\n\t\t\tin vec2 v_texCoord;\n\t\t\tout vec4 fragColor;\n\t\t\t\n\t\t\tvoid main() {\n\t\t\t\tvec4 source = texture(u_sourceTexture, v_texCoord);\n\t\t\t\tfragColor = vec4(source.rgb, 1.0);\n\t\t\t}\n\t\t`);\n        const program = this.gl.createProgram();\n        this.gl.attachShader(program, vertexShader);\n        this.gl.attachShader(program, fragmentShader);\n        this.gl.linkProgram(program);\n        return program;\n    }\n    createAlphaProgram() {\n        const vertexShader = this.createVertexShader();\n        // This shader's more complex. The main reason is that this shader writes data in I420 (yuv420) pixel format\n        // instead of regular RGBA. In other words, we use the shader to write out I420 data into an RGBA canvas, which\n        // we then later read out with JavaScript. The reason being that browsers weirdly encode canvases and mess up\n        // the color spaces, and the only way to have full control over the color space is by outputting YUV data\n        // directly (avoiding the RGB conversion). Doing this conversion in JS is painfully slow, so let's utlize the\n        // GPU since we're already calling it anyway.\n        const fragmentShader = this.createShader(this.gl.FRAGMENT_SHADER, `#version 300 es\n\t\t\tprecision highp float;\n\t\t\t\n\t\t\tuniform sampler2D u_sourceTexture;\n\t\t\tuniform vec2 u_resolution; // The width and height of the canvas\n\t\t\tin vec2 v_texCoord;\n\t\t\tout vec4 fragColor;\n\n\t\t\t// This function determines the value for a single byte in the YUV stream\n\t\t\tfloat getByteValue(float byteOffset) {\n\t\t\t\tfloat width = u_resolution.x;\n\t\t\t\tfloat height = u_resolution.y;\n\n\t\t\t\tfloat yPlaneSize = width * height;\n\n\t\t\t\tif (byteOffset < yPlaneSize) {\n\t\t\t\t\t// This byte is in the luma plane. Find the corresponding pixel coordinates to sample from\n\t\t\t\t\tfloat y = floor(byteOffset / width);\n\t\t\t\t\tfloat x = mod(byteOffset, width);\n\t\t\t\t\t\n\t\t\t\t\t// Add 0.5 to sample the center of the texel\n\t\t\t\t\tvec2 sampleCoord = (vec2(x, y) + 0.5) / u_resolution;\n\t\t\t\t\t\n\t\t\t\t\t// The luma value is the alpha from the source texture\n\t\t\t\t\treturn texture(u_sourceTexture, sampleCoord).a;\n\t\t\t\t} else {\n\t\t\t\t\t// Write a fixed value for chroma and beyond\n\t\t\t\t\treturn 128.0 / 255.0;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tvoid main() {\n\t\t\t\t// Each fragment writes 4 bytes (R, G, B, A)\n\t\t\t\tfloat pixelIndex = floor(gl_FragCoord.y) * u_resolution.x + floor(gl_FragCoord.x);\n\t\t\t\tfloat baseByteOffset = pixelIndex * 4.0;\n\n\t\t\t\tvec4 result;\n\t\t\t\tfor (int i = 0; i < 4; i++) {\n\t\t\t\t\tfloat currentByteOffset = baseByteOffset + float(i);\n\t\t\t\t\tresult[i] = getByteValue(currentByteOffset);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tfragColor = result;\n\t\t\t}\n\t\t`);\n        const program = this.gl.createProgram();\n        this.gl.attachShader(program, vertexShader);\n        this.gl.attachShader(program, fragmentShader);\n        this.gl.linkProgram(program);\n        return program;\n    }\n    createShader(type, source) {\n        const shader = this.gl.createShader(type);\n        this.gl.shaderSource(shader, source);\n        this.gl.compileShader(shader);\n        if (!this.gl.getShaderParameter(shader, this.gl.COMPILE_STATUS)) {\n            console.error('Shader compile error:', this.gl.getShaderInfoLog(shader));\n        }\n        return shader;\n    }\n    createVAO() {\n        const vao = this.gl.createVertexArray();\n        this.gl.bindVertexArray(vao);\n        const vertices = new Float32Array([\n            -1, -1, 0, 1,\n            1, -1, 1, 1,\n            -1, 1, 0, 0,\n            1, 1, 1, 0,\n        ]);\n        const buffer = this.gl.createBuffer();\n        this.gl.bindBuffer(this.gl.ARRAY_BUFFER, buffer);\n        this.gl.bufferData(this.gl.ARRAY_BUFFER, vertices, this.gl.STATIC_DRAW);\n        const positionLocation = this.gl.getAttribLocation(this.colorProgram, 'a_position');\n        const texCoordLocation = this.gl.getAttribLocation(this.colorProgram, 'a_texCoord');\n        this.gl.enableVertexAttribArray(positionLocation);\n        this.gl.vertexAttribPointer(positionLocation, 2, this.gl.FLOAT, false, 16, 0);\n        this.gl.enableVertexAttribArray(texCoordLocation);\n        this.gl.vertexAttribPointer(texCoordLocation, 2, this.gl.FLOAT, false, 16, 8);\n        return vao;\n    }\n    createTexture() {\n        const texture = this.gl.createTexture();\n        this.gl.bindTexture(this.gl.TEXTURE_2D, texture);\n        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);\n        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);\n        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR);\n        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR);\n        return texture;\n    }\n    updateTexture(sourceFrame) {\n        if (this.lastFrame === sourceFrame) {\n            return;\n        }\n        if (sourceFrame.displayWidth !== this.canvas.width || sourceFrame.displayHeight !== this.canvas.height) {\n            this.canvas.width = sourceFrame.displayWidth;\n            this.canvas.height = sourceFrame.displayHeight;\n        }\n        this.gl.activeTexture(this.gl.TEXTURE0);\n        this.gl.bindTexture(this.gl.TEXTURE_2D, this.sourceTexture);\n        this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, sourceFrame);\n        this.lastFrame = sourceFrame;\n    }\n    extractColor(sourceFrame) {\n        this.updateTexture(sourceFrame);\n        this.gl.useProgram(this.colorProgram);\n        this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);\n        this.gl.clear(this.gl.COLOR_BUFFER_BIT);\n        this.gl.bindVertexArray(this.vao);\n        this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);\n        return new VideoFrame(this.canvas, {\n            timestamp: sourceFrame.timestamp,\n            duration: sourceFrame.duration ?? undefined,\n            alpha: 'discard',\n        });\n    }\n    extractAlpha(sourceFrame) {\n        this.updateTexture(sourceFrame);\n        this.gl.useProgram(this.alphaProgram);\n        this.gl.uniform2f(this.alphaResolutionLocation, this.canvas.width, this.canvas.height);\n        this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);\n        this.gl.clear(this.gl.COLOR_BUFFER_BIT);\n        this.gl.bindVertexArray(this.vao);\n        this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);\n        const { width, height } = this.canvas;\n        const chromaSamples = Math.ceil(width / 2) * Math.ceil(height / 2);\n        const yuvSize = width * height + chromaSamples * 2;\n        const requiredHeight = Math.ceil(yuvSize / (width * 4));\n        let yuv = new Uint8Array(4 * width * requiredHeight);\n        this.gl.readPixels(0, 0, width, requiredHeight, this.gl.RGBA, this.gl.UNSIGNED_BYTE, yuv);\n        yuv = yuv.subarray(0, yuvSize);\n        assert(yuv[width * height] === 128); // Where chroma data starts\n        assert(yuv[yuv.length - 1] === 128); // Assert the YUV data has been fully written\n        // Defining this separately because TypeScript doesn't know `transfer` and I can't be bothered to do declaration\n        // merging right now\n        const init = {\n            format: 'I420',\n            codedWidth: width,\n            codedHeight: height,\n            timestamp: sourceFrame.timestamp,\n            duration: sourceFrame.duration ?? undefined,\n            transfer: [yuv.buffer],\n        };\n        return new VideoFrame(yuv, init);\n    }\n    close() {\n        this.gl.getExtension('WEBGL_lose_context')?.loseContext();\n        this.gl = null;\n    }\n}\n/**\n * This source can be used to add raw, unencoded video samples (frames) to an output video track. These frames will\n * automatically be encoded and then piped into the output.\n * @group Media sources\n * @public\n */\nexport class VideoSampleSource extends VideoSource {\n    /**\n     * Creates a new {@link VideoSampleSource} whose samples are encoded according to the specified\n     * {@link VideoEncodingConfig}.\n     */\n    constructor(encodingConfig) {\n        validateVideoEncodingConfig(encodingConfig);\n        super(encodingConfig.codec);\n        this._encoder = new VideoEncoderWrapper(this, encodingConfig);\n    }\n    /**\n     * Encodes a video sample (frame) and then adds it to the output.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(videoSample, encodeOptions) {\n        if (!(videoSample instanceof VideoSample)) {\n            throw new TypeError('videoSample must be a VideoSample.');\n        }\n        return this._encoder.add(videoSample, false, encodeOptions);\n    }\n    /** @internal */\n    _flushAndClose(forceClose) {\n        return this._encoder.flushAndClose(forceClose);\n    }\n}\n/**\n * This source can be used to add video frames to the output track from a fixed canvas element. Since canvases are often\n * used for rendering, this source provides a convenient wrapper around {@link VideoSampleSource}.\n * @group Media sources\n * @public\n */\nexport class CanvasSource extends VideoSource {\n    /**\n     * Creates a new {@link CanvasSource} from a canvas element or `OffscreenCanvas` whose samples are encoded\n     * according to the specified {@link VideoEncodingConfig}.\n     */\n    constructor(canvas, encodingConfig) {\n        if (!(typeof HTMLCanvasElement !== 'undefined' && canvas instanceof HTMLCanvasElement)\n            && !(typeof OffscreenCanvas !== 'undefined' && canvas instanceof OffscreenCanvas)) {\n            throw new TypeError('canvas must be an HTMLCanvasElement or OffscreenCanvas.');\n        }\n        validateVideoEncodingConfig(encodingConfig);\n        super(encodingConfig.codec);\n        this._encoder = new VideoEncoderWrapper(this, encodingConfig);\n        this._canvas = canvas;\n    }\n    /**\n     * Captures the current canvas state as a video sample (frame), encodes it and adds it to the output.\n     *\n     * @param timestamp - The timestamp of the sample, in seconds.\n     * @param duration - The duration of the sample, in seconds.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(timestamp, duration = 0, encodeOptions) {\n        if (!Number.isFinite(timestamp) || timestamp < 0) {\n            throw new TypeError('timestamp must be a non-negative number.');\n        }\n        if (!Number.isFinite(duration) || duration < 0) {\n            throw new TypeError('duration must be a non-negative number.');\n        }\n        const sample = new VideoSample(this._canvas, { timestamp, duration });\n        return this._encoder.add(sample, true, encodeOptions);\n    }\n    /** @internal */\n    _flushAndClose(forceClose) {\n        return this._encoder.flushAndClose(forceClose);\n    }\n}\n/**\n * Video source that encodes the frames of a\n * [`MediaStreamVideoTrack`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack) and pipes them into the\n * output. This is useful for capturing live or real-time data such as webcams or screen captures. Frames will\n * automatically start being captured once the connected {@link Output} is started, and will keep being captured until\n * the {@link Output} is finalized or this source is closed.\n * @group Media sources\n * @public\n */\nexport class MediaStreamVideoTrackSource extends VideoSource {\n    /** A promise that rejects upon any error within this source. This promise never resolves. */\n    get errorPromise() {\n        this._errorPromiseAccessed = true;\n        return this._promiseWithResolvers.promise;\n    }\n    /** Whether this source is currently paused as a result of calling `.pause()`. */\n    get paused() {\n        return this._paused;\n    }\n    /**\n     * Creates a new {@link MediaStreamVideoTrackSource} from a\n     * [`MediaStreamVideoTrack`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack), which will pull\n     * video samples from the stream in real time and encode them according to {@link VideoEncodingConfig}.\n     */\n    constructor(track, encodingConfig) {\n        if (!(track instanceof MediaStreamTrack) || track.kind !== 'video') {\n            throw new TypeError('track must be a video MediaStreamTrack.');\n        }\n        validateVideoEncodingConfig(encodingConfig);\n        encodingConfig = {\n            ...encodingConfig,\n            latencyMode: 'realtime',\n        };\n        super(encodingConfig.codec);\n        /** @internal */\n        this._abortController = null;\n        /** @internal */\n        this._workerTrackId = null;\n        /** @internal */\n        this._workerListener = null;\n        /** @internal */\n        this._promiseWithResolvers = promiseWithResolvers();\n        /** @internal */\n        this._errorPromiseAccessed = false;\n        /** @internal */\n        this._paused = false;\n        /** @internal */\n        this._lastSampleTimestamp = null;\n        /** @internal */\n        this._pauseOffset = 0;\n        this._encoder = new VideoEncoderWrapper(this, encodingConfig);\n        this._track = track;\n    }\n    /** @internal */\n    async _start() {\n        if (!this._errorPromiseAccessed) {\n            console.warn('Make sure not to ignore the `errorPromise` field on MediaStreamVideoTrackSource, so that any internal'\n                + ' errors get bubbled up properly.');\n        }\n        this._abortController = new AbortController();\n        let firstVideoFrameTimestamp = null;\n        let errored = false;\n        const onVideoFrame = (videoFrame) => {\n            if (errored) {\n                videoFrame.close();\n                return;\n            }\n            const currentTimestamp = videoFrame.timestamp / 1e6;\n            if (this._paused) {\n                const frameSeen = firstVideoFrameTimestamp !== null;\n                if (frameSeen) {\n                    if (this._lastSampleTimestamp !== null) {\n                        // In addition to dropping this frame, let's also keep track of the time we have lost due to the\n                        // pause. Doing it like this instead of simply keeping track of the paused time is better since\n                        // it retains the frame rate of the underlying source.\n                        const timeDelta = currentTimestamp - this._lastSampleTimestamp;\n                        // We modify this field instead of _timestampOffset since we still might have data in flight\n                        // in the encoder, with which we don't want to mess.\n                        this._pauseOffset -= timeDelta;\n                    }\n                    this._lastSampleTimestamp = currentTimestamp;\n                }\n                videoFrame.close();\n                return;\n            }\n            if (firstVideoFrameTimestamp === null) {\n                firstVideoFrameTimestamp = currentTimestamp;\n                const muxer = this._connectedTrack.output._muxer;\n                if (muxer.firstMediaStreamTimestamp === null) {\n                    muxer.firstMediaStreamTimestamp = performance.now() / 1000;\n                    this._timestampOffset = -firstVideoFrameTimestamp;\n                }\n                else {\n                    this._timestampOffset = (performance.now() / 1000 - muxer.firstMediaStreamTimestamp)\n                        - firstVideoFrameTimestamp;\n                }\n            }\n            this._lastSampleTimestamp = currentTimestamp;\n            if (this._encoder.getQueueSize() >= 4) {\n                // Drop frames if the encoder is overloaded\n                videoFrame.close();\n                return;\n            }\n            const sample = new VideoSample(videoFrame, {\n                timestamp: currentTimestamp + this._pauseOffset,\n            });\n            void this._encoder.add(sample, true)\n                .catch((error) => {\n                errored = true;\n                this._abortController?.abort();\n                this._promiseWithResolvers.reject(error);\n                if (this._workerTrackId !== null) {\n                    // Tell the worker to stop the track\n                    sendMessageToMediaStreamTrackProcessorWorker({\n                        type: 'stopTrack',\n                        trackId: this._workerTrackId,\n                    });\n                }\n            });\n        };\n        if (typeof MediaStreamTrackProcessor !== 'undefined') {\n            // We can do it here directly, perfect\n            const processor = new MediaStreamTrackProcessor({ track: this._track });\n            const consumer = new WritableStream({ write: onVideoFrame });\n            processor.readable.pipeTo(consumer, {\n                signal: this._abortController.signal,\n            }).catch((error) => {\n                // Handle AbortError silently\n                if (error instanceof DOMException && error.name === 'AbortError')\n                    return;\n                this._promiseWithResolvers.reject(error);\n            });\n        }\n        else {\n            // It might still be supported in a worker, so let's check that\n            const supportedInWorker = await mediaStreamTrackProcessorIsSupportedInWorker();\n            if (supportedInWorker) {\n                this._workerTrackId = nextMediaStreamTrackProcessorWorkerId++;\n                sendMessageToMediaStreamTrackProcessorWorker({\n                    type: 'videoTrack',\n                    trackId: this._workerTrackId,\n                    track: this._track,\n                });\n                this._workerListener = (event) => {\n                    const message = event.data;\n                    if (message.type === 'videoFrame' && message.trackId === this._workerTrackId) {\n                        onVideoFrame(message.videoFrame);\n                    }\n                    else if (message.type === 'error' && message.trackId === this._workerTrackId) {\n                        this._promiseWithResolvers.reject(message.error);\n                    }\n                };\n                mediaStreamTrackProcessorWorker.addEventListener('message', this._workerListener);\n            }\n            else {\n                throw new Error('MediaStreamTrackProcessor is required but not supported by this browser.');\n            }\n        }\n    }\n    /**\n     * Pauses the capture of video frames - any video frames emitted by the underlying media stream will be ignored\n     * while paused. This does *not* close the underlying `MediaStreamVideoTrack`, it just ignores its output.\n     */\n    pause() {\n        this._paused = true;\n    }\n    /** Resumes the capture of video frames after being paused. */\n    resume() {\n        this._paused = false;\n    }\n    /** @internal */\n    async _flushAndClose(forceClose) {\n        if (this._abortController) {\n            this._abortController.abort();\n            this._abortController = null;\n        }\n        if (this._workerTrackId !== null) {\n            assert(this._workerListener);\n            sendMessageToMediaStreamTrackProcessorWorker({\n                type: 'stopTrack',\n                trackId: this._workerTrackId,\n            });\n            // Wait for the worker to stop the track\n            await new Promise((resolve) => {\n                const listener = (event) => {\n                    const message = event.data;\n                    if (message.type === 'trackStopped' && message.trackId === this._workerTrackId) {\n                        assert(this._workerListener);\n                        mediaStreamTrackProcessorWorker.removeEventListener('message', this._workerListener);\n                        mediaStreamTrackProcessorWorker.removeEventListener('message', listener);\n                        resolve();\n                    }\n                };\n                mediaStreamTrackProcessorWorker.addEventListener('message', listener);\n            });\n        }\n        await this._encoder.flushAndClose(forceClose);\n    }\n}\n/**\n * Base class for audio sources - sources for audio tracks.\n * @group Media sources\n * @public\n */\nexport class AudioSource extends MediaSource {\n    /** Internal constructor. */\n    constructor(codec) {\n        super();\n        /** @internal */\n        this._connectedTrack = null;\n        if (!AUDIO_CODECS.includes(codec)) {\n            throw new TypeError(`Invalid audio codec '${codec}'. Must be one of: ${AUDIO_CODECS.join(', ')}.`);\n        }\n        this._codec = codec;\n    }\n}\n/**\n * The most basic audio source; can be used to directly pipe encoded packets into the output file.\n * @group Media sources\n * @public\n */\nexport class EncodedAudioPacketSource extends AudioSource {\n    /** Creates a new {@link EncodedAudioPacketSource} whose packets are encoded using `codec`. */\n    constructor(codec) {\n        super(codec);\n    }\n    /**\n     * Adds an encoded packet to the output audio track. Packets must be added in *decode order*.\n     *\n     * @param meta - Additional metadata from the encoder. You should pass this for the first call, including a valid\n     * decoder config.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(packet, meta) {\n        if (!(packet instanceof EncodedPacket)) {\n            throw new TypeError('packet must be an EncodedPacket.');\n        }\n        if (packet.isMetadataOnly) {\n            throw new TypeError('Metadata-only packets cannot be added.');\n        }\n        if (meta !== undefined && (!meta || typeof meta !== 'object')) {\n            throw new TypeError('meta, when provided, must be an object.');\n        }\n        this._ensureValidAdd();\n        return this._connectedTrack.output._muxer.addEncodedAudioPacket(this._connectedTrack, packet, meta);\n    }\n}\nclass AudioEncoderWrapper {\n    constructor(source, encodingConfig) {\n        this.source = source;\n        this.encodingConfig = encodingConfig;\n        this.ensureEncoderPromise = null;\n        this.encoderInitialized = false;\n        this.encoder = null;\n        this.muxer = null;\n        this.lastNumberOfChannels = null;\n        this.lastSampleRate = null;\n        this.isPcmEncoder = false;\n        this.outputSampleSize = null;\n        this.writeOutputValue = null;\n        this.customEncoder = null;\n        this.customEncoderCallSerializer = new CallSerializer();\n        this.customEncoderQueueSize = 0;\n        this.lastEndSampleIndex = null;\n        /**\n         * Encoders typically throw their errors \"out of band\", meaning asynchronously in some other execution context.\n         * However, we want to surface these errors to the user within the normal control flow, so they don't go uncaught.\n         * So, we keep track of the encoder error and throw it as soon as we get the chance.\n         */\n        this.error = null;\n        this.errorNeedsNewStack = true;\n    }\n    async add(audioSample, shouldClose) {\n        try {\n            this.checkForEncoderError();\n            this.source._ensureValidAdd();\n            // Ensure audio parameters remain constant\n            if (this.lastNumberOfChannels !== null && this.lastSampleRate !== null) {\n                if (audioSample.numberOfChannels !== this.lastNumberOfChannels\n                    || audioSample.sampleRate !== this.lastSampleRate) {\n                    throw new Error(`Audio parameters must remain constant. Expected ${this.lastNumberOfChannels} channels at`\n                        + ` ${this.lastSampleRate} Hz, got ${audioSample.numberOfChannels} channels at`\n                        + ` ${audioSample.sampleRate} Hz.`);\n                }\n            }\n            else {\n                this.lastNumberOfChannels = audioSample.numberOfChannels;\n                this.lastSampleRate = audioSample.sampleRate;\n            }\n            if (!this.encoderInitialized) {\n                if (!this.ensureEncoderPromise) {\n                    this.ensureEncoder(audioSample);\n                }\n                // No, this \"if\" statement is not useless. Sometimes, the above call to `ensureEncoder` might have\n                // synchronously completed and the encoder is already initialized. In this case, we don't need to await\n                // the promise anymore. This also fixes nasty async race condition bugs when multiple code paths are\n                // calling this method: It's important that the call that initialized the encoder go through this\n                // code first.\n                if (!this.encoderInitialized) {\n                    await this.ensureEncoderPromise;\n                }\n            }\n            assert(this.encoderInitialized);\n            // Handle padding of gaps with silence to avoid audio drift over time, like in\n            // https://github.com/Vanilagy/mediabunny/issues/176\n            // TODO An open question is how encoders deal with the first AudioData having a non-zero timestamp, and with\n            // AudioDatas that have an overlapping timestamp range.\n            {\n                const startSampleIndex = Math.round(audioSample.timestamp * audioSample.sampleRate);\n                const endSampleIndex = Math.round((audioSample.timestamp + audioSample.duration) * audioSample.sampleRate);\n                if (this.lastEndSampleIndex === null) {\n                    this.lastEndSampleIndex = endSampleIndex;\n                }\n                else {\n                    const sampleDiff = startSampleIndex - this.lastEndSampleIndex;\n                    if (sampleDiff >= 64) {\n                        // The gap is big enough, let's add a correction sample\n                        const fillSample = new AudioSample({\n                            data: new Float32Array(sampleDiff * audioSample.numberOfChannels),\n                            format: 'f32-planar',\n                            sampleRate: audioSample.sampleRate,\n                            numberOfChannels: audioSample.numberOfChannels,\n                            numberOfFrames: sampleDiff,\n                            timestamp: this.lastEndSampleIndex / audioSample.sampleRate,\n                        });\n                        await this.add(fillSample, true); // Recursive call\n                    }\n                    this.lastEndSampleIndex += audioSample.numberOfFrames;\n                }\n            }\n            if (this.customEncoder) {\n                this.customEncoderQueueSize++;\n                // We clone the sample so it cannot be closed on us from the outside before it reaches the encoder\n                const clonedSample = audioSample.clone();\n                const promise = this.customEncoderCallSerializer\n                    .call(() => this.customEncoder.encode(clonedSample))\n                    .then(() => this.customEncoderQueueSize--)\n                    .catch((error) => this.error ??= error)\n                    .finally(() => {\n                    clonedSample.close();\n                    // `audioSample` gets closed in the finally block at the end of the method\n                });\n                if (this.customEncoderQueueSize >= 4) {\n                    await promise;\n                }\n                await this.muxer.mutex.currentPromise; // Allow the writer to apply backpressure\n            }\n            else if (this.isPcmEncoder) {\n                await this.doPcmEncoding(audioSample, shouldClose);\n            }\n            else {\n                assert(this.encoder);\n                const audioData = audioSample.toAudioData();\n                this.encoder.encode(audioData);\n                audioData.close();\n                if (shouldClose) {\n                    audioSample.close();\n                }\n                if (this.encoder.encodeQueueSize >= 4) {\n                    await new Promise(resolve => this.encoder.addEventListener('dequeue', resolve, { once: true }));\n                }\n                await this.muxer.mutex.currentPromise; // Allow the writer to apply backpressure\n            }\n        }\n        finally {\n            if (shouldClose) {\n                // Make sure it's always closed, even if there was an error\n                audioSample.close();\n            }\n        }\n    }\n    async doPcmEncoding(audioSample, shouldClose) {\n        assert(this.outputSampleSize);\n        assert(this.writeOutputValue);\n        // Need to extract data from the audio data before we close it\n        const { numberOfChannels, numberOfFrames, sampleRate, timestamp } = audioSample;\n        const CHUNK_SIZE = 2048;\n        const outputs = [];\n        // Prepare all of the output buffers, each being bounded by CHUNK_SIZE so we don't generate huge packets\n        for (let frame = 0; frame < numberOfFrames; frame += CHUNK_SIZE) {\n            const frameCount = Math.min(CHUNK_SIZE, audioSample.numberOfFrames - frame);\n            const outputSize = frameCount * numberOfChannels * this.outputSampleSize;\n            const outputBuffer = new ArrayBuffer(outputSize);\n            const outputView = new DataView(outputBuffer);\n            outputs.push({ frameCount, view: outputView });\n        }\n        const allocationSize = audioSample.allocationSize(({ planeIndex: 0, format: 'f32-planar' }));\n        const floats = new Float32Array(allocationSize / Float32Array.BYTES_PER_ELEMENT);\n        for (let i = 0; i < numberOfChannels; i++) {\n            audioSample.copyTo(floats, { planeIndex: i, format: 'f32-planar' });\n            for (let j = 0; j < outputs.length; j++) {\n                const { frameCount, view } = outputs[j];\n                for (let k = 0; k < frameCount; k++) {\n                    this.writeOutputValue(view, (k * numberOfChannels + i) * this.outputSampleSize, floats[j * CHUNK_SIZE + k]);\n                }\n            }\n        }\n        if (shouldClose) {\n            audioSample.close();\n        }\n        const meta = {\n            decoderConfig: {\n                codec: this.encodingConfig.codec,\n                numberOfChannels,\n                sampleRate,\n            },\n        };\n        for (let i = 0; i < outputs.length; i++) {\n            const { frameCount, view } = outputs[i];\n            const outputBuffer = view.buffer;\n            const startFrame = i * CHUNK_SIZE;\n            const packet = new EncodedPacket(new Uint8Array(outputBuffer), 'key', timestamp + startFrame / sampleRate, frameCount / sampleRate);\n            this.encodingConfig.onEncodedPacket?.(packet, meta);\n            await this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta); // With backpressure\n        }\n    }\n    ensureEncoder(audioSample) {\n        const encoderError = new Error();\n        this.ensureEncoderPromise = (async () => {\n            const { numberOfChannels, sampleRate } = audioSample;\n            const encoderConfig = buildAudioEncoderConfig({\n                numberOfChannels,\n                sampleRate,\n                ...this.encodingConfig,\n            });\n            this.encodingConfig.onEncoderConfig?.(encoderConfig);\n            const MatchingCustomEncoder = customAudioEncoders.find(x => x.supports(this.encodingConfig.codec, encoderConfig));\n            if (MatchingCustomEncoder) {\n                // @ts-expect-error \"Can't create instance of abstract class \"\n                this.customEncoder = new MatchingCustomEncoder();\n                // @ts-expect-error It's technically readonly\n                this.customEncoder.codec = this.encodingConfig.codec;\n                // @ts-expect-error It's technically readonly\n                this.customEncoder.config = encoderConfig;\n                // @ts-expect-error It's technically readonly\n                this.customEncoder.onPacket = (packet, meta) => {\n                    if (!(packet instanceof EncodedPacket)) {\n                        throw new TypeError('The first argument passed to onPacket must be an EncodedPacket.');\n                    }\n                    if (meta !== undefined && (!meta || typeof meta !== 'object')) {\n                        throw new TypeError('The second argument passed to onPacket must be an object or undefined.');\n                    }\n                    this.encodingConfig.onEncodedPacket?.(packet, meta);\n                    void this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta)\n                        .catch((error) => {\n                        this.error ??= error;\n                        this.errorNeedsNewStack = false;\n                    });\n                };\n                await this.customEncoder.init();\n            }\n            else if (PCM_AUDIO_CODECS.includes(this.encodingConfig.codec)) {\n                this.initPcmEncoder();\n            }\n            else {\n                if (typeof AudioEncoder === 'undefined') {\n                    throw new Error('AudioEncoder is not supported by this browser.');\n                }\n                const support = await AudioEncoder.isConfigSupported(encoderConfig);\n                if (!support.supported) {\n                    throw new Error(`This specific encoder configuration (${encoderConfig.codec}, ${encoderConfig.bitrate} bps,`\n                        + ` ${encoderConfig.numberOfChannels} channels, ${encoderConfig.sampleRate} Hz) is not`\n                        + ` supported by this browser. Consider using another codec or changing your audio parameters.`);\n                }\n                this.encoder = new AudioEncoder({\n                    output: (chunk, meta) => {\n                        // WebKit emits an invalid description for AAC (https://bugs.webkit.org/show_bug.cgi?id=302253),\n                        // which we try to detect here. If detected, we'll provide our own description instead, derived\n                        // from the codec string and audio parameters.\n                        if (this.encodingConfig.codec === 'aac' && meta?.decoderConfig) {\n                            let needsDescriptionOverwrite = false;\n                            if (!meta.decoderConfig.description || meta.decoderConfig.description.byteLength < 2) {\n                                needsDescriptionOverwrite = true;\n                            }\n                            else {\n                                const audioSpecificConfig = parseAacAudioSpecificConfig(toUint8Array(meta.decoderConfig.description));\n                                needsDescriptionOverwrite = audioSpecificConfig.objectType === 0;\n                            }\n                            if (needsDescriptionOverwrite) {\n                                const objectType = Number(last(encoderConfig.codec.split('.')));\n                                meta.decoderConfig.description = buildAacAudioSpecificConfig({\n                                    objectType,\n                                    numberOfChannels: meta.decoderConfig.numberOfChannels,\n                                    sampleRate: meta.decoderConfig.sampleRate,\n                                });\n                            }\n                        }\n                        const packet = EncodedPacket.fromEncodedChunk(chunk);\n                        this.encodingConfig.onEncodedPacket?.(packet, meta);\n                        void this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta)\n                            .catch((error) => {\n                            this.error ??= error;\n                            this.errorNeedsNewStack = false;\n                        });\n                    },\n                    error: (error) => {\n                        error.stack = encoderError.stack; // Provide a more useful stack trace\n                        this.error ??= error;\n                    },\n                });\n                this.encoder.configure(encoderConfig);\n            }\n            assert(this.source._connectedTrack);\n            this.muxer = this.source._connectedTrack.output._muxer;\n            this.encoderInitialized = true;\n        })();\n    }\n    initPcmEncoder() {\n        this.isPcmEncoder = true;\n        const codec = this.encodingConfig.codec;\n        const { dataType, sampleSize, littleEndian } = parsePcmCodec(codec);\n        this.outputSampleSize = sampleSize;\n        // All these functions receive a float sample as input and map it into the desired format\n        switch (sampleSize) {\n            case 1:\n                {\n                    if (dataType === 'unsigned') {\n                        this.writeOutputValue = (view, byteOffset, value) => view.setUint8(byteOffset, clamp((value + 1) * 127.5, 0, 255));\n                    }\n                    else if (dataType === 'signed') {\n                        this.writeOutputValue = (view, byteOffset, value) => {\n                            view.setInt8(byteOffset, clamp(Math.round(value * 128), -128, 127));\n                        };\n                    }\n                    else if (dataType === 'ulaw') {\n                        this.writeOutputValue = (view, byteOffset, value) => {\n                            const int16 = clamp(Math.floor(value * 32767), -32768, 32767);\n                            view.setUint8(byteOffset, toUlaw(int16));\n                        };\n                    }\n                    else if (dataType === 'alaw') {\n                        this.writeOutputValue = (view, byteOffset, value) => {\n                            const int16 = clamp(Math.floor(value * 32767), -32768, 32767);\n                            view.setUint8(byteOffset, toAlaw(int16));\n                        };\n                    }\n                    else {\n                        assert(false);\n                    }\n                }\n                ;\n                break;\n            case 2:\n                {\n                    if (dataType === 'unsigned') {\n                        this.writeOutputValue = (view, byteOffset, value) => view.setUint16(byteOffset, clamp((value + 1) * 32767.5, 0, 65535), littleEndian);\n                    }\n                    else if (dataType === 'signed') {\n                        this.writeOutputValue = (view, byteOffset, value) => view.setInt16(byteOffset, clamp(Math.round(value * 32767), -32768, 32767), littleEndian);\n                    }\n                    else {\n                        assert(false);\n                    }\n                }\n                ;\n                break;\n            case 3:\n                {\n                    if (dataType === 'unsigned') {\n                        this.writeOutputValue = (view, byteOffset, value) => setUint24(view, byteOffset, clamp((value + 1) * 8388607.5, 0, 16777215), littleEndian);\n                    }\n                    else if (dataType === 'signed') {\n                        this.writeOutputValue = (view, byteOffset, value) => setInt24(view, byteOffset, clamp(Math.round(value * 8388607), -8388608, 8388607), littleEndian);\n                    }\n                    else {\n                        assert(false);\n                    }\n                }\n                ;\n                break;\n            case 4:\n                {\n                    if (dataType === 'unsigned') {\n                        this.writeOutputValue = (view, byteOffset, value) => view.setUint32(byteOffset, clamp((value + 1) * 2147483647.5, 0, 4294967295), littleEndian);\n                    }\n                    else if (dataType === 'signed') {\n                        this.writeOutputValue = (view, byteOffset, value) => view.setInt32(byteOffset, clamp(Math.round(value * 2147483647), -2147483648, 2147483647), littleEndian);\n                    }\n                    else if (dataType === 'float') {\n                        this.writeOutputValue = (view, byteOffset, value) => view.setFloat32(byteOffset, value, littleEndian);\n                    }\n                    else {\n                        assert(false);\n                    }\n                }\n                ;\n                break;\n            case 8:\n                {\n                    if (dataType === 'float') {\n                        this.writeOutputValue = (view, byteOffset, value) => view.setFloat64(byteOffset, value, littleEndian);\n                    }\n                    else {\n                        assert(false);\n                    }\n                }\n                ;\n                break;\n            default:\n                {\n                    assertNever(sampleSize);\n                    assert(false);\n                }\n                ;\n        }\n    }\n    async flushAndClose(forceClose) {\n        if (!forceClose)\n            this.checkForEncoderError();\n        if (this.customEncoder) {\n            if (!forceClose) {\n                void this.customEncoderCallSerializer.call(() => this.customEncoder.flush());\n            }\n            await this.customEncoderCallSerializer.call(() => this.customEncoder.close());\n        }\n        else if (this.encoder) {\n            if (!forceClose) {\n                await this.encoder.flush();\n            }\n            if (this.encoder.state !== 'closed') {\n                this.encoder.close();\n            }\n        }\n        if (!forceClose)\n            this.checkForEncoderError();\n    }\n    getQueueSize() {\n        if (this.customEncoder) {\n            return this.customEncoderQueueSize;\n        }\n        else if (this.isPcmEncoder) {\n            return 0;\n        }\n        else {\n            return this.encoder?.encodeQueueSize ?? 0;\n        }\n    }\n    checkForEncoderError() {\n        if (this.error) {\n            if (this.errorNeedsNewStack) {\n                this.error.stack = new Error().stack; // Provide an even more useful stack trace\n            }\n            throw this.error;\n        }\n    }\n}\n/**\n * This source can be used to add raw, unencoded audio samples to an output audio track. These samples will\n * automatically be encoded and then piped into the output.\n * @group Media sources\n * @public\n */\nexport class AudioSampleSource extends AudioSource {\n    /**\n     * Creates a new {@link AudioSampleSource} whose samples are encoded according to the specified\n     * {@link AudioEncodingConfig}.\n     */\n    constructor(encodingConfig) {\n        validateAudioEncodingConfig(encodingConfig);\n        super(encodingConfig.codec);\n        this._encoder = new AudioEncoderWrapper(this, encodingConfig);\n    }\n    /**\n     * Encodes an audio sample and then adds it to the output.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(audioSample) {\n        if (!(audioSample instanceof AudioSample)) {\n            throw new TypeError('audioSample must be an AudioSample.');\n        }\n        return this._encoder.add(audioSample, false);\n    }\n    /** @internal */\n    _flushAndClose(forceClose) {\n        return this._encoder.flushAndClose(forceClose);\n    }\n}\n/**\n * This source can be used to add audio data from an AudioBuffer to the output track. This is useful when working with\n * the Web Audio API.\n * @group Media sources\n * @public\n */\nexport class AudioBufferSource extends AudioSource {\n    /**\n     * Creates a new {@link AudioBufferSource} whose `AudioBuffer` instances are encoded according to the specified\n     * {@link AudioEncodingConfig}.\n     */\n    constructor(encodingConfig) {\n        validateAudioEncodingConfig(encodingConfig);\n        super(encodingConfig.codec);\n        /** @internal */\n        this._accumulatedTime = 0;\n        this._encoder = new AudioEncoderWrapper(this, encodingConfig);\n    }\n    /**\n     * Converts an AudioBuffer to audio samples, encodes them and adds them to the output. The first AudioBuffer will\n     * be played at timestamp 0, and any subsequent AudioBuffer will have a timestamp equal to the total duration of\n     * all previous AudioBuffers.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    async add(audioBuffer) {\n        if (!(audioBuffer instanceof AudioBuffer)) {\n            throw new TypeError('audioBuffer must be an AudioBuffer.');\n        }\n        const iterator = AudioSample._fromAudioBuffer(audioBuffer, this._accumulatedTime);\n        this._accumulatedTime += audioBuffer.duration;\n        for (const audioSample of iterator) {\n            await this._encoder.add(audioSample, true);\n        }\n    }\n    /** @internal */\n    _flushAndClose(forceClose) {\n        return this._encoder.flushAndClose(forceClose);\n    }\n}\n/**\n * Audio source that encodes the data of a\n * [`MediaStreamAudioTrack`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack) and pipes it into the\n * output. This is useful for capturing live or real-time audio such as microphones or audio from other media elements.\n * Audio will automatically start being captured once the connected {@link Output} is started, and will keep being\n * captured until the {@link Output} is finalized or this source is closed.\n * @group Media sources\n * @public\n */\nexport class MediaStreamAudioTrackSource extends AudioSource {\n    /** A promise that rejects upon any error within this source. This promise never resolves. */\n    get errorPromise() {\n        this._errorPromiseAccessed = true;\n        return this._promiseWithResolvers.promise;\n    }\n    /** Whether this source is currently paused as a result of calling `.pause()`. */\n    get paused() {\n        return this._paused;\n    }\n    /**\n     * Creates a new {@link MediaStreamAudioTrackSource} from a `MediaStreamAudioTrack`, which will pull audio samples\n     * from the stream in real time and encode them according to {@link AudioEncodingConfig}.\n     */\n    constructor(track, encodingConfig) {\n        if (!(track instanceof MediaStreamTrack) || track.kind !== 'audio') {\n            throw new TypeError('track must be an audio MediaStreamTrack.');\n        }\n        validateAudioEncodingConfig(encodingConfig);\n        super(encodingConfig.codec);\n        /** @internal */\n        this._abortController = null;\n        /** @internal */\n        this._audioContext = null;\n        /** @internal */\n        this._scriptProcessorNode = null; // Deprecated but goated\n        /** @internal */\n        this._promiseWithResolvers = promiseWithResolvers();\n        /** @internal */\n        this._errorPromiseAccessed = false;\n        /** @internal */\n        this._paused = false;\n        /** @internal */\n        this._lastSampleTimestamp = null;\n        /** @internal */\n        this._pauseOffset = 0;\n        this._encoder = new AudioEncoderWrapper(this, encodingConfig);\n        this._track = track;\n    }\n    /** @internal */\n    async _start() {\n        if (!this._errorPromiseAccessed) {\n            console.warn('Make sure not to ignore the `errorPromise` field on MediaStreamVideoTrackSource, so that any internal'\n                + ' errors get bubbled up properly.');\n        }\n        this._abortController = new AbortController();\n        let firstAudioDataTimestamp = null;\n        let errored = false;\n        const onAudioSample = (audioSample) => {\n            if (errored) {\n                audioSample.close();\n                return;\n            }\n            const currentTimestamp = audioSample.timestamp;\n            if (this._paused) {\n                const dataSeen = firstAudioDataTimestamp !== null;\n                if (dataSeen) {\n                    if (this._lastSampleTimestamp !== null) {\n                        // In addition to dropping this sample, let's also keep track of the time we have lost due to\n                        // the pause. Doing it like this instead of simply keeping track of the paused time is better\n                        // since it retains the sample rate of the underlying source.\n                        const timeDelta = currentTimestamp - this._lastSampleTimestamp;\n                        // We modify this field instead of _timestampOffset since we still might have data in flight\n                        // in the encoder, with which we don't want to mess.\n                        this._pauseOffset -= timeDelta;\n                    }\n                    this._lastSampleTimestamp = currentTimestamp;\n                }\n                audioSample.close();\n                return;\n            }\n            if (firstAudioDataTimestamp === null) {\n                firstAudioDataTimestamp = audioSample.timestamp;\n                const muxer = this._connectedTrack.output._muxer;\n                if (muxer.firstMediaStreamTimestamp === null) {\n                    muxer.firstMediaStreamTimestamp = performance.now() / 1000;\n                    this._timestampOffset = -firstAudioDataTimestamp;\n                }\n                else {\n                    this._timestampOffset = (performance.now() / 1000 - muxer.firstMediaStreamTimestamp)\n                        - firstAudioDataTimestamp;\n                }\n            }\n            this._lastSampleTimestamp = currentTimestamp;\n            if (this._encoder.getQueueSize() >= 4) {\n                // Drop data if the encoder is overloaded\n                audioSample.close();\n                return;\n            }\n            audioSample.setTimestamp(currentTimestamp + this._pauseOffset);\n            void this._encoder.add(audioSample, true)\n                .catch((error) => {\n                errored = true;\n                this._abortController?.abort();\n                this._promiseWithResolvers.reject(error);\n                void this._audioContext?.suspend();\n            });\n        };\n        if (typeof MediaStreamTrackProcessor !== 'undefined') {\n            // Great, MediaStreamTrackProcessor is supported, this is the preferred way of doing things\n            const processor = new MediaStreamTrackProcessor({ track: this._track });\n            const consumer = new WritableStream({\n                write: audioData => onAudioSample(new AudioSample(audioData)),\n            });\n            processor.readable.pipeTo(consumer, {\n                signal: this._abortController.signal,\n            }).catch((error) => {\n                // Handle AbortError silently\n                if (error instanceof DOMException && error.name === 'AbortError')\n                    return;\n                this._promiseWithResolvers.reject(error);\n            });\n        }\n        else {\n            // Let's fall back to an AudioContext approach\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/no-unsafe-member-access\n            const AudioContext = window.AudioContext || window.webkitAudioContext;\n            this._audioContext = new AudioContext({ sampleRate: this._track.getSettings().sampleRate });\n            const sourceNode = this._audioContext.createMediaStreamSource(new MediaStream([this._track]));\n            this._scriptProcessorNode = this._audioContext.createScriptProcessor(4096);\n            if (this._audioContext.state === 'suspended') {\n                await this._audioContext.resume();\n            }\n            sourceNode.connect(this._scriptProcessorNode);\n            this._scriptProcessorNode.connect(this._audioContext.destination);\n            let totalDuration = 0;\n            this._scriptProcessorNode.onaudioprocess = (event) => {\n                const iterator = AudioSample._fromAudioBuffer(event.inputBuffer, totalDuration);\n                totalDuration += event.inputBuffer.duration;\n                for (const audioSample of iterator) {\n                    onAudioSample(audioSample);\n                }\n            };\n        }\n    }\n    /**\n     * Pauses the capture of audio data - any audio data emitted by the underlying media stream will be ignored\n     * while paused. This does *not* close the underlying `MediaStreamAudioTrack`, it just ignores its output.\n     */\n    pause() {\n        this._paused = true;\n    }\n    /** Resumes the capture of audio data after being paused. */\n    resume() {\n        this._paused = false;\n    }\n    /** @internal */\n    async _flushAndClose(forceClose) {\n        if (this._abortController) {\n            this._abortController.abort();\n            this._abortController = null;\n        }\n        if (this._audioContext) {\n            assert(this._scriptProcessorNode);\n            this._scriptProcessorNode.disconnect();\n            await this._audioContext.suspend();\n        }\n        await this._encoder.flushAndClose(forceClose);\n    }\n}\nconst mediaStreamTrackProcessorWorkerCode = () => {\n    const sendMessage = (message, transfer) => {\n        if (transfer) {\n            self.postMessage(message, { transfer });\n        }\n        else {\n            self.postMessage(message);\n        }\n    };\n    // Immediately send a message to the main thread, letting them know of the support\n    sendMessage({\n        type: 'support',\n        supported: typeof MediaStreamTrackProcessor !== 'undefined',\n    });\n    const abortControllers = new Map();\n    const activeTracks = new Map();\n    self.addEventListener('message', (event) => {\n        const message = event.data;\n        switch (message.type) {\n            case 'videoTrack':\n                {\n                    activeTracks.set(message.trackId, message.track);\n                    const processor = new MediaStreamTrackProcessor({ track: message.track });\n                    const consumer = new WritableStream({\n                        write: (videoFrame) => {\n                            if (!activeTracks.has(message.trackId)) {\n                                videoFrame.close();\n                                return;\n                            }\n                            // Send it to the main thread\n                            sendMessage({\n                                type: 'videoFrame',\n                                trackId: message.trackId,\n                                videoFrame,\n                            }, [videoFrame]);\n                        },\n                    });\n                    const abortController = new AbortController();\n                    abortControllers.set(message.trackId, abortController);\n                    processor.readable.pipeTo(consumer, {\n                        signal: abortController.signal,\n                    }).catch((error) => {\n                        // Handle AbortError silently\n                        if (error instanceof DOMException && error.name === 'AbortError')\n                            return;\n                        sendMessage({\n                            type: 'error',\n                            trackId: message.trackId,\n                            error,\n                        });\n                    });\n                }\n                ;\n                break;\n            case 'stopTrack':\n                {\n                    const abortController = abortControllers.get(message.trackId);\n                    if (abortController) {\n                        abortController.abort();\n                        abortControllers.delete(message.trackId);\n                    }\n                    const track = activeTracks.get(message.trackId);\n                    track?.stop();\n                    activeTracks.delete(message.trackId);\n                    sendMessage({\n                        type: 'trackStopped',\n                        trackId: message.trackId,\n                    });\n                }\n                ;\n                break;\n            default: assertNever(message);\n        }\n    });\n};\nlet nextMediaStreamTrackProcessorWorkerId = 0;\nlet mediaStreamTrackProcessorWorker = null;\nconst initMediaStreamTrackProcessorWorker = () => {\n    const blob = new Blob([`(${mediaStreamTrackProcessorWorkerCode.toString()})()`], { type: 'application/javascript' });\n    const url = URL.createObjectURL(blob);\n    mediaStreamTrackProcessorWorker = new Worker(url);\n};\nlet mediaStreamTrackProcessorIsSupportedInWorkerCache = null;\nconst mediaStreamTrackProcessorIsSupportedInWorker = async () => {\n    if (mediaStreamTrackProcessorIsSupportedInWorkerCache !== null) {\n        return mediaStreamTrackProcessorIsSupportedInWorkerCache;\n    }\n    if (!mediaStreamTrackProcessorWorker) {\n        initMediaStreamTrackProcessorWorker();\n    }\n    return new Promise((resolve) => {\n        assert(mediaStreamTrackProcessorWorker);\n        const listener = (event) => {\n            const message = event.data;\n            if (message.type === 'support') {\n                mediaStreamTrackProcessorIsSupportedInWorkerCache = message.supported;\n                mediaStreamTrackProcessorWorker.removeEventListener('message', listener);\n                resolve(message.supported);\n            }\n        };\n        mediaStreamTrackProcessorWorker.addEventListener('message', listener);\n    });\n};\nconst sendMessageToMediaStreamTrackProcessorWorker = (message, transfer) => {\n    assert(mediaStreamTrackProcessorWorker);\n    if (transfer) {\n        mediaStreamTrackProcessorWorker.postMessage(message, transfer);\n    }\n    else {\n        mediaStreamTrackProcessorWorker.postMessage(message);\n    }\n};\n/**\n * Base class for subtitle sources - sources for subtitle tracks.\n * @group Media sources\n * @public\n */\nexport class SubtitleSource extends MediaSource {\n    /** Internal constructor. */\n    constructor(codec) {\n        super();\n        /** @internal */\n        this._connectedTrack = null;\n        if (!SUBTITLE_CODECS.includes(codec)) {\n            throw new TypeError(`Invalid subtitle codec '${codec}'. Must be one of: ${SUBTITLE_CODECS.join(', ')}.`);\n        }\n        this._codec = codec;\n    }\n}\n/**\n * This source can be used to add subtitles from a subtitle text file.\n * @group Media sources\n * @public\n */\nexport class TextSubtitleSource extends SubtitleSource {\n    /** Creates a new {@link TextSubtitleSource} where added text chunks are in the specified `codec`. */\n    constructor(codec) {\n        super(codec);\n        /** @internal */\n        this._error = null;\n        this._parser = new SubtitleParser({\n            codec,\n            output: (cue, metadata) => {\n                void this._connectedTrack?.output._muxer.addSubtitleCue(this._connectedTrack, cue, metadata)\n                    .catch((error) => {\n                    this._error ??= error;\n                });\n            },\n        });\n    }\n    /**\n     * Parses the subtitle text according to the specified codec and adds it to the output track. You don't have to\n     * add the entire subtitle file at once here; you can provide it in chunks.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(text) {\n        if (typeof text !== 'string') {\n            throw new TypeError('text must be a string.');\n        }\n        this._checkForError();\n        this._ensureValidAdd();\n        this._parser.parse(text);\n        return this._connectedTrack.output._muxer.mutex.currentPromise;\n    }\n    /** @internal */\n    _checkForError() {\n        if (this._error) {\n            throw this._error;\n        }\n    }\n    /** @internal */\n    async _flushAndClose(forceClose) {\n        if (!forceClose) {\n            this._checkForError();\n        }\n    }\n}\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nimport { AsyncMutex, isIso639Dash2LanguageCode } from './misc.js';\nimport { validateMetadataTags, validateTrackDisposition } from './metadata.js';\nimport { OutputFormat } from './output-format.js';\nimport { AudioSource, SubtitleSource, VideoSource } from './media-source.js';\nimport { Target } from './target.js';\n/**\n * List of all track types.\n * @group Miscellaneous\n * @public\n */\nexport const ALL_TRACK_TYPES = ['video', 'audio', 'subtitle'];\nconst validateBaseTrackMetadata = (metadata) => {\n    if (!metadata || typeof metadata !== 'object') {\n        throw new TypeError('metadata must be an object.');\n    }\n    if (metadata.languageCode !== undefined && !isIso639Dash2LanguageCode(metadata.languageCode)) {\n        throw new TypeError('metadata.languageCode, when provided, must be a three-letter, ISO 639-2/T language code.');\n    }\n    if (metadata.name !== undefined && typeof metadata.name !== 'string') {\n        throw new TypeError('metadata.name, when provided, must be a string.');\n    }\n    if (metadata.disposition !== undefined) {\n        validateTrackDisposition(metadata.disposition);\n    }\n    if (metadata.maximumPacketCount !== undefined\n        && (!Number.isInteger(metadata.maximumPacketCount) || metadata.maximumPacketCount < 0)) {\n        throw new TypeError('metadata.maximumPacketCount, when provided, must be a non-negative integer.');\n    }\n};\n/**\n * Main class orchestrating the creation of a new media file.\n * @group Output files\n * @public\n */\nexport class Output {\n    /**\n     * Creates a new instance of {@link Output} which can then be used to create a new media file according to the\n     * specified {@link OutputOptions}.\n     */\n    constructor(options) {\n        /** The current state of the output. */\n        this.state = 'pending';\n        /** @internal */\n        this._tracks = [];\n        /** @internal */\n        this._startPromise = null;\n        /** @internal */\n        this._cancelPromise = null;\n        /** @internal */\n        this._finalizePromise = null;\n        /** @internal */\n        this._mutex = new AsyncMutex();\n        /** @internal */\n        this._metadataTags = {};\n        if (!options || typeof options !== 'object') {\n            throw new TypeError('options must be an object.');\n        }\n        if (!(options.format instanceof OutputFormat)) {\n            throw new TypeError('options.format must be an OutputFormat.');\n        }\n        if (!(options.target instanceof Target)) {\n            throw new TypeError('options.target must be a Target.');\n        }\n        if (options.target._output) {\n            throw new Error('Target is already used for another output.');\n        }\n        options.target._output = this;\n        this.format = options.format;\n        this.target = options.target;\n        this._writer = options.target._createWriter();\n        this._muxer = options.format._createMuxer(this);\n    }\n    /** Adds a video track to the output with the given source. Can only be called before the output is started. */\n    addVideoTrack(source, metadata = {}) {\n        if (!(source instanceof VideoSource)) {\n            throw new TypeError('source must be a VideoSource.');\n        }\n        validateBaseTrackMetadata(metadata);\n        if (metadata.rotation !== undefined && ![0, 90, 180, 270].includes(metadata.rotation)) {\n            throw new TypeError(`Invalid video rotation: ${metadata.rotation}. Has to be 0, 90, 180 or 270.`);\n        }\n        if (!this.format.supportsVideoRotationMetadata && metadata.rotation) {\n            throw new Error(`${this.format._name} does not support video rotation metadata.`);\n        }\n        if (metadata.frameRate !== undefined\n            && (!Number.isFinite(metadata.frameRate) || metadata.frameRate <= 0)) {\n            throw new TypeError(`Invalid video frame rate: ${metadata.frameRate}. Must be a positive number.`);\n        }\n        this._addTrack('video', source, metadata);\n    }\n    /** Adds an audio track to the output with the given source. Can only be called before the output is started. */\n    addAudioTrack(source, metadata = {}) {\n        if (!(source instanceof AudioSource)) {\n            throw new TypeError('source must be an AudioSource.');\n        }\n        validateBaseTrackMetadata(metadata);\n        this._addTrack('audio', source, metadata);\n    }\n    /** Adds a subtitle track to the output with the given source. Can only be called before the output is started. */\n    addSubtitleTrack(source, metadata = {}) {\n        if (!(source instanceof SubtitleSource)) {\n            throw new TypeError('source must be a SubtitleSource.');\n        }\n        validateBaseTrackMetadata(metadata);\n        this._addTrack('subtitle', source, metadata);\n    }\n    /**\n     * Sets descriptive metadata tags about the media file, such as title, author, date, or cover art. When called\n     * multiple times, only the metadata from the last call will be used.\n     *\n     * Can only be called before the output is started.\n     */\n    setMetadataTags(tags) {\n        validateMetadataTags(tags);\n        if (this.state !== 'pending') {\n            throw new Error('Cannot set metadata tags after output has been started or canceled.');\n        }\n        this._metadataTags = tags;\n    }\n    /** @internal */\n    _addTrack(type, source, metadata) {\n        if (this.state !== 'pending') {\n            throw new Error('Cannot add track after output has been started or canceled.');\n        }\n        if (source._connectedTrack) {\n            throw new Error('Source is already used for a track.');\n        }\n        // Verify maximum track count constraints\n        const supportedTrackCounts = this.format.getSupportedTrackCounts();\n        const presentTracksOfThisType = this._tracks.reduce((count, track) => count + (track.type === type ? 1 : 0), 0);\n        const maxCount = supportedTrackCounts[type].max;\n        if (presentTracksOfThisType === maxCount) {\n            throw new Error(maxCount === 0\n                ? `${this.format._name} does not support ${type} tracks.`\n                : (`${this.format._name} does not support more than ${maxCount} ${type} track`\n                    + `${maxCount === 1 ? '' : 's'}.`));\n        }\n        const maxTotalCount = supportedTrackCounts.total.max;\n        if (this._tracks.length === maxTotalCount) {\n            throw new Error(`${this.format._name} does not support more than ${maxTotalCount} tracks`\n                + `${maxTotalCount === 1 ? '' : 's'} in total.`);\n        }\n        const track = {\n            id: this._tracks.length + 1,\n            output: this,\n            type,\n            source: source,\n            metadata,\n        };\n        if (track.type === 'video') {\n            const supportedVideoCodecs = this.format.getSupportedVideoCodecs();\n            if (supportedVideoCodecs.length === 0) {\n                throw new Error(`${this.format._name} does not support video tracks.`\n                    + this.format._codecUnsupportedHint(track.source._codec));\n            }\n            else if (!supportedVideoCodecs.includes(track.source._codec)) {\n                throw new Error(`Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported`\n                    + ` video codecs are: ${supportedVideoCodecs.map(codec => `'${codec}'`).join(', ')}.`\n                    + this.format._codecUnsupportedHint(track.source._codec));\n            }\n        }\n        else if (track.type === 'audio') {\n            const supportedAudioCodecs = this.format.getSupportedAudioCodecs();\n            if (supportedAudioCodecs.length === 0) {\n                throw new Error(`${this.format._name} does not support audio tracks.`\n                    + this.format._codecUnsupportedHint(track.source._codec));\n            }\n            else if (!supportedAudioCodecs.includes(track.source._codec)) {\n                throw new Error(`Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported`\n                    + ` audio codecs are: ${supportedAudioCodecs.map(codec => `'${codec}'`).join(', ')}.`\n                    + this.format._codecUnsupportedHint(track.source._codec));\n            }\n        }\n        else if (track.type === 'subtitle') {\n            const supportedSubtitleCodecs = this.format.getSupportedSubtitleCodecs();\n            if (supportedSubtitleCodecs.length === 0) {\n                throw new Error(`${this.format._name} does not support subtitle tracks.`\n                    + this.format._codecUnsupportedHint(track.source._codec));\n            }\n            else if (!supportedSubtitleCodecs.includes(track.source._codec)) {\n                throw new Error(`Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported`\n                    + ` subtitle codecs are: ${supportedSubtitleCodecs.map(codec => `'${codec}'`).join(', ')}.`\n                    + this.format._codecUnsupportedHint(track.source._codec));\n            }\n        }\n        this._tracks.push(track);\n        source._connectedTrack = track;\n    }\n    /**\n     * Starts the creation of the output file. This method should be called after all tracks have been added. Only after\n     * the output has started can media samples be added to the tracks.\n     *\n     * @returns A promise that resolves when the output has successfully started and is ready to receive media samples.\n     */\n    async start() {\n        // Verify minimum track count constraints\n        const supportedTrackCounts = this.format.getSupportedTrackCounts();\n        for (const trackType of ALL_TRACK_TYPES) {\n            const presentTracksOfThisType = this._tracks.reduce((count, track) => count + (track.type === trackType ? 1 : 0), 0);\n            const minCount = supportedTrackCounts[trackType].min;\n            if (presentTracksOfThisType < minCount) {\n                throw new Error(minCount === supportedTrackCounts[trackType].max\n                    ? (`${this.format._name} requires exactly ${minCount} ${trackType}`\n                        + ` track${minCount === 1 ? '' : 's'}.`)\n                    : (`${this.format._name} requires at least ${minCount} ${trackType}`\n                        + ` track${minCount === 1 ? '' : 's'}.`));\n            }\n        }\n        const totalMinCount = supportedTrackCounts.total.min;\n        if (this._tracks.length < totalMinCount) {\n            throw new Error(totalMinCount === supportedTrackCounts.total.max\n                ? (`${this.format._name} requires exactly ${totalMinCount} track`\n                    + `${totalMinCount === 1 ? '' : 's'}.`)\n                : (`${this.format._name} requires at least ${totalMinCount} track`\n                    + `${totalMinCount === 1 ? '' : 's'}.`));\n        }\n        if (this.state === 'canceled') {\n            throw new Error('Output has been canceled.');\n        }\n        if (this._startPromise) {\n            console.warn('Output has already been started.');\n            return this._startPromise;\n        }\n        return this._startPromise = (async () => {\n            this.state = 'started';\n            this._writer.start();\n            const release = await this._mutex.acquire();\n            await this._muxer.start();\n            const promises = this._tracks.map(track => track.source._start());\n            await Promise.all(promises);\n            release();\n        })();\n    }\n    /**\n     * Resolves with the full MIME type of the output file, including track codecs.\n     *\n     * The returned promise will resolve only once the precise codec strings of all tracks are known.\n     */\n    getMimeType() {\n        return this._muxer.getMimeType();\n    }\n    /**\n     * Cancels the creation of the output file, releasing internal resources like encoders and preventing further\n     * samples from being added.\n     *\n     * @returns A promise that resolves once all internal resources have been released.\n     */\n    async cancel() {\n        if (this._cancelPromise) {\n            console.warn('Output has already been canceled.');\n            return this._cancelPromise;\n        }\n        else if (this.state === 'finalizing' || this.state === 'finalized') {\n            console.warn('Output has already been finalized.');\n            return;\n        }\n        return this._cancelPromise = (async () => {\n            this.state = 'canceled';\n            const release = await this._mutex.acquire();\n            const promises = this._tracks.map(x => x.source._flushOrWaitForOngoingClose(true)); // Force close\n            await Promise.all(promises);\n            await this._writer.close();\n            release();\n        })();\n    }\n    /**\n     * Finalizes the output file. This method must be called after all media samples across all tracks have been added.\n     * Once the Promise returned by this method completes, the output file is ready.\n     */\n    async finalize() {\n        if (this.state === 'pending') {\n            throw new Error('Cannot finalize before starting.');\n        }\n        if (this.state === 'canceled') {\n            throw new Error('Cannot finalize after canceling.');\n        }\n        if (this._finalizePromise) {\n            console.warn('Output has already been finalized.');\n            return this._finalizePromise;\n        }\n        return this._finalizePromise = (async () => {\n            this.state = 'finalizing';\n            const release = await this._mutex.acquire();\n            const promises = this._tracks.map(x => x.source._flushOrWaitForOngoingClose(false));\n            await Promise.all(promises);\n            await this._muxer.finalize();\n            await this._writer.flush();\n            await this._writer.finalize();\n            this.state = 'finalized';\n            release();\n        })();\n    }\n}\n","var __dispose = Symbol.dispose || /* @__PURE__ */ Symbol.for(\"Symbol.dispose\");\nvar __asyncDispose = Symbol.asyncDispose || /* @__PURE__ */ Symbol.for(\"Symbol.asyncDispose\");\nvar __using = (stack, value, async) => {\n  if (value != null) {\n    if (typeof value !== \"object\" && typeof value !== \"function\")\n      throw TypeError('Object expected to be assigned to \"using\" declaration');\n    var dispose;\n    if (async)\n      dispose = value[__asyncDispose];\n    if (dispose === undefined)\n      dispose = value[__dispose];\n    if (typeof dispose !== \"function\")\n      throw TypeError(\"Object not disposable\");\n    stack.push([async, dispose, value]);\n  } else if (async) {\n    stack.push([async]);\n  }\n  return value;\n};\nvar __callDispose = (stack, error, hasError) => {\n  var E = typeof SuppressedError === \"function\" ? SuppressedError : function(e, s, m, _) {\n    return _ = Error(m), _.name = \"SuppressedError\", _.error = e, _.suppressed = s, _;\n  }, fail = (e) => error = hasError ? new E(e, error, \"An error was suppressed during disposal\") : (hasError = true, e), next = (it) => {\n    while (it = stack.pop()) {\n      try {\n        var result = it[1] && it[1].call(it[2]);\n        if (it[0])\n          return Promise.resolve(result).then(next, (e) => (fail(e), next()));\n      } catch (e) {\n        fail(e);\n      }\n    }\n    if (hasError)\n      throw error;\n  };\n  return next();\n};\n\n// src/can-render-media-on-web.ts\nimport { canEncodeVideo } from \"mediabunny\";\n\n// src/can-use-webfs-target.ts\nvar canUseWebFsWriter = async () => {\n  if (!(\"storage\" in navigator)) {\n    return false;\n  }\n  if (!(\"getDirectory\" in navigator.storage)) {\n    return false;\n  }\n  try {\n    const directoryHandle = await navigator.storage.getDirectory();\n    const fileHandle = await directoryHandle.getFileHandle(\"remotion-probe-web-fs-support\", {\n      create: true\n    });\n    const canUse = fileHandle.createWritable !== undefined;\n    return canUse;\n  } catch {\n    return false;\n  }\n};\n\n// src/check-webgl-support.ts\nvar checkWebGLSupport = () => {\n  try {\n    const canvas = new OffscreenCanvas(1, 1);\n    const gl = canvas.getContext(\"webgl2\") || canvas.getContext(\"webgl\");\n    if (!gl) {\n      return {\n        type: \"webgl-unsupported\",\n        message: \"WebGL is not supported. 3D CSS transforms will fail.\",\n        severity: \"error\"\n      };\n    }\n    return null;\n  } catch {\n    return {\n      type: \"webgl-unsupported\",\n      message: \"WebGL is not supported. 3D CSS transforms will fail.\",\n      severity: \"error\"\n    };\n  }\n};\n\n// src/mediabunny-mappings.ts\nimport {\n  Mp4OutputFormat,\n  QUALITY_HIGH,\n  QUALITY_LOW,\n  QUALITY_MEDIUM,\n  QUALITY_VERY_HIGH,\n  QUALITY_VERY_LOW,\n  WebMOutputFormat\n} from \"mediabunny\";\nvar codecToMediabunnyCodec = (codec) => {\n  switch (codec) {\n    case \"h264\":\n      return \"avc\";\n    case \"h265\":\n      return \"hevc\";\n    case \"vp8\":\n      return \"vp8\";\n    case \"vp9\":\n      return \"vp9\";\n    case \"av1\":\n      return \"av1\";\n    default:\n      throw new Error(`Unsupported codec: ${codec}`);\n  }\n};\nvar containerToMediabunnyContainer = (container) => {\n  switch (container) {\n    case \"mp4\":\n      return new Mp4OutputFormat;\n    case \"webm\":\n      return new WebMOutputFormat;\n    default:\n      throw new Error(`Unsupported container: ${container}`);\n  }\n};\nvar getDefaultVideoCodecForContainer = (container) => {\n  switch (container) {\n    case \"mp4\":\n      return \"h264\";\n    case \"webm\":\n      return \"vp8\";\n    default:\n      throw new Error(`Unsupported container: ${container}`);\n  }\n};\nvar getQualityForWebRendererQuality = (quality) => {\n  switch (quality) {\n    case \"very-low\":\n      return QUALITY_VERY_LOW;\n    case \"low\":\n      return QUALITY_LOW;\n    case \"medium\":\n      return QUALITY_MEDIUM;\n    case \"high\":\n      return QUALITY_HIGH;\n    case \"very-high\":\n      return QUALITY_VERY_HIGH;\n    default:\n      throw new Error(`Unsupported quality: ${quality}`);\n  }\n};\nvar getMimeType = (container) => {\n  switch (container) {\n    case \"mp4\":\n      return \"video/mp4\";\n    case \"webm\":\n      return \"video/webm\";\n    default:\n      throw new Error(`Unsupported container: ${container}`);\n  }\n};\nvar getDefaultAudioCodecForContainer = (container) => {\n  switch (container) {\n    case \"mp4\":\n      return \"aac\";\n    case \"webm\":\n      return \"opus\";\n    default:\n      throw new Error(`Unsupported container: ${container}`);\n  }\n};\nvar WEB_RENDERER_VIDEO_CODECS = [\n  \"h264\",\n  \"h265\",\n  \"vp8\",\n  \"vp9\",\n  \"av1\"\n];\nvar getSupportedVideoCodecsForContainer = (container) => {\n  const format = containerToMediabunnyContainer(container);\n  const allSupported = format.getSupportedVideoCodecs();\n  return WEB_RENDERER_VIDEO_CODECS.filter((codec) => allSupported.includes(codecToMediabunnyCodec(codec)));\n};\nvar WEB_RENDERER_AUDIO_CODECS = [\"aac\", \"opus\"];\nvar getSupportedAudioCodecsForContainer = (container) => {\n  const format = containerToMediabunnyContainer(container);\n  const allSupported = format.getSupportedAudioCodecs();\n  return WEB_RENDERER_AUDIO_CODECS.filter((codec) => allSupported.includes(codec));\n};\nvar audioCodecToMediabunnyAudioCodec = (audioCodec) => {\n  return audioCodec;\n};\n\n// src/resolve-audio-codec.ts\nimport { canEncodeAudio } from \"mediabunny\";\nvar resolveAudioCodec = async (options) => {\n  const issues = [];\n  const { container, requestedCodec, userSpecifiedAudioCodec, bitrate } = options;\n  const audioCodec = requestedCodec ?? getDefaultAudioCodecForContainer(container);\n  const supportedAudioCodecs = getSupportedAudioCodecsForContainer(container);\n  if (!supportedAudioCodecs.includes(audioCodec)) {\n    issues.push({\n      type: \"audio-codec-unsupported\",\n      message: `Audio codec \"${audioCodec}\" is not supported for container \"${container}\". Supported: ${supportedAudioCodecs.join(\", \")}`,\n      severity: \"error\"\n    });\n    return { codec: null, issues };\n  }\n  const mediabunnyAudioCodec = audioCodecToMediabunnyAudioCodec(audioCodec);\n  const canEncode = await canEncodeAudio(mediabunnyAudioCodec, { bitrate });\n  if (canEncode) {\n    return { codec: audioCodec, issues };\n  }\n  if (userSpecifiedAudioCodec) {\n    issues.push({\n      type: \"audio-codec-unsupported\",\n      message: `Audio codec \"${audioCodec}\" cannot be encoded by this browser. This is common for AAC on Firefox. Try using \"opus\" instead.`,\n      severity: \"error\"\n    });\n    return { codec: null, issues };\n  }\n  for (const fallbackCodec of supportedAudioCodecs) {\n    if (fallbackCodec !== audioCodec) {\n      const fallbackMediabunnyCodec = audioCodecToMediabunnyAudioCodec(fallbackCodec);\n      const canEncodeFallback = await canEncodeAudio(fallbackMediabunnyCodec, {\n        bitrate\n      });\n      if (canEncodeFallback) {\n        issues.push({\n          type: \"audio-codec-unsupported\",\n          message: `Falling back from audio codec \"${audioCodec}\" to \"${fallbackCodec}\" because the original codec cannot be encoded by this browser.`,\n          severity: \"warning\"\n        });\n        return { codec: fallbackCodec, issues };\n      }\n    }\n  }\n  issues.push({\n    type: \"audio-codec-unsupported\",\n    message: `No audio codec can be encoded by this browser for container \"${container}\".`,\n    severity: \"error\"\n  });\n  return { codec: null, issues };\n};\n\n// src/validate-dimensions.ts\nvar validateDimensions = (options) => {\n  const { width, height, codec } = options;\n  if (codec === \"h264\" || codec === \"h265\") {\n    if (width % 2 !== 0 || height % 2 !== 0) {\n      return {\n        type: \"invalid-dimensions\",\n        message: `${codec.toUpperCase()} codec requires width and height to be multiples of 2. Got ${width}x${height}`,\n        severity: \"error\"\n      };\n    }\n  }\n  return null;\n};\n\n// src/can-render-media-on-web.ts\nvar canRenderMediaOnWeb = async (options) => {\n  const issues = [];\n  if (typeof VideoEncoder === \"undefined\") {\n    issues.push({\n      type: \"webcodecs-unavailable\",\n      message: \"WebCodecs API is not available in this browser. A modern browser with WebCodecs support is required.\",\n      severity: \"error\"\n    });\n  }\n  const container = options.container ?? \"mp4\";\n  const videoCodec = options.videoCodec ?? getDefaultVideoCodecForContainer(container);\n  const transparent = options.transparent ?? false;\n  const muted = options.muted ?? false;\n  const { width, height } = options;\n  const resolvedVideoBitrate = typeof options.videoBitrate === \"number\" ? options.videoBitrate : getQualityForWebRendererQuality(options.videoBitrate ?? \"medium\");\n  const resolvedAudioBitrate = typeof options.audioBitrate === \"number\" ? options.audioBitrate : getQualityForWebRendererQuality(options.audioBitrate ?? \"medium\");\n  const format = containerToMediabunnyContainer(container);\n  if (!format.getSupportedCodecs().includes(codecToMediabunnyCodec(videoCodec))) {\n    issues.push({\n      type: \"container-codec-mismatch\",\n      message: `Codec ${videoCodec} is not supported for container ${container}`,\n      severity: \"error\"\n    });\n  }\n  const dimensionIssue = validateDimensions({ width, height, codec: videoCodec });\n  if (dimensionIssue) {\n    issues.push(dimensionIssue);\n  }\n  const canEncodeVideoResult = await canEncodeVideo(codecToMediabunnyCodec(videoCodec), { bitrate: resolvedVideoBitrate });\n  if (!canEncodeVideoResult) {\n    issues.push({\n      type: \"video-codec-unsupported\",\n      message: `Video codec \"${videoCodec}\" cannot be encoded by this browser`,\n      severity: \"error\"\n    });\n  }\n  if (transparent && ![\"vp8\", \"vp9\"].includes(videoCodec)) {\n    issues.push({\n      type: \"transparent-video-unsupported\",\n      message: `Transparent video requires VP8 or VP9 codec with WebM container. ${videoCodec} does not support alpha channel.`,\n      severity: \"error\"\n    });\n  }\n  let resolvedAudioCodec = null;\n  if (!muted) {\n    const audioResult = await resolveAudioCodec({\n      container,\n      requestedCodec: options.audioCodec,\n      userSpecifiedAudioCodec: options.audioCodec !== undefined && options.audioCodec !== null,\n      bitrate: resolvedAudioBitrate\n    });\n    resolvedAudioCodec = audioResult.codec;\n    issues.push(...audioResult.issues);\n  }\n  const webglIssue = checkWebGLSupport();\n  if (webglIssue) {\n    issues.push(webglIssue);\n  }\n  const canUseWebFs = await canUseWebFsWriter();\n  let resolvedOutputTarget;\n  if (options.outputTarget === \"web-fs\") {\n    if (!canUseWebFs) {\n      issues.push({\n        type: \"output-target-unsupported\",\n        message: 'The \"web-fs\" output target is not supported in this browser. The File System Access API is required.',\n        severity: \"error\"\n      });\n    }\n    resolvedOutputTarget = \"web-fs\";\n  } else if (options.outputTarget === \"arraybuffer\") {\n    resolvedOutputTarget = \"arraybuffer\";\n  } else {\n    resolvedOutputTarget = canUseWebFs ? \"web-fs\" : \"arraybuffer\";\n  }\n  return {\n    canRender: issues.filter((i) => i.severity === \"error\").length === 0,\n    issues,\n    resolvedVideoCodec: videoCodec,\n    resolvedAudioCodec,\n    resolvedOutputTarget\n  };\n};\n// src/get-encodable-codecs.ts\nimport {\n  getEncodableAudioCodecs as mediabunnyGetEncodableAudioCodecs,\n  getEncodableVideoCodecs as mediabunnyGetEncodableVideoCodecs\n} from \"mediabunny\";\nvar getEncodableVideoCodecs = async (container, options) => {\n  const supported = getSupportedVideoCodecsForContainer(container);\n  const mediabunnyCodecs = supported.map(codecToMediabunnyCodec);\n  const resolvedBitrate = options?.videoBitrate ? typeof options.videoBitrate === \"number\" ? options.videoBitrate : getQualityForWebRendererQuality(options.videoBitrate) : undefined;\n  const encodable = await mediabunnyGetEncodableVideoCodecs(mediabunnyCodecs, {\n    bitrate: resolvedBitrate\n  });\n  return supported.filter((c) => encodable.includes(codecToMediabunnyCodec(c)));\n};\nvar getEncodableAudioCodecs = async (container, options) => {\n  const supported = getSupportedAudioCodecsForContainer(container);\n  const resolvedBitrate = options?.audioBitrate ? typeof options.audioBitrate === \"number\" ? options.audioBitrate : getQualityForWebRendererQuality(options.audioBitrate) : undefined;\n  const encodable = await mediabunnyGetEncodableAudioCodecs(supported, {\n    bitrate: resolvedBitrate\n  });\n  return supported.filter((c) => encodable.includes(c));\n};\n// src/render-media-on-web.tsx\nimport { BufferTarget, StreamTarget } from \"mediabunny\";\nimport { Internals as Internals8 } from \"remotion\";\n\n// src/add-sample.ts\nimport { AudioSample, VideoSample } from \"mediabunny\";\nvar addVideoSampleAndCloseFrame = async (frameToEncode, videoSampleSource) => {\n  const sample = new VideoSample(frameToEncode);\n  try {\n    await videoSampleSource.add(sample);\n  } finally {\n    sample.close();\n    frameToEncode.close();\n  }\n};\nvar addAudioSample = async (audio, audioSampleSource) => {\n  const sample = new AudioSample(audio);\n  try {\n    await audioSampleSource.add(sample);\n  } finally {\n    sample.close();\n  }\n};\n\n// src/artifact.ts\nimport { NoReactInternals } from \"remotion/no-react\";\nvar onlyArtifact = async ({\n  assets,\n  frameBuffer\n}) => {\n  const artifacts = assets.filter((asset) => asset.type === \"artifact\");\n  let frameBufferUint8 = null;\n  const result = [];\n  for (const artifact of artifacts) {\n    if (artifact.contentType === \"binary\" || artifact.contentType === \"text\") {\n      result.push({\n        frame: artifact.frame,\n        content: artifact.content,\n        filename: artifact.filename,\n        downloadBehavior: artifact.downloadBehavior\n      });\n      continue;\n    }\n    if (artifact.contentType === \"thumbnail\") {\n      if (frameBuffer === null) {\n        continue;\n      }\n      const ab = frameBuffer instanceof Blob ? await frameBuffer.arrayBuffer() : new Uint8Array(await (await frameBuffer.convertToBlob({ type: \"image/png\" })).arrayBuffer());\n      frameBufferUint8 = new Uint8Array(ab);\n      result.push({\n        frame: artifact.frame,\n        content: frameBufferUint8,\n        filename: artifact.filename,\n        downloadBehavior: artifact.downloadBehavior\n      });\n      continue;\n    }\n    throw new Error(\"Unknown artifact type: \" + artifact);\n  }\n  return result.filter(NoReactInternals.truthy);\n};\nvar handleArtifacts = () => {\n  const previousArtifacts = [];\n  const handle = async ({\n    imageData,\n    frame,\n    assets: artifactAssets,\n    onArtifact\n  }) => {\n    const artifacts = await onlyArtifact({\n      assets: artifactAssets,\n      frameBuffer: imageData\n    });\n    for (const artifact of artifacts) {\n      const previousArtifact = previousArtifacts.find((a) => a.filename === artifact.filename);\n      if (previousArtifact) {\n        throw new Error(`An artifact with output \"${artifact.filename}\" was already registered at frame ${previousArtifact.frame}, but now registered again at frame ${frame}. Artifacts must have unique names. https://remotion.dev/docs/artifacts`);\n      }\n      onArtifact(artifact);\n      previousArtifacts.push({ frame, filename: artifact.filename });\n    }\n  };\n  return { handle };\n};\n\n// src/audio.ts\nvar TARGET_NUMBER_OF_CHANNELS = 2;\nvar TARGET_SAMPLE_RATE = 48000;\nfunction mixAudio(waves, length) {\n  if (waves.length === 1 && waves[0].length === length) {\n    return waves[0];\n  }\n  const mixed = new Int16Array(length);\n  if (waves.length === 1) {\n    mixed.set(waves[0].subarray(0, length));\n    return mixed;\n  }\n  for (let i = 0;i < length; i++) {\n    const sum = waves.reduce((acc, wave) => {\n      return acc + (wave[i] ?? 0);\n    }, 0);\n    mixed[i] = Math.max(-32768, Math.min(32767, sum));\n  }\n  return mixed;\n}\nvar onlyInlineAudio = ({\n  assets,\n  fps,\n  timestamp\n}) => {\n  const inlineAudio = assets.filter((asset) => asset.type === \"inline-audio\");\n  if (inlineAudio.length === 0) {\n    return null;\n  }\n  const expectedLength = Math.round(TARGET_NUMBER_OF_CHANNELS * TARGET_SAMPLE_RATE / fps);\n  for (const asset of inlineAudio) {\n    if (asset.toneFrequency !== 1) {\n      throw new Error(\"Setting the toneFrequency is not supported yet in web rendering.\");\n    }\n  }\n  const mixedAudio = mixAudio(inlineAudio.map((asset) => asset.audio), expectedLength);\n  return new AudioData({\n    data: mixedAudio,\n    format: \"s16\",\n    numberOfChannels: TARGET_NUMBER_OF_CHANNELS,\n    numberOfFrames: expectedLength / TARGET_NUMBER_OF_CHANNELS,\n    sampleRate: TARGET_SAMPLE_RATE,\n    timestamp\n  });\n};\n\n// src/background-keepalive.ts\nimport { Internals } from \"remotion\";\nvar WORKER_CODE = `\nlet intervalId = null;\nself.onmessage = (e) => {\n\tif (e.data.type === 'start') {\n\t\tif (intervalId !== null) {\n\t\t\tclearInterval(intervalId);\n\t\t}\n\t\tintervalId = setInterval(() => self.postMessage('tick'), e.data.intervalMs);\n\t} else if (e.data.type === 'stop') {\n\t\tif (intervalId !== null) {\n\t\t\tclearInterval(intervalId);\n\t\t\tintervalId = null;\n\t\t}\n\t}\n};\n`;\nfunction createBackgroundKeepalive({\n  fps,\n  logLevel\n}) {\n  const intervalMs = Math.round(1000 / fps);\n  let pendingResolvers = [];\n  let worker = null;\n  let disposed = false;\n  if (typeof Worker === \"undefined\") {\n    Internals.Log.warn({ logLevel, tag: \"@remotion/web-renderer\" }, \"Web Workers not available. Rendering may pause when tab is backgrounded.\");\n    return {\n      waitForTick: () => {\n        return new Promise((resolve) => {\n          setTimeout(resolve, intervalMs);\n        });\n      },\n      [Symbol.dispose]: () => {}\n    };\n  }\n  const blob = new Blob([WORKER_CODE], { type: \"application/javascript\" });\n  const workerUrl = URL.createObjectURL(blob);\n  worker = new Worker(workerUrl);\n  worker.onmessage = () => {\n    const resolvers = pendingResolvers;\n    pendingResolvers = [];\n    for (const resolve of resolvers) {\n      resolve();\n    }\n  };\n  worker.onerror = (event) => {\n    Internals.Log.error({ logLevel, tag: \"@remotion/web-renderer\" }, \"Background keepalive worker encountered an error and will be terminated.\", event);\n    const resolvers = pendingResolvers;\n    pendingResolvers = [];\n    for (const resolve of resolvers) {\n      resolve();\n    }\n    if (!disposed) {\n      disposed = true;\n      worker?.terminate();\n      worker = null;\n      URL.revokeObjectURL(workerUrl);\n    }\n  };\n  worker.postMessage({ type: \"start\", intervalMs });\n  return {\n    waitForTick: () => {\n      return new Promise((resolve) => {\n        pendingResolvers.push(resolve);\n      });\n    },\n    [Symbol.dispose]: () => {\n      if (disposed) {\n        return;\n      }\n      disposed = true;\n      worker?.postMessage({ type: \"stop\" });\n      worker?.terminate();\n      worker = null;\n      URL.revokeObjectURL(workerUrl);\n      const resolvers = pendingResolvers;\n      pendingResolvers = [];\n      for (const resolve of resolvers) {\n        resolve();\n      }\n    }\n  };\n}\n\n// src/create-audio-sample-source.ts\nimport { AudioSampleSource } from \"mediabunny\";\nvar createAudioSampleSource = ({\n  muted,\n  codec,\n  bitrate\n}) => {\n  if (muted || codec === null) {\n    return null;\n  }\n  const audioSampleSource = new AudioSampleSource({\n    codec,\n    bitrate\n  });\n  return { audioSampleSource, [Symbol.dispose]: () => audioSampleSource.close() };\n};\n\n// src/create-scaffold.tsx\nimport { createRef } from \"react\";\nimport { flushSync as flushSync2 } from \"react-dom\";\nimport ReactDOM from \"react-dom/client\";\nimport { Internals as Internals3 } from \"remotion\";\n\n// src/update-time.tsx\nimport { useImperativeHandle, useState } from \"react\";\nimport { flushSync } from \"react-dom\";\nimport { Internals as Internals2 } from \"remotion\";\nimport { jsx } from \"react/jsx-runtime\";\nvar UpdateTime = ({\n  children,\n  audioEnabled,\n  videoEnabled,\n  logLevel,\n  compId,\n  initialFrame,\n  timeUpdater\n}) => {\n  const [frame, setFrame] = useState(initialFrame);\n  useImperativeHandle(timeUpdater, () => ({\n    update: (f) => {\n      flushSync(() => {\n        setFrame(f);\n      });\n    }\n  }));\n  return /* @__PURE__ */ jsx(Internals2.RemotionRootContexts, {\n    audioEnabled,\n    videoEnabled,\n    logLevel,\n    numberOfAudioTags: 0,\n    audioLatencyHint: \"interactive\",\n    frameState: {\n      [compId]: frame\n    },\n    children\n  });\n};\n\n// src/create-scaffold.tsx\nimport { jsx as jsx2 } from \"react/jsx-runtime\";\nfunction checkForError(errorHolder) {\n  if (errorHolder.error) {\n    throw errorHolder.error;\n  }\n}\nfunction createScaffold({\n  width,\n  height,\n  delayRenderTimeoutInMilliseconds,\n  logLevel,\n  resolvedProps,\n  id,\n  mediaCacheSizeInBytes,\n  durationInFrames,\n  fps,\n  initialFrame,\n  schema,\n  Component,\n  audioEnabled,\n  videoEnabled,\n  defaultCodec,\n  defaultOutName\n}) {\n  if (!ReactDOM.createRoot) {\n    throw new Error(\"@remotion/web-renderer requires React 18 or higher\");\n  }\n  const div = document.createElement(\"div\");\n  div.style.position = \"fixed\";\n  div.style.display = \"flex\";\n  div.style.flexDirection = \"column\";\n  div.style.backgroundColor = \"transparent\";\n  div.style.width = `${width}px`;\n  div.style.height = `${height}px`;\n  div.style.zIndex = \"-9999\";\n  div.style.top = \"0\";\n  div.style.left = \"0\";\n  div.style.right = \"0\";\n  div.style.bottom = \"0\";\n  div.style.visibility = \"hidden\";\n  div.style.pointerEvents = \"none\";\n  const scaffoldClassName = `remotion-scaffold-${Math.random().toString(36).substring(2, 15)}`;\n  div.className = scaffoldClassName;\n  const cleanupCSS = Internals3.CSSUtils.injectCSS(Internals3.CSSUtils.makeDefaultPreviewCSS(`.${scaffoldClassName}`, \"white\"));\n  document.body.appendChild(div);\n  const errorHolder = { error: null };\n  const root = ReactDOM.createRoot(div, {\n    onUncaughtError: (err) => {\n      errorHolder.error = err instanceof Error ? err : new Error(String(err));\n    }\n  });\n  const delayRenderScope = {\n    remotion_renderReady: true,\n    remotion_delayRenderTimeouts: {},\n    remotion_puppeteerTimeout: delayRenderTimeoutInMilliseconds,\n    remotion_attempt: 0,\n    remotion_delayRenderHandles: []\n  };\n  const timeUpdater = createRef();\n  const collectAssets = createRef();\n  flushSync2(() => {\n    root.render(/* @__PURE__ */ jsx2(Internals3.MaxMediaCacheSizeContext.Provider, {\n      value: mediaCacheSizeInBytes,\n      children: /* @__PURE__ */ jsx2(Internals3.RemotionEnvironmentContext.Provider, {\n        value: {\n          isStudio: false,\n          isRendering: true,\n          isPlayer: false,\n          isReadOnlyStudio: false,\n          isClientSideRendering: true\n        },\n        children: /* @__PURE__ */ jsx2(Internals3.DelayRenderContextType.Provider, {\n          value: delayRenderScope,\n          children: /* @__PURE__ */ jsx2(Internals3.CompositionManager.Provider, {\n            value: {\n              compositions: [\n                {\n                  id,\n                  component: Component,\n                  nonce: 0,\n                  defaultProps: {},\n                  folderName: null,\n                  parentFolderName: null,\n                  schema: schema ?? null,\n                  calculateMetadata: null,\n                  durationInFrames,\n                  fps,\n                  height,\n                  width\n                }\n              ],\n              canvasContent: {\n                type: \"composition\",\n                compositionId: id\n              },\n              currentCompositionMetadata: {\n                props: resolvedProps,\n                durationInFrames,\n                fps,\n                height,\n                width,\n                defaultCodec: defaultCodec ?? null,\n                defaultOutName: defaultOutName ?? null,\n                defaultVideoImageFormat: null,\n                defaultPixelFormat: null,\n                defaultProResProfile: null\n              },\n              folders: []\n            },\n            children: /* @__PURE__ */ jsx2(Internals3.RenderAssetManagerProvider, {\n              collectAssets,\n              children: /* @__PURE__ */ jsx2(UpdateTime, {\n                audioEnabled,\n                videoEnabled,\n                logLevel,\n                compId: id,\n                initialFrame,\n                timeUpdater,\n                children: /* @__PURE__ */ jsx2(Internals3.CanUseRemotionHooks.Provider, {\n                  value: true,\n                  children: /* @__PURE__ */ jsx2(Component, {\n                    ...resolvedProps\n                  })\n                })\n              })\n            })\n          })\n        })\n      })\n    }));\n  });\n  return {\n    delayRenderScope,\n    div,\n    errorHolder,\n    [Symbol.dispose]: () => {\n      root.unmount();\n      div.remove();\n      cleanupCSS();\n    },\n    timeUpdater,\n    collectAssets\n  };\n}\n\n// src/frame-range.ts\nvar getRealFrameRange = (durationInFrames, frameRange) => {\n  if (frameRange === null) {\n    return [0, durationInFrames - 1];\n  }\n  if (typeof frameRange === \"number\") {\n    if (frameRange < 0 || frameRange >= durationInFrames) {\n      throw new Error(`Frame number is out of range, must be between 0 and ${durationInFrames - 1} but got ${frameRange}`);\n    }\n    return [frameRange, frameRange];\n  }\n  if (frameRange[1] >= durationInFrames || frameRange[0] < 0) {\n    throw new Error(`The \"durationInFrames\" of the composition was evaluated to be ${durationInFrames}, but frame range ${frameRange.join(\"-\")} is not inbetween 0-${durationInFrames - 1}`);\n  }\n  return frameRange;\n};\n\n// src/internal-state.ts\nvar makeInternalState = () => {\n  let drawnPrecomposedPixels = 0;\n  let precomposedTextures = 0;\n  let waitForReadyTime = 0;\n  let addSampleTime = 0;\n  let createFrameTime = 0;\n  let audioMixingTime = 0;\n  const helperCanvasState = {\n    current: null\n  };\n  return {\n    getDrawn3dPixels: () => drawnPrecomposedPixels,\n    getPrecomposedTiles: () => precomposedTextures,\n    addPrecompose: ({\n      canvasWidth,\n      canvasHeight\n    }) => {\n      drawnPrecomposedPixels += canvasWidth * canvasHeight;\n      precomposedTextures++;\n    },\n    helperCanvasState,\n    [Symbol.dispose]: () => {\n      if (helperCanvasState.current) {\n        helperCanvasState.current.cleanup();\n      }\n    },\n    getWaitForReadyTime: () => waitForReadyTime,\n    addWaitForReadyTime: (time) => {\n      waitForReadyTime += time;\n    },\n    getAddSampleTime: () => addSampleTime,\n    addAddSampleTime: (time) => {\n      addSampleTime += time;\n    },\n    getCreateFrameTime: () => createFrameTime,\n    addCreateFrameTime: (time) => {\n      createFrameTime += time;\n    },\n    getAudioMixingTime: () => audioMixingTime,\n    addAudioMixingTime: (time) => {\n      audioMixingTime += time;\n    }\n  };\n};\n\n// src/mediabunny-cleanups.ts\nimport { Output, VideoSampleSource } from \"mediabunny\";\nvar makeOutputWithCleanup = (options) => {\n  const output = new Output(options);\n  return {\n    output,\n    [Symbol.dispose]: () => {\n      if (output.state === \"finalized\" || output.state === \"canceled\") {\n        return;\n      }\n      output.cancel();\n    }\n  };\n};\nvar makeVideoSampleSourceCleanup = (encodingConfig) => {\n  const videoSampleSource = new VideoSampleSource(encodingConfig);\n  return {\n    videoSampleSource,\n    [Symbol.dispose]: () => {\n      videoSampleSource.close();\n    }\n  };\n};\n\n// src/render-operations-queue.ts\nvar onlyOneRenderAtATimeQueue = {\n  ref: Promise.resolve()\n};\n\n// ../licensing/dist/esm/index.mjs\nfunction isNetworkError(error) {\n  if (error.message.includes(\"Failed to fetch\") || error.message.includes(\"Load failed\") || error.message.includes(\"NetworkError when attempting to fetch resource\")) {\n    return true;\n  }\n  return false;\n}\nvar HOST = \"https://www.remotion.pro\";\nvar DEFAULT_MAX_RETRIES = 3;\nvar exponentialBackoffMs = (attempt) => {\n  return 1000 * 2 ** (attempt - 1);\n};\nvar sleep = (ms) => {\n  return new Promise((resolve) => {\n    setTimeout(resolve, ms);\n  });\n};\nvar registerUsageEvent = async ({\n  host,\n  succeeded,\n  event,\n  ...apiOrLicenseKey\n}) => {\n  const apiKey = \"apiKey\" in apiOrLicenseKey ? apiOrLicenseKey.apiKey : null;\n  const licenseKey = \"licenseKey\" in apiOrLicenseKey ? apiOrLicenseKey.licenseKey : null;\n  let lastError;\n  const totalAttempts = DEFAULT_MAX_RETRIES + 1;\n  for (let attempt = 1;attempt <= totalAttempts; attempt++) {\n    const abortController = new AbortController;\n    const timeout = setTimeout(() => {\n      abortController.abort();\n    }, 1e4);\n    try {\n      const res = await fetch(`${HOST}/api/track/register-usage-point`, {\n        method: \"POST\",\n        body: JSON.stringify({\n          event,\n          apiKey: licenseKey ?? apiKey,\n          host,\n          succeeded\n        }),\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        signal: abortController.signal\n      });\n      clearTimeout(timeout);\n      const json = await res.json();\n      if (json.success) {\n        return {\n          billable: json.billable,\n          classification: json.classification\n        };\n      }\n      if (!res.ok) {\n        throw new Error(json.error);\n      }\n      throw new Error(`Unexpected response from server: ${JSON.stringify(json)}`);\n    } catch (err) {\n      clearTimeout(timeout);\n      const error = err;\n      const isTimeout = error.name === \"AbortError\";\n      const isRetryable = isNetworkError(error) || isTimeout;\n      if (!isRetryable) {\n        throw err;\n      }\n      lastError = isTimeout ? new Error(\"Request timed out after 10 seconds\") : error;\n      if (attempt < totalAttempts) {\n        const backoffMs = exponentialBackoffMs(attempt);\n        console.log(`Failed to send usage event (attempt ${attempt}/${totalAttempts}), retrying in ${backoffMs}ms...`, err);\n        await sleep(backoffMs);\n      }\n    }\n  }\n  throw lastError;\n};\n\n// src/send-telemetry-event.ts\nimport { Internals as Internals4 } from \"remotion\";\nvar sendUsageEvent = async ({\n  licenseKey,\n  succeeded,\n  apiName\n}) => {\n  const host = typeof window === \"undefined\" ? null : typeof window.location === \"undefined\" ? null : window.location.origin ?? null;\n  if (host === null) {\n    return;\n  }\n  if (licenseKey === null) {\n    Internals4.Log.warn({ logLevel: \"warn\", tag: \"web-renderer\" }, `Pass \"licenseKey\" to ${apiName}(). If you qualify for the Free License (https://remotion.dev/license), pass \"free-license\" instead.`);\n  }\n  await registerUsageEvent({\n    licenseKey: licenseKey === \"free-license\" ? null : licenseKey,\n    event: \"webcodec-conversion\",\n    host,\n    succeeded\n  });\n};\n\n// src/tree-walker-cleanup-after-children.ts\nvar createTreeWalkerCleanupAfterChildren = (treeWalker) => {\n  const cleanupAfterChildren = [];\n  const checkCleanUpAtBeginningOfIteration = () => {\n    for (let i = 0;i < cleanupAfterChildren.length; ) {\n      const cleanup = cleanupAfterChildren[i];\n      if (!(cleanup.element === treeWalker.currentNode || cleanup.element.contains(treeWalker.currentNode))) {\n        cleanup.cleanupFn();\n        cleanupAfterChildren.splice(i, 1);\n      } else {\n        i++;\n      }\n    }\n  };\n  const addCleanup = (element, cleanupFn) => {\n    cleanupAfterChildren.unshift({\n      element,\n      cleanupFn\n    });\n  };\n  const cleanupInTheEndOfTheIteration = () => {\n    for (const cleanup of cleanupAfterChildren) {\n      cleanup.cleanupFn();\n    }\n  };\n  return {\n    checkCleanUpAtBeginningOfIteration,\n    addCleanup,\n    [Symbol.dispose]: cleanupInTheEndOfTheIteration\n  };\n};\n\n// src/drawing/calculate-object-fit.ts\nvar calculateFill = ({\n  containerSize,\n  intrinsicSize\n}) => {\n  return {\n    sourceX: 0,\n    sourceY: 0,\n    sourceWidth: intrinsicSize.width,\n    sourceHeight: intrinsicSize.height,\n    destX: containerSize.left,\n    destY: containerSize.top,\n    destWidth: containerSize.width,\n    destHeight: containerSize.height\n  };\n};\nvar calculateContain = ({\n  containerSize,\n  intrinsicSize\n}) => {\n  const containerAspect = containerSize.width / containerSize.height;\n  const imageAspect = intrinsicSize.width / intrinsicSize.height;\n  let destWidth;\n  let destHeight;\n  if (imageAspect > containerAspect) {\n    destWidth = containerSize.width;\n    destHeight = containerSize.width / imageAspect;\n  } else {\n    destHeight = containerSize.height;\n    destWidth = containerSize.height * imageAspect;\n  }\n  const destX = containerSize.left + (containerSize.width - destWidth) / 2;\n  const destY = containerSize.top + (containerSize.height - destHeight) / 2;\n  return {\n    sourceX: 0,\n    sourceY: 0,\n    sourceWidth: intrinsicSize.width,\n    sourceHeight: intrinsicSize.height,\n    destX,\n    destY,\n    destWidth,\n    destHeight\n  };\n};\nvar calculateCover = ({\n  containerSize,\n  intrinsicSize\n}) => {\n  if (containerSize.height <= 0 || intrinsicSize.height <= 0) {\n    return {\n      sourceX: 0,\n      sourceY: 0,\n      sourceWidth: 0,\n      sourceHeight: 0,\n      destX: containerSize.left,\n      destY: containerSize.top,\n      destWidth: 0,\n      destHeight: 0\n    };\n  }\n  const containerAspect = containerSize.width / containerSize.height;\n  const imageAspect = intrinsicSize.width / intrinsicSize.height;\n  let sourceX = 0;\n  let sourceY = 0;\n  let sourceWidth = intrinsicSize.width;\n  let sourceHeight = intrinsicSize.height;\n  if (imageAspect > containerAspect) {\n    sourceWidth = intrinsicSize.height * containerAspect;\n    sourceX = (intrinsicSize.width - sourceWidth) / 2;\n  } else {\n    sourceHeight = intrinsicSize.width / containerAspect;\n    sourceY = (intrinsicSize.height - sourceHeight) / 2;\n  }\n  return {\n    sourceX,\n    sourceY,\n    sourceWidth,\n    sourceHeight,\n    destX: containerSize.left,\n    destY: containerSize.top,\n    destWidth: containerSize.width,\n    destHeight: containerSize.height\n  };\n};\nvar calculateNone = ({\n  containerSize,\n  intrinsicSize\n}) => {\n  const centeredX = containerSize.left + (containerSize.width - intrinsicSize.width) / 2;\n  const centeredY = containerSize.top + (containerSize.height - intrinsicSize.height) / 2;\n  let sourceX = 0;\n  let sourceY = 0;\n  let sourceWidth = intrinsicSize.width;\n  let sourceHeight = intrinsicSize.height;\n  let destX = centeredX;\n  let destY = centeredY;\n  let destWidth = intrinsicSize.width;\n  let destHeight = intrinsicSize.height;\n  if (destX < containerSize.left) {\n    const clipAmount = containerSize.left - destX;\n    sourceX = clipAmount;\n    sourceWidth -= clipAmount;\n    destX = containerSize.left;\n    destWidth -= clipAmount;\n  }\n  if (destY < containerSize.top) {\n    const clipAmount = containerSize.top - destY;\n    sourceY = clipAmount;\n    sourceHeight -= clipAmount;\n    destY = containerSize.top;\n    destHeight -= clipAmount;\n  }\n  const containerRight = containerSize.left + containerSize.width;\n  if (destX + destWidth > containerRight) {\n    const clipAmount = destX + destWidth - containerRight;\n    sourceWidth -= clipAmount;\n    destWidth -= clipAmount;\n  }\n  const containerBottom = containerSize.top + containerSize.height;\n  if (destY + destHeight > containerBottom) {\n    const clipAmount = destY + destHeight - containerBottom;\n    sourceHeight -= clipAmount;\n    destHeight -= clipAmount;\n  }\n  return {\n    sourceX,\n    sourceY,\n    sourceWidth,\n    sourceHeight,\n    destX,\n    destY,\n    destWidth,\n    destHeight\n  };\n};\nvar calculateObjectFit = ({\n  objectFit,\n  containerSize,\n  intrinsicSize\n}) => {\n  switch (objectFit) {\n    case \"fill\":\n      return calculateFill({ containerSize, intrinsicSize });\n    case \"contain\":\n      return calculateContain({ containerSize, intrinsicSize });\n    case \"cover\":\n      return calculateCover({ containerSize, intrinsicSize });\n    case \"none\":\n      return calculateNone({ containerSize, intrinsicSize });\n    case \"scale-down\": {\n      const containResult = calculateContain({ containerSize, intrinsicSize });\n      const noneResult = calculateNone({ containerSize, intrinsicSize });\n      const containArea = containResult.destWidth * containResult.destHeight;\n      const noneArea = noneResult.destWidth * noneResult.destHeight;\n      return containArea < noneArea ? containResult : noneResult;\n    }\n    default: {\n      const exhaustiveCheck = objectFit;\n      throw new Error(`Unknown object-fit value: ${exhaustiveCheck}`);\n    }\n  }\n};\nvar parseObjectFit = (value) => {\n  if (!value) {\n    return \"fill\";\n  }\n  const normalized = value.trim().toLowerCase();\n  switch (normalized) {\n    case \"fill\":\n    case \"contain\":\n    case \"cover\":\n    case \"none\":\n    case \"scale-down\":\n      return normalized;\n    default:\n      return \"fill\";\n  }\n};\n\n// src/drawing/fit-svg-into-its-dimensions.ts\nvar fitSvgIntoItsContainer = ({\n  containerSize,\n  elementSize\n}) => {\n  if (Math.round(containerSize.width) === Math.round(elementSize.width) && Math.round(containerSize.height) === Math.round(elementSize.height)) {\n    return {\n      width: containerSize.width,\n      height: containerSize.height,\n      top: containerSize.top,\n      left: containerSize.left\n    };\n  }\n  if (containerSize.width <= 0 || containerSize.height <= 0) {\n    throw new Error(`Container must have positive dimensions, but got ${containerSize.width}x${containerSize.height}`);\n  }\n  if (elementSize.width <= 0 || elementSize.height <= 0) {\n    throw new Error(`Element must have positive dimensions, but got ${elementSize.width}x${elementSize.height}`);\n  }\n  const heightRatio = containerSize.height / elementSize.height;\n  const widthRatio = containerSize.width / elementSize.width;\n  const ratio = Math.min(heightRatio, widthRatio);\n  const newWidth = elementSize.width * ratio;\n  const newHeight = elementSize.height * ratio;\n  if (newWidth > containerSize.width + 0.000001 || newHeight > containerSize.height + 0.000001) {\n    throw new Error(`Element is too big to fit into the container. Max size: ${containerSize.width}x${containerSize.height}, element size: ${newWidth}x${newHeight}`);\n  }\n  return {\n    width: newWidth,\n    height: newHeight,\n    top: (containerSize.height - newHeight) / 2 + containerSize.top,\n    left: (containerSize.width - newWidth) / 2 + containerSize.left\n  };\n};\n\n// src/drawing/turn-svg-into-drawable.ts\nvar turnSvgIntoDrawable = (svg) => {\n  const { fill, color } = getComputedStyle(svg);\n  const originalTransform = svg.style.transform;\n  const originalTransformOrigin = svg.style.transformOrigin;\n  const originalMarginLeft = svg.style.marginLeft;\n  const originalMarginRight = svg.style.marginRight;\n  const originalMarginTop = svg.style.marginTop;\n  const originalMarginBottom = svg.style.marginBottom;\n  const originalFill = svg.style.fill;\n  const originalColor = svg.style.color;\n  svg.style.transform = \"none\";\n  svg.style.transformOrigin = \"\";\n  svg.style.marginLeft = \"0\";\n  svg.style.marginRight = \"0\";\n  svg.style.marginTop = \"0\";\n  svg.style.marginBottom = \"0\";\n  svg.style.fill = fill;\n  svg.style.color = color;\n  const svgData = new XMLSerializer().serializeToString(svg);\n  svg.style.marginLeft = originalMarginLeft;\n  svg.style.marginRight = originalMarginRight;\n  svg.style.marginTop = originalMarginTop;\n  svg.style.marginBottom = originalMarginBottom;\n  svg.style.transform = originalTransform;\n  svg.style.transformOrigin = originalTransformOrigin;\n  svg.style.fill = originalFill;\n  svg.style.color = originalColor;\n  return new Promise((resolve, reject) => {\n    const image = new Image;\n    const url = `data:image/svg+xml;base64,${btoa(svgData)}`;\n    image.onload = function() {\n      resolve(image);\n    };\n    image.onerror = () => {\n      reject(new Error(\"Failed to convert SVG to image\"));\n    };\n    image.src = url;\n  });\n};\n\n// src/drawing/draw-dom-element.ts\nvar getReadableImageError = (err, node) => {\n  if (!(err instanceof DOMException)) {\n    return null;\n  }\n  if (err.name === \"SecurityError\") {\n    return new Error(`Could not draw image with src=\"${node.src}\" to canvas: ` + `The image is tainted due to CORS restrictions. ` + `The server hosting this image must respond with the \"Access-Control-Allow-Origin\" header. ` + `See: https://remotion.dev/docs/client-side-rendering/migration`);\n  }\n  if (err.name === \"InvalidStateError\") {\n    return new Error(`Could not draw image with src=\"${node.src}\" to canvas: ` + `The image is in a broken state. ` + `This usually means the image failed to load - check that the URL is valid and accessible.`);\n  }\n  return null;\n};\nvar drawSvg = ({\n  drawable,\n  dimensions,\n  contextToDraw\n}) => {\n  const fitted = fitSvgIntoItsContainer({\n    containerSize: dimensions,\n    elementSize: {\n      width: drawable.width,\n      height: drawable.height\n    }\n  });\n  contextToDraw.drawImage(drawable, fitted.left, fitted.top, fitted.width, fitted.height);\n};\nvar drawReplacedElement = ({\n  drawable,\n  dimensions,\n  computedStyle,\n  contextToDraw\n}) => {\n  const objectFit = parseObjectFit(computedStyle.objectFit);\n  const intrinsicSize = drawable instanceof HTMLImageElement ? { width: drawable.naturalWidth, height: drawable.naturalHeight } : { width: drawable.width, height: drawable.height };\n  const result = calculateObjectFit({\n    objectFit,\n    containerSize: {\n      width: dimensions.width,\n      height: dimensions.height,\n      left: dimensions.left,\n      top: dimensions.top\n    },\n    intrinsicSize\n  });\n  contextToDraw.drawImage(drawable, result.sourceX, result.sourceY, result.sourceWidth, result.sourceHeight, result.destX, result.destY, result.destWidth, result.destHeight);\n};\nvar drawDomElement = (node) => {\n  const domDrawFn = async ({\n    dimensions,\n    contextToDraw,\n    computedStyle\n  }) => {\n    if (node instanceof SVGSVGElement) {\n      const drawable = await turnSvgIntoDrawable(node);\n      drawSvg({ drawable, dimensions, contextToDraw });\n      return;\n    }\n    if (node instanceof HTMLImageElement || node instanceof HTMLCanvasElement) {\n      try {\n        drawReplacedElement({\n          drawable: node,\n          dimensions,\n          computedStyle,\n          contextToDraw\n        });\n      } catch (err) {\n        if (node instanceof HTMLImageElement) {\n          const readableError = getReadableImageError(err, node);\n          if (readableError) {\n            throw readableError;\n          }\n        }\n        throw err;\n      }\n    }\n  };\n  return domDrawFn;\n};\n\n// src/drawing/process-node.ts\nimport { Internals as Internals6 } from \"remotion\";\n\n// src/drawing/has-transform.ts\nvar hasTransformCssValue = (style) => {\n  return style.transform !== \"none\" && style.transform !== \"\";\n};\nvar hasRotateCssValue = (style) => {\n  return style.rotate !== \"none\" && style.rotate !== \"\";\n};\nvar hasScaleCssValue = (style) => {\n  return style.scale !== \"none\" && style.scale !== \"\";\n};\nvar hasAnyTransformCssValue = (style) => {\n  return hasTransformCssValue(style) || hasRotateCssValue(style) || hasScaleCssValue(style);\n};\n\n// src/drawing/parse-linear-gradient.ts\nimport { NoReactInternals as NoReactInternals2 } from \"remotion/no-react\";\nvar isValidColor = (color) => {\n  try {\n    const result = NoReactInternals2.processColor(color);\n    return result !== null && result !== undefined;\n  } catch {\n    return false;\n  }\n};\nvar parseDirection = (directionStr) => {\n  const trimmed = directionStr.trim().toLowerCase();\n  if (trimmed.startsWith(\"to \")) {\n    const direction = trimmed.substring(3).trim();\n    switch (direction) {\n      case \"top\":\n        return 0;\n      case \"right\":\n        return 90;\n      case \"bottom\":\n        return 180;\n      case \"left\":\n        return 270;\n      case \"top right\":\n      case \"right top\":\n        return 45;\n      case \"bottom right\":\n      case \"right bottom\":\n        return 135;\n      case \"bottom left\":\n      case \"left bottom\":\n        return 225;\n      case \"top left\":\n      case \"left top\":\n        return 315;\n      default:\n        return 180;\n    }\n  }\n  const angleMatch = trimmed.match(/^(-?\\d+\\.?\\d*)(deg|rad|grad|turn)$/);\n  if (angleMatch) {\n    const value = parseFloat(angleMatch[1]);\n    const unit = angleMatch[2];\n    switch (unit) {\n      case \"deg\":\n        return value;\n      case \"rad\":\n        return value * 180 / Math.PI;\n      case \"grad\":\n        return value * 360 / 400;\n      case \"turn\":\n        return value * 360;\n      default:\n        return value;\n    }\n  }\n  return 180;\n};\nvar parseColorStops = (colorStopsStr) => {\n  const parts = colorStopsStr.split(/,(?![^(]*\\))/);\n  const stops = [];\n  for (const part of parts) {\n    const trimmed = part.trim();\n    if (!trimmed)\n      continue;\n    const colorMatch = trimmed.match(/(rgba?\\([^)]+\\)|hsla?\\([^)]+\\)|#[0-9a-f]{3,8}|[a-z]+)/i);\n    if (!colorMatch) {\n      continue;\n    }\n    const colorStr = colorMatch[0];\n    if (!isValidColor(colorStr)) {\n      continue;\n    }\n    const remaining = trimmed.substring(colorMatch.index + colorStr.length).trim();\n    const normalizedColor = colorStr;\n    let position = null;\n    if (remaining) {\n      const posMatch = remaining.match(/(-?\\d+\\.?\\d*)(%|px)?/);\n      if (posMatch) {\n        const value = parseFloat(posMatch[1]);\n        const unit = posMatch[2];\n        if (unit === \"%\") {\n          position = value / 100;\n        } else if (unit === \"px\") {\n          position = null;\n        } else {\n          position = value / 100;\n        }\n      }\n    }\n    stops.push({\n      color: normalizedColor,\n      position: position !== null ? position : -1\n    });\n  }\n  if (stops.length === 0) {\n    return null;\n  }\n  let lastExplicitIndex = -1;\n  let lastExplicitPosition = 0;\n  for (let i = 0;i < stops.length; i++) {\n    if (stops[i].position !== -1) {\n      if (lastExplicitIndex >= 0) {\n        const numImplicit = i - lastExplicitIndex - 1;\n        if (numImplicit > 0) {\n          const step = (stops[i].position - lastExplicitPosition) / (numImplicit + 1);\n          for (let j = lastExplicitIndex + 1;j < i; j++) {\n            stops[j].position = lastExplicitPosition + step * (j - lastExplicitIndex);\n          }\n        }\n      } else {\n        const numImplicit = i;\n        if (numImplicit > 0) {\n          const step = stops[i].position / (numImplicit + 1);\n          for (let j = 0;j < i; j++) {\n            stops[j].position = step * (j + 1);\n          }\n        }\n      }\n      lastExplicitIndex = i;\n      lastExplicitPosition = stops[i].position;\n    }\n  }\n  if (stops.every((s) => s.position === -1)) {\n    if (stops.length === 1) {\n      stops[0].position = 0.5;\n    } else {\n      for (let i = 0;i < stops.length; i++) {\n        stops[i].position = i / (stops.length - 1);\n      }\n    }\n  } else if (lastExplicitIndex < stops.length - 1) {\n    const numImplicit = stops.length - 1 - lastExplicitIndex;\n    const step = (1 - lastExplicitPosition) / (numImplicit + 1);\n    for (let i = lastExplicitIndex + 1;i < stops.length; i++) {\n      stops[i].position = lastExplicitPosition + step * (i - lastExplicitIndex);\n    }\n  }\n  for (const stop of stops) {\n    stop.position = Math.max(0, Math.min(1, stop.position));\n  }\n  return stops;\n};\nvar extractGradientContent = (backgroundImage) => {\n  const prefix = \"linear-gradient(\";\n  const startIndex = backgroundImage.toLowerCase().indexOf(prefix);\n  if (startIndex === -1) {\n    return null;\n  }\n  let depth = 0;\n  const contentStart = startIndex + prefix.length;\n  for (let i = contentStart;i < backgroundImage.length; i++) {\n    const char = backgroundImage[i];\n    if (char === \"(\") {\n      depth++;\n    } else if (char === \")\") {\n      if (depth === 0) {\n        return backgroundImage.substring(contentStart, i).trim();\n      }\n      depth--;\n    }\n  }\n  return null;\n};\nvar parseLinearGradient = (backgroundImage) => {\n  if (!backgroundImage || backgroundImage === \"none\") {\n    return null;\n  }\n  const content = extractGradientContent(backgroundImage);\n  if (!content) {\n    return null;\n  }\n  const parts = content.split(/,(?![^(]*\\))/);\n  let angle = 180;\n  let colorStopsStart = 0;\n  if (parts.length > 0) {\n    const firstPart = parts[0].trim();\n    const isDirection = firstPart.startsWith(\"to \") || /^-?\\d+\\.?\\d*(deg|rad|grad|turn)$/.test(firstPart);\n    if (isDirection) {\n      angle = parseDirection(firstPart);\n      colorStopsStart = 1;\n    }\n  }\n  const colorStopsStr = parts.slice(colorStopsStart).join(\",\");\n  const colorStops = parseColorStops(colorStopsStr);\n  if (!colorStops || colorStops.length === 0) {\n    return null;\n  }\n  return {\n    angle,\n    colorStops\n  };\n};\nvar createCanvasGradient = ({\n  ctx,\n  rect,\n  gradientInfo,\n  offsetLeft,\n  offsetTop\n}) => {\n  const angleRad = (gradientInfo.angle - 90) * Math.PI / 180;\n  const centerX = rect.left - offsetLeft + rect.width / 2;\n  const centerY = rect.top - offsetTop + rect.height / 2;\n  const cos = Math.cos(angleRad);\n  const sin = Math.sin(angleRad);\n  const halfWidth = rect.width / 2;\n  const halfHeight = rect.height / 2;\n  let length = Math.abs(cos) * halfWidth + Math.abs(sin) * halfHeight;\n  if (!Number.isFinite(length) || length === 0) {\n    length = Math.sqrt(halfWidth ** 2 + halfHeight ** 2);\n  }\n  const x0 = centerX - cos * length;\n  const y0 = centerY - sin * length;\n  const x1 = centerX + cos * length;\n  const y1 = centerY + sin * length;\n  const gradient = ctx.createLinearGradient(x0, y0, x1, y1);\n  for (const stop of gradientInfo.colorStops) {\n    gradient.addColorStop(stop.position, stop.color);\n  }\n  return gradient;\n};\n\n// src/drawing/mask-image.ts\nvar getMaskImageValue = (computedStyle) => {\n  const { maskImage, webkitMaskImage } = computedStyle;\n  const value = maskImage || webkitMaskImage;\n  if (!value || value === \"none\") {\n    return null;\n  }\n  return value;\n};\nvar parseMaskImage = (maskImageValue) => {\n  return parseLinearGradient(maskImageValue);\n};\n\n// src/drawing/parse-transform-origin.ts\nvar parseTransformOrigin = (transformOrigin) => {\n  if (transformOrigin.trim() === \"\") {\n    return null;\n  }\n  const [x, y] = transformOrigin.split(\" \");\n  return { x: parseFloat(x), y: parseFloat(y) };\n};\n\n// src/drawing/calculate-transforms.ts\nvar getInternalTransformOrigin = (transform) => {\n  const centerX = transform.boundingClientRect.width / 2;\n  const centerY = transform.boundingClientRect.height / 2;\n  const origin = parseTransformOrigin(transform.transformOrigin) ?? {\n    x: centerX,\n    y: centerY\n  };\n  return origin;\n};\nvar getGlobalTransformOrigin = ({ transform }) => {\n  const { x: originX, y: originY } = getInternalTransformOrigin(transform);\n  return {\n    x: originX + transform.boundingClientRect.left,\n    y: originY + transform.boundingClientRect.top\n  };\n};\nvar calculateTransforms = ({\n  element,\n  rootElement\n}) => {\n  let parent = element;\n  const transforms = [];\n  const toReset = [];\n  let opacity = 1;\n  let elementComputedStyle = null;\n  let maskImageInfo = null;\n  while (parent) {\n    const computedStyle = getComputedStyle(parent);\n    if (parent === element) {\n      elementComputedStyle = computedStyle;\n      opacity = parseFloat(computedStyle.opacity);\n      const maskImageValue = getMaskImageValue(computedStyle);\n      maskImageInfo = maskImageValue ? parseMaskImage(maskImageValue) : null;\n      const originalMaskImage = parent.style.maskImage;\n      const originalWebkitMaskImage = parent.style.webkitMaskImage;\n      parent.style.maskImage = \"none\";\n      parent.style.webkitMaskImage = \"none\";\n      const parentRef = parent;\n      toReset.push(() => {\n        parentRef.style.maskImage = originalMaskImage;\n        parentRef.style.webkitMaskImage = originalWebkitMaskImage;\n      });\n    }\n    if (hasAnyTransformCssValue(computedStyle) || parent === element) {\n      const toParse = hasTransformCssValue(computedStyle) ? computedStyle.transform : undefined;\n      const matrix = new DOMMatrix(toParse);\n      const { transform, scale, rotate } = parent.style;\n      const additionalMatrices = [];\n      if (rotate !== \"\" && rotate !== \"none\") {\n        additionalMatrices.push(new DOMMatrix(`rotate(${rotate})`));\n      }\n      if (scale !== \"\" && scale !== \"none\") {\n        additionalMatrices.push(new DOMMatrix(`scale(${scale})`));\n      }\n      additionalMatrices.push(matrix);\n      parent.style.transform = \"none\";\n      parent.style.scale = \"none\";\n      parent.style.rotate = \"none\";\n      transforms.push({\n        element: parent,\n        transformOrigin: computedStyle.transformOrigin,\n        boundingClientRect: null,\n        matrices: additionalMatrices\n      });\n      const parentRef = parent;\n      toReset.push(() => {\n        parentRef.style.transform = transform;\n        parentRef.style.scale = scale;\n        parentRef.style.rotate = rotate;\n      });\n    }\n    if (parent === rootElement) {\n      break;\n    }\n    parent = parent.parentElement;\n  }\n  for (const transform of transforms) {\n    transform.boundingClientRect = transform.element.getBoundingClientRect();\n  }\n  const dimensions = transforms[0].boundingClientRect;\n  const nativeTransformOrigin = getInternalTransformOrigin(transforms[0]);\n  const totalMatrix = new DOMMatrix;\n  for (const transform of transforms.slice().reverse()) {\n    for (const matrix of transform.matrices) {\n      const globalTransformOrigin = getGlobalTransformOrigin({\n        transform\n      });\n      const transformMatrix = new DOMMatrix().translate(globalTransformOrigin.x, globalTransformOrigin.y).multiply(matrix).translate(-globalTransformOrigin.x, -globalTransformOrigin.y);\n      totalMatrix.multiplySelf(transformMatrix);\n    }\n  }\n  if (!elementComputedStyle) {\n    throw new Error(\"Element computed style not found\");\n  }\n  const needs3DTransformViaWebGL = !totalMatrix.is2D;\n  const needsMaskImage = maskImageInfo !== null;\n  return {\n    dimensions,\n    totalMatrix,\n    [Symbol.dispose]: () => {\n      for (const reset of toReset) {\n        reset();\n      }\n    },\n    nativeTransformOrigin,\n    computedStyle: elementComputedStyle,\n    opacity,\n    maskImageInfo,\n    precompositing: {\n      needs3DTransformViaWebGL,\n      needsMaskImage: maskImageInfo,\n      needsPrecompositing: Boolean(needs3DTransformViaWebGL || needsMaskImage)\n    }\n  };\n};\n\n// src/drawing/round-to-expand-rect.ts\nvar roundToExpandRect = (rect) => {\n  const left = Math.floor(rect.left);\n  const top = Math.floor(rect.top);\n  const right = Math.ceil(rect.right);\n  const bottom = Math.ceil(rect.bottom);\n  return new DOMRect(left, top, right - left, bottom - top);\n};\n\n// src/drawing/clamp-rect-to-parent-bounds.ts\nvar getNarrowerRect = ({\n  firstRect,\n  secondRect\n}) => {\n  const left = Math.max(firstRect.left, secondRect.left);\n  const top = Math.max(firstRect.top, secondRect.top);\n  const bottom = Math.min(firstRect.bottom, secondRect.bottom);\n  const right = Math.min(firstRect.right, secondRect.right);\n  return new DOMRect(left, top, right - left, bottom - top);\n};\nvar getWiderRectAndExpand = ({\n  firstRect,\n  secondRect\n}) => {\n  if (firstRect === null) {\n    return roundToExpandRect(secondRect);\n  }\n  const left = Math.min(firstRect.left, secondRect.left);\n  const top = Math.min(firstRect.top, secondRect.top);\n  const bottom = Math.max(firstRect.bottom, secondRect.bottom);\n  const right = Math.max(firstRect.right, secondRect.right);\n  return roundToExpandRect(new DOMRect(left, top, right - left, bottom - top));\n};\n\n// src/drawing/do-rects-intersect.ts\nfunction doRectsIntersect(rect1, rect2) {\n  return !(rect1.right <= rect2.left || rect1.left >= rect2.right || rect1.bottom <= rect2.top || rect1.top >= rect2.bottom);\n}\n\n// src/drawing/draw-rounded.ts\nvar drawRoundedRectPath = ({\n  ctx,\n  x,\n  y,\n  width,\n  height,\n  borderRadius\n}) => {\n  ctx.beginPath();\n  ctx.moveTo(x + borderRadius.topLeft.horizontal, y);\n  ctx.lineTo(x + width - borderRadius.topRight.horizontal, y);\n  if (borderRadius.topRight.horizontal > 0 || borderRadius.topRight.vertical > 0) {\n    ctx.ellipse(x + width - borderRadius.topRight.horizontal, y + borderRadius.topRight.vertical, borderRadius.topRight.horizontal, borderRadius.topRight.vertical, 0, -Math.PI / 2, 0);\n  }\n  ctx.lineTo(x + width, y + height - borderRadius.bottomRight.vertical);\n  if (borderRadius.bottomRight.horizontal > 0 || borderRadius.bottomRight.vertical > 0) {\n    ctx.ellipse(x + width - borderRadius.bottomRight.horizontal, y + height - borderRadius.bottomRight.vertical, borderRadius.bottomRight.horizontal, borderRadius.bottomRight.vertical, 0, 0, Math.PI / 2);\n  }\n  ctx.lineTo(x + borderRadius.bottomLeft.horizontal, y + height);\n  if (borderRadius.bottomLeft.horizontal > 0 || borderRadius.bottomLeft.vertical > 0) {\n    ctx.ellipse(x + borderRadius.bottomLeft.horizontal, y + height - borderRadius.bottomLeft.vertical, borderRadius.bottomLeft.horizontal, borderRadius.bottomLeft.vertical, 0, Math.PI / 2, Math.PI);\n  }\n  ctx.lineTo(x, y + borderRadius.topLeft.vertical);\n  if (borderRadius.topLeft.horizontal > 0 || borderRadius.topLeft.vertical > 0) {\n    ctx.ellipse(x + borderRadius.topLeft.horizontal, y + borderRadius.topLeft.vertical, borderRadius.topLeft.horizontal, borderRadius.topLeft.vertical, 0, Math.PI, Math.PI * 3 / 2);\n  }\n  ctx.closePath();\n};\n\n// src/drawing/get-padding-box.ts\nvar getPaddingBox = (rect, computedStyle) => {\n  const borderLeft = parseFloat(computedStyle.borderLeftWidth);\n  const borderRight = parseFloat(computedStyle.borderRightWidth);\n  const borderTop = parseFloat(computedStyle.borderTopWidth);\n  const borderBottom = parseFloat(computedStyle.borderBottomWidth);\n  return new DOMRect(rect.left + borderLeft, rect.top + borderTop, rect.width - borderLeft - borderRight, rect.height - borderTop - borderBottom);\n};\nvar getContentBox = (rect, computedStyle) => {\n  const paddingBox = getPaddingBox(rect, computedStyle);\n  const paddingLeft = parseFloat(computedStyle.paddingLeft);\n  const paddingRight = parseFloat(computedStyle.paddingRight);\n  const paddingTop = parseFloat(computedStyle.paddingTop);\n  const paddingBottom = parseFloat(computedStyle.paddingBottom);\n  return new DOMRect(paddingBox.left + paddingLeft, paddingBox.top + paddingTop, paddingBox.width - paddingLeft - paddingRight, paddingBox.height - paddingTop - paddingBottom);\n};\nvar getBoxBasedOnBackgroundClip = (rect, computedStyle, backgroundClip) => {\n  if (!backgroundClip) {\n    return rect;\n  }\n  if (backgroundClip.includes(\"text\")) {\n    return rect;\n  }\n  if (backgroundClip.includes(\"padding-box\")) {\n    return getPaddingBox(rect, computedStyle);\n  }\n  if (backgroundClip.includes(\"content-box\")) {\n    return getContentBox(rect, computedStyle);\n  }\n  return rect;\n};\n\n// src/drawing/border-radius.ts\nfunction parseValue({\n  value,\n  reference\n}) {\n  value = value.trim();\n  if (value.endsWith(\"%\")) {\n    const percentage = parseFloat(value);\n    return percentage / 100 * reference;\n  }\n  if (value.endsWith(\"px\")) {\n    return parseFloat(value);\n  }\n  return parseFloat(value);\n}\nfunction expandShorthand(values) {\n  if (values.length === 1) {\n    return [values[0], values[0], values[0], values[0]];\n  }\n  if (values.length === 2) {\n    return [values[0], values[1], values[0], values[1]];\n  }\n  if (values.length === 3) {\n    return [values[0], values[1], values[2], values[1]];\n  }\n  return [values[0], values[1], values[2], values[3]];\n}\nfunction clampBorderRadius({\n  borderRadius,\n  width,\n  height\n}) {\n  const clamped = {\n    topLeft: { ...borderRadius.topLeft },\n    topRight: { ...borderRadius.topRight },\n    bottomRight: { ...borderRadius.bottomRight },\n    bottomLeft: { ...borderRadius.bottomLeft }\n  };\n  const topSum = clamped.topLeft.horizontal + clamped.topRight.horizontal;\n  if (topSum > width) {\n    const factor = width / topSum;\n    clamped.topLeft.horizontal *= factor;\n    clamped.topRight.horizontal *= factor;\n  }\n  const rightSum = clamped.topRight.vertical + clamped.bottomRight.vertical;\n  if (rightSum > height) {\n    const factor = height / rightSum;\n    clamped.topRight.vertical *= factor;\n    clamped.bottomRight.vertical *= factor;\n  }\n  const bottomSum = clamped.bottomRight.horizontal + clamped.bottomLeft.horizontal;\n  if (bottomSum > width) {\n    const factor = width / bottomSum;\n    clamped.bottomRight.horizontal *= factor;\n    clamped.bottomLeft.horizontal *= factor;\n  }\n  const leftSum = clamped.bottomLeft.vertical + clamped.topLeft.vertical;\n  if (leftSum > height) {\n    const factor = height / leftSum;\n    clamped.bottomLeft.vertical *= factor;\n    clamped.topLeft.vertical *= factor;\n  }\n  return clamped;\n}\nfunction parseBorderRadius({\n  borderRadius,\n  width,\n  height\n}) {\n  const parts = borderRadius.split(\"/\").map((part) => part.trim());\n  const horizontalPart = parts[0];\n  const verticalPart = parts[1];\n  const horizontalValues = horizontalPart.split(/\\s+/).filter((v) => v);\n  const verticalValues = verticalPart ? verticalPart.split(/\\s+/).filter((v) => v) : horizontalValues;\n  const [hTopLeft, hTopRight, hBottomRight, hBottomLeft] = expandShorthand(horizontalValues);\n  const [vTopLeft, vTopRight, vBottomRight, vBottomLeft] = expandShorthand(verticalValues);\n  return clampBorderRadius({\n    borderRadius: {\n      topLeft: {\n        horizontal: parseValue({ value: hTopLeft, reference: width }),\n        vertical: parseValue({ value: vTopLeft, reference: height })\n      },\n      topRight: {\n        horizontal: parseValue({ value: hTopRight, reference: width }),\n        vertical: parseValue({ value: vTopRight, reference: height })\n      },\n      bottomRight: {\n        horizontal: parseValue({ value: hBottomRight, reference: width }),\n        vertical: parseValue({ value: vBottomRight, reference: height })\n      },\n      bottomLeft: {\n        horizontal: parseValue({ value: hBottomLeft, reference: width }),\n        vertical: parseValue({ value: vBottomLeft, reference: height })\n      }\n    },\n    width,\n    height\n  });\n}\nfunction setBorderRadius({\n  ctx,\n  rect,\n  borderRadius,\n  forceClipEvenWhenZero = false,\n  computedStyle,\n  backgroundClip\n}) {\n  if (borderRadius.topLeft.horizontal === 0 && borderRadius.topLeft.vertical === 0 && borderRadius.topRight.horizontal === 0 && borderRadius.topRight.vertical === 0 && borderRadius.bottomRight.horizontal === 0 && borderRadius.bottomRight.vertical === 0 && borderRadius.bottomLeft.horizontal === 0 && borderRadius.bottomLeft.vertical === 0 && !forceClipEvenWhenZero) {\n    return () => {};\n  }\n  ctx.save();\n  const boundingRect = getBoxBasedOnBackgroundClip(rect, computedStyle, backgroundClip);\n  const actualBorderRadius = {\n    topLeft: {\n      horizontal: Math.max(0, borderRadius.topLeft.horizontal - (boundingRect.left - rect.left)),\n      vertical: Math.max(0, borderRadius.topLeft.vertical - (boundingRect.top - rect.top))\n    },\n    topRight: {\n      horizontal: Math.max(0, borderRadius.topRight.horizontal - (rect.right - boundingRect.right)),\n      vertical: Math.max(0, borderRadius.topRight.vertical - (boundingRect.top - rect.top))\n    },\n    bottomRight: {\n      horizontal: Math.max(0, borderRadius.bottomRight.horizontal - (rect.right - boundingRect.right)),\n      vertical: Math.max(0, borderRadius.bottomRight.vertical - (rect.bottom - boundingRect.bottom))\n    },\n    bottomLeft: {\n      horizontal: Math.max(0, borderRadius.bottomLeft.horizontal - (boundingRect.left - rect.left)),\n      vertical: Math.max(0, borderRadius.bottomLeft.vertical - (rect.bottom - boundingRect.bottom))\n    }\n  };\n  drawRoundedRectPath({\n    ctx,\n    x: boundingRect.left,\n    y: boundingRect.top,\n    width: boundingRect.width,\n    height: boundingRect.height,\n    borderRadius: actualBorderRadius\n  });\n  ctx.clip();\n  return () => {\n    ctx.restore();\n  };\n}\n\n// src/drawing/get-background-fill.ts\nvar isColorTransparent = (color) => {\n  return color === \"transparent\" || color.startsWith(\"rgba\") && (color.endsWith(\", 0)\") || color.endsWith(\",0\"));\n};\nvar getBackgroundFill = ({\n  backgroundColor,\n  backgroundImage,\n  contextToDraw,\n  boundingRect,\n  offsetLeft,\n  offsetTop\n}) => {\n  if (backgroundImage && backgroundImage !== \"none\") {\n    const gradientInfo = parseLinearGradient(backgroundImage);\n    if (gradientInfo) {\n      const gradient = createCanvasGradient({\n        ctx: contextToDraw,\n        rect: boundingRect,\n        gradientInfo,\n        offsetLeft,\n        offsetTop\n      });\n      return gradient;\n    }\n  }\n  if (backgroundColor && backgroundColor !== \"transparent\" && !isColorTransparent(backgroundColor)) {\n    return backgroundColor;\n  }\n  return null;\n};\n\n// src/drawing/draw-background.ts\nvar drawBackground = async ({\n  backgroundImage,\n  context,\n  rect,\n  backgroundColor,\n  backgroundClip,\n  element,\n  logLevel,\n  internalState,\n  computedStyle,\n  offsetLeft: parentOffsetLeft,\n  offsetTop: parentOffsetTop,\n  scale\n}) => {\n  let __stack = [];\n  try {\n    let contextToDraw = context;\n    const originalCompositeOperation = context.globalCompositeOperation;\n    let offsetLeft = 0;\n    let offsetTop = 0;\n    const _ = __using(__stack, {\n      [Symbol.dispose]: () => {\n        context.globalCompositeOperation = originalCompositeOperation;\n        if (context !== contextToDraw) {\n          context.drawImage(contextToDraw.canvas, offsetLeft, offsetTop, contextToDraw.canvas.width / scale, contextToDraw.canvas.height / scale);\n        }\n      }\n    }, 0);\n    const boundingRect = getBoxBasedOnBackgroundClip(rect, computedStyle, backgroundClip);\n    if (backgroundClip.includes(\"text\")) {\n      offsetLeft = boundingRect.left;\n      offsetTop = boundingRect.top;\n      const originalBackgroundClip = element.style.backgroundClip;\n      const originalWebkitBackgroundClip = element.style.webkitBackgroundClip;\n      element.style.backgroundClip = \"initial\";\n      element.style.webkitBackgroundClip = \"initial\";\n      const onlyBackgroundClipText = await createLayer({\n        element,\n        cutout: new DOMRect(boundingRect.left + parentOffsetLeft, boundingRect.top + parentOffsetTop, boundingRect.width, boundingRect.height),\n        logLevel,\n        internalState,\n        scale,\n        onlyBackgroundClipText: true\n      });\n      onlyBackgroundClipText.setTransform(new DOMMatrix().scale(scale, scale));\n      element.style.backgroundClip = originalBackgroundClip;\n      element.style.webkitBackgroundClip = originalWebkitBackgroundClip;\n      contextToDraw = onlyBackgroundClipText;\n      contextToDraw.globalCompositeOperation = \"source-in\";\n    }\n    const backgroundFill = getBackgroundFill({\n      backgroundImage,\n      backgroundColor,\n      contextToDraw,\n      boundingRect,\n      offsetLeft,\n      offsetTop\n    });\n    if (!backgroundFill) {\n      return;\n    }\n    const originalFillStyle = contextToDraw.fillStyle;\n    contextToDraw.fillStyle = backgroundFill;\n    contextToDraw.fillRect(boundingRect.left - offsetLeft, boundingRect.top - offsetTop, boundingRect.width, boundingRect.height);\n    contextToDraw.fillStyle = originalFillStyle;\n  } catch (_catch) {\n    var _err = _catch, _hasErr = 1;\n  } finally {\n    __callDispose(__stack, _err, _hasErr);\n  }\n};\n\n// src/drawing/draw-border.ts\nvar parseBorderWidth = (value) => {\n  return parseFloat(value) || 0;\n};\nvar getBorderSideProperties = (computedStyle) => {\n  return {\n    top: {\n      width: parseBorderWidth(computedStyle.borderTopWidth),\n      color: computedStyle.borderTopColor || computedStyle.borderColor || \"black\",\n      style: computedStyle.borderTopStyle || computedStyle.borderStyle || \"solid\"\n    },\n    right: {\n      width: parseBorderWidth(computedStyle.borderRightWidth),\n      color: computedStyle.borderRightColor || computedStyle.borderColor || \"black\",\n      style: computedStyle.borderRightStyle || computedStyle.borderStyle || \"solid\"\n    },\n    bottom: {\n      width: parseBorderWidth(computedStyle.borderBottomWidth),\n      color: computedStyle.borderBottomColor || computedStyle.borderColor || \"black\",\n      style: computedStyle.borderBottomStyle || computedStyle.borderStyle || \"solid\"\n    },\n    left: {\n      width: parseBorderWidth(computedStyle.borderLeftWidth),\n      color: computedStyle.borderLeftColor || computedStyle.borderColor || \"black\",\n      style: computedStyle.borderLeftStyle || computedStyle.borderStyle || \"solid\"\n    }\n  };\n};\nvar getLineDashPattern = (style, width) => {\n  if (style === \"dashed\") {\n    return [width * 2, width];\n  }\n  if (style === \"dotted\") {\n    return [width, width];\n  }\n  return [];\n};\nvar drawBorderSide = ({\n  ctx,\n  side,\n  x,\n  y,\n  width,\n  height,\n  borderRadius,\n  borderProperties\n}) => {\n  const { width: borderWidth, color, style } = borderProperties;\n  if (borderWidth <= 0 || style === \"none\" || style === \"hidden\") {\n    return;\n  }\n  ctx.beginPath();\n  ctx.strokeStyle = color;\n  ctx.lineWidth = borderWidth;\n  ctx.setLineDash(getLineDashPattern(style, borderWidth));\n  const halfWidth = borderWidth / 2;\n  if (side === \"top\") {\n    const startX = x + borderRadius.topLeft.horizontal;\n    const startY = y + halfWidth;\n    const endX = x + width - borderRadius.topRight.horizontal;\n    const endY = y + halfWidth;\n    ctx.moveTo(startX, startY);\n    ctx.lineTo(endX, endY);\n  } else if (side === \"right\") {\n    const startX = x + width - halfWidth;\n    const startY = y + borderRadius.topRight.vertical;\n    const endX = x + width - halfWidth;\n    const endY = y + height - borderRadius.bottomRight.vertical;\n    ctx.moveTo(startX, startY);\n    ctx.lineTo(endX, endY);\n  } else if (side === \"bottom\") {\n    const startX = x + borderRadius.bottomLeft.horizontal;\n    const startY = y + height - halfWidth;\n    const endX = x + width - borderRadius.bottomRight.horizontal;\n    const endY = y + height - halfWidth;\n    ctx.moveTo(startX, startY);\n    ctx.lineTo(endX, endY);\n  } else if (side === \"left\") {\n    const startX = x + halfWidth;\n    const startY = y + borderRadius.topLeft.vertical;\n    const endX = x + halfWidth;\n    const endY = y + height - borderRadius.bottomLeft.vertical;\n    ctx.moveTo(startX, startY);\n    ctx.lineTo(endX, endY);\n  }\n  ctx.stroke();\n};\nvar drawCorner = ({\n  ctx,\n  corner,\n  x,\n  y,\n  width,\n  height,\n  borderRadius,\n  topBorder,\n  rightBorder,\n  bottomBorder,\n  leftBorder\n}) => {\n  const radius = borderRadius[corner];\n  if (radius.horizontal <= 0 && radius.vertical <= 0) {\n    return;\n  }\n  let border1;\n  let border2;\n  let centerX;\n  let centerY;\n  let startAngle;\n  let endAngle;\n  if (corner === \"topLeft\") {\n    border1 = leftBorder;\n    border2 = topBorder;\n    centerX = x + radius.horizontal;\n    centerY = y + radius.vertical;\n    startAngle = Math.PI;\n    endAngle = Math.PI * 3 / 2;\n  } else if (corner === \"topRight\") {\n    border1 = topBorder;\n    border2 = rightBorder;\n    centerX = x + width - radius.horizontal;\n    centerY = y + radius.vertical;\n    startAngle = -Math.PI / 2;\n    endAngle = 0;\n  } else if (corner === \"bottomRight\") {\n    border1 = rightBorder;\n    border2 = bottomBorder;\n    centerX = x + width - radius.horizontal;\n    centerY = y + height - radius.vertical;\n    startAngle = 0;\n    endAngle = Math.PI / 2;\n  } else {\n    border1 = bottomBorder;\n    border2 = leftBorder;\n    centerX = x + radius.horizontal;\n    centerY = y + height - radius.vertical;\n    startAngle = Math.PI / 2;\n    endAngle = Math.PI;\n  }\n  const avgWidth = (border1.width + border2.width) / 2;\n  const useColor = border1.width >= border2.width ? border1.color : border2.color;\n  const useStyle = border1.width >= border2.width ? border1.style : border2.style;\n  if (avgWidth > 0 && useStyle !== \"none\" && useStyle !== \"hidden\") {\n    ctx.beginPath();\n    ctx.strokeStyle = useColor;\n    ctx.lineWidth = avgWidth;\n    ctx.setLineDash(getLineDashPattern(useStyle, avgWidth));\n    const adjustedRadiusH = Math.max(0, radius.horizontal - avgWidth / 2);\n    const adjustedRadiusV = Math.max(0, radius.vertical - avgWidth / 2);\n    ctx.ellipse(centerX, centerY, adjustedRadiusH, adjustedRadiusV, 0, startAngle, endAngle);\n    ctx.stroke();\n  }\n};\nvar drawUniformBorder = ({\n  ctx,\n  x,\n  y,\n  width,\n  height,\n  borderRadius,\n  borderWidth,\n  borderColor,\n  borderStyle\n}) => {\n  ctx.beginPath();\n  ctx.strokeStyle = borderColor;\n  ctx.lineWidth = borderWidth;\n  ctx.setLineDash(getLineDashPattern(borderStyle, borderWidth));\n  const halfWidth = borderWidth / 2;\n  const borderX = x + halfWidth;\n  const borderY = y + halfWidth;\n  const borderW = width - borderWidth;\n  const borderH = height - borderWidth;\n  const adjustedBorderRadius = {\n    topLeft: {\n      horizontal: Math.max(0, borderRadius.topLeft.horizontal - halfWidth),\n      vertical: Math.max(0, borderRadius.topLeft.vertical - halfWidth)\n    },\n    topRight: {\n      horizontal: Math.max(0, borderRadius.topRight.horizontal - halfWidth),\n      vertical: Math.max(0, borderRadius.topRight.vertical - halfWidth)\n    },\n    bottomRight: {\n      horizontal: Math.max(0, borderRadius.bottomRight.horizontal - halfWidth),\n      vertical: Math.max(0, borderRadius.bottomRight.vertical - halfWidth)\n    },\n    bottomLeft: {\n      horizontal: Math.max(0, borderRadius.bottomLeft.horizontal - halfWidth),\n      vertical: Math.max(0, borderRadius.bottomLeft.vertical - halfWidth)\n    }\n  };\n  ctx.moveTo(borderX + adjustedBorderRadius.topLeft.horizontal, borderY);\n  ctx.lineTo(borderX + borderW - adjustedBorderRadius.topRight.horizontal, borderY);\n  if (adjustedBorderRadius.topRight.horizontal > 0 || adjustedBorderRadius.topRight.vertical > 0) {\n    ctx.ellipse(borderX + borderW - adjustedBorderRadius.topRight.horizontal, borderY + adjustedBorderRadius.topRight.vertical, adjustedBorderRadius.topRight.horizontal, adjustedBorderRadius.topRight.vertical, 0, -Math.PI / 2, 0);\n  }\n  ctx.lineTo(borderX + borderW, borderY + borderH - adjustedBorderRadius.bottomRight.vertical);\n  if (adjustedBorderRadius.bottomRight.horizontal > 0 || adjustedBorderRadius.bottomRight.vertical > 0) {\n    ctx.ellipse(borderX + borderW - adjustedBorderRadius.bottomRight.horizontal, borderY + borderH - adjustedBorderRadius.bottomRight.vertical, adjustedBorderRadius.bottomRight.horizontal, adjustedBorderRadius.bottomRight.vertical, 0, 0, Math.PI / 2);\n  }\n  ctx.lineTo(borderX + adjustedBorderRadius.bottomLeft.horizontal, borderY + borderH);\n  if (adjustedBorderRadius.bottomLeft.horizontal > 0 || adjustedBorderRadius.bottomLeft.vertical > 0) {\n    ctx.ellipse(borderX + adjustedBorderRadius.bottomLeft.horizontal, borderY + borderH - adjustedBorderRadius.bottomLeft.vertical, adjustedBorderRadius.bottomLeft.horizontal, adjustedBorderRadius.bottomLeft.vertical, 0, Math.PI / 2, Math.PI);\n  }\n  ctx.lineTo(borderX, borderY + adjustedBorderRadius.topLeft.vertical);\n  if (adjustedBorderRadius.topLeft.horizontal > 0 || adjustedBorderRadius.topLeft.vertical > 0) {\n    ctx.ellipse(borderX + adjustedBorderRadius.topLeft.horizontal, borderY + adjustedBorderRadius.topLeft.vertical, adjustedBorderRadius.topLeft.horizontal, adjustedBorderRadius.topLeft.vertical, 0, Math.PI, Math.PI * 3 / 2);\n  }\n  ctx.closePath();\n  ctx.stroke();\n};\nvar drawBorder = ({\n  ctx,\n  rect,\n  borderRadius,\n  computedStyle\n}) => {\n  const borders = getBorderSideProperties(computedStyle);\n  const hasBorder = borders.top.width > 0 || borders.right.width > 0 || borders.bottom.width > 0 || borders.left.width > 0;\n  if (!hasBorder) {\n    return;\n  }\n  const originalStrokeStyle = ctx.strokeStyle;\n  const originalLineWidth = ctx.lineWidth;\n  const originalLineDash = ctx.getLineDash();\n  const allSidesEqual = borders.top.width === borders.right.width && borders.top.width === borders.bottom.width && borders.top.width === borders.left.width && borders.top.color === borders.right.color && borders.top.color === borders.bottom.color && borders.top.color === borders.left.color && borders.top.style === borders.right.style && borders.top.style === borders.bottom.style && borders.top.style === borders.left.style && borders.top.width > 0;\n  if (allSidesEqual) {\n    drawUniformBorder({\n      ctx,\n      x: rect.left,\n      y: rect.top,\n      width: rect.width,\n      height: rect.height,\n      borderRadius,\n      borderWidth: borders.top.width,\n      borderColor: borders.top.color,\n      borderStyle: borders.top.style\n    });\n  } else {\n    drawCorner({\n      ctx,\n      corner: \"topLeft\",\n      x: rect.left,\n      y: rect.top,\n      width: rect.width,\n      height: rect.height,\n      borderRadius,\n      topBorder: borders.top,\n      rightBorder: borders.right,\n      bottomBorder: borders.bottom,\n      leftBorder: borders.left\n    });\n    drawCorner({\n      ctx,\n      corner: \"topRight\",\n      x: rect.left,\n      y: rect.top,\n      width: rect.width,\n      height: rect.height,\n      borderRadius,\n      topBorder: borders.top,\n      rightBorder: borders.right,\n      bottomBorder: borders.bottom,\n      leftBorder: borders.left\n    });\n    drawCorner({\n      ctx,\n      corner: \"bottomRight\",\n      x: rect.left,\n      y: rect.top,\n      width: rect.width,\n      height: rect.height,\n      borderRadius,\n      topBorder: borders.top,\n      rightBorder: borders.right,\n      bottomBorder: borders.bottom,\n      leftBorder: borders.left\n    });\n    drawCorner({\n      ctx,\n      corner: \"bottomLeft\",\n      x: rect.left,\n      y: rect.top,\n      width: rect.width,\n      height: rect.height,\n      borderRadius,\n      topBorder: borders.top,\n      rightBorder: borders.right,\n      bottomBorder: borders.bottom,\n      leftBorder: borders.left\n    });\n    drawBorderSide({\n      ctx,\n      side: \"top\",\n      x: rect.left,\n      y: rect.top,\n      width: rect.width,\n      height: rect.height,\n      borderRadius,\n      borderProperties: borders.top\n    });\n    drawBorderSide({\n      ctx,\n      side: \"right\",\n      x: rect.left,\n      y: rect.top,\n      width: rect.width,\n      height: rect.height,\n      borderRadius,\n      borderProperties: borders.right\n    });\n    drawBorderSide({\n      ctx,\n      side: \"bottom\",\n      x: rect.left,\n      y: rect.top,\n      width: rect.width,\n      height: rect.height,\n      borderRadius,\n      borderProperties: borders.bottom\n    });\n    drawBorderSide({\n      ctx,\n      side: \"left\",\n      x: rect.left,\n      y: rect.top,\n      width: rect.width,\n      height: rect.height,\n      borderRadius,\n      borderProperties: borders.left\n    });\n  }\n  ctx.strokeStyle = originalStrokeStyle;\n  ctx.lineWidth = originalLineWidth;\n  ctx.setLineDash(originalLineDash);\n};\n\n// src/drawing/draw-box-shadow.ts\nimport { Internals as Internals5 } from \"remotion\";\nvar parseBoxShadow = (boxShadowValue) => {\n  if (!boxShadowValue || boxShadowValue === \"none\") {\n    return [];\n  }\n  const shadows = [];\n  const shadowStrings = boxShadowValue.split(/,(?![^(]*\\))/);\n  for (const shadowStr of shadowStrings) {\n    const trimmed = shadowStr.trim();\n    if (!trimmed || trimmed === \"none\") {\n      continue;\n    }\n    const shadow = {\n      offsetX: 0,\n      offsetY: 0,\n      blurRadius: 0,\n      color: \"rgba(0, 0, 0, 0.5)\",\n      inset: false\n    };\n    shadow.inset = /\\binset\\b/i.test(trimmed);\n    let remaining = trimmed.replace(/\\binset\\b/gi, \"\").trim();\n    const colorMatch = remaining.match(/(rgba?\\([^)]+\\)|hsla?\\([^)]+\\)|#[0-9a-f]{3,8}|[a-z]+)/i);\n    if (colorMatch) {\n      shadow.color = colorMatch[0];\n      remaining = remaining.replace(colorMatch[0], \"\").trim();\n    }\n    const numbers = remaining.match(/[+-]?\\d*\\.?\\d+(?:px|em|rem|%)?/gi) || [];\n    const values = numbers.map((n) => parseFloat(n) || 0);\n    if (values.length >= 2) {\n      shadow.offsetX = values[0];\n      shadow.offsetY = values[1];\n      if (values.length >= 3) {\n        shadow.blurRadius = Math.max(0, values[2]);\n      }\n    }\n    shadows.push(shadow);\n  }\n  return shadows;\n};\nvar drawBorderRadius = ({\n  ctx,\n  rect,\n  borderRadius,\n  computedStyle,\n  logLevel\n}) => {\n  const shadows = parseBoxShadow(computedStyle.boxShadow);\n  if (shadows.length === 0) {\n    return;\n  }\n  for (let i = shadows.length - 1;i >= 0; i--) {\n    const shadow = shadows[i];\n    const newLeft = rect.left + Math.min(shadow.offsetX, 0) - shadow.blurRadius;\n    const newRight = rect.right + Math.max(shadow.offsetX, 0) + shadow.blurRadius;\n    const newTop = rect.top + Math.min(shadow.offsetY, 0) - shadow.blurRadius;\n    const newBottom = rect.bottom + Math.max(shadow.offsetY, 0) + shadow.blurRadius;\n    const newRect = new DOMRect(newLeft, newTop, newRight - newLeft, newBottom - newTop);\n    const leftOffset = rect.left - newLeft;\n    const topOffset = rect.top - newTop;\n    const newCanvas = new OffscreenCanvas(newRect.width, newRect.height);\n    const newCtx = newCanvas.getContext(\"2d\");\n    if (!newCtx) {\n      throw new Error(\"Failed to get context\");\n    }\n    if (shadow.inset) {\n      Internals5.Log.warn({\n        logLevel,\n        tag: \"@remotion/web-renderer\"\n      }, 'Detected \"box-shadow\" with \"inset\". This is not yet supported in @remotion/web-renderer');\n      continue;\n    }\n    newCtx.shadowBlur = shadow.blurRadius;\n    newCtx.shadowColor = shadow.color;\n    newCtx.shadowOffsetX = shadow.offsetX;\n    newCtx.shadowOffsetY = shadow.offsetY;\n    newCtx.fillStyle = \"black\";\n    drawRoundedRectPath({\n      ctx: newCtx,\n      x: leftOffset,\n      y: topOffset,\n      width: rect.width,\n      height: rect.height,\n      borderRadius\n    });\n    newCtx.fill();\n    newCtx.shadowColor = \"transparent\";\n    newCtx.globalCompositeOperation = \"destination-out\";\n    drawRoundedRectPath({\n      ctx: newCtx,\n      x: leftOffset,\n      y: topOffset,\n      width: rect.width,\n      height: rect.height,\n      borderRadius\n    });\n    newCtx.fill();\n    ctx.drawImage(newCanvas, rect.left - leftOffset, rect.top - topOffset);\n  }\n};\n\n// src/drawing/draw-outline.ts\nvar parseOutlineWidth = (value) => {\n  return parseFloat(value) || 0;\n};\nvar parseOutlineOffset = (value) => {\n  return parseFloat(value) || 0;\n};\nvar getLineDashPattern2 = (style, width) => {\n  if (style === \"dashed\") {\n    return [width * 2, width];\n  }\n  if (style === \"dotted\") {\n    return [width, width];\n  }\n  return [];\n};\nvar drawOutline = ({\n  ctx,\n  rect,\n  borderRadius,\n  computedStyle\n}) => {\n  const outlineWidth = parseOutlineWidth(computedStyle.outlineWidth);\n  const { outlineStyle } = computedStyle;\n  const outlineColor = computedStyle.outlineColor || \"black\";\n  const outlineOffset = parseOutlineOffset(computedStyle.outlineOffset);\n  if (outlineWidth <= 0 || outlineStyle === \"none\" || outlineStyle === \"hidden\") {\n    return;\n  }\n  const originalStrokeStyle = ctx.strokeStyle;\n  const originalLineWidth = ctx.lineWidth;\n  const originalLineDash = ctx.getLineDash();\n  ctx.strokeStyle = outlineColor;\n  ctx.lineWidth = outlineWidth;\n  ctx.setLineDash(getLineDashPattern2(outlineStyle, outlineWidth));\n  const halfWidth = outlineWidth / 2;\n  const offset = outlineOffset + halfWidth;\n  const outlineX = rect.left - offset;\n  const outlineY = rect.top - offset;\n  const outlineW = rect.width + offset * 2;\n  const outlineH = rect.height + offset * 2;\n  const adjustedBorderRadius = {\n    topLeft: {\n      horizontal: borderRadius.topLeft.horizontal === 0 ? 0 : Math.max(0, borderRadius.topLeft.horizontal + offset),\n      vertical: borderRadius.topLeft.vertical === 0 ? 0 : Math.max(0, borderRadius.topLeft.vertical + offset)\n    },\n    topRight: {\n      horizontal: borderRadius.topRight.horizontal === 0 ? 0 : Math.max(0, borderRadius.topRight.horizontal + offset),\n      vertical: borderRadius.topRight.vertical === 0 ? 0 : Math.max(0, borderRadius.topRight.vertical + offset)\n    },\n    bottomRight: {\n      horizontal: borderRadius.bottomRight.horizontal === 0 ? 0 : Math.max(0, borderRadius.bottomRight.horizontal + offset),\n      vertical: borderRadius.bottomRight.vertical === 0 ? 0 : Math.max(0, borderRadius.bottomRight.vertical + offset)\n    },\n    bottomLeft: {\n      horizontal: borderRadius.bottomLeft.horizontal === 0 ? 0 : Math.max(0, borderRadius.bottomLeft.horizontal + offset),\n      vertical: borderRadius.bottomLeft.vertical === 0 ? 0 : Math.max(0, borderRadius.bottomLeft.vertical + offset)\n    }\n  };\n  drawRoundedRectPath({\n    ctx,\n    x: outlineX,\n    y: outlineY,\n    width: outlineW,\n    height: outlineH,\n    borderRadius: adjustedBorderRadius\n  });\n  ctx.stroke();\n  ctx.strokeStyle = originalStrokeStyle;\n  ctx.lineWidth = originalLineWidth;\n  ctx.setLineDash(originalLineDash);\n};\n\n// src/drawing/opacity.ts\nvar setOpacity = ({\n  ctx,\n  opacity\n}) => {\n  const previousAlpha = ctx.globalAlpha;\n  ctx.globalAlpha = previousAlpha * opacity;\n  return () => {\n    ctx.globalAlpha = previousAlpha;\n  };\n};\n\n// src/drawing/overflow.ts\nvar setOverflowHidden = ({\n  ctx,\n  rect,\n  borderRadius,\n  overflowHidden,\n  computedStyle,\n  backgroundClip\n}) => {\n  if (!overflowHidden) {\n    return () => {};\n  }\n  return setBorderRadius({\n    ctx,\n    rect,\n    borderRadius,\n    forceClipEvenWhenZero: true,\n    computedStyle,\n    backgroundClip\n  });\n};\n\n// src/drawing/transform.ts\nvar setTransform = ({\n  ctx,\n  transform,\n  parentRect,\n  scale\n}) => {\n  const offsetMatrix = new DOMMatrix().scale(scale, scale).translate(-parentRect.x, -parentRect.y).multiply(transform).translate(parentRect.x, parentRect.y);\n  ctx.setTransform(offsetMatrix);\n  return () => {\n    ctx.setTransform(new DOMMatrix);\n  };\n};\n\n// src/drawing/draw-element.ts\nvar drawElement = async ({\n  rect,\n  computedStyle,\n  context,\n  draw,\n  opacity,\n  totalMatrix,\n  parentRect,\n  logLevel,\n  element,\n  internalState,\n  scale\n}) => {\n  const { backgroundImage, backgroundColor, backgroundClip } = computedStyle;\n  const borderRadius = parseBorderRadius({\n    borderRadius: computedStyle.borderRadius,\n    width: rect.width,\n    height: rect.height\n  });\n  const finishTransform = setTransform({\n    ctx: context,\n    transform: totalMatrix,\n    parentRect,\n    scale\n  });\n  const finishOpacity = setOpacity({\n    ctx: context,\n    opacity\n  });\n  drawBorderRadius({\n    ctx: context,\n    computedStyle,\n    rect,\n    borderRadius,\n    logLevel\n  });\n  const finishBorderRadius = setBorderRadius({\n    ctx: context,\n    rect,\n    borderRadius,\n    forceClipEvenWhenZero: false,\n    computedStyle,\n    backgroundClip\n  });\n  await drawBackground({\n    backgroundImage,\n    context,\n    rect,\n    backgroundColor,\n    backgroundClip,\n    element,\n    logLevel,\n    internalState,\n    computedStyle,\n    offsetLeft: parentRect.left,\n    offsetTop: parentRect.top,\n    scale\n  });\n  await draw({ dimensions: rect, computedStyle, contextToDraw: context });\n  finishBorderRadius();\n  drawBorder({\n    ctx: context,\n    rect,\n    borderRadius,\n    computedStyle\n  });\n  drawOutline({\n    ctx: context,\n    rect,\n    borderRadius,\n    computedStyle\n  });\n  const finishOverflowHidden = setOverflowHidden({\n    ctx: context,\n    rect,\n    borderRadius,\n    overflowHidden: computedStyle.overflow === \"hidden\",\n    computedStyle,\n    backgroundClip\n  });\n  finishTransform();\n  return {\n    cleanupAfterChildren: () => {\n      finishOpacity();\n      finishOverflowHidden();\n    }\n  };\n};\n\n// src/walk-tree.ts\nfunction skipToNextNonDescendant(treeWalker) {\n  if (treeWalker.nextSibling()) {\n    return true;\n  }\n  while (treeWalker.parentNode()) {\n    if (treeWalker.nextSibling()) {\n      return true;\n    }\n  }\n  return false;\n}\n\n// src/get-biggest-bounding-client-rect.ts\nvar getBiggestBoundingClientRect = (element) => {\n  const treeWalker = document.createTreeWalker(element, NodeFilter.SHOW_ELEMENT);\n  let mostLeft = Infinity;\n  let mostTop = Infinity;\n  let mostRight = -Infinity;\n  let mostBottom = -Infinity;\n  while (true) {\n    const computedStyle = getComputedStyle(treeWalker.currentNode);\n    const outlineWidth = parseOutlineWidth(computedStyle.outlineWidth);\n    const outlineOffset = parseOutlineOffset(computedStyle.outlineOffset);\n    const rect = treeWalker.currentNode.getBoundingClientRect();\n    const shadows = parseBoxShadow(computedStyle.boxShadow);\n    let shadowLeft = 0;\n    let shadowRight = 0;\n    let shadowTop = 0;\n    let shadowBottom = 0;\n    for (const shadow of shadows) {\n      if (!shadow.inset) {\n        shadowLeft = Math.max(shadowLeft, Math.abs(Math.min(shadow.offsetX, 0)) + shadow.blurRadius);\n        shadowRight = Math.max(shadowRight, Math.max(shadow.offsetX, 0) + shadow.blurRadius);\n        shadowTop = Math.max(shadowTop, Math.abs(Math.min(shadow.offsetY, 0)) + shadow.blurRadius);\n        shadowBottom = Math.max(shadowBottom, Math.max(shadow.offsetY, 0) + shadow.blurRadius);\n      }\n    }\n    mostLeft = Math.min(mostLeft, rect.left - outlineOffset - outlineWidth - shadowLeft);\n    mostTop = Math.min(mostTop, rect.top - outlineOffset - outlineWidth - shadowTop);\n    mostRight = Math.max(mostRight, rect.right + outlineOffset + outlineWidth + shadowRight);\n    mostBottom = Math.max(mostBottom, rect.bottom + outlineOffset + outlineWidth + shadowBottom);\n    if (computedStyle.overflow === \"hidden\") {\n      if (!skipToNextNonDescendant(treeWalker)) {\n        break;\n      }\n    }\n    if (!treeWalker.nextNode()) {\n      break;\n    }\n  }\n  return new DOMRect(mostLeft, mostTop, mostRight - mostLeft, mostBottom - mostTop);\n};\n\n// src/drawing/get-pretransform-rect.ts\nvar MAX_SCALE_FACTOR = 100;\nvar isScaleTooBig = (matrix) => {\n  const origin = new DOMPoint(0, 0).matrixTransform(matrix);\n  const unitX = new DOMPoint(1, 0).matrixTransform(matrix);\n  const unitY = new DOMPoint(0, 1).matrixTransform(matrix);\n  const basisX = { x: unitX.x - origin.x, y: unitX.y - origin.y };\n  const basisY = { x: unitY.x - origin.x, y: unitY.y - origin.y };\n  const scaleX = 1 / Math.hypot(basisX.x, basisX.y);\n  const scaleY = 1 / Math.hypot(basisY.x, basisY.y);\n  const maxScale = Math.max(scaleX, scaleY);\n  if (maxScale > MAX_SCALE_FACTOR) {\n    return true;\n  }\n  return false;\n};\nfunction invertProjectivePoint(xp, yp, matrix) {\n  const A = matrix.m11 - xp * matrix.m14;\n  const B = matrix.m21 - xp * matrix.m24;\n  const C = xp * matrix.m44 - matrix.m41;\n  const D = matrix.m12 - yp * matrix.m14;\n  const E = matrix.m22 - yp * matrix.m24;\n  const F = yp * matrix.m44 - matrix.m42;\n  const det = A * E - B * D;\n  if (Math.abs(det) < 0.0000000001) {\n    return null;\n  }\n  const x = (C * E - B * F) / det;\n  const y = (A * F - C * D) / det;\n  return { x, y };\n}\nfunction getPreTransformRect(targetRect, matrix) {\n  if (isScaleTooBig(matrix)) {\n    return null;\n  }\n  const corners = [\n    { x: targetRect.x, y: targetRect.y },\n    { x: targetRect.x + targetRect.width, y: targetRect.y },\n    { x: targetRect.x + targetRect.width, y: targetRect.y + targetRect.height },\n    { x: targetRect.x, y: targetRect.y + targetRect.height }\n  ];\n  const invertedCorners = [];\n  for (const corner of corners) {\n    const inverted = invertProjectivePoint(corner.x, corner.y, matrix);\n    if (inverted === null) {\n      return null;\n    }\n    invertedCorners.push(inverted);\n  }\n  const xCoords = invertedCorners.map((p) => p.x);\n  const yCoords = invertedCorners.map((p) => p.y);\n  return new DOMRect(Math.min(...xCoords), Math.min(...yCoords), Math.max(...xCoords) - Math.min(...xCoords), Math.max(...yCoords) - Math.min(...yCoords));\n}\n\n// src/drawing/transform-in-3d.ts\nvar vsSource = `\n    attribute vec2 aPosition;\n    attribute vec2 aTexCoord;\n    uniform mat4 uTransform;\n    uniform vec2 uResolution;\n    uniform vec2 uOffset;\n    varying vec2 vTexCoord;\n\n    void main() {\n        vec4 pos = uTransform * vec4(aPosition, 0.0, 1.0);\n        pos.xy = pos.xy + uOffset * pos.w;\n\n        // Convert homogeneous coords to clip space\n        gl_Position = vec4(\n            (pos.x / uResolution.x) * 2.0 - pos.w,   // x\n            pos.w - (pos.y / uResolution.y) * 2.0,   // y (flipped)\n            0.0,\n            pos.w\n        );\n\n        vTexCoord = aTexCoord;\n    }\n`;\nvar fsSource = `\n\t\tprecision mediump float;\n\t\tuniform sampler2D uTexture;\n\t\tvarying vec2 vTexCoord;\n\n\t\tvoid main() {\n\t\t\t\tgl_FragColor = texture2D(uTexture, vTexCoord);\n\t\t}\n`;\nfunction compileShader(shaderGl, source, type) {\n  const shader = shaderGl.createShader(type);\n  if (!shader) {\n    throw new Error(\"Could not create shader\");\n  }\n  shaderGl.shaderSource(shader, source);\n  shaderGl.compileShader(shader);\n  if (!shaderGl.getShaderParameter(shader, shaderGl.COMPILE_STATUS)) {\n    const log = shaderGl.getShaderInfoLog(shader);\n    shaderGl.deleteShader(shader);\n    throw new Error(\"Shader compile error: \" + log);\n  }\n  return shader;\n}\nvar createHelperCanvas = ({\n  canvasWidth,\n  canvasHeight,\n  helperCanvasState\n}) => {\n  if (helperCanvasState.current) {\n    if (helperCanvasState.current.canvas.width !== canvasWidth || helperCanvasState.current.canvas.height !== canvasHeight) {\n      helperCanvasState.current.canvas.width = canvasWidth;\n      helperCanvasState.current.canvas.height = canvasHeight;\n    }\n    helperCanvasState.current.gl.viewport(0, 0, canvasWidth, canvasHeight);\n    helperCanvasState.current.gl.clearColor(0, 0, 0, 0);\n    helperCanvasState.current.gl.clear(helperCanvasState.current.gl.COLOR_BUFFER_BIT);\n    return helperCanvasState.current;\n  }\n  const canvas = new OffscreenCanvas(canvasWidth, canvasHeight);\n  const gl = canvas.getContext(\"webgl\", {\n    premultipliedAlpha: true\n  }) ?? undefined;\n  if (!gl) {\n    throw new Error(\"WebGL not supported\");\n  }\n  const vertexShader = compileShader(gl, vsSource, gl.VERTEX_SHADER);\n  const fragmentShader = compileShader(gl, fsSource, gl.FRAGMENT_SHADER);\n  const program = gl.createProgram();\n  if (!program) {\n    throw new Error(\"Could not create program\");\n  }\n  gl.attachShader(program, vertexShader);\n  gl.attachShader(program, fragmentShader);\n  gl.linkProgram(program);\n  if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {\n    throw new Error(\"Program link error: \" + gl.getProgramInfoLog(program));\n  }\n  const locations = {\n    aPosition: gl.getAttribLocation(program, \"aPosition\"),\n    aTexCoord: gl.getAttribLocation(program, \"aTexCoord\"),\n    uTransform: gl.getUniformLocation(program, \"uTransform\"),\n    uResolution: gl.getUniformLocation(program, \"uResolution\"),\n    uOffset: gl.getUniformLocation(program, \"uOffset\"),\n    uTexture: gl.getUniformLocation(program, \"uTexture\")\n  };\n  gl.deleteShader(vertexShader);\n  gl.deleteShader(fragmentShader);\n  const cleanup = () => {\n    gl.deleteProgram(program);\n    const loseContext = gl.getExtension(\"WEBGL_lose_context\");\n    if (loseContext) {\n      loseContext.loseContext();\n    }\n  };\n  helperCanvasState.current = { canvas, gl, program, locations, cleanup };\n  return helperCanvasState.current;\n};\nvar transformIn3d = ({\n  matrix,\n  sourceCanvas,\n  sourceRect,\n  destRect,\n  internalState,\n  scale\n}) => {\n  const { canvas, gl, program, locations } = createHelperCanvas({\n    canvasWidth: destRect.width,\n    canvasHeight: destRect.height,\n    helperCanvasState: internalState.helperCanvasState\n  });\n  gl.useProgram(program);\n  gl.viewport(0, 0, destRect.width, destRect.height);\n  gl.clearColor(0, 0, 0, 0);\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.enable(gl.BLEND);\n  gl.blendFunc(gl.ONE, gl.ONE_MINUS_SRC_ALPHA);\n  gl.pixelStorei(gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, true);\n  const positionBuffer = gl.createBuffer();\n  gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);\n  const positions = new Float32Array([\n    sourceRect.x,\n    sourceRect.y,\n    sourceRect.x + sourceRect.width,\n    sourceRect.y,\n    sourceRect.x,\n    sourceRect.y + sourceRect.height,\n    sourceRect.x,\n    sourceRect.y + sourceRect.height,\n    sourceRect.x + sourceRect.width,\n    sourceRect.y,\n    sourceRect.x + sourceRect.width,\n    sourceRect.y + sourceRect.height\n  ]);\n  gl.bufferData(gl.ARRAY_BUFFER, positions, gl.STATIC_DRAW);\n  gl.enableVertexAttribArray(locations.aPosition);\n  gl.vertexAttribPointer(locations.aPosition, 2, gl.FLOAT, false, 0, 0);\n  const texCoordBuffer = gl.createBuffer();\n  gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);\n  const texCoords = new Float32Array([\n    0,\n    0,\n    1,\n    0,\n    0,\n    1,\n    0,\n    1,\n    1,\n    0,\n    1,\n    1\n  ]);\n  gl.bufferData(gl.ARRAY_BUFFER, texCoords, gl.STATIC_DRAW);\n  gl.enableVertexAttribArray(locations.aTexCoord);\n  gl.vertexAttribPointer(locations.aTexCoord, 2, gl.FLOAT, false, 0, 0);\n  const texture = gl.createTexture();\n  gl.bindTexture(gl.TEXTURE_2D, texture);\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);\n  gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, sourceCanvas);\n  const actualMatrix = scale !== 1 ? new DOMMatrix().scale(scale, scale).multiply(matrix) : matrix;\n  const transformMatrix = actualMatrix.toFloat32Array();\n  gl.uniformMatrix4fv(locations.uTransform, false, transformMatrix);\n  gl.uniform2f(locations.uResolution, destRect.width, destRect.height);\n  gl.uniform2f(locations.uOffset, -destRect.x, -destRect.y);\n  gl.uniform1i(locations.uTexture, 0);\n  gl.drawArrays(gl.TRIANGLES, 0, 6);\n  gl.disableVertexAttribArray(locations.aPosition);\n  gl.disableVertexAttribArray(locations.aTexCoord);\n  gl.deleteTexture(texture);\n  gl.deleteBuffer(positionBuffer);\n  gl.deleteBuffer(texCoordBuffer);\n  gl.bindTexture(gl.TEXTURE_2D, null);\n  gl.bindBuffer(gl.ARRAY_BUFFER, null);\n  gl.disable(gl.BLEND);\n  gl.pixelStorei(gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, false);\n  return canvas;\n};\n\n// src/drawing/handle-3d-transform.ts\nvar getPrecomposeRectFor3DTransform = ({\n  element,\n  parentRect,\n  matrix\n}) => {\n  const unclampedBiggestBoundingClientRect = getBiggestBoundingClientRect(element);\n  const biggestPossiblePretransformRect = getPreTransformRect(parentRect, matrix);\n  if (!biggestPossiblePretransformRect) {\n    return null;\n  }\n  const preTransformRect = getNarrowerRect({\n    firstRect: unclampedBiggestBoundingClientRect,\n    secondRect: biggestPossiblePretransformRect\n  });\n  return preTransformRect;\n};\nvar handle3dTransform = ({\n  matrix,\n  sourceRect,\n  tempCanvas,\n  rectAfterTransforms,\n  internalState,\n  scale\n}) => {\n  if (rectAfterTransforms.width <= 0 || rectAfterTransforms.height <= 0) {\n    return null;\n  }\n  const transformed = transformIn3d({\n    sourceRect,\n    matrix,\n    sourceCanvas: tempCanvas,\n    destRect: rectAfterTransforms,\n    internalState,\n    scale\n  });\n  return transformed;\n};\n\n// src/drawing/handle-mask.ts\nvar getPrecomposeRectForMask = (element) => {\n  const boundingRect = getBiggestBoundingClientRect(element);\n  return boundingRect;\n};\nvar handleMask = ({\n  gradientInfo,\n  rect,\n  precomposeRect,\n  tempContext,\n  scale\n}) => {\n  const rectToFill = new DOMRect((rect.left - precomposeRect.left) * scale, (rect.top - precomposeRect.top) * scale, rect.width * scale, rect.height * scale);\n  const gradient = createCanvasGradient({\n    ctx: tempContext,\n    rect: rectToFill,\n    gradientInfo,\n    offsetLeft: 0,\n    offsetTop: 0\n  });\n  tempContext.globalCompositeOperation = \"destination-in\";\n  tempContext.fillStyle = gradient;\n  tempContext.fillRect(rectToFill.left, rectToFill.top, rectToFill.width, rectToFill.height);\n};\n\n// src/drawing/scale-rect.ts\nvar scaleRect = ({\n  rect,\n  scale\n}) => {\n  return new DOMRect(rect.x * scale, rect.y * scale, rect.width * scale, rect.height * scale);\n};\n\n// src/drawing/transform-rect-with-matrix.ts\nfunction transformDOMRect({\n  rect,\n  matrix\n}) {\n  const topLeft = new DOMPointReadOnly(rect.left, rect.top);\n  const topRight = new DOMPointReadOnly(rect.right, rect.top);\n  const bottomLeft = new DOMPointReadOnly(rect.left, rect.bottom);\n  const bottomRight = new DOMPointReadOnly(rect.right, rect.bottom);\n  const transformedTopLeft = topLeft.matrixTransform(matrix);\n  const transformedTopRight = topRight.matrixTransform(matrix);\n  const transformedBottomLeft = bottomLeft.matrixTransform(matrix);\n  const transformedBottomRight = bottomRight.matrixTransform(matrix);\n  const minX = Math.min(transformedTopLeft.x / transformedTopLeft.w, transformedTopRight.x / transformedTopRight.w, transformedBottomLeft.x / transformedBottomLeft.w, transformedBottomRight.x / transformedBottomRight.w);\n  const maxX = Math.max(transformedTopLeft.x / transformedTopLeft.w, transformedTopRight.x / transformedTopRight.w, transformedBottomLeft.x / transformedBottomLeft.w, transformedBottomRight.x / transformedBottomRight.w);\n  const minY = Math.min(transformedTopLeft.y / transformedTopLeft.w, transformedTopRight.y / transformedTopRight.w, transformedBottomLeft.y / transformedBottomLeft.w, transformedBottomRight.y / transformedBottomRight.w);\n  const maxY = Math.max(transformedTopLeft.y / transformedTopLeft.w, transformedTopRight.y / transformedTopRight.w, transformedBottomLeft.y / transformedBottomLeft.w, transformedBottomRight.y / transformedBottomRight.w);\n  return new DOMRect(minX, minY, maxX - minX, maxY - minY);\n}\n\n// src/drawing/process-node.ts\nvar processNode = async ({\n  element,\n  context,\n  draw,\n  logLevel,\n  parentRect,\n  internalState,\n  rootElement,\n  scale\n}) => {\n  let __stack = [];\n  try {\n    const transforms = __using(__stack, calculateTransforms({\n      element,\n      rootElement\n    }), 0);\n    const { opacity, computedStyle, totalMatrix, dimensions, precompositing } = transforms;\n    if (opacity === 0) {\n      return { type: \"skip-children\" };\n    }\n    if (computedStyle.backfaceVisibility === \"hidden\" && totalMatrix.m33 < 0) {\n      return { type: \"skip-children\" };\n    }\n    if (dimensions.width <= 0 || dimensions.height <= 0) {\n      return { type: \"continue\", cleanupAfterChildren: null };\n    }\n    const rect = new DOMRect(dimensions.left - parentRect.x, dimensions.top - parentRect.y, dimensions.width, dimensions.height);\n    if (precompositing.needsPrecompositing) {\n      const start = Date.now();\n      let precomposeRect = null;\n      if (precompositing.needsMaskImage) {\n        precomposeRect = roundToExpandRect(getPrecomposeRectForMask(element));\n      }\n      if (precompositing.needs3DTransformViaWebGL) {\n        const tentativePrecomposeRect = getPrecomposeRectFor3DTransform({\n          element,\n          parentRect,\n          matrix: totalMatrix\n        });\n        if (!tentativePrecomposeRect) {\n          return { type: \"continue\", cleanupAfterChildren: null };\n        }\n        precomposeRect = roundToExpandRect(getWiderRectAndExpand({\n          firstRect: precomposeRect,\n          secondRect: tentativePrecomposeRect\n        }));\n      }\n      if (!precomposeRect) {\n        throw new Error(\"Precompose rect not found\");\n      }\n      if (precomposeRect.width <= 0 || precomposeRect.height <= 0) {\n        return { type: \"continue\", cleanupAfterChildren: null };\n      }\n      if (!doRectsIntersect(precomposeRect, parentRect)) {\n        return { type: \"continue\", cleanupAfterChildren: null };\n      }\n      const tempContext = await createLayer({\n        cutout: precomposeRect,\n        element,\n        logLevel,\n        internalState,\n        scale,\n        onlyBackgroundClipText: false\n      });\n      let drawable = tempContext.canvas;\n      const rectAfterTransforms = roundToExpandRect(scaleRect({\n        scale,\n        rect: transformDOMRect({\n          rect: precomposeRect,\n          matrix: totalMatrix\n        })\n      }));\n      if (precompositing.needsMaskImage) {\n        handleMask({\n          gradientInfo: precompositing.needsMaskImage,\n          rect,\n          precomposeRect,\n          tempContext,\n          scale\n        });\n      }\n      if (precompositing.needs3DTransformViaWebGL) {\n        const t = handle3dTransform({\n          matrix: totalMatrix,\n          sourceRect: precomposeRect,\n          tempCanvas: drawable,\n          rectAfterTransforms,\n          internalState,\n          scale\n        });\n        if (t) {\n          drawable = t;\n        }\n      }\n      const previousTransform = context.getTransform();\n      context.setTransform(new DOMMatrix);\n      context.drawImage(drawable, 0, drawable.height - rectAfterTransforms.height, rectAfterTransforms.width, rectAfterTransforms.height, rectAfterTransforms.left - parentRect.x, rectAfterTransforms.top - parentRect.y, rectAfterTransforms.width, rectAfterTransforms.height);\n      context.setTransform(previousTransform);\n      Internals6.Log.trace({\n        logLevel,\n        tag: \"@remotion/web-renderer\"\n      }, `Transforming element in 3D - canvas size: ${precomposeRect.width}x${precomposeRect.height} - compose: ${Date.now() - start}ms - helper canvas: ${drawable.width}x${drawable.height}`);\n      internalState.addPrecompose({\n        canvasWidth: precomposeRect.width,\n        canvasHeight: precomposeRect.height\n      });\n      return { type: \"skip-children\" };\n    }\n    const { cleanupAfterChildren } = await drawElement({\n      rect,\n      computedStyle,\n      context,\n      draw,\n      opacity,\n      totalMatrix,\n      parentRect,\n      logLevel,\n      element,\n      internalState,\n      scale\n    });\n    return { type: \"continue\", cleanupAfterChildren };\n  } catch (_catch) {\n    var _err = _catch, _hasErr = 1;\n  } finally {\n    __callDispose(__stack, _err, _hasErr);\n  }\n};\n\n// src/drawing/text/draw-text.ts\nimport { Internals as Internals7 } from \"remotion\";\n\n// src/drawing/text/apply-text-transform.ts\nvar applyTextTransform = (text, transform) => {\n  if (transform === \"uppercase\") {\n    return text.toUpperCase();\n  }\n  if (transform === \"lowercase\") {\n    return text.toLowerCase();\n  }\n  if (transform === \"capitalize\") {\n    return text.replace(/\\b\\w/g, (char) => char.toUpperCase());\n  }\n  return text;\n};\n\n// src/drawing/text/find-line-breaks.text.ts\nvar findWords = (span) => {\n  const originalText = span.textContent;\n  const segmenter = new Intl.Segmenter(\"en\", { granularity: \"word\" });\n  const segments = segmenter.segment(span.textContent);\n  const words = Array.from(segments).map((s) => s.segment);\n  const tokens = [];\n  for (let i = 0;i < words.length; i++) {\n    const wordsBefore = words.slice(0, i);\n    const wordsAfter = words.slice(i + 1);\n    const word = words[i];\n    const wordsBeforeText = wordsBefore.join(\"\");\n    const wordsAfterText = wordsAfter.join(\"\");\n    const beforeNode = document.createTextNode(wordsBeforeText);\n    const afterNode = document.createTextNode(wordsAfterText);\n    const interstitialNode = document.createElement(\"span\");\n    interstitialNode.textContent = word;\n    span.textContent = \"\";\n    span.appendChild(beforeNode);\n    span.appendChild(interstitialNode);\n    span.appendChild(afterNode);\n    const rect = interstitialNode.getBoundingClientRect();\n    span.textContent = originalText;\n    tokens.push({ text: word, rect });\n  }\n  return tokens;\n};\n\n// src/drawing/text/draw-text.ts\nvar drawText = ({\n  span,\n  logLevel,\n  onlyBackgroundClipText,\n  parentRect\n}) => {\n  const drawFn = ({ computedStyle, contextToDraw }) => {\n    const {\n      fontFamily,\n      fontSize,\n      fontWeight,\n      direction,\n      writingMode,\n      letterSpacing,\n      textTransform,\n      webkitTextFillColor\n    } = computedStyle;\n    const isVertical = writingMode !== \"horizontal-tb\";\n    if (isVertical) {\n      Internals7.Log.warn({\n        logLevel,\n        tag: \"@remotion/web-renderer\"\n      }, 'Detected \"writing-mode\" CSS property. Vertical text is not yet supported in @remotion/web-renderer');\n      return;\n    }\n    contextToDraw.save();\n    const fontSizePx = parseFloat(fontSize);\n    contextToDraw.font = `${fontWeight} ${fontSizePx}px ${fontFamily}`;\n    contextToDraw.fillStyle = onlyBackgroundClipText ? \"black\" : webkitTextFillColor;\n    contextToDraw.letterSpacing = letterSpacing;\n    const isRTL = direction === \"rtl\";\n    contextToDraw.textAlign = isRTL ? \"right\" : \"left\";\n    contextToDraw.textBaseline = \"alphabetic\";\n    const originalText = span.textContent;\n    const transformedText = applyTextTransform(originalText, textTransform);\n    span.textContent = transformedText;\n    const tokens = findWords(span);\n    for (const token of tokens) {\n      const measurements = contextToDraw.measureText(originalText);\n      const { fontBoundingBoxDescent, fontBoundingBoxAscent } = measurements;\n      const fontHeight = fontBoundingBoxAscent + fontBoundingBoxDescent;\n      const leading = token.rect.height - fontHeight;\n      const halfLeading = leading / 2;\n      contextToDraw.fillText(token.text, (isRTL ? token.rect.right : token.rect.left) - parentRect.x, token.rect.top + fontBoundingBoxAscent + halfLeading - parentRect.y);\n    }\n    span.textContent = originalText;\n    contextToDraw.restore();\n  };\n  return drawFn;\n};\n\n// src/drawing/text/handle-text-node.ts\nvar handleTextNode = async ({\n  node,\n  context,\n  logLevel,\n  parentRect,\n  internalState,\n  rootElement,\n  onlyBackgroundClipText,\n  scale\n}) => {\n  const span = document.createElement(\"span\");\n  const parent = node.parentNode;\n  if (!parent) {\n    throw new Error(\"Text node has no parent\");\n  }\n  parent.insertBefore(span, node);\n  span.appendChild(node);\n  const value = await processNode({\n    context,\n    element: span,\n    draw: drawText({ span, logLevel, onlyBackgroundClipText, parentRect }),\n    logLevel,\n    parentRect,\n    internalState,\n    rootElement,\n    scale\n  });\n  parent.insertBefore(node, span);\n  parent.removeChild(span);\n  return value;\n};\n\n// src/walk-over-node.ts\nvar walkOverNode = ({\n  node,\n  context,\n  logLevel,\n  parentRect,\n  internalState,\n  rootElement,\n  onlyBackgroundClipText,\n  scale\n}) => {\n  if (node instanceof HTMLElement || node instanceof SVGElement) {\n    return processNode({\n      element: node,\n      context,\n      draw: drawDomElement(node),\n      logLevel,\n      parentRect,\n      internalState,\n      rootElement,\n      scale\n    });\n  }\n  if (node instanceof Text) {\n    return handleTextNode({\n      node,\n      context,\n      logLevel,\n      parentRect,\n      internalState,\n      rootElement,\n      onlyBackgroundClipText,\n      scale\n    });\n  }\n  throw new Error(\"Unknown node type\");\n};\n\n// src/compose.ts\nvar getFilterFunction = (node) => {\n  if (!(node instanceof Element)) {\n    return NodeFilter.FILTER_ACCEPT;\n  }\n  if (node.parentElement instanceof SVGSVGElement) {\n    return NodeFilter.FILTER_REJECT;\n  }\n  const computedStyle = getComputedStyle(node);\n  if (computedStyle.display === \"none\") {\n    return NodeFilter.FILTER_REJECT;\n  }\n  return NodeFilter.FILTER_ACCEPT;\n};\nvar compose = async ({\n  element,\n  context,\n  logLevel,\n  parentRect,\n  internalState,\n  onlyBackgroundClipText,\n  scale\n}) => {\n  let __stack = [];\n  try {\n    const treeWalker = document.createTreeWalker(element, onlyBackgroundClipText ? NodeFilter.SHOW_TEXT : NodeFilter.SHOW_ELEMENT | NodeFilter.SHOW_TEXT, getFilterFunction);\n    if (onlyBackgroundClipText) {\n      treeWalker.nextNode();\n      if (!treeWalker.currentNode) {\n        return;\n      }\n    }\n    const treeWalkerClean = __using(__stack, createTreeWalkerCleanupAfterChildren(treeWalker), 0);\n    const { checkCleanUpAtBeginningOfIteration, addCleanup } = treeWalkerClean;\n    while (true) {\n      checkCleanUpAtBeginningOfIteration();\n      const val = await walkOverNode({\n        node: treeWalker.currentNode,\n        context,\n        logLevel,\n        parentRect,\n        internalState,\n        rootElement: element,\n        onlyBackgroundClipText,\n        scale\n      });\n      if (val.type === \"skip-children\") {\n        if (!skipToNextNonDescendant(treeWalker)) {\n          break;\n        }\n      } else {\n        if (val.cleanupAfterChildren) {\n          addCleanup(treeWalker.currentNode, val.cleanupAfterChildren);\n        }\n        if (!treeWalker.nextNode()) {\n          break;\n        }\n      }\n    }\n  } catch (_catch) {\n    var _err = _catch, _hasErr = 1;\n  } finally {\n    __callDispose(__stack, _err, _hasErr);\n  }\n};\n\n// src/take-screenshot.ts\nvar createLayer = async ({\n  element,\n  scale,\n  logLevel,\n  internalState,\n  onlyBackgroundClipText,\n  cutout\n}) => {\n  const scaledWidth = Math.ceil(cutout.width * scale);\n  const scaledHeight = Math.ceil(cutout.height * scale);\n  const canvas = new OffscreenCanvas(scaledWidth, scaledHeight);\n  const context = canvas.getContext(\"2d\");\n  if (!context) {\n    throw new Error(\"Could not get context\");\n  }\n  await compose({\n    element,\n    context,\n    logLevel,\n    parentRect: cutout,\n    internalState,\n    onlyBackgroundClipText,\n    scale\n  });\n  return context;\n};\n\n// src/throttle-progress.ts\nvar DEFAULT_THROTTLE_MS = 250;\nvar createThrottledProgressCallback = (callback, throttleMs = DEFAULT_THROTTLE_MS) => {\n  if (!callback) {\n    return null;\n  }\n  let lastCallTime = 0;\n  let pendingUpdate = null;\n  let timeoutId = null;\n  const throttled = (progress) => {\n    const now = Date.now();\n    const timeSinceLastCall = now - lastCallTime;\n    pendingUpdate = progress;\n    if (timeSinceLastCall >= throttleMs) {\n      lastCallTime = now;\n      callback(progress);\n      pendingUpdate = null;\n      if (timeoutId !== null) {\n        clearTimeout(timeoutId);\n        timeoutId = null;\n      }\n    } else if (timeoutId === null) {\n      const remainingTime = throttleMs - timeSinceLastCall;\n      timeoutId = setTimeout(() => {\n        if (pendingUpdate !== null) {\n          lastCallTime = Date.now();\n          callback(pendingUpdate);\n          pendingUpdate = null;\n        }\n        timeoutId = null;\n      }, remainingTime);\n    }\n  };\n  const cleanup = () => {\n    if (timeoutId !== null) {\n      clearTimeout(timeoutId);\n      timeoutId = null;\n    }\n    pendingUpdate = null;\n  };\n  return { throttled, [Symbol.dispose]: cleanup };\n};\n\n// src/validate-scale.ts\nvar validateScale = (scale) => {\n  if (typeof scale === \"undefined\") {\n    return;\n  }\n  if (typeof scale !== \"number\") {\n    throw new Error('Scale should be a number or undefined, but is \"' + JSON.stringify(scale) + '\"');\n  }\n  if (Number.isNaN(scale)) {\n    throw new Error(\"`scale` should not be NaN, but is NaN\");\n  }\n  if (!Number.isFinite(scale)) {\n    throw new Error(`\"scale\" must be finite, but is ${scale}`);\n  }\n  if (scale <= 0) {\n    throw new Error(`\"scale\" must be bigger than 0, but is ${scale}`);\n  }\n  if (scale > 16) {\n    throw new Error(`\"scale\" must be smaller or equal than 16, but is ${scale}`);\n  }\n};\n\n// src/validate-video-frame.ts\nvar validateVideoFrame = ({\n  originalFrame,\n  returnedFrame,\n  expectedWidth,\n  expectedHeight,\n  expectedTimestamp\n}) => {\n  if (!(returnedFrame instanceof VideoFrame)) {\n    originalFrame.close();\n    throw new Error(\"onFrame callback must return a VideoFrame or void\");\n  }\n  if (returnedFrame === originalFrame) {\n    return returnedFrame;\n  }\n  if (returnedFrame.displayWidth !== expectedWidth || returnedFrame.displayHeight !== expectedHeight) {\n    originalFrame.close();\n    returnedFrame.close();\n    throw new Error(`VideoFrame dimensions mismatch: expected ${expectedWidth}x${expectedHeight}, got ${returnedFrame.displayWidth}x${returnedFrame.displayHeight}`);\n  }\n  if (returnedFrame.timestamp !== expectedTimestamp) {\n    originalFrame.close();\n    returnedFrame.close();\n    throw new Error(`VideoFrame timestamp mismatch: expected ${expectedTimestamp}, got ${returnedFrame.timestamp}`);\n  }\n  originalFrame.close();\n  return returnedFrame;\n};\n\n// src/with-resolvers.ts\nvar withResolvers = function() {\n  let resolve;\n  let reject;\n  const promise = new Promise((res, rej) => {\n    resolve = res;\n    reject = rej;\n  });\n  return { promise, resolve, reject };\n};\n\n// src/wait-for-ready.ts\nvar waitForReady = ({\n  timeoutInMilliseconds,\n  scope,\n  signal,\n  apiName,\n  internalState,\n  keepalive\n}) => {\n  const start = performance.now();\n  const { promise, resolve, reject } = withResolvers();\n  let cancelled = false;\n  const check = () => {\n    if (cancelled) {\n      return;\n    }\n    if (signal?.aborted) {\n      cancelled = true;\n      internalState?.addWaitForReadyTime(performance.now() - start);\n      reject(new Error(`${apiName}() was cancelled`));\n      return;\n    }\n    if (scope.remotion_renderReady === true) {\n      internalState?.addWaitForReadyTime(performance.now() - start);\n      resolve();\n      return;\n    }\n    if (scope.remotion_cancelledError !== undefined) {\n      cancelled = true;\n      internalState?.addWaitForReadyTime(performance.now() - start);\n      const stack = scope.remotion_cancelledError;\n      const message = stack.split(`\n`)[0].replace(/^Error: /, \"\");\n      const error = new Error(message);\n      error.stack = stack;\n      reject(error);\n      return;\n    }\n    if (performance.now() - start > timeoutInMilliseconds + 3000) {\n      cancelled = true;\n      internalState?.addWaitForReadyTime(performance.now() - start);\n      reject(new Error(Object.values(scope.remotion_delayRenderTimeouts).map((d) => d.label).join(\", \")));\n      return;\n    }\n    scheduleNextCheck();\n  };\n  const scheduleNextCheck = () => {\n    const rafTick = new Promise((res) => {\n      requestAnimationFrame(() => res());\n    });\n    const backgroundSafeTick = keepalive ? Promise.race([rafTick, keepalive.waitForTick()]) : rafTick;\n    backgroundSafeTick.then(check);\n  };\n  check();\n  return promise;\n};\n\n// src/web-fs-target.ts\nvar sessionId = null;\nvar getPrefix = () => {\n  if (!sessionId) {\n    sessionId = crypto.randomUUID();\n  }\n  return `__remotion_render:${sessionId}:`;\n};\nvar cleanupStaleOpfsFiles = async () => {\n  try {\n    const root = await navigator.storage.getDirectory();\n    for await (const [name] of root.entries()) {\n      if (name.startsWith(\"__remotion_render:\") && !name.startsWith(getPrefix())) {\n        await root.removeEntry(name);\n      }\n    }\n  } catch {}\n};\nvar createWebFsTarget = async () => {\n  const directoryHandle = await navigator.storage.getDirectory();\n  const filename = `${getPrefix()}${crypto.randomUUID()}`;\n  const fileHandle = await directoryHandle.getFileHandle(filename, {\n    create: true\n  });\n  const writable = await fileHandle.createWritable();\n  const stream = new WritableStream({\n    async write(chunk) {\n      await writable.seek(chunk.position);\n      await writable.write(chunk);\n    }\n  });\n  const getBlob = async () => {\n    const handle = await directoryHandle.getFileHandle(filename);\n    return handle.getFile();\n  };\n  const close = () => writable.close();\n  return { stream, getBlob, close };\n};\n\n// src/render-media-on-web.tsx\nvar internalRenderMediaOnWeb = async ({\n  composition,\n  inputProps,\n  delayRenderTimeoutInMilliseconds,\n  logLevel,\n  mediaCacheSizeInBytes,\n  schema,\n  videoCodec: codec,\n  audioCodec: unresolvedAudioCodec,\n  audioBitrate,\n  container,\n  signal,\n  onProgress,\n  hardwareAcceleration,\n  keyframeIntervalInSeconds,\n  videoBitrate,\n  frameRange,\n  transparent,\n  onArtifact,\n  onFrame,\n  outputTarget: userDesiredOutputTarget,\n  licenseKey,\n  muted,\n  scale\n}) => {\n  let __stack2 = [];\n  try {\n    validateScale(scale);\n    const outputTarget = userDesiredOutputTarget === null ? await canUseWebFsWriter() ? \"web-fs\" : \"arraybuffer\" : userDesiredOutputTarget;\n    if (outputTarget === \"web-fs\") {\n      await cleanupStaleOpfsFiles();\n    }\n    const format = containerToMediabunnyContainer(container);\n    if (codec && !format.getSupportedCodecs().includes(codecToMediabunnyCodec(codec))) {\n      return Promise.reject(new Error(`Codec ${codec} is not supported for container ${container}`));\n    }\n    const resolvedAudioBitrate = typeof audioBitrate === \"number\" ? audioBitrate : getQualityForWebRendererQuality(audioBitrate);\n    let finalAudioCodec = null;\n    if (!muted) {\n      const audioResult = await resolveAudioCodec({\n        container,\n        requestedCodec: unresolvedAudioCodec,\n        userSpecifiedAudioCodec: unresolvedAudioCodec !== undefined && unresolvedAudioCodec !== null,\n        bitrate: resolvedAudioBitrate\n      });\n      for (const issue of audioResult.issues) {\n        if (issue.severity === \"error\") {\n          return Promise.reject(new Error(issue.message));\n        }\n        Internals8.Log.warn({ logLevel, tag: \"@remotion/web-renderer\" }, issue.message);\n      }\n      finalAudioCodec = audioResult.codec;\n    }\n    const resolved = await Internals8.resolveVideoConfig({\n      calculateMetadata: composition.calculateMetadata ?? null,\n      signal: signal ?? new AbortController().signal,\n      defaultProps: composition.defaultProps ?? {},\n      inputProps: inputProps ?? {},\n      compositionId: composition.id,\n      compositionDurationInFrames: composition.durationInFrames ?? null,\n      compositionFps: composition.fps ?? null,\n      compositionHeight: composition.height ?? null,\n      compositionWidth: composition.width ?? null\n    });\n    const realFrameRange = getRealFrameRange(resolved.durationInFrames, frameRange);\n    if (signal?.aborted) {\n      return Promise.reject(new Error(\"renderMediaOnWeb() was cancelled\"));\n    }\n    const scaffold = __using(__stack2, createScaffold({\n      width: resolved.width,\n      height: resolved.height,\n      fps: resolved.fps,\n      durationInFrames: resolved.durationInFrames,\n      Component: composition.component,\n      resolvedProps: resolved.props,\n      id: resolved.id,\n      delayRenderTimeoutInMilliseconds,\n      logLevel,\n      mediaCacheSizeInBytes,\n      schema: schema ?? null,\n      audioEnabled: !muted,\n      videoEnabled: true,\n      initialFrame: 0,\n      defaultCodec: resolved.defaultCodec,\n      defaultOutName: resolved.defaultOutName\n    }), 0);\n    const { delayRenderScope, div, timeUpdater, collectAssets, errorHolder } = scaffold;\n    const internalState = __using(__stack2, makeInternalState(), 0);\n    const keepalive = __using(__stack2, createBackgroundKeepalive({\n      fps: resolved.fps,\n      logLevel\n    }), 0);\n    const artifactsHandler = handleArtifacts();\n    const webFsTarget = outputTarget === \"web-fs\" ? await createWebFsTarget() : null;\n    const target = webFsTarget ? new StreamTarget(webFsTarget.stream) : new BufferTarget;\n    const outputWithCleanup = __using(__stack2, makeOutputWithCleanup({\n      format,\n      target\n    }), 0);\n    const throttledProgress = __using(__stack2, createThrottledProgressCallback(onProgress), 0);\n    const throttledOnProgress = throttledProgress?.throttled ?? null;\n    try {\n      let __stack = [];\n      try {\n        if (signal?.aborted) {\n          throw new Error(\"renderMediaOnWeb() was cancelled\");\n        }\n        await waitForReady({\n          timeoutInMilliseconds: delayRenderTimeoutInMilliseconds,\n          scope: delayRenderScope,\n          signal,\n          apiName: \"renderMediaOnWeb\",\n          internalState,\n          keepalive\n        });\n        checkForError(errorHolder);\n        if (signal?.aborted) {\n          throw new Error(\"renderMediaOnWeb() was cancelled\");\n        }\n        const videoSampleSource = __using(__stack, makeVideoSampleSourceCleanup({\n          codec: codecToMediabunnyCodec(codec),\n          bitrate: typeof videoBitrate === \"number\" ? videoBitrate : getQualityForWebRendererQuality(videoBitrate),\n          sizeChangeBehavior: \"deny\",\n          hardwareAcceleration,\n          latencyMode: \"quality\",\n          keyFrameInterval: keyframeIntervalInSeconds,\n          alpha: transparent ? \"keep\" : \"discard\"\n        }), 0);\n        outputWithCleanup.output.addVideoTrack(videoSampleSource.videoSampleSource);\n        const audioSampleSource = __using(__stack, createAudioSampleSource({\n          muted,\n          codec: finalAudioCodec ? audioCodecToMediabunnyAudioCodec(finalAudioCodec) : null,\n          bitrate: resolvedAudioBitrate\n        }), 0);\n        if (audioSampleSource) {\n          outputWithCleanup.output.addAudioTrack(audioSampleSource.audioSampleSource);\n        }\n        await outputWithCleanup.output.start();\n        if (signal?.aborted) {\n          throw new Error(\"renderMediaOnWeb() was cancelled\");\n        }\n        const progress = {\n          renderedFrames: 0,\n          encodedFrames: 0\n        };\n        for (let frame = realFrameRange[0];frame <= realFrameRange[1]; frame++) {\n          if (signal?.aborted) {\n            throw new Error(\"renderMediaOnWeb() was cancelled\");\n          }\n          timeUpdater.current?.update(frame);\n          await waitForReady({\n            timeoutInMilliseconds: delayRenderTimeoutInMilliseconds,\n            scope: delayRenderScope,\n            signal,\n            apiName: \"renderMediaOnWeb\",\n            keepalive,\n            internalState\n          });\n          checkForError(errorHolder);\n          if (signal?.aborted) {\n            throw new Error(\"renderMediaOnWeb() was cancelled\");\n          }\n          const createFrameStart = performance.now();\n          const layer = await createLayer({\n            element: div,\n            scale,\n            logLevel,\n            internalState,\n            onlyBackgroundClipText: false,\n            cutout: new DOMRect(0, 0, resolved.width, resolved.height)\n          });\n          internalState.addCreateFrameTime(performance.now() - createFrameStart);\n          if (signal?.aborted) {\n            throw new Error(\"renderMediaOnWeb() was cancelled\");\n          }\n          const timestamp = Math.round((frame - realFrameRange[0]) / resolved.fps * 1e6);\n          const videoFrame = new VideoFrame(layer.canvas, {\n            timestamp\n          });\n          progress.renderedFrames++;\n          throttledOnProgress?.({ ...progress });\n          let frameToEncode = videoFrame;\n          if (onFrame) {\n            const returnedFrame = await onFrame(videoFrame);\n            if (signal?.aborted) {\n              throw new Error(\"renderMediaOnWeb() was cancelled\");\n            }\n            frameToEncode = validateVideoFrame({\n              originalFrame: videoFrame,\n              returnedFrame,\n              expectedWidth: Math.round(resolved.width * scale),\n              expectedHeight: Math.round(resolved.height * scale),\n              expectedTimestamp: timestamp\n            });\n          }\n          const audioCombineStart = performance.now();\n          const assets = collectAssets.current.collectAssets();\n          if (onArtifact) {\n            await artifactsHandler.handle({\n              imageData: layer.canvas,\n              frame,\n              assets,\n              onArtifact\n            });\n          }\n          if (signal?.aborted) {\n            throw new Error(\"renderMediaOnWeb() was cancelled\");\n          }\n          const audio = muted ? null : onlyInlineAudio({ assets, fps: resolved.fps, timestamp });\n          internalState.addAudioMixingTime(performance.now() - audioCombineStart);\n          const addSampleStart = performance.now();\n          await Promise.all([\n            addVideoSampleAndCloseFrame(frameToEncode, videoSampleSource.videoSampleSource),\n            audio && audioSampleSource ? addAudioSample(audio, audioSampleSource.audioSampleSource) : Promise.resolve()\n          ]);\n          internalState.addAddSampleTime(performance.now() - addSampleStart);\n          progress.encodedFrames++;\n          throttledOnProgress?.({ ...progress });\n          if (signal?.aborted) {\n            throw new Error(\"renderMediaOnWeb() was cancelled\");\n          }\n        }\n        onProgress?.({ ...progress });\n        videoSampleSource.videoSampleSource.close();\n        audioSampleSource?.audioSampleSource.close();\n        await outputWithCleanup.output.finalize();\n        Internals8.Log.verbose({ logLevel, tag: \"web-renderer\" }, `Render timings: waitForReady=${internalState.getWaitForReadyTime().toFixed(2)}ms, createFrame=${internalState.getCreateFrameTime().toFixed(2)}ms, addSample=${internalState.getAddSampleTime().toFixed(2)}ms, audioMixing=${internalState.getAudioMixingTime().toFixed(2)}ms`);\n        if (webFsTarget) {\n          sendUsageEvent({\n            licenseKey: licenseKey ?? null,\n            succeeded: true,\n            apiName: \"renderMediaOnWeb\"\n          });\n          await webFsTarget.close();\n          return {\n            getBlob: () => {\n              return webFsTarget.getBlob();\n            },\n            internalState\n          };\n        }\n        if (!(target instanceof BufferTarget)) {\n          throw new Error(\"Expected target to be a BufferTarget\");\n        }\n        sendUsageEvent({\n          licenseKey: licenseKey ?? null,\n          succeeded: true,\n          apiName: \"renderMediaOnWeb\"\n        });\n        return {\n          getBlob: () => {\n            if (!target.buffer) {\n              throw new Error(\"The resulting buffer is empty\");\n            }\n            return Promise.resolve(new Blob([target.buffer], { type: getMimeType(container) }));\n          },\n          internalState\n        };\n      } catch (_catch) {\n        var _err = _catch, _hasErr = 1;\n      } finally {\n        __callDispose(__stack, _err, _hasErr);\n      }\n    } catch (err) {\n      if (!signal?.aborted) {\n        sendUsageEvent({\n          succeeded: false,\n          licenseKey: licenseKey ?? null,\n          apiName: \"renderMediaOnWeb\"\n        }).catch((err2) => {\n          Internals8.Log.error({ logLevel: \"error\", tag: \"web-renderer\" }, \"Failed to send usage event\", err2);\n        });\n      }\n      throw err;\n    }\n  } catch (_catch2) {\n    var _err2 = _catch2, _hasErr2 = 1;\n  } finally {\n    __callDispose(__stack2, _err2, _hasErr2);\n  }\n};\nvar renderMediaOnWeb = (options) => {\n  const container = options.container ?? \"mp4\";\n  const codec = options.videoCodec ?? getDefaultVideoCodecForContainer(container);\n  onlyOneRenderAtATimeQueue.ref = onlyOneRenderAtATimeQueue.ref.catch(() => Promise.resolve()).then(() => internalRenderMediaOnWeb({\n    ...options,\n    delayRenderTimeoutInMilliseconds: options.delayRenderTimeoutInMilliseconds ?? 30000,\n    logLevel: options.logLevel ?? window.remotion_logLevel ?? \"info\",\n    schema: options.schema ?? undefined,\n    mediaCacheSizeInBytes: options.mediaCacheSizeInBytes ?? null,\n    videoCodec: codec,\n    audioCodec: options.audioCodec ?? null,\n    audioBitrate: options.audioBitrate ?? \"medium\",\n    container,\n    signal: options.signal ?? null,\n    onProgress: options.onProgress ?? null,\n    hardwareAcceleration: options.hardwareAcceleration ?? \"no-preference\",\n    keyframeIntervalInSeconds: options.keyframeIntervalInSeconds ?? 5,\n    videoBitrate: options.videoBitrate ?? \"medium\",\n    frameRange: options.frameRange ?? null,\n    transparent: options.transparent ?? false,\n    onArtifact: options.onArtifact ?? null,\n    onFrame: options.onFrame ?? null,\n    outputTarget: options.outputTarget ?? null,\n    licenseKey: options.licenseKey ?? undefined,\n    muted: options.muted ?? false,\n    scale: options.scale ?? 1\n  }));\n  return onlyOneRenderAtATimeQueue.ref;\n};\n// src/render-still-on-web.tsx\nimport {\n  Internals as Internals9\n} from \"remotion\";\nasync function internalRenderStillOnWeb({\n  frame,\n  delayRenderTimeoutInMilliseconds,\n  logLevel,\n  inputProps,\n  schema,\n  imageFormat,\n  mediaCacheSizeInBytes,\n  composition,\n  signal,\n  onArtifact,\n  licenseKey,\n  scale\n}) {\n  let __stack = [];\n  try {\n    validateScale(scale);\n    const resolved = await Internals9.resolveVideoConfig({\n      calculateMetadata: composition.calculateMetadata ?? null,\n      signal: signal ?? new AbortController().signal,\n      defaultProps: composition.defaultProps ?? {},\n      inputProps: inputProps ?? {},\n      compositionId: composition.id,\n      compositionDurationInFrames: composition.durationInFrames ?? null,\n      compositionFps: composition.fps ?? null,\n      compositionHeight: composition.height ?? null,\n      compositionWidth: composition.width ?? null\n    });\n    if (signal?.aborted) {\n      return Promise.reject(new Error(\"renderStillOnWeb() was cancelled\"));\n    }\n    const internalState = __using(__stack, makeInternalState(), 0);\n    const scaffold = __using(__stack, createScaffold({\n      width: resolved.width,\n      height: resolved.height,\n      delayRenderTimeoutInMilliseconds,\n      logLevel,\n      resolvedProps: resolved.props,\n      id: resolved.id,\n      mediaCacheSizeInBytes,\n      audioEnabled: false,\n      Component: composition.component,\n      videoEnabled: true,\n      durationInFrames: resolved.durationInFrames,\n      fps: resolved.fps,\n      schema: schema ?? null,\n      initialFrame: frame,\n      defaultCodec: resolved.defaultCodec,\n      defaultOutName: resolved.defaultOutName\n    }), 0);\n    const { delayRenderScope, div, collectAssets, errorHolder } = scaffold;\n    const artifactsHandler = handleArtifacts();\n    try {\n      if (signal?.aborted) {\n        throw new Error(\"renderStillOnWeb() was cancelled\");\n      }\n      await waitForReady({\n        timeoutInMilliseconds: delayRenderTimeoutInMilliseconds,\n        scope: delayRenderScope,\n        signal,\n        apiName: \"renderStillOnWeb\",\n        internalState: null,\n        keepalive: null\n      });\n      checkForError(errorHolder);\n      if (signal?.aborted) {\n        throw new Error(\"renderStillOnWeb() was cancelled\");\n      }\n      const capturedFrame = await createLayer({\n        element: div,\n        scale,\n        logLevel,\n        internalState,\n        onlyBackgroundClipText: false,\n        cutout: new DOMRect(0, 0, resolved.width, resolved.height)\n      });\n      const imageData = await capturedFrame.canvas.convertToBlob({\n        type: `image/${imageFormat}`\n      });\n      const assets = collectAssets.current.collectAssets();\n      if (onArtifact) {\n        await artifactsHandler.handle({ imageData, frame, assets, onArtifact });\n      }\n      sendUsageEvent({\n        licenseKey: licenseKey ?? null,\n        succeeded: true,\n        apiName: \"renderStillOnWeb\"\n      });\n      return { blob: imageData, internalState };\n    } catch (err) {\n      if (!signal?.aborted) {\n        sendUsageEvent({\n          succeeded: false,\n          licenseKey: licenseKey ?? null,\n          apiName: \"renderStillOnWeb\"\n        }).catch((err2) => {\n          Internals9.Log.error({ logLevel: \"error\", tag: \"web-renderer\" }, \"Failed to send usage event\", err2);\n        });\n      }\n      throw err;\n    }\n  } catch (_catch) {\n    var _err = _catch, _hasErr = 1;\n  } finally {\n    __callDispose(__stack, _err, _hasErr);\n  }\n}\nvar renderStillOnWeb = (options) => {\n  onlyOneRenderAtATimeQueue.ref = onlyOneRenderAtATimeQueue.ref.catch(() => Promise.resolve()).then(() => internalRenderStillOnWeb({\n    ...options,\n    delayRenderTimeoutInMilliseconds: options.delayRenderTimeoutInMilliseconds ?? 30000,\n    logLevel: options.logLevel ?? window.remotion_logLevel ?? \"info\",\n    schema: options.schema ?? undefined,\n    mediaCacheSizeInBytes: options.mediaCacheSizeInBytes ?? null,\n    signal: options.signal ?? null,\n    onArtifact: options.onArtifact ?? null,\n    licenseKey: options.licenseKey ?? undefined,\n    scale: options.scale ?? 1\n  }));\n  return onlyOneRenderAtATimeQueue.ref;\n};\nexport {\n  renderStillOnWeb,\n  renderMediaOnWeb,\n  getSupportedVideoCodecsForContainer,\n  getSupportedAudioCodecsForContainer,\n  getEncodableVideoCodecs,\n  getEncodableAudioCodecs,\n  getDefaultVideoCodecForContainer,\n  getDefaultAudioCodecForContainer,\n  canRenderMediaOnWeb\n};\n","import {\n  __require,\n  __toESM\n} from \"./chunk-6jf1natv.js\";\n\n// src/Studio.tsx\nimport { useLayoutEffect as useLayoutEffect2 } from \"react\";\nimport { createPortal } from \"react-dom\";\nimport { Internals as Internals66 } from \"remotion\";\n\n// src/components/Editor.tsx\nimport { PlayerInternals as PlayerInternals19 } from \"@remotion/player\";\nimport React177, { useCallback as useCallback135, useEffect as useEffect85, useMemo as useMemo136 } from \"react\";\nimport { Internals as Internals62 } from \"remotion\";\n\n// src/helpers/colors.ts\nvar BACKGROUND = \"rgb(31,36,40)\";\nvar BACKGROUND__TRANSPARENT = \"rgba(31,36,40, 0)\";\nvar INPUT_BACKGROUND = \"#2f363d\";\nvar BORDER_COLOR = \"#000\";\nvar LIGHT_COLOR = \"#ddd\";\nvar SELECTED_BACKGROUND = \"hsla(0, 0%, 100%, 0.15)\";\nvar LIGHT_TEXT = \"#A6A7A9\";\nvar RULER_COLOR = \"#808080\";\nvar VERY_LIGHT_TEXT = \"rgba(255, 255, 255, 0.3)\";\nvar SELECTED_HOVER_BACKGROUND = \"hsla(0, 0%, 100%, 0.25)\";\nvar CLEAR_HOVER = \"rgba(255, 255, 255, 0.06)\";\nvar INPUT_BORDER_COLOR_UNHOVERED = \"rgba(0, 0, 0, 0.6)\";\nvar INPUT_BORDER_COLOR_HOVERED = \"rgba(255, 255, 255, 0.05)\";\nvar TIMELINE_BACKGROUND = \"#111\";\nvar FAIL_COLOR = \"#ff3232\";\nvar TEXT_COLOR = \"#fff\";\nvar WARNING_COLOR = \"#f1c40f\";\nvar BLUE = \"#0b84f3\";\nvar BLUE_DISABLED = \"#284f73\";\nvar LIGHT_TRANSPARENT = \"rgba(255, 255, 255, 0.7)\";\nvar UNSELECTED_GUIDE = \"#7e1219\";\nvar SELECTED_GUIDE = \"#d22d3a\";\nvar LINE_COLOR = \"#363A3E\";\nvar TIMELINE_TRACK_SEPARATOR = \"rgba(0, 0, 0, 0.3)\";\nvar getBackgroundFromHoverState = ({\n  selected,\n  hovered\n}) => {\n  if (selected) {\n    if (hovered) {\n      return SELECTED_HOVER_BACKGROUND;\n    }\n    return SELECTED_BACKGROUND;\n  }\n  if (hovered) {\n    return CLEAR_HOVER;\n  }\n  return \"transparent\";\n};\n\n// src/helpers/noop.ts\nvar noop = () => {\n  return;\n};\n\n// src/state/canvas-ref.ts\nimport { createRef } from \"react\";\nvar canvasRef = createRef();\nvar drawRef = createRef();\n\n// src/state/timeline-zoom.tsx\nimport { createContext as createContext2, useMemo as useMemo2, useState } from \"react\";\n\n// src/components/Timeline/imperative-state.ts\nvar currentFrame = 0;\nvar currentZoom = 1;\nvar currentDuration = 1;\nvar currentFps = 1;\nvar getCurrentZoom = () => {\n  return currentZoom;\n};\nvar setCurrentZoom = (z) => {\n  currentZoom = z;\n};\nvar getCurrentFrame = () => {\n  return currentFrame;\n};\nvar setCurrentFrame = (f) => {\n  currentFrame = f;\n};\nvar getCurrentDuration = () => {\n  return currentDuration;\n};\nvar setCurrentDuration = (d) => {\n  currentDuration = d;\n};\nvar getCurrentFps = () => {\n  return currentFps;\n};\nvar setCurrentFps = (d) => {\n  currentFps = d;\n};\n\n// src/components/Timeline/timeline-scroll-logic.ts\nimport { interpolate } from \"remotion\";\n\n// src/helpers/timeline-layout.ts\nvar TIMELINE_PADDING = 16;\nvar TIMELINE_BORDER = 1;\nvar TIMELINE_ITEM_BORDER_BOTTOM = 1;\nvar getTimelineLayerHeight = (type) => {\n  if (type === \"video\") {\n    return 50;\n  }\n  return 25;\n};\n\n// src/components/Timeline/TimelineSlider.tsx\nimport {\n  createRef as createRef2,\n  useContext,\n  useEffect,\n  useImperativeHandle,\n  useMemo,\n  useRef\n} from \"react\";\nimport { Internals, useVideoConfig } from \"remotion\";\n\n// src/helpers/get-left-of-timeline-slider.ts\nvar getXPositionOfItemInTimelineImperatively = (frame, duration, width) => {\n  const proportion = frame / (duration - 1);\n  return proportion * (width - TIMELINE_PADDING * 2) + TIMELINE_PADDING;\n};\n\n// src/components/Timeline/TimelineSliderHandle.tsx\nimport { jsx } from \"react/jsx-runtime\";\nvar container = {\n  width: 20,\n  height: 20,\n  position: \"fixed\",\n  marginLeft: -8\n};\nvar TimelineSliderHandle = () => {\n  return /* @__PURE__ */ jsx(\"div\", {\n    style: container,\n    children: /* @__PURE__ */ jsx(\"svg\", {\n      width: 17,\n      viewBox: \"0 0 159 212\",\n      children: /* @__PURE__ */ jsx(\"path\", {\n        d: \"M17.0234375,1.07763419 L143.355469,1.07763419 C151.63974,1.07763419 158.355469,7.79336295 158.355469,16.0776342 L158.355469,69.390507 C158.355469,73.7938677 156.420655,77.9748242 153.064021,80.8248415 L89.3980057,134.881757 C83.7986799,139.635978 75.5802263,139.635978 69.9809005,134.881757 L6.66764807,81.1243622 C3.0872392,78.0843437 1.0234375,73.6246568 1.0234375,68.9277387 L1.0234375,17.0776342 C1.0234375,8.2410782 8.1868815,1.07763419 17.0234375,1.07763419 Z\",\n        fill: \"#f02c00\"\n      })\n    })\n  });\n};\n\n// src/components/Timeline/TimelineWidthProvider.tsx\nimport { PlayerInternals } from \"@remotion/player\";\nimport { createContext } from \"react\";\n\n// src/components/Timeline/timeline-refs.ts\nimport React from \"react\";\nvar sliderAreaRef = React.createRef();\nvar scrollableRef = React.createRef();\nvar timelineVerticalScroll = React.createRef();\n\n// src/components/Timeline/TimelineWidthProvider.tsx\nimport { jsx as jsx2 } from \"react/jsx-runtime\";\nvar TimelineWidthContext = createContext(null);\nvar TimelineWidthProvider = ({ children }) => {\n  const size = PlayerInternals.useElementSize(sliderAreaRef, {\n    triggerOnWindowResize: false,\n    shouldApplyCssTransforms: true\n  });\n  return /* @__PURE__ */ jsx2(TimelineWidthContext.Provider, {\n    value: size?.width ?? null,\n    children\n  });\n};\n\n// src/components/Timeline/TimelineSlider.tsx\nimport { jsx as jsx3, jsxs } from \"react/jsx-runtime\";\nvar container2 = {\n  position: \"absolute\",\n  bottom: 0,\n  top: 0,\n  pointerEvents: \"none\"\n};\nvar line = {\n  height: \"100vh\",\n  width: 1,\n  position: \"fixed\",\n  backgroundColor: \"#f02c00\"\n};\nvar redrawTimelineSliderFast = createRef2();\nvar TimelineSlider = () => {\n  const videoConfig = Internals.useUnsafeVideoConfig();\n  const timelineWidth = useContext(TimelineWidthContext);\n  if (videoConfig === null || timelineWidth === null) {\n    return null;\n  }\n  return /* @__PURE__ */ jsx3(Inner, {});\n};\nvar Inner = () => {\n  const videoConfig = useVideoConfig();\n  const timelinePosition = Internals.Timeline.useTimelinePosition();\n  const ref = useRef(null);\n  const timelineWidth = useContext(TimelineWidthContext);\n  if (timelineWidth === null) {\n    throw new Error(\"Unexpectedly did not have timeline width\");\n  }\n  const style = useMemo(() => {\n    const left = getXPositionOfItemInTimelineImperatively(timelinePosition, videoConfig.durationInFrames, timelineWidth);\n    return {\n      ...container2,\n      transform: `translateX(${left}px)`\n    };\n  }, [timelinePosition, videoConfig.durationInFrames, timelineWidth]);\n  useImperativeHandle(redrawTimelineSliderFast, () => {\n    return {\n      draw: (frame, width) => {\n        const { current } = ref;\n        if (!current) {\n          throw new Error(\"unexpectedly did not have ref to timelineslider\");\n        }\n        current.style.transform = `translateX(${getXPositionOfItemInTimelineImperatively(frame, getCurrentDuration(), width ?? sliderAreaRef.current?.clientWidth ?? 0)}px)`;\n      }\n    };\n  }, []);\n  useEffect(() => {\n    const currentRef = ref.current;\n    if (!currentRef) {\n      return;\n    }\n    const { current } = timelineVerticalScroll;\n    if (!current) {\n      return;\n    }\n    const onScroll = () => {\n      currentRef.style.top = current.scrollTop + \"px\";\n    };\n    current.addEventListener(\"scroll\", onScroll);\n    return () => {\n      current.removeEventListener(\"scroll\", onScroll);\n    };\n  }, []);\n  return /* @__PURE__ */ jsxs(\"div\", {\n    ref,\n    style,\n    children: [\n      /* @__PURE__ */ jsx3(\"div\", {\n        style: line\n      }),\n      /* @__PURE__ */ jsx3(TimelineSliderHandle, {})\n    ]\n  });\n};\n\n// src/components/Timeline/timeline-scroll-logic.ts\nvar canScrollTimelineIntoDirection = () => {\n  const current = scrollableRef.current;\n  const { scrollWidth, scrollLeft, clientWidth } = current;\n  const canScrollRight = scrollWidth - scrollLeft - clientWidth > TIMELINE_PADDING;\n  const canScrollLeft = scrollLeft > TIMELINE_PADDING;\n  return { canScrollRight, canScrollLeft };\n};\nvar SCROLL_INCREMENT = 200;\nvar calculateFrameWhileScrollingRight = ({\n  durationInFrames,\n  width,\n  scrollLeft\n}) => {\n  return getFrameFromX({\n    clientX: scrollLeft,\n    durationInFrames,\n    width,\n    extrapolate: \"clamp\"\n  }) + Math.ceil((scrollableRef.current?.clientWidth - TIMELINE_PADDING) / getFrameIncrement(durationInFrames));\n};\nvar getFrameWhileScrollingLeft = ({\n  durationInFrames,\n  width\n}) => {\n  const nextFrame = getFrameFromX({\n    clientX: scrollableRef.current?.scrollLeft - SCROLL_INCREMENT,\n    durationInFrames,\n    width,\n    extrapolate: \"clamp\"\n  });\n  const currentFrame2 = getFrameFromX({\n    clientX: scrollableRef.current?.scrollLeft,\n    durationInFrames,\n    width,\n    extrapolate: \"clamp\"\n  });\n  return Math.max(0, Math.min(currentFrame2 - 1, nextFrame));\n};\nvar isCursorInViewport = ({\n  frame,\n  durationInFrames\n}) => {\n  const width = scrollableRef.current?.scrollWidth ?? 0;\n  const scrollLeft = scrollableRef.current?.scrollLeft ?? 0;\n  const scrollPosOnRightEdge = getScrollPositionForCursorOnRightEdge({\n    nextFrame: frame,\n    durationInFrames\n  });\n  const scrollPosOnLeftEdge = getScrollPositionForCursorOnLeftEdge({\n    nextFrame: frame,\n    durationInFrames\n  });\n  const currentFrameRight = calculateFrameWhileScrollingRight({\n    durationInFrames,\n    scrollLeft,\n    width\n  });\n  return !(scrollPosOnRightEdge >= getScrollPositionForCursorOnRightEdge({\n    nextFrame: currentFrameRight,\n    durationInFrames\n  }) || scrollPosOnLeftEdge < scrollLeft);\n};\nvar ensureFrameIsInViewport = ({\n  direction,\n  durationInFrames,\n  frame\n}) => {\n  redrawTimelineSliderFast.current?.draw(frame);\n  const width = scrollableRef.current?.scrollWidth ?? 0;\n  const scrollLeft = scrollableRef.current?.scrollLeft ?? 0;\n  if (direction === \"fit-left\") {\n    const currentFrameLeft = getFrameFromX({\n      clientX: scrollLeft,\n      durationInFrames,\n      width,\n      extrapolate: \"clamp\"\n    });\n    const scrollPos = getScrollPositionForCursorOnLeftEdge({\n      nextFrame: frame,\n      durationInFrames\n    });\n    const needsToScrollLeft = scrollPos <= getScrollPositionForCursorOnLeftEdge({\n      nextFrame: currentFrameLeft,\n      durationInFrames\n    });\n    if (needsToScrollLeft) {\n      scrollToTimelineXOffset(scrollPos);\n    }\n  }\n  if (direction === \"fit-right\") {\n    const currentFrameRight = calculateFrameWhileScrollingRight({\n      durationInFrames,\n      scrollLeft,\n      width\n    });\n    const scrollPos = getScrollPositionForCursorOnRightEdge({\n      nextFrame: frame,\n      durationInFrames\n    });\n    const needsToScrollRight = scrollPos >= getScrollPositionForCursorOnRightEdge({\n      nextFrame: currentFrameRight,\n      durationInFrames\n    });\n    if (needsToScrollRight) {\n      scrollToTimelineXOffset(scrollPos);\n    }\n  }\n  if (direction === \"page-right\" || direction === \"page-left\") {\n    if (!isCursorInViewport({ frame, durationInFrames })) {\n      scrollToTimelineXOffset(direction === \"page-left\" ? getScrollPositionForCursorOnRightEdge({\n        nextFrame: frame,\n        durationInFrames\n      }) : getScrollPositionForCursorOnLeftEdge({\n        nextFrame: frame,\n        durationInFrames\n      }));\n    }\n  }\n  if (direction === \"center\") {\n    const scrollPosOnRightEdge = getScrollPositionForCursorOnRightEdge({\n      nextFrame: frame,\n      durationInFrames\n    });\n    const scrollPosOnLeftEdge = getScrollPositionForCursorOnLeftEdge({\n      nextFrame: frame,\n      durationInFrames\n    });\n    scrollToTimelineXOffset((scrollPosOnLeftEdge + scrollPosOnRightEdge) / 2);\n  }\n};\nvar scrollToTimelineXOffset = (scrollPos) => {\n  scrollableRef.current?.scroll({\n    left: scrollPos\n  });\n};\nvar getScrollPositionForCursorOnLeftEdge = ({\n  nextFrame,\n  durationInFrames\n}) => {\n  const frameIncrement = getFrameIncrement(durationInFrames);\n  const scrollPos = frameIncrement * nextFrame;\n  return scrollPos;\n};\nvar getScrollPositionForCursorOnRightEdge = ({\n  nextFrame,\n  durationInFrames\n}) => {\n  const frameIncrement = getFrameIncrement(durationInFrames);\n  const framesRemaining = durationInFrames - 1 - nextFrame;\n  const fromRight = framesRemaining * frameIncrement + TIMELINE_PADDING;\n  const scrollPos = scrollableRef.current?.scrollWidth - fromRight - scrollableRef.current?.clientWidth + TIMELINE_PADDING + 4;\n  return scrollPos;\n};\nvar getFrameIncrement = (durationInFrames) => {\n  const width = scrollableRef.current?.scrollWidth ?? 0;\n  return getFrameIncrementFromWidth(durationInFrames, width);\n};\nvar getFrameIncrementFromWidth = (durationInFrames, width) => {\n  return (width - TIMELINE_PADDING * 2) / (durationInFrames - 1);\n};\nvar getFrameWhileScrollingRight = ({\n  durationInFrames,\n  width\n}) => {\n  const nextFrame = calculateFrameWhileScrollingRight({\n    durationInFrames,\n    width,\n    scrollLeft: scrollableRef.current?.scrollLeft + SCROLL_INCREMENT\n  });\n  const currentFrame2 = calculateFrameWhileScrollingRight({\n    durationInFrames,\n    width,\n    scrollLeft: scrollableRef.current?.scrollLeft\n  });\n  return Math.min(durationInFrames - 1, Math.max(nextFrame, currentFrame2 + 1));\n};\nvar getFrameFromX = ({\n  clientX,\n  durationInFrames,\n  width,\n  extrapolate\n}) => {\n  const pos = clientX - TIMELINE_PADDING;\n  const frame = Math.round(interpolate(pos, [0, width - TIMELINE_PADDING * 2], [0, durationInFrames - 1], {\n    extrapolateLeft: extrapolate,\n    extrapolateRight: extrapolate\n  }));\n  return frame;\n};\nvar zoomAndPreserveCursor = ({\n  oldZoom,\n  newZoom,\n  currentFrame: currentFrame2,\n  currentDurationInFrames\n}) => {\n  const ratio = newZoom / oldZoom;\n  if (ratio === 1) {\n    return;\n  }\n  const { current } = scrollableRef;\n  if (!current) {\n    return;\n  }\n  const frameIncrement = getFrameIncrement(currentDurationInFrames);\n  const prevCursorPosition = frameIncrement * currentFrame2 + TIMELINE_PADDING;\n  const newCursorPosition = ratio * (prevCursorPosition - TIMELINE_PADDING) + TIMELINE_PADDING;\n  current.scrollLeft += newCursorPosition - prevCursorPosition;\n  redrawTimelineSliderFast.current?.draw(currentFrame2, (scrollableRef.current?.clientWidth ?? 0) * ratio);\n};\n\n// src/components/ZoomPersistor.tsx\nimport { useContext as useContext2, useEffect as useEffect2 } from \"react\";\nimport { Internals as Internals2 } from \"remotion\";\n\n// src/helpers/url-state.ts\nvar getUrlHandlingType = () => {\n  if (window.remotion_isReadOnlyStudio) {\n    return \"query-string\";\n  }\n  return \"spa\";\n};\nvar pushUrl = (url) => {\n  if (getUrlHandlingType() === \"query-string\") {\n    window.history.pushState({}, \"Studio\", `${window.location.pathname}?${url}`);\n  } else {\n    window.history.pushState({}, \"Studio\", url);\n  }\n};\nvar clearUrl = () => {\n  window.location.href = window.location.pathname;\n};\nvar reloadUrl = () => {\n  window.location.reload();\n};\nvar getRoute = () => {\n  if (getUrlHandlingType() === \"query-string\") {\n    return window.location.search.substring(1);\n  }\n  return window.location.pathname;\n};\n\n// src/components/load-canvas-content-from-url.ts\nvar deriveCanvasContentFromUrl = () => {\n  const route = getRoute();\n  const substrings = route.split(\"/\").filter(Boolean);\n  const lastPart = substrings[substrings.length - 1];\n  if (substrings[0] === \"assets\") {\n    return {\n      type: \"asset\",\n      asset: decodeURIComponent(route.substring(\"/assets/\".length))\n    };\n  }\n  if (substrings[0] === \"outputs\") {\n    return {\n      type: \"output\",\n      path: decodeURIComponent(route.substring(\"/outputs/\".length))\n    };\n  }\n  if (lastPart) {\n    return {\n      type: \"composition\",\n      compositionId: decodeURIComponent(lastPart)\n    };\n  }\n  return null;\n};\n\n// src/components/ZoomPersistor.tsx\nvar makeKey = () => {\n  return `remotion.zoom-map`;\n};\nvar persistCurrentZoom = (zoom) => {\n  localStorage.setItem(makeKey(), JSON.stringify(zoom));\n};\nvar getZoomFromLocalStorage = () => {\n  const zoom = localStorage.getItem(makeKey());\n  return zoom ? JSON.parse(zoom) : {};\n};\nvar ZoomPersistor = () => {\n  const [playing] = Internals2.Timeline.usePlayingState();\n  const { zoom } = useContext2(TimelineZoomCtx);\n  const { canvasContent } = useContext2(Internals2.CompositionManager);\n  const urlState = deriveCanvasContentFromUrl();\n  const isActive = urlState && urlState.type === \"composition\" && canvasContent && canvasContent.type === \"composition\" && urlState.compositionId === canvasContent.compositionId;\n  useEffect2(() => {\n    if (!isActive) {\n      return;\n    }\n    persistCurrentZoom(zoom);\n  }, [zoom, isActive, playing, urlState]);\n  return null;\n};\n\n// src/state/timeline-zoom.tsx\nimport { jsx as jsx4 } from \"react/jsx-runtime\";\nvar TIMELINE_MIN_ZOOM = 1;\nvar TIMELINE_MAX_ZOOM = 5;\nvar TimelineZoomCtx = createContext2({\n  zoom: {},\n  setZoom: () => {\n    throw new Error(\"has no context\");\n  }\n});\nvar TimelineZoomContext = ({ children }) => {\n  const [zoom, setZoom] = useState(() => getZoomFromLocalStorage());\n  const value = useMemo2(() => {\n    return {\n      zoom,\n      setZoom: (compositionId, callback) => {\n        setZoom((prevZoomMap) => {\n          const newZoomWithFloatingPointErrors = Math.min(TIMELINE_MAX_ZOOM, Math.max(TIMELINE_MIN_ZOOM, callback(prevZoomMap[compositionId] ?? TIMELINE_MIN_ZOOM)));\n          const newZoom = Math.round(newZoomWithFloatingPointErrors * 10) / 10;\n          zoomAndPreserveCursor({\n            oldZoom: prevZoomMap[compositionId] ?? TIMELINE_MIN_ZOOM,\n            newZoom,\n            currentDurationInFrames: getCurrentDuration(),\n            currentFrame: getCurrentFrame()\n          });\n          return { ...prevZoomMap, [compositionId]: newZoom };\n        });\n      }\n    };\n  }, [zoom]);\n  return /* @__PURE__ */ jsx4(TimelineZoomCtx.Provider, {\n    value,\n    children\n  });\n};\n\n// src/state/z-index.tsx\nimport {\n  createContext as createContext5,\n  useContext as useContext4,\n  useEffect as useEffect4,\n  useMemo as useMemo6,\n  useRef as useRef3\n} from \"react\";\n\n// src/helpers/use-keybinding.ts\nimport { useCallback as useCallback2, useContext as useContext3, useEffect as useEffect3, useMemo as useMemo4, useState as useState2 } from \"react\";\n\n// src/state/keybindings.tsx\nimport { createContext as createContext3, useCallback, useMemo as useMemo3, useRef as useRef2 } from \"react\";\nimport { jsx as jsx5 } from \"react/jsx-runtime\";\nvar KeybindingContext = createContext3({\n  registerKeybinding: () => {\n    throw new Error(\"Has no keybinding context\");\n  },\n  unregisterKeybinding: () => {\n    return;\n  },\n  unregisterPane: () => {\n    return;\n  }\n});\nvar KeybindingContextProvider = ({ children }) => {\n  const registered = useRef2([]);\n  const registerKeybinding = useCallback((binding) => {\n    registered.current = [...registered.current, binding];\n    window.addEventListener(binding.event, binding.callback);\n  }, []);\n  const unregisterKeybinding = useCallback((binding) => {\n    registered.current = registered.current.filter((r) => {\n      if (r.id === binding.id) {\n        window.removeEventListener(binding.event, binding.callback);\n        return false;\n      }\n      return true;\n    });\n  }, []);\n  const unregisterPane = useCallback((paneId) => {\n    const matchedKeybindings = registered.current.filter((r) => r.registeredFromPane === paneId);\n    for (const matched of matchedKeybindings) {\n      unregisterKeybinding(matched);\n    }\n  }, [unregisterKeybinding]);\n  const value = useMemo3(() => {\n    return {\n      registerKeybinding,\n      unregisterKeybinding,\n      unregisterPane\n    };\n  }, [registerKeybinding, unregisterKeybinding, unregisterPane]);\n  return /* @__PURE__ */ jsx5(KeybindingContext.Provider, {\n    value,\n    children\n  });\n};\n\n// src/helpers/use-keybinding.ts\nif (!process.env.KEYBOARD_SHORTCUTS_ENABLED) {\n  console.warn(\"Keyboard shortcuts disabled either due to: a) --disable-keyboard-shortcuts being passed b) Config.setKeyboardShortcutsEnabled(false) being set or c) a Remotion version mismatch.\");\n}\nvar areKeyboardShortcutsDisabled = () => {\n  return !process.env.KEYBOARD_SHORTCUTS_ENABLED;\n};\nvar useKeybinding = () => {\n  const [paneId] = useState2(() => String(Math.random()));\n  const context = useContext3(KeybindingContext);\n  const { isHighestContext } = useZIndex();\n  const registerKeybinding = useCallback2((options) => {\n    if (!process.env.KEYBOARD_SHORTCUTS_ENABLED) {\n      return {\n        unregister: () => {\n          return;\n        }\n      };\n    }\n    if (!isHighestContext && !options.keepRegisteredWhenNotHighestContext) {\n      return {\n        unregister: () => {\n          return;\n        }\n      };\n    }\n    const listener = (e) => {\n      const commandKey = window.navigator.platform.startsWith(\"Mac\") ? e.metaKey : e.ctrlKey;\n      if (!e.key) {\n        return;\n      }\n      if (e.key.toLowerCase() === options.key.toLowerCase() && options.commandCtrlKey === commandKey) {\n        if (!options.triggerIfInputFieldFocused) {\n          const { activeElement } = document;\n          if (activeElement instanceof HTMLInputElement) {\n            return;\n          }\n          if (activeElement instanceof HTMLTextAreaElement) {\n            return;\n          }\n        }\n        options.callback(e);\n        if (options.preventDefault) {\n          e.preventDefault();\n        }\n      }\n    };\n    const toRegister = {\n      registeredFromPane: paneId,\n      event: options.event,\n      key: options.key,\n      callback: listener,\n      id: String(Math.random())\n    };\n    context.registerKeybinding(toRegister);\n    return {\n      unregister: () => context.unregisterKeybinding(toRegister)\n    };\n  }, [context, isHighestContext, paneId]);\n  useEffect3(() => {\n    return () => {\n      context.unregisterPane(paneId);\n    };\n  }, [context, paneId]);\n  return useMemo4(() => ({ registerKeybinding, isHighestContext }), [registerKeybinding, isHighestContext]);\n};\n\n// src/state/highest-z-index.tsx\nimport { createContext as createContext4, useCallback as useCallback3, useMemo as useMemo5, useState as useState3 } from \"react\";\nimport { jsx as jsx6 } from \"react/jsx-runtime\";\nvar HighestZIndexContext = createContext4({\n  highestIndex: 0,\n  registerZIndex: () => {\n    return;\n  },\n  unregisterZIndex: () => {\n    return;\n  }\n});\nvar HighestZIndexProvider = ({ children }) => {\n  const [zIndexes, setZIndexes] = useState3([]);\n  const registerZIndex = useCallback3((newIndex) => {\n    setZIndexes((prev) => [...prev, newIndex]);\n  }, []);\n  const unregisterZIndex = useCallback3((newIndex) => {\n    setZIndexes((prev) => {\n      const index = prev.indexOf(newIndex);\n      if (index === -1) {\n        throw new Error(\"did not find z-index \" + newIndex);\n      }\n      return prev.filter((_n, i) => i !== index);\n    });\n  }, []);\n  const highestIndex = Math.max(...zIndexes);\n  const value = useMemo5(() => {\n    return {\n      highestIndex,\n      registerZIndex,\n      unregisterZIndex\n    };\n  }, [registerZIndex, unregisterZIndex, highestIndex]);\n  return /* @__PURE__ */ jsx6(HighestZIndexContext.Provider, {\n    value,\n    children\n  });\n};\n\n// src/state/input-dragger-click-lock.ts\nvar clickLock = false;\nvar getClickLock = () => clickLock;\nvar setClickLock = (lock) => {\n  clickLock = lock;\n};\n\n// src/state/z-index.tsx\nimport { jsx as jsx7, jsxs as jsxs2 } from \"react/jsx-runtime\";\nvar ZIndexContext = createContext5({\n  currentIndex: 0\n});\nvar margin = {\n  margin: \"auto\"\n};\nvar EscapeHook = ({ onEscape }) => {\n  const keybindings = useKeybinding();\n  useEffect4(() => {\n    const escape = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"Escape\",\n      callback: onEscape,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      escape.unregister();\n    };\n  }, [keybindings, onEscape]);\n  return null;\n};\nvar HigherZIndex = ({ children, onEscape, onOutsideClick, disabled }) => {\n  const context = useContext4(ZIndexContext);\n  const highestContext = useContext4(HighestZIndexContext);\n  const containerRef = useRef3(null);\n  const currentIndex = disabled ? context.currentIndex : context.currentIndex + 1;\n  useEffect4(() => {\n    if (disabled) {\n      return;\n    }\n    highestContext.registerZIndex(currentIndex);\n    return () => highestContext.unregisterZIndex(currentIndex);\n  }, [currentIndex, highestContext, disabled]);\n  useEffect4(() => {\n    if (disabled) {\n      return;\n    }\n    let onUp = null;\n    const listener = (downEvent) => {\n      const outsideClick = !containerRef.current?.contains(downEvent.target);\n      if (!outsideClick) {\n        return;\n      }\n      onUp = (upEvent) => {\n        if (highestContext.highestIndex === currentIndex && !getClickLock() && document.contains(upEvent.target)) {\n          upEvent.stopPropagation();\n          onOutsideClick(upEvent.target);\n        }\n      };\n      window.addEventListener(\"pointerup\", onUp, { once: true });\n    };\n    requestAnimationFrame(() => {\n      window.addEventListener(\"pointerdown\", listener);\n    });\n    return () => {\n      if (onUp) {\n        window.removeEventListener(\"pointerup\", onUp, { once: true });\n      }\n      onUp = null;\n      return window.removeEventListener(\"pointerdown\", listener);\n    };\n  }, [currentIndex, disabled, highestContext.highestIndex, onOutsideClick]);\n  const value = useMemo6(() => {\n    return {\n      currentIndex\n    };\n  }, [currentIndex]);\n  return /* @__PURE__ */ jsxs2(ZIndexContext.Provider, {\n    value,\n    children: [\n      disabled ? null : /* @__PURE__ */ jsx7(EscapeHook, {\n        onEscape\n      }),\n      /* @__PURE__ */ jsx7(\"div\", {\n        ref: containerRef,\n        style: margin,\n        children\n      })\n    ]\n  });\n};\nvar useZIndex = () => {\n  const context = useContext4(ZIndexContext);\n  const highestContext = useContext4(HighestZIndexContext);\n  const isHighestContext = highestContext.highestIndex === context.currentIndex;\n  return useMemo6(() => ({\n    currentZIndex: context.currentIndex,\n    highestZIndex: highestContext.highestIndex,\n    isHighestContext,\n    tabIndex: isHighestContext ? 0 : -1\n  }), [context.currentIndex, highestContext.highestIndex, isHighestContext]);\n};\n\n// src/components/EditorContent.tsx\nimport { useContext as useContext70 } from \"react\";\nimport { Internals as Internals55 } from \"remotion\";\n\n// src/helpers/is-current-selected-still.ts\nimport { useContext as useContext5 } from \"react\";\nimport { Internals as Internals3 } from \"remotion\";\n\n// src/helpers/is-composition-still.ts\nvar isCompositionStill = (comp) => {\n  if (!comp) {\n    return false;\n  }\n  return comp.durationInFrames === 1;\n};\n\n// src/helpers/is-current-selected-still.ts\nvar useIsStill = () => {\n  const resolved = Internals3.useResolvedVideoConfig(null);\n  if (!resolved || resolved.type !== \"success\") {\n    return false;\n  }\n  return isCompositionStill(resolved.result);\n};\nvar useIsVideoComposition = () => {\n  const isStill = useIsStill();\n  const { canvasContent } = useContext5(Internals3.CompositionManager);\n  if (canvasContent === null) {\n    return false;\n  }\n  if (isStill) {\n    return false;\n  }\n  return canvasContent.type === \"composition\";\n};\n\n// src/components/InitialCompositionLoader.tsx\nimport { useCallback as useCallback23, useContext as useContext13, useEffect as useEffect14 } from \"react\";\nimport { Internals as Internals10 } from \"remotion\";\n\n// src/api/get-static-files.ts\nvar warnedServer = false;\nvar warnedPlayer = false;\nvar warnServerOnce = () => {\n  if (warnedServer) {\n    return;\n  }\n  warnedServer = true;\n  console.warn(\"Called getStaticFiles() on the server. The API is only available in the browser. An empty array was returned.\");\n};\nvar warnPlayerOnce = () => {\n  if (warnedPlayer) {\n    return;\n  }\n  warnedPlayer = true;\n  console.warn(\"Called getStaticFiles() while using the Remotion Player. The API is only available while using the Remotion Studio. An empty array was returned.\");\n};\nvar getStaticFiles = () => {\n  if (typeof document === \"undefined\") {\n    warnServerOnce();\n    return [];\n  }\n  if (window.remotion_isPlayer) {\n    warnPlayerOnce();\n    return [];\n  }\n  return window.remotion_staticFiles;\n};\n\n// src/helpers/mobile-layout.ts\nimport { useEffect as useEffect5, useRef as useRef4, useState as useState4 } from \"react\";\nvar breakpoint = 900;\nfunction getIsMobile() {\n  return window.innerWidth < breakpoint;\n}\nvar useMobileLayout = () => {\n  const [isMobile, setIsMobile] = useState4(getIsMobile());\n  const isMobileRef = useRef4(isMobile);\n  useEffect5(() => {\n    function handleResize() {\n      if (getIsMobile() !== isMobileRef.current) {\n        setIsMobile(getIsMobile());\n      }\n      isMobileRef.current = getIsMobile();\n    }\n    window.addEventListener(\"resize\", handleResize);\n    return () => {\n      return window.removeEventListener(\"resize\", handleResize);\n    };\n  }, []);\n  return isMobile;\n};\n\n// src/state/folders.tsx\nimport { createContext as createContext7, useMemo as useMemo7, useState as useState5 } from \"react\";\n\n// src/helpers/persist-open-folders.tsx\nimport { createContext as createContext6 } from \"react\";\nvar openFolderKey = ({\n  folderName,\n  parentName\n}) => {\n  return [parentName ?? \"no-parent\", folderName].join(\"/\");\n};\nvar localStorageKey = (type) => type === \"compositions\" ? \"remotion.expandedFolders\" : \"remotion.expandedAssetFolders\";\nvar persistExpandedFolders = (type, state) => {\n  window.localStorage.setItem(localStorageKey(type), JSON.stringify(state));\n};\nvar loadExpandedFolders = (type) => {\n  const item = window.localStorage.getItem(localStorageKey(type));\n  if (item === null) {\n    return {};\n  }\n  return JSON.parse(item);\n};\nvar ExpandedFoldersContext = createContext6({\n  toggleFolder: () => {},\n  foldersExpanded: {},\n  setFoldersExpanded: () => {}\n});\n\n// src/state/folders.tsx\nimport { jsx as jsx8 } from \"react/jsx-runtime\";\nvar FolderContext = createContext7({\n  compositionFoldersExpanded: {},\n  setCompositionFoldersExpanded: () => {\n    throw new Error(\"default state\");\n  },\n  assetFoldersExpanded: {},\n  setAssetFoldersExpanded: () => {\n    throw new Error(\"default state\");\n  }\n});\nvar FolderContextProvider = ({ children }) => {\n  const [compositionFoldersExpanded, setCompositionFoldersExpanded] = useState5(() => loadExpandedFolders(\"compositions\"));\n  const [assetFoldersExpanded, setAssetFoldersExpanded] = useState5(() => loadExpandedFolders(\"assets\"));\n  const value = useMemo7(() => {\n    return {\n      compositionFoldersExpanded,\n      setCompositionFoldersExpanded,\n      assetFoldersExpanded,\n      setAssetFoldersExpanded\n    };\n  }, [assetFoldersExpanded, compositionFoldersExpanded]);\n  return /* @__PURE__ */ jsx8(FolderContext.Provider, {\n    value,\n    children\n  });\n};\n\n// src/state/sidebar.tsx\nimport { createContext as createContext8, useMemo as useMemo8, useState as useState6 } from \"react\";\nimport { jsx as jsx9 } from \"react/jsx-runtime\";\nvar storageKey = (sidebar) => {\n  if (sidebar === \"right\") {\n    return \"remotion.sidebarRightCollapsing\";\n  }\n  return \"remotion.sidebarCollapsing\";\n};\nvar getSavedCollapsedStateLeft = (isMobileLayout = false) => {\n  const state = window.localStorage.getItem(storageKey(\"left\"));\n  if (isMobileLayout) {\n    return \"collapsed\";\n  }\n  if (state === \"collapsed\") {\n    return \"collapsed\";\n  }\n  if (state === \"expanded\") {\n    return \"expanded\";\n  }\n  return \"responsive\";\n};\nvar getSavedCollapsedStateRight = (isMobileLayout = false) => {\n  const state = window.localStorage.getItem(storageKey(\"right\"));\n  if (isMobileLayout) {\n    return \"collapsed\";\n  }\n  if (state === \"expanded\") {\n    return \"expanded\";\n  }\n  return \"collapsed\";\n};\nvar saveCollapsedState = (type, sidebar) => {\n  window.localStorage.setItem(storageKey(sidebar), type);\n};\nvar SidebarContext = createContext8({\n  sidebarCollapsedStateLeft: \"collapsed\",\n  setSidebarCollapsedState: () => {\n    throw new Error(\"sidebar collapsed state\");\n  },\n  sidebarCollapsedStateRight: \"collapsed\"\n});\nvar SidebarContextProvider = ({ children }) => {\n  const isMobileLayout = useMobileLayout();\n  const [sidebarCollapsedState, setSidebarCollapsedState] = useState6(() => ({\n    left: getSavedCollapsedStateLeft(isMobileLayout),\n    right: getSavedCollapsedStateRight(isMobileLayout)\n  }));\n  const value = useMemo8(() => {\n    return {\n      sidebarCollapsedStateLeft: sidebarCollapsedState.left,\n      sidebarCollapsedStateRight: sidebarCollapsedState.right,\n      setSidebarCollapsedState: (options) => {\n        const { left, right } = options;\n        setSidebarCollapsedState((f) => {\n          const copied = { ...f };\n          if (left) {\n            const updatedLeft = typeof left === \"function\" ? left(f.left) : left;\n            saveCollapsedState(updatedLeft, \"left\");\n            copied.left = updatedLeft;\n          }\n          if (right) {\n            const updatedRight = typeof right === \"function\" ? right(f.right) : right;\n            saveCollapsedState(updatedRight, \"right\");\n            copied.right = updatedRight;\n          }\n          return copied;\n        });\n      }\n    };\n  }, [sidebarCollapsedState]);\n  return /* @__PURE__ */ jsx9(SidebarContext.Provider, {\n    value,\n    children\n  });\n};\n\n// src/components/CompositionSelector.tsx\nimport { useCallback as useCallback16, useContext as useContext9, useMemo as useMemo21 } from \"react\";\nimport { Internals as Internals7 } from \"remotion\";\n\n// src/helpers/create-folder-tree.ts\nvar buildAssetFolderStructure = (files, parentFolderName, foldersExpanded) => {\n  const notInFolder = files.filter((f) => !f.name.includes(\"/\"));\n  const inFolder = files.filter((f) => f.name.includes(\"/\"));\n  const groupedByFolder = {};\n  for (const item of inFolder) {\n    const folderName = item.name.split(\"/\")[0];\n    if (!groupedByFolder[folderName]) {\n      groupedByFolder[folderName] = [];\n    }\n    groupedByFolder[folderName].push(item);\n  }\n  return {\n    files: notInFolder,\n    folders: Object.keys(groupedByFolder).map((folderName) => {\n      const filesInFolder = groupedByFolder[folderName];\n      const filesWithoutFolderName = filesInFolder.map((f) => {\n        return {\n          ...f,\n          name: f.name.substring(folderName.length + 1)\n        };\n      });\n      const key = [parentFolderName, folderName].filter(Boolean).join(\"/\");\n      const isExpanded = foldersExpanded[key] ?? false;\n      return {\n        name: folderName,\n        items: buildAssetFolderStructure(filesWithoutFolderName, [parentFolderName, folderName].filter(Boolean).join(\"/\"), foldersExpanded),\n        expanded: isExpanded\n      };\n    })\n  };\n};\nvar splitParentIntoNameAndParent = (name) => {\n  if (name === null) {\n    return {\n      name: null,\n      parent: null\n    };\n  }\n  const splitted = name.split(\"/\");\n  const lastName = splitted[splitted.length - 1];\n  const parentParentArray = splitted.slice(0, splitted.length - 1);\n  const parentParent = parentParentArray.length === 0 ? null : parentParentArray.join(\"/\");\n  return {\n    name: lastName,\n    parent: parentParent\n  };\n};\nvar doesFolderExist = (items, folderName, parentName) => {\n  for (const item of items) {\n    if (item.type === \"folder\") {\n      if (item.folderName === folderName && item.parentName === parentName) {\n        return item.items;\n      }\n      const found = doesFolderExist(item.items, folderName, parentName);\n      if (found !== false) {\n        return found;\n      }\n    }\n  }\n  return false;\n};\nvar findItemListToPush = (items, folderName, parentName) => {\n  if (folderName === null) {\n    return items;\n  }\n  const folder = doesFolderExist(items, folderName, parentName);\n  if (!folder) {\n    console.log({ items, folderName, parentName });\n    throw new Error(\"did not find folder \" + folderName);\n  }\n  return folder;\n};\nvar createFolderIfDoesNotExist = (items, availableFolders, folderItem, foldersExpanded) => {\n  if (doesFolderExist(items, folderItem.name, folderItem.parent)) {\n    return;\n  }\n  const splitted = splitParentIntoNameAndParent(folderItem.parent);\n  if (folderItem.parent) {\n    const parent = availableFolders.find((f) => f.name === splitted.name && f.parent === splitted.parent);\n    if (!parent) {\n      throw new Error(\"unexpectedly did not have parent\");\n    }\n    createFolderIfDoesNotExist(items, availableFolders, parent, foldersExpanded);\n  }\n  const itemList = findItemListToPush(items, splitted.name, splitted.parent);\n  if (!itemList) {\n    throw new Error(\"why did folder not exist? \" + folderItem.name);\n  }\n  itemList.push({\n    type: \"folder\",\n    folderName: folderItem.name,\n    items: [],\n    key: folderItem.name,\n    expanded: foldersExpanded[openFolderKey({\n      folderName: folderItem.name,\n      parentName: folderItem.parent\n    })] ?? false,\n    parentName: folderItem.parent\n  });\n};\nvar createFolderTree = (comps, folders, foldersExpanded) => {\n  const items = [];\n  const uniqueFolderKeys = [];\n  for (const folder of folders) {\n    const folderKey = openFolderKey({\n      folderName: folder.name,\n      parentName: folder.parent\n    });\n    if (uniqueFolderKeys.includes(folderKey)) {\n      if (folder.parent) {\n        throw new Error(`Multiple folders with the name ${folder.name} inside the folder ${folder.parent} exist. Folder names must be unique.`);\n      }\n      throw new Error(\"Multiple folders with the name \" + folder.name + \" exist. Folder names must be unique.\");\n    }\n    uniqueFolderKeys.push(folderKey);\n    createFolderIfDoesNotExist(items, folders, folder, foldersExpanded);\n  }\n  for (const item of comps) {\n    const toPush = {\n      type: \"composition\",\n      composition: item,\n      key: item.id\n    };\n    const list = findItemListToPush(items, item.folderName, item.parentFolderName);\n    list.push(toPush);\n  }\n  return items;\n};\n\n// src/components/CompositionSelectorItem.tsx\nimport { useCallback as useCallback15, useContext as useContext8, useMemo as useMemo20, useState as useState14 } from \"react\";\n\n// src/icons/folder.tsx\nimport { jsx as jsx10 } from \"react/jsx-runtime\";\nvar CollapsedFolderIcon = ({ color, ...props }) => {\n  return /* @__PURE__ */ jsx10(\"svg\", {\n    viewBox: \"0 0 512 512\",\n    ...props,\n    children: /* @__PURE__ */ jsx10(\"path\", {\n      fill: color,\n      d: \"M447.1 96H272L226.7 50.75C214.7 38.74 198.5 32 181.5 32H63.1c-35.35 0-64 28.65-64 64v320c0 35.35 28.65 64 64 64h384c35.35 0 64-28.65 64-64V160C511.1 124.7 483.3 96 447.1 96zM480 416c0 17.64-14.36 32-32 32H64c-17.64 0-32-14.36-32-32V96c0-17.64 14.36-32 32-32h117.5c8.549 0 16.58 3.328 22.63 9.375L258.7 128H448c17.64 0 32 14.36 32 32V416z\"\n    })\n  });\n};\nvar ExpandedFolderIcon = ({ color, ...props }) => {\n  return /* @__PURE__ */ jsx10(\"svg\", {\n    viewBox: \"0 0 576 512\",\n    ...props,\n    children: /* @__PURE__ */ jsx10(\"path\", {\n      fill: color,\n      d: \"M566.6 211.6C557.5 199.1 543.4 192 527.1 192H134.2C114.3 192 96.2 204.5 89.23 223.1L32 375.8V96c0-17.64 14.36-32 32-32h117.5c8.549 0 16.58 3.328 22.63 9.375L258.7 128H448c17.64 0 32 14.36 32 32h32c0-35.35-28.65-64-64-64H272L226.7 50.75C214.7 38.74 198.5 32 181.5 32H64C28.65 32 0 60.65 0 96v320c0 35.35 28.65 64 64 64h403.1c21.11 0 39.53-13.53 45.81-33.69l60-192C578.4 239.6 575.8 224 566.6 211.6zM543.2 244.8l-60 192C481.1 443.5 475 448 467.1 448H64c-3.322 0-6.357-.9551-9.373-1.898c-2.184-1.17-4.109-2.832-5.596-4.977c-3.031-4.375-3.703-9.75-1.828-14.73l72-192C121.5 228.2 127.5 224 134.2 224h393.8c5.141 0 9.844 2.375 12.89 6.516C543.9 234.7 544.8 239.9 543.2 244.8z\"\n    })\n  });\n};\nvar ExpandedFolderIconSolid = ({ color, ...props }) => {\n  return /* @__PURE__ */ jsx10(\"svg\", {\n    viewBox: \"0 0 576 512\",\n    ...props,\n    children: /* @__PURE__ */ jsx10(\"path\", {\n      fill: color,\n      d: \"M384 480h48c11.4 0 21.9-6 27.6-15.9l112-192c5.8-9.9 5.8-22.1 .1-32.1S555.5 224 544 224H144c-11.4 0-21.9 6-27.6 15.9L48 357.1V96c0-8.8 7.2-16 16-16H181.5c4.2 0 8.3 1.7 11.3 4.7l26.5 26.5c21 21 49.5 32.8 79.2 32.8H416c8.8 0 16 7.2 16 16v32h48V160c0-35.3-28.7-64-64-64H298.5c-17 0-33.3-6.7-45.3-18.7L226.7 50.7c-12-12-28.3-18.7-45.3-18.7H64C28.7 32 0 60.7 0 96V416c0 35.3 28.7 64 64 64H87.7 384z\"\n    })\n  });\n};\n\n// src/icons/still.tsx\nimport { jsx as jsx11 } from \"react/jsx-runtime\";\nvar StillIcon = ({ color, ...props }) => {\n  return /* @__PURE__ */ jsx11(\"svg\", {\n    ...props,\n    viewBox: \"0 0 512 512\",\n    children: /* @__PURE__ */ jsx11(\"path\", {\n      fill: color,\n      d: \"M144 288C144 226.1 194.1 176 256 176C317.9 176 368 226.1 368 288C368 349.9 317.9 400 256 400C194.1 400 144 349.9 144 288zM256 208C211.8 208 176 243.8 176 288C176 332.2 211.8 368 256 368C300.2 368 336 332.2 336 288C336 243.8 300.2 208 256 208zM362.9 64.82L373.3 96H448C483.3 96 512 124.7 512 160V416C512 451.3 483.3 480 448 480H64C28.65 480 0 451.3 0 416V160C0 124.7 28.65 96 64 96H138.7L149.1 64.82C155.6 45.22 173.9 32 194.6 32H317.4C338.1 32 356.4 45.22 362.9 64.82H362.9zM64 128C46.33 128 32 142.3 32 160V416C32 433.7 46.33 448 64 448H448C465.7 448 480 433.7 480 416V160C480 142.3 465.7 128 448 128H350.3L332.6 74.94C330.4 68.41 324.3 64 317.4 64H194.6C187.7 64 181.6 68.41 179.4 74.94L161.7 128H64z\"\n    })\n  });\n};\n\n// src/icons/video.tsx\nimport { jsx as jsx12 } from \"react/jsx-runtime\";\nvar FilmIcon = ({ color, ...props }) => {\n  return /* @__PURE__ */ jsx12(\"svg\", {\n    ...props,\n    xmlns: \"http://www.w3.org/2000/svg\",\n    viewBox: \"0 0 512 512\",\n    children: /* @__PURE__ */ jsx12(\"path\", {\n      fill: color,\n      d: \"M448 32H64C28.65 32 0 60.65 0 96v320c0 35.35 28.65 64 64 64h384c35.35 0 64-28.65 64-64V96C512 60.65 483.3 32 448 32zM384 64v176H128V64H384zM32 96c0-17.64 14.36-32 32-32h32v80H32V96zM32 176h64v64H32V176zM32 272h64v64H32V272zM64 448c-17.64 0-32-14.36-32-32v-48h64V448H64zM128 448V272h256V448H128zM480 416c0 17.64-14.36 32-32 32h-32v-80h64V416zM480 336h-64v-64h64V336zM480 240h-64v-64h64V240zM480 144h-64V64h32c17.64 0 32 14.36 32 32V144z\"\n    })\n  });\n};\n\n// src/state/modals.ts\nimport { createContext as createContext9 } from \"react\";\nvar ModalsContext = createContext9({\n  selectedModal: null,\n  setSelectedModal: () => {\n    return;\n  }\n});\n\n// src/components/CompositionContextButton.tsx\nimport { useCallback as useCallback12, useContext as useContext6, useMemo as useMemo17 } from \"react\";\n\n// src/helpers/client-id.tsx\nimport React12, { useCallback as useCallback6, useEffect as useEffect8, useMemo as useMemo10, useRef as useRef6 } from \"react\";\nimport { Internals as Internals4 } from \"remotion\";\n\n// src/components/Notifications/NotificationCenter.tsx\nimport {\n  createRef as createRef3,\n  useCallback as useCallback4,\n  useImperativeHandle as useImperativeHandle2,\n  useState as useState7\n} from \"react\";\n\n// src/components/Notifications/Notification.tsx\nimport { useEffect as useEffect6 } from \"react\";\nimport { jsx as jsx13 } from \"react/jsx-runtime\";\nvar notification = {\n  backgroundColor: \"#111111\",\n  color: \"white\",\n  fontFamily: \"Arial, Helvetica, sans-serif\",\n  display: \"inline-flex\",\n  padding: \"8px 14px\",\n  borderRadius: 4,\n  fontSize: 15,\n  border: \"0.25px solid rgba(255, 255, 255, 0.1)\",\n  boxShadow: \"0 2px 3px rgba(0, 0, 0, 1)\",\n  marginTop: 3,\n  marginBottom: 3,\n  alignItems: \"center\"\n};\nvar Notification = ({ children, id, duration, created, onRemove }) => {\n  useEffect6(() => {\n    if (duration === null) {\n      return;\n    }\n    const timeout = setTimeout(() => {\n      onRemove(id);\n    }, duration - (Date.now() - created));\n    return () => {\n      clearTimeout(timeout);\n    };\n  }, [created, duration, id, onRemove]);\n  return /* @__PURE__ */ jsx13(\"div\", {\n    className: \"css-reset\",\n    style: notification,\n    children\n  });\n};\n\n// src/components/Notifications/NotificationCenter.tsx\nimport { jsx as jsx14 } from \"react/jsx-runtime\";\nvar container3 = {\n  position: \"absolute\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  display: \"flex\",\n  width: \"100%\",\n  flexDirection: \"column\",\n  paddingTop: 20,\n  pointerEvents: \"none\",\n  backgroundColor: \"transparent\"\n};\nvar notificationCenter = createRef3();\nvar showNotification = (content, durationInMs) => {\n  return notificationCenter.current.addNotification({\n    content,\n    duration: durationInMs,\n    created: Date.now(),\n    id: String(Math.random()).replace(\"0.\", \"\")\n  });\n};\nvar NotificationCenter = () => {\n  const [notifications, setNotifications] = useState7([]);\n  const onRemove = useCallback4((id) => {\n    setNotifications((not) => {\n      return not.filter((n) => n.id !== id);\n    });\n  }, []);\n  const addNotification = useCallback4((notification2) => {\n    setNotifications((previousNotifications) => {\n      return [...previousNotifications, notification2];\n    });\n    return {\n      replaceContent: (newContent, durationInMs) => {\n        setNotifications((oldNotifications) => {\n          return oldNotifications.map((notificationToMap) => {\n            if (notificationToMap.id === notification2.id) {\n              return {\n                ...notificationToMap,\n                duration: durationInMs,\n                content: newContent,\n                created: Date.now()\n              };\n            }\n            return notificationToMap;\n          });\n        });\n      }\n    };\n  }, []);\n  useImperativeHandle2(notificationCenter, () => {\n    return {\n      addNotification\n    };\n  }, [addNotification]);\n  return /* @__PURE__ */ jsx14(\"div\", {\n    style: container3,\n    children: notifications.map((n) => {\n      return /* @__PURE__ */ jsx14(Notification, {\n        created: n.created,\n        duration: n.duration,\n        id: n.id,\n        onRemove,\n        children: n.content\n      }, n.id);\n    })\n  });\n};\n\n// src/components/PlayBeepSound.tsx\nvar beeped = {};\nvar playBeepSound = async (renderId) => {\n  if (beeped[renderId]) {\n    return;\n  }\n  beeped[renderId] = true;\n  const beepAudio = new Audio(\"/beep.wav\");\n  try {\n    await beepAudio.play();\n  } catch (error) {\n    console.error(\"Error playing beep sound:\", error);\n    throw error;\n  }\n};\nvar PlayBeepSound_default = playBeepSound;\n\n// src/components/RenderQueue/context.tsx\nimport React11, {\n  createRef as createRef4,\n  useCallback as useCallback5,\n  useEffect as useEffect7,\n  useImperativeHandle as useImperativeHandle3,\n  useMemo as useMemo9,\n  useRef as useRef5,\n  useState as useState8\n} from \"react\";\n\n// src/components/RenderQueue/client-render-queue.ts\nvar compositionRegistry = new Map;\nvar registerCompositionForJob = (jobId, compositionRef) => {\n  compositionRegistry.set(jobId, compositionRef);\n};\nvar getCompositionForJob = (jobId) => {\n  return compositionRegistry.get(jobId);\n};\nvar cleanupCompositionForJob = (jobId) => {\n  compositionRegistry.delete(jobId);\n};\nvar generateJobId = () => {\n  return `client-${Date.now()}-${Math.random().toString(36).substring(2, 11)}`;\n};\nvar clientJobAbortControllers = new Map;\nvar getAbortController = (jobId) => {\n  let controller = clientJobAbortControllers.get(jobId);\n  if (!controller) {\n    controller = new AbortController;\n    clientJobAbortControllers.set(jobId, controller);\n  }\n  return controller;\n};\nvar deleteAbortController = (jobId) => {\n  clientJobAbortControllers.delete(jobId);\n};\nvar cancelAbortController = (jobId) => {\n  const controller = clientJobAbortControllers.get(jobId);\n  if (controller) {\n    controller.abort();\n  }\n};\n\n// src/components/RenderQueue/context.tsx\nimport { jsx as jsx15 } from \"react/jsx-runtime\";\nvar isClientRenderJob = (job) => {\n  return job.type === \"client-still\" || job.type === \"client-video\";\n};\nvar noopString = () => \"\";\nvar noop2 = () => {\n  return;\n};\nvar RenderQueueContext = React11.createContext({\n  jobs: [],\n  serverJobs: [],\n  clientJobs: [],\n  addClientStillJob: noopString,\n  addClientVideoJob: noopString,\n  updateClientJobProgress: noop2,\n  markClientJobDone: noop2,\n  markClientJobFailed: noop2,\n  markClientJobCancelled: noop2,\n  removeClientJob: noop2,\n  cancelClientJob: noop2,\n  setProcessJobCallback: noop2,\n  getAbortController: () => new AbortController,\n  getCompositionForJob: () => {\n    return;\n  }\n});\nvar renderJobsRef = createRef4();\nvar RenderQueueContextProvider = ({ children }) => {\n  const [serverJobs, setServerJobs] = useState8(window.remotion_initialRenderQueue ?? []);\n  const [clientJobs, setClientJobs] = useState8([]);\n  const [currentlyProcessing, setCurrentlyProcessing] = useState8(null);\n  const processJobCallbackRef = useRef5(null);\n  useEffect7(() => {\n    if (currentlyProcessing) {\n      return;\n    }\n    const nextJob = clientJobs.find((job) => job.status === \"idle\");\n    if (!nextJob || !processJobCallbackRef.current) {\n      return;\n    }\n    setCurrentlyProcessing(nextJob.id);\n    setClientJobs((prev) => prev.map((job) => job.id === nextJob.id ? {\n      ...job,\n      status: \"running\",\n      progress: { renderedFrames: 0, encodedFrames: 0, totalFrames: 0 }\n    } : job));\n    processJobCallbackRef.current(nextJob);\n  }, [clientJobs, currentlyProcessing]);\n  const addClientStillJob = useCallback5((params, compositionRef) => {\n    const id = generateJobId();\n    registerCompositionForJob(id, compositionRef);\n    const newJob = {\n      ...params,\n      id,\n      startedAt: Date.now(),\n      status: \"idle\"\n    };\n    setClientJobs((prev) => [...prev, newJob]);\n    return id;\n  }, []);\n  const addClientVideoJob = useCallback5((params, compositionRef) => {\n    const id = generateJobId();\n    registerCompositionForJob(id, compositionRef);\n    const newJob = {\n      ...params,\n      id,\n      startedAt: Date.now(),\n      status: \"idle\"\n    };\n    setClientJobs((prev) => [...prev, newJob]);\n    return id;\n  }, []);\n  const updateClientJobProgress = useCallback5((jobId, progress) => {\n    setClientJobs((prev) => prev.map((job) => job.id === jobId ? { ...job, status: \"running\", progress } : job));\n  }, []);\n  const markClientJobDone = useCallback5((jobId, getBlob, metadata) => {\n    deleteAbortController(jobId);\n    cleanupCompositionForJob(jobId);\n    setClientJobs((prev) => prev.map((job) => job.id === jobId ? { ...job, status: \"done\", getBlob, metadata } : job));\n    setCurrentlyProcessing(null);\n  }, []);\n  const markClientJobFailed = useCallback5((jobId, error) => {\n    deleteAbortController(jobId);\n    cleanupCompositionForJob(jobId);\n    setClientJobs((prev) => prev.map((job) => job.id === jobId ? {\n      ...job,\n      status: \"failed\",\n      error: { message: error.message, stack: error.stack }\n    } : job));\n    setCurrentlyProcessing(null);\n  }, []);\n  const markClientJobCancelled = useCallback5((jobId) => {\n    deleteAbortController(jobId);\n    cleanupCompositionForJob(jobId);\n    setClientJobs((prev) => prev.map((job) => job.id === jobId ? {\n      ...job,\n      status: \"cancelled\"\n    } : job));\n    setCurrentlyProcessing(null);\n  }, []);\n  const removeClientJob = useCallback5((jobId) => {\n    setClientJobs((prev) => {\n      const jobToRemove = prev.find((j) => j.id === jobId);\n      if (jobToRemove?.status === \"running\") {\n        return prev;\n      }\n      deleteAbortController(jobId);\n      cleanupCompositionForJob(jobId);\n      return prev.filter((job) => job.id !== jobId);\n    });\n  }, []);\n  const cancelClientJob = useCallback5((jobId) => {\n    cancelAbortController(jobId);\n  }, []);\n  const setProcessJobCallback = useCallback5((callback) => {\n    processJobCallbackRef.current = callback;\n  }, []);\n  useImperativeHandle3(renderJobsRef, () => ({\n    updateRenderJobs: (newJobs) => {\n      setServerJobs(newJobs);\n    }\n  }), []);\n  const value = useMemo9(() => {\n    return {\n      jobs: [...serverJobs, ...clientJobs],\n      serverJobs,\n      clientJobs,\n      addClientStillJob,\n      addClientVideoJob,\n      updateClientJobProgress,\n      markClientJobDone,\n      markClientJobFailed,\n      markClientJobCancelled,\n      removeClientJob,\n      cancelClientJob,\n      setProcessJobCallback,\n      getAbortController,\n      getCompositionForJob\n    };\n  }, [\n    serverJobs,\n    clientJobs,\n    addClientStillJob,\n    addClientVideoJob,\n    updateClientJobProgress,\n    markClientJobDone,\n    markClientJobFailed,\n    markClientJobCancelled,\n    removeClientJob,\n    cancelClientJob,\n    setProcessJobCallback\n  ]);\n  return /* @__PURE__ */ jsx15(RenderQueueContext.Provider, {\n    value,\n    children\n  });\n};\n\n// src/helpers/client-id.tsx\nimport { jsx as jsx16 } from \"react/jsx-runtime\";\nvar StudioServerConnectionCtx = React12.createContext({\n  previewServerState: {\n    type: \"init\"\n  },\n  subscribeToEvent: () => {\n    throw new Error(\"Context not initalized\");\n  }\n});\nvar PreviewServerConnection = ({ children, readOnlyStudio }) => {\n  const listeners = useRef6([]);\n  const subscribeToEvent = useCallback6((type, listener) => {\n    listeners.current.push({ type, listener });\n    return () => {\n      listeners.current = listeners.current.filter((l) => l.type !== type || l.listener !== listener);\n    };\n  }, []);\n  const openEventSource = useCallback6(() => {\n    const source = new EventSource(\"/events\");\n    source.addEventListener(\"message\", (event) => {\n      const newEvent = JSON.parse(event.data);\n      if (newEvent.type === \"new-input-props\" || newEvent.type === \"new-env-variables\") {\n        reloadUrl();\n      }\n      if (newEvent.type === \"init\") {\n        setState({\n          type: \"connected\",\n          clientId: newEvent.clientId\n        });\n      }\n      if (newEvent.type === \"render-queue-updated\") {\n        renderJobsRef.current?.updateRenderJobs(newEvent.queue);\n        for (const job of newEvent.queue) {\n          if (job.status === \"done\" && job.beepOnFinish) {\n            PlayBeepSound_default(job.id);\n          }\n        }\n      }\n      if (newEvent.type === \"render-job-failed\") {\n        showNotification(`Rendering \"${newEvent.compositionId}\" failed`, 2000);\n      }\n      if (newEvent.type === \"new-public-folder\") {\n        const payload = {\n          files: newEvent.files\n        };\n        window.remotion_staticFiles = newEvent.files;\n        window.remotion_publicFolderExists = newEvent.folderExists;\n        window.dispatchEvent(new CustomEvent(Internals4.WATCH_REMOTION_STATIC_FILES, {\n          detail: payload\n        }));\n      }\n      listeners.current.forEach((l) => {\n        if (l.type === newEvent.type) {\n          l.listener(newEvent);\n        }\n      });\n    });\n    source.addEventListener(\"open\", () => {\n      source.addEventListener(\"error\", () => {\n        setState({ type: \"disconnected\" });\n        source?.close();\n        setTimeout(() => {\n          openEventSource();\n        }, 1000);\n      }, { once: true });\n    });\n    const close = () => {\n      source.close();\n    };\n    return {\n      close\n    };\n  }, []);\n  useEffect8(() => {\n    if (readOnlyStudio) {\n      return;\n    }\n    const { close } = openEventSource();\n    return () => {\n      close();\n    };\n  }, [openEventSource, readOnlyStudio]);\n  const [state, setState] = React12.useState({\n    type: \"init\"\n  });\n  const context = useMemo10(() => {\n    return {\n      previewServerState: state,\n      subscribeToEvent\n    };\n  }, [state, subscribeToEvent]);\n  return /* @__PURE__ */ jsx16(StudioServerConnectionCtx.Provider, {\n    value: context,\n    children\n  });\n};\n\n// src/icons/ellipsis.tsx\nimport { jsx as jsx17 } from \"react/jsx-runtime\";\nvar EllipsisIcon = (props) => {\n  return /* @__PURE__ */ jsx17(\"svg\", {\n    ...props.svgProps,\n    viewBox: \"0 0 448 512\",\n    children: /* @__PURE__ */ jsx17(\"path\", {\n      fill: props.fill,\n      d: \"M8 256a56 56 0 1 1 112 0A56 56 0 1 1 8 256zm160 0a56 56 0 1 1 112 0 56 56 0 1 1 -112 0zm216-56a56 56 0 1 1 0 112 56 56 0 1 1 0-112z\"\n    })\n  });\n};\n\n// src/components/InlineDropdown.tsx\nimport { PlayerInternals as PlayerInternals3 } from \"@remotion/player\";\nimport { useCallback as useCallback11, useMemo as useMemo16, useRef as useRef9, useState as useState12 } from \"react\";\nimport ReactDOM2 from \"react-dom\";\n\n// src/components/InlineAction.tsx\nimport { useCallback as useCallback7, useMemo as useMemo11, useState as useState9 } from \"react\";\nimport { jsx as jsx18 } from \"react/jsx-runtime\";\nvar InlineAction = ({\n  renderAction,\n  onClick,\n  disabled,\n  title\n}) => {\n  const { tabIndex } = useZIndex();\n  const [hovered, setHovered] = useState9(false);\n  const onPointerEnter = useCallback7(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback7(() => {\n    setHovered(false);\n  }, []);\n  const style = useMemo11(() => {\n    return {\n      border: \"none\",\n      background: disabled ? \"transparent\" : getBackgroundFromHoverState({ hovered, selected: false }),\n      height: 24,\n      width: 24,\n      display: \"inline-flex\",\n      justifyContent: \"center\",\n      alignItems: \"center\",\n      borderRadius: 3,\n      pointerEvents: disabled ? \"none\" : \"auto\"\n    };\n  }, [disabled, hovered]);\n  return /* @__PURE__ */ jsx18(\"button\", {\n    type: \"button\",\n    onPointerEnter,\n    onPointerLeave,\n    onClick,\n    style,\n    tabIndex,\n    title,\n    children: renderAction(hovered ? \"white\" : LIGHT_TEXT)\n  });\n};\n\n// src/components/Menu/portals.ts\nvar portals = [\n  document.getElementById(\"menuportal-0\"),\n  document.getElementById(\"menuportal-1\"),\n  document.getElementById(\"menuportal-2\"),\n  document.getElementById(\"menuportal-3\"),\n  document.getElementById(\"menuportal-4\"),\n  document.getElementById(\"menuportal-5\")\n];\nvar getPortal = (i) => {\n  return portals[i];\n};\n\n// src/components/Menu/styles.ts\nvar MENU_VERTICAL_PADDING = 4;\nvar SUBMENU_LEFT_INSET = -8;\nvar MAX_MENU_WIDTH = 400;\nvar MAX_MOBILE_MENU_WIDTH = 300;\nvar menuContainer = {\n  backgroundColor: BACKGROUND,\n  position: \"fixed\",\n  color: \"white\",\n  userSelect: \"none\",\n  WebkitUserSelect: \"none\"\n};\nvar SHADOW_TOWARDS_BOTTOM = \"0 2px 8px rgba(0, 0, 0, 0.5)\";\nvar SHADOW_TOWARDS_TOP = \"0 -2px 8px rgba(0, 0, 0, 0.5)\";\nvar menuContainerTowardsBottom = {\n  ...menuContainer,\n  boxShadow: SHADOW_TOWARDS_BOTTOM\n};\nvar menuContainerTowardsTop = {\n  ...menuContainer,\n  boxShadow: SHADOW_TOWARDS_TOP\n};\nvar fullScreenOverlay = {\n  position: \"fixed\",\n  top: 0,\n  left: 0,\n  right: 0,\n  bottom: 0\n};\nvar outerPortal = {\n  position: \"fixed\"\n};\nvar inlineCodeSnippet = {\n  fontSize: 14,\n  color: BLUE,\n  fontFamily: \"monospace\"\n};\n\n// src/components/NewComposition/MenuContent.tsx\nimport { useCallback as useCallback10, useEffect as useEffect10, useMemo as useMemo15, useRef as useRef8, useState as useState11 } from \"react\";\n\n// src/components/Menu/MenuDivider.tsx\nimport { jsx as jsx19 } from \"react/jsx-runtime\";\nvar menuDivider = {\n  marginTop: 4,\n  marginBottom: 4,\n  height: 1,\n  backgroundColor: INPUT_BORDER_COLOR_HOVERED\n};\nvar MenuDivider = () => {\n  return /* @__PURE__ */ jsx19(\"div\", {\n    style: menuDivider\n  });\n};\n\n// src/components/Menu/MenuSubItem.tsx\nimport { PlayerInternals as PlayerInternals2 } from \"@remotion/player\";\nimport { useCallback as useCallback9, useEffect as useEffect9, useMemo as useMemo14, useRef as useRef7, useState as useState10 } from \"react\";\nimport ReactDOM from \"react-dom\";\n\n// src/icons/caret.tsx\nimport { useMemo as useMemo12 } from \"react\";\nimport { jsx as jsx20 } from \"react/jsx-runtime\";\nvar caret = {\n  height: 12\n};\nvar caretDown = {\n  width: 10\n};\nvar angleDown = {\n  width: 10\n};\nvar CaretRight = () => /* @__PURE__ */ jsx20(\"svg\", {\n  viewBox: \"0 0 192 512\",\n  style: caret,\n  children: /* @__PURE__ */ jsx20(\"path\", {\n    fill: \"currentColor\",\n    d: \"M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z\"\n  })\n});\nvar CaretDown = () => {\n  return /* @__PURE__ */ jsx20(\"svg\", {\n    viewBox: \"0 0 320 512\",\n    style: caretDown,\n    children: /* @__PURE__ */ jsx20(\"path\", {\n      fill: \"currentColor\",\n      d: \"M31.3 192h257.3c17.8 0 26.7 21.5 14.1 34.1L174.1 354.8c-7.8 7.8-20.5 7.8-28.3 0L17.2 226.1C4.6 213.5 13.5 192 31.3 192z\"\n    })\n  });\n};\nvar AngleDown = ({ down }) => {\n  const style = useMemo12(() => {\n    return {\n      ...angleDown,\n      transform: down ? \"rotate(180deg)\" : \"rotate(0deg)\",\n      marginTop: 1\n    };\n  }, [down]);\n  return /* @__PURE__ */ jsx20(\"svg\", {\n    style,\n    viewBox: \"0 0 448 512\",\n    children: /* @__PURE__ */ jsx20(\"path\", {\n      fill: LIGHT_TEXT,\n      d: \"M201.4 342.6c12.5 12.5 32.8 12.5 45.3 0l160-160c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L224 274.7 86.6 137.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l160 160z\"\n    })\n  });\n};\n\n// src/components/layout.tsx\nimport { useMemo as useMemo13 } from \"react\";\nimport { jsx as jsx21 } from \"react/jsx-runtime\";\nvar SPACING_UNIT = 8;\nvar Spacing = ({ x = 0, y = 0, block = false }) => {\n  const style = useMemo13(() => {\n    return {\n      display: block ? \"block\" : \"inline-block\",\n      width: x * SPACING_UNIT,\n      height: y * SPACING_UNIT,\n      flexShrink: 0\n    };\n  }, [block, x, y]);\n  return /* @__PURE__ */ jsx21(\"div\", {\n    style\n  });\n};\nvar flexCss = { flex: 1 };\nvar Flex = ({ children }) => /* @__PURE__ */ jsx21(\"div\", {\n  style: flexCss,\n  children\n});\nvar Row = ({ children, justify, className, align, flex, style = {}, ...other }) => {\n  const finalStyle = useMemo13(() => {\n    return {\n      ...style,\n      display: \"flex\",\n      flexDirection: \"row\",\n      justifyContent: justify ?? \"flex-start\",\n      alignItems: align ?? \"flex-start\",\n      flex: flex ?? undefined\n    };\n  }, [align, flex, justify, style]);\n  return /* @__PURE__ */ jsx21(\"div\", {\n    className,\n    style: finalStyle,\n    ...other,\n    children\n  });\n};\nvar Column = ({ children, justify, className, align, style = {} }) => {\n  const finalStyle = useMemo13(() => {\n    return {\n      ...style,\n      display: \"flex\",\n      flexDirection: \"column\",\n      justifyContent: justify ?? \"flex-start\",\n      alignItems: align ?? \"flex-start\"\n    };\n  }, [align, justify, style]);\n  return /* @__PURE__ */ jsx21(\"div\", {\n    className,\n    style: finalStyle,\n    children\n  });\n};\n\n// src/components/Menu/SubMenu.tsx\nimport { useCallback as useCallback8 } from \"react\";\nimport { jsx as jsx22 } from \"react/jsx-runtime\";\nvar SubMenuComponent = ({\n  portalStyle,\n  subMenuActivated,\n  subMenu,\n  onQuitFullMenu,\n  onQuitSubMenu\n}) => {\n  const mobileLayout = useMobileLayout();\n  const onOutsideClick = useCallback8((e) => {\n    if (portals.find((p) => p.contains(e)) || mobileLayout) {\n      onQuitSubMenu();\n    } else {\n      onQuitFullMenu();\n    }\n  }, [mobileLayout, onQuitFullMenu, onQuitSubMenu]);\n  return /* @__PURE__ */ jsx22(HigherZIndex, {\n    onEscape: onQuitFullMenu,\n    onOutsideClick,\n    children: /* @__PURE__ */ jsx22(\"div\", {\n      style: portalStyle,\n      className: \"css-reset\",\n      children: /* @__PURE__ */ jsx22(MenuContent, {\n        onNextMenu: noop,\n        onPreviousMenu: onQuitSubMenu,\n        values: subMenu.items,\n        onHide: onQuitFullMenu,\n        leaveLeftSpace: subMenu.leaveLeftSpace,\n        preselectIndex: subMenuActivated === \"without-mouse\" && typeof subMenu.preselectIndex === \"number\" ? subMenu.preselectIndex : false,\n        topItemCanBeUnselected: false,\n        fixedHeight: null\n      })\n    })\n  });\n};\n\n// src/components/Menu/is-menu-item.tsx\nvar MENU_INITIATOR_CLASSNAME = \"__remotion-studio-menu-initiator\";\nvar MENU_ITEM_CLASSNAME = \"__remotion-studio-menu-item\";\nvar HORIZONTAL_SCROLLBAR_CLASSNAME = \"__remotion-horizontal-scrollbar\";\nvar VERTICAL_SCROLLBAR_CLASSNAME = \"__remotion-vertical-scrollbar\";\nvar isMenuItem = (el) => {\n  return Boolean(el.classList.contains(MENU_ITEM_CLASSNAME) || el.closest(`.${MENU_ITEM_CLASSNAME}`) || el.classList.contains(MENU_INITIATOR_CLASSNAME) || el.closest(`.${MENU_INITIATOR_CLASSNAME}`));\n};\n\n// src/components/Menu/MenuSubItem.tsx\nimport { jsx as jsx23, jsxs as jsxs3, Fragment } from \"react/jsx-runtime\";\nvar container4 = {\n  paddingTop: 8,\n  paddingBottom: 8,\n  paddingLeft: 12,\n  paddingRight: 8,\n  cursor: \"default\"\n};\nvar labelStyle = {\n  fontSize: 13,\n  overflow: \"hidden\",\n  textOverflow: \"ellipsis\",\n  whiteSpace: \"nowrap\",\n  flex: 1\n};\nvar keyHintCss = {\n  flexDirection: \"row\",\n  color: LIGHT_TEXT,\n  fontSize: 13\n};\nvar leftSpace = {\n  width: 24,\n  marginLeft: -6,\n  display: \"inline-flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\"\n};\nvar MenuSubItem = ({\n  label,\n  leaveLeftSpace,\n  leftItem,\n  onActionChosen,\n  id,\n  selected,\n  onItemSelected,\n  keyHint,\n  subMenu,\n  onQuitMenu,\n  subMenuActivated,\n  setSubMenuActivated,\n  disabled\n}) => {\n  const [hovered, setHovered] = useState10(false);\n  const ref = useRef7(null);\n  const size = PlayerInternals2.useElementSize(ref, {\n    triggerOnWindowResize: true,\n    shouldApplyCssTransforms: true\n  });\n  const mobileLayout = useMobileLayout();\n  const { currentZIndex } = useZIndex();\n  const style = useMemo14(() => {\n    return {\n      ...container4,\n      backgroundColor: selected && !disabled ? CLEAR_HOVER : \"transparent\",\n      opacity: disabled ? 0.5 : 1,\n      cursor: disabled ? \"not-allowed\" : \"default\"\n    };\n  }, [selected, disabled]);\n  const onPointerUp = useCallback9((e) => {\n    if (disabled) {\n      return;\n    }\n    if (subMenu) {\n      setSubMenuActivated(\"with-mouse\");\n      setHovered(true);\n      return;\n    }\n    onActionChosen(id, e);\n  }, [disabled, id, onActionChosen, setSubMenuActivated, subMenu]);\n  const onPointerEnter = useCallback9(() => {\n    if (disabled) {\n      return;\n    }\n    onItemSelected(id);\n    setHovered(true);\n  }, [disabled, id, onItemSelected]);\n  const onPointerLeave = useCallback9(() => {\n    setHovered(false);\n  }, []);\n  const onQuitSubmenu = useCallback9(() => {\n    setSubMenuActivated(false);\n  }, [setSubMenuActivated]);\n  const portalStyle = useMemo14(() => {\n    if (!selected || !size || !subMenu || !subMenuActivated) {\n      return null;\n    }\n    const left = size.left + size.width + SUBMENU_LEFT_INSET;\n    return {\n      ...menuContainerTowardsBottom,\n      left: mobileLayout ? left * 0.7 : left,\n      top: size.top - MENU_VERTICAL_PADDING\n    };\n  }, [mobileLayout, selected, size, subMenu, subMenuActivated]);\n  useEffect9(() => {\n    if (!hovered || !subMenu) {\n      return;\n    }\n    const hi = setTimeout(() => {\n      setSubMenuActivated(\"with-mouse\");\n    }, 100);\n    return () => clearTimeout(hi);\n  }, [hovered, selected, setSubMenuActivated, subMenu]);\n  useEffect9(() => {\n    if (selected) {\n      ref.current?.scrollIntoView({\n        block: \"nearest\"\n      });\n    }\n  }, [selected]);\n  return /* @__PURE__ */ jsx23(\"div\", {\n    ref,\n    onPointerEnter,\n    onPointerLeave,\n    style,\n    onPointerUp,\n    role: \"button\",\n    className: MENU_ITEM_CLASSNAME,\n    children: /* @__PURE__ */ jsxs3(Row, {\n      align: \"center\",\n      children: [\n        leaveLeftSpace ? /* @__PURE__ */ jsxs3(Fragment, {\n          children: [\n            /* @__PURE__ */ jsx23(\"div\", {\n              style: leftSpace,\n              children: leftItem\n            }),\n            /* @__PURE__ */ jsx23(Spacing, {\n              x: 1\n            })\n          ]\n        }) : null,\n        /* @__PURE__ */ jsx23(\"div\", {\n          style: labelStyle,\n          ...{ title: typeof label === \"string\" ? label : undefined },\n          children: label\n        }),\n        \" \",\n        /* @__PURE__ */ jsx23(Spacing, {\n          x: 2\n        }),\n        subMenu ? /* @__PURE__ */ jsx23(CaretRight, {}) : null,\n        keyHint && !areKeyboardShortcutsDisabled() ? /* @__PURE__ */ jsx23(\"span\", {\n          style: keyHintCss,\n          children: keyHint\n        }) : null,\n        portalStyle && subMenu ? ReactDOM.createPortal(/* @__PURE__ */ jsx23(SubMenuComponent, {\n          onQuitFullMenu: onQuitMenu,\n          subMenu,\n          onQuitSubMenu: onQuitSubmenu,\n          portalStyle,\n          subMenuActivated\n        }), getPortal(currentZIndex)) : null\n      ]\n    })\n  });\n};\n\n// src/components/NewComposition/MenuContent.tsx\nimport { jsx as jsx24 } from \"react/jsx-runtime\";\nvar BORDER_SIZE = 1;\nvar container5 = {\n  paddingTop: MENU_VERTICAL_PADDING,\n  paddingBottom: MENU_VERTICAL_PADDING,\n  border: `${BORDER_SIZE}px solid ${INPUT_BORDER_COLOR_UNHOVERED}`,\n  marginLeft: 0 - BORDER_SIZE,\n  overflowY: \"auto\",\n  overflowX: \"hidden\",\n  minWidth: 200,\n  maxWidth: MAX_MENU_WIDTH\n};\nvar MenuContent = ({\n  onHide,\n  values,\n  preselectIndex,\n  onNextMenu,\n  onPreviousMenu,\n  leaveLeftSpace,\n  topItemCanBeUnselected,\n  fixedHeight\n}) => {\n  const keybindings = useKeybinding();\n  const containerRef = useRef8(null);\n  const isMobileLayout = useMobileLayout();\n  const [subMenuActivated, setSubMenuActivated] = useState11(false);\n  if (values[0].type === \"divider\") {\n    throw new Error(\"first value cant be divide\");\n  }\n  const [selectedItem, setSelectedItem] = useState11(typeof preselectIndex === \"number\" && preselectIndex >= 0 ? values[preselectIndex].id : null);\n  const onEscape = useCallback10(() => {\n    onHide();\n  }, [onHide]);\n  const onItemSelected = useCallback10((id) => {\n    setSelectedItem(id);\n  }, []);\n  const isItemSelectable = useCallback10((v) => {\n    return v.type !== \"divider\" && !v.disabled;\n  }, []);\n  const onArrowUp = useCallback10(() => {\n    setSelectedItem((prevItem) => {\n      if (prevItem === null) {\n        return null;\n      }\n      const index = values.findIndex((val) => val.id === prevItem);\n      if (topItemCanBeUnselected && index === 0 || prevItem === null) {\n        return null;\n      }\n      const previousItems = values.filter((v, i) => i < index && isItemSelectable(v));\n      if (previousItems.length > 0) {\n        return previousItems[previousItems.length - 1].id;\n      }\n      const firstSelectable = values.find((v) => isItemSelectable(v));\n      if (firstSelectable) {\n        return firstSelectable.id;\n      }\n      throw new Error(\"could not find previous item\");\n    });\n  }, [topItemCanBeUnselected, values, isItemSelectable]);\n  const onArrowDown = useCallback10(() => {\n    setSelectedItem((prevItem) => {\n      const index = values.findIndex((val) => val.id === prevItem);\n      const nextItem = values.find((v, i) => i > index && isItemSelectable(v));\n      if (nextItem) {\n        return nextItem.id;\n      }\n      const lastSelectable = values.slice().reverse().find((v) => isItemSelectable(v));\n      if (lastSelectable) {\n        return lastSelectable.id;\n      }\n      throw new Error(\"could not find next item\");\n    });\n  }, [values, isItemSelectable]);\n  const onEnter = useCallback10(() => {\n    if (selectedItem === null) {\n      return onHide();\n    }\n    const item = values.find((i) => i.id === selectedItem);\n    if (!item) {\n      throw new Error(\"cannot find item\");\n    }\n    if (item.type === \"divider\") {\n      throw new Error(\"cannot find divider\");\n    }\n    if (item.disabled) {\n      return;\n    }\n    if (item.subMenu) {\n      return setSubMenuActivated(\"without-mouse\");\n    }\n    onHide();\n    item.onClick(item.id, null);\n  }, [onHide, selectedItem, values]);\n  const onArrowRight = useCallback10(() => {\n    if (selectedItem === null) {\n      return onNextMenu();\n    }\n    const item = values.find((i) => i.id === selectedItem);\n    if (!item) {\n      throw new Error(\"cannot find item\");\n    }\n    if (item.type === \"divider\") {\n      throw new Error(\"cannot find divider\");\n    }\n    if (!item.subMenu) {\n      return onNextMenu();\n    }\n    setSubMenuActivated(\"without-mouse\");\n  }, [onNextMenu, selectedItem, values]);\n  const containerWithHeight = useMemo15(() => {\n    const containerStyles = { ...container5 };\n    if (fixedHeight === null) {\n      containerStyles.maxHeight = 600;\n    } else {\n      containerStyles.maxHeight = fixedHeight;\n    }\n    if (isMobileLayout) {\n      containerStyles.maxWidth = MAX_MOBILE_MENU_WIDTH;\n    }\n    return containerStyles;\n  }, [fixedHeight, isMobileLayout]);\n  useEffect10(() => {\n    const escapeBinding = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"Escape\",\n      callback: onEscape,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const rightBinding = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"ArrowRight\",\n      commandCtrlKey: false,\n      callback: onArrowRight,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const leftBinding = keybindings.registerKeybinding({\n      event: \"keydown\",\n      commandCtrlKey: false,\n      key: \"ArrowLeft\",\n      callback: onPreviousMenu,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const downBinding = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"ArrowDown\",\n      commandCtrlKey: false,\n      callback: onArrowDown,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const upBinding = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"ArrowUp\",\n      callback: onArrowUp,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const enterBinding = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"Enter\",\n      callback: onEnter,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const spaceBinding = keybindings.registerKeybinding({\n      event: \"keyup\",\n      key: \" \",\n      callback: onEnter,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      escapeBinding.unregister();\n      leftBinding.unregister();\n      rightBinding.unregister();\n      downBinding.unregister();\n      upBinding.unregister();\n      enterBinding.unregister();\n      spaceBinding.unregister();\n    };\n  }, [\n    keybindings,\n    onEscape,\n    onNextMenu,\n    onPreviousMenu,\n    onArrowDown,\n    onArrowUp,\n    onEnter,\n    onArrowRight\n  ]);\n  useEffect10(() => {\n    if (!subMenuActivated) {\n      return;\n    }\n    if (selectedItem === null) {\n      return setSubMenuActivated(false);\n    }\n    const item = values.find((i) => i.id === selectedItem);\n    if (!item) {\n      return;\n    }\n    if (item.type === \"divider\") {\n      throw new Error(\"should not select divider\");\n    }\n    if (!item.subMenu && subMenuActivated) {\n      setSubMenuActivated(false);\n    }\n  }, [selectedItem, subMenuActivated, values]);\n  useEffect10(() => {\n    const { current } = containerRef;\n    if (!current) {\n      return;\n    }\n    const onPointerLeave = () => {\n      if (subMenuActivated) {\n        return;\n      }\n      setSelectedItem(null);\n    };\n    current.addEventListener(\"pointerleave\", onPointerLeave);\n    return () => current.removeEventListener(\"pointerleave\", onPointerLeave);\n  }, [onHide, subMenuActivated]);\n  return /* @__PURE__ */ jsx24(\"div\", {\n    ref: containerRef,\n    style: containerWithHeight,\n    className: VERTICAL_SCROLLBAR_CLASSNAME,\n    children: values.map((item) => {\n      if (item.type === \"divider\") {\n        return /* @__PURE__ */ jsx24(MenuDivider, {}, item.id);\n      }\n      const onClick = (id, e) => {\n        item.onClick(id, e);\n        if (item.subMenu) {\n          return null;\n        }\n        onHide();\n      };\n      return /* @__PURE__ */ jsx24(MenuSubItem, {\n        selected: item.id === selectedItem,\n        onActionChosen: onClick,\n        onItemSelected,\n        label: item.label,\n        id: item.id,\n        keyHint: item.keyHint,\n        leaveLeftSpace,\n        leftItem: item.leftItem,\n        subMenu: item.subMenu,\n        onQuitMenu: onHide,\n        onNextMenu,\n        subMenuActivated,\n        setSubMenuActivated,\n        disabled: item.disabled\n      }, item.id);\n    })\n  });\n};\n\n// src/components/InlineDropdown.tsx\nimport { jsx as jsx25, jsxs as jsxs4, Fragment as Fragment2 } from \"react/jsx-runtime\";\nvar InlineDropdown = ({\n  values,\n  ...props\n}) => {\n  const ref = useRef9(null);\n  const [opened, setOpened] = useState12({ type: \"not-open\" });\n  const { currentZIndex } = useZIndex();\n  const size = PlayerInternals3.useElementSize(ref, {\n    triggerOnWindowResize: true,\n    shouldApplyCssTransforms: true\n  });\n  const isMobileLayout = useMobileLayout();\n  const onClick = useCallback11((e) => {\n    e.preventDefault();\n    e.stopPropagation();\n    setOpened({ type: \"open\", left: e.clientX, top: e.clientY });\n  }, []);\n  const spaceToBottom = useMemo16(() => {\n    if (size && opened.type === \"open\") {\n      return size.windowSize.height - opened.top;\n    }\n    return 0;\n  }, [opened, size]);\n  const spaceToTop = useMemo16(() => {\n    if (size && opened.type === \"open\") {\n      return opened.top;\n    }\n    return 0;\n  }, [opened, size]);\n  const portalStyle = useMemo16(() => {\n    if (opened.type === \"not-open\") {\n      return;\n    }\n    if (!size) {\n      return;\n    }\n    const spaceToRight = size.windowSize.width - size.left;\n    const spaceToLeft = size.left + size.width;\n    const minSpaceRequired = isMobileLayout ? MAX_MOBILE_MENU_WIDTH : MAX_MENU_WIDTH;\n    const verticalLayout = spaceToTop > spaceToBottom ? \"bottom\" : \"top\";\n    const canOpenOnLeft = spaceToLeft >= minSpaceRequired;\n    const canOpenOnRight = spaceToRight >= minSpaceRequired;\n    const horizontalLayout = canOpenOnRight ? \"left\" : \"right\";\n    return {\n      ...menuContainerTowardsTop,\n      ...verticalLayout === \"top\" ? {\n        top: opened.top\n      } : {\n        bottom: size.windowSize.height - opened.top\n      },\n      ...horizontalLayout === \"left\" ? {\n        left: opened.left\n      } : {\n        right: canOpenOnLeft ? size.windowSize.width - opened.left : 0\n      }\n    };\n  }, [opened, size, isMobileLayout, spaceToTop, spaceToBottom]);\n  const onHide = useCallback11(() => {\n    setOpened({ type: \"not-open\" });\n  }, []);\n  return /* @__PURE__ */ jsxs4(Fragment2, {\n    children: [\n      /* @__PURE__ */ jsx25(\"div\", {\n        ref,\n        children: /* @__PURE__ */ jsx25(InlineAction, {\n          onClick,\n          ...props\n        })\n      }),\n      portalStyle ? ReactDOM2.createPortal(/* @__PURE__ */ jsx25(\"div\", {\n        style: fullScreenOverlay,\n        children: /* @__PURE__ */ jsx25(\"div\", {\n          style: outerPortal,\n          className: \"css-reset\",\n          children: /* @__PURE__ */ jsx25(HigherZIndex, {\n            onOutsideClick: onHide,\n            onEscape: onHide,\n            children: /* @__PURE__ */ jsx25(\"div\", {\n              style: portalStyle,\n              children: /* @__PURE__ */ jsx25(MenuContent, {\n                onNextMenu: noop,\n                onPreviousMenu: noop,\n                values,\n                onHide,\n                leaveLeftSpace: true,\n                preselectIndex: false,\n                topItemCanBeUnselected: false,\n                fixedHeight: null\n              })\n            })\n          })\n        })\n      }), getPortal(currentZIndex)) : null\n    ]\n  });\n};\n\n// src/components/CompositionContextButton.tsx\nimport { jsx as jsx26 } from \"react/jsx-runtime\";\nvar CompositionContextButton = ({ visible, values }) => {\n  const iconStyle = useMemo17(() => {\n    return {\n      style: {\n        height: 12\n      }\n    };\n  }, []);\n  const connectionStatus = useContext6(StudioServerConnectionCtx).previewServerState.type;\n  const renderAction = useCallback12((color) => {\n    return /* @__PURE__ */ jsx26(EllipsisIcon, {\n      fill: color,\n      svgProps: iconStyle\n    });\n  }, [iconStyle]);\n  if (!visible || connectionStatus !== \"connected\") {\n    return null;\n  }\n  return /* @__PURE__ */ jsx26(InlineDropdown, {\n    renderAction,\n    values\n  });\n};\n\n// src/components/ContextMenu.tsx\nimport { PlayerInternals as PlayerInternals4 } from \"@remotion/player\";\nimport { useCallback as useCallback13, useEffect as useEffect11, useMemo as useMemo18, useRef as useRef10, useState as useState13 } from \"react\";\nimport ReactDOM3 from \"react-dom\";\nimport { jsx as jsx27, jsxs as jsxs5, Fragment as Fragment3 } from \"react/jsx-runtime\";\nvar ContextMenu = ({ children, values }) => {\n  const ref = useRef10(null);\n  const [opened, setOpened] = useState13({ type: \"not-open\" });\n  const { currentZIndex } = useZIndex();\n  const style = useMemo18(() => {\n    return {};\n  }, []);\n  const size = PlayerInternals4.useElementSize(ref, {\n    triggerOnWindowResize: true,\n    shouldApplyCssTransforms: true\n  });\n  const isMobileLayout = useMobileLayout();\n  useEffect11(() => {\n    const { current } = ref;\n    if (!current) {\n      return;\n    }\n    const onClick = (e) => {\n      e.preventDefault();\n      e.stopPropagation();\n      setOpened({ type: \"open\", left: e.clientX, top: e.clientY });\n      return false;\n    };\n    current.addEventListener(\"contextmenu\", onClick);\n    return () => {\n      current.removeEventListener(\"contextmenu\", onClick);\n    };\n  }, [size]);\n  const spaceToBottom = useMemo18(() => {\n    if (size && opened.type === \"open\") {\n      return size.windowSize.height - opened.top;\n    }\n    return 0;\n  }, [opened, size]);\n  const spaceToTop = useMemo18(() => {\n    if (size && opened.type === \"open\") {\n      return opened.top;\n    }\n    return 0;\n  }, [opened, size]);\n  const portalStyle = useMemo18(() => {\n    if (opened.type === \"not-open\") {\n      return;\n    }\n    if (!size) {\n      return;\n    }\n    const spaceToRight = size.windowSize.width - size.left;\n    const spaceToLeft = size.left + size.width;\n    const minSpaceRequired = isMobileLayout ? MAX_MOBILE_MENU_WIDTH : MAX_MENU_WIDTH;\n    const verticalLayout = spaceToTop > spaceToBottom ? \"bottom\" : \"top\";\n    const canOpenOnLeft = spaceToLeft >= minSpaceRequired;\n    const canOpenOnRight = spaceToRight >= minSpaceRequired;\n    const horizontalLayout = canOpenOnRight ? \"left\" : \"right\";\n    return {\n      ...menuContainerTowardsTop,\n      ...verticalLayout === \"top\" ? {\n        top: opened.top\n      } : {\n        bottom: size.windowSize.height - opened.top\n      },\n      ...horizontalLayout === \"left\" ? {\n        left: opened.left\n      } : {\n        right: canOpenOnLeft ? size.windowSize.width - opened.left : 0\n      }\n    };\n  }, [opened, size, isMobileLayout, spaceToTop, spaceToBottom]);\n  const onHide = useCallback13(() => {\n    setOpened({ type: \"not-open\" });\n  }, []);\n  return /* @__PURE__ */ jsxs5(Fragment3, {\n    children: [\n      /* @__PURE__ */ jsx27(\"div\", {\n        ref,\n        onContextMenu: () => false,\n        style,\n        children\n      }),\n      portalStyle ? ReactDOM3.createPortal(/* @__PURE__ */ jsx27(\"div\", {\n        style: fullScreenOverlay,\n        children: /* @__PURE__ */ jsx27(\"div\", {\n          style: outerPortal,\n          className: \"css-reset\",\n          children: /* @__PURE__ */ jsx27(HigherZIndex, {\n            onOutsideClick: onHide,\n            onEscape: onHide,\n            children: /* @__PURE__ */ jsx27(\"div\", {\n              style: portalStyle,\n              children: /* @__PURE__ */ jsx27(MenuContent, {\n                onNextMenu: noop,\n                onPreviousMenu: noop,\n                values,\n                onHide,\n                leaveLeftSpace: true,\n                preselectIndex: false,\n                topItemCanBeUnselected: false,\n                fixedHeight: null\n              })\n            })\n          })\n        })\n      }), getPortal(currentZIndex)) : null\n    ]\n  });\n};\n\n// src/components/SidebarRenderButton.tsx\nimport { useCallback as useCallback14, useContext as useContext7, useMemo as useMemo19 } from \"react\";\nimport { Internals as Internals5 } from \"remotion\";\n\n// src/icons/render.tsx\nimport { jsx as jsx28 } from \"react/jsx-runtime\";\nvar ThinRenderIcon = (props) => {\n  return /* @__PURE__ */ jsx28(\"svg\", {\n    ...props.svgProps,\n    xmlns: \"http://www.w3.org/2000/svg\",\n    viewBox: \"0 0 512 512\",\n    children: /* @__PURE__ */ jsx28(\"path\", {\n      fill: props.fill,\n      d: \"M188.9 372l-50.4-50.4c18.6-42.6 61.7-137.7 95.1-187C304.6 30.1 409 24.6 475.7 36.3c11.7 66.7 6.2 171.1-98.4 242c-49.4 33.5-145.5 75.6-188.4 93.7zm-79.9-62.8c-5.2 11.9-2.5 25.7 6.7 34.9l50.7 50.7c9.1 9.1 22.7 11.9 34.5 6.9c6.5-2.7 14.3-6 23-9.8L224 496c0 5.5 2.9 10.7 7.6 13.6s10.6 3.2 15.6 .7l101.5-50.7c21.7-10.8 35.4-33 35.4-57.2V312.1c4-2.5 7.7-4.9 11.3-7.3C516.1 222.9 520.1 100.9 506.7 28.1c-2.1-11.6-11.2-20.6-22.8-22.8C411.1-8.1 289.1-4.1 207.2 116.7c-2.4 3.6-4.9 7.3-7.3 11.3l-90.2 0c-24.2 0-46.4 13.7-57.2 35.4L1.7 264.8c-2.5 5-2.2 10.8 .7 15.6s8.1 7.6 13.6 7.6H118.5c-3.6 8-6.8 15.2-9.4 21.2zM256 470.1l0-92.5c30.3-13.7 65.4-30.3 96-47v71.7c0 12.1-6.8 23.2-17.7 28.6L256 470.1zM109.7 160h71.5c-16.9 30.7-34 65.8-48.1 96H41.9L81 177.7c5.4-10.8 16.5-17.7 28.6-17.7zM392 144a24 24 0 1 1 -48 0 24 24 0 1 1 48 0zM368 88a56 56 0 1 0 0 112 56 56 0 1 0 0-112z\"\n    })\n  });\n};\n\n// src/components/SidebarRenderButton.tsx\nimport { jsx as jsx29 } from \"react/jsx-runtime\";\nvar SidebarRenderButton = ({ composition, visible }) => {\n  const { setSelectedModal } = useContext7(ModalsContext);\n  const { setSidebarCollapsedState } = useContext7(SidebarContext);\n  const isMobileLayout = useMobileLayout();\n  const iconStyle = useMemo19(() => {\n    return {\n      style: {\n        height: 12\n      }\n    };\n  }, []);\n  const connectionStatus = useContext7(StudioServerConnectionCtx).previewServerState.type;\n  const { props } = useContext7(Internals5.EditorPropsContext);\n  const onClick = useCallback14((e) => {\n    const defaults = window.remotion_renderDefaults;\n    if (!defaults) {\n      throw new Error(\"expected defaults\");\n    }\n    e.stopPropagation();\n    setSelectedModal({\n      type: \"server-render\",\n      compositionId: composition.id,\n      initialFrame: 0,\n      initialVideoImageFormat: defaults.videoImageFormat,\n      initialStillImageFormat: defaults.stillImageFormat,\n      initialJpegQuality: defaults.jpegQuality,\n      initialScale: defaults.scale,\n      initialLogLevel: defaults.logLevel,\n      initialConcurrency: defaults.concurrency,\n      maxConcurrency: defaults.maxConcurrency,\n      minConcurrency: defaults.minConcurrency,\n      initialMuted: defaults.muted,\n      initialEnforceAudioTrack: defaults.enforceAudioTrack,\n      initialProResProfile: defaults.proResProfile,\n      initialx264Preset: defaults.x264Preset,\n      initialPixelFormat: null,\n      initialAudioBitrate: defaults.audioBitrate,\n      initialVideoBitrate: defaults.videoBitrate,\n      initialEveryNthFrame: defaults.everyNthFrame,\n      initialNumberOfGifLoops: defaults.numberOfGifLoops,\n      initialDelayRenderTimeout: defaults.delayRenderTimeout,\n      defaultConfigurationAudioCodec: defaults.audioCodec,\n      initialEnvVariables: window.process.env,\n      initialDisableWebSecurity: defaults.disableWebSecurity,\n      initialOpenGlRenderer: defaults.openGlRenderer,\n      initialHeadless: defaults.headless,\n      initialOffthreadVideoCacheSizeInBytes: defaults.offthreadVideoCacheSizeInBytes,\n      initialOffthreadVideoThreads: defaults.offthreadVideoThreads,\n      initialIgnoreCertificateErrors: defaults.ignoreCertificateErrors,\n      defaultProps: props[composition.id] ?? composition.defaultProps,\n      inFrameMark: null,\n      outFrameMark: null,\n      initialColorSpace: defaults.colorSpace,\n      initialMultiProcessOnLinux: defaults.multiProcessOnLinux,\n      defaultConfigurationVideoCodec: defaults.codec,\n      initialEncodingBufferSize: defaults.encodingBufferSize,\n      initialEncodingMaxRate: defaults.encodingMaxRate,\n      initialUserAgent: defaults.userAgent,\n      initialBeep: defaults.beepOnFinish,\n      initialRepro: defaults.repro,\n      initialForSeamlessAacConcatenation: defaults.forSeamlessAacConcatenation,\n      renderTypeOfLastRender: null,\n      defaulMetadata: defaults.metadata,\n      initialHardwareAcceleration: defaults.hardwareAcceleration,\n      initialChromeMode: defaults.chromeMode,\n      initialMediaCacheSizeInBytes: defaults.mediaCacheSizeInBytes,\n      renderDefaults: defaults,\n      initialDarkMode: defaults.darkMode\n    });\n    if (isMobileLayout) {\n      setSidebarCollapsedState({ left: \"collapsed\", right: \"collapsed\" });\n    }\n  }, [\n    composition.defaultProps,\n    composition.id,\n    isMobileLayout,\n    props,\n    setSelectedModal,\n    setSidebarCollapsedState\n  ]);\n  const renderAction = useCallback14((color) => {\n    return /* @__PURE__ */ jsx29(ThinRenderIcon, {\n      fill: color,\n      svgProps: iconStyle\n    });\n  }, [iconStyle]);\n  if (!visible || connectionStatus !== \"connected\") {\n    return null;\n  }\n  return /* @__PURE__ */ jsx29(InlineAction, {\n    renderAction,\n    onClick\n  });\n};\n\n// src/components/CompositionSelectorItem.tsx\nimport { jsx as jsx30, jsxs as jsxs6, Fragment as Fragment4 } from \"react/jsx-runtime\";\nvar COMPOSITION_ITEM_HEIGHT = 32;\nvar itemStyle = {\n  paddingRight: 10,\n  paddingTop: 6,\n  paddingBottom: 6,\n  fontSize: 13,\n  display: \"flex\",\n  textDecoration: \"none\",\n  cursor: \"default\",\n  alignItems: \"center\",\n  marginBottom: 1,\n  appearance: \"none\",\n  border: \"none\",\n  width: \"100%\",\n  textAlign: \"left\",\n  backgroundColor: BACKGROUND,\n  height: COMPOSITION_ITEM_HEIGHT\n};\nvar labelStyle2 = {\n  textAlign: \"left\",\n  textDecoration: \"none\",\n  fontSize: 13,\n  flex: 1,\n  whiteSpace: \"nowrap\",\n  overflow: \"hidden\",\n  textOverflow: \"ellipsis\"\n};\nvar iconStyle = {\n  width: 18,\n  height: 18,\n  flexShrink: 0\n};\nvar CompositionSelectorItem = ({\n  item,\n  level,\n  currentComposition,\n  tabIndex,\n  selectComposition,\n  toggleFolder\n}) => {\n  const selected = useMemo20(() => {\n    if (item.type === \"composition\") {\n      return currentComposition === item.composition.id;\n    }\n    return false;\n  }, [item, currentComposition]);\n  const [hovered, setHovered] = useState14(false);\n  const onPointerEnter = useCallback15(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback15(() => {\n    setHovered(false);\n  }, []);\n  const style = useMemo20(() => {\n    return {\n      ...itemStyle,\n      backgroundColor: getBackgroundFromHoverState({ hovered, selected }),\n      paddingLeft: 12 + level * 8\n    };\n  }, [hovered, level, selected]);\n  const label = useMemo20(() => {\n    return {\n      ...labelStyle2,\n      color: selected || hovered ? \"white\" : LIGHT_TEXT\n    };\n  }, [hovered, selected]);\n  const onClick = useCallback15((evt) => {\n    evt.preventDefault();\n    if (item.type === \"composition\") {\n      selectComposition(item.composition, true);\n    } else {\n      toggleFolder(item.folderName, item.parentName);\n    }\n  }, [item, selectComposition, toggleFolder]);\n  const onKeyPress = useCallback15((evt) => {\n    if (evt.key === \"Enter\") {\n      onClick(evt);\n    }\n  }, [onClick]);\n  const { setSelectedModal } = useContext8(ModalsContext);\n  const contextMenu = useMemo20(() => {\n    if (item.type === \"composition\") {\n      return [\n        {\n          id: \"duplicate\",\n          keyHint: null,\n          label: `Duplicate...`,\n          leftItem: null,\n          onClick: () => {\n            setSelectedModal({\n              type: \"duplicate-comp\",\n              compositionId: item.composition.id,\n              compositionType: item.composition.durationInFrames === 1 ? \"still\" : \"composition\"\n            });\n          },\n          quickSwitcherLabel: null,\n          subMenu: null,\n          type: \"item\",\n          value: \"duplicate\"\n        },\n        {\n          id: \"rename\",\n          keyHint: null,\n          label: `Rename...`,\n          leftItem: null,\n          onClick: () => {\n            setSelectedModal({\n              type: \"rename-comp\",\n              compositionId: item.composition.id\n            });\n          },\n          quickSwitcherLabel: null,\n          subMenu: null,\n          type: \"item\",\n          value: \"rename\"\n        },\n        {\n          id: \"delete\",\n          keyHint: null,\n          label: `Delete...`,\n          leftItem: null,\n          onClick: () => {\n            setSelectedModal({\n              type: \"delete-comp\",\n              compositionId: item.composition.id\n            });\n          },\n          quickSwitcherLabel: null,\n          subMenu: null,\n          type: \"item\",\n          value: \"delete\"\n        },\n        {\n          type: \"divider\",\n          id: \"copy-id-divider\"\n        },\n        {\n          id: \"copy-id\",\n          keyHint: null,\n          label: `Copy ID`,\n          leftItem: null,\n          onClick: () => {\n            navigator.clipboard.writeText(item.composition.id).catch((err) => {\n              showNotification(`Could not copy to clipboard: ${err.message}`, 1000);\n            }).then(() => {\n              showNotification(\"Copied to clipboard\", 1000);\n            });\n          },\n          quickSwitcherLabel: null,\n          subMenu: null,\n          type: \"item\",\n          value: \"remove\"\n        }\n      ];\n    }\n    return [];\n  }, [item, setSelectedModal]);\n  if (item.type === \"folder\") {\n    return /* @__PURE__ */ jsxs6(Fragment4, {\n      children: [\n        /* @__PURE__ */ jsxs6(\"button\", {\n          style,\n          onPointerEnter,\n          onPointerLeave,\n          tabIndex,\n          onClick,\n          type: \"button\",\n          title: item.folderName,\n          children: [\n            item.expanded ? /* @__PURE__ */ jsx30(ExpandedFolderIcon, {\n              style: iconStyle,\n              color: hovered || selected ? \"white\" : LIGHT_TEXT\n            }) : /* @__PURE__ */ jsx30(CollapsedFolderIcon, {\n              color: hovered || selected ? \"white\" : LIGHT_TEXT,\n              style: iconStyle\n            }),\n            /* @__PURE__ */ jsx30(Spacing, {\n              x: 1\n            }),\n            /* @__PURE__ */ jsx30(\"div\", {\n              style: label,\n              children: item.folderName\n            })\n          ]\n        }),\n        item.expanded ? item.items.map((childItem) => {\n          return /* @__PURE__ */ jsx30(CompositionSelectorItem, {\n            currentComposition,\n            selectComposition,\n            item: childItem,\n            tabIndex,\n            level: level + 1,\n            toggleFolder\n          }, childItem.key + childItem.type);\n        }) : null\n      ]\n    });\n  }\n  return /* @__PURE__ */ jsx30(ContextMenu, {\n    values: contextMenu,\n    children: /* @__PURE__ */ jsx30(Row, {\n      align: \"center\",\n      children: /* @__PURE__ */ jsxs6(\"a\", {\n        style,\n        onPointerEnter,\n        onPointerLeave,\n        tabIndex,\n        onClick,\n        onKeyPress,\n        type: \"button\",\n        title: item.composition.id,\n        className: \"__remotion-composition\",\n        \"data-compname\": item.composition.id,\n        children: [\n          isCompositionStill(item.composition) ? /* @__PURE__ */ jsx30(StillIcon, {\n            color: hovered || selected ? \"white\" : LIGHT_TEXT,\n            style: iconStyle\n          }) : /* @__PURE__ */ jsx30(FilmIcon, {\n            color: hovered || selected ? \"white\" : LIGHT_TEXT,\n            style: iconStyle\n          }),\n          /* @__PURE__ */ jsx30(Spacing, {\n            x: 1\n          }),\n          /* @__PURE__ */ jsx30(\"div\", {\n            style: label,\n            children: item.composition.id\n          }),\n          /* @__PURE__ */ jsx30(Spacing, {\n            x: 0.5\n          }),\n          /* @__PURE__ */ jsx30(CompositionContextButton, {\n            values: contextMenu,\n            visible: hovered\n          }),\n          /* @__PURE__ */ jsx30(SidebarRenderButton, {\n            visible: hovered,\n            composition: item.composition\n          })\n        ]\n      })\n    })\n  });\n};\n\n// src/components/CurrentComposition.tsx\nimport { Internals as Internals6 } from \"remotion\";\n\n// src/state/render-frame.ts\nvar renderFrame = (frame, fps) => {\n  const hours = Math.floor(frame / fps / 3600);\n  const remainingMinutes = frame - hours * fps * 3600;\n  const minutes = Math.floor(remainingMinutes / 60 / fps);\n  const remainingSec = frame - hours * fps * 3600 - minutes * fps * 60;\n  const seconds = Math.floor(remainingSec / fps);\n  const frameAfterSec = Math.round(frame % fps);\n  const hoursStr = String(hours);\n  const minutesStr = String(minutes).padStart(2, \"0\");\n  const secondsStr = String(seconds).padStart(2, \"0\");\n  const frameStr = String(frameAfterSec).padStart(2, \"0\");\n  if (hours > 0) {\n    return `${hoursStr}:${minutesStr}:${secondsStr}.${frameStr}`;\n  }\n  return `${minutesStr}:${secondsStr}.${frameStr}`;\n};\n\n// src/components/CurrentComposition.tsx\nimport { jsx as jsx31, jsxs as jsxs7 } from \"react/jsx-runtime\";\nvar CURRENT_COMPOSITION_HEIGHT = 80;\nvar container6 = {\n  height: CURRENT_COMPOSITION_HEIGHT,\n  display: \"block\",\n  borderBottom: `1px solid ${BORDER_COLOR}`,\n  padding: 12,\n  color: \"white\",\n  backgroundColor: BACKGROUND\n};\nvar title = {\n  fontWeight: \"bold\",\n  fontSize: 12,\n  whiteSpace: \"nowrap\",\n  lineHeight: \"18px\",\n  backgroundColor: BACKGROUND\n};\nvar subtitle = {\n  fontSize: 12,\n  opacity: 0.8,\n  whiteSpace: \"nowrap\",\n  lineHeight: \"18px\",\n  backgroundColor: BACKGROUND\n};\nvar row = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  lineHeight: \"18px\",\n  backgroundColor: BACKGROUND\n};\nvar CurrentComposition = () => {\n  const video = Internals6.useVideo();\n  if (!video) {\n    return /* @__PURE__ */ jsx31(\"div\", {\n      style: container6\n    });\n  }\n  return /* @__PURE__ */ jsx31(\"div\", {\n    style: container6,\n    children: /* @__PURE__ */ jsx31(\"div\", {\n      style: row,\n      children: /* @__PURE__ */ jsxs7(\"div\", {\n        children: [\n          /* @__PURE__ */ jsx31(\"div\", {\n            style: title,\n            children: video.id\n          }),\n          /* @__PURE__ */ jsxs7(\"div\", {\n            style: subtitle,\n            children: [\n              video.width,\n              \"x\",\n              video.height,\n              isCompositionStill(video) ? null : `, ${video.fps} FPS`\n            ]\n          }),\n          isCompositionStill(video) ? /* @__PURE__ */ jsx31(\"div\", {\n            style: subtitle,\n            children: \"Still\"\n          }) : /* @__PURE__ */ jsxs7(\"div\", {\n            style: subtitle,\n            children: [\n              \"Duration \",\n              renderFrame(video.durationInFrames, video.fps)\n            ]\n          })\n        ]\n      })\n    })\n  });\n};\n\n// src/components/CompositionSelector.tsx\nimport { jsx as jsx32, jsxs as jsxs8 } from \"react/jsx-runtime\";\nvar useCompositionNavigation = () => {\n  const { compositions, canvasContent } = useContext9(Internals7.CompositionManager);\n  const selectComposition = useSelectComposition();\n  const navigateToNextComposition = useCallback16(() => {\n    if (!canvasContent || canvasContent.type !== \"composition\" || compositions.length <= 1) {\n      return;\n    }\n    const currentIndex = compositions.findIndex((c) => c.id === canvasContent.compositionId);\n    if (currentIndex === -1) {\n      return;\n    }\n    const nextIndex = (currentIndex + 1) % compositions.length;\n    const nextComposition = compositions[nextIndex];\n    selectComposition(nextComposition, true);\n  }, [canvasContent, compositions, selectComposition]);\n  const navigateToPreviousComposition = useCallback16(() => {\n    if (!canvasContent || canvasContent.type !== \"composition\" || compositions.length <= 1) {\n      return;\n    }\n    const currentIndex = compositions.findIndex((c) => c.id === canvasContent.compositionId);\n    if (currentIndex === -1) {\n      return;\n    }\n    const previousIndex = (currentIndex - 1 + compositions.length) % compositions.length;\n    const previousComposition = compositions[previousIndex];\n    selectComposition(previousComposition, true);\n  }, [canvasContent, compositions, selectComposition]);\n  return useMemo21(() => ({\n    navigateToNextComposition,\n    navigateToPreviousComposition\n  }), [navigateToNextComposition, navigateToPreviousComposition]);\n};\nvar container7 = {\n  display: \"flex\",\n  flexDirection: \"column\",\n  flex: 1,\n  overflow: \"hidden\",\n  backgroundColor: BACKGROUND\n};\nvar getKeysToExpand = (initialFolderName, parentFolderName, initial = []) => {\n  initial.push(openFolderKey({\n    folderName: initialFolderName,\n    parentName: parentFolderName\n  }));\n  const { name, parent } = splitParentIntoNameAndParent(parentFolderName);\n  if (!name) {\n    return initial;\n  }\n  return getKeysToExpand(name, parent, initial);\n};\nvar CompositionSelector = () => {\n  const { compositions, canvasContent, folders } = useContext9(Internals7.CompositionManager);\n  const { foldersExpanded } = useContext9(ExpandedFoldersContext);\n  const { tabIndex } = useZIndex();\n  const selectComposition = useSelectComposition();\n  const items = useMemo21(() => {\n    return createFolderTree(compositions, folders, foldersExpanded);\n  }, [compositions, folders, foldersExpanded]);\n  const showCurrentComposition = canvasContent && canvasContent.type === \"composition\";\n  const list = useMemo21(() => {\n    return {\n      height: showCurrentComposition ? `calc(100% - ${CURRENT_COMPOSITION_HEIGHT}px)` : \"100%\",\n      overflowY: \"auto\"\n    };\n  }, [showCurrentComposition]);\n  const toggleFolder = useCallback16((folderName, parentName) => {\n    Internals7.compositionSelectorRef.current?.toggleFolder(folderName, parentName);\n  }, []);\n  return /* @__PURE__ */ jsxs8(\"div\", {\n    style: container7,\n    children: [\n      showCurrentComposition ? /* @__PURE__ */ jsx32(CurrentComposition, {}) : null,\n      /* @__PURE__ */ jsx32(\"div\", {\n        className: \"__remotion-vertical-scrollbar\",\n        style: list,\n        children: items.map((c) => {\n          return /* @__PURE__ */ jsx32(CompositionSelectorItem, {\n            level: 0,\n            currentComposition: showCurrentComposition ? canvasContent.compositionId : null,\n            selectComposition,\n            toggleFolder,\n            tabIndex,\n            item: c\n          }, c.key + c.type);\n        })\n      })\n    ]\n  });\n};\n\n// src/components/ExplorerPanel.tsx\nimport { createRef as createRef5, useCallback as useCallback22, useImperativeHandle as useImperativeHandle5, useState as useState19 } from \"react\";\n\n// src/components/AssetSelector.tsx\nimport React25, {\n  useCallback as useCallback19,\n  useContext as useContext11,\n  useEffect as useEffect13,\n  useMemo as useMemo24,\n  useState as useState16\n} from \"react\";\n\n// src/api/write-static-file.ts\nvar writeStaticFile = async ({\n  contents,\n  filePath\n}) => {\n  if (window.remotion_isReadOnlyStudio) {\n    throw new Error(\"writeStaticFile() is not available in read-only Studio\");\n  }\n  const url = new URL(\"/api/add-asset\", window.location.origin);\n  if (filePath.includes(\"\\\\\")) {\n    return Promise.reject(new Error(\"File path cannot contain backslashes\"));\n  }\n  url.search = new URLSearchParams({\n    filePath\n  }).toString();\n  const response = await fetch(url, {\n    method: \"POST\",\n    body: contents\n  });\n  if (!response.ok) {\n    const jsonResponse = await response.json();\n    throw new Error(jsonResponse.error);\n  }\n};\n\n// src/helpers/use-asset-drag-events.ts\nimport { useCallback as useCallback17, useEffect as useEffect12, useMemo as useMemo22, useRef as useRef11 } from \"react\";\nimport { NoReactInternals } from \"remotion/no-react\";\nfunction useAssetDragEvents({\n  name,\n  parentFolder,\n  dropLocation,\n  setDropLocation\n}) {\n  const dragDepthRef = useRef11(0);\n  const combinedParents = useMemo22(() => {\n    return [parentFolder, name].filter(NoReactInternals.truthy).join(\"/\");\n  }, [name, parentFolder]);\n  const isDropDiv = useMemo22(() => {\n    return dropLocation === combinedParents;\n  }, [combinedParents, dropLocation]);\n  const onDragEnter = useCallback17(() => {\n    if (dragDepthRef.current === 0) {\n      setDropLocation((currentDropLocation) => currentDropLocation?.includes(combinedParents) ? currentDropLocation : combinedParents);\n    }\n    dragDepthRef.current++;\n  }, [combinedParents, dragDepthRef, setDropLocation]);\n  const onDragLeave = useCallback17(() => {\n    dragDepthRef.current--;\n    if (dragDepthRef.current === 0) {\n      setDropLocation((currentPath) => currentPath === combinedParents ? parentFolder : currentPath);\n    }\n  }, [combinedParents, dragDepthRef, parentFolder, setDropLocation]);\n  useEffect12(() => {\n    if (dropLocation === null) {\n      dragDepthRef.current = 0;\n    }\n  }, [dropLocation]);\n  return {\n    isDropDiv,\n    onDragEnter,\n    onDragLeave\n  };\n}\nvar use_asset_drag_events_default = useAssetDragEvents;\n\n// src/components/AssetSelectorItem.tsx\nimport React24, { useCallback as useCallback18, useContext as useContext10, useMemo as useMemo23, useRef as useRef12, useState as useState15 } from \"react\";\nimport { Internals as Internals8 } from \"remotion\";\nimport { NoReactInternals as NoReactInternals3 } from \"remotion/no-react\";\n\n// src/helpers/copy-text.ts\nvar copyText = (cmd) => {\n  const permissionName = \"clipboard-write\";\n  return new Promise((resolve, reject) => {\n    navigator.permissions.query({ name: permissionName }).then((result) => {\n      if (result.state === \"granted\" || result.state === \"prompt\") {\n        navigator.clipboard.writeText(cmd);\n        resolve();\n      } else {\n        reject(new Error(\"Permission to copy not granted\"));\n      }\n    }).catch((err) => {\n      reject(err);\n    });\n  });\n};\n\n// src/icons/clipboard.tsx\nimport { jsx as jsx33 } from \"react/jsx-runtime\";\nvar ClipboardIcon = ({ color, ...props }) => /* @__PURE__ */ jsx33(\"svg\", {\n  viewBox: \"0 0 384 512\",\n  ...props,\n  children: /* @__PURE__ */ jsx33(\"path\", {\n    fill: color,\n    d: \"M336 64h-80c0-35.3-28.7-64-64-64s-64 28.7-64 64H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 40c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm144 418c0 3.3-2.7 6-6 6H54c-3.3 0-6-2.7-6-6V118c0-3.3 2.7-6 6-6h42v36c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12v-36h42c3.3 0 6 2.7 6 6z\"\n  })\n});\n\n// src/icons/file.tsx\nimport { jsx as jsx34 } from \"react/jsx-runtime\";\nvar FileIcon = ({\n  color,\n  ...props\n}) => /* @__PURE__ */ jsx34(\"svg\", {\n  xmlns: \"http://www.w3.org/2000/svg\",\n  viewBox: \"0 0 384 512\",\n  ...props,\n  children: /* @__PURE__ */ jsx34(\"path\", {\n    fill: color ?? \"currentColor\",\n    d: \"M0 64C0 28.65 28.65 0 64 0h156.1c12.7 0 25 5.057 34 14.06L369.9 129.9c9 9 14.1 21.3 14.1 34V448c0 35.3-28.7 64-64 64H64c-35.35 0-64-28.7-64-64V64zm352 128H240c-26.5 0-48-21.5-48-48V32H64c-17.67 0-32 14.33-32 32v384c0 17.7 14.33 32 32 32h256c17.7 0 32-14.3 32-32V192zm-4.7-39.4L231.4 36.69c-2-2.07-4.6-3.51-7.4-4.21V144c0 8.8 7.2 16 16 16h111.5c-.7-2.8-2.1-5.4-4.2-7.4z\"\n  })\n});\n\n// src/components/RenderQueue/actions.ts\nimport { NoReactInternals as NoReactInternals2 } from \"remotion/no-react\";\n\n// src/components/call-api.ts\nvar callApi = (endpoint, body, signal) => {\n  return new Promise((resolve, reject) => {\n    fetch(endpoint, {\n      method: \"post\",\n      headers: {\n        \"content-type\": \"application/json\"\n      },\n      signal,\n      body: JSON.stringify(body)\n    }).then((res) => res.json()).then((data) => {\n      if (data.success) {\n        resolve(data.data);\n      } else {\n        reject(new Error(data.error));\n      }\n    }).catch((err) => {\n      reject(err);\n    });\n  });\n};\n\n// src/components/RenderQueue/actions.ts\nvar addStillRenderJob = ({\n  compositionId,\n  outName,\n  imageFormat,\n  jpegQuality,\n  frame,\n  scale,\n  logLevel,\n  chromiumOptions,\n  delayRenderTimeout,\n  envVariables,\n  inputProps,\n  offthreadVideoCacheSizeInBytes,\n  offthreadVideoThreads,\n  multiProcessOnLinux,\n  beepOnFinish,\n  metadata,\n  chromeMode,\n  mediaCacheSizeInBytes\n}) => {\n  return callApi(\"/api/render\", {\n    compositionId,\n    type: \"still\",\n    outName,\n    imageFormat,\n    jpegQuality,\n    frame,\n    scale,\n    logLevel,\n    chromiumOptions,\n    delayRenderTimeout,\n    envVariables,\n    serializedInputPropsWithCustomSchema: NoReactInternals2.serializeJSONWithSpecialTypes({\n      data: inputProps,\n      staticBase: window.remotion_staticBase,\n      indent: undefined\n    }).serializedString,\n    offthreadVideoCacheSizeInBytes,\n    offthreadVideoThreads,\n    multiProcessOnLinux,\n    beepOnFinish,\n    metadata,\n    chromeMode,\n    mediaCacheSizeInBytes\n  });\n};\nvar addSequenceRenderJob = ({\n  compositionId,\n  outName,\n  imageFormat,\n  startFrame,\n  endFrame,\n  scale,\n  logLevel,\n  chromiumOptions,\n  delayRenderTimeout,\n  envVariables,\n  inputProps,\n  concurrency,\n  offthreadVideoCacheSizeInBytes,\n  offthreadVideoThreads,\n  jpegQuality,\n  disallowParallelEncoding,\n  multiProcessOnLinux,\n  beepOnFinish,\n  repro,\n  metadata,\n  chromeMode,\n  mediaCacheSizeInBytes\n}) => {\n  return callApi(\"/api/render\", {\n    compositionId,\n    type: \"sequence\",\n    outName,\n    imageFormat,\n    jpegQuality,\n    scale,\n    startFrame,\n    endFrame,\n    logLevel,\n    chromiumOptions,\n    delayRenderTimeout,\n    envVariables,\n    concurrency,\n    serializedInputPropsWithCustomSchema: NoReactInternals2.serializeJSONWithSpecialTypes({\n      data: inputProps,\n      staticBase: window.remotion_staticBase,\n      indent: undefined\n    }).serializedString,\n    offthreadVideoCacheSizeInBytes,\n    offthreadVideoThreads,\n    disallowParallelEncoding,\n    multiProcessOnLinux,\n    beepOnFinish,\n    repro,\n    metadata,\n    chromeMode,\n    mediaCacheSizeInBytes\n  });\n};\nvar addVideoRenderJob = ({\n  compositionId,\n  outName,\n  imageFormat,\n  jpegQuality,\n  scale,\n  logLevel,\n  codec,\n  concurrency,\n  crf,\n  startFrame,\n  endFrame,\n  muted,\n  enforceAudioTrack,\n  proResProfile,\n  x264Preset,\n  pixelFormat,\n  audioBitrate,\n  videoBitrate,\n  everyNthFrame,\n  numberOfGifLoops,\n  delayRenderTimeout,\n  audioCodec,\n  disallowParallelEncoding,\n  chromiumOptions,\n  envVariables,\n  inputProps,\n  offthreadVideoCacheSizeInBytes,\n  offthreadVideoThreads,\n  colorSpace,\n  multiProcessOnLinux,\n  encodingMaxRate,\n  encodingBufferSize,\n  beepOnFinish,\n  repro,\n  forSeamlessAacConcatenation,\n  separateAudioTo,\n  metadata,\n  hardwareAcceleration,\n  chromeMode,\n  mediaCacheSizeInBytes\n}) => {\n  return callApi(\"/api/render\", {\n    compositionId,\n    type: \"video\",\n    outName,\n    imageFormat,\n    jpegQuality,\n    scale,\n    logLevel,\n    codec,\n    concurrency,\n    crf,\n    endFrame,\n    startFrame,\n    muted,\n    enforceAudioTrack,\n    proResProfile,\n    x264Preset,\n    pixelFormat,\n    audioBitrate,\n    videoBitrate,\n    everyNthFrame,\n    numberOfGifLoops,\n    delayRenderTimeout,\n    audioCodec,\n    disallowParallelEncoding,\n    chromiumOptions,\n    envVariables,\n    serializedInputPropsWithCustomSchema: NoReactInternals2.serializeJSONWithSpecialTypes({\n      data: inputProps,\n      staticBase: window.remotion_staticBase,\n      indent: undefined\n    }).serializedString,\n    offthreadVideoCacheSizeInBytes,\n    offthreadVideoThreads,\n    colorSpace,\n    multiProcessOnLinux,\n    encodingBufferSize,\n    encodingMaxRate,\n    beepOnFinish,\n    repro,\n    forSeamlessAacConcatenation,\n    separateAudioTo,\n    metadata,\n    hardwareAcceleration,\n    chromeMode,\n    mediaCacheSizeInBytes\n  });\n};\nvar unsubscribeFromFileExistenceWatcher = ({\n  file,\n  clientId\n}) => {\n  return callApi(\"/api/unsubscribe-from-file-existence\", { file, clientId });\n};\nvar subscribeToFileExistenceWatcher = async ({\n  file,\n  clientId\n}) => {\n  const { exists } = await callApi(\"/api/subscribe-to-file-existence\", {\n    file,\n    clientId\n  });\n  return exists;\n};\nvar openInFileExplorer = ({ directory }) => {\n  const body = {\n    directory\n  };\n  return callApi(\"/api/open-in-file-explorer\", body);\n};\nvar applyCodemod = ({\n  codemod,\n  dryRun,\n  signal\n}) => {\n  const body = {\n    codemod,\n    dryRun\n  };\n  return callApi(\"/api/apply-codemod\", body, signal);\n};\nvar removeRenderJob = (job) => {\n  return callApi(\"/api/remove-render\", {\n    jobId: job.id\n  });\n};\nvar cancelRenderJob = (job) => {\n  return callApi(\"/api/cancel\", {\n    jobId: job.id\n  });\n};\nvar updateAvailable = (signal) => {\n  return callApi(\"/api/update-available\", {}, signal);\n};\nvar getProjectInfo = (signal) => {\n  return callApi(\"/api/project-info\", {}, signal);\n};\nvar callUpdateDefaultPropsApi = (compositionId, defaultProps, enumPaths) => {\n  return callApi(\"/api/update-default-props\", {\n    compositionId,\n    defaultProps: NoReactInternals2.serializeJSONWithSpecialTypes({\n      data: defaultProps,\n      indent: undefined,\n      staticBase: window.remotion_staticBase\n    }).serializedString,\n    enumPaths\n  });\n};\nvar canUpdateDefaultProps = (compositionId, readOnlyStudio) => {\n  if (readOnlyStudio) {\n    return Promise.resolve({\n      canUpdate: false,\n      reason: \"Read-only studio\"\n    });\n  }\n  return callApi(\"/api/can-update-default-props\", {\n    compositionId\n  });\n};\nvar applyVisualControlChange = ({\n  fileName,\n  changes\n}) => {\n  return callApi(\"/api/apply-visual-control-change\", {\n    fileName,\n    changes\n  });\n};\n\n// src/components/AssetSelectorItem.tsx\nimport { jsx as jsx35, jsxs as jsxs9, Fragment as Fragment5 } from \"react/jsx-runtime\";\nvar ASSET_ITEM_HEIGHT = 32;\nvar iconStyle2 = {\n  width: 18,\n  height: 18,\n  flexShrink: 0\n};\nvar itemStyle2 = {\n  paddingRight: 10,\n  paddingTop: 6,\n  paddingBottom: 6,\n  fontSize: 13,\n  display: \"flex\",\n  textDecoration: \"none\",\n  cursor: \"default\",\n  alignItems: \"center\",\n  marginBottom: 1,\n  appearance: \"none\",\n  border: \"none\",\n  width: \"100%\",\n  textAlign: \"left\",\n  backgroundColor: BACKGROUND,\n  height: ASSET_ITEM_HEIGHT,\n  userSelect: \"none\",\n  WebkitUserSelect: \"none\"\n};\nvar labelStyle3 = {\n  textAlign: \"left\",\n  textDecoration: \"none\",\n  fontSize: 13,\n  flex: \"1 1 0%\",\n  whiteSpace: \"nowrap\",\n  overflow: \"hidden\",\n  textOverflow: \"ellipsis\"\n};\nvar revealIconStyle = {\n  height: 12,\n  color: \"currentColor\"\n};\nvar AssetFolderItem = ({\n  tabIndex,\n  item,\n  level,\n  parentFolder,\n  toggleFolder,\n  dropLocation,\n  setDropLocation\n}) => {\n  const [hovered, setHovered] = useState15(false);\n  const openFolderTimerRef = useRef12(null);\n  const { isDropDiv, onDragEnter, onDragLeave } = use_asset_drag_events_default({\n    name: item.name,\n    parentFolder,\n    dropLocation,\n    setDropLocation\n  });\n  const onPointerEnter = useCallback18(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback18(() => {\n    setHovered(false);\n  }, []);\n  const folderStyle = useMemo23(() => {\n    return {\n      ...itemStyle2,\n      paddingLeft: 4 + level * 8,\n      backgroundColor: hovered ? CLEAR_HOVER : \"transparent\"\n    };\n  }, [hovered, level]);\n  const label = useMemo23(() => {\n    return {\n      ...labelStyle3,\n      color: hovered ? \"white\" : LIGHT_TEXT\n    };\n  }, [hovered]);\n  const onClick = useCallback18(() => {\n    toggleFolder(item.name, parentFolder);\n  }, [item.name, parentFolder, toggleFolder]);\n  const Icon = item.expanded ? ExpandedFolderIcon : CollapsedFolderIcon;\n  return /* @__PURE__ */ jsxs9(\"div\", {\n    onDragEnter,\n    onDragLeave,\n    style: {\n      backgroundColor: isDropDiv ? CLEAR_HOVER : BACKGROUND\n    },\n    children: [\n      /* @__PURE__ */ jsx35(\"div\", {\n        style: folderStyle,\n        onPointerEnter,\n        onPointerLeave,\n        tabIndex,\n        title: item.name,\n        onClick,\n        onDragEnter: () => {\n          if (!item.expanded) {\n            openFolderTimerRef.current = window.setTimeout(() => {\n              toggleFolder(item.name, parentFolder);\n            }, 1000);\n          }\n        },\n        onDragLeave: () => {\n          if (openFolderTimerRef.current) {\n            clearTimeout(openFolderTimerRef.current);\n          }\n        },\n        children: /* @__PURE__ */ jsxs9(Row, {\n          children: [\n            /* @__PURE__ */ jsx35(Icon, {\n              style: iconStyle2,\n              color: hovered ? \"white\" : LIGHT_TEXT\n            }),\n            /* @__PURE__ */ jsx35(Spacing, {\n              x: 1\n            }),\n            /* @__PURE__ */ jsx35(\"div\", {\n              style: label,\n              children: item.name\n            })\n          ]\n        })\n      }),\n      item.expanded ? /* @__PURE__ */ jsx35(AssetFolderTree, {\n        item: item.items,\n        name: item.name,\n        level,\n        parentFolder,\n        tabIndex,\n        toggleFolder,\n        dropLocation,\n        setDropLocation\n      }, item.name) : null\n    ]\n  });\n};\nvar AssetFolderTree = ({\n  item,\n  level,\n  name,\n  parentFolder,\n  toggleFolder,\n  tabIndex,\n  dropLocation,\n  setDropLocation\n}) => {\n  const combinedParents = useMemo23(() => {\n    return [parentFolder, name].filter(NoReactInternals3.truthy).join(\"/\");\n  }, [name, parentFolder]);\n  return /* @__PURE__ */ jsxs9(\"div\", {\n    children: [\n      item.folders.map((folder) => {\n        return /* @__PURE__ */ jsx35(AssetFolderItem, {\n          item: folder,\n          tabIndex,\n          level: level + 1,\n          parentFolder: combinedParents,\n          toggleFolder,\n          dropLocation,\n          setDropLocation\n        }, folder.name);\n      }),\n      item.files.map((file) => {\n        return /* @__PURE__ */ jsx35(AssetSelectorItem, {\n          item: file,\n          tabIndex,\n          level,\n          parentFolder: combinedParents\n        }, file.src);\n      })\n    ]\n  });\n};\nvar AssetSelectorItem = ({ item, tabIndex, level, parentFolder }) => {\n  const isMobileLayout = useMobileLayout();\n  const [hovered, setHovered] = useState15(false);\n  const { setSidebarCollapsedState } = useContext10(SidebarContext);\n  const onPointerEnter = useCallback18(() => {\n    setHovered(true);\n  }, []);\n  const { setCanvasContent } = useContext10(Internals8.CompositionSetters);\n  const { canvasContent } = useContext10(Internals8.CompositionManager);\n  const selected = useMemo23(() => {\n    if (canvasContent && canvasContent.type === \"asset\") {\n      const nameWOParent = canvasContent.asset.split(\"/\").pop();\n      return nameWOParent === item.name;\n    }\n    return false;\n  }, [canvasContent, item.name]);\n  const onPointerLeave = useCallback18(() => {\n    setHovered(false);\n  }, []);\n  const onClick = useCallback18(() => {\n    const relativePath = parentFolder ? parentFolder + \"/\" + item.name : item.name;\n    setCanvasContent({ type: \"asset\", asset: relativePath });\n    pushUrl(`/assets/${relativePath}`);\n    if (isMobileLayout) {\n      setSidebarCollapsedState({ left: \"collapsed\", right: \"collapsed\" });\n    }\n  }, [\n    isMobileLayout,\n    item.name,\n    parentFolder,\n    setCanvasContent,\n    setSidebarCollapsedState\n  ]);\n  const style = useMemo23(() => {\n    return {\n      ...itemStyle2,\n      color: hovered || selected ? \"white\" : LIGHT_TEXT,\n      backgroundColor: hovered ? selected ? SELECTED_BACKGROUND : CLEAR_HOVER : selected ? SELECTED_BACKGROUND : \"transparent\",\n      paddingLeft: 12 + level * 8\n    };\n  }, [hovered, level, selected]);\n  const label = useMemo23(() => {\n    return {\n      ...labelStyle3,\n      color: hovered || selected ? \"white\" : LIGHT_TEXT\n    };\n  }, [hovered, selected]);\n  const renderFileExplorerAction = useCallback18((color) => {\n    return /* @__PURE__ */ jsx35(ExpandedFolderIcon, {\n      style: revealIconStyle,\n      color\n    });\n  }, []);\n  const renderCopyAction = useCallback18((color) => {\n    return /* @__PURE__ */ jsx35(ClipboardIcon, {\n      style: revealIconStyle,\n      color\n    });\n  }, []);\n  const revealInExplorer = React24.useCallback((e) => {\n    e.stopPropagation();\n    openInFileExplorer({\n      directory: window.remotion_publicFolderExists + \"/\" + parentFolder + \"/\" + item.name\n    }).catch((err) => {\n      showNotification(`Could not open file: ${err.message}`, 2000);\n    });\n  }, [item.name, parentFolder]);\n  const copyToClipboard = useCallback18((e) => {\n    e.stopPropagation();\n    const content = `staticFile(\"${[parentFolder, item.name].join(\"/\")}\")`;\n    copyText(content).then(() => {\n      showNotification(`Copied '${content}' to clipboard`, 1000);\n    }).catch((err) => {\n      showNotification(`Could not copy: ${err.message}`, 2000);\n    });\n  }, [item.name, parentFolder]);\n  return /* @__PURE__ */ jsx35(Row, {\n    align: \"center\",\n    children: /* @__PURE__ */ jsxs9(\"div\", {\n      style,\n      onPointerEnter,\n      onPointerLeave,\n      onClick,\n      tabIndex,\n      title: item.name,\n      children: [\n        /* @__PURE__ */ jsx35(FileIcon, {\n          style: iconStyle2,\n          color: LIGHT_TEXT\n        }),\n        /* @__PURE__ */ jsx35(Spacing, {\n          x: 1\n        }),\n        /* @__PURE__ */ jsx35(\"div\", {\n          style: label,\n          children: item.name\n        }),\n        hovered ? /* @__PURE__ */ jsxs9(Fragment5, {\n          children: [\n            /* @__PURE__ */ jsx35(Spacing, {\n              x: 0.5\n            }),\n            /* @__PURE__ */ jsx35(InlineAction, {\n              title: \"Copy staticFile() name\",\n              renderAction: renderCopyAction,\n              onClick: copyToClipboard\n            }),\n            /* @__PURE__ */ jsx35(Spacing, {\n              x: 0.5\n            }),\n            /* @__PURE__ */ jsx35(InlineAction, {\n              title: \"Open in Explorer\",\n              renderAction: renderFileExplorerAction,\n              onClick: revealInExplorer\n            })\n          ]\n        }) : null\n      ]\n    })\n  });\n};\n\n// src/components/AssetSelector.tsx\nimport { jsx as jsx36, jsxs as jsxs10 } from \"react/jsx-runtime\";\nvar container8 = {\n  display: \"flex\",\n  flexDirection: \"column\",\n  flex: 1,\n  overflow: \"hidden\",\n  backgroundColor: BACKGROUND\n};\nvar emptyState = {\n  display: \"flex\",\n  flex: 1,\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  textAlign: \"center\",\n  padding: \"0 12px\"\n};\nvar label = {\n  color: LIGHT_TEXT,\n  lineHeight: 1.5,\n  fontSize: 14\n};\nvar list = {\n  height: \"100%\",\n  overflowY: \"auto\"\n};\nvar AssetSelector = ({ readOnlyStudio }) => {\n  const { tabIndex } = useZIndex();\n  const { assetFoldersExpanded, setAssetFoldersExpanded } = useContext11(FolderContext);\n  const [dropLocation, setDropLocation] = useState16(null);\n  const { subscribeToEvent } = useContext11(StudioServerConnectionCtx);\n  const connectionStatus = useContext11(StudioServerConnectionCtx).previewServerState.type;\n  const shouldAllowUpload = connectionStatus === \"connected\" && !readOnlyStudio;\n  const [{ publicFolderExists, staticFiles }, setState] = React25.useState(() => {\n    return {\n      staticFiles: getStaticFiles(),\n      publicFolderExists: window.remotion_publicFolderExists\n    };\n  });\n  const assetTree = useMemo24(() => {\n    return buildAssetFolderStructure(staticFiles, null, assetFoldersExpanded);\n  }, [assetFoldersExpanded, staticFiles]);\n  useEffect13(() => {\n    const onUpdate = () => {\n      setState({\n        staticFiles: getStaticFiles(),\n        publicFolderExists: window.remotion_publicFolderExists\n      });\n    };\n    const unsub = subscribeToEvent(\"new-public-folder\", onUpdate);\n    return () => {\n      unsub();\n    };\n  }, [subscribeToEvent]);\n  const toggleFolder = useCallback19((folderName, parentName) => {\n    setAssetFoldersExpanded((p) => {\n      const key = [parentName, folderName].filter(Boolean).join(\"/\");\n      const prev = p[key] ?? false;\n      const foldersExpandedState = {\n        ...p,\n        [key]: !prev\n      };\n      persistExpandedFolders(\"assets\", foldersExpandedState);\n      return foldersExpandedState;\n    });\n  }, [setAssetFoldersExpanded]);\n  const { isDropDiv, onDragEnter, onDragLeave } = use_asset_drag_events_default({\n    name: null,\n    parentFolder: null,\n    dropLocation,\n    setDropLocation\n  });\n  const onDragOver = useCallback19((e) => {\n    e.preventDefault();\n  }, []);\n  const onDrop = useCallback19(async (e) => {\n    try {\n      e.preventDefault();\n      e.stopPropagation();\n      const { files } = e.dataTransfer;\n      const assetPath = dropLocation ?? null;\n      const makePath = (file) => {\n        return [assetPath, file.name].filter(Boolean).join(\"/\");\n      };\n      for (const file of files) {\n        const body = await file.arrayBuffer();\n        await writeStaticFile({\n          contents: body,\n          filePath: makePath(file)\n        });\n      }\n      if (files.length === 1) {\n        showNotification(`Created ${makePath(files[0])}`, 3000);\n      } else {\n        showNotification(`Added ${files.length} files to ${assetPath}`, 3000);\n      }\n    } catch (error) {\n      showNotification(`Error during upload: ${error}`, 3000);\n    } finally {\n      setDropLocation(null);\n    }\n  }, [dropLocation]);\n  return /* @__PURE__ */ jsx36(\"div\", {\n    style: container8,\n    onDragOver: shouldAllowUpload ? onDragOver : undefined,\n    onDrop: shouldAllowUpload ? onDrop : undefined,\n    children: staticFiles.length === 0 ? publicFolderExists ? /* @__PURE__ */ jsx36(\"div\", {\n      style: emptyState,\n      children: /* @__PURE__ */ jsxs10(\"div\", {\n        style: label,\n        children: [\n          \"To add assets, place a file in the\",\n          \" \",\n          /* @__PURE__ */ jsx36(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"public\"\n          }),\n          \" folder of your project or drag and drop a file here.\"\n        ]\n      })\n    }) : /* @__PURE__ */ jsx36(\"div\", {\n      style: emptyState,\n      children: /* @__PURE__ */ jsxs10(\"div\", {\n        style: label,\n        children: [\n          \"To add assets, create a folder called\",\n          \" \",\n          /* @__PURE__ */ jsx36(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"public\"\n          }),\n          \" in the root of your project and place a file in it.\"\n        ]\n      })\n    }) : /* @__PURE__ */ jsx36(\"div\", {\n      className: \"__remotion-vertical-scrollbar\",\n      style: {\n        ...list,\n        backgroundColor: isDropDiv ? CLEAR_HOVER : BACKGROUND\n      },\n      onDragEnter,\n      onDragLeave,\n      children: /* @__PURE__ */ jsx36(AssetFolderTree, {\n        item: assetTree,\n        level: 0,\n        parentFolder: null,\n        name: null,\n        tabIndex,\n        toggleFolder,\n        dropLocation,\n        setDropLocation\n      })\n    })\n  });\n};\n\n// src/components/CompSelectorRef.tsx\nimport {\n  useCallback as useCallback20,\n  useContext as useContext12,\n  useImperativeHandle as useImperativeHandle4,\n  useMemo as useMemo25,\n  useState as useState17\n} from \"react\";\nimport { Internals as Internals9 } from \"remotion\";\nimport { jsx as jsx37 } from \"react/jsx-runtime\";\nvar CompSelectorRef = ({ children }) => {\n  const { compositions } = useContext12(Internals9.CompositionManager);\n  const [foldersExpanded, setFoldersExpanded] = useState17(loadExpandedFolders(\"compositions\"));\n  const selectComposition = useSelectComposition();\n  const toggleFolder = useCallback20((folderName, parentName) => {\n    setFoldersExpanded((p) => {\n      const key = openFolderKey({ folderName, parentName });\n      const prev = p[key] ?? false;\n      const foldersExpandedState = {\n        ...p,\n        [key]: !prev\n      };\n      persistExpandedFolders(\"compositions\", foldersExpandedState);\n      return foldersExpandedState;\n    });\n  }, []);\n  useImperativeHandle4(Internals9.compositionSelectorRef, () => {\n    return {\n      expandComposition: (compName) => {\n        const compositionToExpand = compositions.find((c) => c.id === compName);\n        if (!compositionToExpand) {\n          return;\n        }\n        const { folderName, parentFolderName } = compositionToExpand;\n        if (folderName === null) {\n          return;\n        }\n        setFoldersExpanded((previousState) => {\n          const foldersExpandedState = {\n            ...previousState\n          };\n          const currentFolder = folderName;\n          const currentParentName = parentFolderName;\n          const key = openFolderKey({\n            folderName: currentFolder,\n            parentName: currentParentName\n          });\n          const splitted = key.split(\"/\");\n          for (let i = 0;i < splitted.length - 1; i++) {\n            const allExceptLast = i === 0 ? openFolderKey({\n              folderName: splitted.filter((s) => s !== \"no-parent\")[0],\n              parentName: null\n            }) : splitted.slice(0, i + 1).join(\"/\");\n            foldersExpandedState[allExceptLast] = true;\n          }\n          persistExpandedFolders(\"compositions\", foldersExpandedState);\n          return foldersExpandedState;\n        });\n      },\n      selectComposition: (compName) => {\n        const comp = compositions.find((c) => c.id === compName);\n        if (!comp) {\n          throw new Error(`Composition ${compName} not found`);\n        }\n        selectComposition(comp, true);\n      },\n      toggleFolder: (folderName, parentName) => {\n        toggleFolder(folderName, parentName);\n      }\n    };\n  }, [compositions, selectComposition, toggleFolder]);\n  const contextValue = useMemo25(() => {\n    return {\n      foldersExpanded,\n      setFoldersExpanded,\n      toggleFolder\n    };\n  }, [foldersExpanded, setFoldersExpanded, toggleFolder]);\n  return /* @__PURE__ */ jsx37(ExpandedFoldersContext.Provider, {\n    value: contextValue,\n    children\n  });\n};\n\n// src/components/Tabs/index.tsx\nimport { useCallback as useCallback21, useMemo as useMemo26, useState as useState18 } from \"react\";\nimport { jsx as jsx38 } from \"react/jsx-runtime\";\nvar tabsContainer = {\n  display: \"flex\",\n  flexDirection: \"row\"\n};\nvar Tabs = ({ children, style }) => {\n  const definiteStyle = useMemo26(() => {\n    return {\n      ...tabsContainer,\n      ...style\n    };\n  }, [style]);\n  return /* @__PURE__ */ jsx38(\"div\", {\n    style: definiteStyle,\n    children\n  });\n};\nvar selectorButton = {\n  border: \"none\",\n  flex: 1,\n  padding: 4,\n  height: 40,\n  paddingLeft: 16,\n  display: \"flex\",\n  flexDirection: \"row\",\n  fontSize: 14,\n  color: \"inherit\",\n  alignItems: \"center\",\n  cursor: \"default\"\n};\nvar Tab = ({ children, onClick, style, selected }) => {\n  const [hovered, setHovered] = useState18(false);\n  const { tabIndex } = useZIndex();\n  const onPointerEnter = useCallback21(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback21(() => {\n    setHovered(false);\n  }, []);\n  const definiteStyle = useMemo26(() => ({\n    ...selectorButton,\n    backgroundColor: selected ? BACKGROUND : hovered ? CLEAR_HOVER : INPUT_BACKGROUND,\n    color: selected ? \"white\" : LIGHT_TEXT,\n    borderTop: selected ? \"2px solid \" + BLUE : \"2px solid transparent\",\n    boxShadow: selected ? \"none\" : undefined,\n    ...style\n  }), [hovered, selected, style]);\n  return /* @__PURE__ */ jsx38(\"div\", {\n    style: definiteStyle,\n    role: \"button\",\n    onClick,\n    tabIndex,\n    onPointerLeave,\n    onPointerEnter,\n    children\n  });\n};\n\n// src/components/ExplorerPanel.tsx\nimport { jsx as jsx39, jsxs as jsxs11 } from \"react/jsx-runtime\";\nvar container9 = {\n  height: \"100%\",\n  width: \"100%\",\n  maxWidth: \"100%\",\n  display: \"flex\",\n  flexDirection: \"column\",\n  flex: 1\n};\nvar localStorageKey2 = \"remotion.sidebarPanel\";\nvar getSelectedPanel = () => {\n  const panel = localStorage.getItem(localStorageKey2);\n  if (panel === \"assets\") {\n    return \"assets\";\n  }\n  return \"compositions\";\n};\nvar tabsContainer2 = {\n  backgroundColor: BACKGROUND\n};\nvar persistSelectedOptionsSidebarPanel = (panel) => {\n  localStorage.setItem(localStorageKey2, panel);\n};\nvar explorerSidebarTabs = createRef5();\nvar ExplorerPanel = ({ readOnlyStudio }) => {\n  const [panel, setPanel] = useState19(() => getSelectedPanel());\n  const onCompositionsSelected = useCallback22(() => {\n    setPanel(\"compositions\");\n    persistSelectedOptionsSidebarPanel(\"compositions\");\n  }, []);\n  const onAssetsSelected = useCallback22(() => {\n    setPanel(\"assets\");\n    persistSelectedOptionsSidebarPanel(\"assets\");\n  }, []);\n  useImperativeHandle5(explorerSidebarTabs, () => {\n    return {\n      selectAssetsPanel: () => {\n        setPanel(\"assets\");\n        persistSelectedOptionsSidebarPanel(\"assets\");\n      },\n      selectCompositionPanel: () => {\n        setPanel(\"compositions\");\n        persistSelectedOptionsSidebarPanel(\"compositions\");\n      }\n    };\n  }, []);\n  return /* @__PURE__ */ jsx39(CompSelectorRef, {\n    children: /* @__PURE__ */ jsxs11(\"div\", {\n      style: container9,\n      className: \"css-reset\",\n      children: [\n        /* @__PURE__ */ jsx39(\"div\", {\n          style: tabsContainer2,\n          children: /* @__PURE__ */ jsxs11(Tabs, {\n            children: [\n              /* @__PURE__ */ jsx39(Tab, {\n                selected: panel === \"compositions\",\n                onClick: onCompositionsSelected,\n                children: \"Compositions\"\n              }),\n              /* @__PURE__ */ jsx39(Tab, {\n                selected: panel === \"assets\",\n                onClick: onAssetsSelected,\n                children: \"Assets\"\n              })\n            ]\n          })\n        }),\n        panel === \"compositions\" ? /* @__PURE__ */ jsx39(CompositionSelector, {}) : /* @__PURE__ */ jsx39(AssetSelector, {\n          readOnlyStudio\n        })\n      ]\n    })\n  });\n};\n\n// src/components/InitialCompositionLoader.tsx\nvar useSelectAsset = () => {\n  const { setCanvasContent } = useContext13(Internals10.CompositionSetters);\n  const { setAssetFoldersExpanded } = useContext13(FolderContext);\n  return (asset) => {\n    setCanvasContent({ type: \"asset\", asset });\n    explorerSidebarTabs.current?.selectAssetsPanel();\n    setAssetFoldersExpanded((ex) => {\n      const split = asset.split(\"/\");\n      const keysToExpand = split.map((_, i) => {\n        return split.slice(0, i).join(\"/\");\n      });\n      const newState = {\n        ...ex\n      };\n      for (const key of keysToExpand) {\n        newState[key] = true;\n      }\n      return newState;\n    });\n  };\n};\nvar useSelectComposition = () => {\n  const { setCompositionFoldersExpanded } = useContext13(FolderContext);\n  const { setCanvasContent } = useContext13(Internals10.CompositionSetters);\n  const isMobileLayout = useMobileLayout();\n  const { setSidebarCollapsedState } = useContext13(SidebarContext);\n  return useCallback23((c, push) => {\n    if (push) {\n      pushUrl(`/${c.id}`);\n    }\n    explorerSidebarTabs.current?.selectCompositionPanel();\n    setCanvasContent({ type: \"composition\", compositionId: c.id });\n    const { folderName, parentFolderName } = c;\n    if (folderName !== null) {\n      setCompositionFoldersExpanded((ex) => {\n        const keysToExpand = getKeysToExpand(folderName, parentFolderName);\n        const newState = {\n          ...ex\n        };\n        for (const key of keysToExpand) {\n          newState[key] = true;\n        }\n        return newState;\n      });\n      if (isMobileLayout) {\n        setSidebarCollapsedState({ left: \"collapsed\", right: \"collapsed\" });\n      }\n    }\n  }, [\n    isMobileLayout,\n    setCanvasContent,\n    setCompositionFoldersExpanded,\n    setSidebarCollapsedState\n  ]);\n};\nvar InitialCompositionLoader = () => {\n  const { compositions, canvasContent } = useContext13(Internals10.CompositionManager);\n  const { setCanvasContent } = useContext13(Internals10.CompositionSetters);\n  const selectComposition = useSelectComposition();\n  const selectAsset = useSelectAsset();\n  useEffect14(() => {\n    if (canvasContent) {\n      return;\n    }\n    const canvasContentFromUrl = deriveCanvasContentFromUrl();\n    if (canvasContentFromUrl && canvasContentFromUrl.type === \"composition\") {\n      const exists = compositions.find((c) => c.id === canvasContentFromUrl.compositionId);\n      if (exists) {\n        selectComposition(exists, false);\n      }\n      return;\n    }\n    if (canvasContentFromUrl && canvasContentFromUrl.type === \"asset\") {\n      selectAsset(canvasContentFromUrl.asset);\n      return;\n    }\n    if (canvasContentFromUrl && canvasContentFromUrl.type === \"output\") {\n      setCanvasContent(canvasContentFromUrl);\n      return;\n    }\n    if (compositions.length > 0) {\n      selectComposition(compositions[0], true);\n    }\n  }, [\n    compositions,\n    canvasContent,\n    selectComposition,\n    setCanvasContent,\n    selectAsset\n  ]);\n  useEffect14(() => {\n    const onchange = () => {\n      const newCanvas = deriveCanvasContentFromUrl();\n      if (newCanvas && newCanvas.type === \"composition\") {\n        const newComp = getRoute().substring(1);\n        const exists = compositions.find((c) => c.id === newComp);\n        if (exists) {\n          selectComposition(exists, false);\n        }\n        return;\n      }\n      if (newCanvas && newCanvas.type === \"asset\") {\n        const staticFiles = getStaticFiles();\n        const exists = staticFiles.find((file) => {\n          return file.name === newCanvas.asset;\n        });\n        if (exists) {\n          setCanvasContent(newCanvas);\n        }\n        return;\n      }\n      setCanvasContent(newCanvas);\n    };\n    window.addEventListener(\"popstate\", onchange);\n    return () => window.removeEventListener(\"popstate\", onchange);\n  }, [compositions, selectComposition, setCanvasContent]);\n  return null;\n};\n\n// src/components/MenuToolbar.tsx\nimport { useCallback as useCallback93, useMemo as useMemo98, useState as useState64 } from \"react\";\n\n// src/helpers/use-menu-structure.tsx\nimport { useContext as useContext20, useMemo as useMemo37 } from \"react\";\nimport { Internals as Internals15 } from \"remotion\";\nimport { NoReactInternals as NoReactInternals5 } from \"remotion/no-react\";\n\n// src/api/restart-studio.ts\nimport { getRemotionEnvironment } from \"remotion\";\nvar restartStudio = () => {\n  if (!getRemotionEnvironment().isStudio) {\n    throw new Error(\"restartStudio() is only available in the Studio\");\n  }\n  if (window.remotion_isReadOnlyStudio) {\n    throw new Error(\"restartStudio() is not available in read-only Studio\");\n  }\n  return callApi(\"/api/restart-studio\", {});\n};\n\n// src/components/AskAiModal.tsx\nimport {\n  createRef as createRef6,\n  useCallback as useCallback25,\n  useEffect as useEffect15,\n  useImperativeHandle as useImperativeHandle6,\n  useRef as useRef13,\n  useState as useState20\n} from \"react\";\nimport { AbsoluteFill } from \"remotion\";\n\n// src/components/ModalContainer.tsx\nimport { jsx as jsx40 } from \"react/jsx-runtime\";\nvar padding = 20;\nvar getMaxModalWidth = (width) => {\n  return `min(calc(100vw - ${padding * 2}px), calc(${width}px - ${padding * 2}px))`;\n};\nvar getMaxModalHeight = (height) => {\n  return `min(calc(100vh - ${padding * 2}px), calc(${height}px - ${padding * 2}px))`;\n};\nvar backgroundOverlay = {\n  backgroundColor: \"rgba(255, 255, 255, 0.2)\",\n  backdropFilter: `blur(1px)`,\n  position: \"fixed\",\n  height: \"100%\",\n  width: \"100%\",\n  display: \"flex\",\n  padding\n};\nvar panel = {\n  backgroundColor: BACKGROUND,\n  boxShadow: \"0 0 4px black\",\n  color: \"white\",\n  margin: \"auto\"\n};\nvar ModalContainer = ({ children, onEscape, onOutsideClick, noZIndex }) => {\n  return /* @__PURE__ */ jsx40(\"div\", {\n    className: \"css-reset\",\n    style: backgroundOverlay,\n    role: \"dialog\",\n    \"aria-modal\": \"true\",\n    children: /* @__PURE__ */ jsx40(HigherZIndex, {\n      disabled: noZIndex,\n      onOutsideClick,\n      onEscape,\n      children: /* @__PURE__ */ jsx40(\"div\", {\n        style: panel,\n        children\n      })\n    })\n  });\n};\n\n// src/components/ModalHeader.tsx\nimport { useCallback as useCallback24, useContext as useContext14 } from \"react\";\n\n// src/components/NewComposition/CancelButton.tsx\nimport { jsx as jsx41 } from \"react/jsx-runtime\";\nvar style = {\n  appearance: \"none\",\n  border: \"none\",\n  backgroundColor: \"transparent\",\n  color: \"white\",\n  cursor: \"pointer\",\n  display: \"inline-flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\"\n};\nvar CancelButton = ({ onPress, ...props }) => {\n  const { tabIndex } = useZIndex();\n  return /* @__PURE__ */ jsx41(\"button\", {\n    tabIndex,\n    style,\n    type: \"button\",\n    onClick: onPress,\n    children: /* @__PURE__ */ jsx41(\"svg\", {\n      viewBox: \"0 0 320 512\",\n      ...props,\n      children: /* @__PURE__ */ jsx41(\"path\", {\n        fill: \"currentColor\",\n        d: \"M207.6 256l107.72-107.72c6.23-6.23 6.23-16.34 0-22.58l-25.03-25.03c-6.23-6.23-16.34-6.23-22.58 0L160 208.4 52.28 100.68c-6.23-6.23-16.34-6.23-22.58 0L4.68 125.7c-6.23 6.23-6.23 16.34 0 22.58L112.4 256 4.68 363.72c-6.23 6.23-6.23 16.34 0 22.58l25.03 25.03c6.23 6.23 16.34 6.23 22.58 0L160 303.6l107.72 107.72c6.23 6.23 16.34 6.23 22.58 0l25.03-25.03c6.23-6.23 6.23-16.34 0-22.58L207.6 256z\"\n      })\n    })\n  });\n};\n\n// src/components/ModalHeader.tsx\nimport { jsx as jsx42, jsxs as jsxs12 } from \"react/jsx-runtime\";\nvar container10 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  padding: \"12px 16px\",\n  width: \"100%\",\n  borderBottom: \"1px solid black\"\n};\nvar titleStyle = {\n  fontSize: 14,\n  color: \"white\"\n};\nvar icon = {\n  height: 20,\n  width: 20\n};\nvar ModalHeader = ({ title: title2, onClose }) => {\n  const { setSelectedModal } = useContext14(ModalsContext);\n  const onPress = useCallback24(() => {\n    setSelectedModal(null);\n  }, [setSelectedModal]);\n  return /* @__PURE__ */ jsxs12(\"div\", {\n    style: container10,\n    children: [\n      /* @__PURE__ */ jsx42(\"div\", {\n        style: titleStyle,\n        children: title2\n      }),\n      /* @__PURE__ */ jsx42(Flex, {}),\n      /* @__PURE__ */ jsx42(CancelButton, {\n        style: icon,\n        onPress: onClose ?? onPress\n      })\n    ]\n  });\n};\n\n// src/components/AskAiModal.tsx\nimport { jsx as jsx43, jsxs as jsxs13 } from \"react/jsx-runtime\";\nvar container11 = {\n  height: \"calc(100vh - 100px)\",\n  width: \"calc(100vw - 160px)\",\n  maxWidth: 800,\n  maxHeight: 900,\n  display: \"block\"\n};\nvar askAiModalRef = createRef6();\nvar AskAiModal = () => {\n  const [state, setState] = useState20(\"never-opened\");\n  const iframe = useRef13(null);\n  useImperativeHandle6(askAiModalRef, () => ({\n    toggle: () => {\n      setState((s) => {\n        if (s === \"visible\") {\n          iframe.current?.blur();\n          iframe.current?.contentWindow?.blur();\n        }\n        return s === \"visible\" ? \"hidden\" : \"visible\";\n      });\n    }\n  }), []);\n  useEffect15(() => {\n    const onMessage = (event) => {\n      try {\n        const json = typeof event.data === \"string\" ? JSON.parse(event.data) : event.data;\n        if (json.type === \"cmd-i\") {\n          askAiModalRef.current?.toggle();\n        }\n      } catch {}\n    };\n    window.addEventListener(\"message\", onMessage);\n    return () => {\n      window.removeEventListener(\"message\", onMessage);\n    };\n  }, []);\n  const onQuit = useCallback25(() => {\n    setState(\"hidden\");\n  }, [setState]);\n  useEffect15(() => {\n    if (!iframe.current) {\n      return;\n    }\n    if (state === \"visible\") {\n      iframe.current.contentWindow?.postMessage({\n        type: \"focus\"\n      }, \"*\");\n    }\n  }, [state]);\n  if (state === \"never-opened\") {\n    return null;\n  }\n  return /* @__PURE__ */ jsx43(AbsoluteFill, {\n    style: { display: state === \"visible\" ? \"block\" : \"none\" },\n    children: /* @__PURE__ */ jsxs13(ModalContainer, {\n      noZIndex: state === \"hidden\",\n      onOutsideClick: onQuit,\n      onEscape: onQuit,\n      children: [\n        /* @__PURE__ */ jsx43(ModalHeader, {\n          title: \"Ask AI\",\n          onClose: onQuit\n        }),\n        /* @__PURE__ */ jsx43(\"iframe\", {\n          ref: iframe,\n          frameBorder: 0,\n          style: container11,\n          src: \"https://www.remotion.dev/ai-embed\",\n          allow: \"clipboard-read; clipboard-write\"\n        })\n      ]\n    })\n  });\n};\n\n// src/components/SizeSelector.tsx\nimport { useContext as useContext18, useMemo as useMemo33 } from \"react\";\nimport { Internals as Internals12 } from \"remotion\";\n\n// src/icons/Checkmark.tsx\nimport { jsx as jsx44 } from \"react/jsx-runtime\";\nvar style2 = {\n  width: 14,\n  height: 14\n};\nvar Checkmark = () => /* @__PURE__ */ jsx44(\"svg\", {\n  focusable: \"false\",\n  role: \"img\",\n  viewBox: \"0 0 512 512\",\n  style: style2,\n  children: /* @__PURE__ */ jsx44(\"path\", {\n    fill: \"currentColor\",\n    d: \"M435.848 83.466L172.804 346.51l-96.652-96.652c-4.686-4.686-12.284-4.686-16.971 0l-28.284 28.284c-4.686 4.686-4.686 12.284 0 16.971l133.421 133.421c4.686 4.686 12.284 4.686 16.971 0l299.813-299.813c4.686-4.686 4.686-12.284 0-16.971l-28.284-28.284c-4.686-4.686-12.284-4.686-16.97 0z\"\n  })\n});\n\n// src/components/ControlButton.tsx\nimport { useMemo as useMemo27 } from \"react\";\nimport { jsx as jsx45 } from \"react/jsx-runtime\";\nvar CONTROL_BUTTON_PADDING = 6;\nvar ControlButton = (props) => {\n  const style3 = useMemo27(() => {\n    return {\n      opacity: props.disabled ? 0.5 : 1,\n      display: \"inline-flex\",\n      background: \"none\",\n      border: \"none\",\n      padding: CONTROL_BUTTON_PADDING\n    };\n  }, [props.disabled]);\n  const { tabIndex } = useZIndex();\n  return /* @__PURE__ */ jsx45(\"button\", {\n    type: \"button\",\n    tabIndex,\n    ...props,\n    style: style3\n  });\n};\n\n// src/components/NewComposition/ComboBox.tsx\nimport { PlayerInternals as PlayerInternals5 } from \"@remotion/player\";\nimport { useCallback as useCallback26, useEffect as useEffect16, useMemo as useMemo28, useRef as useRef14, useState as useState21 } from \"react\";\nimport ReactDOM4 from \"react-dom\";\nimport { jsx as jsx46, jsxs as jsxs14, Fragment as Fragment6 } from \"react/jsx-runtime\";\nvar container12 = {\n  padding: \"8px 10px\",\n  display: \"inline-block\",\n  backgroundColor: INPUT_BACKGROUND,\n  borderWidth: 1,\n  borderStyle: \"solid\",\n  maxWidth: \"100%\"\n};\nvar label2 = {\n  flex: 1,\n  overflow: \"hidden\",\n  textOverflow: \"ellipsis\",\n  fontSize: 14,\n  textAlign: \"left\"\n};\nvar Combobox = ({ values, selectedId, style: customStyle, title: title2 }) => {\n  const [hovered, setIsHovered] = useState21(false);\n  const [opened, setOpened] = useState21(false);\n  const ref = useRef14(null);\n  const { tabIndex, currentZIndex } = useZIndex();\n  const size = PlayerInternals5.useElementSize(ref, {\n    triggerOnWindowResize: true,\n    shouldApplyCssTransforms: true\n  });\n  const refresh = size?.refresh;\n  const onHide = useCallback26(() => {\n    setOpened(false);\n  }, []);\n  useEffect16(() => {\n    const { current } = ref;\n    if (!current) {\n      return;\n    }\n    const onMouseEnter = () => setIsHovered(true);\n    const onMouseLeave = () => setIsHovered(false);\n    const onPointerDown = () => {\n      return setOpened((o) => {\n        if (!o) {\n          refresh?.();\n        }\n        return !o;\n      });\n    };\n    const onClick = (e) => {\n      e.stopPropagation();\n      const isKeyboardInitiated = e.detail === 0;\n      if (!isKeyboardInitiated) {\n        return;\n      }\n      return setOpened((o) => {\n        if (!o) {\n          refresh?.();\n          window.addEventListener(\"pointerup\", (evt) => {\n            if (!isMenuItem(evt.target)) {\n              setOpened(false);\n            }\n          }, {\n            once: true\n          });\n        }\n        return !o;\n      });\n    };\n    current.addEventListener(\"mouseenter\", onMouseEnter);\n    current.addEventListener(\"mouseleave\", onMouseLeave);\n    current.addEventListener(\"pointerdown\", onPointerDown);\n    current.addEventListener(\"click\", onClick);\n    return () => {\n      current.removeEventListener(\"mouseenter\", onMouseEnter);\n      current.removeEventListener(\"mouseleave\", onMouseLeave);\n      current.removeEventListener(\"pointerdown\", onPointerDown);\n      current.removeEventListener(\"click\", onClick);\n    };\n  }, [refresh]);\n  const spaceToBottom = useMemo28(() => {\n    const margin2 = 10;\n    if (size && opened) {\n      return size.windowSize.height - (size.top + size.height) - margin2;\n    }\n    return 0;\n  }, [opened, size]);\n  const spaceToTop = useMemo28(() => {\n    const margin2 = 10;\n    if (size && opened) {\n      return size.top - margin2;\n    }\n    return 0;\n  }, [opened, size]);\n  const derivedMaxHeight = useMemo28(() => {\n    return spaceToTop > spaceToBottom ? spaceToTop : spaceToBottom;\n  }, [spaceToBottom, spaceToTop]);\n  const isMobileLayout = useMobileLayout();\n  const portalStyle = useMemo28(() => {\n    if (!opened || !size) {\n      return null;\n    }\n    const spaceToRight = size.windowSize.width - size.left;\n    const spaceToLeft = size.left + size.width;\n    const minSpaceRequired = isMobileLayout ? MAX_MOBILE_MENU_WIDTH : MAX_MENU_WIDTH;\n    const verticalLayout = spaceToTop > spaceToBottom ? \"bottom\" : \"top\";\n    const canOpenOnLeft = spaceToLeft >= minSpaceRequired;\n    const canOpenOnRight = spaceToRight >= minSpaceRequired;\n    const horizontalLayout = canOpenOnRight ? \"left\" : \"right\";\n    return {\n      ...verticalLayout === \"top\" ? {\n        ...menuContainerTowardsBottom,\n        top: size.top + size.height\n      } : {\n        ...menuContainerTowardsTop,\n        bottom: size.windowSize.height - size.top\n      },\n      ...horizontalLayout === \"left\" ? {\n        left: size.left\n      } : canOpenOnLeft ? {\n        right: size.windowSize.width - size.left - size.width\n      } : { left: 0 }\n    };\n  }, [isMobileLayout, opened, size, spaceToBottom, spaceToTop]);\n  const selected = values.find((v) => v.id === selectedId);\n  const style3 = useMemo28(() => {\n    return {\n      ...container12,\n      ...customStyle ?? {},\n      userSelect: \"none\",\n      WebkitUserSelect: \"none\",\n      color: \"white\",\n      display: \"inline-flex\",\n      flexDirection: \"row\",\n      alignItems: \"center\",\n      borderColor: opened ? SELECTED_BACKGROUND : hovered ? INPUT_BORDER_COLOR_HOVERED : INPUT_BORDER_COLOR_UNHOVERED\n    };\n  }, [customStyle, hovered, opened]);\n  return /* @__PURE__ */ jsxs14(Fragment6, {\n    children: [\n      /* @__PURE__ */ jsxs14(\"button\", {\n        ref,\n        title: title2,\n        tabIndex,\n        type: \"button\",\n        style: style3,\n        className: MENU_INITIATOR_CLASSNAME,\n        children: [\n          selected ? /* @__PURE__ */ jsx46(\"div\", {\n            title: typeof selected.label === \"string\" ? selected.label : undefined,\n            style: label2,\n            children: selected?.label\n          }) : null,\n          /* @__PURE__ */ jsx46(Spacing, {\n            x: 1\n          }),\n          \" \",\n          /* @__PURE__ */ jsx46(CaretDown, {})\n        ]\n      }),\n      portalStyle ? ReactDOM4.createPortal(/* @__PURE__ */ jsx46(\"div\", {\n        style: fullScreenOverlay,\n        children: /* @__PURE__ */ jsx46(\"div\", {\n          style: outerPortal,\n          className: \"css-reset\",\n          children: /* @__PURE__ */ jsx46(HigherZIndex, {\n            onOutsideClick: onHide,\n            onEscape: onHide,\n            children: /* @__PURE__ */ jsx46(\"div\", {\n              style: portalStyle,\n              children: /* @__PURE__ */ jsx46(MenuContent, {\n                onNextMenu: noop,\n                onPreviousMenu: noop,\n                values,\n                onHide,\n                leaveLeftSpace: true,\n                preselectIndex: values.findIndex((v) => selected && v.id === selected.id),\n                topItemCanBeUnselected: false,\n                fixedHeight: derivedMaxHeight\n              })\n            })\n          })\n        })\n      }), getPortal(currentZIndex)) : null\n    ]\n  });\n};\n\n// src/components/Preview.tsx\nimport { PlayerInternals as PlayerInternals6 } from \"@remotion/player\";\nimport { useContext as useContext17, useEffect as useEffect22, useMemo as useMemo32, useRef as useRef17 } from \"react\";\nimport { Internals as Internals11 } from \"remotion\";\n\n// src/helpers/checkerboard-background.ts\nvar getCheckerboardBackgroundSize = (size) => `${size}px ${size}px`;\nvar getCheckerboardBackgroundPos = (size) => `0 0, ${size / 2}px 0, ${size / 2}px -${size / 2}px, 0px ${size / 2}px`;\nvar checkerboardBackgroundColor = (checkerboard) => {\n  if (checkerboard) {\n    return \"white\";\n  }\n  return \"black\";\n};\nvar checkerboardBackgroundImage = (checkerboard) => {\n  if (checkerboard) {\n    return `\n     linear-gradient(\n        45deg,\n        rgba(0, 0, 0, 0.1) 25%,\n        transparent 25%\n      ),\n      linear-gradient(135deg, rgba(0, 0, 0, 0.1) 25%, transparent 25%),\n      linear-gradient(45deg, transparent 75%, rgba(0, 0, 0, 0.1) 75%),\n      linear-gradient(135deg, transparent 75%, rgba(0, 0, 0, 0.1) 75%)\n    `;\n  }\n  return;\n};\n\n// src/state/checkerboard.ts\nimport { createContext as createContext10 } from \"react\";\nvar persistCheckerboardOption = (option) => {\n  localStorage.setItem(\"option\", String(option));\n};\nvar loadCheckerboardOption = () => {\n  const item = localStorage.getItem(\"option\");\n  return item !== \"false\";\n};\nvar CheckerboardContext = createContext10({\n  checkerboard: loadCheckerboardOption(),\n  setCheckerboard: () => {\n    return;\n  }\n});\n\n// src/components/RenderPreview.tsx\nimport { useContext as useContext15, useEffect as useEffect21, useState as useState26 } from \"react\";\n\n// src/helpers/get-asset-metadata.ts\nimport { getVideoMetadata } from \"@remotion/media-utils\";\nimport { staticFile } from \"remotion\";\nvar remotion_outputsBase = window.remotion_staticBase.replace(\"static\", \"outputs\");\nvar getSrcFromCanvasContent = (canvasContent) => {\n  if (canvasContent.type === \"asset\") {\n    return staticFile(canvasContent.asset);\n  }\n  return remotion_outputsBase + canvasContent.path;\n};\nvar getAssetMetadata = async (canvasContent, addTime) => {\n  if (canvasContent.type === \"output-blob\") {\n    return {\n      type: \"found\",\n      size: canvasContent.sizeInBytes,\n      dimensions: { width: canvasContent.width, height: canvasContent.height },\n      fetchedAt: Date.now()\n    };\n  }\n  if (canvasContent.type === \"composition\") {\n    throw new Error(\"cannot get dimensions for composition\");\n  }\n  const src = getSrcFromCanvasContent(canvasContent);\n  const file = await fetch(src, {\n    method: \"HEAD\"\n  });\n  if (file.status === 404) {\n    return { type: \"not-found\" };\n  }\n  if (file.status !== 200) {\n    throw new Error(`Expected status code 200 or 404 for file, got ${file.status}`);\n  }\n  const size = file.headers.get(\"content-length\");\n  if (!size) {\n    throw new Error(\"Unexpected error: content-length is null\");\n  }\n  const fetchedAt = Date.now();\n  const srcWithTime = addTime ? `${src}?date=${fetchedAt}` : src;\n  const fileType = getPreviewFileType(src);\n  if (fileType === \"video\") {\n    const resolution = await getVideoMetadata(srcWithTime);\n    return {\n      type: \"found\",\n      size: Number(size),\n      dimensions: { width: resolution.width, height: resolution.height },\n      fetchedAt\n    };\n  }\n  if (fileType === \"image\") {\n    const resolution = await new Promise((resolve, reject) => {\n      const img = new Image;\n      img.onload = () => {\n        resolve({\n          type: \"found\",\n          size: Number(size),\n          dimensions: { width: img.width, height: img.height },\n          fetchedAt\n        });\n      };\n      img.onerror = () => {\n        reject(new Error(\"Failed to load image\"));\n      };\n      img.src = srcWithTime;\n    });\n    return resolution;\n  }\n  return {\n    type: \"found\",\n    dimensions: \"none\",\n    size: Number(size),\n    fetchedAt\n  };\n};\n\n// src/components/FilePreview.tsx\nimport { formatBytes } from \"@remotion/studio-shared\";\n\n// src/components/JSONViewer.tsx\nimport { useEffect as useEffect19, useState as useState24 } from \"react\";\n\n// src/components/NewComposition/RemTextarea.tsx\nimport {\n  forwardRef as forwardRef2,\n  useEffect as useEffect18,\n  useImperativeHandle as useImperativeHandle8,\n  useMemo as useMemo30,\n  useRef as useRef16,\n  useState as useState23\n} from \"react\";\n\n// src/components/NewComposition/RemInput.tsx\nimport {\n  forwardRef,\n  useEffect as useEffect17,\n  useImperativeHandle as useImperativeHandle7,\n  useMemo as useMemo29,\n  useRef as useRef15,\n  useState as useState22\n} from \"react\";\nimport { jsx as jsx47 } from \"react/jsx-runtime\";\nvar INPUT_HORIZONTAL_PADDING = 8;\nvar aligner = {\n  marginRight: -INPUT_HORIZONTAL_PADDING\n};\nvar RightAlignInput = ({ children }) => {\n  return /* @__PURE__ */ jsx47(\"div\", {\n    style: aligner,\n    children\n  });\n};\nvar inputBaseStyle = {\n  padding: `${INPUT_HORIZONTAL_PADDING}px 10px`,\n  color: \"white\",\n  borderStyle: \"solid\",\n  borderWidth: 1,\n  fontSize: 14\n};\nvar getInputBorderColor = ({\n  status,\n  isFocused,\n  isHovered\n}) => status === \"warning\" ? WARNING_COLOR : status === \"error\" ? FAIL_COLOR : isFocused ? SELECTED_BACKGROUND : isHovered ? INPUT_BORDER_COLOR_HOVERED : INPUT_BORDER_COLOR_UNHOVERED;\nvar RemInputForwardRef = ({ status, rightAlign, ...props }, ref) => {\n  const [isFocused, setIsFocused] = useState22(false);\n  const [isHovered, setIsHovered] = useState22(false);\n  const inputRef = useRef15(null);\n  const { tabIndex } = useZIndex();\n  const style3 = useMemo29(() => {\n    return {\n      backgroundColor: INPUT_BACKGROUND,\n      ...inputBaseStyle,\n      width: \"100%\",\n      borderColor: getInputBorderColor({ isFocused, isHovered, status }),\n      textAlign: rightAlign ? \"right\" : \"left\",\n      ...props.style ?? {}\n    };\n  }, [isFocused, isHovered, rightAlign, props.style, status]);\n  useImperativeHandle7(ref, () => {\n    return inputRef.current;\n  }, []);\n  useEffect17(() => {\n    if (!inputRef.current) {\n      return;\n    }\n    const { current } = inputRef;\n    const onFocus = () => setIsFocused(true);\n    const onBlur = () => setIsFocused(false);\n    const onMouseEnter = () => setIsHovered(true);\n    const onMouseLeave = () => setIsHovered(false);\n    current.addEventListener(\"focus\", onFocus);\n    current.addEventListener(\"blur\", onBlur);\n    current.addEventListener(\"mouseenter\", onMouseEnter);\n    current.addEventListener(\"mouseleave\", onMouseLeave);\n    return () => {\n      current.removeEventListener(\"focus\", onFocus);\n      current.removeEventListener(\"blur\", onBlur);\n      current.removeEventListener(\"mouseenter\", onMouseEnter);\n      current.removeEventListener(\"mouseleave\", onMouseLeave);\n    };\n  }, [inputRef]);\n  return /* @__PURE__ */ jsx47(\"input\", {\n    ref: inputRef,\n    tabIndex,\n    ...props,\n    style: style3\n  });\n};\nvar RemotionInput = forwardRef(RemInputForwardRef);\n\n// src/components/NewComposition/RemTextarea.tsx\nimport { jsx as jsx48 } from \"react/jsx-runtime\";\nvar inputBaseStyle2 = {\n  padding: `${INPUT_HORIZONTAL_PADDING}px 10px`,\n  color: \"white\",\n  borderStyle: \"solid\",\n  borderWidth: 1,\n  fontSize: 14,\n  resize: \"none\",\n  overflowX: \"hidden\"\n};\nvar RemTextareaFRFunction = ({ status, ...props }, ref) => {\n  const [isFocused, setIsFocused] = useState23(false);\n  const [isHovered, setIsHovered] = useState23(false);\n  const inputRef = useRef16(null);\n  const { tabIndex } = useZIndex();\n  useImperativeHandle8(ref, () => {\n    return inputRef.current;\n  }, []);\n  const style3 = useMemo30(() => {\n    return {\n      backgroundColor: INPUT_BACKGROUND,\n      ...inputBaseStyle2,\n      width: \"100%\",\n      borderColor: getInputBorderColor({ isFocused, isHovered, status }),\n      ...props.style ?? {}\n    };\n  }, [isFocused, isHovered, props.style, status]);\n  useEffect18(() => {\n    if (!inputRef.current) {\n      return;\n    }\n    const { current } = inputRef;\n    const onFocus = () => setIsFocused(true);\n    const onBlur = () => setIsFocused(false);\n    const onMouseEnter = () => setIsHovered(true);\n    const onMouseLeave = () => setIsHovered(false);\n    const onKeyDown = (e) => {\n      if (!inputRef.current) {\n        return;\n      }\n      if (inputRef.current !== document.activeElement) {\n        return;\n      }\n      if (e.code === \"Tab\") {\n        e.preventDefault();\n        document.execCommand(\"insertText\", false, \" \".repeat(2));\n      }\n      if (e.code === \"Enter\") {\n        e.preventDefault();\n        const { selectionStart, selectionEnd, value } = inputRef.current;\n        if (selectionStart !== selectionEnd) {\n          return;\n        }\n        let prevNewline = selectionStart;\n        for (let i = selectionStart - 1;i >= 0; i--) {\n          if (value[i] === `\n`) {\n            break;\n          }\n          prevNewline = i;\n        }\n        const currentLine = value.substring(prevNewline, selectionStart);\n        const trimmed = currentLine.trim();\n        const difference = currentLine.length - trimmed.length;\n        document.execCommand(\"insertText\", false, `\n` + \" \".repeat(difference));\n      }\n    };\n    current.addEventListener(\"focus\", onFocus);\n    current.addEventListener(\"blur\", onBlur);\n    current.addEventListener(\"mouseenter\", onMouseEnter);\n    current.addEventListener(\"mouseleave\", onMouseLeave);\n    current.addEventListener(\"keydown\", onKeyDown);\n    return () => {\n      current.removeEventListener(\"focus\", onFocus);\n      current.removeEventListener(\"blur\", onBlur);\n      current.removeEventListener(\"mouseenter\", onMouseEnter);\n      current.removeEventListener(\"mouseleave\", onMouseLeave);\n      current.removeEventListener(\"keydown\", onKeyDown);\n    };\n  }, [inputRef]);\n  return /* @__PURE__ */ jsx48(\"textarea\", {\n    ref: inputRef,\n    tabIndex,\n    ...props,\n    className: VERTICAL_SCROLLBAR_CLASSNAME,\n    style: style3\n  });\n};\nvar RemTextarea = forwardRef2(RemTextareaFRFunction);\n\n// src/components/JSONViewer.tsx\nimport { jsx as jsx49 } from \"react/jsx-runtime\";\nvar jsonStyle = {\n  marginTop: 14,\n  marginBottom: 14,\n  fontFamily: \"monospace\",\n  flex: 1\n};\nvar JSONViewer = ({ src }) => {\n  const [json, setJson] = useState24(null);\n  useEffect19(() => {\n    fetch(src).then((res) => res.json()).then((jsonRes) => {\n      setJson(JSON.stringify(jsonRes, null, 2));\n    });\n  }, [src]);\n  return /* @__PURE__ */ jsx49(RemTextarea, {\n    value: json ?? undefined,\n    status: \"ok\",\n    onChange: () => {\n      return null;\n    },\n    style: jsonStyle\n  });\n};\n\n// src/components/TextViewer.tsx\nimport { useEffect as useEffect20, useState as useState25 } from \"react\";\nimport { jsxs as jsxs15 } from \"react/jsx-runtime\";\nvar textStyle = {\n  margin: 14,\n  fontFamily: \"monospace\",\n  flex: 1,\n  color: \"white\",\n  whiteSpace: \"pre-wrap\"\n};\nvar TextViewer = ({ src }) => {\n  const [txt, setTxt] = useState25(\"\");\n  useEffect20(() => {\n    fetch(src).then(async (res) => {\n      if (!res.ok || !res.body) {\n        return;\n      }\n      const text = await res.text();\n      setTxt(text);\n    });\n  }, [src]);\n  return /* @__PURE__ */ jsxs15(\"div\", {\n    style: textStyle,\n    children: [\n      txt,\n      \" \"\n    ]\n  });\n};\n\n// src/components/FilePreview.tsx\nimport { jsx as jsx50, jsxs as jsxs16, Fragment as Fragment7 } from \"react/jsx-runtime\";\nvar msgStyle = {\n  fontSize: 13,\n  color: \"white\",\n  fontFamily: \"sans-serif\",\n  display: \"flex\",\n  justifyContent: \"center\"\n};\nvar FilePreview = ({ fileType, src, currentAsset, assetMetadata }) => {\n  if (!assetMetadata) {\n    throw new Error(\"expected to have assetMetadata\");\n  }\n  if (assetMetadata.type === \"not-found\") {\n    throw new Error('expected to have assetMetadata, got \"not-found\"');\n  }\n  if (fileType === \"audio\") {\n    return /* @__PURE__ */ jsx50(\"audio\", {\n      src,\n      controls: true\n    });\n  }\n  if (fileType === \"video\") {\n    return /* @__PURE__ */ jsx50(\"video\", {\n      src,\n      controls: true\n    });\n  }\n  if (fileType === \"image\") {\n    return /* @__PURE__ */ jsx50(\"img\", {\n      src\n    });\n  }\n  if (fileType === \"json\") {\n    return /* @__PURE__ */ jsx50(JSONViewer, {\n      src\n    });\n  }\n  if (fileType === \"txt\") {\n    return /* @__PURE__ */ jsx50(TextViewer, {\n      src\n    });\n  }\n  return /* @__PURE__ */ jsxs16(Fragment7, {\n    children: [\n      /* @__PURE__ */ jsx50(\"div\", {\n        style: msgStyle,\n        children: currentAsset\n      }),\n      /* @__PURE__ */ jsx50(Spacing, {\n        y: 0.5\n      }),\n      /* @__PURE__ */ jsxs16(\"div\", {\n        style: msgStyle,\n        children: [\n          \"Size: \",\n          formatBytes(assetMetadata.size),\n          \" \"\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderPreview.tsx\nimport { jsx as jsx51, jsxs as jsxs17 } from \"react/jsx-runtime\";\nvar msgStyle2 = {\n  fontSize: 13,\n  color: \"white\",\n  fontFamily: \"sans-serif\",\n  display: \"flex\",\n  justifyContent: \"center\"\n};\nvar errMsgStyle = {\n  ...msgStyle2,\n  color: LIGHT_TEXT\n};\nvar RenderPreview = ({ path, assetMetadata, getBlob }) => {\n  const fileType = getPreviewFileType(path);\n  const connectionStatus = useContext15(StudioServerConnectionCtx).previewServerState.type;\n  const [blobUrl, setBlobUrl] = useState26(null);\n  const [blobError, setBlobError] = useState26(null);\n  useEffect21(() => {\n    if (!getBlob) {\n      setBlobUrl(null);\n      setBlobError(null);\n      return;\n    }\n    let cancelled = false;\n    let blobUrlToRevoke = null;\n    setBlobError(null);\n    getBlob().then((blob) => {\n      const url = URL.createObjectURL(blob);\n      if (cancelled) {\n        URL.revokeObjectURL(url);\n        return;\n      }\n      blobUrlToRevoke = url;\n      setBlobUrl(url);\n    }).catch((err) => {\n      if (cancelled) {\n        return;\n      }\n      setBlobError(err instanceof Error ? err : new Error(String(err)));\n    });\n    return () => {\n      cancelled = true;\n      if (blobUrlToRevoke) {\n        URL.revokeObjectURL(blobUrlToRevoke);\n      }\n    };\n  }, [getBlob]);\n  const src = blobUrl ?? remotion_outputsBase + path;\n  if (connectionStatus === \"disconnected\") {\n    return /* @__PURE__ */ jsx51(\"div\", {\n      style: errMsgStyle,\n      children: \"Studio server disconnected\"\n    });\n  }\n  if (getBlob && blobError) {\n    return /* @__PURE__ */ jsxs17(\"div\", {\n      style: errMsgStyle,\n      children: [\n        \"Failed to load preview: \",\n        blobError.message\n      ]\n    });\n  }\n  if (getBlob && !blobUrl) {\n    return /* @__PURE__ */ jsx51(\"div\", {\n      style: msgStyle2,\n      children: \"Loading preview...\"\n    });\n  }\n  return /* @__PURE__ */ jsx51(FilePreview, {\n    assetMetadata,\n    currentAsset: path,\n    fileType,\n    src\n  });\n};\n\n// src/components/Spinner.tsx\nimport { useMemo as useMemo31 } from \"react\";\nimport { jsx as jsx52, jsxs as jsxs18, Fragment as Fragment8 } from \"react/jsx-runtime\";\nvar viewBox = 100;\nvar lines = 8;\nvar className = \"__remotion_spinner_line\";\nvar remotionSpinnerAnimation = \"__remotion_spinner_animation\";\nvar translated = \"M 44 0 L 50 0 a 6 6 0 0 1 6 6 L 56 26 a 6 6 0 0 1 -6 6 L 50 32 a 6 6 0 0 1 -6 -6 L 44 6 a 6 6 0 0 1 6 -6 Z\";\nvar Spinner = ({ size, duration }) => {\n  const style3 = useMemo31(() => {\n    return {\n      width: size,\n      height: size\n    };\n  }, [size]);\n  return /* @__PURE__ */ jsxs18(Fragment8, {\n    children: [\n      /* @__PURE__ */ jsx52(\"style\", {\n        type: \"text/css\",\n        children: `\n\t\t\t\t@keyframes ${remotionSpinnerAnimation} {\n          0% {\n            opacity: 1;\n          }\n          100% {\n            opacity: 0.15;\n          }\n        }\n        \n        .${className} {\n            animation: ${remotionSpinnerAnimation} ${duration}s linear infinite;\n        }        \n\t\t\t`\n      }),\n      /* @__PURE__ */ jsx52(\"svg\", {\n        style: style3,\n        viewBox: `0 0 ${viewBox} ${viewBox}`,\n        children: new Array(lines).fill(true).map((_, index) => {\n          return /* @__PURE__ */ jsx52(\"path\", {\n            className,\n            style: {\n              rotate: `${index * Math.PI * 2 / lines}rad`,\n              transformOrigin: \"center center\",\n              animationDelay: `${index * (duration / lines) - duration}s`\n            },\n            d: translated,\n            fill: LIGHT_TEXT\n          }, index);\n        })\n      })\n    ]\n  });\n};\n\n// src/components/StaticFilePreview.tsx\nimport { useContext as useContext16 } from \"react\";\nimport { staticFile as staticFile2 } from \"remotion\";\nimport { jsx as jsx53, jsxs as jsxs19 } from \"react/jsx-runtime\";\nvar msgStyle3 = {\n  fontSize: 13,\n  color: \"white\",\n  fontFamily: \"sans-serif\",\n  display: \"flex\",\n  justifyContent: \"center\"\n};\nvar errMsgStyle2 = {\n  ...msgStyle3,\n  color: LIGHT_TEXT\n};\nvar StaticFilePreview = ({ currentAsset, assetMetadata }) => {\n  const fileType = getPreviewFileType(currentAsset);\n  const staticFileSrc = staticFile2(currentAsset);\n  const staticFiles = getStaticFiles();\n  const connectionStatus = useContext16(StudioServerConnectionCtx).previewServerState.type;\n  const exists = staticFiles.find((file) => file.name === currentAsset);\n  if (connectionStatus === \"disconnected\") {\n    return /* @__PURE__ */ jsx53(\"div\", {\n      style: errMsgStyle2,\n      children: \"Studio server disconnected\"\n    });\n  }\n  if (!exists) {\n    return /* @__PURE__ */ jsxs19(\"div\", {\n      style: errMsgStyle2,\n      children: [\n        currentAsset,\n        \" does not exist in your public folder.\"\n      ]\n    });\n  }\n  if (!currentAsset) {\n    return null;\n  }\n  return /* @__PURE__ */ jsx53(FilePreview, {\n    currentAsset,\n    fileType,\n    src: `${staticFileSrc}?date=${assetMetadata && assetMetadata.type === \"found\" ? assetMetadata.fetchedAt : 0}`,\n    assetMetadata\n  });\n};\n\n// src/components/Preview.tsx\nimport { jsx as jsx54 } from \"react/jsx-runtime\";\nvar centeredContainer = {\n  display: \"flex\",\n  flex: 1,\n  justifyContent: \"center\",\n  alignItems: \"center\"\n};\nvar label3 = {\n  fontFamily: \"sans-serif\",\n  fontSize: 14,\n  color: LIGHT_TEXT\n};\nvar getPreviewFileType = (fileName) => {\n  if (!fileName) {\n    return \"other\";\n  }\n  const audioExtensions = [\"mp3\", \"wav\", \"ogg\", \"aac\"];\n  const videoExtensions = [\"mp4\", \"avi\", \"mkv\", \"mov\", \"webm\"];\n  const imageExtensions = [\"jpg\", \"jpeg\", \"png\", \"gif\", \"bmp\"];\n  const fileExtension = fileName.split(\".\").pop()?.toLowerCase();\n  if (fileExtension === undefined) {\n    throw new Error(\"File extension is undefined\");\n  }\n  if (audioExtensions.includes(fileExtension)) {\n    return \"audio\";\n  }\n  if (videoExtensions.includes(fileExtension)) {\n    return \"video\";\n  }\n  if (imageExtensions.includes(fileExtension)) {\n    return \"image\";\n  }\n  if (fileExtension === \"json\") {\n    return \"json\";\n  }\n  if (fileExtension === \"txt\") {\n    return \"txt\";\n  }\n  return \"other\";\n};\nvar checkerboardSize = 49;\nvar containerStyle = (options) => {\n  return {\n    transform: `scale(${options.scale})`,\n    marginLeft: options.xCorrection,\n    marginTop: options.yCorrection,\n    width: options.width,\n    height: options.height,\n    display: \"flex\",\n    position: \"absolute\",\n    backgroundColor: checkerboardBackgroundColor(options.checkerboard),\n    backgroundImage: checkerboardBackgroundImage(options.checkerboard),\n    backgroundSize: getCheckerboardBackgroundSize(checkerboardSize),\n    backgroundPosition: getCheckerboardBackgroundPos(checkerboardSize)\n  };\n};\nvar VideoPreview = ({ canvasSize, contentDimensions, canvasContent, assetMetadata }) => {\n  if (assetMetadata && assetMetadata.type === \"not-found\") {\n    return /* @__PURE__ */ jsx54(\"div\", {\n      style: centeredContainer,\n      children: /* @__PURE__ */ jsx54(\"div\", {\n        style: label3,\n        children: \"File does not exist\"\n      })\n    });\n  }\n  if (contentDimensions === null) {\n    return /* @__PURE__ */ jsx54(\"div\", {\n      style: centeredContainer,\n      children: /* @__PURE__ */ jsx54(Spinner, {\n        duration: 0.5,\n        size: 24\n      })\n    });\n  }\n  return /* @__PURE__ */ jsx54(CompWhenItHasDimensions, {\n    contentDimensions,\n    canvasSize,\n    canvasContent,\n    assetMetadata\n  });\n};\nvar CompWhenItHasDimensions = ({ contentDimensions, canvasSize, canvasContent, assetMetadata }) => {\n  const { size: previewSize } = useContext17(Internals11.PreviewSizeContext);\n  const { centerX, centerY, yCorrection, xCorrection, scale } = useMemo32(() => {\n    if (contentDimensions === \"none\") {\n      return {\n        centerX: 0,\n        centerY: 0,\n        yCorrection: 0,\n        xCorrection: 0,\n        scale: 1\n      };\n    }\n    return PlayerInternals6.calculateCanvasTransformation({\n      canvasSize,\n      compositionHeight: contentDimensions.height,\n      compositionWidth: contentDimensions.width,\n      previewSize: previewSize.size\n    });\n  }, [canvasSize, contentDimensions, previewSize.size]);\n  const outer = useMemo32(() => {\n    return {\n      width: contentDimensions === \"none\" ? \"100%\" : contentDimensions.width * scale,\n      height: contentDimensions === \"none\" ? \"100%\" : contentDimensions.height * scale,\n      display: \"flex\",\n      flexDirection: \"column\",\n      position: \"absolute\",\n      left: centerX - previewSize.translation.x,\n      top: centerY - previewSize.translation.y,\n      overflow: \"hidden\",\n      justifyContent: canvasContent.type === \"asset\" ? \"center\" : \"flex-start\",\n      alignItems: canvasContent.type === \"asset\" && getPreviewFileType(canvasContent.asset) === \"audio\" ? \"center\" : \"normal\"\n    };\n  }, [\n    contentDimensions,\n    scale,\n    centerX,\n    previewSize.translation.x,\n    previewSize.translation.y,\n    centerY,\n    canvasContent\n  ]);\n  if (canvasContent.type === \"asset\") {\n    return /* @__PURE__ */ jsx54(\"div\", {\n      style: outer,\n      children: /* @__PURE__ */ jsx54(StaticFilePreview, {\n        assetMetadata,\n        currentAsset: canvasContent.asset\n      })\n    });\n  }\n  if (canvasContent.type === \"output\") {\n    return /* @__PURE__ */ jsx54(\"div\", {\n      style: outer,\n      children: /* @__PURE__ */ jsx54(RenderPreview, {\n        path: canvasContent.path,\n        assetMetadata\n      })\n    });\n  }\n  if (canvasContent.type === \"output-blob\") {\n    return /* @__PURE__ */ jsx54(\"div\", {\n      style: outer,\n      children: /* @__PURE__ */ jsx54(RenderPreview, {\n        path: canvasContent.displayName,\n        assetMetadata,\n        getBlob: canvasContent.getBlob\n      })\n    });\n  }\n  return /* @__PURE__ */ jsx54(\"div\", {\n    style: outer,\n    children: /* @__PURE__ */ jsx54(PortalContainer, {\n      contentDimensions,\n      scale,\n      xCorrection,\n      yCorrection\n    })\n  });\n};\nvar PortalContainer = ({ scale, xCorrection, yCorrection, contentDimensions }) => {\n  const { checkerboard } = useContext17(CheckerboardContext);\n  const style3 = useMemo32(() => {\n    return containerStyle({\n      checkerboard,\n      scale,\n      xCorrection,\n      yCorrection,\n      width: contentDimensions.width,\n      height: contentDimensions.height\n    });\n  }, [\n    checkerboard,\n    contentDimensions.height,\n    contentDimensions.width,\n    scale,\n    xCorrection,\n    yCorrection\n  ]);\n  useEffect22(() => {\n    const { current } = portalContainer;\n    current?.appendChild(Internals11.portalNode());\n    return () => {\n      current?.removeChild(Internals11.portalNode());\n    };\n  }, []);\n  const portalContainer = useRef17(null);\n  return /* @__PURE__ */ jsx54(\"div\", {\n    ref: portalContainer,\n    style: style3\n  });\n};\n\n// src/components/SizeSelector.tsx\nimport { jsx as jsx55 } from \"react/jsx-runtime\";\nvar commonPreviewSizes = [\n  {\n    size: \"auto\",\n    translation: {\n      x: 0,\n      y: 0\n    }\n  },\n  {\n    size: 0.25,\n    translation: {\n      x: 0,\n      y: 0\n    }\n  },\n  {\n    size: 0.5,\n    translation: {\n      x: 0,\n      y: 0\n    }\n  },\n  {\n    size: 1,\n    translation: {\n      x: 0,\n      y: 0\n    }\n  }\n];\nvar getPreviewSizeLabel = (previewSize) => {\n  if (previewSize.size === \"auto\") {\n    return \"Fit\";\n  }\n  return `${(previewSize.size * 100).toFixed(0)}%`;\n};\nvar accessibilityLabel = \"Preview Size\";\nvar comboStyle = { width: 80 };\nvar getUniqueSizes = (size) => {\n  const customPreviewSizes = [size, ...commonPreviewSizes];\n  const uniqueSizes = [];\n  customPreviewSizes.forEach((p) => {\n    if (!uniqueSizes.find((s) => s.size === p.size)) {\n      uniqueSizes.push(p);\n    }\n  });\n  return uniqueSizes.sort((a, b) => {\n    if (a.size === \"auto\") {\n      return -1;\n    }\n    if (b.size === \"auto\") {\n      return 1;\n    }\n    return a.size - b.size;\n  });\n};\nvar zoomableFileTypes = [\"video\", \"image\"];\nvar SizeSelector = () => {\n  const { size, setSize } = useContext18(Internals12.PreviewSizeContext);\n  const { canvasContent } = useContext18(Internals12.CompositionManager);\n  const style3 = useMemo33(() => {\n    return {\n      padding: CONTROL_BUTTON_PADDING\n    };\n  }, []);\n  const zoomable = useMemo33(() => {\n    if (!canvasContent) {\n      return null;\n    }\n    if (canvasContent.type === \"composition\") {\n      return true;\n    }\n    if (canvasContent.type === \"asset\" && zoomableFileTypes.includes(getPreviewFileType(canvasContent.asset))) {\n      return true;\n    }\n    if (canvasContent.type === \"output\" && zoomableFileTypes.includes(getPreviewFileType(canvasContent.path))) {\n      return true;\n    }\n    return false;\n  }, [canvasContent]);\n  const items = useMemo33(() => {\n    return getUniqueSizes(size).map((newSize) => {\n      return {\n        id: String(newSize.size),\n        label: getPreviewSizeLabel(newSize),\n        onClick: () => {\n          return setSize(() => {\n            return newSize;\n          });\n        },\n        type: \"item\",\n        value: newSize.size,\n        keyHint: newSize.size === \"auto\" ? \"0\" : null,\n        leftItem: String(size.size) === String(newSize.size) ? /* @__PURE__ */ jsx55(Checkmark, {}) : null,\n        subMenu: null,\n        quickSwitcherLabel: null\n      };\n    });\n  }, [setSize, size]);\n  if (!zoomable) {\n    return null;\n  }\n  return /* @__PURE__ */ jsx55(\"div\", {\n    style: style3,\n    \"aria-label\": accessibilityLabel,\n    children: /* @__PURE__ */ jsx55(Combobox, {\n      title: accessibilityLabel,\n      style: comboStyle,\n      selectedId: String(size.size),\n      values: items\n    })\n  });\n};\n\n// src/components/TimelineInOutToggle.tsx\nimport { PlayerInternals as PlayerInternals7 } from \"@remotion/player\";\nimport {\n  createRef as createRef7,\n  useCallback as useCallback27,\n  useEffect as useEffect23,\n  useImperativeHandle as useImperativeHandle9\n} from \"react\";\nimport { Internals as Internals14 } from \"remotion\";\nimport { NoReactInternals as NoReactInternals4 } from \"remotion/no-react\";\n\n// src/icons/timelineInOutPointer.tsx\nimport { jsx as jsx56 } from \"react/jsx-runtime\";\nvar TimelineInPointer = (props) => {\n  return /* @__PURE__ */ jsx56(\"svg\", {\n    viewBox: \"0 0 256 256\",\n    fill: \"none\",\n    ...props,\n    children: /* @__PURE__ */ jsx56(\"path\", {\n      d: \"M158 25H99V230.5H158\",\n      stroke: props.color,\n      strokeWidth: \"42\",\n      strokeLinecap: \"round\",\n      strokeLinejoin: \"round\"\n    })\n  });\n};\nvar TimelineOutPointer = (props) => {\n  return /* @__PURE__ */ jsx56(\"svg\", {\n    viewBox: \"0 0 256 256\",\n    fill: \"none\",\n    ...props,\n    children: /* @__PURE__ */ jsx56(\"path\", {\n      d: \"M98 25H157V230.5H98\",\n      stroke: props.color,\n      strokeWidth: \"42\",\n      strokeLinecap: \"round\",\n      strokeLinejoin: \"round\"\n    })\n  });\n};\n\n// src/state/in-out.ts\nimport { createContext as createContext11, useContext as useContext19, useMemo as useMemo34 } from \"react\";\nimport { Internals as Internals13 } from \"remotion\";\nvar TimelineInOutContext = createContext11({});\nvar SetTimelineInOutContext = createContext11({\n  setInAndOutFrames: () => {\n    throw new Error(\"default\");\n  }\n});\nvar useTimelineInOutFramePosition = () => {\n  const videoConfig = Internals13.useUnsafeVideoConfig();\n  const state = useContext19(TimelineInOutContext);\n  const id = videoConfig?.id;\n  const durationInFrames = videoConfig?.durationInFrames;\n  return useMemo34(() => {\n    if (!id || !durationInFrames) {\n      return { inFrame: null, outFrame: null };\n    }\n    const maxFrame = durationInFrames - 1;\n    const actualInFrame = state[id]?.inFrame ?? null;\n    const actualOutFrame = state[id]?.outFrame ?? null;\n    return {\n      inFrame: actualInFrame === null ? null : actualInFrame >= maxFrame ? null : actualInFrame,\n      outFrame: actualOutFrame === null ? null : actualOutFrame >= maxFrame ? null : actualOutFrame\n    };\n  }, [durationInFrames, id, state]);\n};\nvar useTimelineSetInOutFramePosition = () => {\n  const { setInAndOutFrames } = useContext19(SetTimelineInOutContext);\n  return { setInAndOutFrames };\n};\n\n// src/components/TimelineInOutToggle.tsx\nimport { jsx as jsx57, jsxs as jsxs20, Fragment as Fragment9 } from \"react/jsx-runtime\";\nvar getTooltipText = (pointType, key) => [\n  `Mark ${pointType}`,\n  areKeyboardShortcutsDisabled() ? null : `(${key})`,\n  \"- right click to clear\"\n].filter(NoReactInternals4.truthy).join(\" \");\nvar style3 = {\n  width: 16,\n  height: 16\n};\nvar inOutHandles = createRef7();\nvar defaultInOutValue = { inFrame: null, outFrame: null };\nvar TimelineInOutPointToggle = () => {\n  const { inFrame, outFrame } = useTimelineInOutFramePosition();\n  const { setInAndOutFrames } = useTimelineSetInOutFramePosition();\n  const videoConfig = Internals14.useUnsafeVideoConfig();\n  const keybindings = useKeybinding();\n  const { getCurrentFrame: getCurrentFrame2, isFirstFrame, isLastFrame } = PlayerInternals7.usePlayer();\n  const onInOutClear = useCallback27((composition) => {\n    setInAndOutFrames((prev) => {\n      return {\n        ...prev,\n        [composition]: {\n          inFrame: null,\n          outFrame: null\n        }\n      };\n    });\n  }, [setInAndOutFrames]);\n  const onInMark = useCallback27((e) => {\n    if (!videoConfig) {\n      return null;\n    }\n    if (e?.shiftKey) {\n      setInAndOutFrames((prev) => {\n        return {\n          ...prev,\n          [videoConfig.id]: {\n            ...prev[videoConfig.id] ?? defaultInOutValue,\n            inFrame: null\n          }\n        };\n      });\n      return null;\n    }\n    setInAndOutFrames((prev) => {\n      const prevOut = prev[videoConfig.id]?.outFrame;\n      const biggestPossible = prevOut === undefined || prevOut === null ? Infinity : prevOut - 1;\n      const selected = Math.min(getCurrentFrame2(), biggestPossible);\n      if (selected === 0) {\n        return {\n          ...prev,\n          [videoConfig.id]: {\n            ...prev[videoConfig.id] ?? defaultInOutValue,\n            inFrame: null\n          }\n        };\n      }\n      const prevIn = prev[videoConfig.id]?.inFrame;\n      if (prevIn !== null && prevIn !== undefined) {\n        if (prevIn === selected) {\n          return {\n            ...prev,\n            [videoConfig.id]: {\n              ...prev[videoConfig.id] ?? defaultInOutValue,\n              inFrame: null\n            }\n          };\n        }\n      }\n      return {\n        ...prev,\n        [videoConfig.id]: {\n          ...prev[videoConfig.id] ?? defaultInOutValue,\n          inFrame: selected\n        }\n      };\n    });\n  }, [getCurrentFrame2, setInAndOutFrames, videoConfig]);\n  const clearInMark = useCallback27((e) => {\n    if (!videoConfig) {\n      return null;\n    }\n    e.preventDefault();\n    setInAndOutFrames((f) => {\n      return {\n        ...f,\n        [videoConfig.id]: {\n          ...f[videoConfig.id] ?? defaultInOutValue,\n          inFrame: null\n        }\n      };\n    });\n  }, [setInAndOutFrames, videoConfig]);\n  const clearOutMark = useCallback27((e) => {\n    if (!videoConfig) {\n      return null;\n    }\n    e?.preventDefault();\n    setInAndOutFrames((f) => {\n      return {\n        ...f,\n        [videoConfig.id]: {\n          ...f[videoConfig.id] ?? defaultInOutValue,\n          outFrame: null\n        }\n      };\n    });\n  }, [setInAndOutFrames, videoConfig]);\n  const onOutMark = useCallback27((e) => {\n    if (!videoConfig) {\n      return null;\n    }\n    if (e?.shiftKey) {\n      setInAndOutFrames((f) => {\n        return {\n          ...f,\n          [videoConfig.id]: {\n            ...f[videoConfig.id] ?? defaultInOutValue,\n            outFrame: null\n          }\n        };\n      });\n      return;\n    }\n    setInAndOutFrames((prev) => {\n      const prevInFrame = prev[videoConfig.id]?.inFrame;\n      const smallestPossible = prevInFrame === null || prevInFrame === undefined ? -Infinity : prevInFrame + 1;\n      const selected = Math.max(getCurrentFrame2(), smallestPossible);\n      if (selected === videoConfig.durationInFrames - 1) {\n        return {\n          ...prev,\n          [videoConfig.id]: {\n            ...prev[videoConfig.id] ?? defaultInOutValue,\n            outFrame: null\n          }\n        };\n      }\n      const prevOut = prev[videoConfig.id]?.outFrame;\n      if (prevOut !== null && prevOut !== undefined) {\n        if (prevOut === selected) {\n          return {\n            ...prev,\n            [videoConfig.id]: {\n              ...prev[videoConfig.id] ?? defaultInOutValue,\n              outFrame: null\n            }\n          };\n        }\n      }\n      return {\n        ...prev,\n        [videoConfig.id]: {\n          ...prev[videoConfig.id] ?? defaultInOutValue,\n          outFrame: selected\n        }\n      };\n    });\n  }, [getCurrentFrame2, setInAndOutFrames, videoConfig]);\n  const confId = videoConfig?.id;\n  useEffect23(() => {\n    if (!confId) {\n      return;\n    }\n    const iKey = keybindings.registerKeybinding({\n      event: \"keypress\",\n      key: \"i\",\n      callback: (e) => {\n        onInMark(e);\n      },\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const oKey = keybindings.registerKeybinding({\n      event: \"keypress\",\n      key: \"o\",\n      callback: (e) => {\n        onOutMark(e);\n      },\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const xKey = keybindings.registerKeybinding({\n      event: \"keypress\",\n      key: \"x\",\n      callback: () => {\n        onInOutClear(confId);\n      },\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      oKey.unregister();\n      iKey.unregister();\n      xKey.unregister();\n    };\n  }, [confId, keybindings, onInMark, onInOutClear, onOutMark]);\n  useImperativeHandle9(inOutHandles, () => {\n    return {\n      clearMarks: () => {\n        if (!confId) {\n          return;\n        }\n        onInOutClear(confId);\n      },\n      inMarkClick: onInMark,\n      outMarkClick: onOutMark\n    };\n  }, [confId, onInMark, onInOutClear, onOutMark]);\n  return /* @__PURE__ */ jsxs20(Fragment9, {\n    children: [\n      /* @__PURE__ */ jsx57(ControlButton, {\n        title: getTooltipText(\"In\", \"I\"),\n        \"aria-label\": getTooltipText(\"In\", \"I\"),\n        onClick: onInMark,\n        onContextMenu: clearInMark,\n        disabled: !videoConfig || isFirstFrame,\n        children: /* @__PURE__ */ jsx57(TimelineInPointer, {\n          color: inFrame === null ? \"white\" : BLUE,\n          style: style3\n        })\n      }),\n      /* @__PURE__ */ jsx57(ControlButton, {\n        title: getTooltipText(\"Out\", \"O\"),\n        \"aria-label\": getTooltipText(\"Out\", \"O\"),\n        onClick: onOutMark,\n        onContextMenu: clearOutMark,\n        disabled: !videoConfig || isLastFrame,\n        children: /* @__PURE__ */ jsx57(TimelineOutPointer, {\n          color: outFrame === null ? \"white\" : BLUE,\n          style: style3\n        })\n      })\n    ]\n  });\n};\n\n// src/error-overlay/remotion-overlay/ShortcutHint.tsx\nimport { useMemo as useMemo35 } from \"react\";\nimport { jsx as jsx58, jsxs as jsxs21 } from \"react/jsx-runtime\";\nvar cmdOrCtrlCharacter = window.navigator.platform.startsWith(\"Mac\") ? \"\" : \"Ctrl\";\nvar container13 = {\n  display: \"inline-block\",\n  marginLeft: 6,\n  opacity: 0.6,\n  verticalAlign: \"middle\",\n  fontSize: 14\n};\nvar ShortcutHint = ({ keyToPress, cmdOrCtrl }) => {\n  const style4 = useMemo35(() => {\n    if (keyToPress === \"\") {\n      return {\n        display: \"inline-block\",\n        transform: `translateY(2px)`,\n        fontSize: 14\n      };\n    }\n    return {};\n  }, [keyToPress]);\n  if (areKeyboardShortcutsDisabled()) {\n    return null;\n  }\n  return /* @__PURE__ */ jsxs21(\"span\", {\n    style: container13,\n    children: [\n      cmdOrCtrl ? `${cmdOrCtrlCharacter}` : \"\",\n      /* @__PURE__ */ jsx58(\"span\", {\n        style: style4,\n        children: keyToPress.toUpperCase()\n      })\n    ]\n  });\n};\n\n// src/state/editor-guides.ts\nimport { createContext as createContext12 } from \"react\";\nvar persistEditorShowGuidesOption = (option) => {\n  localStorage.setItem(\"remotion.editorShowGuides\", String(option));\n};\nvar loadEditorShowGuidesOption = () => {\n  const item = localStorage.getItem(\"remotion.editorShowGuides\");\n  return item === \"true\";\n};\nvar persistGuidesList = (guides) => {\n  localStorage.setItem(\"remotion.guidesList\", JSON.stringify(guides));\n};\nvar loadGuidesList = () => {\n  const item = localStorage.getItem(\"remotion.guidesList\");\n  return item ? JSON.parse(item) : [];\n};\nvar EditorShowGuidesContext = createContext12({\n  editorShowGuides: false,\n  setEditorShowGuides: () => {\n    return;\n  },\n  guidesList: [],\n  setGuidesList: () => {\n    return;\n  },\n  selectedGuideId: null,\n  setSelectedGuideId: () => {\n    return;\n  },\n  shouldCreateGuideRef: { current: false },\n  shouldDeleteGuideRef: { current: false },\n  hoveredGuideId: null,\n  setHoveredGuideId: () => {\n    return;\n  }\n});\n\n// src/state/editor-rulers.ts\nimport { createContext as createContext13 } from \"react\";\nvar persistEditorShowRulersOption = (option) => {\n  localStorage.setItem(\"remotion.editorShowRulers\", String(option));\n};\nvar loadEditorShowRulersOption = () => {\n  const item = localStorage.getItem(\"remotion.editorShowRulers\");\n  return item === \"true\";\n};\nvar EditorShowRulersContext = createContext13({\n  editorShowRulers: loadEditorShowRulersOption(),\n  setEditorShowRulers: () => {\n    return;\n  }\n});\nvar RULER_WIDTH = 20;\nvar MINIMUM_VISIBLE_CANVAS_SIZE = 50;\nvar PREDEFINED_RULER_SCALE_GAPS = [\n  1,\n  2,\n  5,\n  10,\n  20,\n  50,\n  100,\n  250,\n  500,\n  1000,\n  2000,\n  5000\n];\nvar MAXIMUM_PREDEFINED_RULER_SCALE_GAP = 5000;\nvar MINIMUM_RULER_MARKING_GAP_PX = 50;\n\n// src/state/editor-zoom-gestures.ts\nimport { createContext as createContext14 } from \"react\";\nvar persistEditorZoomGesturesOption = (option) => {\n  localStorage.setItem(\"remotion.editorZoomGestures\", String(option));\n};\nvar loadEditorZoomGesturesOption = () => {\n  const item = localStorage.getItem(\"remotion.editorZoomGestures\");\n  return item !== \"false\";\n};\nvar EditorZoomGesturesContext = createContext14({\n  editorZoomGestures: loadEditorZoomGesturesOption(),\n  setEditorZoomGestures: () => {\n    return;\n  }\n});\n\n// src/helpers/check-fullscreen-support.ts\nvar checkFullscreenSupport = () => {\n  return document.fullscreenEnabled || document.webkitFullscreenEnabled;\n};\n\n// src/helpers/get-git-menu-item.ts\nvar getGitSourceName = (gitSource) => {\n  if (gitSource.type === \"github\") {\n    return \"GitHub\";\n  }\n  throw new Error(\"Unknown git source type\");\n};\nvar getGitSourceBranchUrl = (gitSource) => {\n  if (gitSource.type === \"github\") {\n    return `https://github.com/${gitSource.org}/${gitSource.name}/tree/${gitSource.ref}${gitSource.relativeFromGitRoot ? `/${gitSource.relativeFromGitRoot}` : \"\"}`;\n  }\n  throw new Error(\"Unknown git source type\");\n};\nvar getGitRefUrl = (gitSource, originalLocation) => {\n  if (gitSource.type === \"github\") {\n    return `https://github.com/${gitSource.org}/${gitSource.name}/tree/${gitSource.ref}/${gitSource.relativeFromGitRoot ? `${gitSource.relativeFromGitRoot}/` : \"\"}${originalLocation.source}#L${originalLocation.line}`;\n  }\n  throw new Error(\"Unknown git source type\");\n};\nvar getGitMenuItem = () => {\n  if (!window.remotion_gitSource) {\n    return null;\n  }\n  return {\n    id: \"open-git-source\",\n    value: \"open-git-source\",\n    label: `Open ${getGitSourceName(window.remotion_gitSource)} Repo`,\n    onClick: () => {\n      window.open(getGitSourceBranchUrl(window.remotion_gitSource), \"_blank\");\n    },\n    type: \"item\",\n    keyHint: null,\n    leftItem: null,\n    subMenu: null,\n    quickSwitcherLabel: `Open ${getGitSourceName(window.remotion_gitSource)} repo`\n  };\n};\n\n// src/helpers/open-in-editor.ts\nvar openInEditor = (stack) => {\n  const {\n    originalFileName,\n    originalLineNumber,\n    originalColumnNumber,\n    originalFunctionName,\n    originalScriptCode\n  } = stack;\n  return fetch(`/api/open-in-editor`, {\n    method: \"post\",\n    headers: {\n      \"content-type\": \"application/json\"\n    },\n    body: JSON.stringify({\n      stack: {\n        originalFileName,\n        originalLineNumber,\n        originalColumnNumber,\n        originalFunctionName,\n        originalScriptCode\n      }\n    })\n  });\n};\nvar openOriginalPositionInEditor = async (originalPosition) => {\n  await openInEditor({\n    originalColumnNumber: originalPosition.column,\n    originalFileName: originalPosition.source,\n    originalFunctionName: null,\n    originalLineNumber: originalPosition.line,\n    originalScriptCode: null\n  });\n};\n\n// src/components/Notifications/ColorDot.tsx\nimport { useMemo as useMemo36 } from \"react\";\nimport { jsx as jsx59 } from \"react/jsx-runtime\";\nvar container14 = {\n  height: 16,\n  width: 16,\n  backgroundColor: \"red\",\n  border: \"1px solid rgba(255, 255, 255, 0.2)\",\n  borderRadius: 8\n};\nvar ColorDot = ({ color }) => {\n  const style4 = useMemo36(() => {\n    return {\n      ...container14,\n      backgroundColor: color\n    };\n  }, [color]);\n  return /* @__PURE__ */ jsx59(\"div\", {\n    style: style4\n  });\n};\n\n// src/helpers/pick-color.tsx\nimport { jsx as jsx60, jsxs as jsxs22, Fragment as Fragment10 } from \"react/jsx-runtime\";\nvar pickColor = () => {\n  const open = new EyeDropper().open();\n  open.then((color) => {\n    copyText(color.sRGBHex).then(() => {\n      showNotification(/* @__PURE__ */ jsxs22(Fragment10, {\n        children: [\n          /* @__PURE__ */ jsx60(ColorDot, {\n            color: color.sRGBHex\n          }),\n          \" \",\n          /* @__PURE__ */ jsx60(Spacing, {\n            x: 1\n          }),\n          \" Copied\",\n          \" \",\n          color.sRGBHex\n        ]\n      }), 2000);\n    }).catch((err) => {\n      showNotification(`Could not copy: ${err.message}`, 2000);\n    });\n  }).catch((err) => {\n    if (err.message.includes(\"canceled\")) {\n      return;\n    }\n    showNotification(`Could not pick color.`, 2000);\n  });\n};\n\n// src/helpers/show-browser-rendering.ts\nvar SHOW_BROWSER_RENDERING = Boolean(process.env.EXPERIMENTAL_CLIENT_SIDE_RENDERING_ENABLED);\n\n// src/helpers/use-menu-structure.tsx\nimport { jsx as jsx61 } from \"react/jsx-runtime\";\nvar openExternal = (link) => {\n  window.open(link, \"_blank\");\n};\nvar rotate = {\n  transform: `rotate(90deg)`\n};\nvar ICON_SIZE = 16;\nvar getFileMenu = ({\n  readOnlyStudio,\n  closeMenu,\n  previewServerState,\n  setSelectedModal\n}) => {\n  const items = [\n    window.remotion_isReadOnlyStudio ? {\n      id: \"input-props-override\",\n      value: \"input-props-override\",\n      label: \"Set input props...\",\n      onClick: () => {\n        closeMenu();\n        setSelectedModal({\n          type: \"input-props-override\"\n        });\n      },\n      type: \"item\",\n      keyHint: null,\n      leftItem: null,\n      subMenu: null,\n      quickSwitcherLabel: \"Override input props\"\n    } : null,\n    readOnlyStudio ? null : {\n      id: \"render\",\n      value: \"render\",\n      label: \"Render...\",\n      onClick: () => {\n        closeMenu();\n        if (previewServerState !== \"connected\") {\n          showNotification(\"Restart the studio to render\", 2000);\n          return;\n        }\n        const renderButton = document.getElementById(\"render-modal-button-server\");\n        renderButton.click();\n      },\n      type: \"item\",\n      keyHint: \"R\",\n      leftItem: null,\n      subMenu: null,\n      quickSwitcherLabel: \"Render...\"\n    },\n    SHOW_BROWSER_RENDERING && !readOnlyStudio ? {\n      id: \"render-on-web\",\n      value: \"render-on-web\",\n      label: \"Render on web...\",\n      onClick: () => {\n        closeMenu();\n        const renderButton = document.getElementById(\"render-modal-button-client\");\n        renderButton.click();\n      },\n      type: \"item\",\n      keyHint: null,\n      leftItem: null,\n      subMenu: null,\n      quickSwitcherLabel: \"Render on web...\"\n    } : null,\n    window.remotion_editorName && !readOnlyStudio ? {\n      type: \"divider\",\n      id: \"open-in-editor-divider\"\n    } : null,\n    window.remotion_editorName && !readOnlyStudio ? {\n      id: \"open-in-editor\",\n      value: \"open-in-editor\",\n      label: `Open in ${window.remotion_editorName}`,\n      onClick: async () => {\n        await openInEditor({\n          originalFileName: `${window.remotion_cwd}`,\n          originalLineNumber: 1,\n          originalColumnNumber: 1,\n          originalFunctionName: null,\n          originalScriptCode: null\n        }).then((res) => res.json()).then(({ success }) => {\n          if (!success) {\n            showNotification(`Could not open ${window.remotion_editorName}`, 2000);\n          }\n        }).catch((err) => {\n          console.error(err);\n          showNotification(`Could not open ${window.remotion_editorName}`, 2000);\n        });\n      },\n      type: \"item\",\n      keyHint: null,\n      leftItem: null,\n      subMenu: null,\n      quickSwitcherLabel: \"Open in editor...\"\n    } : null,\n    getGitMenuItem()\n  ].filter(NoReactInternals5.truthy);\n  if (items.length === 0) {\n    return null;\n  }\n  return {\n    id: \"file\",\n    label: \"File\",\n    leaveLeftPadding: false,\n    items,\n    quickSwitcherLabel: null\n  };\n};\nvar useMenuStructure = (closeMenu, readOnlyStudio) => {\n  const { setSelectedModal } = useContext20(ModalsContext);\n  const { checkerboard, setCheckerboard } = useContext20(CheckerboardContext);\n  const { editorZoomGestures, setEditorZoomGestures } = useContext20(EditorZoomGesturesContext);\n  const { editorShowRulers, setEditorShowRulers } = useContext20(EditorShowRulersContext);\n  const { editorShowGuides, setEditorShowGuides } = useContext20(EditorShowGuidesContext);\n  const { size, setSize } = useContext20(Internals15.PreviewSizeContext);\n  const { type } = useContext20(StudioServerConnectionCtx).previewServerState;\n  const {\n    setSidebarCollapsedState,\n    sidebarCollapsedStateLeft,\n    sidebarCollapsedStateRight\n  } = useContext20(SidebarContext);\n  const sizes = useMemo37(() => getUniqueSizes(size), [size]);\n  const isFullscreenSupported = checkFullscreenSupport();\n  const { remotion_packageManager } = window;\n  const sizePreselectIndex = sizes.findIndex((s) => String(size.size) === String(s.size));\n  const mobileLayout = useMobileLayout();\n  const structure = useMemo37(() => {\n    let struct = [\n      {\n        id: \"remotion\",\n        label: /* @__PURE__ */ jsx61(Row, {\n          align: \"center\",\n          justify: \"center\",\n          children: /* @__PURE__ */ jsx61(\"svg\", {\n            width: ICON_SIZE,\n            height: ICON_SIZE,\n            viewBox: \"-100 -100 400 400\",\n            style: rotate,\n            children: /* @__PURE__ */ jsx61(\"path\", {\n              fill: \"#fff\",\n              stroke: \"#fff\",\n              strokeWidth: \"100\",\n              strokeLinejoin: \"round\",\n              d: \"M 2 172 a 196 100 0 0 0 195 5 A 196 240 0 0 0 100 2.259 A 196 240 0 0 0 2 172 z\"\n            })\n          })\n        }),\n        leaveLeftPadding: false,\n        items: [\n          {\n            id: \"about\",\n            value: \"about\",\n            label: \"About Remotion\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://remotion.dev\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Help: About Remotion\"\n          },\n          {\n            id: \"changelog\",\n            value: \"changelog\",\n            label: \"Changelog\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://github.com/remotion-dev/remotion/releases\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Help: Changelog\"\n          },\n          {\n            id: \"license\",\n            value: \"license\",\n            label: \"License\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://github.com/remotion-dev/remotion/blob/main/LICENSE.md\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Help: License\"\n          },\n          {\n            id: \"acknowledgements\",\n            value: \"acknowledgements\",\n            label: \"Acknowledgements\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://remotion.dev/acknowledgements\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Help: Acknowledgements\"\n          },\n          {\n            type: \"divider\",\n            id: \"timeline-divider-1\"\n          },\n          {\n            id: \"restart-studio\",\n            value: \"restart-studio\",\n            label: \"Restart Studio Server\",\n            onClick: () => {\n              closeMenu();\n              restartStudio();\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Restart Studio Server\"\n          }\n        ],\n        quickSwitcherLabel: null\n      },\n      getFileMenu({\n        readOnlyStudio,\n        closeMenu,\n        previewServerState: type,\n        setSelectedModal\n      }),\n      {\n        id: \"view\",\n        label: \"View\",\n        leaveLeftPadding: true,\n        items: [\n          {\n            id: \"preview-size\",\n            keyHint: null,\n            label: \"Preview size\",\n            onClick: () => {\n              return;\n            },\n            type: \"item\",\n            value: \"preview-size\",\n            leftItem: null,\n            subMenu: {\n              leaveLeftSpace: true,\n              preselectIndex: sizePreselectIndex,\n              items: sizes.map((newSize) => ({\n                id: String(newSize.size),\n                keyHint: newSize.size === 1 ? \"0\" : null,\n                label: getPreviewSizeLabel(newSize),\n                leftItem: String(newSize.size) === String(size.size) ? /* @__PURE__ */ jsx61(Checkmark, {}) : null,\n                onClick: () => {\n                  closeMenu();\n                  setSize(() => newSize);\n                },\n                subMenu: null,\n                type: \"item\",\n                value: newSize.size,\n                quickSwitcherLabel: null\n              })),\n              quickSwitcherLabel: null\n            },\n            quickSwitcherLabel: null\n          },\n          {\n            id: \"editor-zoom-gestures\",\n            keyHint: null,\n            label: \"Zoom and Pan Gestures\",\n            onClick: () => {\n              closeMenu();\n              setEditorZoomGestures((c) => !c);\n            },\n            type: \"item\",\n            value: \"editor-zoom-gestures\",\n            leftItem: editorZoomGestures ? /* @__PURE__ */ jsx61(Checkmark, {}) : null,\n            subMenu: null,\n            quickSwitcherLabel: editorZoomGestures ? \"Disable Zoom and Pan Gestures\" : \"Enable Zoom and Pan Gestures\"\n          },\n          {\n            id: \"show-rulers\",\n            keyHint: null,\n            label: \"Show Rulers\",\n            onClick: () => {\n              closeMenu();\n              setEditorShowRulers((c) => !c);\n            },\n            type: \"item\",\n            value: \"show-ruler\",\n            leftItem: editorShowRulers ? /* @__PURE__ */ jsx61(Checkmark, {}) : null,\n            subMenu: null,\n            quickSwitcherLabel: editorShowRulers ? \"Hide Rulers\" : \"Show Rulers\"\n          },\n          {\n            id: \"show-guides\",\n            keyHint: null,\n            label: \"Show Guides\",\n            onClick: () => {\n              closeMenu();\n              setEditorShowGuides((c) => !c);\n            },\n            type: \"item\",\n            value: \"show-guides\",\n            leftItem: editorShowGuides ? /* @__PURE__ */ jsx61(Checkmark, {}) : null,\n            subMenu: null,\n            quickSwitcherLabel: editorShowGuides ? \"Hide Guides\" : \"Show Guides\"\n          },\n          {\n            id: \"timeline-divider-1\",\n            type: \"divider\"\n          },\n          {\n            id: \"left-sidebar\",\n            label: \"Left Sidebar\",\n            keyHint: null,\n            type: \"item\",\n            value: \"preview-size\",\n            leftItem: null,\n            quickSwitcherLabel: null,\n            subMenu: {\n              leaveLeftSpace: true,\n              preselectIndex: 0,\n              items: [\n                {\n                  id: \"left-sidebar-responsive\",\n                  keyHint: null,\n                  label: \"Responsive\",\n                  leftItem: sidebarCollapsedStateLeft === \"responsive\" ? /* @__PURE__ */ jsx61(Checkmark, {}) : null,\n                  onClick: () => {\n                    closeMenu();\n                    setSidebarCollapsedState({\n                      left: \"responsive\",\n                      right: null\n                    });\n                  },\n                  subMenu: null,\n                  type: \"item\",\n                  value: \"responsive\",\n                  quickSwitcherLabel: null\n                },\n                {\n                  id: \"left-sidebar-expanded\",\n                  keyHint: null,\n                  label: \"Expanded\",\n                  leftItem: sidebarCollapsedStateLeft === \"expanded\" ? /* @__PURE__ */ jsx61(Checkmark, {}) : null,\n                  onClick: () => {\n                    closeMenu();\n                    setSidebarCollapsedState({ left: \"expanded\", right: null });\n                  },\n                  subMenu: null,\n                  type: \"item\",\n                  value: \"expanded\",\n                  quickSwitcherLabel: \"Expand\"\n                },\n                {\n                  id: \"left-sidebar-collapsed\",\n                  keyHint: null,\n                  label: \"Collapsed\",\n                  leftItem: sidebarCollapsedStateLeft === \"collapsed\" ? /* @__PURE__ */ jsx61(Checkmark, {}) : null,\n                  onClick: () => {\n                    closeMenu();\n                    setSidebarCollapsedState({\n                      left: \"collapsed\",\n                      right: null\n                    });\n                  },\n                  subMenu: null,\n                  type: \"item\",\n                  value: \"collapsed\",\n                  quickSwitcherLabel: \"Collapse\"\n                }\n              ]\n            },\n            onClick: () => {\n              return;\n            }\n          },\n          {\n            id: \"right-sidebar\",\n            label: \"Right Sidebar\",\n            keyHint: null,\n            type: \"item\",\n            value: \"preview-size\",\n            leftItem: null,\n            quickSwitcherLabel: null,\n            subMenu: {\n              leaveLeftSpace: true,\n              preselectIndex: 0,\n              items: [\n                {\n                  id: \"sidebar-expanded\",\n                  keyHint: null,\n                  label: \"Expanded\",\n                  leftItem: sidebarCollapsedStateRight === \"expanded\" ? /* @__PURE__ */ jsx61(Checkmark, {}) : null,\n                  onClick: () => {\n                    closeMenu();\n                    setSidebarCollapsedState({ left: null, right: \"expanded\" });\n                  },\n                  subMenu: null,\n                  type: \"item\",\n                  value: \"expanded\",\n                  quickSwitcherLabel: \"Expand\"\n                },\n                {\n                  id: \"right-sidebar-collapsed\",\n                  keyHint: null,\n                  label: \"Collapsed\",\n                  leftItem: sidebarCollapsedStateRight === \"collapsed\" ? /* @__PURE__ */ jsx61(Checkmark, {}) : null,\n                  onClick: () => {\n                    closeMenu();\n                    setSidebarCollapsedState({\n                      left: null,\n                      right: \"collapsed\"\n                    });\n                  },\n                  subMenu: null,\n                  type: \"item\",\n                  value: \"collapsed\",\n                  quickSwitcherLabel: \"Collapse\"\n                }\n              ]\n            },\n            onClick: () => {\n              return;\n            }\n          },\n          {\n            id: \"timeline-divider-2\",\n            type: \"divider\"\n          },\n          {\n            id: \"checkerboard\",\n            keyHint: \"T\",\n            label: \"Transparency as checkerboard\",\n            onClick: () => {\n              closeMenu();\n              setCheckerboard((c) => !c);\n            },\n            type: \"item\",\n            value: \"checkerboard\",\n            leftItem: checkerboard ? /* @__PURE__ */ jsx61(Checkmark, {}) : null,\n            subMenu: null,\n            quickSwitcherLabel: checkerboard ? \"Disable Checkerboard Transparency\" : \"Enable Checkerboard Transparency\"\n          },\n          {\n            id: \"timeline-divider-3\",\n            type: \"divider\"\n          },\n          {\n            id: \"quick-switcher\",\n            keyHint: `${cmdOrCtrlCharacter}+K`,\n            label: \"Quick Switcher\",\n            onClick: () => {\n              closeMenu();\n              setSelectedModal({\n                type: \"quick-switcher\",\n                mode: \"compositions\",\n                invocationTimestamp: Date.now()\n              });\n            },\n            type: \"item\",\n            value: \"quick-switcher\",\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Switch composition\"\n          },\n          {\n            id: \"in-out-divider-5\",\n            type: \"divider\"\n          },\n          {\n            id: \"in-mark\",\n            keyHint: \"I\",\n            label: \"In Mark\",\n            leftItem: null,\n            onClick: () => {\n              closeMenu();\n              inOutHandles.current?.inMarkClick(null);\n            },\n            subMenu: null,\n            type: \"item\",\n            value: \"in-mark\",\n            quickSwitcherLabel: \"Timeline: Set In Mark\"\n          },\n          {\n            id: \"out-mark\",\n            keyHint: \"O\",\n            label: \"Out Mark\",\n            leftItem: null,\n            onClick: () => {\n              closeMenu();\n              inOutHandles.current?.outMarkClick(null);\n            },\n            subMenu: null,\n            type: \"item\",\n            value: \"out-mark\",\n            quickSwitcherLabel: \"Timeline: Set Out Mark\"\n          },\n          {\n            id: \"x-mark\",\n            keyHint: \"X\",\n            label: \"Clear In/Out Marks\",\n            leftItem: null,\n            onClick: () => {\n              closeMenu();\n              inOutHandles.current?.clearMarks();\n            },\n            subMenu: null,\n            type: \"item\",\n            value: \"clear-marks\",\n            quickSwitcherLabel: \"Timeline: Clear In and Out Mark\"\n          },\n          {\n            id: \"goto-time\",\n            keyHint: \"G\",\n            label: \"Go to frame\",\n            leftItem: null,\n            onClick: () => {\n              closeMenu();\n              Internals15.timeValueRef.current?.goToFrame();\n            },\n            subMenu: null,\n            type: \"item\",\n            value: \"clear-marks\",\n            quickSwitcherLabel: \"Timeline: Go to frame\"\n          },\n          {\n            id: \"fullscreen-divider\",\n            type: \"divider\"\n          },\n          isFullscreenSupported ? {\n            id: \"fullscreen\",\n            keyHint: null,\n            label: \"Fullscreen\",\n            leftItem: null,\n            onClick: () => {\n              closeMenu();\n              drawRef.current?.requestFullscreen();\n            },\n            subMenu: null,\n            type: \"item\",\n            value: \"fullscreen\",\n            quickSwitcherLabel: \"Go Fullscreen\"\n          } : null\n        ].filter(Internals15.truthy)\n      },\n      {\n        id: \"tools\",\n        label: \"Tools\",\n        leaveLeftPadding: false,\n        items: [\n          process.env.ASK_AI_ENABLED ? {\n            id: \"ask-ai\",\n            value: \"ask-ai\",\n            label: \"Ask AI\",\n            onClick: () => {\n              closeMenu();\n              askAiModalRef.current?.toggle();\n            },\n            leftItem: null,\n            keyHint: `${cmdOrCtrlCharacter}+I`,\n            subMenu: null,\n            type: \"item\",\n            quickSwitcherLabel: \"Ask AI\"\n          } : null,\n          \"EyeDropper\" in window ? {\n            id: \"color-picker\",\n            value: \"color-picker\",\n            label: \"Color Picker\",\n            onClick: () => {\n              closeMenu();\n              pickColor();\n            },\n            leftItem: null,\n            keyHint: null,\n            subMenu: null,\n            type: \"item\",\n            quickSwitcherLabel: \"Show Color Picker\"\n          } : null,\n          {\n            id: \"spring-editor\",\n            value: \"spring-editor\",\n            label: \"Timing Editor\",\n            onClick: () => {\n              closeMenu();\n              window.open(\"https://www.remotion.dev/timing-editor\", \"_blank\");\n            },\n            leftItem: null,\n            keyHint: null,\n            subMenu: null,\n            type: \"item\",\n            quickSwitcherLabel: \"Open spring() Editor\"\n          }\n        ].filter(Internals15.truthy),\n        quickSwitcherLabel: null\n      },\n      readOnlyStudio || remotion_packageManager === \"unknown\" ? null : {\n        id: \"install\",\n        label: \"Packages\",\n        leaveLeftPadding: false,\n        items: [\n          {\n            id: \"install-packages\",\n            value: \"install-packages\",\n            label: \"Install...\",\n            onClick: () => {\n              closeMenu();\n              setSelectedModal({\n                type: \"install-packages\",\n                packageManager: remotion_packageManager\n              });\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: `Install packages`\n          }\n        ]\n      },\n      {\n        id: \"help\",\n        label: \"Help\",\n        leaveLeftPadding: false,\n        items: [\n          {\n            id: \"shortcuts\",\n            value: \"shortcuts\",\n            label: areKeyboardShortcutsDisabled() ? \"Shortcuts (disabled)\" : \"Shortcuts\",\n            onClick: () => {\n              closeMenu();\n              setSelectedModal({\n                type: \"quick-switcher\",\n                mode: \"docs\",\n                invocationTimestamp: Date.now()\n              });\n            },\n            keyHint: \"?\",\n            leftItem: null,\n            subMenu: null,\n            type: \"item\",\n            quickSwitcherLabel: areKeyboardShortcutsDisabled() ? \"Show all Keyboard Shortcuts (disabled)\" : \"Show all Keyboard Shortcuts\"\n          },\n          {\n            id: \"docs\",\n            value: \"docs\",\n            label: \"Docs\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://remotion.dev/docs\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Visit Documentation\"\n          },\n          {\n            id: \"file-issue\",\n            value: \"file-issue\",\n            label: \"File an issue\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://github.com/remotion-dev/remotion/issues/new/choose\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"File GitHub issue\"\n          },\n          {\n            id: \"discord\",\n            value: \"discord\",\n            label: \"Join Discord community\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://discord.com/invite/6VzzNDwUwV\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: null\n          },\n          {\n            id: \"help-divider-6\",\n            type: \"divider\"\n          },\n          {\n            id: \"insta\",\n            value: \"insta\",\n            label: \"Instagram\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://instagram.com/remotion\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Follow Remotion on Instagram\"\n          },\n          {\n            id: \"x\",\n            value: \"x\",\n            label: \"X\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://x.com/remotion\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Follow Remotion on X\"\n          },\n          {\n            id: \"youtube\",\n            value: \"youtube\",\n            label: \"YouTube\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://www.youtube.com/@remotion_dev\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Watch Remotion on YouTube\"\n          },\n          {\n            id: \"linkedin\",\n            value: \"linkedin\",\n            label: \"LinkedIn\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://www.linkedin.com/company/remotion-dev/\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Follow Remotion on LinkedIn\"\n          },\n          {\n            id: \"tiktok\",\n            value: \"tiktok\",\n            label: \"TikTok\",\n            onClick: () => {\n              closeMenu();\n              openExternal(\"https://www.tiktok.com/@remotion\");\n            },\n            type: \"item\",\n            keyHint: null,\n            leftItem: null,\n            subMenu: null,\n            quickSwitcherLabel: \"Follow Remotion on TikTok\"\n          }\n        ]\n      }\n    ].filter(Internals15.truthy);\n    if (mobileLayout) {\n      struct = [\n        {\n          ...struct[0],\n          items: [\n            ...struct.slice(1).map((s) => {\n              return {\n                ...s,\n                keyHint: null,\n                onClick: () => {\n                  return;\n                },\n                type: \"item\",\n                value: s.id,\n                leftItem: null,\n                subMenu: {\n                  items: s.items,\n                  leaveLeftSpace: true,\n                  preselectIndex: 0\n                },\n                quickSwitcherLabel: null\n              };\n            }),\n            ...struct[0].items\n          ]\n        }\n      ];\n    }\n    return struct;\n  }, [\n    readOnlyStudio,\n    closeMenu,\n    type,\n    sizePreselectIndex,\n    sizes,\n    editorZoomGestures,\n    editorShowRulers,\n    editorShowGuides,\n    sidebarCollapsedStateLeft,\n    sidebarCollapsedStateRight,\n    checkerboard,\n    isFullscreenSupported,\n    remotion_packageManager,\n    mobileLayout,\n    size.size,\n    setSize,\n    setEditorZoomGestures,\n    setEditorShowRulers,\n    setEditorShowGuides,\n    setSidebarCollapsedState,\n    setCheckerboard,\n    setSelectedModal\n  ]);\n  return structure;\n};\nvar getItemLabel = (item) => {\n  if (item.quickSwitcherLabel !== null) {\n    return item.quickSwitcherLabel;\n  }\n  if (typeof item.label === \"string\") {\n    return item.label;\n  }\n  return item.label?.toString();\n};\nvar itemToSearchResult = (item, setSelectedModal, prefixes) => {\n  if (item.subMenu) {\n    return item.subMenu.items.map((subItem) => {\n      if (subItem.type === \"divider\") {\n        return null;\n      }\n      return itemToSearchResult(subItem, setSelectedModal, [\n        ...prefixes,\n        getItemLabel(item)\n      ]);\n    }).flat(1).filter(NoReactInternals5.truthy);\n  }\n  return [\n    {\n      type: \"menu-item\",\n      id: item.id,\n      onSelected: () => {\n        setSelectedModal(null);\n        item.onClick(item.id, null);\n      },\n      title: [...prefixes, getItemLabel(item)].join(\": \")\n    }\n  ];\n};\nvar makeSearchResults = (actions, setSelectedModal) => {\n  const items = actions.map((menu) => {\n    return menu.items.map((item) => {\n      if (item.type === \"divider\") {\n        return null;\n      }\n      return itemToSearchResult(item, setSelectedModal, []);\n    });\n  }).flat(Infinity).filter(NoReactInternals5.truthy);\n  return items;\n};\n\n// src/components/Menu/MenuItem.tsx\nimport { PlayerInternals as PlayerInternals8 } from \"@remotion/player\";\nimport { useCallback as useCallback28, useMemo as useMemo38, useRef as useRef18, useState as useState27 } from \"react\";\nimport ReactDOM5 from \"react-dom\";\nimport { jsx as jsx62, jsxs as jsxs23, Fragment as Fragment11 } from \"react/jsx-runtime\";\nvar container15 = {\n  fontSize: 13,\n  color: \"white\",\n  paddingLeft: 10,\n  paddingRight: 10,\n  cursor: \"default\",\n  paddingTop: 8,\n  paddingBottom: 8,\n  userSelect: \"none\",\n  WebkitUserSelect: \"none\",\n  border: \"none\"\n};\nvar MenuItem = ({\n  label: itemName,\n  selected,\n  id,\n  onItemSelected,\n  onItemHovered,\n  onItemQuit,\n  onPreviousMenu,\n  onNextMenu,\n  menu\n}) => {\n  const [hovered, setHovered] = useState27(false);\n  const ref = useRef18(null);\n  const size = PlayerInternals8.useElementSize(ref, {\n    triggerOnWindowResize: true,\n    shouldApplyCssTransforms: true\n  });\n  const { tabIndex, currentZIndex } = useZIndex();\n  const containerStyle2 = useMemo38(() => {\n    return {\n      ...container15,\n      backgroundColor: getBackgroundFromHoverState({\n        hovered,\n        selected\n      })\n    };\n  }, [hovered, selected]);\n  const portalStyle = useMemo38(() => {\n    if (!selected || !size) {\n      return null;\n    }\n    return {\n      ...menuContainerTowardsBottom,\n      left: size.left,\n      top: size.top + size.height\n    };\n  }, [selected, size]);\n  const onPointerEnter = useCallback28(() => {\n    onItemHovered(id);\n    setHovered(true);\n  }, [id, onItemHovered]);\n  const onPointerLeave = useCallback28(() => {\n    setHovered(false);\n  }, []);\n  const onPointerDown = useCallback28((e) => {\n    if (e.button !== 0) {\n      return;\n    }\n    onItemSelected(id);\n    window.addEventListener(\"pointerup\", (evt) => {\n      if (!isMenuItem(evt.target)) {\n        onItemQuit();\n      }\n    }, {\n      once: true\n    });\n  }, [id, onItemQuit, onItemSelected]);\n  const onClick = useCallback28((e) => {\n    e.stopPropagation();\n    const isKeyboardInitiated = e.detail === 0;\n    if (!isKeyboardInitiated) {\n      return;\n    }\n    onItemSelected((p) => {\n      return p === null ? id : null;\n    });\n  }, [id, onItemSelected]);\n  const outerStyle = useMemo38(() => {\n    return {\n      ...outerPortal,\n      top: (size?.top ?? 0) + (size?.height ?? 0)\n    };\n  }, [size]);\n  return /* @__PURE__ */ jsxs23(Fragment11, {\n    children: [\n      /* @__PURE__ */ jsx62(\"button\", {\n        ref,\n        role: \"button\",\n        tabIndex,\n        onPointerEnter,\n        onPointerLeave,\n        onPointerDown,\n        onClick,\n        style: containerStyle2,\n        type: \"button\",\n        className: MENU_INITIATOR_CLASSNAME,\n        children: itemName\n      }),\n      portalStyle ? ReactDOM5.createPortal(/* @__PURE__ */ jsx62(\"div\", {\n        className: \"css-reset\",\n        style: outerStyle,\n        children: /* @__PURE__ */ jsx62(HigherZIndex, {\n          onEscape: onItemQuit,\n          onOutsideClick: onItemQuit,\n          children: /* @__PURE__ */ jsx62(\"div\", {\n            style: portalStyle,\n            children: /* @__PURE__ */ jsx62(MenuContent, {\n              onNextMenu: onPreviousMenu,\n              onPreviousMenu: onNextMenu,\n              values: menu.items,\n              onHide: onItemQuit,\n              leaveLeftSpace: menu.leaveLeftPadding,\n              preselectIndex: false,\n              topItemCanBeUnselected: true,\n              fixedHeight: null\n            })\n          })\n        })\n      }), getPortal(currentZIndex)) : null\n    ]\n  });\n};\n\n// src/components/MenuBuildIndicator.tsx\nimport { useContext as useContext21, useEffect as useEffect24, useState as useState29 } from \"react\";\n\n// src/components/OpenEditorButton.tsx\nimport { useCallback as useCallback29, useMemo as useMemo39, useState as useState28 } from \"react\";\nimport { jsx as jsx63 } from \"react/jsx-runtime\";\nvar svgStyle = {\n  width: 11,\n  height: 11\n};\nvar buttonStyle = {\n  border: \"none\",\n  height: \"20px\",\n  display: \"flex\",\n  paddingInline: \"6px\",\n  justifyContent: \"center\",\n  alignItems: \"center\"\n};\nvar OpenEditorButton = ({ type }) => {\n  const [hovered, setHovered] = useState28(false);\n  const svgFillColor = useMemo39(() => {\n    return hovered ? \"white\" : LIGHT_TEXT;\n  }, [hovered]);\n  const handleClick = useCallback29(async () => {\n    if (type === \"editor\") {\n      await openInEditor({\n        originalFileName: `${window.remotion_cwd}`,\n        originalLineNumber: 1,\n        originalColumnNumber: 1,\n        originalFunctionName: null,\n        originalScriptCode: null\n      }).then((res) => res.json()).then(({ success }) => {\n        if (!success) {\n          showNotification(`Could not open ${window.remotion_editorName}`, 2000);\n        }\n      }).catch((err) => {\n        console.error(err);\n        showNotification(`Could not open ${window.remotion_editorName}`, 2000);\n      });\n    }\n    if (type === \"git\") {\n      if (!window.remotion_gitSource) {\n        throw new Error(\"No git source\");\n      }\n      window.open(getGitSourceBranchUrl(window.remotion_gitSource), \"_blank\");\n    }\n  }, [type]);\n  const buttonTooltip = type === \"git\" ? `Open ${getGitSourceName(window.remotion_gitSource)} Repo` : `Open in ${window.remotion_editorName}`;\n  const openInEditorSvg = /* @__PURE__ */ jsx63(\"svg\", {\n    viewBox: \"0 0 512 512\",\n    style: svgStyle,\n    children: /* @__PURE__ */ jsx63(\"path\", {\n      fill: svgFillColor,\n      d: \"M320 0c-17.7 0-32 14.3-32 32s14.3 32 32 32h82.7L201.4 265.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L448 109.3V192c0 17.7 14.3 32 32 32s32-14.3 32-32V32c0-17.7-14.3-32-32-32H320zM80 32C35.8 32 0 67.8 0 112V432c0 44.2 35.8 80 80 80H400c44.2 0 80-35.8 80-80V320c0-17.7-14.3-32-32-32s-32 14.3-32 32V432c0 8.8-7.2 16-16 16H80c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16H192c17.7 0 32-14.3 32-32s-14.3-32-32-32H80z\"\n    })\n  });\n  const onPointerEnter = useCallback29(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback29(() => {\n    setHovered(false);\n  }, []);\n  return /* @__PURE__ */ jsx63(\"button\", {\n    title: buttonTooltip,\n    type: \"button\",\n    onPointerEnter,\n    onPointerLeave,\n    style: buttonStyle,\n    onClick: handleClick,\n    children: openInEditorSvg\n  });\n};\n\n// src/components/MenuBuildIndicator.tsx\nimport { jsx as jsx64, jsxs as jsxs24 } from \"react/jsx-runtime\";\nvar cwd = {\n  fontSize: 13,\n  opacity: 0.8,\n  display: \"flex\",\n  alignItems: \"center\",\n  justifyContent: \"center\"\n};\nvar spinnerSize = 14;\nvar spinner = {\n  position: \"relative\",\n  width: spinnerSize,\n  marginTop: 4\n};\nvar noSpinner = {\n  position: \"relative\",\n  width: spinnerSize\n};\nvar MenuBuildIndicator = () => {\n  const [isBuilding, setIsBuilding] = useState29(false);\n  const ctx = useContext21(StudioServerConnectionCtx).previewServerState;\n  const showButton = window.remotion_editorName && ctx.type === \"connected\";\n  useEffect24(() => {\n    window.remotion_isBuilding = () => {\n      setIsBuilding(true);\n    };\n    window.remotion_finishedBuilding = () => {\n      setIsBuilding(false);\n    };\n    return () => {\n      window.remotion_isBuilding = undefined;\n      window.remotion_finishedBuilding = undefined;\n    };\n  }, []);\n  return /* @__PURE__ */ jsxs24(\"div\", {\n    style: cwd,\n    title: window.remotion_cwd,\n    children: [\n      showButton ? /* @__PURE__ */ jsx64(Spacing, {\n        x: 2\n      }) : null,\n      isBuilding ? /* @__PURE__ */ jsx64(\"div\", {\n        style: spinner,\n        children: /* @__PURE__ */ jsx64(Spinner, {\n          duration: 0.5,\n          size: spinnerSize\n        })\n      }) : /* @__PURE__ */ jsx64(\"div\", {\n        style: noSpinner\n      }),\n      showButton ? /* @__PURE__ */ jsx64(Spacing, {\n        x: 0.5\n      }) : null,\n      window.remotion_projectName,\n      showButton ? /* @__PURE__ */ jsx64(Spacing, {\n        x: 0.25\n      }) : null,\n      showButton ? /* @__PURE__ */ jsx64(OpenEditorButton, {\n        type: \"editor\"\n      }) : window.remotion_gitSource ? /* @__PURE__ */ jsx64(OpenEditorButton, {\n        type: \"git\"\n      }) : null\n    ]\n  });\n};\n\n// src/components/SidebarCollapserControls.tsx\nimport { useCallback as useCallback91, useContext as useContext59, useEffect as useEffect62 } from \"react\";\n\n// src/components/TopPanel.tsx\nimport { useCallback as useCallback90, useContext as useContext58, useEffect as useEffect61, useMemo as useMemo96 } from \"react\";\n\n// src/helpers/use-breakpoint.ts\nimport { useEffect as useEffect25, useState as useState30 } from \"react\";\nfunction useBreakpoint(breakpoint2) {\n  const [compactUI, setCompactUI] = useState30(window.innerWidth < breakpoint2);\n  useEffect25(() => {\n    function handleResize() {\n      setCompactUI(window.innerWidth < breakpoint2);\n    }\n    window.addEventListener(\"resize\", handleResize);\n    handleResize();\n    return () => window.removeEventListener(\"resize\", handleResize);\n  }, [breakpoint2]);\n  return compactUI;\n}\n\n// src/components/CanvasIfSizeIsAvailable.tsx\nimport { useContext as useContext30, useMemo as useMemo51 } from \"react\";\nimport { Internals as Internals25 } from \"remotion\";\n\n// src/components/CanvasOrLoading.tsx\nimport { useContext as useContext29, useEffect as useEffect36 } from \"react\";\nimport { Internals as Internals24 } from \"remotion\";\n\n// src/error-overlay/remotion-overlay/ErrorLoader.tsx\nimport { useEffect as useEffect31, useState as useState34 } from \"react\";\n\n// src/error-overlay/react-overlay/utils/parser.ts\nimport { getLocationFromBuildError } from \"@remotion/studio-shared\";\n\n// src/error-overlay/react-overlay/effects/resolve-file-source.ts\nvar resolveFileSource = async (location, contextLines) => {\n  const res = await fetch(`/api/file-source?f=${encodeURIComponent(location.fileName)}`);\n  const text = await res.text();\n  const lines2 = text.split(`\n`).map((l, i) => {\n    const oneIndexedLineNumber = i + 1;\n    return [oneIndexedLineNumber, l];\n  }).filter(([oneIndexedLineNumber]) => {\n    return Math.abs(oneIndexedLineNumber - location.lineNumber) <= contextLines;\n  });\n  const scriptCode = lines2.map(([num, line2]) => {\n    return {\n      content: line2,\n      highlight: location.lineNumber === num,\n      lineNumber: num\n    };\n  });\n  return {\n    originalColumnNumber: location.columnNumber,\n    originalFunctionName: null,\n    originalFileName: location.fileName,\n    originalLineNumber: location.lineNumber,\n    originalScriptCode: scriptCode\n  };\n};\n\n// src/error-overlay/react-overlay/utils/make-stack-frame.ts\nvar makeStackFrame = ({\n  functionName,\n  fileName,\n  lineNumber,\n  columnNumber\n}) => {\n  if (functionName && functionName.indexOf(\"Object.\") === 0) {\n    functionName = functionName.slice(\"Object.\".length);\n  }\n  if (functionName === \"friendlySyntaxErrorLabel\" || functionName === \"exports.__esModule\" || functionName === \"<anonymous>\" || !functionName) {\n    functionName = null;\n  }\n  return {\n    columnNumber,\n    fileName,\n    functionName,\n    lineNumber\n  };\n};\n\n// src/error-overlay/react-overlay/utils/parser.ts\nvar regexExtractLocation = /\\(?(.+?)(?::(\\d+))?(?::(\\d+))?\\)?$/;\nfunction extractLocation(token) {\n  const execed = regexExtractLocation.exec(token);\n  if (!execed) {\n    throw new Error(\"Could not match in extractLocation\");\n  }\n  return execed.slice(1).map((v) => {\n    const p = Number(v);\n    if (!isNaN(p)) {\n      return p;\n    }\n    return v;\n  });\n}\nvar regexValidFrame_Chrome = /^\\s*(at|in)\\s.+(:\\d+)/;\nvar regexValidFrame_FireFox = /(^|@)\\S+:\\d+|.+line\\s+\\d+\\s+>\\s+(eval|Function).+/;\nfunction parseStack(stack) {\n  const frames = stack.filter((e) => regexValidFrame_Chrome.test(e) || regexValidFrame_FireFox.test(e)).map((e) => {\n    if (regexValidFrame_FireFox.test(e)) {\n      let isEval = false;\n      if (/ > (eval|Function)/.test(e)) {\n        e = e.replace(/ line (\\d+)(?: > eval line \\d+)* > (eval|Function):\\d+:\\d+/g, \":$1\");\n        isEval = true;\n      }\n      const _data = e.split(/[@]/g);\n      const _last = _data.pop();\n      if (!_last) {\n        throw new Error(\"could not get last\");\n      }\n      const [_fileName, _lineNumber, _columnNumber] = extractLocation(_last);\n      return makeStackFrame({\n        functionName: _data.join(\"@\") || (isEval ? \"eval\" : null),\n        fileName: _fileName,\n        lineNumber: _lineNumber,\n        columnNumber: _columnNumber\n      });\n    }\n    if (e.indexOf(\"(eval \") !== -1) {\n      e = e.replace(/(\\(eval at [^()]*)|(\\),.*$)/g, \"\");\n    }\n    if (e.indexOf(\"(at \") !== -1) {\n      e = e.replace(/\\(at /, \"(\");\n    }\n    const data = e.trim().split(/\\s+/g).slice(1);\n    const last = data.pop();\n    if (!last) {\n      throw new Error(\"could not get last\");\n    }\n    const [fileName, lineNumber, columnNumber] = extractLocation(last);\n    return makeStackFrame({\n      functionName: data.join(\" \") || null,\n      fileName,\n      lineNumber,\n      columnNumber\n    });\n  });\n  return frames;\n}\nvar parseError = async (error, contextLines) => {\n  if (error === null) {\n    throw new Error(\"You cannot pass a null object.\");\n  }\n  if (typeof error === \"string\") {\n    return parseStack(error.split(`\n`)).map((frame) => {\n      return {\n        type: \"transpiled\",\n        frame\n      };\n    });\n  }\n  if (Array.isArray(error)) {\n    return parseStack(error).map((frame) => {\n      return {\n        type: \"transpiled\",\n        frame\n      };\n    });\n  }\n  const errorLocation = getLocationFromBuildError(error);\n  if (errorLocation) {\n    return [\n      {\n        type: \"symbolicated\",\n        frame: await resolveFileSource(errorLocation, contextLines)\n      }\n    ];\n  }\n  if (typeof error.stack === \"string\") {\n    return parseStack(error.stack.split(`\n`)).map((frame) => {\n      return {\n        type: \"transpiled\",\n        frame\n      };\n    });\n  }\n  return [];\n};\n\n// src/error-overlay/react-overlay/utils/unmapper.ts\nimport { Internals as Internals16 } from \"remotion\";\n\n// src/error-overlay/react-overlay/utils/get-lines-around.ts\nfunction getLinesAround(line2, count, lines2) {\n  const result = [];\n  for (let index = Math.max(0, line2 - 1 - count);index <= Math.min(lines2.length - 1, line2 - 1 + count); ++index) {\n    result.push({\n      lineNumber: index + 1,\n      content: lines2[index],\n      highlight: index === line2 - 1\n    });\n  }\n  return result;\n}\n\n// src/error-overlay/react-overlay/utils/get-source-map.ts\nimport { SourceMapConsumer } from \"source-map\";\nvar getOriginalPosition = (source_map, line2, column) => {\n  const result = source_map.originalPositionFor({\n    line: line2,\n    column\n  });\n  return { line: result.line, column: result.column, source: result.source };\n};\nfunction extractSourceMapUrl(fileContents) {\n  const regex = /\\/\\/[#@] ?sourceMappingURL=([^\\s'\"]+)\\s*$/gm;\n  let match = null;\n  for (;; ) {\n    const next = regex.exec(fileContents);\n    if (next == null) {\n      break;\n    }\n    match = next;\n  }\n  if (!match?.[1]) {\n    return null;\n  }\n  return match[1].toString();\n}\nasync function getSourceMap(fileUri, fileContents) {\n  const sm = extractSourceMapUrl(fileContents);\n  if (sm === null) {\n    return null;\n  }\n  if (sm.indexOf(\"data:\") === 0) {\n    const base64 = /^data:application\\/json;([\\w=:\"-]+;)*base64,/;\n    const match2 = sm.match(base64);\n    if (!match2) {\n      throw new Error(\"Sorry, non-base64 inline source-map encoding is not supported.\");\n    }\n    const converted = window.atob(sm.substring(match2[0].length));\n    return new SourceMapConsumer(JSON.parse(converted));\n  }\n  const index = fileUri.lastIndexOf(\"/\");\n  const url = fileUri.substring(0, index + 1) + sm;\n  const obj = await fetch(url).then((res) => res.json());\n  return new SourceMapConsumer(obj);\n}\n\n// src/error-overlay/react-overlay/utils/unmapper.ts\nvar getFileContents = async (fileName) => {\n  const res = await fetch(fileName);\n  const fileContents = await res.text();\n  return fileContents;\n};\nvar unmap = async (frames, contextLines) => {\n  const transpiled = frames.filter((s) => s.type === \"transpiled\").map((s) => s.frame);\n  const uniqueFileNames = [\n    ...new Set(transpiled.map((f) => f.fileName).filter(Internals16.truthy))\n  ];\n  const maps = await Promise.all(uniqueFileNames.map(async (fileName) => {\n    const fileContents = await getFileContents(fileName);\n    return getSourceMap(fileName, fileContents);\n  }));\n  const mapValues = {};\n  for (let i = 0;i < uniqueFileNames.length; i++) {\n    mapValues[uniqueFileNames[i]] = maps[i];\n  }\n  return frames.map((frame) => {\n    if (frame.type === \"symbolicated\") {\n      return frame.frame;\n    }\n    const map = mapValues[frame.frame.fileName];\n    if (!map) {\n      return null;\n    }\n    const pos = getOriginalPosition(map, frame.frame.lineNumber, frame.frame.columnNumber);\n    const { functionName } = frame.frame;\n    let hasSource = null;\n    hasSource = pos.source ? map.sourceContentFor(pos.source, false) : null;\n    const scriptCode = hasSource && pos.line ? getLinesAround(pos.line, contextLines, hasSource.split(`\n`)) : null;\n    return {\n      originalColumnNumber: pos.column,\n      originalFileName: pos.source,\n      originalFunctionName: functionName,\n      originalLineNumber: pos.line,\n      originalScriptCode: scriptCode\n    };\n  }).filter(Internals16.truthy);\n};\n\n// src/error-overlay/react-overlay/utils/get-stack-frames.ts\nvar getStackFrames = async (error, contextSize) => {\n  const parsedFrames = await parseError(error, contextSize);\n  const enhancedFrames = await unmap(parsedFrames, contextSize);\n  if (enhancedFrames.map((f) => f.originalFileName).filter((f_1) => f_1 !== null && f_1 !== undefined).length === 0) {\n    return null;\n  }\n  return enhancedFrames;\n};\n\n// src/error-overlay/react-overlay/listen-to-runtime-errors.ts\nvar CONTEXT_SIZE = 3;\nvar getErrorRecord = async (error) => {\n  const stackFrames = await getStackFrames(error, CONTEXT_SIZE);\n  if (stackFrames === null || stackFrames === undefined) {\n    return null;\n  }\n  return {\n    error,\n    contextSize: CONTEXT_SIZE,\n    stackFrames\n  };\n};\n\n// src/error-overlay/remotion-overlay/ErrorDisplay.tsx\nimport { getLocationFromBuildError as getLocationFromBuildError2 } from \"@remotion/studio-shared\";\nimport { useMemo as useMemo44 } from \"react\";\n\n// src/error-overlay/remotion-overlay/AskOnDiscord.tsx\nimport { useCallback as useCallback30, useEffect as useEffect26 } from \"react\";\n\n// src/components/Button.tsx\nimport { forwardRef as forwardRef3, useMemo as useMemo40 } from \"react\";\nimport { jsx as jsx65 } from \"react/jsx-runtime\";\nvar button = {\n  border: `1px solid ${INPUT_BORDER_COLOR_UNHOVERED}`,\n  borderRadius: 4,\n  backgroundColor: INPUT_BACKGROUND,\n  appearance: \"none\",\n  fontFamily: \"inherit\",\n  fontSize: 14,\n  color: \"white\",\n  flexDirection: \"row\"\n};\nvar ButtonRefForwardFunction = ({\n  children,\n  onClick,\n  title: title2,\n  disabled,\n  style: style4,\n  id,\n  autoFocus,\n  buttonContainerStyle\n}, ref) => {\n  const combined = useMemo40(() => {\n    return {\n      ...button,\n      ...style4 ?? {}\n    };\n  }, [style4]);\n  const buttonContainer = useMemo40(() => {\n    return {\n      padding: 10,\n      cursor: disabled ? \"inherit\" : \"pointer\",\n      fontSize: 14,\n      opacity: disabled ? 0.7 : 1,\n      ...buttonContainerStyle ?? {}\n    };\n  }, [buttonContainerStyle, disabled]);\n  return /* @__PURE__ */ jsx65(\"button\", {\n    ref,\n    id,\n    style: combined,\n    type: \"button\",\n    disabled,\n    onClick,\n    autoFocus,\n    title: title2,\n    children: /* @__PURE__ */ jsx65(\"div\", {\n      className: \"css-reset\",\n      style: buttonContainer,\n      children\n    })\n  });\n};\nvar Button = forwardRef3(ButtonRefForwardFunction);\n\n// src/error-overlay/remotion-overlay/AskOnDiscord.tsx\nimport { jsx as jsx66, jsxs as jsxs25 } from \"react/jsx-runtime\";\nvar DISCORD_LINK = \"https://remotion.dev/discord\";\nvar AskOnDiscord = ({ canHaveKeyboardShortcuts }) => {\n  const openInBrowser = useCallback30(() => {\n    window.open(DISCORD_LINK, \"_blank\");\n  }, []);\n  const { registerKeybinding } = useKeybinding();\n  useEffect26(() => {\n    if (!canHaveKeyboardShortcuts) {\n      return;\n    }\n    const onEditor = () => {\n      openInBrowser();\n    };\n    const { unregister } = registerKeybinding({\n      event: \"keydown\",\n      key: \"d\",\n      callback: onEditor,\n      commandCtrlKey: true,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => unregister();\n  }, [canHaveKeyboardShortcuts, openInBrowser, registerKeybinding]);\n  return /* @__PURE__ */ jsxs25(Button, {\n    onClick: openInBrowser,\n    children: [\n      \"Ask on Discord\",\n      \" \",\n      canHaveKeyboardShortcuts ? /* @__PURE__ */ jsx66(ShortcutHint, {\n        keyToPress: \"d\",\n        cmdOrCtrl: true\n      }) : null\n    ]\n  });\n};\n\n// src/error-overlay/remotion-overlay/CalculateMetadataErrorExplainer.tsx\nimport { jsx as jsx67, jsxs as jsxs26 } from \"react/jsx-runtime\";\nvar CalculateMetadataErrorExplainer = () => {\n  return /* @__PURE__ */ jsxs26(\"div\", {\n    style: style4,\n    children: [\n      \"This error occured while calling\",\n      \" \",\n      /* @__PURE__ */ jsx67(\"code\", {\n        style: inlineCodeSnippet,\n        children: \"calculateMetadata()\"\n      }),\n      \".\"\n    ]\n  });\n};\nvar style4 = {\n  borderRadius: 3,\n  color: \"white\",\n  padding: 12,\n  backgroundColor: BORDER_COLOR,\n  fontSize: 14,\n  fontFamily: \"sans-serif\"\n};\n\n// src/error-overlay/remotion-overlay/CompositionIdsDropdown.tsx\nimport { useEffect as useEffect27, useMemo as useMemo41, useRef as useRef19, useState as useState31 } from \"react\";\n\n// src/error-overlay/remotion-overlay/CompositionIdListItem.tsx\nimport React45 from \"react\";\nimport { jsx as jsx68 } from \"react/jsx-runtime\";\nvar listItemStyle = {\n  padding: 8,\n  cursor: \"pointer\",\n  borderRadius: 4,\n  lineHeight: 1.4,\n  color: TEXT_COLOR,\n  fontFamily: \"inherit\",\n  fontSize: 14\n};\nvar listItemActiveStyle = {\n  backgroundColor: SELECTED_BACKGROUND\n};\nvar listItemHoverStyle = {\n  backgroundColor: CLEAR_HOVER\n};\nvar CompositionIdListItem = ({ id, isActive, onSelect }) => {\n  const [hover, setHover] = React45.useState(false);\n  return /* @__PURE__ */ jsx68(\"div\", {\n    role: \"button\",\n    onPointerEnter: () => setHover(true),\n    onPointerLeave: () => setHover(false),\n    onClick: () => onSelect(id),\n    style: {\n      ...listItemStyle,\n      ...hover ? listItemHoverStyle : {},\n      ...isActive ? listItemActiveStyle : {}\n    },\n    title: id,\n    children: id\n  });\n};\n\n// src/error-overlay/remotion-overlay/carets.tsx\nimport { jsx as jsx69 } from \"react/jsx-runtime\";\nvar CaretRight2 = ({ size }) => {\n  return /* @__PURE__ */ jsx69(\"svg\", {\n    style: { height: size ?? 20 },\n    \"aria-hidden\": \"true\",\n    focusable: \"false\",\n    role: \"img\",\n    viewBox: \"0 0 192 512\",\n    children: /* @__PURE__ */ jsx69(\"path\", {\n      fill: \"currentColor\",\n      d: \"M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z\"\n    })\n  });\n};\nvar CaretDown2 = ({ invert, size }) => {\n  return /* @__PURE__ */ jsx69(\"svg\", {\n    \"aria-hidden\": \"true\",\n    focusable: \"false\",\n    role: \"img\",\n    xmlns: \"http://www.w3.org/2000/svg\",\n    viewBox: \"0 0 320 512\",\n    style: { height: size ?? 20, transform: invert ? `rotate(180deg)` : \"\" },\n    children: /* @__PURE__ */ jsx69(\"path\", {\n      fill: \"currentColor\",\n      d: \"M31.3 192h257.3c17.8 0 26.7 21.5 14.1 34.1L174.1 354.8c-7.8 7.8-20.5 7.8-28.3 0L17.2 226.1C4.6 213.5 13.5 192 31.3 192z\"\n    })\n  });\n};\n\n// src/error-overlay/remotion-overlay/CompositionIdsDropdown.tsx\nimport { jsx as jsx70, jsxs as jsxs27 } from \"react/jsx-runtime\";\nvar containerStyle2 = {\n  display: \"inline-block\",\n  position: \"relative\"\n};\nvar dropdownStyle = {\n  position: \"absolute\",\n  top: \"110%\",\n  left: 0,\n  width: 320,\n  maxHeight: 300,\n  overflowY: \"auto\",\n  backgroundColor: INPUT_BACKGROUND,\n  border: `1px solid ${INPUT_BORDER_COLOR_UNHOVERED}`,\n  borderRadius: 8,\n  padding: 8,\n  boxShadow: \"0 6px 24px rgba(0,0,0,0.35)\",\n  zIndex: 1000,\n  fontFamily: \"inherit\",\n  fontSize: 14\n};\nvar searchStyle = {\n  width: \"100%\",\n  padding: \"6px 8px\",\n  borderRadius: 6,\n  border: `1px solid ${INPUT_BORDER_COLOR_UNHOVERED}`,\n  background: INPUT_BACKGROUND,\n  color: TEXT_COLOR,\n  marginBottom: 8,\n  outline: \"none\",\n  fontFamily: \"inherit\",\n  fontSize: 14\n};\nvar CompositionIdsDropdown = ({ compositionIds, currentId }) => {\n  const [open, setOpen] = useState31(false);\n  const [query, setQuery] = useState31(\"\");\n  const containerRef = useRef19(null);\n  const filtered = useMemo41(() => {\n    const q = query.trim().toLowerCase();\n    if (!q) {\n      return compositionIds;\n    }\n    return compositionIds.filter((id) => id.toLowerCase().includes(q));\n  }, [compositionIds, query]);\n  const onSelect = (id) => {\n    const isQuery = window.remotion_isReadOnlyStudio;\n    if (isQuery) {\n      window.location.href = `${window.location.pathname}?/${id}`;\n    } else {\n      window.location.href = `/${id}`;\n    }\n  };\n  useEffect27(() => {\n    if (!open) {\n      return;\n    }\n    const onClickAway = (e) => {\n      if (!containerRef.current) {\n        return;\n      }\n      if (!containerRef.current.contains(e.target)) {\n        setOpen(false);\n      }\n    };\n    const onKey = (e) => {\n      if (e.key === \"Escape\") {\n        setOpen(false);\n      }\n    };\n    document.addEventListener(\"mousedown\", onClickAway);\n    document.addEventListener(\"touchstart\", onClickAway, { passive: true });\n    document.addEventListener(\"keydown\", onKey);\n    return () => {\n      document.removeEventListener(\"mousedown\", onClickAway);\n      document.removeEventListener(\"touchstart\", onClickAway);\n      document.removeEventListener(\"keydown\", onKey);\n    };\n  }, [open, containerRef]);\n  return /* @__PURE__ */ jsxs27(\"div\", {\n    ref: containerRef,\n    style: containerStyle2,\n    children: [\n      /* @__PURE__ */ jsxs27(Button, {\n        onClick: () => setOpen((p) => !p),\n        buttonContainerStyle: {\n          display: \"flex\",\n          alignItems: \"center\",\n          justifyContent: \"space-between\",\n          gap: 8,\n          minWidth: 180\n        },\n        children: [\n          /* @__PURE__ */ jsx70(\"span\", {\n            style: {\n              overflow: \"hidden\",\n              textOverflow: \"ellipsis\",\n              whiteSpace: \"nowrap\",\n              fontSize: \"14px\",\n              lineHeight: \"24px\"\n            },\n            children: currentId ?? \"Select composition\"\n          }),\n          /* @__PURE__ */ jsx70(CaretDown2, {\n            size: 20,\n            invert: open\n          })\n        ]\n      }),\n      open ? /* @__PURE__ */ jsxs27(\"div\", {\n        style: dropdownStyle,\n        children: [\n          /* @__PURE__ */ jsx70(\"input\", {\n            value: query,\n            onChange: (e) => setQuery(e.target.value),\n            placeholder: \"Search compositions...\",\n            style: searchStyle,\n            \"aria-label\": \"Search compositions\"\n          }),\n          /* @__PURE__ */ jsx70(\"div\", {\n            children: filtered.length === 0 ? /* @__PURE__ */ jsx70(\"div\", {\n              style: { opacity: 0.7, padding: 8, textAlign: \"center\" },\n              children: \"No compositions found\"\n            }) : filtered.map((id) => /* @__PURE__ */ jsx70(CompositionIdListItem, {\n              id,\n              isActive: id === currentId,\n              onSelect\n            }, id))\n          })\n        ]\n      }) : null\n    ]\n  });\n};\n\n// src/error-overlay/react-overlay/index.ts\nimport { Internals as Internals17 } from \"remotion\";\nvar didUnmountReactApp = () => {\n  return !Internals17.getPreviewDomElement()?.hasChildNodes();\n};\n\n// src/error-overlay/remotion-overlay/DismissButton.tsx\nimport { useCallback as useCallback31 } from \"react\";\nimport { jsx as jsx71 } from \"react/jsx-runtime\";\nvar size = {\n  height: 20,\n  width: 20\n};\nvar style5 = {\n  appearance: \"none\",\n  WebkitAppearance: \"none\",\n  backgroundColor: \"transparent\",\n  border: \"none\",\n  cursor: \"pointer\"\n};\nvar DismissButton = () => {\n  const dismiss = useCallback31(() => {\n    clearUrl();\n  }, []);\n  return /* @__PURE__ */ jsx71(\"button\", {\n    type: \"button\",\n    style: style5,\n    onClick: dismiss,\n    children: /* @__PURE__ */ jsx71(\"svg\", {\n      focusable: \"false\",\n      role: \"img\",\n      xmlns: \"http://www.w3.org/2000/svg\",\n      viewBox: \"0 0 352 512\",\n      style: size,\n      children: /* @__PURE__ */ jsx71(\"path\", {\n        fill: \"white\",\n        d: \"M242.72 256l100.07-100.07c12.28-12.28 12.28-32.19 0-44.48l-22.24-22.24c-12.28-12.28-32.19-12.28-44.48 0L176 189.28 75.93 89.21c-12.28-12.28-32.19-12.28-44.48 0L9.21 111.45c-12.28 12.28-12.28 32.19 0 44.48L109.28 256 9.21 356.07c-12.28 12.28-12.28 32.19 0 44.48l22.24 22.24c12.28 12.28 32.2 12.28 44.48 0L176 322.72l100.07 100.07c12.28 12.28 32.2 12.28 44.48 0l22.24-22.24c12.28-12.28 12.28-32.19 0-44.48L242.72 256z\"\n      })\n    })\n  });\n};\n\n// src/error-overlay/remotion-overlay/ErrorMessage.tsx\nimport { PlayerInternals as PlayerInternals9 } from \"@remotion/player\";\nimport { useCallback as useCallback32, useMemo as useMemo42, useRef as useRef20, useState as useState32 } from \"react\";\nimport { jsx as jsx72, jsxs as jsxs28 } from \"react/jsx-runtime\";\nvar fontSize = 24;\nvar lineHeight = 1.5;\nvar maxLines = 2;\nvar buttonSize = 32;\nvar maskImage = \"linear-gradient(to bottom, white 60%, transparent)\";\nvar container16 = {\n  position: \"relative\",\n  marginBottom: 15\n};\nvar messageContainer = {\n  overflow: \"hidden\"\n};\nvar textContainer = {\n  fontSize,\n  lineHeight\n};\nvar moreLine = {\n  width: \"100%\",\n  display: \"flex\",\n  justifyContent: \"center\",\n  position: \"absolute\",\n  border: `1px solid ${INPUT_BORDER_COLOR_HOVERED}`,\n  height: 0,\n  marginTop: 4\n};\nvar moreButton = {\n  height: buttonSize,\n  width: buttonSize,\n  borderRadius: buttonSize / 2,\n  backgroundColor: INPUT_BACKGROUND,\n  border: `1px solid ${INPUT_BORDER_COLOR_UNHOVERED}`,\n  marginTop: -buttonSize / 2,\n  display: \"flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  cursor: \"pointer\",\n  color: \"white\"\n};\nvar ErrorMessage = ({ message }) => {\n  const [expanded, setExpanded] = useState32(false);\n  const ref = useRef20(null);\n  const size2 = PlayerInternals9.useElementSize(ref, {\n    shouldApplyCssTransforms: false,\n    triggerOnWindowResize: true\n  });\n  const errorLines = size2 ? size2.height / (lineHeight * fontSize) : null;\n  const style6 = useMemo42(() => {\n    const isExpanded = expanded || errorLines !== null && errorLines <= maxLines;\n    return {\n      ...messageContainer,\n      maxHeight: isExpanded ? undefined : fontSize * lineHeight * maxLines,\n      maskImage: isExpanded ? undefined : maskImage,\n      WebkitMaskImage: isExpanded ? undefined : maskImage\n    };\n  }, [errorLines, expanded]);\n  const toggle = useCallback32(() => {\n    setExpanded((e) => !e);\n  }, []);\n  return /* @__PURE__ */ jsxs28(\"div\", {\n    style: container16,\n    children: [\n      /* @__PURE__ */ jsx72(\"div\", {\n        style: style6,\n        children: /* @__PURE__ */ jsx72(\"div\", {\n          ref,\n          style: textContainer,\n          children: message\n        })\n      }),\n      errorLines !== null && errorLines > maxLines ? /* @__PURE__ */ jsx72(\"div\", {\n        style: moreLine,\n        children: /* @__PURE__ */ jsx72(\"button\", {\n          type: \"button\",\n          onClick: toggle,\n          style: moreButton,\n          children: /* @__PURE__ */ jsx72(CaretDown2, {\n            invert: expanded\n          })\n        })\n      }) : null\n    ]\n  });\n};\n\n// src/error-overlay/remotion-overlay/Symbolicating.tsx\nimport { jsx as jsx73, jsxs as jsxs29 } from \"react/jsx-runtime\";\nvar Symbolicating = (props) => {\n  return /* @__PURE__ */ jsxs29(\"svg\", {\n    id: \"loading\",\n    xmlns: \"http://www.w3.org/2000/svg\",\n    viewBox: \"0 0 32 32\",\n    width: \"16\",\n    height: \"16\",\n    fill: \"white\",\n    ...props,\n    children: [\n      /* @__PURE__ */ jsx73(\"path\", {\n        opacity: \".1\",\n        d: \"M14 0 H18 V8 H14 z\",\n        transform: \"rotate(0 16 16)\",\n        children: /* @__PURE__ */ jsx73(\"animate\", {\n          attributeName: \"opacity\",\n          from: \"1\",\n          to: \".1\",\n          dur: \"1s\",\n          repeatCount: \"indefinite\",\n          begin: \"0\"\n        })\n      }),\n      /* @__PURE__ */ jsx73(\"path\", {\n        opacity: \".1\",\n        d: \"M14 0 H18 V8 H14 z\",\n        transform: \"rotate(45 16 16)\",\n        children: /* @__PURE__ */ jsx73(\"animate\", {\n          attributeName: \"opacity\",\n          from: \"1\",\n          to: \".1\",\n          dur: \"1s\",\n          repeatCount: \"indefinite\",\n          begin: \"0.125s\"\n        })\n      }),\n      /* @__PURE__ */ jsx73(\"path\", {\n        opacity: \".1\",\n        d: \"M14 0 H18 V8 H14 z\",\n        transform: \"rotate(90 16 16)\",\n        children: /* @__PURE__ */ jsx73(\"animate\", {\n          attributeName: \"opacity\",\n          from: \"1\",\n          to: \".1\",\n          dur: \"1s\",\n          repeatCount: \"indefinite\",\n          begin: \"0.25s\"\n        })\n      }),\n      /* @__PURE__ */ jsx73(\"path\", {\n        opacity: \".1\",\n        d: \"M14 0 H18 V8 H14 z\",\n        transform: \"rotate(135 16 16)\",\n        children: /* @__PURE__ */ jsx73(\"animate\", {\n          attributeName: \"opacity\",\n          from: \"1\",\n          to: \".1\",\n          dur: \"1s\",\n          repeatCount: \"indefinite\",\n          begin: \"0.375s\"\n        })\n      }),\n      /* @__PURE__ */ jsx73(\"path\", {\n        opacity: \".1\",\n        d: \"M14 0 H18 V8 H14 z\",\n        transform: \"rotate(180 16 16)\",\n        children: /* @__PURE__ */ jsx73(\"animate\", {\n          attributeName: \"opacity\",\n          from: \"1\",\n          to: \".1\",\n          dur: \"1s\",\n          repeatCount: \"indefinite\",\n          begin: \"0.5s\"\n        })\n      }),\n      /* @__PURE__ */ jsx73(\"path\", {\n        opacity: \".1\",\n        d: \"M14 0 H18 V8 H14 z\",\n        transform: \"rotate(225 16 16)\",\n        children: /* @__PURE__ */ jsx73(\"animate\", {\n          attributeName: \"opacity\",\n          from: \"1\",\n          to: \".1\",\n          dur: \"1s\",\n          repeatCount: \"indefinite\",\n          begin: \"0.675s\"\n        })\n      }),\n      /* @__PURE__ */ jsx73(\"path\", {\n        opacity: \".1\",\n        d: \"M14 0 H18 V8 H14 z\",\n        transform: \"rotate(270 16 16)\",\n        children: /* @__PURE__ */ jsx73(\"animate\", {\n          attributeName: \"opacity\",\n          from: \"1\",\n          to: \".1\",\n          dur: \"1s\",\n          repeatCount: \"indefinite\",\n          begin: \"0.75s\"\n        })\n      }),\n      /* @__PURE__ */ jsx73(\"path\", {\n        opacity: \".1\",\n        d: \"M14 0 H18 V8 H14 z\",\n        transform: \"rotate(315 16 16)\",\n        children: /* @__PURE__ */ jsx73(\"animate\", {\n          attributeName: \"opacity\",\n          from: \"1\",\n          to: \".1\",\n          dur: \"1s\",\n          repeatCount: \"indefinite\",\n          begin: \"0.875s\"\n        })\n      })\n    ]\n  });\n};\n\n// src/error-overlay/remotion-overlay/ErrorTitle.tsx\nimport { jsx as jsx74, jsxs as jsxs30, Fragment as Fragment12 } from \"react/jsx-runtime\";\nvar title2 = {\n  marginBottom: 8,\n  display: \"flex\",\n  flexDirection: \"row\",\n  justifyContent: \"center\"\n};\nvar left = {\n  flex: 1,\n  paddingRight: 14,\n  fontWeight: \"bold\",\n  maxWidth: \"100%\"\n};\nvar errName = {\n  fontSize: 18,\n  color: BLUE,\n  display: \"inline-block\"\n};\nvar row2 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar spacer = {\n  width: 5\n};\nvar ErrorTitle = ({ name, message, symbolicating, canHaveDismissButton }) => {\n  return /* @__PURE__ */ jsxs30(\"div\", {\n    style: title2,\n    className: \"css-reset\",\n    children: [\n      /* @__PURE__ */ jsxs30(\"div\", {\n        style: left,\n        children: [\n          /* @__PURE__ */ jsx74(\"span\", {\n            style: errName,\n            children: name\n          }),\n          /* @__PURE__ */ jsx74(\"br\", {}),\n          /* @__PURE__ */ jsxs30(\"div\", {\n            style: row2,\n            children: [\n              symbolicating ? /* @__PURE__ */ jsxs30(Fragment12, {\n                children: [\n                  /* @__PURE__ */ jsx74(Symbolicating, {}),\n                  /* @__PURE__ */ jsx74(\"div\", {\n                    style: spacer\n                  })\n                ]\n              }) : null,\n              /* @__PURE__ */ jsx74(ErrorMessage, {\n                message\n              })\n            ]\n          })\n        ]\n      }),\n      didUnmountReactApp() ? null : canHaveDismissButton ? /* @__PURE__ */ jsx74(DismissButton, {}) : null\n    ]\n  });\n};\n\n// src/error-overlay/remotion-overlay/HelpLink.tsx\nimport { useCallback as useCallback33, useEffect as useEffect28 } from \"react\";\nimport { jsx as jsx75, jsxs as jsxs31 } from \"react/jsx-runtime\";\nvar buttonStyle2 = {\n  backgroundColor: BLUE,\n  color: \"white\"\n};\nvar HelpLink = ({ canHaveKeyboardShortcuts, link }) => {\n  const openLink = useCallback33(() => {\n    window.open(link.url, \"_blank\");\n  }, [link]);\n  const { registerKeybinding } = useKeybinding();\n  useEffect28(() => {\n    if (!canHaveKeyboardShortcuts) {\n      return;\n    }\n    const onEditor = () => {\n      openLink();\n    };\n    const { unregister } = registerKeybinding({\n      event: \"keydown\",\n      key: \"h\",\n      callback: onEditor,\n      commandCtrlKey: true,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => unregister();\n  }, [canHaveKeyboardShortcuts, openLink, registerKeybinding]);\n  return /* @__PURE__ */ jsxs31(Button, {\n    style: buttonStyle2,\n    onClick: openLink,\n    children: [\n      \"Help: \",\n      '\"',\n      link.title,\n      '\"',\n      canHaveKeyboardShortcuts ? /* @__PURE__ */ jsx75(ShortcutHint, {\n        keyToPress: \"h\",\n        cmdOrCtrl: true\n      }) : null\n    ]\n  });\n};\n\n// src/error-overlay/remotion-overlay/OpenInEditor.tsx\nimport {\n  useCallback as useCallback34,\n  useEffect as useEffect29,\n  useMemo as useMemo43,\n  useReducer,\n  useRef as useRef21\n} from \"react\";\nimport { jsx as jsx76, jsxs as jsxs32 } from \"react/jsx-runtime\";\nvar initialState = { type: \"idle\" };\nvar reducer = (state, action) => {\n  if (action.type === \"start\") {\n    return {\n      type: \"load\"\n    };\n  }\n  if (action.type === \"fail\") {\n    return {\n      type: \"error\"\n    };\n  }\n  if (action.type === \"reset\") {\n    return {\n      type: \"idle\"\n    };\n  }\n  if (action.type === \"succeed\") {\n    return {\n      type: \"success\"\n    };\n  }\n  return state;\n};\nvar OpenInEditor = ({ stack, canHaveKeyboardShortcuts }) => {\n  const isMounted = useRef21(true);\n  const [state, dispatch] = useReducer(reducer, initialState);\n  const { registerKeybinding } = useKeybinding();\n  const dispatchIfMounted = useCallback34((payload) => {\n    if (isMounted.current === false)\n      return;\n    dispatch(payload);\n  }, []);\n  const openInBrowser = useCallback34(() => {\n    dispatch({ type: \"start\" });\n    openInEditor(stack).then((res) => res.json()).then((data) => {\n      if (data.success) {\n        dispatchIfMounted({ type: \"succeed\" });\n      } else {\n        dispatchIfMounted({ type: \"fail\" });\n      }\n    }).catch((err) => {\n      dispatchIfMounted({ type: \"fail\" });\n      console.log(\"Could not open browser\", err);\n    }).finally(() => {\n      setTimeout(() => {\n        dispatchIfMounted({ type: \"reset\" });\n      }, 2000);\n    });\n  }, [dispatchIfMounted, stack]);\n  useEffect29(() => {\n    return () => {\n      isMounted.current = false;\n    };\n  }, []);\n  useEffect29(() => {\n    if (!canHaveKeyboardShortcuts) {\n      return;\n    }\n    const onEditor = () => {\n      openInBrowser();\n    };\n    const { unregister } = registerKeybinding({\n      event: \"keydown\",\n      key: \"o\",\n      callback: onEditor,\n      commandCtrlKey: true,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => unregister();\n  }, [canHaveKeyboardShortcuts, openInBrowser, registerKeybinding]);\n  const label4 = useMemo43(() => {\n    switch (state.type) {\n      case \"error\":\n        return \"Failed to open\";\n      case \"idle\":\n        return `Open in ${window.remotion_editorName}`;\n      case \"success\":\n        return `Opened in ${window.remotion_editorName}`;\n      case \"load\":\n        return `Opening...`;\n      default:\n        throw new Error(\"invalid state\");\n    }\n  }, [state.type]);\n  return /* @__PURE__ */ jsxs32(Button, {\n    onClick: openInBrowser,\n    disabled: state.type !== \"idle\",\n    children: [\n      label4,\n      canHaveKeyboardShortcuts ? /* @__PURE__ */ jsx76(ShortcutHint, {\n        keyToPress: \"o\",\n        cmdOrCtrl: true\n      }) : null\n    ]\n  });\n};\n\n// src/error-overlay/remotion-overlay/Retry.tsx\nimport { jsx as jsx77 } from \"react/jsx-runtime\";\nvar RetryButton = ({ onClick }) => {\n  return /* @__PURE__ */ jsx77(Button, {\n    onClick,\n    children: \"Retry calculateMetadata()\"\n  });\n};\n\n// src/error-overlay/remotion-overlay/SearchGitHubIssues.tsx\nimport { useCallback as useCallback35, useEffect as useEffect30 } from \"react\";\nimport { jsx as jsx78, jsxs as jsxs33 } from \"react/jsx-runtime\";\nvar SearchGithubIssues = ({ message, canHaveKeyboardShortcuts }) => {\n  const openInBrowser = useCallback35(() => {\n    window.open(`https://github.com/remotion-dev/remotion/issues?q=${encodeURIComponent(message)}`, \"_blank\");\n  }, [message]);\n  const { registerKeybinding } = useKeybinding();\n  useEffect30(() => {\n    if (!canHaveKeyboardShortcuts) {\n      return;\n    }\n    const onEditor = () => {\n      openInBrowser();\n    };\n    const { unregister } = registerKeybinding({\n      event: \"keydown\",\n      key: \"g\",\n      callback: onEditor,\n      commandCtrlKey: true,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => unregister();\n  }, [canHaveKeyboardShortcuts, openInBrowser, registerKeybinding]);\n  return /* @__PURE__ */ jsxs33(Button, {\n    onClick: openInBrowser,\n    children: [\n      \"Search GitHub Issues\",\n      \" \",\n      canHaveKeyboardShortcuts ? /* @__PURE__ */ jsx78(ShortcutHint, {\n        keyToPress: \"g\",\n        cmdOrCtrl: true\n      }) : null\n    ]\n  });\n};\n\n// src/error-overlay/remotion-overlay/StackFrame.tsx\nimport { useCallback as useCallback36, useState as useState33 } from \"react\";\n\n// src/error-overlay/remotion-overlay/CodeFrame.tsx\nimport { jsx as jsx79, jsxs as jsxs34 } from \"react/jsx-runtime\";\nvar container17 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  width: \"100%\"\n};\nvar frame = {\n  backgroundColor: \"#070707\",\n  marginBottom: 20,\n  overflowY: \"auto\"\n};\nvar lineNumber = {\n  whiteSpace: \"pre\",\n  paddingRight: 12,\n  color: \"inherit\",\n  fontSize: 14,\n  lineHeight: 1.7,\n  width: 60,\n  flexShrink: 0,\n  display: \"inline-flex\",\n  alignItems: \"center\",\n  justifyContent: \"flex-end\",\n  fontFamily: \"monospace\"\n};\nvar CodeFrame = ({ source, lineNumberWidth }) => {\n  return /* @__PURE__ */ jsx79(\"div\", {\n    style: frame,\n    className: HORIZONTAL_SCROLLBAR_CLASSNAME,\n    children: source.map((s, j) => {\n      return /* @__PURE__ */ jsxs34(\"div\", {\n        style: container17,\n        children: [\n          /* @__PURE__ */ jsx79(\"div\", {\n            style: {\n              ...lineNumber,\n              backgroundColor: s.highlight ? \"white\" : \"#121212\",\n              color: s.highlight ? \"black\" : \"rgba(255, 255, 255, 0.6)\"\n            },\n            children: String(s.lineNumber).padStart(lineNumberWidth, \" \")\n          }),\n          /* @__PURE__ */ jsx79(\"div\", {\n            style: {\n              fontFamily: \"monospace\",\n              whiteSpace: \"pre\",\n              tabSize: 2,\n              color: s.highlight ? \"white\" : \"rgba(255, 255, 255, 0.6)\",\n              backgroundColor: s.highlight ? BLUE : \"transparent\",\n              lineHeight: 1.7,\n              paddingRight: 12,\n              paddingLeft: 12\n            },\n            children: s.content\n          })\n        ]\n      }, j);\n    })\n  });\n};\n\n// src/error-overlay/remotion-overlay/format-location.ts\nvar formatLocation = (location) => {\n  if (location.startsWith(\"webpack://\")) {\n    return location.replace(\"webpack://\", \"\");\n  }\n  return location;\n};\n\n// src/error-overlay/remotion-overlay/StackFrame.tsx\nimport { jsx as jsx80, jsxs as jsxs35 } from \"react/jsx-runtime\";\nvar location = {\n  color: \"rgba(255, 255, 255, 0.6)\",\n  fontFamily: \"monospace\",\n  fontSize: 14\n};\nvar header = {\n  paddingLeft: 14,\n  paddingTop: 10,\n  paddingBottom: 10,\n  paddingRight: 14,\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  borderBottom: \"1px solid rgb(66, 144, 245)\",\n  backgroundColor: \"black\"\n};\nvar left2 = {\n  paddingRight: 14,\n  flex: 1\n};\nvar fnName = {\n  fontSize: 14,\n  lineHeight: 1.5,\n  marginBottom: 3\n};\nvar StackElement = ({ s, lineNumberWidth, isFirst, defaultFunctionName }) => {\n  const [showCodeFrame, setShowCodeFrame] = useState33(() => !s.originalFileName?.includes(\"node_modules\") && !s.originalFileName?.startsWith(\"webpack/\") || isFirst);\n  const toggleCodeFrame = useCallback36(() => {\n    setShowCodeFrame((f) => !f);\n  }, []);\n  return /* @__PURE__ */ jsxs35(\"div\", {\n    className: \"css-reset\",\n    children: [\n      /* @__PURE__ */ jsxs35(\"div\", {\n        style: header,\n        children: [\n          /* @__PURE__ */ jsxs35(\"div\", {\n            style: left2,\n            children: [\n              /* @__PURE__ */ jsx80(\"div\", {\n                style: fnName,\n                children: s.originalFunctionName ?? defaultFunctionName\n              }),\n              s.originalFileName ? /* @__PURE__ */ jsxs35(\"div\", {\n                style: location,\n                children: [\n                  formatLocation(s.originalFileName),\n                  \":\",\n                  s.originalLineNumber\n                ]\n              }) : null\n            ]\n          }),\n          s.originalScriptCode && s.originalScriptCode.length > 0 ? /* @__PURE__ */ jsx80(Button, {\n            onClick: toggleCodeFrame,\n            children: showCodeFrame ? /* @__PURE__ */ jsx80(CaretDown2, {\n              invert: false\n            }) : /* @__PURE__ */ jsx80(CaretRight2, {})\n          }) : null\n        ]\n      }),\n      /* @__PURE__ */ jsx80(\"div\", {\n        children: s.originalScriptCode && s.originalScriptCode.length > 0 && showCodeFrame ? /* @__PURE__ */ jsx80(CodeFrame, {\n          lineNumberWidth,\n          source: s.originalScriptCode\n        }) : null\n      })\n    ]\n  });\n};\n\n// src/error-overlay/remotion-overlay/get-help-link.ts\nvar getHelpLink = (message) => {\n  if (message.includes(\"See https://www.remotion.dev/docs/the-fundamentals#defining-compositions\")) {\n    return {\n      title: \"Defining compositions\",\n      url: \"See https://www.remotion.dev/docs/the-fundamentals#defining-compositions\"\n    };\n  }\n  if (message.includes(\"https://remotion.dev/docs/wrong-composition-mount\")) {\n    return {\n      title: \"Wrongly mounted <Composition>\",\n      url: \"https://remotion.dev/docs/wrong-composition-mount\"\n    };\n  }\n  if (message.includes(\"https://remotion.dev/docs/staticfile-relative-paths\")) {\n    return {\n      title: \"staticFile() relative paths\",\n      url: \"https://remotion.dev/docs/staticfile-relative-paths\"\n    };\n  }\n  if (message.includes(\"https://remotion.dev/docs/staticfile-remote-urls\")) {\n    return {\n      title: \"staticFile() remote URLs\",\n      url: \"https://remotion.dev/docs/staticfile-remote-urls\"\n    };\n  }\n  if (message.includes(\"https://remotion.dev/docs/non-seekable-media\")) {\n    return {\n      title: \"Non-seekable media\",\n      url: \"https://remotion.dev/docs/non-seekable-media\"\n    };\n  }\n  if (message.includes(\"https://remotion.dev/docs/media-playback-error\")) {\n    return {\n      title: \"Media playback error\",\n      url: \"https://remotion.dev/docs/media-playback-error\"\n    };\n  }\n  if (message.includes(\"Div is not part of the THREE\")) {\n    return {\n      title: \"<Sequence> inside <ThreeCanvas>\",\n      url: \"https://remotion.dev/docs/sequence#note-for-remotionthree\"\n    };\n  }\n  return null;\n};\n\n// src/error-overlay/remotion-overlay/ErrorDisplay.tsx\nimport { jsx as jsx81, jsxs as jsxs36, Fragment as Fragment13 } from \"react/jsx-runtime\";\nvar stack = {\n  marginTop: 17,\n  overflowX: \"scroll\",\n  marginBottom: \"10vh\"\n};\nvar spacer2 = {\n  width: 5,\n  display: \"inline-block\"\n};\nvar ErrorDisplay = ({\n  display,\n  keyboardShortcuts,\n  onRetry,\n  canHaveDismissButton,\n  calculateMetadata\n}) => {\n  const compositionIds = window?.remotion_seenCompositionIds ?? [];\n  const highestLineNumber = Math.max(...display.stackFrames.map((s) => s.originalScriptCode).flat(1).map((s) => s?.lineNumber ?? 0));\n  const message = useMemo44(() => {\n    const location2 = getLocationFromBuildError2(display.error);\n    if (!location2) {\n      return display.error.message;\n    }\n    return location2.message.replace(/\\\\n/g, `\n`).replace(/\\\\t/g, \"  \").replace(/^error:/, \"\").trim();\n  }, [display.error]);\n  const lineNumberWidth = String(highestLineNumber).length;\n  const helpLink = getHelpLink(message);\n  const getCurrentCompositionId = () => {\n    const route = getRoute();\n    const id = route.startsWith(\"/\") ? route.slice(1) : route;\n    return compositionIds.includes(id) ? id : compositionIds[0] ?? null;\n  };\n  return /* @__PURE__ */ jsxs36(\"div\", {\n    children: [\n      /* @__PURE__ */ jsx81(ErrorTitle, {\n        symbolicating: false,\n        name: display.error.name,\n        message,\n        canHaveDismissButton\n      }),\n      helpLink ? /* @__PURE__ */ jsxs36(Fragment13, {\n        children: [\n          /* @__PURE__ */ jsx81(HelpLink, {\n            link: helpLink,\n            canHaveKeyboardShortcuts: keyboardShortcuts\n          }),\n          /* @__PURE__ */ jsx81(\"div\", {\n            style: spacer2\n          })\n        ]\n      }) : null,\n      display.stackFrames.length > 0 && window.remotion_editorName ? /* @__PURE__ */ jsxs36(Fragment13, {\n        children: [\n          /* @__PURE__ */ jsx81(OpenInEditor, {\n            canHaveKeyboardShortcuts: keyboardShortcuts,\n            stack: display.stackFrames[0]\n          }),\n          /* @__PURE__ */ jsx81(\"div\", {\n            style: spacer2\n          })\n        ]\n      }) : null,\n      compositionIds.length > 0 ? /* @__PURE__ */ jsxs36(Fragment13, {\n        children: [\n          /* @__PURE__ */ jsx81(CompositionIdsDropdown, {\n            compositionIds,\n            currentId: getCurrentCompositionId()\n          }),\n          /* @__PURE__ */ jsx81(\"div\", {\n            style: spacer2\n          })\n        ]\n      }) : null,\n      /* @__PURE__ */ jsx81(SearchGithubIssues, {\n        canHaveKeyboardShortcuts: keyboardShortcuts,\n        message: display.error.message\n      }),\n      /* @__PURE__ */ jsx81(\"div\", {\n        style: spacer2\n      }),\n      /* @__PURE__ */ jsx81(AskOnDiscord, {\n        canHaveKeyboardShortcuts: keyboardShortcuts\n      }),\n      onRetry ? /* @__PURE__ */ jsxs36(Fragment13, {\n        children: [\n          /* @__PURE__ */ jsx81(\"div\", {\n            style: spacer2\n          }),\n          /* @__PURE__ */ jsx81(RetryButton, {\n            onClick: onRetry\n          })\n        ]\n      }) : null,\n      calculateMetadata ? /* @__PURE__ */ jsxs36(Fragment13, {\n        children: [\n          /* @__PURE__ */ jsx81(\"br\", {}),\n          /* @__PURE__ */ jsx81(Spacing, {\n            y: 0.5\n          }),\n          /* @__PURE__ */ jsx81(CalculateMetadataErrorExplainer, {})\n        ]\n      }) : null,\n      /* @__PURE__ */ jsx81(\"div\", {\n        style: stack,\n        className: HORIZONTAL_SCROLLBAR_CLASSNAME,\n        children: display.stackFrames.map((s, i) => {\n          return /* @__PURE__ */ jsx81(StackElement, {\n            isFirst: i === 0,\n            s,\n            lineNumberWidth,\n            defaultFunctionName: \"(anonymous function)\"\n          }, i);\n        })\n      })\n    ]\n  });\n};\n\n// src/error-overlay/remotion-overlay/ErrorLoader.tsx\nimport { jsx as jsx82, jsxs as jsxs37 } from \"react/jsx-runtime\";\nvar container18 = {\n  width: \"100%\",\n  maxWidth: 1000,\n  paddingLeft: 14,\n  paddingRight: 14,\n  marginLeft: \"auto\",\n  marginRight: \"auto\",\n  fontFamily: \"SF Pro Text, sans-serif\",\n  paddingTop: \"5vh\"\n};\nvar errorWhileErrorStyle = {\n  color: \"white\",\n  lineHeight: 1.5,\n  whiteSpace: \"pre\"\n};\nvar ErrorLoader = ({\n  error,\n  keyboardShortcuts,\n  onRetry,\n  canHaveDismissButton,\n  calculateMetadata\n}) => {\n  const [state, setState] = useState34({\n    type: \"loading\"\n  });\n  useEffect31(() => {\n    getErrorRecord(error).then((record) => {\n      if (record) {\n        setState({\n          type: \"symbolicated\",\n          record\n        });\n      } else {\n        setState({\n          type: \"no-record\"\n        });\n      }\n    }).catch((err) => {\n      setState({\n        err,\n        type: \"error\"\n      });\n    });\n  }, [error]);\n  if (state.type === \"loading\") {\n    return /* @__PURE__ */ jsx82(\"div\", {\n      style: container18,\n      children: /* @__PURE__ */ jsx82(ErrorTitle, {\n        symbolicating: true,\n        name: error.name,\n        message: error.message,\n        canHaveDismissButton\n      })\n    });\n  }\n  if (state.type === \"error\") {\n    return /* @__PURE__ */ jsxs37(\"div\", {\n      style: container18,\n      children: [\n        /* @__PURE__ */ jsx82(ErrorTitle, {\n          symbolicating: false,\n          name: error.name,\n          message: error.message,\n          canHaveDismissButton\n        }),\n        /* @__PURE__ */ jsx82(\"div\", {\n          style: errorWhileErrorStyle,\n          children: \"Error while getting stack trace:\"\n        }),\n        /* @__PURE__ */ jsx82(\"div\", {\n          style: errorWhileErrorStyle,\n          children: state.err.stack\n        }),\n        /* @__PURE__ */ jsx82(\"div\", {\n          style: errorWhileErrorStyle,\n          children: \"Report this in the Remotion repo.\"\n        })\n      ]\n    });\n  }\n  if (state.type === \"no-record\") {\n    return /* @__PURE__ */ jsxs37(\"div\", {\n      style: container18,\n      children: [\n        /* @__PURE__ */ jsx82(ErrorTitle, {\n          symbolicating: false,\n          name: error.name,\n          message: error.message,\n          canHaveDismissButton\n        }),\n        /* @__PURE__ */ jsx82(\"div\", {\n          style: errorWhileErrorStyle,\n          children: \"Check the Terminal and browser console for error messages.\"\n        })\n      ]\n    });\n  }\n  return /* @__PURE__ */ jsx82(\"div\", {\n    style: container18,\n    children: /* @__PURE__ */ jsx82(ErrorDisplay, {\n      keyboardShortcuts,\n      display: state.record,\n      onRetry,\n      canHaveDismissButton,\n      calculateMetadata\n    })\n  });\n};\n\n// src/components/Canvas.tsx\nimport {\n  useCallback as useCallback40,\n  useContext as useContext28,\n  useEffect as useEffect34,\n  useMemo as useMemo50,\n  useState as useState36\n} from \"react\";\nimport { Internals as Internals22, watchStaticFile } from \"remotion\";\n\n// src/helpers/get-effective-translation.ts\nvar getEffectiveXTranslation = ({\n  canvasSize,\n  scale,\n  compositionWidth,\n  translation\n}) => {\n  const maxTranslation = Math.abs(canvasSize.width / 2 + scale * compositionWidth / 2 - MUST_BE_INSIDE_CANVAS);\n  return Math.max(-maxTranslation, Math.min(translation.x, maxTranslation));\n};\nvar MUST_BE_INSIDE_CANVAS = 50;\nvar getEffectiveYTranslation = ({\n  canvasSize,\n  scale,\n  compositionHeight,\n  translation\n}) => {\n  const maxTranslation = Math.abs(canvasSize.height / 2 + scale * compositionHeight / 2) - MUST_BE_INSIDE_CANVAS;\n  return Math.max(-maxTranslation, Math.min(translation.y, maxTranslation));\n};\nvar getEffectiveTranslation = ({\n  canvasSize,\n  scale,\n  compositionHeight,\n  compositionWidth,\n  translation\n}) => {\n  return {\n    x: getEffectiveXTranslation({\n      canvasSize,\n      compositionWidth,\n      scale,\n      translation\n    }),\n    y: getEffectiveYTranslation({\n      canvasSize,\n      compositionHeight,\n      scale,\n      translation\n    })\n  };\n};\nvar getCenterPointWhileScrolling = ({\n  size: size2,\n  clientX,\n  clientY,\n  compositionWidth,\n  compositionHeight,\n  scale,\n  translation\n}) => {\n  const mouseLeft = clientX - size2.left;\n  const mouseTop = clientY - size2.top;\n  const contentLeftPoint = size2.width / 2 - compositionWidth * scale / 2 - translation.x;\n  const contentTopPoint = size2.height / 2 - compositionHeight * scale / 2 - translation.y;\n  const offsetFromVideoLeft = Math.min(compositionWidth, Math.max(0, (mouseLeft - contentLeftPoint) / scale));\n  const offsetFromVideoTop = Math.min(compositionHeight, Math.max(0, (mouseTop - contentTopPoint) / scale));\n  return {\n    centerX: offsetFromVideoLeft,\n    centerY: offsetFromVideoTop\n  };\n};\n\n// src/helpers/smooth-zoom.ts\nvar BASE = Math.E / 4;\nvar MIN_ZOOM = 0.05;\nvar MAX_ZOOM = 10;\nfunction logN(val) {\n  return Math.log(val) / Math.log(BASE);\n}\nvar smoothenZoom = (input) => {\n  return BASE ** (input - 1);\n};\nvar unsmoothenZoom = (input) => {\n  if (input < 0) {\n    return MAX_ZOOM;\n  }\n  return Math.min(MAX_ZOOM, Math.max(MIN_ZOOM, logN(input) + 1));\n};\n\n// src/components/EditorGuides/index.tsx\nimport { useContext as useContext24, useMemo as useMemo47 } from \"react\";\nimport { Internals as Internals19 } from \"remotion\";\n\n// src/helpers/use-studio-canvas-dimensions.ts\nimport { PlayerInternals as PlayerInternals10 } from \"@remotion/player\";\nimport { useContext as useContext22, useMemo as useMemo45 } from \"react\";\nimport { Internals as Internals18 } from \"remotion\";\nvar useStudioCanvasDimensions = ({\n  canvasSize,\n  contentDimensions,\n  assetMetadata\n}) => {\n  const { size: previewSize } = useContext22(Internals18.PreviewSizeContext);\n  const { centerX, centerY, scale } = useMemo45(() => {\n    if (contentDimensions === \"none\" || contentDimensions === null || assetMetadata && assetMetadata.type === \"not-found\" || !canvasSize) {\n      return {\n        centerX: previewSize.translation.x,\n        centerY: previewSize.translation.y,\n        scale: 1\n      };\n    }\n    return PlayerInternals10.calculateCanvasTransformation({\n      canvasSize,\n      compositionHeight: contentDimensions.height,\n      compositionWidth: contentDimensions.width,\n      previewSize: previewSize.size\n    });\n  }, [\n    canvasSize,\n    contentDimensions,\n    previewSize.size,\n    previewSize.translation.y,\n    previewSize.translation.x,\n    assetMetadata\n  ]);\n  const canvasPosition = useMemo45(() => {\n    return {\n      left: centerX - previewSize.translation.x,\n      top: centerY - previewSize.translation.y,\n      width: contentDimensions === \"none\" || !contentDimensions ? canvasSize?.width || 0 : contentDimensions.width * scale,\n      height: contentDimensions === \"none\" || !contentDimensions ? canvasSize?.height || 0 : contentDimensions.height * scale\n    };\n  }, [\n    scale,\n    centerX,\n    previewSize.translation.x,\n    previewSize.translation.y,\n    centerY,\n    canvasSize,\n    contentDimensions\n  ]);\n  return {\n    canvasPosition,\n    scale\n  };\n};\n\n// src/components/EditorGuides/Guide.tsx\nimport { memo, useCallback as useCallback37, useContext as useContext23, useMemo as useMemo46 } from \"react\";\nimport { NoReactInternals as NoReactInternals6 } from \"remotion/no-react\";\nimport { jsx as jsx83 } from \"react/jsx-runtime\";\nvar PADDING_FOR_EASY_DRAG = 4;\nvar GuideComp = ({ guide, canvasDimensions, scale }) => {\n  const {\n    shouldCreateGuideRef,\n    setGuidesList,\n    setSelectedGuideId,\n    selectedGuideId,\n    setHoveredGuideId,\n    hoveredGuideId\n  } = useContext23(EditorShowGuidesContext);\n  const onPointerEnter = useCallback37(() => {\n    setHoveredGuideId(() => guide.id);\n  }, [guide.id, setHoveredGuideId]);\n  const onPointerLeave = useCallback37(() => {\n    setHoveredGuideId(() => null);\n  }, [setHoveredGuideId]);\n  const isVerticalGuide = guide.orientation === \"vertical\";\n  const guideStyle = useMemo46(() => {\n    const canvasPosition = isVerticalGuide ? canvasDimensions.left : canvasDimensions.top;\n    const guidePosition = guide.position * scale + canvasPosition;\n    return {\n      position: \"absolute\",\n      width: `${isVerticalGuide ? \"1px\" : \"100%\"}`,\n      height: `${isVerticalGuide ? \"100%\" : \"1px\"}`,\n      left: `${isVerticalGuide ? guidePosition - PADDING_FOR_EASY_DRAG : 0}px`,\n      top: `${isVerticalGuide ? 0 : guidePosition - PADDING_FOR_EASY_DRAG}px`,\n      cursor: `${isVerticalGuide ? \"ew-resize\" : \"ns-resize\"}`,\n      padding: isVerticalGuide ? `0 ${PADDING_FOR_EASY_DRAG}px` : `${PADDING_FOR_EASY_DRAG}px 0`\n    };\n  }, [guide, scale, canvasDimensions, isVerticalGuide]);\n  const guideContentStyle = useMemo46(() => {\n    return {\n      position: \"relative\",\n      minWidth: `${isVerticalGuide ? \"1px\" : `calc(100% + ${RULER_WIDTH}px`}`,\n      minHeight: `${isVerticalGuide ? `calc(100% + ${RULER_WIDTH}px` : \"1px\"}`,\n      top: `${isVerticalGuide ? `-${RULER_WIDTH}px` : \"0px\"}`,\n      left: `${isVerticalGuide ? \"0px\" : `-${RULER_WIDTH}px`}`,\n      display: guide.show ? \"block\" : \"none\",\n      backgroundColor: selectedGuideId === guide.id || hoveredGuideId === guide.id ? SELECTED_GUIDE : UNSELECTED_GUIDE\n    };\n  }, [isVerticalGuide, guide.show, guide.id, selectedGuideId, hoveredGuideId]);\n  const onMouseDown = useCallback37((e) => {\n    e.preventDefault();\n    if (e.button !== 0) {\n      return;\n    }\n    shouldCreateGuideRef.current = true;\n    document.body.style.cursor = \"no-drop\";\n    setSelectedGuideId(() => guide.id);\n  }, [shouldCreateGuideRef, setSelectedGuideId, guide.id]);\n  const values = useMemo46(() => {\n    return [\n      {\n        id: \"1\",\n        keyHint: null,\n        label: \"Remove guide\",\n        leftItem: null,\n        onClick: () => {\n          setGuidesList((prevState) => {\n            const newGuides = prevState.filter((selected) => {\n              return selected.id !== guide.id;\n            });\n            persistGuidesList(newGuides);\n            return newGuides;\n          });\n        },\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: \"remove\"\n      }\n    ];\n  }, [guide.id, setGuidesList]);\n  return /* @__PURE__ */ jsx83(ContextMenu, {\n    values,\n    children: /* @__PURE__ */ jsx83(\"div\", {\n      style: guideStyle,\n      onMouseDown,\n      className: \"__remotion_editor_guide\",\n      onPointerEnter,\n      onPointerLeave,\n      children: /* @__PURE__ */ jsx83(\"div\", {\n        style: guideContentStyle,\n        className: [\n          \"__remotion_editor_guide_content\",\n          selectedGuideId === guide.id || hoveredGuideId === guide.id ? \"__remotion_editor_guide_selected\" : null\n        ].filter(NoReactInternals6.truthy).join(\" \")\n      })\n    })\n  });\n};\nvar Guide_default = memo(GuideComp);\n\n// src/components/EditorGuides/index.tsx\nimport { jsx as jsx84, Fragment as Fragment14 } from \"react/jsx-runtime\";\nvar EditorGuides = ({ canvasSize, contentDimensions, assetMetadata }) => {\n  const { canvasPosition: canvasDimensions, scale } = useStudioCanvasDimensions({\n    canvasSize,\n    contentDimensions,\n    assetMetadata\n  });\n  const { canvasContent } = useContext24(Internals19.CompositionManager);\n  if (canvasContent === null || canvasContent.type !== \"composition\") {\n    throw new Error(\"Expected to be in a composition\");\n  }\n  const { guidesList } = useContext24(EditorShowGuidesContext);\n  const guidesForThisComposition = useMemo47(() => {\n    return guidesList.filter((guide) => {\n      return guide.compositionId === canvasContent.compositionId;\n    });\n  }, [canvasContent.compositionId, guidesList]);\n  return /* @__PURE__ */ jsx84(Fragment14, {\n    children: guidesForThisComposition.map((guide) => {\n      return /* @__PURE__ */ jsx84(Guide_default, {\n        guide,\n        canvasDimensions,\n        scale\n      }, guide.id);\n    })\n  });\n};\nvar EditorGuides_default = EditorGuides;\n\n// src/components/EditorRuler/index.tsx\nimport {\n  useCallback as useCallback39,\n  useContext as useContext26,\n  useEffect as useEffect33,\n  useMemo as useMemo49,\n  useRef as useRef23\n} from \"react\";\n\n// src/helpers/editor-ruler.ts\nvar drawLabel = ({\n  orientation,\n  context,\n  label: label4,\n  originDistance,\n  color\n}) => {\n  context.fillStyle = color;\n  if (orientation === \"horizontal\") {\n    context.fillText(label4, originDistance + 4, 16);\n  } else {\n    context.rotate(-Math.PI / 2);\n    context.fillText(label4, -originDistance + 4, 16);\n    context.rotate(Math.PI / 2);\n  }\n};\nvar drawGradient = ({\n  orientation,\n  context,\n  originDistance,\n  canvasHeight,\n  canvasWidth\n}) => {\n  const size2 = 250;\n  const startX = orientation === \"horizontal\" ? originDistance - size2 / 2 : 0;\n  const startY = orientation === \"horizontal\" ? 0 : originDistance - size2 / 2;\n  const endX = orientation === \"horizontal\" ? originDistance + size2 / 2 : canvasWidth;\n  const endY = orientation === \"horizontal\" ? canvasHeight : originDistance + size2 / 2;\n  const grd = context.createLinearGradient(startX, startY, endX, endY);\n  grd.addColorStop(0, BACKGROUND__TRANSPARENT);\n  grd.addColorStop(0.25, BACKGROUND);\n  grd.addColorStop(0.75, BACKGROUND);\n  grd.addColorStop(1, BACKGROUND__TRANSPARENT);\n  context.fillStyle = grd;\n  context.fillRect(startX, startY, endX - startX, endY - startY);\n};\nvar drawGuide = ({\n  selectedGuide,\n  scale,\n  startMarking,\n  context,\n  canvasHeight,\n  canvasWidth,\n  orientation,\n  originOffset\n}) => {\n  const originDistance = rulerValueToPosition({\n    value: selectedGuide.position,\n    startMarking,\n    scale\n  }) + originOffset - startMarking * scale;\n  drawGradient({\n    canvasHeight,\n    context,\n    orientation,\n    originDistance,\n    canvasWidth\n  });\n  context.strokeStyle = SELECTED_GUIDE;\n  context.lineWidth = 1;\n  context.beginPath();\n  if (orientation === \"horizontal\" && selectedGuide.orientation === \"horizontal\") {\n    return;\n  }\n  if (orientation === \"vertical\" && selectedGuide.orientation === \"vertical\") {\n    return;\n  }\n  if (orientation === \"vertical\" && selectedGuide.orientation === \"horizontal\") {\n    context.moveTo(0, originDistance);\n    context.lineTo(canvasWidth, originDistance);\n    drawLabel({\n      context,\n      label: selectedGuide.position.toString(),\n      originDistance,\n      orientation,\n      color: SELECTED_GUIDE\n    });\n  } else if (orientation === \"horizontal\" && selectedGuide.orientation === \"vertical\") {\n    context.moveTo(originDistance, 0);\n    context.lineTo(originDistance, canvasHeight);\n    drawLabel({\n      context,\n      label: selectedGuide.position.toString(),\n      originDistance,\n      orientation,\n      color: SELECTED_GUIDE\n    });\n  }\n  context.stroke();\n};\nvar drawMarkingOnRulerCanvas = ({\n  scale,\n  points,\n  startMarking,\n  originOffset,\n  markingGaps,\n  orientation,\n  rulerCanvasRef,\n  selectedGuide,\n  canvasHeight,\n  canvasWidth\n}) => {\n  const canvas = rulerCanvasRef.current;\n  if (!canvas)\n    return;\n  const context = canvas.getContext(\"2d\");\n  if (!context)\n    return;\n  canvas.width = canvasWidth;\n  canvas.height = canvasHeight;\n  context.scale(window.devicePixelRatio, window.devicePixelRatio);\n  context.clearRect(0, 0, canvasWidth, canvasHeight);\n  context.strokeStyle = RULER_COLOR;\n  context.lineWidth = 1;\n  context.beginPath();\n  points.forEach((point) => {\n    context.strokeStyle = RULER_COLOR;\n    context.lineWidth = 1;\n    const originDistance = point.position + originOffset - startMarking * scale;\n    context.beginPath();\n    if (orientation === \"horizontal\") {\n      context.moveTo(originDistance, 0);\n      context.lineTo(originDistance, canvasHeight);\n    } else {\n      context.moveTo(0, originDistance);\n      context.lineTo(canvasWidth, originDistance);\n    }\n    for (let i = 1;i < 5; i++) {\n      const markingOffsetXY = i * markingGaps * scale;\n      if (orientation === \"horizontal\") {\n        context.moveTo(originDistance + markingOffsetXY / 5, 0);\n        context.lineTo(originDistance + markingOffsetXY / 5, 4);\n      } else {\n        context.moveTo(0, originDistance + markingOffsetXY / 5);\n        context.lineTo(4, originDistance + markingOffsetXY / 5);\n      }\n    }\n    context.stroke();\n    context.font = \"10px Arial, Helvetica, sans-serif\";\n    context.textAlign = \"left\";\n    context.fillStyle = RULER_COLOR;\n    drawLabel({\n      orientation,\n      context,\n      label: point.value.toString(),\n      originDistance,\n      color: RULER_COLOR\n    });\n  });\n  if (selectedGuide && orientation !== selectedGuide.orientation) {\n    drawGuide({\n      canvasHeight,\n      canvasWidth,\n      context,\n      orientation,\n      originOffset,\n      scale,\n      selectedGuide,\n      startMarking\n    });\n  }\n};\nvar getRulerPoints = ({\n  rulerScaleRange,\n  rulerMarkingGaps,\n  scale\n}) => {\n  const points = [];\n  const startPoint = Math.ceil(rulerScaleRange.start / rulerMarkingGaps);\n  const endPoint = Math.floor(rulerScaleRange.end / rulerMarkingGaps);\n  const startMarking = startPoint * rulerMarkingGaps;\n  for (let i = startPoint;i <= endPoint; i++) {\n    points.push({\n      value: i * rulerMarkingGaps,\n      position: rulerValueToPosition({\n        scale,\n        startMarking,\n        value: i * rulerMarkingGaps\n      })\n    });\n  }\n  return {\n    points,\n    startMarking\n  };\n};\nvar rulerValueToPosition = ({\n  value,\n  startMarking,\n  scale\n}) => {\n  return (value + startMarking) * scale;\n};\nvar getRulerScaleRange = ({\n  canvasLength,\n  scale,\n  canvasSize\n}) => {\n  const scaleRangeBeyondCanvas = (canvasSize.width || MINIMUM_VISIBLE_CANVAS_SIZE - MINIMUM_VISIBLE_CANVAS_SIZE) / scale;\n  return {\n    start: -scaleRangeBeyondCanvas,\n    end: scaleRangeBeyondCanvas + canvasLength\n  };\n};\n\n// src/components/EditorRuler/Ruler.tsx\nimport {\n  useCallback as useCallback38,\n  useContext as useContext25,\n  useEffect as useEffect32,\n  useMemo as useMemo48,\n  useRef as useRef22,\n  useState as useState35\n} from \"react\";\nimport { Internals as Internals20 } from \"remotion\";\nimport { jsx as jsx85 } from \"react/jsx-runtime\";\nvar makeGuideId = () => {\n  return Math.random().toString(36).substring(7);\n};\nvar Ruler = ({\n  scale,\n  points,\n  originOffset,\n  startMarking,\n  size: size2,\n  markingGaps,\n  orientation\n}) => {\n  const rulerCanvasRef = useRef22(null);\n  const isVerticalRuler = orientation === \"vertical\";\n  const {\n    shouldCreateGuideRef,\n    setGuidesList,\n    selectedGuideId,\n    hoveredGuideId,\n    setSelectedGuideId,\n    guidesList,\n    setEditorShowGuides\n  } = useContext25(EditorShowGuidesContext);\n  const unsafeVideoConfig = Internals20.useUnsafeVideoConfig();\n  if (!unsafeVideoConfig) {\n    throw new Error(\"Video config not set\");\n  }\n  const [cursor, setCursor] = useState35(isVerticalRuler ? \"ew-resize\" : \"ns-resize\");\n  const selectedOrHoveredGuide = useMemo48(() => {\n    return guidesList.find((guide) => guide.id === selectedGuideId) ?? guidesList.find((guide) => guide.id === hoveredGuideId) ?? null;\n  }, [guidesList, hoveredGuideId, selectedGuideId]);\n  const rulerWidth = isVerticalRuler ? RULER_WIDTH : size2.width - RULER_WIDTH;\n  const rulerHeight = isVerticalRuler ? size2.height - RULER_WIDTH : RULER_WIDTH;\n  useEffect32(() => {\n    drawMarkingOnRulerCanvas({\n      scale,\n      points,\n      startMarking,\n      originOffset,\n      markingGaps,\n      orientation,\n      rulerCanvasRef,\n      selectedGuide: selectedOrHoveredGuide,\n      canvasHeight: rulerHeight * window.devicePixelRatio,\n      canvasWidth: rulerWidth * window.devicePixelRatio\n    });\n  }, [\n    scale,\n    points,\n    startMarking,\n    originOffset,\n    markingGaps,\n    orientation,\n    selectedOrHoveredGuide,\n    size2,\n    rulerHeight,\n    rulerWidth\n  ]);\n  const rulerStyle = useMemo48(() => ({\n    position: \"absolute\",\n    background: BACKGROUND,\n    width: rulerWidth,\n    height: rulerHeight,\n    left: isVerticalRuler ? 0 : \"unset\",\n    top: isVerticalRuler ? \"unset\" : 0,\n    borderBottom: isVerticalRuler ? undefined : \"1px solid \" + RULER_COLOR,\n    borderRight: isVerticalRuler ? \"1px solid \" + RULER_COLOR : undefined,\n    cursor\n  }), [rulerWidth, rulerHeight, cursor, isVerticalRuler]);\n  const onMouseDown = useCallback38((e) => {\n    if (e.button !== 0) {\n      return;\n    }\n    e.preventDefault();\n    shouldCreateGuideRef.current = true;\n    document.body.style.cursor = \"no-drop\";\n    const guideId = makeGuideId();\n    setEditorShowGuides(() => true);\n    setSelectedGuideId(() => guideId);\n    setGuidesList((prevState) => {\n      return [\n        ...prevState,\n        {\n          orientation,\n          position: -originOffset,\n          show: false,\n          id: guideId,\n          compositionId: unsafeVideoConfig.id\n        }\n      ];\n    });\n  }, [\n    shouldCreateGuideRef,\n    setEditorShowGuides,\n    setSelectedGuideId,\n    setGuidesList,\n    orientation,\n    originOffset,\n    unsafeVideoConfig.id\n  ]);\n  const changeCursor = useCallback38((e) => {\n    e.preventDefault();\n    if (selectedGuideId !== null) {\n      setCursor(\"no-drop\");\n    }\n  }, [setCursor, selectedGuideId]);\n  useEffect32(() => {\n    if (selectedGuideId === null) {\n      setCursor(isVerticalRuler ? \"ew-resize\" : \"ns-resize\");\n    }\n  }, [selectedGuideId, isVerticalRuler]);\n  return /* @__PURE__ */ jsx85(\"canvas\", {\n    ref: rulerCanvasRef,\n    width: rulerWidth * window.devicePixelRatio,\n    height: rulerHeight * window.devicePixelRatio,\n    style: rulerStyle,\n    onPointerDown: onMouseDown,\n    onPointerEnter: changeCursor,\n    onPointerLeave: changeCursor\n  });\n};\nvar Ruler_default = Ruler;\n\n// src/components/EditorRuler/index.tsx\nimport { jsx as jsx86, jsxs as jsxs38, Fragment as Fragment15 } from \"react/jsx-runtime\";\nvar originBlockStyles = {\n  position: \"absolute\",\n  top: 0,\n  left: 0,\n  borderBottom: \"1px solid \" + RULER_COLOR,\n  borderRight: \"1px solid \" + RULER_COLOR,\n  width: `${RULER_WIDTH}px`,\n  height: `${RULER_WIDTH}px`,\n  background: BACKGROUND\n};\nvar EditorRulers = ({ contentDimensions, canvasSize, assetMetadata, containerRef }) => {\n  const { scale, canvasPosition } = useStudioCanvasDimensions({\n    canvasSize,\n    contentDimensions,\n    assetMetadata\n  });\n  const {\n    shouldCreateGuideRef,\n    shouldDeleteGuideRef,\n    setGuidesList,\n    selectedGuideId,\n    setSelectedGuideId\n  } = useContext26(EditorShowGuidesContext);\n  const rulerMarkingGaps = useMemo49(() => {\n    const minimumGap = MINIMUM_RULER_MARKING_GAP_PX;\n    const predefinedGap = PREDEFINED_RULER_SCALE_GAPS.find((gap) => gap * scale > minimumGap);\n    return predefinedGap || MAXIMUM_PREDEFINED_RULER_SCALE_GAP;\n  }, [scale]);\n  const horizontalRulerScaleRange = useMemo49(() => getRulerScaleRange({\n    canvasLength: canvasPosition.width,\n    scale,\n    canvasSize\n  }), [canvasPosition.width, canvasSize, scale]);\n  const verticalRulerScaleRange = useMemo49(() => getRulerScaleRange({\n    canvasLength: canvasPosition.height,\n    scale,\n    canvasSize\n  }), [canvasPosition.height, canvasSize, scale]);\n  const {\n    points: horizontalRulerPoints,\n    startMarking: horizontalRulerStartMarking\n  } = useMemo49(() => getRulerPoints({\n    rulerScaleRange: horizontalRulerScaleRange,\n    rulerMarkingGaps,\n    scale\n  }), [horizontalRulerScaleRange, rulerMarkingGaps, scale]);\n  const { points: verticalRulerPoints, startMarking: verticalRulerStartMarking } = useMemo49(() => getRulerPoints({\n    rulerScaleRange: verticalRulerScaleRange,\n    rulerMarkingGaps,\n    scale\n  }), [verticalRulerScaleRange, rulerMarkingGaps, scale]);\n  const requestAnimationFrameRef = useRef23(null);\n  const onMouseMove = useCallback39((e) => {\n    if (requestAnimationFrameRef.current) {\n      cancelAnimationFrame(requestAnimationFrameRef.current);\n    }\n    requestAnimationFrameRef.current = requestAnimationFrame(() => {\n      const { clientX: mouseX, clientY: mouseY } = e;\n      const {\n        left: containerLeft = 0,\n        top: containerTop = 0,\n        right: containerRight = 0,\n        bottom: containerBottom = 0\n      } = containerRef.current?.getBoundingClientRect() || {};\n      if (mouseX < containerLeft || mouseX > containerRight || mouseY < containerTop || mouseY > containerBottom) {\n        if (!shouldDeleteGuideRef.current) {\n          shouldDeleteGuideRef.current = true;\n        }\n        if (document.body.style.cursor !== \"no-drop\") {\n          document.body.style.cursor = \"no-drop\";\n        }\n        setGuidesList((prevState) => {\n          const newGuides = prevState.map((guide) => {\n            if (guide.id !== selectedGuideId) {\n              return guide;\n            }\n            return {\n              ...guide,\n              show: false\n            };\n          });\n          persistGuidesList(newGuides);\n          return newGuides;\n        });\n      } else {\n        if (shouldDeleteGuideRef.current) {\n          shouldDeleteGuideRef.current = false;\n        }\n        setGuidesList((prevState) => {\n          return prevState.map((guide) => {\n            if (guide.id !== selectedGuideId) {\n              return guide;\n            }\n            const position = guide.orientation === \"vertical\" ? (mouseX - containerLeft) / scale - canvasPosition.left / scale : (mouseY - containerTop) / scale - canvasPosition.top / scale;\n            const desiredCursor = guide.orientation === \"vertical\" ? \"ew-resize\" : \"ns-resize\";\n            if (document.body.style.cursor !== desiredCursor) {\n              document.body.style.cursor = desiredCursor;\n            }\n            return {\n              ...guide,\n              position: Math.floor(position / 1),\n              show: true\n            };\n          });\n        });\n      }\n    });\n  }, [\n    containerRef,\n    shouldDeleteGuideRef,\n    setGuidesList,\n    selectedGuideId,\n    scale,\n    canvasPosition.left,\n    canvasPosition.top\n  ]);\n  const onMouseUp = useCallback39(() => {\n    setGuidesList((prevState) => {\n      const newGuides = prevState.filter((selected) => {\n        if (!shouldDeleteGuideRef.current) {\n          return true;\n        }\n        return selected.id !== selectedGuideId;\n      });\n      persistGuidesList(newGuides);\n      return newGuides;\n    });\n    shouldDeleteGuideRef.current = false;\n    document.body.style.cursor = \"auto\";\n    shouldCreateGuideRef.current = false;\n    setSelectedGuideId(() => null);\n    document.removeEventListener(\"pointerup\", onMouseUp);\n    document.removeEventListener(\"pointermove\", onMouseMove);\n  }, [\n    selectedGuideId,\n    shouldCreateGuideRef,\n    shouldDeleteGuideRef,\n    setSelectedGuideId,\n    setGuidesList,\n    onMouseMove\n  ]);\n  useEffect33(() => {\n    if (selectedGuideId !== null) {\n      document.addEventListener(\"pointermove\", onMouseMove);\n      document.addEventListener(\"pointerup\", onMouseUp);\n    }\n    return () => {\n      document.removeEventListener(\"pointermove\", onMouseMove);\n      document.removeEventListener(\"pointerup\", onMouseUp);\n      if (requestAnimationFrameRef.current) {\n        cancelAnimationFrame(requestAnimationFrameRef.current);\n      }\n    };\n  }, [selectedGuideId, onMouseMove, onMouseUp]);\n  return /* @__PURE__ */ jsxs38(Fragment15, {\n    children: [\n      /* @__PURE__ */ jsx86(\"div\", {\n        style: originBlockStyles\n      }),\n      /* @__PURE__ */ jsx86(Ruler_default, {\n        orientation: \"horizontal\",\n        scale,\n        points: horizontalRulerPoints,\n        startMarking: horizontalRulerStartMarking,\n        markingGaps: rulerMarkingGaps,\n        originOffset: canvasPosition.left,\n        size: canvasSize\n      }),\n      /* @__PURE__ */ jsx86(Ruler_default, {\n        orientation: \"vertical\",\n        scale,\n        points: verticalRulerPoints,\n        startMarking: verticalRulerStartMarking,\n        markingGaps: rulerMarkingGaps,\n        originOffset: canvasPosition.top,\n        size: canvasSize\n      })\n    ]\n  });\n};\n\n// src/components/EditorRuler/use-is-ruler-visible.ts\nimport { useContext as useContext27 } from \"react\";\nimport { Internals as Internals21 } from \"remotion\";\nvar useIsRulerVisible = () => {\n  const { canvasContent } = useContext27(Internals21.CompositionManager);\n  const { editorShowRulers } = useContext27(EditorShowRulersContext);\n  return editorShowRulers && canvasContent && canvasContent.type === \"composition\";\n};\n\n// src/components/ResetZoomButton.tsx\nimport { jsx as jsx87 } from \"react/jsx-runtime\";\nvar ResetZoomButton = ({ onClick }) => {\n  return /* @__PURE__ */ jsx87(Button, {\n    onClick,\n    children: \"Reset zoom\"\n  });\n};\n\n// src/components/Canvas.tsx\nimport { jsx as jsx88, jsxs as jsxs39, Fragment as Fragment16 } from \"react/jsx-runtime\";\nvar container19 = {\n  flex: 1,\n  display: \"flex\",\n  overflow: \"hidden\",\n  position: \"relative\",\n  backgroundColor: BACKGROUND\n};\nvar resetZoom = {\n  position: \"absolute\",\n  top: SPACING_UNIT * 2,\n  right: SPACING_UNIT * 2\n};\nvar ZOOM_PX_FACTOR = 0.003;\nvar Canvas = ({ canvasContent, size: size2 }) => {\n  const { setSize, size: previewSize } = useContext28(Internals22.PreviewSizeContext);\n  const { editorZoomGestures } = useContext28(EditorZoomGesturesContext);\n  const keybindings = useKeybinding();\n  const config = Internals22.useUnsafeVideoConfig();\n  const areRulersVisible = useIsRulerVisible();\n  const { editorShowGuides } = useContext28(EditorShowGuidesContext);\n  const [assetResolution, setAssetResolution] = useState36(null);\n  const contentDimensions = useMemo50(() => {\n    if ((canvasContent.type === \"asset\" || canvasContent.type === \"output\" || canvasContent.type === \"output-blob\") && assetResolution && assetResolution.type === \"found\") {\n      return assetResolution.dimensions;\n    }\n    if (config) {\n      return { width: config.width, height: config.height };\n    }\n    return null;\n  }, [assetResolution, config, canvasContent]);\n  const isFit = previewSize.size === \"auto\";\n  const onWheel = useCallback40((e) => {\n    if (!editorZoomGestures) {\n      return;\n    }\n    if (!size2) {\n      return;\n    }\n    if (!contentDimensions || contentDimensions === \"none\") {\n      return;\n    }\n    const wantsToZoom = e.ctrlKey || e.metaKey;\n    if (!wantsToZoom && isFit) {\n      return;\n    }\n    e.preventDefault();\n    setSize((prevSize) => {\n      const scale = Internals22.calculateScale({\n        canvasSize: size2,\n        compositionHeight: contentDimensions.height,\n        compositionWidth: contentDimensions.width,\n        previewSize: prevSize.size\n      });\n      if (wantsToZoom) {\n        const oldSize = prevSize.size === \"auto\" ? scale : prevSize.size;\n        const smoothened = smoothenZoom(oldSize);\n        const added = smoothened + e.deltaY * ZOOM_PX_FACTOR;\n        const unsmoothened = unsmoothenZoom(added);\n        const { centerX, centerY } = getCenterPointWhileScrolling({\n          size: size2,\n          clientX: e.clientX,\n          clientY: e.clientY,\n          compositionWidth: contentDimensions.width,\n          compositionHeight: contentDimensions.height,\n          scale,\n          translation: prevSize.translation\n        });\n        const zoomDifference = unsmoothened - oldSize;\n        const uvCoordinatesX = centerX / contentDimensions.width;\n        const uvCoordinatesY = centerY / contentDimensions.height;\n        const correctionLeft = -uvCoordinatesX * (zoomDifference * contentDimensions.width) + (1 - uvCoordinatesX) * zoomDifference * contentDimensions.width;\n        const correctionTop = -uvCoordinatesY * (zoomDifference * contentDimensions.height) + (1 - uvCoordinatesY) * zoomDifference * contentDimensions.height;\n        return {\n          translation: getEffectiveTranslation({\n            translation: {\n              x: prevSize.translation.x - correctionLeft / 2,\n              y: prevSize.translation.y - correctionTop / 2\n            },\n            canvasSize: size2,\n            compositionHeight: contentDimensions.height,\n            compositionWidth: contentDimensions.width,\n            scale\n          }),\n          size: unsmoothened\n        };\n      }\n      const effectiveTranslation = getEffectiveTranslation({\n        translation: prevSize.translation,\n        canvasSize: size2,\n        compositionHeight: contentDimensions.height,\n        compositionWidth: contentDimensions.width,\n        scale\n      });\n      return {\n        ...prevSize,\n        translation: getEffectiveTranslation({\n          translation: {\n            x: effectiveTranslation.x + e.deltaX,\n            y: effectiveTranslation.y + e.deltaY\n          },\n          canvasSize: size2,\n          compositionHeight: contentDimensions.height,\n          compositionWidth: contentDimensions.width,\n          scale\n        })\n      };\n    });\n  }, [editorZoomGestures, contentDimensions, isFit, setSize, size2]);\n  useEffect34(() => {\n    const { current } = canvasRef;\n    if (!current) {\n      return;\n    }\n    current.addEventListener(\"wheel\", onWheel, { passive: false });\n    return () => current.removeEventListener(\"wheel\", onWheel, {\n      passive: false\n    });\n  }, [onWheel]);\n  const onReset = useCallback40(() => {\n    setSize(() => {\n      return {\n        translation: {\n          x: 0,\n          y: 0\n        },\n        size: \"auto\"\n      };\n    });\n  }, [setSize]);\n  const onZoomIn = useCallback40(() => {\n    if (!contentDimensions || contentDimensions === \"none\") {\n      return;\n    }\n    if (!size2) {\n      return;\n    }\n    setSize((prevSize) => {\n      const scale = Internals22.calculateScale({\n        canvasSize: size2,\n        compositionHeight: contentDimensions.height,\n        compositionWidth: contentDimensions.width,\n        previewSize: prevSize.size\n      });\n      return {\n        translation: {\n          x: 0,\n          y: 0\n        },\n        size: Math.min(MAX_ZOOM, scale * 2)\n      };\n    });\n  }, [contentDimensions, setSize, size2]);\n  const onZoomOut = useCallback40(() => {\n    if (!contentDimensions || contentDimensions === \"none\") {\n      return;\n    }\n    if (!size2) {\n      return;\n    }\n    setSize((prevSize) => {\n      const scale = Internals22.calculateScale({\n        canvasSize: size2,\n        compositionHeight: contentDimensions.height,\n        compositionWidth: contentDimensions.width,\n        previewSize: prevSize.size\n      });\n      return {\n        translation: {\n          x: 0,\n          y: 0\n        },\n        size: Math.max(MIN_ZOOM, scale / 2)\n      };\n    });\n  }, [contentDimensions, setSize, size2]);\n  useEffect34(() => {\n    const resetBinding = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"0\",\n      commandCtrlKey: false,\n      callback: onReset,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const zoomIn = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"+\",\n      commandCtrlKey: false,\n      callback: onZoomIn,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const zoomOut = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"-\",\n      commandCtrlKey: false,\n      callback: onZoomOut,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      resetBinding.unregister();\n      zoomIn.unregister();\n      zoomOut.unregister();\n    };\n  }, [keybindings, onReset, onZoomIn, onZoomOut]);\n  const fetchMetadata = useCallback40(async () => {\n    setAssetResolution(null);\n    if (canvasContent.type === \"composition\") {\n      return;\n    }\n    const metadata = await getAssetMetadata(canvasContent, canvasContent.type === \"asset\");\n    setAssetResolution(metadata);\n  }, [canvasContent]);\n  useEffect34(() => {\n    if (canvasContent.type !== \"asset\") {\n      return;\n    }\n    const file = watchStaticFile(canvasContent.asset, () => {\n      fetchMetadata();\n    });\n    return () => {\n      file.cancel();\n    };\n  }, [canvasContent, fetchMetadata]);\n  useEffect34(() => {\n    fetchMetadata();\n  }, [fetchMetadata]);\n  return /* @__PURE__ */ jsxs39(Fragment16, {\n    children: [\n      /* @__PURE__ */ jsxs39(\"div\", {\n        ref: canvasRef,\n        style: container19,\n        children: [\n          size2 ? /* @__PURE__ */ jsx88(VideoPreview, {\n            canvasContent,\n            contentDimensions,\n            canvasSize: size2,\n            assetMetadata: assetResolution\n          }) : null,\n          isFit ? null : /* @__PURE__ */ jsx88(\"div\", {\n            style: resetZoom,\n            className: \"css-reset\",\n            children: /* @__PURE__ */ jsx88(ResetZoomButton, {\n              onClick: onReset\n            })\n          }),\n          editorShowGuides && canvasContent.type === \"composition\" && /* @__PURE__ */ jsx88(EditorGuides_default, {\n            canvasSize: size2,\n            contentDimensions,\n            assetMetadata: assetResolution\n          })\n        ]\n      }),\n      areRulersVisible && /* @__PURE__ */ jsx88(EditorRulers, {\n        contentDimensions,\n        canvasSize: size2,\n        assetMetadata: assetResolution,\n        containerRef: canvasRef\n      })\n    ]\n  });\n};\n\n// src/components/FramePersistor.tsx\nimport { useEffect as useEffect35 } from \"react\";\nimport { Internals as Internals23, useVideoConfig as useVideoConfig2 } from \"remotion\";\nvar FramePersistor = () => {\n  const [playing] = Internals23.Timeline.usePlayingState();\n  const config = useVideoConfig2();\n  const frame2 = Internals23.Timeline.useTimelinePosition();\n  const setFrame = Internals23.useTimelineSetFrame();\n  useEffect35(() => {\n    if (!playing) {\n      setFrame((f) => {\n        const newObj = { ...f, [config.id]: frame2 };\n        Internals23.persistCurrentFrame(newObj);\n        return newObj;\n      });\n    }\n  }, [config.id, frame2, playing, setFrame]);\n  return null;\n};\n\n// src/components/RefreshCompositionOverlay.tsx\nimport { AbsoluteFill as AbsoluteFill2 } from \"remotion\";\n\n// src/components/RunningCalculateMetadata.tsx\nimport { jsx as jsx89, jsxs as jsxs40 } from \"react/jsx-runtime\";\nvar loaderLabel = {\n  fontSize: 14,\n  color: LIGHT_TEXT,\n  fontFamily: \"sans-serif\",\n  lineHeight: 1.5\n};\nvar container20 = {\n  backgroundColor: BACKGROUND,\n  display: \"inline-flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  flexDirection: \"row\",\n  padding: 20\n};\nvar RunningCalculateMetadata = () => {\n  return /* @__PURE__ */ jsxs40(\"div\", {\n    style: container20,\n    children: [\n      /* @__PURE__ */ jsx89(Spinner, {\n        size: 24,\n        duration: 1\n      }),\n      /* @__PURE__ */ jsx89(Spacing, {\n        x: 2\n      }),\n      /* @__PURE__ */ jsxs40(\"div\", {\n        style: loaderLabel,\n        children: [\n          \"Running \",\n          /* @__PURE__ */ jsx89(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"calculateMetadata()\"\n          }),\n          \"...\"\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RefreshCompositionOverlay.tsx\nimport { jsx as jsx90 } from \"react/jsx-runtime\";\nvar container21 = {\n  justifyContent: \"flex-end\",\n  alignItems: \"flex-start\",\n  padding: 20,\n  pointerEvents: \"none\"\n};\nvar shadow = {\n  boxShadow: \"0 0 4px black\"\n};\nvar RefreshCompositionOverlay = () => {\n  return /* @__PURE__ */ jsx90(AbsoluteFill2, {\n    style: container21,\n    children: /* @__PURE__ */ jsx90(\"div\", {\n      style: shadow,\n      children: /* @__PURE__ */ jsx90(RunningCalculateMetadata, {})\n    })\n  });\n};\n\n// src/components/CanvasOrLoading.tsx\nimport { jsx as jsx91, jsxs as jsxs41, Fragment as Fragment17 } from \"react/jsx-runtime\";\nvar container22 = {\n  color: \"white\",\n  flex: 1,\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  display: \"flex\",\n  backgroundColor: BACKGROUND,\n  flexDirection: \"column\"\n};\nvar CanvasOrLoading = ({ size: size2 }) => {\n  const resolved = Internals24.useResolvedVideoConfig(null);\n  const { setZoom } = useContext29(TimelineZoomCtx);\n  const { canvasContent } = useContext29(Internals24.CompositionManager);\n  useEffect36(() => {\n    if (resolved?.type !== \"success\" && resolved?.type !== \"success-and-refreshing\") {\n      return;\n    }\n    const c = resolved.result;\n    setTimeout(() => {\n      ensureFrameIsInViewport({\n        direction: \"center\",\n        frame: getCurrentFrame(),\n        durationInFrames: c.durationInFrames\n      });\n    });\n  }, [resolved, setZoom]);\n  if (!canvasContent) {\n    const compname = window.location.pathname.replace(\"/\", \"\");\n    return /* @__PURE__ */ jsx91(\"div\", {\n      style: container22,\n      className: \"css-reset\",\n      children: /* @__PURE__ */ jsxs41(\"div\", {\n        style: loaderLabel,\n        children: [\n          \"Composition with ID \",\n          compname,\n          \" not found.\"\n        ]\n      })\n    });\n  }\n  const content = /* @__PURE__ */ jsxs41(Fragment17, {\n    children: [\n      /* @__PURE__ */ jsx91(ZoomPersistor, {}),\n      /* @__PURE__ */ jsx91(Canvas, {\n        size: size2,\n        canvasContent\n      }),\n      resolved?.type === \"success-and-refreshing\" ? /* @__PURE__ */ jsx91(RefreshCompositionOverlay, {}) : null\n    ]\n  });\n  if (canvasContent.type === \"asset\" || canvasContent.type === \"output\" || canvasContent.type === \"output-blob\") {\n    return content;\n  }\n  if (!resolved) {\n    return null;\n  }\n  if (resolved.type === \"loading\") {\n    return /* @__PURE__ */ jsx91(\"div\", {\n      style: container22,\n      className: \"css-reset\",\n      children: /* @__PURE__ */ jsx91(RunningCalculateMetadata, {})\n    });\n  }\n  if (resolved.type === \"error\") {\n    return /* @__PURE__ */ jsx91(ErrorLoading, {\n      error: resolved.error\n    });\n  }\n  return /* @__PURE__ */ jsxs41(Fragment17, {\n    children: [\n      /* @__PURE__ */ jsx91(FramePersistor, {}),\n      \" \",\n      content\n    ]\n  });\n};\nvar loaderContainer = {\n  marginLeft: \"auto\",\n  marginRight: \"auto\",\n  width: \"100%\",\n  position: \"absolute\",\n  height: \"100%\",\n  overflowY: \"auto\"\n};\nvar ErrorLoading = ({ error }) => {\n  return /* @__PURE__ */ jsx91(\"div\", {\n    style: loaderContainer,\n    className: VERTICAL_SCROLLBAR_CLASSNAME,\n    children: /* @__PURE__ */ jsx91(ErrorLoader, {\n      canHaveDismissButton: false,\n      keyboardShortcuts: false,\n      error,\n      onRetry: () => Internals24.resolveCompositionsRef.current?.reloadCurrentlySelectedComposition(),\n      calculateMetadata: true\n    }, error.stack)\n  });\n};\n\n// src/components/CanvasIfSizeIsAvailable.tsx\nimport { jsx as jsx92 } from \"react/jsx-runtime\";\nvar CanvasIfSizeIsAvailable = () => {\n  const rulersAreVisible = useIsRulerVisible();\n  const context = useContext30(Internals25.CurrentScaleContext);\n  const sizeWithRulersApplied = useMemo51(() => {\n    const size2 = context && context.type === \"canvas-size\" ? context.canvasSize : null;\n    if (!rulersAreVisible) {\n      return size2;\n    }\n    if (!size2) {\n      return null;\n    }\n    return {\n      ...size2,\n      width: size2.width - RULER_WIDTH,\n      height: size2.height - RULER_WIDTH\n    };\n  }, [context, rulersAreVisible]);\n  if (!sizeWithRulersApplied) {\n    return null;\n  }\n  return /* @__PURE__ */ jsx92(CanvasOrLoading, {\n    size: sizeWithRulersApplied\n  });\n};\n\n// src/components/CurrentCompositionSideEffects.tsx\nimport { useCallback as useCallback41, useContext as useContext31, useEffect as useEffect37 } from \"react\";\nimport { Internals as Internals26 } from \"remotion\";\n\n// src/helpers/document-title.ts\nimport { NoReactInternals as NoReactInternals7 } from \"remotion/no-react\";\nvar currentItemName = null;\nvar unsavedProps = false;\nvar tabInactive = false;\nvar renderJobs = [];\nvar setCurrentCanvasContentId = (id) => {\n  if (!id) {\n    currentItemName = id;\n    updateTitle();\n    return;\n  }\n  const idWithoutFolder = id.split(\"/\").pop();\n  currentItemName = idWithoutFolder;\n  updateTitle();\n};\nvar setUnsavedProps = (unsaved) => {\n  window.remotion_unsavedProps = unsaved;\n  unsavedProps = unsaved;\n};\nvar setRenderJobs = (jobs) => {\n  renderJobs = jobs;\n  updateTitle();\n};\ndocument.addEventListener(\"visibilitychange\", () => {\n  tabInactive = document.visibilityState === \"hidden\";\n  updateTitle();\n});\nvar productName = \"Remotion Studio\";\nvar suffix = `- ${productName}`;\nvar updateTitle = () => {\n  if (!currentItemName) {\n    document.title = productName;\n    return;\n  }\n  const currentCompTitle = `${currentItemName} / ${window.remotion_projectName}`;\n  document.title = [\n    getProgressInBrackets(currentItemName, renderJobs),\n    unsavedProps && tabInactive ? \"\" : null,\n    `${currentCompTitle} ${suffix}`\n  ].filter(NoReactInternals7.truthy).join(\" \");\n};\nvar getProgressInBrackets = (selectedCompositionId, jobs) => {\n  const currentRender = jobs.find((job) => job.status === \"running\");\n  if (!currentRender) {\n    return null;\n  }\n  if (currentRender.status !== \"running\") {\n    throw new Error(\"expected running job\");\n  }\n  let progInPercent;\n  if (isClientRenderJob(currentRender)) {\n    const { renderedFrames, totalFrames } = currentRender.progress;\n    progInPercent = totalFrames > 0 ? Math.ceil(renderedFrames / totalFrames * 100) : 0;\n  } else {\n    progInPercent = Math.ceil(currentRender.progress.value * 100);\n  }\n  const progressInBrackets = currentRender.compositionId === selectedCompositionId ? `[${progInPercent}%]` : `[${progInPercent}% ${currentRender.compositionId}]`;\n  return progressInBrackets;\n};\ndocument.addEventListener(\"visibilitychange\", () => {\n  tabInactive = document.visibilityState === \"hidden\";\n  updateTitle();\n});\n\n// src/components/CurrentCompositionSideEffects.tsx\nvar TitleUpdater = () => {\n  const renderQueue = useContext31(RenderQueueContext);\n  const { canvasContent } = useContext31(Internals26.CompositionManager);\n  const { jobs } = renderQueue;\n  useEffect37(() => {\n    if (!canvasContent) {\n      setCurrentCanvasContentId(null);\n      return;\n    }\n    if (canvasContent.type === \"composition\") {\n      setCurrentCanvasContentId(canvasContent.compositionId);\n      return;\n    }\n    if (canvasContent.type === \"output\") {\n      setCurrentCanvasContentId(canvasContent.path);\n      return;\n    }\n    if (canvasContent.type === \"output-blob\") {\n      setCurrentCanvasContentId(canvasContent.displayName);\n      return;\n    }\n    setCurrentCanvasContentId(canvasContent.asset);\n  }, [canvasContent]);\n  useEffect37(() => {\n    setRenderJobs(jobs);\n  }, [jobs]);\n  return null;\n};\nvar CurrentCompositionKeybindings = ({ readOnlyStudio }) => {\n  const keybindings = useKeybinding();\n  const video = Internals26.useVideo();\n  const { type } = useContext31(StudioServerConnectionCtx).previewServerState;\n  const openRenderModal = useCallback41(() => {\n    if (!video) {\n      return;\n    }\n    if (readOnlyStudio) {\n      return showNotification(\"Studio is read-only\", 2000);\n    }\n    if (type !== \"connected\") {\n      showNotification(\"Studio server is offline\", 2000);\n      return;\n    }\n    const renderButton = document.getElementById(\"render-modal-button\");\n    renderButton.click();\n  }, [readOnlyStudio, type, video]);\n  useEffect37(() => {\n    const binding = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"r\",\n      commandCtrlKey: false,\n      callback: openRenderModal,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      binding.unregister();\n    };\n  }, [keybindings, openRenderModal]);\n  return null;\n};\n\n// src/components/MobilePanel.tsx\nimport ReactDOM6 from \"react-dom\";\nimport { jsx as jsx93, jsxs as jsxs42 } from \"react/jsx-runtime\";\nvar container23 = {\n  position: \"fixed\",\n  top: 0,\n  left: 0,\n  width: \"100%\",\n  height: \"100%\",\n  padding: \"0 0px 50px 0px\",\n  background: BACKGROUND\n};\nvar buttonContainer = {\n  height: \"40px\",\n  width: \"100%\",\n  alignItems: \"center\",\n  display: \"flex\",\n  justifyContent: \"flex-end\"\n};\nvar button2 = {\n  height: 20,\n  width: 20\n};\nfunction MobilePanel({\n  children,\n  onClose\n}) {\n  const { currentZIndex } = useZIndex();\n  return ReactDOM6.createPortal(/* @__PURE__ */ jsxs42(\"div\", {\n    style: container23,\n    children: [\n      /* @__PURE__ */ jsx93(\"div\", {\n        style: buttonContainer,\n        children: /* @__PURE__ */ jsx93(CancelButton, {\n          style: button2,\n          onPress: onClose\n        })\n      }),\n      children\n    ]\n  }), getPortal(currentZIndex));\n}\n\n// src/components/OptionsPanel.tsx\nimport {\n  createRef as createRef9,\n  useCallback as useCallback81,\n  useContext as useContext48,\n  useEffect as useEffect52,\n  useImperativeHandle as useImperativeHandle12,\n  useMemo as useMemo90,\n  useState as useState56\n} from \"react\";\nimport { Internals as Internals37 } from \"remotion\";\n\n// src/visual-controls/VisualControls.tsx\nimport {\n  createContext as createContext16,\n  createRef as createRef8,\n  useCallback as useCallback42,\n  useEffect as useEffect39,\n  useImperativeHandle as useImperativeHandle10,\n  useMemo as useMemo53,\n  useRef as useRef24,\n  useState as useState38\n} from \"react\";\nimport { useRemotionEnvironment } from \"remotion\";\n\n// src/api/get-zod-schema-from-primitive.ts\nvar getZodSchemaFromPrimitive = (value, z) => {\n  if (typeof value === \"string\") {\n    return z.string();\n  }\n  if (typeof value === \"number\") {\n    return z.number();\n  }\n  let stringified;\n  try {\n    stringified = JSON.stringify(value);\n  } catch {}\n  throw new Error(`visualControl(): Specify a schema for this value: ${stringified ?? \"[non-serializable value]\"}. See https://remotion.dev/docs/studio/visual-control`);\n};\n\n// src/components/get-zod-if-possible.tsx\nimport {\n  createContext as createContext15,\n  useContext as useContext32,\n  useEffect as useEffect38,\n  useMemo as useMemo52,\n  useState as useState37\n} from \"react\";\nimport { jsx as jsx94 } from \"react/jsx-runtime\";\nvar getZodIfPossible = async () => {\n  try {\n    const { z } = await import(\"zod\");\n    return z;\n  } catch {\n    return null;\n  }\n};\nvar getZTypesIfPossible = async () => {\n  try {\n    const mod = await import(\"@remotion/zod-types\");\n    return mod;\n  } catch {\n    return null;\n  }\n};\nvar useZodIfPossible = () => {\n  const context = useContext32(ZodContext);\n  return context?.zod ?? null;\n};\nvar useZodTypesIfPossible = () => {\n  const context = useContext32(ZodContext);\n  return context?.zodTypes ?? null;\n};\nvar ZodContext = createContext15(null);\nvar ZodProvider = ({ children }) => {\n  const [zod, setZod] = useState37(null);\n  const [zodTypes, setZodTypes] = useState37(null);\n  useEffect38(() => {\n    getZodIfPossible().then((z) => setZod(z));\n  }, []);\n  useEffect38(() => {\n    getZTypesIfPossible().then((z) => setZodTypes(z));\n  }, []);\n  const contextValue = useMemo52(() => {\n    return {\n      zod,\n      zodTypes\n    };\n  }, [zod, zodTypes]);\n  return /* @__PURE__ */ jsx94(ZodContext.Provider, {\n    value: contextValue,\n    children\n  });\n};\n\n// src/visual-controls/get-current-edited-value.ts\nvar getVisualControlEditedValue = ({\n  handles,\n  key\n}) => {\n  return handles?.[key]?.unsavedValue ?? null;\n};\n\n// src/visual-controls/VisualControls.tsx\nimport { jsx as jsx95 } from \"react/jsx-runtime\";\nvar VisualControlsTabActivatedContext = createContext16(false);\nvar VisualControlsContext = createContext16({\n  handles: {}\n});\nvar visualControlRef = createRef8();\nvar SetVisualControlsContext = createContext16({\n  updateHandles: () => {\n    throw new Error(\"updateHandles is not implemented\");\n  },\n  updateValue: () => {\n    throw new Error(\"updateValue is not implemented\");\n  },\n  visualControl: () => {\n    throw new Error(\"visualControl is not implemented\");\n  }\n});\nvar VisualControlsProvider = ({ children }) => {\n  const imperativeHandles = useRef24({});\n  const [handles, setHandles] = useState38({});\n  const state = useMemo53(() => {\n    return {\n      handles\n    };\n  }, [handles]);\n  const setControl = useCallback42((key, value) => {\n    const currentUnsaved = imperativeHandles.current?.[key]?.unsavedValue;\n    const currentSavedState = imperativeHandles.current?.[key]?.valueInCode;\n    const changedSavedValue = value.valueInCode !== currentSavedState;\n    const changedUnsavedValue = currentUnsaved === undefined && value.valueInCode !== undefined;\n    imperativeHandles.current = {\n      ...imperativeHandles.current,\n      [key]: {\n        ...value,\n        unsavedValue: currentUnsaved ?? value.valueInCode,\n        valueInCode: value.valueInCode\n      }\n    };\n    return {\n      changed: changedSavedValue || changedUnsavedValue,\n      currentValue: getVisualControlEditedValue({\n        key,\n        handles: imperativeHandles.current\n      })\n    };\n  }, []);\n  const z = useZodIfPossible();\n  const changedRef = useRef24(false);\n  const env = useRemotionEnvironment();\n  const visualControl = useCallback42(function(key, value, schema) {\n    if (handles && false) {}\n    if (!env.isStudio) {\n      return value;\n    }\n    if (!z) {\n      return value;\n    }\n    const { changed, currentValue } = setControl(key, {\n      valueInCode: value,\n      schema: schema ?? getZodSchemaFromPrimitive(value, z),\n      stack: new Error().stack\n    });\n    if (changed) {\n      changedRef.current = true;\n    }\n    return currentValue;\n  }, [setControl, handles, z, env.isStudio]);\n  const updateHandles = useCallback42(() => {\n    setHandles(() => {\n      return imperativeHandles.current;\n    });\n  }, []);\n  const updateValue = useCallback42((key, value) => {\n    imperativeHandles.current = {\n      ...imperativeHandles.current,\n      [key]: {\n        ...imperativeHandles.current[key],\n        unsavedValue: value\n      }\n    };\n    updateHandles();\n  }, [updateHandles]);\n  useImperativeHandle10(visualControlRef, () => {\n    return {\n      globalVisualControl: visualControl\n    };\n  }, [visualControl]);\n  useEffect39(() => {\n    const callback = () => {\n      if (imperativeHandles.current) {\n        updateHandles();\n        changedRef.current = false;\n      }\n    };\n    const interval = setInterval(callback, 100);\n    return () => {\n      clearInterval(interval);\n    };\n  }, [updateHandles]);\n  const setState = useMemo53(() => {\n    return {\n      setControl,\n      updateHandles,\n      updateValue,\n      visualControl\n    };\n  }, [setControl, updateHandles, updateValue, visualControl]);\n  return /* @__PURE__ */ jsx95(VisualControlsTabActivatedContext.Provider, {\n    value: Object.keys(state.handles).length > 0,\n    children: /* @__PURE__ */ jsx95(VisualControlsContext.Provider, {\n      value: state,\n      children: /* @__PURE__ */ jsx95(SetVisualControlsContext.Provider, {\n        value: setState,\n        children\n      })\n    })\n  });\n};\n\n// src/components/GlobalPropsEditorUpdateButton.tsx\nimport React63, { useCallback as useCallback45, useContext as useContext33 } from \"react\";\nimport { Internals as Internals28 } from \"remotion\";\n\n// src/api/save-default-props.ts\nimport { getRemotionEnvironment as getRemotionEnvironment3 } from \"remotion\";\n\n// src/components/RenderModal/SchemaEditor/extract-enum-json-paths.ts\nvar extractEnumJsonPaths = ({\n  schema,\n  zodRuntime,\n  currentPath,\n  zodTypes\n}) => {\n  const def = schema._def;\n  const typeName = def.typeName;\n  switch (typeName) {\n    case zodRuntime.ZodFirstPartyTypeKind.ZodObject: {\n      const shape = def.shape();\n      const keys = Object.keys(shape);\n      return keys.map((key) => {\n        return extractEnumJsonPaths({\n          schema: shape[key],\n          zodRuntime,\n          currentPath: [...currentPath, key],\n          zodTypes\n        });\n      }).flat(1);\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodArray: {\n      return extractEnumJsonPaths({\n        schema: def.type,\n        zodRuntime,\n        currentPath: [...currentPath, \"[]\"],\n        zodTypes\n      });\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodUnion: {\n      return def.options.map((option) => {\n        return extractEnumJsonPaths({\n          schema: option,\n          zodRuntime,\n          currentPath,\n          zodTypes\n        });\n      }).flat(1);\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodDiscriminatedUnion: {\n      return def.options.map((op) => {\n        return extractEnumJsonPaths({\n          schema: op,\n          zodRuntime,\n          currentPath,\n          zodTypes\n        });\n      }).flat(1);\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodLiteral: {\n      return [currentPath];\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodEffects: {\n      if (zodTypes && schema._def.description === zodTypes.ZodZypesInternals.REMOTION_MATRIX_BRAND) {\n        return [currentPath];\n      }\n      return extractEnumJsonPaths({\n        schema: def.schema,\n        zodRuntime,\n        currentPath,\n        zodTypes\n      });\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodIntersection: {\n      const { left: left3, right } = def;\n      const leftValue = extractEnumJsonPaths({\n        schema: left3,\n        zodRuntime,\n        currentPath,\n        zodTypes\n      });\n      const rightValue = extractEnumJsonPaths({\n        schema: right,\n        zodRuntime,\n        currentPath,\n        zodTypes\n      });\n      return [...leftValue, ...rightValue];\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodTuple: {\n      return def.items.map((item, i) => extractEnumJsonPaths({\n        schema: item,\n        zodRuntime,\n        currentPath: [...currentPath, i],\n        zodTypes\n      })).flat(1);\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodRecord: {\n      const values = extractEnumJsonPaths({\n        schema: def.valueType,\n        zodRuntime,\n        currentPath: [...currentPath, \"{}\"],\n        zodTypes\n      });\n      return values;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodFunction: {\n      throw new Error(\"Cannot create a value for type function\");\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodEnum: {\n      return [currentPath];\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNativeEnum: {\n      return [];\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodOptional: {\n      const defType = def;\n      const value = extractEnumJsonPaths({\n        schema: defType.innerType,\n        zodRuntime,\n        currentPath,\n        zodTypes\n      });\n      return value;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNullable: {\n      const defType = def;\n      const value = extractEnumJsonPaths({\n        schema: defType.innerType,\n        zodRuntime,\n        currentPath,\n        zodTypes\n      });\n      return value;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodDefault: {\n      const defType = def;\n      return extractEnumJsonPaths({\n        schema: defType.innerType,\n        zodRuntime,\n        currentPath,\n        zodTypes\n      });\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodCatch: {\n      const defType = def;\n      return extractEnumJsonPaths({\n        schema: defType.innerType,\n        zodRuntime,\n        currentPath,\n        zodTypes\n      });\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodPromise: {\n      return [];\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodBranded: {\n      const defType = def;\n      const value = extractEnumJsonPaths({\n        schema: defType.type,\n        zodRuntime,\n        currentPath,\n        zodTypes\n      });\n      return value;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodPipeline: {\n      const defType = def;\n      const value = extractEnumJsonPaths({\n        schema: defType.out,\n        zodRuntime,\n        currentPath,\n        zodTypes\n      });\n      return value;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodString:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNumber:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodBigInt:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodBoolean:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNaN:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodDate:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodSymbol:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodUndefined:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNull:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodAny:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodUnknown:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNever:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodVoid:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodMap:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodLazy:\n    case zodRuntime.ZodFirstPartyTypeKind.ZodSet: {\n      return [];\n    }\n    default:\n      throw new Error(\"Not implemented: \" + typeName);\n  }\n};\n\n// src/api/helpers/calc-new-props.ts\nimport { Internals as Internals27, getRemotionEnvironment as getRemotionEnvironment2 } from \"remotion\";\nvar calcNewProps = (compositionId, defaultProps) => {\n  if (!getRemotionEnvironment2().isStudio) {\n    throw new Error(\"saveDefaultProps can only be called in the Remotion Studio.\");\n  }\n  const { compositionsRef, editorPropsProviderRef } = Internals27;\n  const compositionsStore = compositionsRef.current;\n  if (!compositionsStore) {\n    throw new Error(\"No compositions ref found. Are you in the Remotion Studio and are the Remotion versions aligned?\");\n  }\n  const compositions = compositionsStore.getCompositions();\n  const composition = compositions.find((c) => c.id === compositionId);\n  if (!composition) {\n    throw new Error(`No composition with the ID ${compositionId} found. Available compositions: ${compositions.map((c) => c.id).join(\", \")}`);\n  }\n  const propsStore = editorPropsProviderRef.current;\n  if (!propsStore) {\n    throw new Error(\"No props store found. Are you in the Remotion Studio and are the Remotion versions aligned?\");\n  }\n  const savedDefaultProps = composition.defaultProps ?? {};\n  const unsavedDefaultProps = propsStore.getProps()[compositionId] ?? savedDefaultProps;\n  const generatedDefaultProps = defaultProps({\n    schema: composition.schema,\n    savedDefaultProps,\n    unsavedDefaultProps\n  });\n  return {\n    composition,\n    generatedDefaultProps\n  };\n};\n\n// src/api/save-default-props.ts\nvar saveDefaultProps = async ({\n  compositionId,\n  defaultProps\n}) => {\n  if (!getRemotionEnvironment3().isStudio) {\n    throw new Error(\"saveDefaultProps() is only available in the Studio\");\n  }\n  if (window.remotion_isReadOnlyStudio) {\n    throw new Error(\"saveDefaultProps() is not available in read-only Studio\");\n  }\n  try {\n    await import(\"zod\");\n  } catch {\n    throw new Error('\"zod\" is required to use saveDefaultProps(), but is not installed.');\n  }\n  const z = await import(\"zod\");\n  let zodTypes = null;\n  try {\n    zodTypes = await import(\"@remotion/zod-types\");\n  } catch {}\n  const { generatedDefaultProps, composition } = calcNewProps(compositionId, defaultProps);\n  const res = await callUpdateDefaultPropsApi(compositionId, generatedDefaultProps, composition.schema ? extractEnumJsonPaths({\n    schema: composition.schema,\n    zodRuntime: z,\n    currentPath: [],\n    zodTypes\n  }) : []);\n  if (res.success) {\n    return Promise.resolve();\n  }\n  const err = new Error(res.reason);\n  err.stack = res.stack;\n  return Promise.reject(err);\n};\n\n// src/components/RenderModal/SchemaEditor/SchemaResetButton.tsx\nimport { useCallback as useCallback43 } from \"react\";\nimport { jsx as jsx96 } from \"react/jsx-runtime\";\nvar icon2 = {\n  height: 14,\n  color: \"currentColor\"\n};\nvar SchemaResetButton = ({ onClick }) => {\n  const renderAction = useCallback43((color) => {\n    return /* @__PURE__ */ jsx96(\"svg\", {\n      style: icon2,\n      viewBox: \"0 0 512 512\",\n      children: /* @__PURE__ */ jsx96(\"path\", {\n        fill: color,\n        d: \"M48.5 224H40c-13.3 0-24-10.7-24-24V72c0-9.7 5.8-18.5 14.8-22.2s19.3-1.7 26.2 5.2L98.6 96.6c87.6-86.5 228.7-86.2 315.8 1c87.5 87.5 87.5 229.3 0 316.8s-229.3 87.5-316.8 0c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0c62.5 62.5 163.8 62.5 226.3 0s62.5-163.8 0-226.3c-62.2-62.2-162.7-62.5-225.3-1L185 183c6.9 6.9 8.9 17.2 5.2 26.2s-12.5 14.8-22.2 14.8H48.5z\"\n      })\n    });\n  }, []);\n  return /* @__PURE__ */ jsx96(InlineAction, {\n    renderAction,\n    onClick\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/SchemaSaveButton.tsx\nimport { useCallback as useCallback44 } from \"react\";\nimport { jsx as jsx97 } from \"react/jsx-runtime\";\nvar icon3 = {\n  height: 14,\n  color: \"currentColor\"\n};\nvar SchemaSaveButton = ({ onClick, disabled }) => {\n  const renderAction = useCallback44((color) => {\n    return /* @__PURE__ */ jsx97(\"svg\", {\n      style: icon3,\n      viewBox: \"0 0 448 512\",\n      children: /* @__PURE__ */ jsx97(\"path\", {\n        fill: disabled ? LIGHT_TEXT : color,\n        d: \"M64 32C28.7 32 0 60.7 0 96V416c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V173.3c0-17-6.7-33.3-18.7-45.3L352 50.7C340 38.7 323.7 32 306.7 32H64zm0 96c0-17.7 14.3-32 32-32H288c17.7 0 32 14.3 32 32v64c0 17.7-14.3 32-32 32H96c-17.7 0-32-14.3-32-32V128zM224 288a64 64 0 1 1 0 128 64 64 0 1 1 0-128z\"\n      })\n    });\n  }, [disabled]);\n  return /* @__PURE__ */ jsx97(InlineAction, {\n    renderAction,\n    onClick,\n    disabled\n  });\n};\n\n// src/components/GlobalPropsEditorUpdateButton.tsx\nimport { jsx as jsx98, jsxs as jsxs43 } from \"react/jsx-runtime\";\nvar container24 = {\n  display: \"inline-block\",\n  flexDirection: \"row\"\n};\nvar GlobalPropsEditorUpdateButton = ({ compositionId, currentDefaultProps }) => {\n  const { fastRefreshes } = useContext33(Internals28.NonceContext);\n  const [disabled, setDisabled] = React63.useState(false);\n  const onClicked = useCallback45(() => {\n    setDisabled(true);\n    window.remotion_ignoreFastRefreshUpdate = fastRefreshes + 1;\n    saveDefaultProps({\n      compositionId,\n      defaultProps: () => currentDefaultProps\n    }).catch((err) => {\n      showNotification(`Cannot update default props: ${err.stack}`, 2000);\n    }).finally(() => {\n      setDisabled(true);\n    });\n  }, [compositionId, currentDefaultProps, fastRefreshes]);\n  const onReset = useCallback45(() => {\n    window.remotion_ignoreFastRefreshUpdate = null;\n    window.dispatchEvent(new CustomEvent(Internals28.PROPS_UPDATED_EXTERNALLY, {\n      detail: {\n        resetUnsaved: compositionId\n      }\n    }));\n  }, [compositionId]);\n  return /* @__PURE__ */ jsxs43(\"div\", {\n    style: container24,\n    children: [\n      /* @__PURE__ */ jsx98(SchemaResetButton, {\n        onClick: onReset\n      }),\n      /* @__PURE__ */ jsx98(SchemaSaveButton, {\n        disabled,\n        onClick: onClicked\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/DataEditor.tsx\nimport React94, {\n  useCallback as useCallback69,\n  useContext as useContext36,\n  useEffect as useEffect47,\n  useMemo as useMemo80,\n  useState as useState51\n} from \"react\";\nimport { getInputProps, Internals as Internals31 } from \"remotion\";\nimport { NoReactInternals as NoReactInternals10 } from \"remotion/no-react\";\n\n// src/components/NewComposition/ValidationMessage.tsx\nimport { useMemo as useMemo54 } from \"react\";\nimport { jsx as jsx99, jsxs as jsxs44 } from \"react/jsx-runtime\";\nvar WarningTriangle = (props) => {\n  return /* @__PURE__ */ jsx99(\"svg\", {\n    viewBox: \"0 0 576 512\",\n    ...props,\n    children: /* @__PURE__ */ jsx99(\"path\", {\n      d: \"M248.747 204.705l6.588 112c.373 6.343 5.626 11.295 11.979 11.295h41.37a12 12 0 0 0 11.979-11.295l6.588-112c.405-6.893-5.075-12.705-11.979-12.705h-54.547c-6.903 0-12.383 5.812-11.978 12.705zM330 384c0 23.196-18.804 42-42 42s-42-18.804-42-42 18.804-42 42-42 42 18.804 42 42zm-.423-360.015c-18.433-31.951-64.687-32.009-83.154 0L6.477 440.013C-11.945 471.946 11.118 512 48.054 512H527.94c36.865 0 60.035-39.993 41.577-71.987L329.577 23.985zM53.191 455.002L282.803 57.008c2.309-4.002 8.085-4.002 10.394 0l229.612 397.993c2.308 4-.579 8.998-5.197 8.998H58.388c-4.617.001-7.504-4.997-5.197-8.997z\"\n    })\n  });\n};\nvar style6 = {\n  width: 12,\n  height: 12,\n  flexShrink: 0\n};\nvar container25 = {\n  maxWidth: 500\n};\nvar label4 = {\n  fontSize: 13,\n  color: \"white\",\n  fontFamily: \"sans-serif\"\n};\nvar ValidationMessage = ({ message, align, type }) => {\n  const finalStyle = useMemo54(() => {\n    return {\n      ...style6,\n      fill: type === \"warning\" ? WARNING_COLOR : FAIL_COLOR\n    };\n  }, [type]);\n  return /* @__PURE__ */ jsx99(\"div\", {\n    style: container25,\n    children: /* @__PURE__ */ jsxs44(Row, {\n      align: \"center\",\n      justify: align,\n      children: [\n        /* @__PURE__ */ jsx99(WarningTriangle, {\n          style: finalStyle\n        }),\n        /* @__PURE__ */ jsx99(Spacing, {\n          x: 1\n        }),\n        /* @__PURE__ */ jsx99(\"div\", {\n          style: label4,\n          children: message\n        })\n      ]\n    })\n  });\n};\n\n// src/components/SegmentedControl.tsx\nimport { useCallback as useCallback46, useMemo as useMemo55, useState as useState39 } from \"react\";\nimport { jsx as jsx100 } from \"react/jsx-runtime\";\nvar container26 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  overflow: \"hidden\",\n  border: \"1px solid \" + INPUT_BORDER_COLOR_UNHOVERED,\n  flexWrap: \"wrap\",\n  maxWidth: 350,\n  justifyContent: \"flex-end\"\n};\nvar item = {\n  display: \"flex\",\n  fontSize: 15,\n  padding: \"4px 12px\",\n  cursor: \"pointer\",\n  appearance: \"none\",\n  border: \"none\",\n  flex: 1,\n  justifyContent: \"center\",\n  whiteSpace: \"nowrap\"\n};\nvar SegmentedControl = ({ items, needsWrapping }) => {\n  const controlStyle = useMemo55(() => {\n    if (needsWrapping) {\n      return {\n        ...container26,\n        flexWrap: \"wrap\",\n        maxWidth: \"248px\",\n        justifyContent: \"flex-end\",\n        marginBottom: \"8px\"\n      };\n    }\n    return {\n      ...container26\n    };\n  }, [needsWrapping]);\n  return /* @__PURE__ */ jsx100(\"div\", {\n    style: controlStyle,\n    children: items.map((i) => {\n      return /* @__PURE__ */ jsx100(Item, {\n        onClick: i.onClick,\n        selected: i.selected,\n        children: i.label\n      }, i.key);\n    })\n  });\n};\nvar Item = ({ selected, onClick, children }) => {\n  const [hovered, setHovered] = useState39(false);\n  const { tabIndex } = useZIndex();\n  const onPointerEnter = useCallback46(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback46(() => {\n    setHovered(false);\n  }, []);\n  const itemStyle3 = useMemo55(() => {\n    return {\n      ...item,\n      backgroundColor: selected ? INPUT_BACKGROUND : \"transparent\",\n      color: selected ? \"white\" : hovered ? \"white\" : LIGHT_TEXT\n    };\n  }, [hovered, selected]);\n  return /* @__PURE__ */ jsx100(\"button\", {\n    type: \"button\",\n    onPointerEnter,\n    onPointerLeave,\n    style: itemStyle3,\n    tabIndex,\n    onClick,\n    children\n  });\n};\n\n// src/components/RenderModal/RenderModalJSONPropsEditor.tsx\nimport React67, { useCallback as useCallback47, useEffect as useEffect40, useMemo as useMemo57 } from \"react\";\nimport { NoReactInternals as NoReactInternals8 } from \"remotion/no-react\";\n\n// src/components/RenderModal/SchemaEditor/ZodErrorMessages.tsx\nimport { useMemo as useMemo56 } from \"react\";\nimport { jsx as jsx101, jsxs as jsxs45 } from \"react/jsx-runtime\";\nvar schemaLabel = {\n  fontSize: 14,\n  color: LIGHT_TEXT\n};\nvar jsonLabel = {\n  color: \"white\",\n  fontSize: 13,\n  fontFamily: \"sans-serif\",\n  display: \"flex\",\n  alignItems: \"center\"\n};\nvar triangleStyle = {\n  width: 12,\n  height: 12,\n  flexShrink: 0,\n  fill: FAIL_COLOR\n};\nvar ZodErrorMessages = ({ zodValidationResult, viewTab }) => {\n  if (zodValidationResult.success) {\n    throw new Error(\"Expected error\");\n  }\n  const style7 = useMemo56(() => {\n    return viewTab === \"json\" ? jsonLabel : schemaLabel;\n  }, [viewTab]);\n  const code = useMemo56(() => {\n    return {\n      ...schemaLabel,\n      fontFamily: \"monospace\"\n    };\n  }, []);\n  if (viewTab === \"json\") {\n    return /* @__PURE__ */ jsx101(\"div\", {\n      children: zodValidationResult.error.errors.map((error) => {\n        return /* @__PURE__ */ jsxs45(\"div\", {\n          style: style7,\n          children: [\n            /* @__PURE__ */ jsx101(WarningTriangle, {\n              style: triangleStyle\n            }),\n            /* @__PURE__ */ jsx101(Spacing, {\n              x: 1\n            }),\n            error.path.length === 0 ? \"Root\" : error.path.join(\".\"),\n            \":\",\n            \" \",\n            error.message\n          ]\n        }, error.path.join(\".\"));\n      })\n    });\n  }\n  return /* @__PURE__ */ jsx101(\"div\", {\n    children: zodValidationResult.error.errors.map((error) => {\n      return /* @__PURE__ */ jsxs45(\"div\", {\n        style: style7,\n        children: [\n          \"-\",\n          \" \",\n          /* @__PURE__ */ jsx101(\"code\", {\n            style: code,\n            children: error.path.length === 0 ? \"Root\" : error.path.join(\".\")\n          }),\n          \": \",\n          error.message\n        ]\n      }, error.path.join(\".\"));\n    })\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/deep-equal.ts\nfunction deepEqual(a, b) {\n  if (a === b) {\n    return true;\n  }\n  if (a instanceof Date && b instanceof Date) {\n    return a.getTime() === b.getTime();\n  }\n  if (typeof a !== \"object\" || a === null || typeof b !== \"object\" || b === null) {\n    return false;\n  }\n  const keysA = Object.keys(a);\n  const keysB = Object.keys(b);\n  if (keysA.length !== keysB.length) {\n    return false;\n  }\n  for (const key of keysA) {\n    if (!keysB.includes(key) || !deepEqual(a[key], b[key])) {\n      return false;\n    }\n  }\n  return true;\n}\n\n// src/components/RenderModal/RenderModalJSONPropsEditor.tsx\nimport { jsx as jsx102, jsxs as jsxs46 } from \"react/jsx-runtime\";\nvar style7 = {\n  fontFamily: \"monospace\",\n  flex: 1\n};\nvar scrollable = {\n  padding: \"8px 12px\",\n  display: \"flex\",\n  flexDirection: \"column\",\n  flex: 1\n};\nvar parseJSON = (str, schema) => {\n  try {\n    const value = NoReactInternals8.deserializeJSONWithSpecialTypes(str);\n    const zodValidation = schema.safeParse(value);\n    return { str, value, validJSON: true, zodValidation };\n  } catch (e) {\n    return { str, validJSON: false, error: e.message };\n  }\n};\nvar RenderModalJSONPropsEditor = ({\n  setValue,\n  value,\n  defaultProps,\n  onSave,\n  showSaveButton,\n  serializedJSON,\n  schema\n}) => {\n  if (serializedJSON === null) {\n    throw new Error(\"expecting serializedJSON to be defined\");\n  }\n  const keybindings = useKeybinding();\n  const [localValue, setLocalValue] = React67.useState(() => {\n    return parseJSON(serializedJSON.serializedString, schema);\n  });\n  const onPretty = useCallback47(() => {\n    if (!localValue.validJSON) {\n      return;\n    }\n    const parsed = JSON.parse(localValue.str);\n    setLocalValue({ ...localValue, str: JSON.stringify(parsed, null, 2) });\n  }, [localValue, setLocalValue]);\n  const onChange = useCallback47((e) => {\n    const parsed = parseJSON(e.target.value, schema);\n    if (parsed.validJSON) {\n      const validationResult = schema.safeParse(parsed.value);\n      setLocalValue({\n        str: e.target.value,\n        value: parsed.value,\n        validJSON: parsed.validJSON,\n        zodValidation: validationResult\n      });\n      if (validationResult.success) {\n        setValue(parsed.value);\n      }\n    } else {\n      setLocalValue({\n        str: e.target.value,\n        validJSON: parsed.validJSON,\n        error: parsed.error\n      });\n    }\n  }, [schema, setValue]);\n  const hasChanged = useMemo57(() => {\n    return !deepEqual(value, defaultProps);\n  }, [defaultProps, value]);\n  useEffect40(() => {\n    setUnsavedProps(hasChanged);\n  }, [hasChanged]);\n  const onQuickSave = useCallback47(() => {\n    if (hasChanged) {\n      onSave();\n    }\n  }, [hasChanged, onSave]);\n  useEffect40(() => {\n    setLocalValue(parseJSON(localValue.str, schema));\n  }, [localValue.str, schema]);\n  useEffect40(() => {\n    const save = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"s\",\n      commandCtrlKey: true,\n      callback: onQuickSave,\n      preventDefault: true,\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      save.unregister();\n    };\n  }, [keybindings, onQuickSave, onSave]);\n  const reset = useCallback47(() => {\n    setValue(defaultProps);\n    setLocalValue(parseJSON(JSON.stringify(defaultProps, null, 2), schema));\n  }, [defaultProps, schema, setValue]);\n  const textAreaStyle = useMemo57(() => {\n    const fail = !localValue.validJSON || !localValue.zodValidation.success;\n    if (!fail) {\n      return style7;\n    }\n    return {\n      ...style7,\n      borderColor: FAIL_COLOR\n    };\n  }, [localValue]);\n  return /* @__PURE__ */ jsxs46(\"div\", {\n    style: scrollable,\n    children: [\n      /* @__PURE__ */ jsx102(RemTextarea, {\n        onChange,\n        value: localValue.str,\n        status: localValue.validJSON ? \"ok\" : \"error\",\n        style: textAreaStyle\n      }),\n      /* @__PURE__ */ jsx102(Spacing, {\n        y: 1\n      }),\n      localValue.validJSON === false ? /* @__PURE__ */ jsx102(ValidationMessage, {\n        align: \"flex-start\",\n        message: localValue.error,\n        type: \"error\"\n      }) : localValue.zodValidation.success === false ? /* @__PURE__ */ jsx102(ZodErrorMessages, {\n        zodValidationResult: localValue.zodValidation,\n        viewTab: \"json\"\n      }) : null,\n      /* @__PURE__ */ jsx102(Spacing, {\n        y: 1\n      }),\n      /* @__PURE__ */ jsxs46(Row, {\n        children: [\n          /* @__PURE__ */ jsx102(Button, {\n            disabled: !(hasChanged || !localValue.validJSON),\n            onClick: reset,\n            children: \"Reset\"\n          }),\n          /* @__PURE__ */ jsx102(Flex, {}),\n          /* @__PURE__ */ jsx102(Button, {\n            disabled: !localValue.validJSON,\n            onClick: onPretty,\n            children: \"Format\"\n          }),\n          /* @__PURE__ */ jsx102(Spacing, {\n            x: 1\n          }),\n          showSaveButton ? /* @__PURE__ */ jsx102(Button, {\n            onClick: onSave,\n            disabled: !(localValue.validJSON && localValue.zodValidation.success) || !localValue.validJSON || !hasChanged,\n            children: \"Save\"\n          }) : null\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/SchemaEditor.tsx\nimport { useCallback as useCallback67, useEffect as useEffect46, useMemo as useMemo78, useState as useState50 } from \"react\";\nimport { Internals as Internals30 } from \"remotion\";\n\n// src/components/RenderModal/SchemaEditor/SchemaErrorMessages.tsx\nimport { jsx as jsx103, jsxs as jsxs47 } from \"react/jsx-runtime\";\nvar explainer = {\n  display: \"flex\",\n  flex: 1,\n  flexDirection: \"column\",\n  padding: \"0 12px\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  textAlign: \"center\",\n  background: BACKGROUND\n};\nvar errorExplanation = {\n  fontSize: 14,\n  color: LIGHT_TEXT,\n  fontFamily: \"sans-serif\",\n  lineHeight: 1.5\n};\nvar codeSnippet = {\n  fontSize: 14,\n  color: BLUE,\n  fontFamily: \"monospace\"\n};\nvar errorContainer = {\n  padding: \"8px 12px\",\n  overflowY: \"auto\"\n};\nvar openDocs = () => {\n  window.open(\"https://www.remotion.dev/docs/schemas\");\n};\nvar ZodNotInstalled = () => {\n  return /* @__PURE__ */ jsxs47(\"div\", {\n    style: explainer,\n    children: [\n      /* @__PURE__ */ jsxs47(\"div\", {\n        style: errorExplanation,\n        children: [\n          \"Install \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"zod\"\n          }),\n          \" as a dependency to interactively control the props of the composition.\"\n        ]\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 2,\n        block: true\n      }),\n      /* @__PURE__ */ jsx103(Button, {\n        onClick: openDocs,\n        children: \"Learn how\"\n      })\n    ]\n  });\n};\nvar NoSchemaDefined = () => {\n  return /* @__PURE__ */ jsxs47(\"div\", {\n    style: explainer,\n    children: [\n      /* @__PURE__ */ jsxs47(\"div\", {\n        style: errorExplanation,\n        children: [\n          \"Make the props of this composition interactively editable by adding a\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"schema\"\n          }),\n          \" prop to the\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"<Composition>\"\n          }),\n          \" component.\"\n        ]\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 2,\n        block: true\n      }),\n      /* @__PURE__ */ jsx103(Button, {\n        onClick: openDocs,\n        children: \"Learn how\"\n      })\n    ]\n  });\n};\nvar NoDefaultProps = () => {\n  return /* @__PURE__ */ jsxs47(\"div\", {\n    style: explainer,\n    children: [\n      /* @__PURE__ */ jsxs47(\"div\", {\n        style: errorExplanation,\n        children: [\n          \"The schema can not be edited because the\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"defaultProps\"\n          }),\n          \" prop in the\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"<Composition>\"\n          }),\n          \" does not exist.\"\n        ]\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 1\n      }),\n      /* @__PURE__ */ jsxs47(\"div\", {\n        style: errorExplanation,\n        children: [\n          \"Fix the schema by adding a\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"defaultProps\"\n          }),\n          \" prop to your composition.\"\n        ]\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 2,\n        block: true\n      }),\n      /* @__PURE__ */ jsx103(Button, {\n        onClick: openDocs,\n        children: \"Learn more\"\n      })\n    ]\n  });\n};\nvar InvalidDefaultProps = ({ zodValidationResult }) => {\n  return /* @__PURE__ */ jsxs47(\"div\", {\n    style: errorContainer,\n    children: [\n      /* @__PURE__ */ jsxs47(\"div\", {\n        style: errorExplanation,\n        children: [\n          \"The schema can not be edited because the\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"defaultProps\"\n          }),\n          \" prop in the\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"<Composition>\"\n          }),\n          \" is not valid:\"\n        ]\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 1,\n        block: true\n      }),\n      /* @__PURE__ */ jsx103(ZodErrorMessages, {\n        zodValidationResult,\n        viewTab: \"schema\"\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 1,\n        block: true\n      }),\n      /* @__PURE__ */ jsxs47(\"div\", {\n        style: errorExplanation,\n        children: [\n          \"Fix the schema by changing the\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"defaultProps\"\n          }),\n          \" prop in your composition so it does not give a type error.\"\n        ]\n      })\n    ]\n  });\n};\nvar InvalidSchema = ({ zodValidationResult, reset }) => {\n  return /* @__PURE__ */ jsxs47(\"div\", {\n    style: errorContainer,\n    children: [\n      /* @__PURE__ */ jsx103(\"div\", {\n        style: errorExplanation,\n        children: \"The data does not satisfy the schema:\"\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 1,\n        block: true\n      }),\n      /* @__PURE__ */ jsx103(ZodErrorMessages, {\n        zodValidationResult,\n        viewTab: \"schema\"\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 1,\n        block: true\n      }),\n      /* @__PURE__ */ jsx103(\"div\", {\n        style: errorExplanation,\n        children: \"Fix the schema using the JSON editor.\"\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 1,\n        block: true\n      }),\n      /* @__PURE__ */ jsxs47(\"div\", {\n        style: errorExplanation,\n        children: [\n          \"Alternatively, reset the data to the\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: inlineCodeSnippet,\n            children: \"defaultProps\"\n          }),\n          \" that you have defined.\"\n        ]\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 1,\n        block: true\n      }),\n      /* @__PURE__ */ jsx103(Button, {\n        onClick: reset,\n        children: \"Reset props\"\n      })\n    ]\n  });\n};\nvar TopLevelZodValue = ({ typeReceived }) => {\n  return /* @__PURE__ */ jsxs47(\"div\", {\n    style: explainer,\n    children: [\n      /* @__PURE__ */ jsxs47(\"div\", {\n        style: errorExplanation,\n        children: [\n          \"The top-level type of the schema must be a pure\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: codeSnippet,\n            children: \"z.object\"\n          }),\n          \". Instead got a schema of type\",\n          \" \",\n          /* @__PURE__ */ jsx103(\"code\", {\n            style: codeSnippet,\n            children: typeReceived\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 1\n      }),\n      /* @__PURE__ */ jsx103(\"div\", {\n        style: errorExplanation,\n        children: \"Fix the schema by changing the top-level Zod type to an object.\"\n      }),\n      /* @__PURE__ */ jsx103(Spacing, {\n        y: 2,\n        block: true\n      }),\n      /* @__PURE__ */ jsx103(Button, {\n        onClick: openDocs,\n        children: \"Learn more\"\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodObjectEditor.tsx\nimport React91, { useMemo as useMemo77, useState as useState49 } from \"react\";\n\n// src/components/RenderModal/layout.ts\nvar optionRow = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  minHeight: 40,\n  paddingLeft: 16,\n  paddingRight: 16,\n  paddingTop: 8,\n  paddingBottom: 8\n};\nvar label5 = {\n  width: 290,\n  fontSize: 15,\n  lineHeight: \"40px\",\n  color: LIGHT_TEXT,\n  fontFamily: \"sans-serif\",\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar rightRow = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  justifyContent: \"flex-end\",\n  alignSelf: \"center\",\n  flex: 1\n};\nvar input = {\n  minWidth: 250\n};\nvar fieldSetText = {\n  color: LIGHT_TEXT,\n  fontSize: 14,\n  fontFamily: \"monospace\"\n};\nvar fieldsetLabel = {\n  ...fieldSetText,\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  width: \"100%\"\n};\n\n// src/components/RenderModal/SchemaEditor/Fieldset.tsx\nimport { createContext as createContext17, useContext as useContext34, useMemo as useMemo58 } from \"react\";\nimport { jsx as jsx104 } from \"react/jsx-runtime\";\nvar SCHEMA_EDITOR_FIELDSET_PADDING = 10;\nvar AlreadyPaddedRightContext = createContext17(false);\nvar Fieldset = ({ children, shouldPad }) => {\n  const alreadyPadded = useContext34(AlreadyPaddedRightContext);\n  const style8 = useMemo58(() => {\n    if (shouldPad) {\n      return {\n        padding: SCHEMA_EDITOR_FIELDSET_PADDING,\n        paddingTop: SCHEMA_EDITOR_FIELDSET_PADDING / 2,\n        paddingRight: alreadyPadded ? 0 : SCHEMA_EDITOR_FIELDSET_PADDING\n      };\n    }\n    return {};\n  }, [alreadyPadded, shouldPad]);\n  const content = /* @__PURE__ */ jsx104(\"div\", {\n    style: style8,\n    children\n  });\n  if (shouldPad) {\n    return /* @__PURE__ */ jsx104(AlreadyPaddedRightContext.Provider, {\n      value: true,\n      children: content\n    });\n  }\n  return content;\n};\n\n// src/components/RenderModal/SchemaEditor/SchemaLabel.tsx\nimport { useCallback as useCallback49, useMemo as useMemo59, useState as useState40 } from \"react\";\n\n// src/components/RenderModal/InlineRemoveButton.tsx\nimport { useCallback as useCallback48 } from \"react\";\nimport { jsx as jsx105 } from \"react/jsx-runtime\";\nvar clearIcon = {\n  height: 14,\n  color: \"currentColor\"\n};\nvar InlineRemoveButton = ({ onClick }) => {\n  const renderAction = useCallback48((color) => {\n    return /* @__PURE__ */ jsx105(\"svg\", {\n      xmlns: \"http://www.w3.org/2000/svg\",\n      viewBox: \"0 0 320 512\",\n      style: clearIcon,\n      children: /* @__PURE__ */ jsx105(\"path\", {\n        d: \"M310.6 150.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L160 210.7 54.6 105.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L114.7 256 9.4 361.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L160 301.3 265.4 406.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L205.3 256 310.6 150.6z\",\n        fill: color\n      })\n    });\n  }, []);\n  return /* @__PURE__ */ jsx105(InlineAction, {\n    renderAction,\n    onClick\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/get-schema-label.ts\nvar getSchemaLabel = (jsonPath) => {\n  const lastKey = jsonPath[jsonPath.length - 1];\n  if (typeof lastKey === \"number\") {\n    const secondLastKey = jsonPath[jsonPath.length - 2];\n    if (typeof secondLastKey === \"undefined\") {\n      return `[${lastKey}]:`;\n    }\n    return `${lastKey}:`;\n  }\n  return `${lastKey}:`;\n};\n\n// src/components/RenderModal/SchemaEditor/scroll-to-default-props-path.ts\nimport React69 from \"react\";\nvar DEFAULT_PROPS_PATH_CLASSNAME = \"__remotion-default-props-editor-label\";\nvar DEFAULT_PROPS_PATH_ACTIVE_CLASSNAME = \"__remotion-default-props-editor-label-active\";\nvar defaultPropsEditorScrollableAreaRef = React69.createRef();\n\n// src/components/RenderModal/SchemaEditor/SchemaLabel.tsx\nimport { jsx as jsx106, jsxs as jsxs48 } from \"react/jsx-runtime\";\nvar compactStyles = {\n  fontSize: 15,\n  color: LIGHT_TEXT,\n  fontFamily: \"sans-serif\",\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  flex: 1\n};\nvar SchemaLabel = ({\n  jsonPath,\n  isDefaultValue,\n  onReset,\n  onSave,\n  showSaveButton,\n  onRemove,\n  saving,\n  valid,\n  saveDisabledByParent,\n  suffix: suffix2,\n  handleClick\n}) => {\n  const [clickableButtonHovered, setClickableButtonHovered] = useState40(false);\n  const disableSave = saving || !valid || saveDisabledByParent;\n  const labelStyle4 = useMemo59(() => {\n    return {\n      fontFamily: \"monospace\",\n      fontSize: 14,\n      color: valid ? clickableButtonHovered ? \"white\" : LIGHT_TEXT : FAIL_COLOR,\n      lineHeight: \"24px\"\n    };\n  }, [clickableButtonHovered, valid]);\n  const onClickablePointerEnter = useCallback49(() => {\n    setClickableButtonHovered(true);\n  }, []);\n  const onClickablePointerLeave = useCallback49(() => {\n    setClickableButtonHovered(false);\n  }, []);\n  const labelContent = /* @__PURE__ */ jsxs48(\"span\", {\n    style: labelStyle4,\n    children: [\n      getSchemaLabel(jsonPath),\n      \" \",\n      suffix2 ? suffix2 : null\n    ]\n  });\n  return /* @__PURE__ */ jsxs48(\"div\", {\n    style: compactStyles,\n    className: DEFAULT_PROPS_PATH_CLASSNAME,\n    \"data-json-path\": jsonPath.join(\".\"),\n    children: [\n      handleClick ? /* @__PURE__ */ jsx106(\"button\", {\n        onPointerEnter: onClickablePointerEnter,\n        onPointerLeave: onClickablePointerLeave,\n        type: \"button\",\n        onClick: handleClick,\n        style: { border: \"none\", padding: 0 },\n        children: labelContent\n      }) : labelContent,\n      /* @__PURE__ */ jsx106(Flex, {}),\n      isDefaultValue ? null : /* @__PURE__ */ jsx106(SchemaResetButton, {\n        onClick: onReset\n      }),\n      isDefaultValue ? null : showSaveButton ? /* @__PURE__ */ jsx106(SchemaSaveButton, {\n        onClick: onSave,\n        disabled: disableSave\n      }) : null,\n      onRemove ? /* @__PURE__ */ jsx106(InlineRemoveButton, {\n        onClick: onRemove\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/SchemaSeparationLine.tsx\nimport { useCallback as useCallback50, useMemo as useMemo60, useState as useState41 } from \"react\";\n\n// src/icons/plus.tsx\nimport { jsx as jsx107 } from \"react/jsx-runtime\";\nvar Plus = ({ color, ...props }) => {\n  return /* @__PURE__ */ jsx107(\"svg\", {\n    ...props,\n    xmlns: \"http://www.w3.org/2000/svg\",\n    viewBox: \"0 0 448 512\",\n    children: /* @__PURE__ */ jsx107(\"path\", {\n      fill: color,\n      d: \"M432 256c0 17.69-14.33 32.01-32 32.01H256v144c0 17.69-14.33 31.99-32 31.99s-32-14.3-32-31.99v-144H48c-17.67 0-32-14.32-32-32.01s14.33-31.99 32-31.99H192v-144c0-17.69 14.33-32.01 32-32.01s32 14.32 32 32.01v144h144C417.7 224 432 238.3 432 256z\"\n    })\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/create-zod-values.ts\nvar createZodValues = (schema, zodRuntime, zodTypes) => {\n  if (!schema) {\n    throw new Error(\"Invalid zod schema\");\n  }\n  const def = schema._def;\n  const typeName = def.typeName;\n  switch (typeName) {\n    case zodRuntime.ZodFirstPartyTypeKind.ZodString:\n      return \"\";\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNumber: {\n      for (const check of def.checks) {\n        if (check.kind === \"min\") {\n          return check.value;\n        }\n        if (check.kind === \"max\" && check.value < 0) {\n          return check.value;\n        }\n      }\n      return 0;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodBigInt:\n      return BigInt(0);\n    case zodRuntime.ZodFirstPartyTypeKind.ZodBoolean:\n      return false;\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNaN:\n      return NaN;\n    case zodRuntime.ZodFirstPartyTypeKind.ZodDate:\n      return new Date;\n    case zodRuntime.ZodFirstPartyTypeKind.ZodSymbol:\n      return Symbol(\"remotion\");\n    case zodRuntime.ZodFirstPartyTypeKind.ZodUndefined:\n      return;\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNull:\n      return null;\n    case zodRuntime.ZodFirstPartyTypeKind.ZodAny:\n      throw new Error(\"Cannot create a value for type z.any()\");\n    case zodRuntime.ZodFirstPartyTypeKind.ZodUnknown:\n      throw new Error(\"Cannot create a value for type z.unknown()\");\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNever:\n      throw new Error(\"Cannot create a value for type z.never()\");\n    case zodRuntime.ZodFirstPartyTypeKind.ZodVoid:\n      return;\n    case zodRuntime.ZodFirstPartyTypeKind.ZodObject: {\n      const shape = def.shape();\n      const keys = Object.keys(shape);\n      const returnValue = keys.reduce((existing, key) => {\n        existing[key] = createZodValues(shape[key], zodRuntime, zodTypes);\n        return existing;\n      }, {});\n      return returnValue;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodArray: {\n      return [\n        createZodValues(def.type, zodRuntime, zodTypes)\n      ];\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodUnion: {\n      const firstOptions = def.options[0];\n      return firstOptions ? createZodValues(firstOptions, zodRuntime, zodTypes) : undefined;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodDiscriminatedUnion: {\n      const options = def.options[0];\n      return createZodValues(options, zodRuntime, zodTypes);\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodLiteral: {\n      return def.value;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodEffects: {\n      if (zodTypes && schema._def.description === zodTypes.ZodZypesInternals.REMOTION_COLOR_BRAND) {\n        return \"#ffffff\";\n      }\n      if (zodTypes && schema._def.description === zodTypes.ZodZypesInternals.REMOTION_TEXTAREA_BRAND) {\n        return \"\";\n      }\n      if (zodTypes && schema._def.description === zodTypes.ZodZypesInternals.REMOTION_MATRIX_BRAND) {\n        return [\n          [1, 0, 0],\n          [0, 1, 0],\n          [0, 0, 1]\n        ];\n      }\n      return createZodValues(def.schema, zodRuntime, zodTypes);\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodIntersection: {\n      const { left: left3, right } = def;\n      const leftValue = createZodValues(left3, zodRuntime, zodTypes);\n      if (typeof leftValue !== \"object\") {\n        throw new Error(\"Cannot create value for type z.intersection: Left side is not an object\");\n      }\n      const rightValue = createZodValues(right, zodRuntime, zodTypes);\n      if (typeof rightValue !== \"object\") {\n        throw new Error(\"Cannot create value for type z.intersection: Right side is not an object\");\n      }\n      return { ...leftValue, ...rightValue };\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodTuple: {\n      const items = def.items.map((item2) => createZodValues(item2, zodRuntime, zodTypes));\n      return items;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodRecord: {\n      const values = createZodValues(def.valueType, zodRuntime, zodTypes);\n      return { key: values };\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodMap: {\n      const defType = def;\n      const values = createZodValues(defType.valueType, zodRuntime, zodTypes);\n      const key = createZodValues(defType.keyType, zodRuntime, zodTypes);\n      return new Map([[key, values]]);\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodLazy: {\n      const defType = def;\n      const type = defType.getter();\n      return createZodValues(type, zodRuntime, zodTypes);\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodSet: {\n      const defType = def;\n      const values = createZodValues(defType.valueType, zodRuntime, zodTypes);\n      return new Set([values]);\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodFunction: {\n      throw new Error(\"Cannot create a value for type function\");\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodEnum: {\n      const { values } = def;\n      return values[0];\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNativeEnum: {\n      return 0;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodOptional: {\n      const defType = def;\n      const value = createZodValues(defType.innerType, zodRuntime, zodTypes);\n      return value;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodNullable: {\n      const defType = def;\n      const value = createZodValues(defType.innerType, zodRuntime, zodTypes);\n      return value;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodDefault: {\n      const defType = def;\n      return defType.defaultValue();\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodCatch: {\n      const defType = def;\n      const value = createZodValues(defType.innerType, zodRuntime, zodTypes);\n      return value;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodPromise: {\n      const defType = def;\n      const value = createZodValues(defType.type, zodRuntime, zodTypes);\n      return Promise.resolve(value);\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodBranded: {\n      const defType = def;\n      const value = createZodValues(defType.type, zodRuntime, zodTypes);\n      return value;\n    }\n    case zodRuntime.ZodFirstPartyTypeKind.ZodPipeline: {\n      const defType = def;\n      const value = createZodValues(defType.out, zodRuntime, zodTypes);\n      return value;\n    }\n    default:\n      throw new Error(\"Not implemented: \" + typeName);\n  }\n};\n\n// src/components/RenderModal/SchemaEditor/SchemaSeparationLine.tsx\nimport { jsx as jsx108, jsxs as jsxs49, Fragment as Fragment18 } from \"react/jsx-runtime\";\nvar VERTICAL_GUIDE_HEIGHT = 24;\nvar line2 = {\n  borderBottom: \"1px solid \" + LINE_COLOR\n};\nvar SchemaSeparationLine = () => {\n  return /* @__PURE__ */ jsx108(\"div\", {\n    style: line2\n  });\n};\nvar arraySeparationLine = {\n  borderBottom: \"1px solid \" + LINE_COLOR,\n  marginTop: -VERTICAL_GUIDE_HEIGHT / 2,\n  pointerEvents: \"none\",\n  width: \"100%\",\n  flexBasis: \"100%\"\n};\nvar SchemaArrayItemSeparationLine = ({ onChange, index, schema, isLast, showAddButton }) => {\n  const [outerHovered, setOuterHovered] = useState41(false);\n  const [innerHovered, setInnerHovered] = useState41(false);\n  const zodTypes = useZodTypesIfPossible();\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const def = schema._def;\n  const onAdd = useCallback50(() => {\n    onChange((oldV) => {\n      return [\n        ...oldV.slice(0, index + 1),\n        createZodValues(def.type, z, zodTypes),\n        ...oldV.slice(index + 1)\n      ];\n    }, false, true);\n  }, [def.type, index, onChange, z, zodTypes]);\n  const dynamicAddButtonStyle = useMemo60(() => {\n    return {\n      display: \"flex\",\n      justifyContent: \"center\",\n      height: VERTICAL_GUIDE_HEIGHT,\n      opacity: outerHovered || isLast ? 1 : 0,\n      position: \"absolute\",\n      top: \"50%\",\n      left: \"50%\",\n      transform: \"translate(-50%, -50%)\"\n    };\n  }, [isLast, outerHovered]);\n  const inner = useMemo60(() => {\n    return {\n      background: BACKGROUND,\n      paddingLeft: 10,\n      paddingRight: 10\n    };\n  }, []);\n  const onOuterMouseEnter = useCallback50(() => {\n    setOuterHovered(true);\n  }, []);\n  const onOuterMouseLeave = useCallback50(() => {\n    setOuterHovered(false);\n  }, []);\n  const onInnerMouseEnter = useCallback50(() => {\n    setInnerHovered(true);\n  }, []);\n  const onInnerMouseLeave = useCallback50(() => {\n    setInnerHovered(false);\n  }, []);\n  return /* @__PURE__ */ jsxs49(\"div\", {\n    style: {\n      display: \"flex\",\n      flexDirection: \"row\",\n      height: VERTICAL_GUIDE_HEIGHT\n    },\n    children: [\n      /* @__PURE__ */ jsxs49(\"div\", {\n        style: {\n          flex: 1,\n          position: \"relative\",\n          display: \"flex\",\n          flexDirection: \"column\",\n          alignItems: \"flex-end\"\n        },\n        children: [\n          showAddButton && /* @__PURE__ */ jsx108(\"div\", {\n            style: dynamicAddButtonStyle,\n            onPointerEnter: onOuterMouseEnter,\n            onPointerLeave: onOuterMouseLeave,\n            children: /* @__PURE__ */ jsx108(\"div\", {\n              onClick: onAdd,\n              style: inner,\n              onPointerEnter: onInnerMouseEnter,\n              onPointerLeave: onInnerMouseLeave,\n              children: /* @__PURE__ */ jsx108(Plus, {\n                color: innerHovered ? \"white\" : LIGHT_TEXT,\n                style: { height: VERTICAL_GUIDE_HEIGHT / 2 }\n              })\n            })\n          }),\n          /* @__PURE__ */ jsx108(\"div\", {\n            style: arraySeparationLine\n          })\n        ]\n      }),\n      isLast ? /* @__PURE__ */ jsxs49(Fragment18, {\n        children: [\n          /* @__PURE__ */ jsx108(Spacing, {\n            x: 1\n          }),\n          /* @__PURE__ */ jsx108(\"div\", {\n            style: {\n              ...fieldSetText,\n              alignItems: \"center\",\n              display: \"flex\"\n            },\n            children: \"]\"\n          })\n        ]\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/SchemaVerticalGuide.tsx\nimport { useMemo as useMemo61 } from \"react\";\nimport { jsx as jsx109, jsxs as jsxs50 } from \"react/jsx-runtime\";\nvar flex = {\n  flex: 1\n};\nvar SchemaVerticalGuide = ({ isRoot, children }) => {\n  const outer = useMemo61(() => {\n    return {\n      display: \"flex\",\n      flexDirection: \"row\",\n      position: \"relative\",\n      marginLeft: isRoot ? 0 : 4\n    };\n  }, [isRoot]);\n  const inner = useMemo61(() => {\n    return isRoot ? {} : {\n      height: `calc(100% - ${VERTICAL_GUIDE_HEIGHT / 2}px)`,\n      width: 1,\n      background: \"#363A3E\",\n      position: \"absolute\"\n    };\n  }, [isRoot]);\n  return /* @__PURE__ */ jsxs50(\"div\", {\n    style: outer,\n    children: [\n      /* @__PURE__ */ jsx109(\"div\", {\n        style: inner\n      }),\n      /* @__PURE__ */ jsx109(\"div\", {\n        style: flex,\n        children\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodArrayEditor.tsx\nimport React76, { useMemo as useMemo66, useState as useState44 } from \"react\";\n\n// src/components/RenderModal/SchemaEditor/ZodArrayItemEditor.tsx\nimport { useCallback as useCallback51, useMemo as useMemo62 } from \"react\";\nimport { jsx as jsx110 } from \"react/jsx-runtime\";\nvar ZodArrayItemEditor = ({\n  def,\n  onChange,\n  jsonPath,\n  index,\n  value,\n  defaultValue,\n  onSave: onSaveObject,\n  showSaveButton,\n  saving,\n  saveDisabledByParent,\n  mayPad,\n  mayRemove\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const onRemove = useCallback51(() => {\n    onChange((oldV) => [...oldV.slice(0, index), ...oldV.slice(index + 1)], false, true);\n  }, [index, onChange]);\n  const setValue = useCallback51((val) => {\n    onChange((oldV) => [\n      ...oldV.slice(0, index),\n      typeof val === \"function\" ? val(oldV[index]) : val,\n      ...oldV.slice(index + 1)\n    ], false, false);\n  }, [index, onChange]);\n  const newJsonPath = useMemo62(() => [...jsonPath, index], [index, jsonPath]);\n  const onSave = useCallback51((updater) => {\n    onSaveObject((oldV) => [\n      ...oldV.slice(0, index),\n      updater(oldV[index]),\n      ...oldV.slice(index + 1)\n    ], false, false);\n  }, [index, onSaveObject]);\n  return /* @__PURE__ */ jsx110(\"div\", {\n    children: /* @__PURE__ */ jsx110(ZodSwitch, {\n      jsonPath: newJsonPath,\n      schema: def.type,\n      value,\n      setValue,\n      defaultValue,\n      onSave,\n      showSaveButton,\n      onRemove: mayRemove ? onRemove : null,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    })\n  });\n};\n\n// src/components/RenderModal/InfoBubble.tsx\nimport { PlayerInternals as PlayerInternals11 } from \"@remotion/player\";\nimport { useCallback as useCallback52, useEffect as useEffect41, useMemo as useMemo64, useRef as useRef25, useState as useState42 } from \"react\";\nimport ReactDOM7 from \"react-dom\";\n\n// src/components/RenderModal/InfoTooltip.tsx\nimport { useMemo as useMemo63 } from \"react\";\nimport { jsx as jsx111, jsxs as jsxs51 } from \"react/jsx-runtime\";\nvar arrow = {\n  height: 7,\n  display: \"block\",\n  overflow: \"visible\",\n  marginLeft: 7\n};\nvar arrowUp = {\n  ...arrow,\n  transform: `translateY(1px)`\n};\nvar arrowDown = {\n  ...arrow,\n  marginTop: -1\n};\nvar InfoTooltip = ({ children, arrowDirection, backgroundColor }) => {\n  const container27 = useMemo63(() => {\n    return {\n      boxShadow: arrowDirection === \"down\" ? SHADOW_TOWARDS_TOP : SHADOW_TOWARDS_BOTTOM,\n      background: backgroundColor,\n      color: \"white\",\n      border: \"0.5px solid \" + BORDER_COLOR,\n      maxHeight: 200,\n      overflow: \"auto\",\n      borderRadius: \"4px\"\n    };\n  }, [arrowDirection, backgroundColor]);\n  return /* @__PURE__ */ jsxs51(\"div\", {\n    style: {\n      display: \"flex\",\n      flexDirection: arrowDirection === \"up\" ? \"column-reverse\" : \"column\",\n      alignItems: \"flex-start\"\n    },\n    children: [\n      /* @__PURE__ */ jsx111(\"div\", {\n        style: container27,\n        className: VERTICAL_SCROLLBAR_CLASSNAME,\n        children\n      }),\n      arrowDirection === \"down\" ? /* @__PURE__ */ jsx111(\"svg\", {\n        viewBox: \"0 0 14 7\",\n        style: arrowDown,\n        children: /* @__PURE__ */ jsx111(\"path\", {\n          d: `M 14 0 L 7 7 L 0 0`,\n          fill: backgroundColor,\n          strokeLinecap: \"butt\",\n          stroke: BORDER_COLOR,\n          strokeWidth: 0.5\n        })\n      }) : null,\n      arrowDirection === \"up\" ? /* @__PURE__ */ jsx111(\"svg\", {\n        viewBox: \"0 0 14 7\",\n        style: arrowUp,\n        children: /* @__PURE__ */ jsx111(\"path\", {\n          d: `M 0 7 L 7 0 L 14 7`,\n          fill: backgroundColor,\n          strokeLinecap: \"butt\",\n          stroke: BORDER_COLOR,\n          strokeWidth: 0.5\n        })\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/InfoBubble.tsx\nimport { jsx as jsx112, jsxs as jsxs52, Fragment as Fragment19 } from \"react/jsx-runtime\";\nvar icon4 = {\n  color: LIGHT_TEXT,\n  height: 15\n};\nvar container27 = {\n  display: \"inline-block\",\n  border: \"none\",\n  fontSize: 14,\n  verticalAlign: \"text-bottom\"\n};\nvar InfoBubble = ({ title: title3, children }) => {\n  const [hovered, setIsHovered] = useState42(false);\n  const [opened, setOpened] = useState42(false);\n  const ref = useRef25(null);\n  const { tabIndex, currentZIndex } = useZIndex();\n  const size2 = PlayerInternals11.useElementSize(ref, {\n    triggerOnWindowResize: true,\n    shouldApplyCssTransforms: true\n  });\n  const refresh = size2?.refresh;\n  const onHide = useCallback52(() => {\n    setOpened(false);\n  }, []);\n  useEffect41(() => {\n    const { current } = ref;\n    if (!current) {\n      return;\n    }\n    const onMouseEnter = () => setIsHovered(true);\n    const onMouseLeave = () => setIsHovered(false);\n    const onPointerUp = () => {\n      return setOpened((o) => {\n        if (!o) {\n          refresh?.();\n        }\n        return !o;\n      });\n    };\n    const onClick = (e) => {\n      e.stopPropagation();\n      const isKeyboardInitiated = e.detail === 0;\n      if (!isKeyboardInitiated) {\n        return;\n      }\n      return setOpened((o) => {\n        return !o;\n      });\n    };\n    current.addEventListener(\"mouseenter\", onMouseEnter);\n    current.addEventListener(\"mouseleave\", onMouseLeave);\n    current.addEventListener(\"pointerup\", onPointerUp);\n    current.addEventListener(\"click\", onClick);\n    return () => {\n      current.removeEventListener(\"mouseenter\", onMouseEnter);\n      current.removeEventListener(\"mouseleave\", onMouseLeave);\n      current.removeEventListener(\"pointerup\", onPointerUp);\n      current.removeEventListener(\"click\", onClick);\n    };\n  }, [refresh]);\n  const layout = useMemo64(() => {\n    if (!size2) {\n      return \"down\";\n    }\n    const spaceToBottom = size2.windowSize.height - (size2.top + size2.height);\n    const spaceToTop = size2.top;\n    const l = spaceToTop > spaceToBottom ? \"down\" : \"up\";\n    return l;\n  }, [size2]);\n  const portalStyle = useMemo64(() => {\n    if (!size2 || !opened) {\n      return null;\n    }\n    return {\n      ...layout === \"up\" ? {\n        position: \"fixed\",\n        top: size2.top + size2.height\n      } : {\n        position: \"fixed\",\n        bottom: size2.windowSize.height - size2.top\n      },\n      left: size2.left\n    };\n  }, [layout, opened, size2]);\n  const style8 = useMemo64(() => {\n    return {\n      ...container27,\n      userSelect: \"none\",\n      WebkitUserSelect: \"none\",\n      color: \"white\",\n      display: \"inline-flex\",\n      flexDirection: \"row\",\n      alignItems: \"center\",\n      padding: 6\n    };\n  }, []);\n  return /* @__PURE__ */ jsxs52(Fragment19, {\n    children: [\n      /* @__PURE__ */ jsx112(\"button\", {\n        ref,\n        tabIndex,\n        style: style8,\n        title: title3,\n        type: \"button\",\n        children: /* @__PURE__ */ jsx112(\"svg\", {\n          style: icon4,\n          viewBox: \"0 0 512 512\",\n          children: /* @__PURE__ */ jsx112(\"path\", {\n            fill: hovered ? \"white\" : LIGHT_TEXT,\n            d: \"M256 48a208 208 0 1 1 0 416 208 208 0 1 1 0-416zm0 464A256 256 0 1 0 256 0a256 256 0 1 0 0 512zM216 336c-13.3 0-24 10.7-24 24s10.7 24 24 24h80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8V248c0-13.3-10.7-24-24-24H216c-13.3 0-24 10.7-24 24s10.7 24 24 24h24v64H216zm40-144a32 32 0 1 0 0-64 32 32 0 1 0 0 64z\"\n          })\n        })\n      }),\n      portalStyle ? ReactDOM7.createPortal(/* @__PURE__ */ jsx112(\"div\", {\n        style: outerPortal,\n        className: \"css-reset\",\n        children: /* @__PURE__ */ jsx112(HigherZIndex, {\n          onOutsideClick: onHide,\n          onEscape: onHide,\n          children: /* @__PURE__ */ jsx112(\"div\", {\n            style: portalStyle,\n            children: /* @__PURE__ */ jsx112(InfoTooltip, {\n              backgroundColor: INPUT_BACKGROUND,\n              arrowDirection: layout,\n              children\n            })\n          })\n        })\n      }), getPortal(currentZIndex)) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodFieldValidation.tsx\nimport { jsx as jsx113, jsxs as jsxs53 } from \"react/jsx-runtime\";\nvar legend = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar stackTrace = {\n  padding: 10\n};\nvar stackTraceLabel = {\n  fontSize: 14\n};\nvar ZodFieldValidation = ({ localValue, path }) => {\n  if (localValue.zodValidation.success) {\n    return null;\n  }\n  return /* @__PURE__ */ jsxs53(\"div\", {\n    style: legend,\n    children: [\n      /* @__PURE__ */ jsx113(ValidationMessage, {\n        align: \"flex-start\",\n        message: localValue.zodValidation.error.format()._errors[0],\n        type: \"error\"\n      }),\n      /* @__PURE__ */ jsx113(Spacing, {\n        x: 0.5\n      }),\n      /* @__PURE__ */ jsx113(InfoBubble, {\n        title: \"Zod validation failure\",\n        children: /* @__PURE__ */ jsxs53(\"div\", {\n          style: stackTrace,\n          children: [\n            /* @__PURE__ */ jsx113(\"div\", {\n              style: stackTraceLabel,\n              children: \"Zod Validation has failed:\"\n            }),\n            localValue.zodValidation.error.errors.map((error, index) => /* @__PURE__ */ jsxs53(\"div\", {\n              style: stackTraceLabel,\n              children: [\n                \"Type: \",\n                error.code,\n                \" \",\n                /* @__PURE__ */ jsx113(\"br\", {}),\n                \"Message: \",\n                error.message,\n                /* @__PURE__ */ jsx113(\"br\", {}),\n                \"Path: \",\n                path.join(\".\")\n              ]\n            }, index))\n          ]\n        })\n      }),\n      /* @__PURE__ */ jsx113(Spacing, {\n        x: 0.5\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/local-state.tsx\nimport {\n  createContext as createContext18,\n  useCallback as useCallback53,\n  useContext as useContext35,\n  useEffect as useEffect42,\n  useMemo as useMemo65,\n  useRef as useRef26,\n  useState as useState43\n} from \"react\";\nimport { Internals as Internals29 } from \"remotion\";\nimport { jsx as jsx114 } from \"react/jsx-runtime\";\nvar RevisionContext = createContext18({\n  childResetRevision: 0\n});\nvar useLocalState = ({\n  unsavedValue,\n  schema,\n  setValue,\n  savedValue\n}) => {\n  const parentRevision = useContext35(RevisionContext).childResetRevision;\n  const [resetRevision, setResetRevision] = useState43(0);\n  const [localValueOrNull, setLocalValue] = useState43(() => {\n    return {\n      [parentRevision]: {\n        value: unsavedValue,\n        keyStabilityRevision: 0,\n        zodValidation: schema.safeParse(unsavedValue)\n      }\n    };\n  });\n  const localUnsavedValue = useMemo65(() => {\n    if ((localValueOrNull[parentRevision] ?? null) === null) {\n      return {\n        value: unsavedValue,\n        keyStabilityRevision: 0,\n        zodValidation: schema.safeParse(unsavedValue)\n      };\n    }\n    return localValueOrNull[parentRevision];\n  }, [localValueOrNull, parentRevision, schema, unsavedValue]);\n  useEffect42(() => {\n    const checkFile = () => {\n      setResetRevision((old) => old + 1);\n      setLocalValue({});\n    };\n    window.addEventListener(Internals29.PROPS_UPDATED_EXTERNALLY, checkFile);\n    return () => {\n      window.removeEventListener(Internals29.PROPS_UPDATED_EXTERNALLY, checkFile);\n    };\n  }, []);\n  const currentLocalValue = useMemo65(() => {\n    return localUnsavedValue ?? {\n      value: savedValue,\n      keyStabilityRevision: 0,\n      zodValidation: schema.safeParse(savedValue)\n    };\n  }, [localUnsavedValue, savedValue, schema]);\n  const stateRef = useRef26(currentLocalValue);\n  stateRef.current = currentLocalValue;\n  const onChange = useCallback53((updater, forceApply, increment) => {\n    const newValue = updater(stateRef.current.value);\n    const isSame = deepEqual(newValue, stateRef.current.value);\n    if (isSame) {\n      return;\n    }\n    const safeParse = schema.safeParse(newValue);\n    if (safeParse.success || forceApply) {\n      setValue(updater, forceApply, increment);\n    }\n    setLocalValue(() => {\n      const newState = {\n        keyStabilityRevision: currentLocalValue.keyStabilityRevision + (increment ? 1 : 0),\n        value: newValue,\n        zodValidation: safeParse\n      };\n      stateRef.current = newState;\n      return {\n        ...localUnsavedValue,\n        [parentRevision]: newState\n      };\n    });\n  }, [\n    currentLocalValue.keyStabilityRevision,\n    localUnsavedValue,\n    parentRevision,\n    schema,\n    setValue\n  ]);\n  const contextValue = useMemo65(() => {\n    return {\n      childResetRevision: resetRevision\n    };\n  }, [resetRevision]);\n  const reset = useCallback53(() => {\n    onChange(() => savedValue, true, true);\n    setResetRevision((old) => old + 1);\n  }, [savedValue, onChange]);\n  const RevisionContextProvider = useCallback53(({ children }) => {\n    return /* @__PURE__ */ jsx114(RevisionContext.Provider, {\n      value: contextValue,\n      children\n    });\n  }, [contextValue]);\n  return useMemo65(() => ({\n    localValue: currentLocalValue,\n    onChange,\n    reset,\n    RevisionContextProvider\n  }), [RevisionContextProvider, currentLocalValue, onChange, reset]);\n};\n\n// src/components/RenderModal/SchemaEditor/ZodArrayEditor.tsx\nimport { jsx as jsx115, jsxs as jsxs54 } from \"react/jsx-runtime\";\nvar ZodArrayEditor = ({\n  schema,\n  jsonPath,\n  setValue,\n  defaultValue,\n  value,\n  onSave,\n  showSaveButton,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const { localValue, onChange, RevisionContextProvider, reset } = useLocalState({\n    unsavedValue: value,\n    schema,\n    setValue,\n    savedValue: defaultValue\n  });\n  const [expanded, setExpanded] = useState44(true);\n  const def = schema._def;\n  const suffix2 = useMemo66(() => {\n    return expanded ? \" [\" : \" [...] \";\n  }, [expanded]);\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const zodTypes = useZodTypesIfPossible();\n  const typeName = def.typeName;\n  if (typeName !== z.ZodFirstPartyTypeKind.ZodArray) {\n    throw new Error(\"expected object\");\n  }\n  const isDefaultValue = useMemo66(() => {\n    return deepEqual(localValue.value, defaultValue);\n  }, [defaultValue, localValue]);\n  return /* @__PURE__ */ jsxs54(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx115(\"div\", {\n        style: {\n          display: \"flex\",\n          flexDirection: \"row\"\n        },\n        children: /* @__PURE__ */ jsx115(SchemaLabel, {\n          onReset: reset,\n          isDefaultValue,\n          jsonPath,\n          onRemove,\n          suffix: suffix2,\n          onSave: () => {\n            onSave(() => localValue.value, false, false);\n          },\n          saveDisabledByParent,\n          saving,\n          showSaveButton,\n          valid: localValue.zodValidation.success,\n          handleClick: () => setExpanded(!expanded)\n        })\n      }),\n      expanded ? /* @__PURE__ */ jsx115(RevisionContextProvider, {\n        children: /* @__PURE__ */ jsxs54(SchemaVerticalGuide, {\n          isRoot: false,\n          children: [\n            localValue.value.map((child, i) => {\n              return /* @__PURE__ */ jsxs54(React76.Fragment, {\n                children: [\n                  /* @__PURE__ */ jsx115(ZodArrayItemEditor, {\n                    onChange,\n                    value: child,\n                    def,\n                    index: i,\n                    jsonPath,\n                    defaultValue: defaultValue?.[i] ?? createZodValues(def.type, z, zodTypes),\n                    onSave,\n                    showSaveButton,\n                    saving,\n                    saveDisabledByParent,\n                    mayPad,\n                    mayRemove: true\n                  }),\n                  /* @__PURE__ */ jsx115(SchemaArrayItemSeparationLine, {\n                    schema,\n                    index: i,\n                    onChange,\n                    isLast: i === localValue.value.length - 1,\n                    showAddButton: true\n                  })\n                ]\n              }, `${i}${localValue.keyStabilityRevision}`);\n            }),\n            value.length === 0 ? /* @__PURE__ */ jsx115(SchemaArrayItemSeparationLine, {\n              schema,\n              index: 0,\n              onChange,\n              isLast: true,\n              showAddButton: true\n            }) : null\n          ]\n        })\n      }) : null,\n      /* @__PURE__ */ jsx115(ZodFieldValidation, {\n        path: jsonPath,\n        localValue\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodBooleanEditor.tsx\nimport { useCallback as useCallback54 } from \"react\";\n\n// src/components/Checkbox.tsx\nimport { useEffect as useEffect43, useMemo as useMemo67, useRef as useRef27 } from \"react\";\nimport { jsx as jsx116, jsxs as jsxs55 } from \"react/jsx-runtime\";\nvar size2 = 20;\nvar background = {\n  height: size2,\n  width: size2,\n  position: \"relative\"\n};\nvar bullet = {\n  width: 10,\n  height: 10,\n  backgroundColor: LIGHT_TEXT,\n  borderRadius: \"50%\"\n};\nvar box = {\n  display: \"flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  position: \"absolute\",\n  height: size2,\n  width: size2,\n  top: 0,\n  left: 0,\n  pointerEvents: \"none\",\n  color: \"white\"\n};\nvar Checkbox = ({ checked, onChange, disabled, name, rounded }) => {\n  const ref = useRef27(null);\n  const input2 = useMemo67(() => {\n    return {\n      appearance: \"none\",\n      background: disabled ? \"transparent\" : INPUT_BACKGROUND,\n      border: \"1px solid \" + INPUT_BORDER_COLOR_UNHOVERED,\n      height: size2,\n      width: size2,\n      top: 0,\n      left: 0,\n      position: \"absolute\",\n      margin: 0\n    };\n  }, [disabled]);\n  useEffect43(() => {\n    if (ref.current) {\n      ref.current.style.setProperty(\"border-radius\", rounded ? \"50%\" : \"0%\", \"important\");\n    }\n  }, [rounded]);\n  return /* @__PURE__ */ jsxs55(\"div\", {\n    style: background,\n    children: [\n      /* @__PURE__ */ jsx116(\"input\", {\n        ref,\n        style: input2,\n        type: \"checkbox\",\n        checked,\n        onChange,\n        disabled,\n        name\n      }),\n      /* @__PURE__ */ jsx116(\"div\", {\n        style: box,\n        children: checked ? rounded ? /* @__PURE__ */ jsx116(\"div\", {\n          style: bullet\n        }) : /* @__PURE__ */ jsx116(Checkmark, {}) : null\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodBooleanEditor.tsx\nimport { jsx as jsx117, jsxs as jsxs56 } from \"react/jsx-runtime\";\nvar fullWidth = {\n  width: \"100%\"\n};\nvar ZodBooleanEditor = ({\n  schema,\n  jsonPath,\n  value,\n  setValue,\n  onSave,\n  defaultValue,\n  onRemove,\n  showSaveButton,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const { localValue, onChange, reset } = useLocalState({\n    schema,\n    setValue,\n    unsavedValue: value,\n    savedValue: defaultValue\n  });\n  const onToggle = useCallback54((e) => {\n    onChange(() => e.target.checked, false, false);\n  }, [onChange]);\n  const save = useCallback54(() => {\n    onSave(() => value, false, false);\n  }, [onSave, value]);\n  return /* @__PURE__ */ jsxs56(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx117(SchemaLabel, {\n        handleClick: null,\n        isDefaultValue: localValue.value === defaultValue,\n        jsonPath,\n        onReset: reset,\n        onSave: save,\n        showSaveButton,\n        onRemove,\n        saving,\n        valid: true,\n        saveDisabledByParent,\n        suffix: null\n      }),\n      /* @__PURE__ */ jsx117(\"div\", {\n        style: fullWidth,\n        children: /* @__PURE__ */ jsx117(Checkbox, {\n          name: jsonPath.join(\".\"),\n          checked: localValue.value,\n          onChange: onToggle,\n          disabled: false\n        })\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodColorEditor.tsx\nimport { useCallback as useCallback56, useMemo as useMemo70 } from \"react\";\n\n// src/helpers/color-math.ts\nvar colorWithNewOpacity = (color, opacity, zodTypes) => {\n  const { r, g, b } = zodTypes.ZodZypesInternals.parseColor(color);\n  if (opacity >= 255) {\n    return `#${r.toString(16).padStart(2, \"0\")}${g.toString(16).padStart(2, \"0\")}${b.toString(16).padStart(2, \"0\")}`;\n  }\n  return `rgba(${r}, ${g}, ${b}, ${(opacity / 255).toFixed(2)})`;\n};\n\n// src/components/NewComposition/InputDragger.tsx\nimport React79, { useCallback as useCallback55, useEffect as useEffect44, useMemo as useMemo68, useRef as useRef28, useState as useState45 } from \"react\";\nimport { interpolate as interpolate2 } from \"remotion\";\nimport { jsx as jsx118 } from \"react/jsx-runtime\";\nvar isInt = (num) => {\n  return num % 1 === 0;\n};\nvar InputDraggerForwardRefFn = ({\n  onValueChange,\n  min: _min,\n  max: _max,\n  step: _step,\n  value,\n  onTextChange,\n  formatter = (q) => String(q),\n  status,\n  rightAlign,\n  ...props\n}, ref) => {\n  const [inputFallback, setInputFallback] = useState45(false);\n  const fallbackRef = useRef28(null);\n  const style8 = useMemo68(() => {\n    return {\n      ...inputBaseStyle,\n      backgroundColor: \"transparent\",\n      borderColor: \"transparent\"\n    };\n  }, []);\n  const span = useMemo68(() => ({\n    borderBottom: \"1px dotted \" + BLUE,\n    paddingBottom: 1,\n    color: BLUE,\n    cursor: \"ew-resize\",\n    userSelect: \"none\",\n    WebkitUserSelect: \"none\",\n    fontSize: 13,\n    fontVariantNumeric: \"tabular-nums\"\n  }), []);\n  const onClick = useCallback55((e) => {\n    if (!getClickLock()) {\n      e.stopPropagation();\n    }\n    if (getClickLock()) {\n      return;\n    }\n    setInputFallback(true);\n  }, []);\n  const onEscape = useCallback55(() => {\n    setInputFallback(false);\n  }, []);\n  const onBlur = useCallback55(() => {\n    if (!fallbackRef.current) {\n      return;\n    }\n    const newValue = fallbackRef.current.value;\n    if (newValue.trim() === \"\") {\n      onEscape();\n      return;\n    }\n    if (fallbackRef.current.checkValidity()) {\n      onTextChange?.(newValue);\n      setInputFallback(false);\n    } else {\n      fallbackRef.current.reportValidity();\n    }\n  }, [onEscape, onTextChange]);\n  const onKeyPress = useCallback55((e) => {\n    if (e.key === \"Enter\") {\n      fallbackRef.current?.blur();\n    }\n  }, []);\n  const roundToStep = (val, stepSize) => {\n    const factor = 1 / stepSize;\n    return Math.ceil(val * factor) / factor;\n  };\n  const onPointerDown = useCallback55((e) => {\n    const { pageX, pageY, button: button3 } = e;\n    if (button3 !== 0) {\n      return;\n    }\n    const moveListener = (ev) => {\n      const xDistance = ev.pageX - pageX;\n      const distanceFromStart = Math.sqrt(xDistance ** 2 + (ev.pageY - pageY) ** 2);\n      const step = Number(_step ?? 1);\n      const min = Number(_min ?? 0);\n      const max = Number(_max ?? Infinity);\n      if (distanceFromStart > 4) {\n        setClickLock(true);\n      }\n      const diff = interpolate2(xDistance, [-5, -4, 0, 4, 5], [-step, 0, 0, 0, step]);\n      const newValue = Math.min(max, Math.max(min, Number(value) + diff));\n      const roundedToStep = roundToStep(newValue, step);\n      onValueChange(roundedToStep);\n    };\n    window.addEventListener(\"mousemove\", moveListener);\n    window.addEventListener(\"pointerup\", () => {\n      window.removeEventListener(\"mousemove\", moveListener);\n      setTimeout(() => {\n        setClickLock(false);\n      }, 2);\n    }, {\n      once: true\n    });\n  }, [_step, _min, _max, value, onValueChange]);\n  useEffect44(() => {\n    if (inputFallback) {\n      fallbackRef.current?.select();\n    }\n  }, [inputFallback]);\n  const deriveStep = useMemo68(() => {\n    if (_step !== undefined) {\n      return _step;\n    }\n    if (typeof _min === \"number\" && isInt(_min)) {\n      return 1;\n    }\n    return 0.0001;\n  }, [_min, _step]);\n  if (inputFallback) {\n    return /* @__PURE__ */ jsx118(HigherZIndex, {\n      onEscape,\n      onOutsideClick: noop,\n      children: /* @__PURE__ */ jsx118(RemotionInput, {\n        ref: fallbackRef,\n        autoFocus: true,\n        onKeyPress,\n        onBlur,\n        min: _min,\n        max: _max,\n        step: deriveStep,\n        defaultValue: value,\n        status,\n        pattern: \"[0-9]*[.]?[0-9]*\",\n        rightAlign,\n        ...props\n      })\n    });\n  }\n  return /* @__PURE__ */ jsx118(\"button\", {\n    ref,\n    type: \"button\",\n    style: style8,\n    onClick,\n    onPointerDown,\n    children: /* @__PURE__ */ jsx118(\"span\", {\n      style: span,\n      children: formatter(value)\n    })\n  });\n};\nvar InputDragger = React79.forwardRef(InputDraggerForwardRefFn);\n\n// src/components/NewComposition/RemInputTypeColor.tsx\nimport {\n  forwardRef as forwardRef4,\n  useEffect as useEffect45,\n  useImperativeHandle as useImperativeHandle11,\n  useMemo as useMemo69,\n  useRef as useRef29,\n  useState as useState46\n} from \"react\";\nimport { jsx as jsx119 } from \"react/jsx-runtime\";\nvar inputBaseStyle3 = {\n  padding: 0,\n  borderStyle: \"solid\",\n  borderWidth: 1\n};\nvar RemInputTypeColorForwardRef = ({ status, ...props }, ref) => {\n  const [isFocused, setIsFocused] = useState46(false);\n  const [isHovered, setIsHovered] = useState46(false);\n  const inputRef = useRef29(null);\n  const { tabIndex } = useZIndex();\n  const style8 = useMemo69(() => {\n    return {\n      backgroundColor: INPUT_BACKGROUND,\n      ...inputBaseStyle3,\n      borderColor: getInputBorderColor({ isFocused, isHovered, status }),\n      ...props.style ?? {}\n    };\n  }, [isFocused, isHovered, props.style, status]);\n  useImperativeHandle11(ref, () => {\n    return inputRef.current;\n  }, []);\n  useEffect45(() => {\n    if (!inputRef.current) {\n      return;\n    }\n    const { current } = inputRef;\n    const onFocus = () => setIsFocused(true);\n    const onBlur = () => setIsFocused(false);\n    const onMouseEnter = () => setIsHovered(true);\n    const onMouseLeave = () => setIsHovered(false);\n    current.addEventListener(\"focus\", onFocus);\n    current.addEventListener(\"blur\", onBlur);\n    current.addEventListener(\"mouseenter\", onMouseEnter);\n    current.addEventListener(\"mouseleave\", onMouseLeave);\n    return () => {\n      current.removeEventListener(\"focus\", onFocus);\n      current.removeEventListener(\"blur\", onBlur);\n      current.removeEventListener(\"mouseenter\", onMouseEnter);\n      current.removeEventListener(\"mouseleave\", onMouseLeave);\n    };\n  }, [inputRef]);\n  return /* @__PURE__ */ jsx119(\"input\", {\n    ref: inputRef,\n    type: \"color\",\n    tabIndex,\n    ...props,\n    name: props.name,\n    style: style8\n  });\n};\nvar RemInputTypeColor = forwardRef4(RemInputTypeColorForwardRef);\n\n// src/components/RenderModal/SchemaEditor/ZodColorEditor.tsx\nimport { jsx as jsx120, jsxs as jsxs57 } from \"react/jsx-runtime\";\nvar fullWidth2 = {\n  width: \"100%\"\n};\nvar ZodColorEditor = ({\n  jsonPath,\n  value,\n  setValue,\n  showSaveButton,\n  defaultValue,\n  schema,\n  onSave,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const zodTypes = useZodTypesIfPossible();\n  if (!zodTypes) {\n    throw new Error(\"expected zod color\");\n  }\n  const {\n    localValue,\n    onChange: onValueChange,\n    reset\n  } = useLocalState({\n    schema,\n    setValue,\n    unsavedValue: value,\n    savedValue: defaultValue\n  });\n  const { a, b, g, r } = localValue.zodValidation.success ? zodTypes.ZodZypesInternals.parseColor(localValue.value) : { a: 1, b: 0, g: 0, r: 0 };\n  const onChange = useCallback56((e) => {\n    const newColor = colorWithNewOpacity(e.target.value, Math.round(a), zodTypes);\n    onValueChange(() => newColor, false, false);\n  }, [a, onValueChange, zodTypes]);\n  const onTextChange = useCallback56((e) => {\n    const newValue = e.target.value;\n    onValueChange(() => newValue, false, false);\n  }, [onValueChange]);\n  const save = useCallback56(() => {\n    onSave(() => value, false, false);\n  }, [onSave, value]);\n  const rgb = `#${r.toString(16).padStart(2, \"0\")}${g.toString(16).padStart(2, \"0\")}${b.toString(16).padStart(2, \"0\")}`;\n  const status = localValue.zodValidation.success ? \"ok\" : \"error\";\n  const colorPicker = useMemo70(() => {\n    return {\n      height: 39,\n      width: 45,\n      display: \"inline-block\"\n    };\n  }, []);\n  const onOpacityChange = useCallback56((newValue) => {\n    const newColor = colorWithNewOpacity(localValue.value, Math.round(Number(newValue) / 100 * 255), zodTypes);\n    onValueChange(() => newColor, false, false);\n  }, [localValue.value, onValueChange, zodTypes]);\n  const onOpacityValueChange = useCallback56((newValue) => {\n    const newColor = colorWithNewOpacity(localValue.value, Math.round(Number(newValue) / 100 * 255), zodTypes);\n    onValueChange(() => newColor, false, false);\n  }, [localValue.value, onValueChange, zodTypes]);\n  return /* @__PURE__ */ jsxs57(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx120(SchemaLabel, {\n        handleClick: null,\n        isDefaultValue: localValue.value === defaultValue,\n        jsonPath,\n        onReset: reset,\n        onSave: save,\n        showSaveButton,\n        onRemove,\n        saving,\n        valid: localValue.zodValidation.success,\n        saveDisabledByParent,\n        suffix: null\n      }),\n      /* @__PURE__ */ jsxs57(\"div\", {\n        style: fullWidth2,\n        children: [\n          /* @__PURE__ */ jsxs57(Row, {\n            align: \"center\",\n            children: [\n              /* @__PURE__ */ jsx120(\"div\", {\n                style: colorPicker,\n                children: /* @__PURE__ */ jsx120(RemInputTypeColor, {\n                  type: \"color\",\n                  style: {\n                    height: 39\n                  },\n                  value: rgb,\n                  onChange,\n                  className: \"__remotion_color_picker\",\n                  status,\n                  name: jsonPath.join(\".\")\n                })\n              }),\n              /* @__PURE__ */ jsx120(Spacing, {\n                x: 1,\n                block: true\n              }),\n              /* @__PURE__ */ jsx120(RemotionInput, {\n                value: localValue.value,\n                status,\n                placeholder: jsonPath.join(\".\"),\n                onChange: onTextChange,\n                rightAlign: false\n              }),\n              /* @__PURE__ */ jsx120(Spacing, {\n                x: 1\n              }),\n              /* @__PURE__ */ jsx120(InputDragger, {\n                onTextChange: onOpacityChange,\n                onValueChange: onOpacityValueChange,\n                status,\n                value: a / 255 * 100,\n                min: 0,\n                max: 100,\n                step: 1,\n                formatter: (v) => `${Math.round(Number(v))}%`,\n                rightAlign: false\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx120(ZodFieldValidation, {\n            path: jsonPath,\n            localValue\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodDateEditor.tsx\nimport { useCallback as useCallback57 } from \"react\";\nimport { jsx as jsx121, jsxs as jsxs58 } from \"react/jsx-runtime\";\nvar fullWidth3 = {\n  width: \"100%\"\n};\nvar explainer2 = {\n  fontFamily: \"sans-serif\",\n  fontSize: 12,\n  color: VERY_LIGHT_TEXT\n};\nvar inputStyle = {\n  colorScheme: \"dark\"\n};\nvar formatDate = (date) => {\n  const year = date.getFullYear();\n  const month = date.getMonth() + 1;\n  const day = date.getDate();\n  const hours = date.getHours();\n  const minutes = date.getMinutes();\n  const seconds = date.getSeconds();\n  const milliseconds = date.getMilliseconds();\n  const formattedDate = `${year}-${month.toString().padStart(2, \"0\")}-${day.toString().padStart(2, \"0\")}T${hours.toString().padStart(2, \"0\")}:${minutes.toString().padStart(2, \"0\")}:${seconds.toString().padStart(2, \"0\")}.${milliseconds.toString().padStart(3, \"0\")}`;\n  return formattedDate;\n};\nvar ZodDateEditor = ({\n  jsonPath,\n  value,\n  setValue,\n  showSaveButton,\n  defaultValue,\n  schema,\n  onSave,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const {\n    localValue,\n    onChange: setLocalValue,\n    reset\n  } = useLocalState({\n    schema,\n    setValue,\n    unsavedValue: value,\n    savedValue: defaultValue\n  });\n  const onChange = useCallback57((e) => {\n    setLocalValue(() => new Date(e.target.value), false, false);\n  }, [setLocalValue]);\n  const save = useCallback57(() => {\n    onSave(() => value, false, false);\n  }, [onSave, value]);\n  return /* @__PURE__ */ jsxs58(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx121(SchemaLabel, {\n        handleClick: null,\n        isDefaultValue: localValue.value.getTime() === defaultValue.getTime(),\n        jsonPath,\n        onReset: reset,\n        onSave: save,\n        showSaveButton,\n        onRemove,\n        saving,\n        valid: localValue.zodValidation.success,\n        saveDisabledByParent,\n        suffix: null\n      }),\n      /* @__PURE__ */ jsxs58(\"div\", {\n        style: fullWidth3,\n        children: [\n          /* @__PURE__ */ jsx121(RemotionInput, {\n            value: formatDate(localValue.value),\n            type: \"datetime-local\",\n            status: localValue.zodValidation.success ? \"ok\" : \"error\",\n            placeholder: jsonPath.join(\".\"),\n            onChange,\n            style: inputStyle,\n            rightAlign: false\n          }),\n          /* @__PURE__ */ jsx121(Spacing, {\n            y: 1,\n            block: true\n          }),\n          /* @__PURE__ */ jsx121(\"div\", {\n            style: explainer2,\n            children: \"Date is in local format\"\n          }),\n          /* @__PURE__ */ jsx121(ZodFieldValidation, {\n            path: jsonPath,\n            localValue\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodDefaultEditor.tsx\nimport { jsx as jsx122 } from \"react/jsx-runtime\";\nvar ZodDefaultEditor = ({\n  jsonPath,\n  schema,\n  setValue,\n  onSave,\n  defaultValue,\n  value,\n  showSaveButton,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const { innerType } = schema._def;\n  return /* @__PURE__ */ jsx122(ZodSwitch, {\n    defaultValue,\n    jsonPath,\n    onRemove,\n    onSave,\n    schema: innerType,\n    setValue,\n    showSaveButton,\n    value,\n    saving,\n    saveDisabledByParent,\n    mayPad\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodDiscriminatedUnionEditor.tsx\nimport { useCallback as useCallback58, useMemo as useMemo71 } from \"react\";\nimport { jsx as jsx123, jsxs as jsxs59 } from \"react/jsx-runtime\";\nvar ZodDiscriminatedUnionEditor = ({\n  schema,\n  setValue,\n  showSaveButton,\n  saving,\n  value,\n  defaultValue,\n  saveDisabledByParent,\n  onSave,\n  mayPad,\n  jsonPath,\n  onRemove\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const zodTypes = useZodTypesIfPossible();\n  const typedSchema = schema._def;\n  const options = useMemo71(() => [...typedSchema.optionsMap.keys()], [typedSchema.optionsMap]);\n  const {\n    localValue,\n    onChange: setLocalValue,\n    reset\n  } = useLocalState({\n    schema,\n    setValue,\n    unsavedValue: value,\n    savedValue: defaultValue\n  });\n  const comboBoxValues = useMemo71(() => {\n    return options.map((option) => {\n      return {\n        value: option,\n        label: option,\n        id: option,\n        keyHint: null,\n        leftItem: option === value[typedSchema.discriminator] ? /* @__PURE__ */ jsx123(Checkmark, {}) : null,\n        onClick: () => {\n          const val = createZodValues(typedSchema.optionsMap.get(option), z, zodTypes);\n          setLocalValue(() => val, false, false);\n        },\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\"\n      };\n    });\n  }, [\n    options,\n    setLocalValue,\n    typedSchema.discriminator,\n    typedSchema.optionsMap,\n    value,\n    z,\n    zodTypes\n  ]);\n  const save = useCallback58(() => {\n    onSave(() => value, false, false);\n  }, [onSave, value]);\n  const discriminatedUnionReplacement = useMemo71(() => {\n    return {\n      discriminator: typedSchema.discriminator,\n      markup: /* @__PURE__ */ jsxs59(Fieldset, {\n        shouldPad: mayPad,\n        success: true,\n        children: [\n          /* @__PURE__ */ jsx123(SchemaLabel, {\n            handleClick: null,\n            isDefaultValue: localValue.value[typedSchema.discriminator] === defaultValue[typedSchema.discriminator],\n            jsonPath: [...jsonPath, typedSchema.discriminator],\n            onRemove,\n            onReset: reset,\n            onSave: save,\n            saveDisabledByParent,\n            saving,\n            showSaveButton,\n            suffix: null,\n            valid: localValue.zodValidation.success\n          }),\n          /* @__PURE__ */ jsx123(Combobox, {\n            title: \"Select type\",\n            values: comboBoxValues,\n            selectedId: value[typedSchema.discriminator]\n          })\n        ]\n      }, \"replacement\")\n    };\n  }, [\n    comboBoxValues,\n    defaultValue,\n    jsonPath,\n    localValue.value,\n    localValue.zodValidation.success,\n    mayPad,\n    onRemove,\n    reset,\n    save,\n    saveDisabledByParent,\n    saving,\n    showSaveButton,\n    typedSchema.discriminator,\n    value\n  ]);\n  return /* @__PURE__ */ jsx123(ZodObjectEditor, {\n    jsonPath,\n    mayPad,\n    savedValue: defaultValue,\n    onRemove,\n    onSave,\n    saveDisabledByParent,\n    saving,\n    schema: typedSchema.optionsMap.get(value[typedSchema.discriminator]),\n    setValue: setLocalValue,\n    showSaveButton,\n    unsavedValue: value,\n    discriminatedUnionReplacement\n  }, value[typedSchema.discriminator]);\n};\n\n// src/components/RenderModal/SchemaEditor/ZodEffectEditor.tsx\nimport { jsx as jsx124, jsxs as jsxs60 } from \"react/jsx-runtime\";\nvar fullWidth4 = {\n  width: \"100%\"\n};\nvar ZodEffectEditor = ({\n  schema,\n  jsonPath,\n  value,\n  setValue: updateValue,\n  defaultValue,\n  onSave,\n  onRemove,\n  showSaveButton,\n  saving,\n  mayPad\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const { localValue, onChange } = useLocalState({\n    unsavedValue: value,\n    schema,\n    setValue: updateValue,\n    savedValue: defaultValue\n  });\n  const def = schema._def;\n  const typeName = def.typeName;\n  if (typeName !== z.ZodFirstPartyTypeKind.ZodEffects) {\n    throw new Error(\"expected effect\");\n  }\n  return /* @__PURE__ */ jsxs60(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx124(\"div\", {\n        style: fullWidth4,\n        children: /* @__PURE__ */ jsx124(ZodSwitch, {\n          value,\n          setValue: onChange,\n          jsonPath,\n          schema: def.schema,\n          defaultValue,\n          onSave,\n          showSaveButton,\n          onRemove,\n          saving,\n          saveDisabledByParent: !localValue.zodValidation.success,\n          mayPad: false\n        })\n      }),\n      /* @__PURE__ */ jsx124(ZodFieldValidation, {\n        path: jsonPath,\n        localValue\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodEnumEditor.tsx\nimport { useCallback as useCallback59, useMemo as useMemo72 } from \"react\";\nimport { jsx as jsx125, jsxs as jsxs61 } from \"react/jsx-runtime\";\nvar container28 = {\n  width: \"100%\"\n};\nvar ZodEnumEditor = ({\n  schema,\n  jsonPath,\n  setValue,\n  defaultValue,\n  value,\n  onSave,\n  showSaveButton,\n  onRemove,\n  saving\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const {\n    localValue,\n    onChange: setLocalValue,\n    reset\n  } = useLocalState({\n    schema,\n    setValue,\n    unsavedValue: value,\n    savedValue: defaultValue\n  });\n  const def = schema._def;\n  const typeName = def.typeName;\n  if (typeName !== z.ZodFirstPartyTypeKind.ZodEnum) {\n    throw new Error(\"expected enum\");\n  }\n  const isRoot = jsonPath.length === 0;\n  const comboBoxValues = useMemo72(() => {\n    return def.values.map((option) => {\n      return {\n        value: option,\n        label: option,\n        id: option,\n        keyHint: null,\n        leftItem: option === value ? /* @__PURE__ */ jsx125(Checkmark, {}) : null,\n        onClick: (id) => {\n          setLocalValue(() => id, false, false);\n        },\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\"\n      };\n    });\n  }, [def.values, setLocalValue, value]);\n  const save = useCallback59(() => {\n    onSave(() => value, false, false);\n  }, [onSave, value]);\n  return /* @__PURE__ */ jsxs61(Fieldset, {\n    shouldPad: true,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx125(SchemaLabel, {\n        handleClick: null,\n        onSave: save,\n        showSaveButton,\n        isDefaultValue: localValue.value === defaultValue,\n        onReset: reset,\n        jsonPath,\n        onRemove,\n        saving,\n        valid: localValue.zodValidation.success,\n        saveDisabledByParent: !localValue.zodValidation.success,\n        suffix: null\n      }),\n      /* @__PURE__ */ jsx125(\"div\", {\n        style: isRoot ? undefined : container28,\n        children: /* @__PURE__ */ jsx125(Combobox, {\n          values: comboBoxValues,\n          selectedId: value,\n          title: value\n        })\n      }),\n      /* @__PURE__ */ jsx125(ZodFieldValidation, {\n        path: jsonPath,\n        localValue\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodMatrixEditor.tsx\nimport React84, { useMemo as useMemo73, useState as useState47 } from \"react\";\nimport { jsx as jsx126, jsxs as jsxs62 } from \"react/jsx-runtime\";\nvar rowStyle = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  width: \"100%\"\n};\nvar ZodMatrixEditor = ({\n  schema,\n  jsonPath,\n  setValue,\n  defaultValue,\n  value,\n  onSave,\n  showSaveButton,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const { localValue, onChange, RevisionContextProvider, reset } = useLocalState({\n    unsavedValue: value,\n    schema,\n    setValue,\n    savedValue: defaultValue\n  });\n  const [expanded, setExpanded] = useState47(true);\n  const def = schema._def;\n  const suffix2 = useMemo73(() => {\n    return expanded ? \" [\" : \" [...] \";\n  }, [expanded]);\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const zodTypes = useZodTypesIfPossible();\n  const isDefaultValue = useMemo73(() => {\n    return deepEqual(localValue.value, defaultValue);\n  }, [defaultValue, localValue]);\n  const dimensions = Math.sqrt(localValue.value.length);\n  if (!Number.isInteger(dimensions)) {\n    throw new Error(\"Invalid matrix\");\n  }\n  const chunkedItems = useMemo73(() => {\n    return localValue.value.reduce((acc, item2, index) => {\n      const chunkIndex = Math.floor(index / dimensions);\n      acc[chunkIndex] = acc[chunkIndex] || [];\n      acc[chunkIndex].push(item2);\n      return acc;\n    }, []);\n  }, [localValue.value, dimensions]);\n  return /* @__PURE__ */ jsxs62(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx126(SchemaLabel, {\n        onReset: reset,\n        isDefaultValue,\n        jsonPath,\n        onRemove,\n        suffix: suffix2,\n        onSave: () => {\n          onSave(() => localValue.value, false, false);\n        },\n        saveDisabledByParent,\n        saving,\n        showSaveButton,\n        valid: localValue.zodValidation.success,\n        handleClick: () => setExpanded(!expanded)\n      }),\n      expanded ? /* @__PURE__ */ jsx126(RevisionContextProvider, {\n        children: /* @__PURE__ */ jsxs62(SchemaVerticalGuide, {\n          isRoot: false,\n          children: [\n            chunkedItems.map((row3, rowIndex) => {\n              return /* @__PURE__ */ jsx126(React84.Fragment, {\n                children: /* @__PURE__ */ jsx126(\"div\", {\n                  style: rowStyle,\n                  children: row3.map((item2, _index) => {\n                    const actualIndex = rowIndex * dimensions + _index;\n                    return /* @__PURE__ */ jsx126(\"div\", {\n                      style: { flex: 1 },\n                      children: /* @__PURE__ */ jsx126(ZodArrayItemEditor, {\n                        onChange,\n                        value: item2,\n                        def,\n                        index: actualIndex,\n                        jsonPath,\n                        defaultValue: defaultValue?.[actualIndex] ?? createZodValues(def.type, z, zodTypes),\n                        onSave,\n                        showSaveButton,\n                        saving,\n                        saveDisabledByParent,\n                        mayPad,\n                        mayRemove: false\n                      })\n                    }, `${_index}${localValue.keyStabilityRevision}`);\n                  })\n                })\n              }, `${rowIndex}${localValue.keyStabilityRevision}`);\n            }),\n            value.length === 0 ? /* @__PURE__ */ jsx126(SchemaArrayItemSeparationLine, {\n              schema,\n              index: 0,\n              onChange,\n              isLast: true,\n              showAddButton: true\n            }) : null\n          ]\n        })\n      }) : null,\n      /* @__PURE__ */ jsx126(ZodFieldValidation, {\n        path: jsonPath,\n        localValue\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodNonEditableValue.tsx\nimport { useCallback as useCallback60 } from \"react\";\nimport { jsx as jsx127, jsxs as jsxs63 } from \"react/jsx-runtime\";\nvar fullWidth5 = {\n  width: \"100%\"\n};\nvar emptyLabel = {\n  width: \"100%\",\n  color: VERY_LIGHT_TEXT,\n  fontFamily: \"sans-serif\",\n  fontSize: 14\n};\nvar wideEmptyLabel = {\n  ...emptyLabel,\n  lineHeight: \"37px\"\n};\nvar ZonNonEditableValue = ({ jsonPath, label: label6, showSaveButton, saving, mayPad }) => {\n  const save = useCallback60(() => {\n    return;\n  }, []);\n  const reset = useCallback60(() => {\n    return;\n  }, []);\n  return /* @__PURE__ */ jsxs63(Fieldset, {\n    shouldPad: mayPad,\n    success: true,\n    children: [\n      /* @__PURE__ */ jsx127(SchemaLabel, {\n        handleClick: null,\n        isDefaultValue: true,\n        jsonPath,\n        onReset: reset,\n        onSave: save,\n        showSaveButton,\n        onRemove: null,\n        saving,\n        valid: true,\n        saveDisabledByParent: true,\n        suffix: null\n      }),\n      /* @__PURE__ */ jsx127(\"div\", {\n        style: fullWidth5,\n        children: /* @__PURE__ */ jsx127(\"em\", {\n          style: wideEmptyLabel,\n          children: label6\n        })\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodOrNullishEditor.tsx\nimport { useCallback as useCallback61 } from \"react\";\nimport { jsx as jsx128, jsxs as jsxs64 } from \"react/jsx-runtime\";\nvar labelStyle4 = {\n  fontFamily: \"sans-serif\",\n  fontSize: 14,\n  color: LIGHT_TEXT\n};\nvar checkBoxWrapper = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  marginTop: \"5px\"\n};\nvar ZodOrNullishEditor = ({\n  jsonPath,\n  schema,\n  setValue,\n  onSave,\n  defaultValue,\n  value,\n  showSaveButton,\n  onRemove,\n  nullishValue,\n  saving,\n  saveDisabledByParent,\n  mayPad,\n  innerSchema\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const zodTypes = useZodTypesIfPossible();\n  const isChecked = value === nullishValue;\n  const {\n    localValue,\n    onChange: setLocalValue,\n    reset\n  } = useLocalState({\n    schema,\n    setValue,\n    unsavedValue: value,\n    savedValue: defaultValue\n  });\n  const onCheckBoxChange = useCallback61((e) => {\n    const val = e.target.checked ? nullishValue : createZodValues(innerSchema, z, zodTypes);\n    setLocalValue(() => val, false, false);\n  }, [innerSchema, nullishValue, setLocalValue, z, zodTypes]);\n  const save = useCallback61(() => {\n    onSave(() => value, false, false);\n  }, [onSave, value]);\n  return /* @__PURE__ */ jsxs64(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      localValue.value === nullishValue ? /* @__PURE__ */ jsx128(SchemaLabel, {\n        handleClick: null,\n        isDefaultValue: localValue.value === defaultValue,\n        jsonPath,\n        onReset: reset,\n        onSave: save,\n        showSaveButton,\n        onRemove,\n        saving,\n        valid: localValue.zodValidation.success,\n        saveDisabledByParent,\n        suffix: null\n      }) : /* @__PURE__ */ jsx128(ZodSwitch, {\n        value: localValue.value,\n        setValue: setLocalValue,\n        jsonPath,\n        schema: innerSchema,\n        defaultValue,\n        onSave,\n        showSaveButton,\n        onRemove,\n        saving,\n        saveDisabledByParent,\n        mayPad: false\n      }),\n      /* @__PURE__ */ jsxs64(\"div\", {\n        style: checkBoxWrapper,\n        children: [\n          /* @__PURE__ */ jsx128(Checkbox, {\n            checked: isChecked,\n            onChange: onCheckBoxChange,\n            disabled: false,\n            name: jsonPath.join(\".\")\n          }),\n          /* @__PURE__ */ jsx128(Spacing, {\n            x: 1\n          }),\n          /* @__PURE__ */ jsx128(\"div\", {\n            style: labelStyle4,\n            children: String(nullishValue)\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodNullableEditor.tsx\nimport { jsx as jsx129 } from \"react/jsx-runtime\";\nvar ZodNullableEditor = ({\n  jsonPath,\n  schema,\n  setValue,\n  onSave,\n  defaultValue,\n  value,\n  showSaveButton,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const { innerType } = schema._def;\n  return /* @__PURE__ */ jsx129(ZodOrNullishEditor, {\n    defaultValue,\n    jsonPath,\n    onRemove,\n    onSave,\n    schema,\n    innerSchema: innerType,\n    setValue,\n    showSaveButton,\n    value,\n    nullishValue: null,\n    saving,\n    saveDisabledByParent,\n    mayPad\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodNumberEditor.tsx\nimport { useCallback as useCallback62 } from \"react\";\nimport { jsx as jsx130, jsxs as jsxs65 } from \"react/jsx-runtime\";\nvar fullWidth6 = {\n  width: \"100%\"\n};\nvar getMinValue = (schema) => {\n  const minCheck = schema._def.checks.find((c) => c.kind === \"min\");\n  if (!minCheck) {\n    return -Infinity;\n  }\n  if (minCheck.kind !== \"min\") {\n    throw new Error(\"Expected min check\");\n  }\n  if (!minCheck.inclusive) {\n    return -Infinity;\n  }\n  return minCheck.value;\n};\nvar getMaxValue = (schema) => {\n  const maxCheck = schema._def.checks.find((c) => c.kind === \"max\");\n  if (!maxCheck) {\n    return Infinity;\n  }\n  if (maxCheck.kind !== \"max\") {\n    throw new Error(\"Expected max check\");\n  }\n  if (!maxCheck.inclusive) {\n    return Infinity;\n  }\n  return maxCheck.value;\n};\nvar getStep = (schema) => {\n  const multipleStep = schema._def.checks.find((c) => c.kind === \"multipleOf\");\n  if (!multipleStep) {\n    return;\n  }\n  if (multipleStep.kind !== \"multipleOf\") {\n    throw new Error(\"Expected multipleOf check\");\n  }\n  return multipleStep.value;\n};\nvar ZodNumberEditor = ({\n  jsonPath,\n  value,\n  schema,\n  setValue,\n  onSave,\n  defaultValue,\n  onRemove,\n  showSaveButton,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const {\n    localValue,\n    onChange: setLocalValue,\n    reset\n  } = useLocalState({\n    unsavedValue: value,\n    schema,\n    setValue,\n    savedValue: defaultValue\n  });\n  const onNumberChange = useCallback62((newValue) => {\n    setLocalValue(() => newValue, false, false);\n  }, [setLocalValue]);\n  const isDefault = localValue.value === defaultValue;\n  const onTextChange = useCallback62((newValue) => {\n    setLocalValue(() => Number(newValue), false, false);\n  }, [setLocalValue]);\n  const save = useCallback62(() => {\n    onSave(() => value, false, false);\n  }, [onSave, value]);\n  return /* @__PURE__ */ jsxs65(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx130(SchemaLabel, {\n        handleClick: null,\n        isDefaultValue: isDefault,\n        jsonPath,\n        onReset: reset,\n        onSave: save,\n        showSaveButton,\n        onRemove,\n        saving,\n        valid: localValue.zodValidation.success,\n        saveDisabledByParent,\n        suffix: null\n      }),\n      /* @__PURE__ */ jsxs65(\"div\", {\n        style: fullWidth6,\n        children: [\n          /* @__PURE__ */ jsx130(InputDragger, {\n            type: \"number\",\n            value: localValue.value,\n            style: fullWidth6,\n            status: localValue.zodValidation.success ? \"ok\" : \"error\",\n            placeholder: jsonPath.join(\".\"),\n            onTextChange,\n            onValueChange: onNumberChange,\n            min: getMinValue(schema),\n            max: getMaxValue(schema),\n            step: getStep(schema),\n            rightAlign: false\n          }),\n          /* @__PURE__ */ jsx130(ZodFieldValidation, {\n            path: jsonPath,\n            localValue\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodOptionalEditor.tsx\nimport { jsx as jsx131 } from \"react/jsx-runtime\";\nvar ZodOptionalEditor = ({\n  jsonPath,\n  schema,\n  setValue,\n  onSave,\n  defaultValue,\n  value,\n  showSaveButton,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const { innerType } = schema._def;\n  return /* @__PURE__ */ jsx131(ZodOrNullishEditor, {\n    defaultValue,\n    jsonPath,\n    onRemove,\n    onSave,\n    schema,\n    setValue,\n    showSaveButton,\n    value,\n    nullishValue: undefined,\n    saving,\n    saveDisabledByParent,\n    mayPad,\n    innerSchema: innerType\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodStaticFileEditor.tsx\nimport { useCallback as useCallback63, useMemo as useMemo74 } from \"react\";\nimport { jsx as jsx132, jsxs as jsxs66 } from \"react/jsx-runtime\";\nvar container29 = {\n  width: \"100%\"\n};\nvar ZodStaticFileEditor = ({\n  schema,\n  jsonPath,\n  setValue,\n  defaultValue,\n  value,\n  onSave,\n  showSaveButton,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const {\n    localValue,\n    onChange: setLocalValue,\n    reset\n  } = useLocalState({\n    schema,\n    setValue,\n    unsavedValue: value,\n    savedValue: defaultValue\n  });\n  const def = schema._def;\n  const typeName = def.typeName;\n  if (typeName !== z.ZodFirstPartyTypeKind.ZodString) {\n    throw new Error(\"expected enum\");\n  }\n  const isRoot = jsonPath.length === 0;\n  const comboBoxValues = useMemo74(() => {\n    return getStaticFiles().map((option) => {\n      return {\n        value: option.src,\n        label: option.name,\n        id: option.src,\n        keyHint: null,\n        leftItem: option.src === value ? /* @__PURE__ */ jsx132(Checkmark, {}) : null,\n        onClick: (id) => {\n          setLocalValue(() => id, false, false);\n        },\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\"\n      };\n    });\n  }, [setLocalValue, value]);\n  const save = useCallback63(() => {\n    onSave(() => value);\n  }, [onSave, value]);\n  return /* @__PURE__ */ jsxs66(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx132(SchemaLabel, {\n        handleClick: null,\n        onSave: save,\n        showSaveButton,\n        isDefaultValue: localValue.value === defaultValue,\n        onReset: reset,\n        jsonPath,\n        onRemove,\n        saving,\n        valid: localValue.zodValidation.success,\n        saveDisabledByParent,\n        suffix: null\n      }),\n      /* @__PURE__ */ jsx132(\"div\", {\n        style: isRoot ? undefined : container29,\n        children: /* @__PURE__ */ jsx132(Combobox, {\n          values: comboBoxValues,\n          selectedId: localValue.value,\n          title: value\n        })\n      }),\n      /* @__PURE__ */ jsx132(ZodFieldValidation, {\n        path: jsonPath,\n        localValue\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodStringEditor.tsx\nimport { useCallback as useCallback64 } from \"react\";\nimport { jsx as jsx133, jsxs as jsxs67 } from \"react/jsx-runtime\";\nvar fullWidth7 = {\n  width: \"100%\"\n};\nvar ZodStringEditor = ({\n  jsonPath,\n  value,\n  setValue,\n  showSaveButton,\n  defaultValue,\n  schema,\n  onSave,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const {\n    localValue,\n    onChange: setLocalValue,\n    reset\n  } = useLocalState({\n    schema,\n    setValue,\n    unsavedValue: value,\n    savedValue: defaultValue\n  });\n  const onChange = useCallback64((e) => {\n    setLocalValue(() => e.target.value, false, false);\n  }, [setLocalValue]);\n  const save = useCallback64(() => {\n    onSave(() => value, false, false);\n  }, [onSave, value]);\n  return /* @__PURE__ */ jsxs67(Fieldset, {\n    shouldPad: mayPad,\n    success: false,\n    children: [\n      /* @__PURE__ */ jsx133(SchemaLabel, {\n        handleClick: null,\n        isDefaultValue: localValue.value === defaultValue,\n        jsonPath,\n        onReset: reset,\n        onSave: save,\n        showSaveButton,\n        onRemove,\n        saving,\n        valid: localValue.zodValidation.success,\n        saveDisabledByParent,\n        suffix: null\n      }),\n      /* @__PURE__ */ jsxs67(\"div\", {\n        style: fullWidth7,\n        children: [\n          /* @__PURE__ */ jsx133(RemotionInput, {\n            value: localValue.value,\n            status: localValue.zodValidation ? \"ok\" : \"error\",\n            placeholder: jsonPath.join(\".\"),\n            onChange,\n            rightAlign: false,\n            name: jsonPath.join(\".\")\n          }),\n          /* @__PURE__ */ jsx133(ZodFieldValidation, {\n            path: jsonPath,\n            localValue\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodTextareaEditor.tsx\nimport { useCallback as useCallback65 } from \"react\";\nimport { jsx as jsx134, jsxs as jsxs68 } from \"react/jsx-runtime\";\nvar fullWidth8 = {\n  width: \"100%\"\n};\nvar textareaStyle = {\n  resize: \"vertical\",\n  minHeight: 100\n};\nvar ZodTextareaEditor = ({\n  jsonPath,\n  value,\n  setValue,\n  showSaveButton,\n  defaultValue,\n  schema,\n  onSave,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const zodTypes = useZodTypesIfPossible();\n  if (!zodTypes) {\n    throw new Error(\"expected zod textarea\");\n  }\n  const {\n    localValue,\n    onChange: setLocalValue,\n    reset\n  } = useLocalState({\n    schema,\n    setValue,\n    unsavedValue: value,\n    savedValue: defaultValue\n  });\n  const onChange = useCallback65((e) => {\n    setLocalValue(() => e.target.value, false, false);\n  }, [setLocalValue]);\n  const save = useCallback65(() => {\n    onSave(() => value, false, false);\n  }, [onSave, value]);\n  return /* @__PURE__ */ jsxs68(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx134(SchemaLabel, {\n        handleClick: null,\n        isDefaultValue: localValue.value === defaultValue,\n        jsonPath,\n        onReset: reset,\n        onSave: save,\n        showSaveButton,\n        onRemove,\n        saving,\n        valid: localValue.zodValidation.success,\n        saveDisabledByParent,\n        suffix: null\n      }),\n      /* @__PURE__ */ jsxs68(\"div\", {\n        style: fullWidth8,\n        children: [\n          /* @__PURE__ */ jsx134(RemTextarea, {\n            onChange,\n            value: localValue.value,\n            status: localValue.zodValidation ? \"ok\" : \"error\",\n            placeholder: jsonPath.join(\".\"),\n            name: jsonPath.join(\".\"),\n            style: textareaStyle\n          }),\n          /* @__PURE__ */ jsx134(ZodFieldValidation, {\n            path: jsonPath,\n            localValue\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodTupleEditor.tsx\nimport React90, { useMemo as useMemo76, useState as useState48 } from \"react\";\n\n// src/components/RenderModal/SchemaEditor/ZodTupleItemEditor.tsx\nimport { useCallback as useCallback66, useMemo as useMemo75 } from \"react\";\nimport { jsx as jsx135 } from \"react/jsx-runtime\";\nvar ZodTupleItemEditor = ({\n  def,\n  onChange,\n  jsonPath,\n  index,\n  value,\n  defaultValue,\n  onSave: onSaveObject,\n  showSaveButton,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const setValue = useCallback66((val) => {\n    onChange((oldV) => [\n      ...oldV.slice(0, index),\n      typeof val === \"function\" ? val(oldV[index]) : val,\n      ...oldV.slice(index + 1)\n    ], false, false);\n  }, [index, onChange]);\n  const newJsonPath = useMemo75(() => [...jsonPath, index], [index, jsonPath]);\n  const onSave = useCallback66((updater) => {\n    onSaveObject((oldV) => [\n      ...oldV.slice(0, index),\n      updater(oldV[index]),\n      ...oldV.slice(index + 1)\n    ], false, false);\n  }, [index, onSaveObject]);\n  return /* @__PURE__ */ jsx135(\"div\", {\n    children: /* @__PURE__ */ jsx135(ZodSwitch, {\n      jsonPath: newJsonPath,\n      schema: def.items[index],\n      value,\n      setValue,\n      defaultValue,\n      onSave,\n      showSaveButton,\n      onRemove: null,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    })\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodTupleEditor.tsx\nimport { jsx as jsx136, jsxs as jsxs69 } from \"react/jsx-runtime\";\nvar ZodTupleEditor = ({\n  schema,\n  jsonPath,\n  setValue,\n  defaultValue,\n  value,\n  onSave,\n  showSaveButton,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const { localValue, onChange, RevisionContextProvider, reset } = useLocalState({\n    unsavedValue: value,\n    schema,\n    setValue,\n    savedValue: defaultValue\n  });\n  const [expanded, setExpanded] = useState48(true);\n  const def = schema._def;\n  const suffix2 = useMemo76(() => {\n    return expanded ? \" [\" : \" [...] \";\n  }, [expanded]);\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const zodTypes = useZodTypesIfPossible();\n  const typeName = def.typeName;\n  if (typeName !== z.ZodFirstPartyTypeKind.ZodTuple) {\n    throw new Error(\"expected object\");\n  }\n  const isDefaultValue = useMemo76(() => {\n    return deepEqual(localValue.value, defaultValue);\n  }, [defaultValue, localValue]);\n  return /* @__PURE__ */ jsxs69(Fieldset, {\n    shouldPad: mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      /* @__PURE__ */ jsx136(\"div\", {\n        style: {\n          display: \"flex\",\n          flexDirection: \"row\"\n        },\n        children: /* @__PURE__ */ jsx136(SchemaLabel, {\n          onReset: reset,\n          isDefaultValue,\n          jsonPath,\n          onRemove,\n          suffix: suffix2,\n          onSave: () => {\n            onSave(() => localValue.value, false, false);\n          },\n          saveDisabledByParent,\n          saving,\n          showSaveButton,\n          valid: localValue.zodValidation.success,\n          handleClick: () => setExpanded(!expanded)\n        })\n      }),\n      expanded ? /* @__PURE__ */ jsx136(RevisionContextProvider, {\n        children: /* @__PURE__ */ jsxs69(SchemaVerticalGuide, {\n          isRoot: false,\n          children: [\n            localValue.value.map((child, i) => {\n              return /* @__PURE__ */ jsxs69(React90.Fragment, {\n                children: [\n                  /* @__PURE__ */ jsx136(ZodTupleItemEditor, {\n                    onChange,\n                    value: child,\n                    def,\n                    index: i,\n                    jsonPath,\n                    defaultValue: defaultValue?.[i] ?? createZodValues(def.items[i], z, zodTypes),\n                    onSave,\n                    showSaveButton,\n                    saving,\n                    saveDisabledByParent,\n                    mayPad\n                  }),\n                  /* @__PURE__ */ jsx136(SchemaArrayItemSeparationLine, {\n                    schema,\n                    index: i,\n                    onChange,\n                    isLast: i === localValue.value.length - 1,\n                    showAddButton: false\n                  })\n                ]\n              }, `${i}${localValue.keyStabilityRevision}`);\n            }),\n            value.length === 0 ? /* @__PURE__ */ jsx136(SchemaArrayItemSeparationLine, {\n              schema,\n              index: 0,\n              onChange,\n              isLast: true,\n              showAddButton: false\n            }) : null\n          ]\n        })\n      }) : null,\n      /* @__PURE__ */ jsx136(ZodFieldValidation, {\n        path: jsonPath,\n        localValue\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodUnionEditor.tsx\nimport { jsx as jsx137 } from \"react/jsx-runtime\";\nvar findNull = (value, zodType) => {\n  const nullIndex = value.findIndex((v) => v._def.typeName === zodType.ZodFirstPartyTypeKind.ZodNull || v._def.typeName === zodType.ZodFirstPartyTypeKind.ZodUndefined);\n  if (nullIndex === -1) {\n    return null;\n  }\n  const nullishValue = value[nullIndex]._def.typeName === zodType.ZodFirstPartyTypeKind.ZodNull ? null : undefined;\n  const otherSchema = value[nullIndex === 0 ? 1 : 0];\n  const otherSchemaIsAlsoNullish = otherSchema._def.typeName === zodType.ZodFirstPartyTypeKind.ZodNull || otherSchema._def.typeName === zodType.ZodFirstPartyTypeKind.ZodUndefined;\n  return {\n    nullIndex,\n    nullishValue,\n    otherSchema,\n    otherSchemaIsAlsoNullish\n  };\n};\nvar ZodUnionEditor = ({\n  jsonPath,\n  schema,\n  setValue,\n  onSave,\n  defaultValue,\n  value,\n  showSaveButton,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const { options } = schema._def;\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  if (options.length > 2) {\n    return /* @__PURE__ */ jsx137(ZonNonEditableValue, {\n      jsonPath,\n      label: \"Union with more than 2 options not editable\",\n      showSaveButton,\n      saving,\n      mayPad\n    });\n  }\n  if (options.length < 2) {\n    return /* @__PURE__ */ jsx137(ZonNonEditableValue, {\n      jsonPath,\n      label: \"Union with less than 2 options not editable\",\n      showSaveButton,\n      saving,\n      mayPad\n    });\n  }\n  const nullResult = findNull(options, z);\n  if (!nullResult) {\n    return /* @__PURE__ */ jsx137(ZonNonEditableValue, {\n      jsonPath,\n      label: \"Union only editable with 1 value being null\",\n      showSaveButton,\n      saving,\n      mayPad\n    });\n  }\n  const { otherSchema, nullishValue, otherSchemaIsAlsoNullish } = nullResult;\n  if (otherSchemaIsAlsoNullish) {\n    return /* @__PURE__ */ jsx137(ZonNonEditableValue, {\n      jsonPath,\n      label: \"Not editable - both union values are nullish\",\n      showSaveButton,\n      saving,\n      mayPad\n    });\n  }\n  return /* @__PURE__ */ jsx137(ZodOrNullishEditor, {\n    defaultValue,\n    jsonPath,\n    onRemove,\n    onSave,\n    schema,\n    innerSchema: otherSchema,\n    setValue,\n    showSaveButton,\n    value,\n    nullishValue,\n    saving,\n    saveDisabledByParent,\n    mayPad\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodSwitch.tsx\nimport { jsx as jsx138 } from \"react/jsx-runtime\";\nvar ZodSwitch = ({\n  schema,\n  jsonPath,\n  value,\n  setValue,\n  defaultValue,\n  onSave,\n  showSaveButton,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad\n}) => {\n  const def = schema._def;\n  const typeName = def.typeName;\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const zodTypes = useZodTypesIfPossible();\n  if (typeName === z.ZodFirstPartyTypeKind.ZodObject) {\n    return /* @__PURE__ */ jsx138(ZodObjectEditor, {\n      setValue,\n      unsavedValue: value,\n      savedValue: defaultValue,\n      jsonPath,\n      schema,\n      onSave,\n      showSaveButton,\n      onRemove,\n      saving,\n      saveDisabledByParent,\n      mayPad,\n      discriminatedUnionReplacement: null\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodString) {\n    if (value.startsWith(window.remotion_staticBase)) {\n      return /* @__PURE__ */ jsx138(ZodStaticFileEditor, {\n        setValue,\n        value,\n        jsonPath,\n        schema,\n        defaultValue,\n        onSave,\n        showSaveButton,\n        onRemove,\n        saving,\n        saveDisabledByParent,\n        mayPad\n      });\n    }\n    if (zodTypes && schema._def.description === zodTypes.ZodZypesInternals.REMOTION_TEXTAREA_BRAND) {\n      return /* @__PURE__ */ jsx138(ZodTextareaEditor, {\n        value,\n        setValue,\n        jsonPath,\n        schema,\n        onSave,\n        defaultValue,\n        showSaveButton,\n        onRemove,\n        saving,\n        saveDisabledByParent,\n        mayPad\n      });\n    }\n    return /* @__PURE__ */ jsx138(ZodStringEditor, {\n      value,\n      setValue,\n      jsonPath,\n      schema,\n      onSave,\n      defaultValue,\n      showSaveButton,\n      onRemove,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodDate) {\n    return /* @__PURE__ */ jsx138(ZodDateEditor, {\n      value,\n      setValue,\n      jsonPath,\n      schema,\n      onSave,\n      defaultValue,\n      showSaveButton,\n      onRemove,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodNumber) {\n    return /* @__PURE__ */ jsx138(ZodNumberEditor, {\n      value,\n      setValue,\n      jsonPath,\n      schema,\n      defaultValue,\n      onSave,\n      showSaveButton,\n      onRemove,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodBoolean) {\n    return /* @__PURE__ */ jsx138(ZodBooleanEditor, {\n      value,\n      setValue,\n      jsonPath,\n      defaultValue,\n      onSave,\n      showSaveButton,\n      onRemove,\n      saving,\n      saveDisabledByParent,\n      mayPad,\n      schema\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodUndefined) {\n    return /* @__PURE__ */ jsx138(ZonNonEditableValue, {\n      jsonPath,\n      showSaveButton,\n      label: \"undefined\",\n      saving,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodNull) {\n    return /* @__PURE__ */ jsx138(ZonNonEditableValue, {\n      jsonPath,\n      showSaveButton,\n      label: \"null\",\n      saving,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodAny) {\n    return /* @__PURE__ */ jsx138(ZonNonEditableValue, {\n      jsonPath,\n      showSaveButton,\n      label: \"any (not editable)\",\n      saving,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodBigInt) {\n    return /* @__PURE__ */ jsx138(ZonNonEditableValue, {\n      jsonPath,\n      showSaveButton,\n      label: \"BigInt (not editable)\",\n      saving,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodUnknown) {\n    return /* @__PURE__ */ jsx138(ZonNonEditableValue, {\n      jsonPath,\n      showSaveButton,\n      label: \"unknown (not editable)\",\n      saving,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodArray) {\n    return /* @__PURE__ */ jsx138(ZodArrayEditor, {\n      setValue,\n      value,\n      jsonPath,\n      schema,\n      defaultValue,\n      onSave,\n      showSaveButton,\n      onRemove,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodEnum) {\n    return /* @__PURE__ */ jsx138(ZodEnumEditor, {\n      setValue,\n      value,\n      jsonPath,\n      schema,\n      defaultValue,\n      onSave,\n      showSaveButton,\n      onRemove,\n      saving\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodEffects) {\n    if (zodTypes && schema._def.description === zodTypes.ZodZypesInternals.REMOTION_COLOR_BRAND) {\n      return /* @__PURE__ */ jsx138(ZodColorEditor, {\n        value,\n        setValue,\n        jsonPath,\n        schema,\n        onSave,\n        defaultValue,\n        showSaveButton,\n        onRemove,\n        saving,\n        saveDisabledByParent,\n        mayPad\n      });\n    }\n    if (zodTypes && schema._def.description === zodTypes.ZodZypesInternals.REMOTION_MATRIX_BRAND) {\n      return /* @__PURE__ */ jsx138(ZodMatrixEditor, {\n        setValue,\n        value,\n        jsonPath,\n        schema: schema._def.schema,\n        defaultValue,\n        onSave,\n        showSaveButton,\n        onRemove,\n        saving,\n        saveDisabledByParent,\n        mayPad\n      });\n    }\n    return /* @__PURE__ */ jsx138(ZodEffectEditor, {\n      value,\n      setValue,\n      jsonPath,\n      schema,\n      defaultValue,\n      onSave,\n      showSaveButton,\n      onRemove,\n      saving,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodUnion) {\n    return /* @__PURE__ */ jsx138(ZodUnionEditor, {\n      schema,\n      showSaveButton,\n      jsonPath,\n      value,\n      defaultValue,\n      setValue,\n      onSave,\n      onRemove,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodOptional) {\n    return /* @__PURE__ */ jsx138(ZodOptionalEditor, {\n      jsonPath,\n      showSaveButton,\n      defaultValue,\n      value,\n      setValue,\n      onSave,\n      onRemove,\n      schema,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodNullable) {\n    return /* @__PURE__ */ jsx138(ZodNullableEditor, {\n      jsonPath,\n      showSaveButton,\n      defaultValue,\n      value,\n      setValue,\n      onSave,\n      onRemove,\n      schema,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodDefault) {\n    return /* @__PURE__ */ jsx138(ZodDefaultEditor, {\n      jsonPath,\n      showSaveButton,\n      defaultValue,\n      value,\n      setValue,\n      onSave,\n      onRemove,\n      schema,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodDiscriminatedUnion) {\n    return /* @__PURE__ */ jsx138(ZodDiscriminatedUnionEditor, {\n      defaultValue,\n      mayPad,\n      schema,\n      setValue,\n      value,\n      jsonPath,\n      onRemove,\n      onSave,\n      saving,\n      saveDisabledByParent,\n      showSaveButton\n    });\n  }\n  if (typeName === z.ZodFirstPartyTypeKind.ZodTuple) {\n    return /* @__PURE__ */ jsx138(ZodTupleEditor, {\n      setValue,\n      value,\n      jsonPath,\n      schema,\n      defaultValue,\n      onSave,\n      showSaveButton,\n      onRemove,\n      saving,\n      saveDisabledByParent,\n      mayPad\n    });\n  }\n  return /* @__PURE__ */ jsx138(ZonNonEditableValue, {\n    jsonPath,\n    showSaveButton,\n    label: `${typeName} (not editable)`,\n    saving,\n    mayPad\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/ZodObjectEditor.tsx\nimport { jsx as jsx139, jsxs as jsxs70 } from \"react/jsx-runtime\";\nvar ZodObjectEditor = ({\n  schema,\n  jsonPath,\n  setValue,\n  unsavedValue,\n  savedValue,\n  onSave,\n  showSaveButton,\n  onRemove,\n  saving,\n  saveDisabledByParent,\n  mayPad,\n  discriminatedUnionReplacement\n}) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const [expanded, setExpanded] = useState49(true);\n  const { localValue, onChange, RevisionContextProvider, reset } = useLocalState({\n    schema,\n    setValue,\n    unsavedValue,\n    savedValue\n  });\n  const def = schema._def;\n  const typeName = def.typeName;\n  if (typeName !== z.ZodFirstPartyTypeKind.ZodObject) {\n    throw new Error(\"expected object\");\n  }\n  const shape = def.shape();\n  const keys = Object.keys(shape);\n  const isRoot = jsonPath.length === 0;\n  const isDefaultValue = useMemo77(() => {\n    return deepEqual(localValue.value, savedValue);\n  }, [savedValue, localValue]);\n  const suffix2 = useMemo77(() => {\n    return expanded ? \" {\" : \" {...}\";\n  }, [expanded]);\n  return /* @__PURE__ */ jsxs70(Fieldset, {\n    shouldPad: !isRoot && mayPad,\n    success: localValue.zodValidation.success,\n    children: [\n      isRoot ? null : /* @__PURE__ */ jsx139(SchemaLabel, {\n        isDefaultValue,\n        onReset: reset,\n        jsonPath,\n        onRemove,\n        suffix: suffix2,\n        onSave: () => {\n          onSave(() => {\n            return localValue.value;\n          }, false, false);\n        },\n        saveDisabledByParent,\n        saving,\n        showSaveButton,\n        valid: localValue.zodValidation.success,\n        handleClick: () => setExpanded(!expanded)\n      }),\n      expanded ? /* @__PURE__ */ jsx139(RevisionContextProvider, {\n        children: /* @__PURE__ */ jsx139(SchemaVerticalGuide, {\n          isRoot,\n          children: keys.map((key, i) => {\n            if (discriminatedUnionReplacement && key === discriminatedUnionReplacement.discriminator) {\n              return discriminatedUnionReplacement.markup;\n            }\n            return /* @__PURE__ */ jsxs70(React91.Fragment, {\n              children: [\n                /* @__PURE__ */ jsx139(ZodSwitch, {\n                  mayPad: true,\n                  jsonPath: [...jsonPath, key],\n                  schema: shape[key],\n                  value: localValue.value[key],\n                  defaultValue: (savedValue ?? unsavedValue)[key],\n                  setValue: (val, forceApply) => {\n                    onChange((oldVal) => {\n                      return {\n                        ...oldVal,\n                        [key]: typeof val === \"function\" ? val(oldVal[key]) : val\n                      };\n                    }, forceApply, false);\n                  },\n                  onSave: (val, forceApply) => {\n                    onSave((oldVal) => {\n                      return {\n                        ...oldVal,\n                        [key]: typeof val === \"function\" ? val(oldVal[key]) : val\n                      };\n                    }, forceApply, false);\n                  },\n                  onRemove: null,\n                  showSaveButton,\n                  saving,\n                  saveDisabledByParent\n                }),\n                i === keys.length - 1 ? null : /* @__PURE__ */ jsx139(SchemaSeparationLine, {})\n              ]\n            }, key);\n          })\n        })\n      }) : null,\n      isRoot || !expanded ? null : /* @__PURE__ */ jsx139(\"div\", {\n        style: fieldsetLabel,\n        children: \"}\"\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SchemaEditor/SchemaEditor.tsx\nimport { jsx as jsx140 } from \"react/jsx-runtime\";\nvar scrollable2 = {\n  display: \"flex\",\n  flexDirection: \"column\",\n  overflowY: \"auto\"\n};\nvar SchemaEditor = ({\n  schema,\n  unsavedDefaultProps,\n  setValue,\n  zodValidationResult,\n  savedDefaultProps,\n  onSave,\n  showSaveButton,\n  saving,\n  saveDisabledByParent\n}) => {\n  const keybindings = useKeybinding();\n  const [revision, setRevision] = useState50(0);\n  const revisionState = useMemo78(() => {\n    return {\n      childResetRevision: revision\n    };\n  }, [revision]);\n  useEffect46(() => {\n    const bumpRevision = () => {\n      setRevision((old) => old + 1);\n    };\n    window.addEventListener(Internals30.PROPS_UPDATED_EXTERNALLY, bumpRevision);\n    return () => {\n      window.removeEventListener(Internals30.PROPS_UPDATED_EXTERNALLY, bumpRevision);\n    };\n  }, []);\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const hasChanged = useMemo78(() => {\n    return !deepEqual(savedDefaultProps, unsavedDefaultProps);\n  }, [savedDefaultProps, unsavedDefaultProps]);\n  useEffect46(() => {\n    setUnsavedProps(hasChanged);\n  }, [hasChanged]);\n  const onQuickSave = useCallback67(() => {\n    if (hasChanged && showSaveButton) {\n      onSave(() => {\n        return unsavedDefaultProps;\n      });\n    }\n  }, [hasChanged, onSave, showSaveButton, unsavedDefaultProps]);\n  useEffect46(() => {\n    const save = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"s\",\n      commandCtrlKey: true,\n      callback: onQuickSave,\n      preventDefault: true,\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: true\n    });\n    return () => {\n      save.unregister();\n    };\n  }, [keybindings, onQuickSave, onSave]);\n  const def = schema._def;\n  const typeName = def.typeName;\n  const reset = useCallback67(() => {\n    setValue(savedDefaultProps);\n  }, [savedDefaultProps, setValue]);\n  if (!zodValidationResult.success) {\n    const defaultPropsValid = schema.safeParse(savedDefaultProps);\n    if (!defaultPropsValid.success) {\n      return /* @__PURE__ */ jsx140(InvalidDefaultProps, {\n        zodValidationResult\n      });\n    }\n    return /* @__PURE__ */ jsx140(InvalidSchema, {\n      reset,\n      zodValidationResult\n    });\n  }\n  if (typeName !== z.ZodFirstPartyTypeKind.ZodObject) {\n    return /* @__PURE__ */ jsx140(TopLevelZodValue, {\n      typeReceived: typeName\n    });\n  }\n  return /* @__PURE__ */ jsx140(\"div\", {\n    ref: defaultPropsEditorScrollableAreaRef,\n    style: scrollable2,\n    className: VERTICAL_SCROLLBAR_CLASSNAME,\n    children: /* @__PURE__ */ jsx140(RevisionContext.Provider, {\n      value: revisionState,\n      children: /* @__PURE__ */ jsx140(ZodObjectEditor, {\n        discriminatedUnionReplacement: null,\n        unsavedValue: unsavedDefaultProps,\n        setValue,\n        jsonPath: [],\n        schema,\n        savedValue: savedDefaultProps,\n        onSave,\n        showSaveButton,\n        onRemove: null,\n        saving,\n        saveDisabledByParent,\n        mayPad: true\n      })\n    })\n  });\n};\n\n// src/components/RenderModal/WarningIndicatorButton.tsx\nimport { useCallback as useCallback68, useMemo as useMemo79 } from \"react\";\nimport { jsx as jsx141, jsxs as jsxs71 } from \"react/jsx-runtime\";\nvar style8 = {\n  fontSize: 12,\n  display: \"inline-flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  backgroundColor: \"transparent\",\n  color: LIGHT_TEXT,\n  borderStyle: \"solid\",\n  borderWidth: 1,\n  cursor: \"pointer\",\n  paddingLeft: 8,\n  paddingRight: 8,\n  paddingTop: 4,\n  paddingBottom: 4\n};\nvar triangleStyle2 = {\n  width: 12,\n  height: 12,\n  flexShrink: 0,\n  fill: WARNING_COLOR\n};\nvar WarningTriangle2 = (props) => {\n  return /* @__PURE__ */ jsx141(\"svg\", {\n    viewBox: \"0 0 576 512\",\n    ...props,\n    children: /* @__PURE__ */ jsx141(\"path\", {\n      d: \"M248.747 204.705l6.588 112c.373 6.343 5.626 11.295 11.979 11.295h41.37a12 12 0 0 0 11.979-11.295l6.588-112c.405-6.893-5.075-12.705-11.979-12.705h-54.547c-6.903 0-12.383 5.812-11.978 12.705zM330 384c0 23.196-18.804 42-42 42s-42-18.804-42-42 18.804-42 42-42 42 18.804 42 42zm-.423-360.015c-18.433-31.951-64.687-32.009-83.154 0L6.477 440.013C-11.945 471.946 11.118 512 48.054 512H527.94c36.865 0 60.035-39.993 41.577-71.987L329.577 23.985zM53.191 455.002L282.803 57.008c2.309-4.002 8.085-4.002 10.394 0l229.612 397.993c2.308 4-.579 8.998-5.197 8.998H58.388c-4.617.001-7.504-4.997-5.197-8.997z\"\n    })\n  });\n};\nvar WarningIndicatorButton = ({ setShowWarning, showWarning, warningCount }) => {\n  const onClick = useCallback68(() => {\n    setShowWarning((s) => !s);\n  }, [setShowWarning]);\n  const buttonStyle3 = useMemo79(() => {\n    return {\n      ...style8,\n      backgroundColor: showWarning ? INPUT_BACKGROUND : \"transparent\",\n      borderColor: showWarning ? INPUT_BORDER_COLOR_HOVERED : INPUT_BORDER_COLOR_UNHOVERED,\n      color: showWarning ? \"white\" : LIGHT_TEXT\n    };\n  }, [showWarning]);\n  return /* @__PURE__ */ jsxs71(\"button\", {\n    type: \"button\",\n    style: buttonStyle3,\n    onClick,\n    children: [\n      /* @__PURE__ */ jsx141(WarningTriangle2, {\n        style: triangleStyle2\n      }),\n      /* @__PURE__ */ jsx141(Spacing, {\n        x: 0.5\n      }),\n      warningCount,\n      /* @__PURE__ */ jsx141(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsx141(AngleDown, {\n        down: showWarning\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/get-render-modal-warnings.ts\nimport { NoReactInternals as NoReactInternals9 } from \"remotion/no-react\";\nvar defaultTypeCanSaveState = {\n  canUpdate: false,\n  reason: \"Loading...\",\n  determined: false\n};\nvar getInputPropsWarning = ({\n  cliProps,\n  propsEditType\n}) => {\n  if (Object.keys(cliProps).length > 0 && propsEditType === \"default-props\") {\n    return \"The data that was passed using --props takes priority over the data you enter here.\";\n  }\n  return null;\n};\nvar getCannotSaveDefaultProps = (canSaveDefaultProps) => {\n  if (canSaveDefaultProps.canUpdate) {\n    return null;\n  }\n  if (!canSaveDefaultProps.determined) {\n    return null;\n  }\n  return `Can't save default props: ${canSaveDefaultProps.reason}.`;\n};\nvar customDateUsed = (used, inJSONEditor) => {\n  if (used && inJSONEditor) {\n    return \"There is a Date in the schema which was serialized. Note the custom syntax.\";\n  }\n  return null;\n};\nvar staticFileUsed = (used, inJSONEditor) => {\n  if (used && inJSONEditor) {\n    return \"There is a staticFile() in the schema which was serialized. Note the custom syntax.\";\n  }\n  return null;\n};\nvar mapUsed = (used, inJSONEditor) => {\n  if (used && inJSONEditor) {\n    return \"A `Map` was used in the schema which can not be serialized to JSON.\";\n  }\n  return null;\n};\nvar setUsed = (used, inJSONEditor) => {\n  if (used && inJSONEditor) {\n    return \"A `Set` was used in the schema which can not be serialized to JSON.\";\n  }\n  return null;\n};\nvar getRenderModalWarnings = ({\n  cliProps,\n  canSaveDefaultProps,\n  isCustomDateUsed,\n  customFileUsed,\n  jsMapUsed,\n  jsSetUsed,\n  inJSONEditor,\n  propsEditType\n}) => {\n  return [\n    getInputPropsWarning({ cliProps, propsEditType }),\n    getCannotSaveDefaultProps(canSaveDefaultProps),\n    customDateUsed(isCustomDateUsed, inJSONEditor),\n    staticFileUsed(customFileUsed, inJSONEditor),\n    mapUsed(jsMapUsed, inJSONEditor),\n    setUsed(jsSetUsed, inJSONEditor)\n  ].filter(NoReactInternals9.truthy);\n};\n\n// src/components/RenderModal/DataEditor.tsx\nimport { jsx as jsx142, jsxs as jsxs72 } from \"react/jsx-runtime\";\nvar errorExplanation2 = {\n  fontSize: 14,\n  color: LIGHT_TEXT,\n  fontFamily: \"sans-serif\",\n  lineHeight: 1.5\n};\nvar explainer3 = {\n  display: \"flex\",\n  flex: 1,\n  flexDirection: \"column\",\n  padding: \"0 12px\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  textAlign: \"center\"\n};\nvar outer = {\n  display: \"flex\",\n  flexDirection: \"column\",\n  flex: 1,\n  overflow: \"hidden\",\n  backgroundColor: BACKGROUND\n};\nvar controlContainer = {\n  flexDirection: \"column\",\n  display: \"flex\",\n  padding: 12,\n  borderBottom: `1px solid ${BORDER_COLOR}`\n};\nvar tabWrapper = {\n  display: \"flex\",\n  marginBottom: \"4px\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar persistanceKey = \"remotion.show-render-modalwarning\";\nvar getPersistedShowWarningState = () => {\n  const val = localStorage.getItem(persistanceKey);\n  if (!val) {\n    return true;\n  }\n  return val === \"true\";\n};\nvar setPersistedShowWarningState = (val) => {\n  localStorage.setItem(persistanceKey, String(Boolean(val)));\n};\nvar DataEditor = ({\n  unresolvedComposition,\n  defaultProps,\n  setDefaultProps,\n  mayShowSaveButton,\n  propsEditType,\n  saving,\n  setSaving,\n  readOnlyStudio\n}) => {\n  const [mode, setMode] = useState51(\"schema\");\n  const [showWarning, setShowWarningWithoutPersistance] = useState51(() => getPersistedShowWarningState());\n  const { updateCompositionDefaultProps } = useContext36(Internals31.CompositionSetters);\n  const inJSONEditor = mode === \"json\";\n  const serializedJSON = useMemo80(() => {\n    if (!inJSONEditor) {\n      return null;\n    }\n    const value = defaultProps;\n    return NoReactInternals10.serializeJSONWithSpecialTypes({\n      data: value,\n      indent: 2,\n      staticBase: window.remotion_staticBase\n    });\n  }, [inJSONEditor, defaultProps]);\n  const cliProps = getInputProps();\n  const [canSaveDefaultPropsObjectState, setCanSaveDefaultProps] = useState51({\n    [unresolvedComposition.id]: defaultTypeCanSaveState\n  });\n  const z = useZodIfPossible();\n  const zodTypes = useZodTypesIfPossible();\n  const schema = useMemo80(() => {\n    if (!z) {\n      return \"no-zod\";\n    }\n    if (!unresolvedComposition.schema) {\n      return \"no-schema\";\n    }\n    if (!(typeof unresolvedComposition.schema.safeParse === \"function\")) {\n      throw new Error(\"A value which is not a Zod schema was passed to `schema`\");\n    }\n    return unresolvedComposition.schema;\n  }, [unresolvedComposition.schema, z]);\n  const zodValidationResult = useMemo80(() => {\n    if (schema === \"no-zod\") {\n      return \"no-zod\";\n    }\n    if (schema === \"no-schema\") {\n      return \"no-schema\";\n    }\n    return schema.safeParse(defaultProps);\n  }, [defaultProps, schema]);\n  const setShowWarning = useCallback69((val) => {\n    setShowWarningWithoutPersistance((prevVal) => {\n      if (typeof val === \"boolean\") {\n        setPersistedShowWarningState(val);\n        return val;\n      }\n      setPersistedShowWarningState(val(prevVal));\n      return val(prevVal);\n    });\n  }, []);\n  const canSaveDefaultProps = useMemo80(() => {\n    return canSaveDefaultPropsObjectState[unresolvedComposition.id] ? canSaveDefaultPropsObjectState[unresolvedComposition.id] : defaultTypeCanSaveState;\n  }, [canSaveDefaultPropsObjectState, unresolvedComposition.id]);\n  const showSaveButton = mayShowSaveButton && canSaveDefaultProps.canUpdate;\n  const { fastRefreshes } = useContext36(Internals31.NonceContext);\n  const checkIfCanSaveDefaultProps = useCallback69(async () => {\n    try {\n      const can = await canUpdateDefaultProps(unresolvedComposition.id, readOnlyStudio);\n      if (can.canUpdate) {\n        setCanSaveDefaultProps((prevState) => ({\n          ...prevState,\n          [unresolvedComposition.id]: {\n            canUpdate: true\n          }\n        }));\n      } else {\n        setCanSaveDefaultProps((prevState) => ({\n          ...prevState,\n          [unresolvedComposition.id]: {\n            canUpdate: false,\n            reason: can.reason,\n            determined: true\n          }\n        }));\n      }\n    } catch (err) {\n      setCanSaveDefaultProps((prevState) => ({\n        ...prevState,\n        [unresolvedComposition.id]: {\n          canUpdate: false,\n          reason: err.message,\n          determined: true\n        }\n      }));\n    }\n  }, [readOnlyStudio, unresolvedComposition.id]);\n  useEffect47(() => {\n    checkIfCanSaveDefaultProps();\n  }, [checkIfCanSaveDefaultProps]);\n  const { previewServerState, subscribeToEvent } = useContext36(StudioServerConnectionCtx);\n  useEffect47(() => {\n    const unsub = subscribeToEvent(\"root-file-changed\", checkIfCanSaveDefaultProps);\n    return () => {\n      unsub();\n    };\n  }, [checkIfCanSaveDefaultProps, subscribeToEvent]);\n  const modeItems = useMemo80(() => {\n    return [\n      {\n        key: \"schema\",\n        label: \"Schema\",\n        onClick: () => {\n          setMode(\"schema\");\n        },\n        selected: mode === \"schema\"\n      },\n      {\n        key: \"json\",\n        label: \"JSON\",\n        onClick: () => {\n          setMode(\"json\");\n        },\n        selected: mode === \"json\"\n      }\n    ];\n  }, [mode]);\n  const onUpdate = useCallback69(() => {\n    if (schema === \"no-zod\" || schema === \"no-schema\" || z === null) {\n      showNotification(\"Cannot update default props: No Zod schema\", 2000);\n      return;\n    }\n    callUpdateDefaultPropsApi(unresolvedComposition.id, defaultProps, extractEnumJsonPaths({ schema, zodRuntime: z, currentPath: [], zodTypes })).then((response) => {\n      if (!response.success) {\n        showNotification(`Cannot update default props: ${response.reason}`, 2000);\n      }\n    });\n  }, [schema, z, unresolvedComposition.id, defaultProps, zodTypes]);\n  const onSave = useCallback69((updater) => {\n    if (schema === \"no-zod\" || schema === \"no-schema\" || z === null) {\n      showNotification(\"Cannot update default props: No Zod schema\", 2000);\n      return;\n    }\n    window.remotion_ignoreFastRefreshUpdate = fastRefreshes + 1;\n    setSaving(true);\n    const newDefaultProps = updater(unresolvedComposition.defaultProps ?? {});\n    callUpdateDefaultPropsApi(unresolvedComposition.id, newDefaultProps, extractEnumJsonPaths({\n      schema,\n      zodRuntime: z,\n      currentPath: [],\n      zodTypes\n    })).then((response) => {\n      if (!response.success) {\n        console.log(response.stack);\n        showNotification(`Cannot update default props: ${response.reason}. See console for more information.`, 2000);\n      }\n      updateCompositionDefaultProps(unresolvedComposition.id, newDefaultProps);\n    }).catch((err) => {\n      showNotification(`Cannot update default props: ${err.message}`, 2000);\n    }).finally(() => {\n      setSaving(false);\n    });\n  }, [\n    schema,\n    z,\n    zodTypes,\n    fastRefreshes,\n    setSaving,\n    unresolvedComposition.defaultProps,\n    unresolvedComposition.id,\n    updateCompositionDefaultProps\n  ]);\n  const connectionStatus = previewServerState.type;\n  const warnings = useMemo80(() => {\n    return getRenderModalWarnings({\n      canSaveDefaultProps,\n      cliProps,\n      isCustomDateUsed: serializedJSON ? serializedJSON.customDateUsed : false,\n      customFileUsed: serializedJSON ? serializedJSON.customFileUsed : false,\n      inJSONEditor,\n      propsEditType,\n      jsMapUsed: serializedJSON ? serializedJSON.mapUsed : false,\n      jsSetUsed: serializedJSON ? serializedJSON.setUsed : false\n    });\n  }, [\n    cliProps,\n    canSaveDefaultProps,\n    inJSONEditor,\n    propsEditType,\n    serializedJSON\n  ]);\n  if (connectionStatus === \"disconnected\") {\n    return /* @__PURE__ */ jsxs72(\"div\", {\n      style: explainer3,\n      children: [\n        /* @__PURE__ */ jsx142(Spacing, {\n          y: 5\n        }),\n        /* @__PURE__ */ jsx142(\"div\", {\n          style: errorExplanation2,\n          children: \"The studio server has disconnected. Reconnect to edit the schema.\"\n        }),\n        /* @__PURE__ */ jsx142(Spacing, {\n          y: 2,\n          block: true\n        })\n      ]\n    });\n  }\n  if (schema === \"no-zod\") {\n    return /* @__PURE__ */ jsx142(ZodNotInstalled, {});\n  }\n  if (schema === \"no-schema\") {\n    return /* @__PURE__ */ jsx142(NoSchemaDefined, {});\n  }\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  if (zodValidationResult === \"no-zod\") {\n    throw new Error(\"expected zod\");\n  }\n  if (zodValidationResult === \"no-schema\") {\n    throw new Error(\"expected schema\");\n  }\n  const def = schema._def;\n  const typeName = def.typeName;\n  if (typeName === z.ZodFirstPartyTypeKind.ZodAny) {\n    return /* @__PURE__ */ jsx142(NoSchemaDefined, {});\n  }\n  if (!unresolvedComposition.defaultProps) {\n    return /* @__PURE__ */ jsx142(NoDefaultProps, {});\n  }\n  return /* @__PURE__ */ jsxs72(\"div\", {\n    style: outer,\n    children: [\n      /* @__PURE__ */ jsxs72(\"div\", {\n        style: controlContainer,\n        children: [\n          /* @__PURE__ */ jsxs72(\"div\", {\n            style: tabWrapper,\n            children: [\n              /* @__PURE__ */ jsx142(SegmentedControl, {\n                items: modeItems,\n                needsWrapping: false\n              }),\n              /* @__PURE__ */ jsx142(Flex, {}),\n              warnings.length > 0 ? /* @__PURE__ */ jsx142(WarningIndicatorButton, {\n                setShowWarning,\n                showWarning,\n                warningCount: warnings.length\n              }) : null\n            ]\n          }),\n          showWarning && warnings.length > 0 ? warnings.map((warning) => /* @__PURE__ */ jsxs72(React94.Fragment, {\n            children: [\n              /* @__PURE__ */ jsx142(Spacing, {\n                y: 1\n              }),\n              /* @__PURE__ */ jsx142(ValidationMessage, {\n                message: warning,\n                align: \"flex-start\",\n                type: \"warning\"\n              })\n            ]\n          }, warning)) : null\n        ]\n      }),\n      mode === \"schema\" ? /* @__PURE__ */ jsx142(SchemaEditor, {\n        unsavedDefaultProps: defaultProps,\n        setValue: setDefaultProps,\n        schema,\n        zodValidationResult,\n        savedDefaultProps: unresolvedComposition.defaultProps,\n        onSave,\n        showSaveButton,\n        saving,\n        saveDisabledByParent: !zodValidationResult.success\n      }) : /* @__PURE__ */ jsx142(RenderModalJSONPropsEditor, {\n        value: defaultProps ?? {},\n        setValue: setDefaultProps,\n        onSave: onUpdate,\n        showSaveButton,\n        serializedJSON,\n        defaultProps: unresolvedComposition.defaultProps,\n        schema\n      })\n    ]\n  });\n};\n\n// src/components/RenderQueue/index.tsx\nimport React104, { useContext as useContext44, useEffect as useEffect49, useMemo as useMemo87 } from \"react\";\nimport { Internals as Internals34 } from \"remotion\";\n\n// src/components/RenderQueue/RenderQueueItem.tsx\nimport {\n  useCallback as useCallback78,\n  useContext as useContext43,\n  useEffect as useEffect48,\n  useMemo as useMemo86,\n  useState as useState52\n} from \"react\";\nimport { Internals as Internals33 } from \"remotion\";\n\n// src/components/RenderQueue/item-style.ts\nvar renderQueueItemSubtitleStyle = {\n  fontSize: 13,\n  color: LIGHT_TEXT,\n  appearance: \"none\",\n  border: \"none\",\n  padding: 0,\n  cursor: \"pointer\",\n  lineHeight: 1.2,\n  textAlign: \"left\",\n  whiteSpace: \"nowrap\",\n  marginRight: SPACING_UNIT,\n  overflowX: \"hidden\",\n  maxWidth: 500,\n  textOverflow: \"ellipsis\"\n};\n\n// src/components/RenderQueue/RenderQueueCancelledMessage.tsx\nimport { jsx as jsx143 } from \"react/jsx-runtime\";\nvar cancelledStyle = {\n  ...renderQueueItemSubtitleStyle,\n  color: LIGHT_TEXT,\n  cursor: \"default\"\n};\nvar RenderQueueCancelledMessage = () => {\n  return /* @__PURE__ */ jsx143(\"span\", {\n    style: cancelledStyle,\n    children: \"Cancelled\"\n  });\n};\n\n// src/components/RenderQueue/RenderQueueCopyToClipboard.tsx\nimport { useCallback as useCallback70 } from \"react\";\nimport { jsx as jsx144 } from \"react/jsx-runtime\";\nvar revealIconStyle2 = {\n  height: 12,\n  color: \"currentColor\"\n};\nvar supportsCopyingToClipboard = (job) => {\n  if (job.status !== \"done\") {\n    return false;\n  }\n  if (job.type !== \"still\") {\n    return false;\n  }\n  if (job.imageFormat === \"png\") {\n    return true;\n  }\n  if (job.imageFormat === \"jpeg\") {\n    return true;\n  }\n  return false;\n};\nvar RenderQueueCopyToClipboard = ({ job }) => {\n  const renderCopyAction = useCallback70((color) => {\n    return /* @__PURE__ */ jsx144(ClipboardIcon, {\n      style: revealIconStyle2,\n      color\n    });\n  }, []);\n  const onClick = useCallback70(async (e) => {\n    e.stopPropagation();\n    try {\n      const src = `${remotion_outputsBase}/${job.outName}`;\n      const content = await fetch(src);\n      const contentType = content.headers.get(\"content-type\");\n      if (!contentType) {\n        throw new Error(\"Expected content-type header\");\n      }\n      const blob = await content.blob();\n      await navigator.clipboard.write([\n        new ClipboardItem({\n          [contentType]: blob\n        })\n      ]);\n      showNotification(\"Copied to clipboard!\", 1000);\n    } catch (err) {\n      showNotification(`Could not copy to clipboard: ${err.message}`, 2000);\n    }\n  }, [job.outName]);\n  return /* @__PURE__ */ jsx144(InlineAction, {\n    title: \"Copy to clipboard\",\n    renderAction: renderCopyAction,\n    onClick\n  });\n};\n\n// src/components/RenderQueue/RenderQueueError.tsx\nimport { useCallback as useCallback71, useContext as useContext37 } from \"react\";\nimport { jsx as jsx145 } from \"react/jsx-runtime\";\nvar outputLocation = {\n  ...renderQueueItemSubtitleStyle\n};\nvar RenderQueueError = ({ job }) => {\n  const { setSelectedModal } = useContext37(ModalsContext);\n  const { tabIndex } = useZIndex();\n  const onClick = useCallback71(() => {\n    setSelectedModal({\n      type: \"render-progress\",\n      jobId: job.id\n    });\n  }, [job.id, setSelectedModal]);\n  if (job.status !== \"failed\") {\n    throw new Error(\"should not have rendered this component\");\n  }\n  return /* @__PURE__ */ jsx145(\"button\", {\n    onClick,\n    type: \"button\",\n    style: outputLocation,\n    tabIndex,\n    title: job.error.message,\n    children: job.error.message\n  });\n};\n\n// src/components/RenderQueue/RenderQueueItemCancelButton.tsx\nimport { useCallback as useCallback72, useContext as useContext38, useMemo as useMemo81 } from \"react\";\nimport { jsx as jsx146 } from \"react/jsx-runtime\";\nvar RenderQueueCancelButton = ({ job }) => {\n  const isClientJob = isClientRenderJob(job);\n  const { cancelClientJob } = useContext38(RenderQueueContext);\n  const onClick = useCallback72((e) => {\n    e.stopPropagation();\n    if (isClientJob) {\n      cancelClientJob(job.id);\n      return;\n    }\n    cancelRenderJob(job).catch((err) => {\n      showNotification(`Could not cancel job: ${err.message}`, 2000);\n    });\n  }, [job, isClientJob, cancelClientJob]);\n  const icon5 = useMemo81(() => {\n    return {\n      height: 14,\n      color: \"currentColor\"\n    };\n  }, []);\n  const renderAction = useCallback72((color) => {\n    return /* @__PURE__ */ jsx146(\"svg\", {\n      style: icon5,\n      xmlns: \"http://www.w3.org/2000/svg\",\n      viewBox: \"0 0 512 512\",\n      children: /* @__PURE__ */ jsx146(\"path\", {\n        fill: color,\n        d: \"M367.2 412.5L99.5 144.8C77.1 176.1 64 214.5 64 256c0 106 86 192 192 192c41.5 0 79.9-13.1 111.2-35.5zm45.3-45.3C434.9 335.9 448 297.5 448 256c0-106-86-192-192-192c-41.5 0-79.9 13.1-111.2 35.5L412.5 367.2zM512 256c0 141.4-114.6 256-256 256S0 397.4 0 256S114.6 0 256 0S512 114.6 512 256z\"\n      })\n    });\n  }, [icon5]);\n  return /* @__PURE__ */ jsx146(InlineAction, {\n    renderAction,\n    onClick\n  });\n};\n\n// src/components/RenderQueue/RenderQueueItemStatus.tsx\nimport React97, { useCallback as useCallback73, useContext as useContext39 } from \"react\";\n\n// src/components/RenderQueue/CircularProgress.tsx\nimport { jsx as jsx147 } from \"react/jsx-runtime\";\nvar RENDER_STATUS_INDICATOR_SIZE = 16;\nvar STROKE_WIDTH = 3;\nvar container30 = {\n  height: RENDER_STATUS_INDICATOR_SIZE,\n  width: RENDER_STATUS_INDICATOR_SIZE,\n  transform: `rotate(-90deg)`\n};\nvar CircularProgress = ({ progress }) => {\n  const r = RENDER_STATUS_INDICATOR_SIZE / 2 - STROKE_WIDTH;\n  const circumference = r * Math.PI * 2;\n  return /* @__PURE__ */ jsx147(\"svg\", {\n    style: container30,\n    viewBox: `0 0 ${RENDER_STATUS_INDICATOR_SIZE} ${RENDER_STATUS_INDICATOR_SIZE}`,\n    children: /* @__PURE__ */ jsx147(\"circle\", {\n      r: RENDER_STATUS_INDICATOR_SIZE / 2 - STROKE_WIDTH,\n      stroke: LIGHT_TEXT,\n      fill: \"none\",\n      strokeWidth: STROKE_WIDTH,\n      cx: RENDER_STATUS_INDICATOR_SIZE / 2,\n      cy: RENDER_STATUS_INDICATOR_SIZE / 2,\n      strokeDasharray: `${circumference} ${circumference}`,\n      strokeMiterlimit: 0,\n      strokeDashoffset: (1 - progress) * circumference\n    })\n  });\n};\n\n// src/components/RenderQueue/RenderQueueItemStatus.tsx\nimport { jsx as jsx148 } from \"react/jsx-runtime\";\nvar iconStyle3 = {\n  height: RENDER_STATUS_INDICATOR_SIZE,\n  width: RENDER_STATUS_INDICATOR_SIZE\n};\nvar invisibleStyle = {\n  appearance: \"none\",\n  border: \"none\",\n  padding: 0,\n  cursor: \"pointer\",\n  display: \"flex\"\n};\nvar RenderQueueItemStatus = ({ job }) => {\n  const { setSelectedModal } = useContext39(ModalsContext);\n  const [hovered, setHovered] = React97.useState(false);\n  const isClientJob = isClientRenderJob(job);\n  const onPointerEnter = useCallback73(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback73(() => {\n    setHovered(false);\n  }, []);\n  const onClick = useCallback73((e) => {\n    e.stopPropagation();\n    setSelectedModal({\n      type: \"render-progress\",\n      jobId: job.id\n    });\n  }, [job.id, setSelectedModal]);\n  if (job.status === \"failed\") {\n    return /* @__PURE__ */ jsx148(\"button\", {\n      type: \"button\",\n      style: invisibleStyle,\n      onClick,\n      children: /* @__PURE__ */ jsx148(\"svg\", {\n        style: iconStyle3,\n        viewBox: \"0 0 512 512\",\n        children: /* @__PURE__ */ jsx148(\"path\", {\n          fill: FAIL_COLOR,\n          d: \"M0 160V352L160 512H352L512 352V160L352 0H160L0 160zm353.9 32l-17 17-47 47 47 47 17 17L320 353.9l-17-17-47-47-47 47-17 17L158.1 320l17-17 47-47-47-47-17-17L192 158.1l17 17 47 47 47-47 17-17L353.9 192z\"\n        })\n      })\n    });\n  }\n  if (job.status === \"idle\") {\n    return /* @__PURE__ */ jsx148(\"svg\", {\n      style: iconStyle3,\n      viewBox: \"0 0 512 512\",\n      children: /* @__PURE__ */ jsx148(\"path\", {\n        fill: LIGHT_TEXT,\n        d: \"M256 512C114.6 512 0 397.4 0 256S114.6 0 256 0S512 114.6 512 256s-114.6 256-256 256zM232 120V256c0 8 4 15.5 10.7 20l96 64c11 7.4 25.9 4.4 33.3-6.7s4.4-25.9-6.7-33.3L280 243.2V120c0-13.3-10.7-24-24-24s-24 10.7-24 24z\"\n      })\n    });\n  }\n  if (job.status === \"done\") {\n    return /* @__PURE__ */ jsx148(\"button\", {\n      type: \"button\",\n      style: invisibleStyle,\n      onPointerEnter,\n      onPointerLeave,\n      onClick,\n      children: /* @__PURE__ */ jsx148(\"svg\", {\n        style: iconStyle3,\n        viewBox: \"0 0 512 512\",\n        children: /* @__PURE__ */ jsx148(\"path\", {\n          fill: hovered ? \"white\" : LIGHT_TEXT,\n          d: \"M256 512c141.4 0 256-114.6 256-256S397.4 0 256 0S0 114.6 0 256S114.6 512 256 512zM369 209L241 337l-17 17-17-17-64-64-17-17L160 222.1l17 17 47 47L335 175l17-17L385.9 192l-17 17z\"\n        })\n      })\n    });\n  }\n  if (job.status === \"running\") {\n    let progressValue;\n    if (isClientJob) {\n      const { renderedFrames, totalFrames } = job.progress;\n      progressValue = totalFrames > 0 ? renderedFrames / totalFrames : 0;\n    } else {\n      progressValue = job.progress.value;\n    }\n    return /* @__PURE__ */ jsx148(\"button\", {\n      type: \"button\",\n      style: invisibleStyle,\n      onClick,\n      children: /* @__PURE__ */ jsx148(CircularProgress, {\n        progress: Math.max(0.07, progressValue)\n      })\n    });\n  }\n  if (job.status === \"cancelled\") {\n    return /* @__PURE__ */ jsx148(\"svg\", {\n      style: iconStyle3,\n      viewBox: \"0 0 512 512\",\n      children: /* @__PURE__ */ jsx148(\"path\", {\n        fill: FAIL_COLOR,\n        d: \"M0 160V352L160 512H352L512 352V160L352 0H160L0 160zm353.9 32l-17 17-47 47 47 47 17 17L320 353.9l-17-17-47-47-47 47-17 17L158.1 320l17-17 47-47-47-47-17-17L192 158.1l17 17 47 47 47-47 17-17L353.9 192z\"\n      })\n    });\n  }\n  throw new Error(\"Unknown job status\");\n};\n\n// src/components/RenderQueue/RenderQueueOpenInFolder.tsx\nimport { useCallback as useCallback74, useMemo as useMemo82 } from \"react\";\nimport { jsx as jsx149 } from \"react/jsx-runtime\";\nvar RenderQueueOpenInFinderItem = ({ job }) => {\n  const onClick = useCallback74((e) => {\n    e.stopPropagation();\n    openInFileExplorer({ directory: job.outName }).catch((err) => {\n      showNotification(`Could not open file: ${err.message}`, 2000);\n    });\n  }, [job.outName]);\n  const icon5 = useMemo82(() => {\n    return {\n      height: 12,\n      color: \"currentColor\"\n    };\n  }, []);\n  const renderAction = useCallback74((color) => {\n    return /* @__PURE__ */ jsx149(ExpandedFolderIconSolid, {\n      style: icon5,\n      color\n    });\n  }, [icon5]);\n  return /* @__PURE__ */ jsx149(InlineAction, {\n    renderAction,\n    onClick\n  });\n};\n\n// src/components/RenderQueue/RenderQueueOutputName.tsx\nimport { useMemo as useMemo83 } from \"react\";\nimport { jsx as jsx150 } from \"react/jsx-runtime\";\nvar RenderQueueOutputName = ({ job }) => {\n  const isClientJob = isClientRenderJob(job);\n  const deletedOutputLocation = isClientJob ? false : job.deletedOutputLocation;\n  const style9 = useMemo83(() => {\n    return {\n      ...renderQueueItemSubtitleStyle,\n      textDecoration: deletedOutputLocation ? \"line-through\" : \"none\",\n      color: renderQueueItemSubtitleStyle.color,\n      cursor: \"inherit\"\n    };\n  }, [deletedOutputLocation]);\n  const getTitle = () => {\n    if (isClientJob) {\n      return `Downloaded as ${job.outName}`;\n    }\n    if (deletedOutputLocation) {\n      return \"File was deleted\";\n    }\n    return job.outName;\n  };\n  return /* @__PURE__ */ jsx150(\"span\", {\n    style: style9,\n    title: getTitle(),\n    children: job.outName\n  });\n};\n\n// src/components/RenderQueue/RenderQueueProgressMessage.tsx\nimport { useCallback as useCallback75, useContext as useContext40 } from \"react\";\nimport { jsx as jsx151 } from \"react/jsx-runtime\";\nvar outputLocation2 = {\n  ...renderQueueItemSubtitleStyle\n};\nvar RenderQueueProgressMessage = ({ job }) => {\n  if (job.status !== \"running\") {\n    throw new Error(\"should not have rendered this component\");\n  }\n  const { setSelectedModal } = useContext40(ModalsContext);\n  const { tabIndex } = useZIndex();\n  const isClientJob = isClientRenderJob(job);\n  const onClick = useCallback75(() => {\n    setSelectedModal({\n      type: \"render-progress\",\n      jobId: job.id\n    });\n  }, [job.id, setSelectedModal]);\n  const message = isClientJob ? `Rendering frame ${job.progress.renderedFrames}/${job.progress.totalFrames}` : job.progress.message;\n  return /* @__PURE__ */ jsx151(\"button\", {\n    onClick,\n    type: \"button\",\n    style: outputLocation2,\n    tabIndex,\n    title: message,\n    children: message\n  });\n};\n\n// src/components/RenderQueue/RenderQueueRemoveItem.tsx\nimport { useCallback as useCallback76, useContext as useContext41, useMemo as useMemo84 } from \"react\";\nimport { Internals as Internals32 } from \"remotion\";\nimport { jsx as jsx152 } from \"react/jsx-runtime\";\nvar RenderQueueRemoveItem = ({ job }) => {\n  const isClientJob = isClientRenderJob(job);\n  const { removeClientJob } = useContext41(RenderQueueContext);\n  const { canvasContent } = useContext41(Internals32.CompositionManager);\n  const { setCanvasContent } = useContext41(Internals32.CompositionSetters);\n  const onClick = useCallback76((e) => {\n    e.stopPropagation();\n    if (isClientJob) {\n      if (canvasContent && canvasContent.type === \"output-blob\" && job.status === \"done\" && canvasContent.getBlob === job.getBlob) {\n        setCanvasContent(null);\n      }\n      removeClientJob(job.id);\n      showNotification(\"Removed job\", 2000);\n      return;\n    }\n    removeRenderJob(job).then(() => {\n      showNotification(\"Removed job\", 2000);\n    }).catch((err) => {\n      showNotification(`Could not remove item: ${err.message}`, 2000);\n    });\n  }, [job, isClientJob, removeClientJob, canvasContent, setCanvasContent]);\n  const icon5 = useMemo84(() => {\n    return {\n      height: 16,\n      color: \"currentColor\"\n    };\n  }, []);\n  const renderAction = useCallback76((color) => {\n    return /* @__PURE__ */ jsx152(\"svg\", {\n      style: icon5,\n      xmlns: \"http://www.w3.org/2000/svg\",\n      viewBox: \"0 0 320 512\",\n      children: /* @__PURE__ */ jsx152(\"path\", {\n        fill: color,\n        d: \"M310.6 150.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L160 210.7 54.6 105.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L114.7 256 9.4 361.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L160 301.3 265.4 406.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L205.3 256 310.6 150.6z\"\n      })\n    });\n  }, [icon5]);\n  return /* @__PURE__ */ jsx152(InlineAction, {\n    renderAction,\n    onClick\n  });\n};\n\n// src/components/RenderQueue/RenderQueueRepeat.tsx\nimport { useCallback as useCallback77, useContext as useContext42, useMemo as useMemo85 } from \"react\";\n\n// src/helpers/retry-payload.ts\nimport { NoReactInternals as NoReactInternals11 } from \"remotion/no-react\";\nvar makeRetryPayload = (job) => {\n  const defaults = window.remotion_renderDefaults;\n  if (!defaults) {\n    throw new Error(\"defaults not set\");\n  }\n  if (job.type === \"still\") {\n    return {\n      type: \"server-render\",\n      compositionId: job.compositionId,\n      initialFrame: job.frame,\n      initialStillImageFormat: job.imageFormat,\n      initialVideoImageFormat: null,\n      initialJpegQuality: job.jpegQuality ?? defaults.jpegQuality,\n      initialScale: job.scale,\n      initialLogLevel: job.logLevel,\n      initialConcurrency: defaults.concurrency,\n      maxConcurrency: defaults.maxConcurrency,\n      minConcurrency: defaults.minConcurrency,\n      initialMuted: defaults.muted,\n      initialEnforceAudioTrack: defaults.enforceAudioTrack,\n      initialProResProfile: null,\n      initialx264Preset: defaults.x264Preset,\n      initialPixelFormat: defaults.pixelFormat,\n      initialAudioBitrate: defaults.audioBitrate,\n      initialVideoBitrate: defaults.videoBitrate,\n      initialEveryNthFrame: defaults.everyNthFrame,\n      initialNumberOfGifLoops: defaults.numberOfGifLoops,\n      initialDelayRenderTimeout: job.delayRenderTimeout,\n      defaultConfigurationAudioCodec: defaults.audioCodec,\n      initialEnvVariables: job.envVariables,\n      initialDisableWebSecurity: job.chromiumOptions.disableWebSecurity,\n      initialOpenGlRenderer: job.chromiumOptions.gl,\n      initialHeadless: job.chromiumOptions.headless,\n      initialIgnoreCertificateErrors: job.chromiumOptions.ignoreCertificateErrors,\n      initialDarkMode: job.chromiumOptions.darkMode,\n      defaultProps: NoReactInternals11.deserializeJSONWithSpecialTypes(job.serializedInputPropsWithCustomSchema),\n      inFrameMark: null,\n      outFrameMark: null,\n      initialOffthreadVideoCacheSizeInBytes: job.offthreadVideoCacheSizeInBytes,\n      initialOffthreadVideoThreads: job.offthreadVideoThreads,\n      initialColorSpace: defaults.colorSpace,\n      initialMultiProcessOnLinux: job.multiProcessOnLinux,\n      defaultConfigurationVideoCodec: defaults.codec,\n      initialEncodingBufferSize: defaults.encodingBufferSize,\n      initialEncodingMaxRate: defaults.encodingMaxRate,\n      initialUserAgent: job.chromiumOptions.userAgent,\n      initialBeep: job.beepOnFinish,\n      initialRepro: job.repro,\n      initialForSeamlessAacConcatenation: defaults.forSeamlessAacConcatenation,\n      defaulMetadata: job.metadata,\n      renderTypeOfLastRender: \"still\",\n      initialHardwareAcceleration: defaults.hardwareAcceleration,\n      initialChromeMode: job.chromeMode,\n      initialMediaCacheSizeInBytes: job.mediaCacheSizeInBytes,\n      renderDefaults: defaults\n    };\n  }\n  if (job.type === \"sequence\") {\n    return {\n      type: \"server-render\",\n      initialFrame: 0,\n      compositionId: job.compositionId,\n      initialVideoImageFormat: null,\n      initialJpegQuality: job.jpegQuality ?? defaults.jpegQuality,\n      initialScale: job.scale,\n      initialLogLevel: job.logLevel,\n      initialConcurrency: defaults.concurrency,\n      maxConcurrency: defaults.maxConcurrency,\n      minConcurrency: defaults.minConcurrency,\n      initialMuted: defaults.muted,\n      initialEnforceAudioTrack: defaults.enforceAudioTrack,\n      initialProResProfile: null,\n      initialx264Preset: defaults.x264Preset,\n      initialPixelFormat: defaults.pixelFormat,\n      initialAudioBitrate: defaults.audioBitrate,\n      initialVideoBitrate: defaults.videoBitrate,\n      initialEveryNthFrame: defaults.everyNthFrame,\n      initialNumberOfGifLoops: defaults.numberOfGifLoops,\n      initialDelayRenderTimeout: job.delayRenderTimeout,\n      initialEnvVariables: job.envVariables,\n      initialDisableWebSecurity: job.chromiumOptions.disableWebSecurity,\n      initialOpenGlRenderer: job.chromiumOptions.gl,\n      initialHeadless: job.chromiumOptions.headless,\n      initialIgnoreCertificateErrors: job.chromiumOptions.ignoreCertificateErrors,\n      initialDarkMode: job.chromiumOptions.darkMode,\n      defaultProps: NoReactInternals11.deserializeJSONWithSpecialTypes(job.serializedInputPropsWithCustomSchema),\n      initialStillImageFormat: defaults.stillImageFormat,\n      inFrameMark: job.startFrame,\n      outFrameMark: job.endFrame,\n      initialOffthreadVideoCacheSizeInBytes: job.offthreadVideoCacheSizeInBytes,\n      initialOffthreadVideoThreads: job.offthreadVideoThreads,\n      initialColorSpace: defaults.colorSpace,\n      initialMultiProcessOnLinux: job.multiProcessOnLinux,\n      defaultConfigurationVideoCodec: defaults.codec,\n      defaultConfigurationAudioCodec: defaults.audioCodec,\n      initialEncodingBufferSize: defaults.encodingBufferSize,\n      initialEncodingMaxRate: defaults.encodingMaxRate,\n      initialUserAgent: job.chromiumOptions.userAgent,\n      initialBeep: job.beepOnFinish,\n      initialRepro: job.repro,\n      initialForSeamlessAacConcatenation: defaults.forSeamlessAacConcatenation,\n      defaulMetadata: job.metadata,\n      renderTypeOfLastRender: \"sequence\",\n      initialHardwareAcceleration: defaults.hardwareAcceleration,\n      initialChromeMode: job.chromeMode,\n      initialMediaCacheSizeInBytes: job.mediaCacheSizeInBytes,\n      renderDefaults: defaults\n    };\n  }\n  if (job.type === \"video\") {\n    return {\n      type: \"server-render\",\n      compositionId: job.compositionId,\n      initialStillImageFormat: defaults.stillImageFormat,\n      initialVideoImageFormat: job.imageFormat,\n      initialJpegQuality: job.jpegQuality ?? defaults.jpegQuality,\n      initialScale: job.scale,\n      initialLogLevel: job.logLevel,\n      initialFrame: 0,\n      initialConcurrency: job.concurrency,\n      maxConcurrency: defaults.maxConcurrency,\n      minConcurrency: defaults.minConcurrency,\n      initialMuted: job.muted,\n      initialEnforceAudioTrack: job.enforceAudioTrack,\n      initialProResProfile: job.proResProfile ?? null,\n      initialx264Preset: job.x264Preset ?? defaults.x264Preset,\n      initialPixelFormat: job.pixelFormat,\n      initialAudioBitrate: job.audioBitrate,\n      initialVideoBitrate: job.videoBitrate,\n      initialEveryNthFrame: job.everyNthFrame,\n      initialNumberOfGifLoops: job.numberOfGifLoops,\n      initialDelayRenderTimeout: job.delayRenderTimeout,\n      initialEnvVariables: job.envVariables,\n      initialDisableWebSecurity: job.chromiumOptions.disableWebSecurity,\n      initialOpenGlRenderer: job.chromiumOptions.gl,\n      initialHeadless: job.chromiumOptions.headless,\n      initialIgnoreCertificateErrors: job.chromiumOptions.ignoreCertificateErrors,\n      initialDarkMode: job.chromiumOptions.darkMode,\n      defaultProps: NoReactInternals11.deserializeJSONWithSpecialTypes(job.serializedInputPropsWithCustomSchema),\n      inFrameMark: job.startFrame,\n      outFrameMark: job.endFrame,\n      initialOffthreadVideoCacheSizeInBytes: job.offthreadVideoCacheSizeInBytes,\n      initialOffthreadVideoThreads: job.offthreadVideoThreads,\n      initialColorSpace: job.colorSpace,\n      initialMultiProcessOnLinux: job.multiProcessOnLinux,\n      defaultConfigurationVideoCodec: job.codec,\n      defaultConfigurationAudioCodec: job.audioCodec,\n      initialEncodingBufferSize: job.encodingBufferSize,\n      initialEncodingMaxRate: job.encodingMaxRate,\n      initialUserAgent: job.chromiumOptions.userAgent,\n      initialBeep: job.beepOnFinish,\n      initialRepro: job.repro,\n      initialForSeamlessAacConcatenation: job.forSeamlessAacConcatenation,\n      defaulMetadata: job.metadata,\n      renderTypeOfLastRender: \"video\",\n      initialHardwareAcceleration: job.hardwareAcceleration,\n      initialChromeMode: job.chromeMode,\n      initialMediaCacheSizeInBytes: job.mediaCacheSizeInBytes,\n      renderDefaults: defaults\n    };\n  }\n  throw new Error(`Job ${JSON.stringify(job)} Not implemented`);\n};\nvar makeClientRetryPayload = (job) => {\n  return {\n    type: \"web-render\",\n    compositionId: job.compositionId,\n    initialFrame: job.type === \"client-still\" ? job.frame : 0,\n    initialLogLevel: job.logLevel,\n    initialLicenseKey: job.licenseKey,\n    defaultProps: job.inputProps,\n    inFrameMark: job.type === \"client-video\" ? job.startFrame : null,\n    outFrameMark: job.type === \"client-video\" ? job.endFrame : null\n  };\n};\n\n// src/components/RenderQueue/RenderQueueRepeat.tsx\nimport { jsx as jsx153 } from \"react/jsx-runtime\";\nvar RenderQueueRepeatItem = ({ job }) => {\n  const { setSelectedModal } = useContext42(ModalsContext);\n  const isMobileLayout = useMobileLayout();\n  const { setSidebarCollapsedState } = useContext42(SidebarContext);\n  const isClientJob = isClientRenderJob(job);\n  const onClick = useCallback77((e) => {\n    e.stopPropagation();\n    if (isClientJob) {\n      const retryPayload = makeClientRetryPayload(job);\n      setSelectedModal(retryPayload);\n    } else {\n      const retryPayload = makeRetryPayload(job);\n      setSelectedModal(retryPayload);\n    }\n    if (isMobileLayout) {\n      setSidebarCollapsedState({ left: \"collapsed\", right: \"collapsed\" });\n    }\n  }, [\n    isMobileLayout,\n    job,\n    isClientJob,\n    setSelectedModal,\n    setSidebarCollapsedState\n  ]);\n  const icon5 = useMemo85(() => {\n    return {\n      height: 12,\n      color: \"currentColor\"\n    };\n  }, []);\n  const renderAction = useCallback77((color) => {\n    return /* @__PURE__ */ jsx153(\"svg\", {\n      style: icon5,\n      viewBox: \"0 0 512 512\",\n      children: /* @__PURE__ */ jsx153(\"path\", {\n        fill: color,\n        d: \"M386.3 160H336c-17.7 0-32 14.3-32 32s14.3 32 32 32H464c17.7 0 32-14.3 32-32V64c0-17.7-14.3-32-32-32s-32 14.3-32 32v51.2L414.4 97.6c-87.5-87.5-229.3-87.5-316.8 0s-87.5 229.3 0 316.8s229.3 87.5 316.8 0c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0c-62.5 62.5-163.8 62.5-226.3 0s-62.5-163.8 0-226.3s163.8-62.5 226.3 0L386.3 160z\"\n      })\n    });\n  }, [icon5]);\n  return /* @__PURE__ */ jsx153(InlineAction, {\n    onClick,\n    renderAction\n  });\n};\n\n// src/components/RenderQueue/RenderQueueItem.tsx\nimport { jsx as jsx154, jsxs as jsxs73 } from \"react/jsx-runtime\";\nvar container31 = {\n  padding: 12,\n  display: \"flex\",\n  flexDirection: \"row\",\n  paddingBottom: 10,\n  paddingRight: 4\n};\nvar title3 = {\n  fontSize: 13,\n  lineHeight: 1\n};\nvar right = {\n  flex: 1,\n  display: \"flex\",\n  flexDirection: \"column\",\n  overflow: \"hidden\"\n};\nvar subtitle2 = {\n  maxWidth: \"100%\",\n  flex: 1,\n  display: \"flex\",\n  overflow: \"hidden\"\n};\nvar SELECTED_CLASSNAME = \"__remotion_selected_classname\";\nvar RenderQueueItem = ({ job, selected }) => {\n  const [hovered, setHovered] = useState52(false);\n  const { setCanvasContent } = useContext43(Internals33.CompositionSetters);\n  const isClientJob = isClientRenderJob(job);\n  const onPointerEnter = useCallback78(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback78(() => {\n    setHovered(false);\n  }, []);\n  const isHoverable = job.status === \"done\" && (isClientJob || job.type !== \"sequence\");\n  const containerStyle3 = useMemo86(() => {\n    return {\n      ...container31,\n      backgroundColor: getBackgroundFromHoverState({\n        hovered: isHoverable && hovered,\n        selected\n      }),\n      userSelect: \"none\",\n      WebkitUserSelect: \"none\"\n    };\n  }, [hovered, isHoverable, selected]);\n  const scrollCurrentIntoView = useCallback78(() => {\n    document.querySelector(`.${SELECTED_CLASSNAME}`)?.scrollIntoView({ behavior: \"smooth\" });\n  }, []);\n  const onClick = useCallback78(() => {\n    if (job.status !== \"done\") {\n      return;\n    }\n    if (isClientJob) {\n      const clientJob = job;\n      setCanvasContent({\n        type: \"output-blob\",\n        displayName: job.outName,\n        getBlob: clientJob.getBlob,\n        width: clientJob.metadata.width,\n        height: clientJob.metadata.height,\n        sizeInBytes: clientJob.metadata.sizeInBytes\n      });\n      return;\n    }\n    if (job.type === \"sequence\") {\n      return;\n    }\n    setCanvasContent((c) => {\n      const isAlreadySelected = c && c.type === \"output\" && c.path === `/${job.outName}`;\n      if (isAlreadySelected && !selected) {\n        scrollCurrentIntoView();\n        return c;\n      }\n      return { type: \"output\", path: `/${job.outName}` };\n    });\n    pushUrl(`/outputs/${job.outName}`);\n  }, [job, isClientJob, scrollCurrentIntoView, selected, setCanvasContent]);\n  useEffect48(() => {\n    if (selected) {\n      scrollCurrentIntoView();\n    }\n  }, [scrollCurrentIntoView, selected]);\n  return /* @__PURE__ */ jsxs73(Row, {\n    onPointerEnter,\n    onPointerLeave,\n    style: containerStyle3,\n    align: \"center\",\n    onClick,\n    className: selected ? SELECTED_CLASSNAME : undefined,\n    children: [\n      /* @__PURE__ */ jsx154(RenderQueueItemStatus, {\n        job\n      }),\n      /* @__PURE__ */ jsx154(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsxs73(\"div\", {\n        style: right,\n        children: [\n          /* @__PURE__ */ jsx154(\"div\", {\n            style: title3,\n            children: job.compositionId\n          }),\n          /* @__PURE__ */ jsx154(\"div\", {\n            style: subtitle2,\n            children: job.status === \"done\" ? /* @__PURE__ */ jsx154(RenderQueueOutputName, {\n              job\n            }) : job.status === \"failed\" ? /* @__PURE__ */ jsx154(RenderQueueError, {\n              job\n            }) : job.status === \"running\" ? /* @__PURE__ */ jsx154(RenderQueueProgressMessage, {\n              job\n            }) : job.status === \"cancelled\" ? /* @__PURE__ */ jsx154(RenderQueueCancelledMessage, {}) : null\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx154(Spacing, {\n        x: 1\n      }),\n      !isClientJob && supportsCopyingToClipboard(job) ? /* @__PURE__ */ jsx154(RenderQueueCopyToClipboard, {\n        job\n      }) : null,\n      job.status === \"done\" || job.status === \"failed\" || job.status === \"cancelled\" ? /* @__PURE__ */ jsx154(RenderQueueRepeatItem, {\n        job\n      }) : null,\n      job.status === \"running\" ? /* @__PURE__ */ jsx154(RenderQueueCancelButton, {\n        job\n      }) : /* @__PURE__ */ jsx154(RenderQueueRemoveItem, {\n        job\n      }),\n      job.status === \"done\" && !isClientJob ? /* @__PURE__ */ jsx154(RenderQueueOpenInFinderItem, {\n        job\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderQueue/index.tsx\nimport { jsx as jsx155, jsxs as jsxs74 } from \"react/jsx-runtime\";\nvar separatorStyle = {\n  borderBottom: `1px solid ${BORDER_COLOR}`\n};\nvar errorExplanation3 = {\n  fontSize: 14,\n  color: LIGHT_TEXT,\n  fontFamily: \"sans-serif\",\n  lineHeight: 1.5\n};\nvar explainer4 = {\n  display: \"flex\",\n  flex: 1,\n  flexDirection: \"column\",\n  padding: \"0 12px\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  textAlign: \"center\",\n  background: BACKGROUND\n};\nvar renderQueue = {\n  background: BACKGROUND,\n  flex: 1,\n  overflowY: \"auto\"\n};\nvar RenderQueue = () => {\n  const connectionStatus = useContext44(StudioServerConnectionCtx).previewServerState.type;\n  const { jobs } = useContext44(RenderQueueContext);\n  const { canvasContent } = useContext44(Internals34.CompositionManager);\n  const previousJobCount = React104.useRef(jobs.length);\n  const jobCount = jobs.length;\n  const divRef = React104.useRef(null);\n  useEffect49(() => {\n    if (!divRef.current) {\n      return;\n    }\n    if (jobCount > previousJobCount.current) {\n      divRef.current.scrollTo({\n        top: divRef.current.scrollHeight,\n        behavior: \"smooth\"\n      });\n    }\n    previousJobCount.current = jobCount;\n  }, [jobCount]);\n  const selectedJob = useMemo87(() => {\n    if (!canvasContent) {\n      return -1;\n    }\n    if (canvasContent.type === \"output-blob\") {\n      for (let i = 0;i < jobs.length; i++) {\n        const job = jobs[i];\n        if (isClientRenderJob(job) && job.status === \"done\") {\n          if (canvasContent.getBlob === job.getBlob) {\n            return i;\n          }\n        }\n      }\n      return -1;\n    }\n    if (canvasContent.type === \"output\") {\n      for (let i = 0;i < jobs.length; i++) {\n        const job = jobs[i];\n        if (!isClientRenderJob(job) && job.status === \"done\" && canvasContent.path === `/${job.outName}`) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }, [canvasContent, jobs]);\n  if (connectionStatus === \"disconnected\") {\n    return /* @__PURE__ */ jsxs74(\"div\", {\n      style: explainer4,\n      children: [\n        /* @__PURE__ */ jsx155(Spacing, {\n          y: 5\n        }),\n        /* @__PURE__ */ jsx155(\"div\", {\n          style: errorExplanation3,\n          children: \"The studio server has disconnected.\"\n        }),\n        /* @__PURE__ */ jsx155(Spacing, {\n          y: 2,\n          block: true\n        })\n      ]\n    });\n  }\n  if (jobCount === 0) {\n    return /* @__PURE__ */ jsxs74(\"div\", {\n      style: explainer4,\n      children: [\n        /* @__PURE__ */ jsx155(Spacing, {\n          y: 5\n        }),\n        /* @__PURE__ */ jsx155(\"div\", {\n          style: errorExplanation3,\n          children: \"No renders in the queue.\"\n        }),\n        /* @__PURE__ */ jsx155(Spacing, {\n          y: 2,\n          block: true\n        })\n      ]\n    });\n  }\n  return /* @__PURE__ */ jsx155(\"div\", {\n    ref: divRef,\n    style: renderQueue,\n    className: [\"css-reset\", VERTICAL_SCROLLBAR_CLASSNAME].join(\" \"),\n    children: jobs.map((j, index) => {\n      return /* @__PURE__ */ jsx155(\"div\", {\n        style: index === jobs.length - 1 ? undefined : separatorStyle,\n        children: /* @__PURE__ */ jsx155(RenderQueueItem, {\n          selected: selectedJob === index,\n          job: j\n        })\n      }, j.id);\n    })\n  });\n};\n\n// src/components/RendersTab.tsx\nimport { useContext as useContext45, useMemo as useMemo88 } from \"react\";\nimport { Internals as Internals35 } from \"remotion\";\nimport { jsx as jsx156, jsxs as jsxs75, Fragment as Fragment20 } from \"react/jsx-runtime\";\nvar row3 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  fontSize: 14,\n  color: \"inherit\",\n  alignItems: \"center\",\n  flex: 1\n};\nvar badge = {\n  height: 16,\n  width: 16,\n  borderRadius: 3,\n  fontSize: 10,\n  display: \"inline-flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\"\n};\nvar RendersTab = ({ selected, onClick }) => {\n  const { jobs } = useContext45(RenderQueueContext);\n  const { canvasContent } = useContext45(Internals35.CompositionManager);\n  const failedJobs = jobs.filter((j) => j.status === \"failed\").length;\n  const jobCount = jobs.length;\n  const isActuallySelected = useMemo88(() => {\n    if (!canvasContent || canvasContent.type !== \"composition\") {\n      return true;\n    }\n    return selected;\n  }, [canvasContent, selected]);\n  const badgeStyle = useMemo88(() => {\n    return {\n      ...badge,\n      backgroundColor: failedJobs > 0 ? FAIL_COLOR : \"transparent\",\n      color: failedJobs > 0 ? \"white\" : LIGHT_TEXT,\n      borderWidth: failedJobs > 0 ? 0 : 1,\n      borderStyle: \"solid\",\n      borderColor: LIGHT_TEXT\n    };\n  }, [failedJobs]);\n  return /* @__PURE__ */ jsx156(Tab, {\n    selected: isActuallySelected,\n    onClick,\n    children: /* @__PURE__ */ jsxs75(\"div\", {\n      style: row3,\n      children: [\n        \"Renders\",\n        jobCount > 0 ? /* @__PURE__ */ jsxs75(Fragment20, {\n          children: [\n            /* @__PURE__ */ jsx156(Flex, {}),\n            /* @__PURE__ */ jsx156(\"div\", {\n              style: badgeStyle,\n              children: jobCount\n            })\n          ]\n        }) : null\n      ]\n    })\n  });\n};\n\n// src/components/VisualControls/VisualControlsContent.tsx\nimport React107, { useContext as useContext47 } from \"react\";\n\n// src/components/VisualControls/VisualControlHandle.tsx\nimport { useCallback as useCallback80, useContext as useContext46, useEffect as useEffect51, useState as useState55 } from \"react\";\nimport { Internals as Internals36 } from \"remotion\";\nimport { NoReactInternals as NoReactInternals12 } from \"remotion/no-react\";\n\n// src/components/VisualControls/ClickableFileName.tsx\nimport { useCallback as useCallback79, useMemo as useMemo89, useState as useState53 } from \"react\";\n\n// src/components/Timeline/TimelineStack/source-attribution.ts\nvar getOriginalSourceAttribution = (originalLocation) => {\n  if (!originalLocation.source) {\n    return \"\";\n  }\n  const split = originalLocation.source.split(\"/\");\n  const last = split[split.length - 1];\n  if (last.startsWith(\"index\")) {\n    const lastTwo = split[split.length - 2];\n    return `${lastTwo}/${last}:${originalLocation.line}`;\n  }\n  return `${last}:${originalLocation.line}`;\n};\n\n// src/components/VisualControls/ClickableFileName.tsx\nimport { jsx as jsx157 } from \"react/jsx-runtime\";\nvar container32 = {\n  paddingLeft: SCHEMA_EDITOR_FIELDSET_PADDING,\n  paddingTop: SCHEMA_EDITOR_FIELDSET_PADDING / 2\n};\nvar ClickableFileName = ({\n  originalFileName\n}) => {\n  const [titleHovered, setTitleHovered] = useState53(false);\n  const hoverEffect = titleHovered && originalFileName.type === \"loaded\";\n  const onTitlePointerEnter = useCallback79(() => {\n    setTitleHovered(true);\n  }, []);\n  const onTitlePointerLeave = useCallback79(() => {\n    setTitleHovered(false);\n  }, []);\n  const style9 = useMemo89(() => {\n    return {\n      fontSize: 12,\n      cursor: originalFileName.type === \"loaded\" ? \"pointer\" : undefined,\n      borderBottom: hoverEffect ? \"1px solid #fff\" : \"none\",\n      color: hoverEffect ? \"#fff\" : LIGHT_COLOR\n    };\n  }, [originalFileName, hoverEffect]);\n  const onClick = useCallback79(async () => {\n    if (originalFileName.type !== \"loaded\") {\n      return;\n    }\n    await openOriginalPositionInEditor(originalFileName.originalFileName);\n  }, [originalFileName]);\n  return /* @__PURE__ */ jsx157(\"div\", {\n    style: container32,\n    children: /* @__PURE__ */ jsx157(\"span\", {\n      style: style9,\n      onClick,\n      onPointerEnter: onTitlePointerEnter,\n      onPointerLeave: onTitlePointerLeave,\n      children: originalFileName.type === \"loaded\" ? getOriginalSourceAttribution(originalFileName.originalFileName) : originalFileName.type === \"loading\" ? \"Loading...\" : \"Error loading\"\n    })\n  });\n};\n\n// src/components/VisualControls/VisualControlHandleHeader.tsx\nimport { jsx as jsx158 } from \"react/jsx-runtime\";\nvar VisualControlHandleHeader = ({ originalFileName }) => {\n  return /* @__PURE__ */ jsx158(ClickableFileName, {\n    originalFileName\n  });\n};\n\n// src/components/VisualControls/get-original-stack-trace.ts\nimport { useEffect as useEffect50, useState as useState54 } from \"react\";\n\n// src/components/Timeline/TimelineStack/get-stack.ts\nimport { SourceMapConsumer as SourceMapConsumer2 } from \"source-map\";\n\n// src/helpers/get-location-of-sequence.ts\nvar getLocationOfSequence = (stack2) => {\n  if (!stack2) {\n    return null;\n  }\n  const parsed = parseStack(stack2.split(`\n`));\n  let i = 0;\n  while (i < parsed.length) {\n    const frame2 = parsed[i];\n    if (frame2.functionName === \"apply\") {\n      i++;\n      continue;\n    }\n    return frame2;\n  }\n  return null;\n};\nvar getLocationOfFunctionCall = (stack2, functionName) => {\n  if (!stack2) {\n    return null;\n  }\n  const parsed = parseStack(stack2.split(`\n`));\n  let i = 0;\n  while (i < parsed.length) {\n    const frame2 = parsed[i];\n    if (frame2.functionName !== functionName) {\n      i++;\n      continue;\n    }\n    return parsed[i + 1];\n  }\n  return null;\n};\n\n// src/components/Timeline/TimelineStack/get-stack.ts\nvar waiters = [];\nvar sourceMapConsumerCache = {};\nvar isCreating = {};\nvar getSourceMapCache = async (fileName) => {\n  if (sourceMapConsumerCache[fileName]) {\n    return sourceMapConsumerCache[fileName];\n  }\n  if (isCreating[fileName]) {\n    return new Promise((resolve) => {\n      waiters.push({\n        id: String(Math.random()),\n        forFileName: fileName,\n        resolve\n      });\n    });\n  }\n  isCreating[fileName] = true;\n  const res = await fetch(`${fileName}.map`);\n  const json = await res.json();\n  const map = await new Promise((resolve) => {\n    SourceMapConsumer2.with(json, null, (consumer) => {\n      resolve(consumer);\n    });\n  });\n  waiters.filter((w) => {\n    if (w.forFileName === fileName) {\n      w.resolve(map);\n      return false;\n    }\n    return true;\n  });\n  sourceMapConsumerCache[fileName] = map;\n  isCreating[fileName] = false;\n  return map;\n};\nvar getOriginalLocationFromStack = async (stack2, type) => {\n  const location2 = type === \"sequence\" ? getLocationOfSequence(stack2) : getLocationOfFunctionCall(stack2, \"visualControl\");\n  if (!location2) {\n    return null;\n  }\n  const map = await getSourceMapCache(location2.fileName);\n  const originalPosition = getOriginalPosition(map, location2.lineNumber, location2.columnNumber);\n  return originalPosition;\n};\n\n// src/components/VisualControls/get-original-stack-trace.ts\nvar useOriginalFileName = (stack2) => {\n  const [originalFileName, setOriginalFileName] = useState54({ type: \"loading\" });\n  useEffect50(() => {\n    if (!stack2) {\n      return;\n    }\n    getOriginalLocationFromStack(stack2, \"visual-control\").then((frame2) => {\n      if (frame2 === null) {\n        setOriginalFileName({\n          type: \"error\",\n          error: new Error(\"No frame found\")\n        });\n      } else {\n        setOriginalFileName({ type: \"loaded\", originalFileName: frame2 });\n      }\n    }).catch((err) => {\n      console.error(\"Could not get original location of Sequence\", err);\n    });\n  }, [stack2]);\n  return originalFileName;\n};\n\n// src/components/VisualControls/VisualControlHandle.tsx\nimport { jsx as jsx159, jsxs as jsxs76, Fragment as Fragment21 } from \"react/jsx-runtime\";\nvar VisualControlHandle = ({ value, keyName }) => {\n  const z = useZodIfPossible();\n  if (!z) {\n    throw new Error(\"expected zod\");\n  }\n  const zodTypes = useZodTypesIfPossible();\n  const state = useContext46(VisualControlsContext);\n  const { updateValue } = useContext46(SetVisualControlsContext);\n  const { fastRefreshes } = useContext46(Internals36.NonceContext);\n  const { increaseManualRefreshes } = useContext46(Internals36.SetNonceContext);\n  const [saving, setSaving] = useState55(false);\n  const currentValue = getVisualControlEditedValue({\n    handles: state.handles,\n    key: keyName\n  });\n  const originalFileName = useOriginalFileName(value.stack);\n  const { localValue, RevisionContextProvider, onChange } = useLocalState({\n    schema: value.schema,\n    setValue: (updater) => {\n      updateValue(keyName, updater(currentValue));\n      increaseManualRefreshes();\n    },\n    unsavedValue: currentValue,\n    savedValue: value.valueInCode\n  });\n  const disableSave = window.remotion_isReadOnlyStudio || originalFileName.type !== \"loaded\";\n  const onSave = useCallback80((updater) => {\n    if (disableSave) {\n      return;\n    }\n    if (originalFileName.type !== \"loaded\") {\n      throw new Error(\"Original file name is not loaded\");\n    }\n    const val = updater(value.valueInCode);\n    window.remotion_ignoreFastRefreshUpdate = fastRefreshes + 1;\n    const enumPaths = extractEnumJsonPaths({\n      schema: value.schema,\n      zodRuntime: z,\n      currentPath: [],\n      zodTypes\n    });\n    setSaving(true);\n    Promise.resolve().then(() => {\n      return applyVisualControlChange({\n        fileName: originalFileName.originalFileName.source,\n        changes: [\n          {\n            id: keyName,\n            newValueSerialized: NoReactInternals12.serializeJSONWithSpecialTypes({\n              data: val,\n              indent: 2,\n              staticBase: window.remotion_staticBase\n            }).serializedString,\n            enumPaths\n          }\n        ]\n      });\n    }).catch((e) => {\n      showNotification(`Could not save visual control: ${e.message}`, 3000);\n    });\n  }, [\n    disableSave,\n    value.valueInCode,\n    value.schema,\n    fastRefreshes,\n    z,\n    originalFileName,\n    keyName,\n    zodTypes\n  ]);\n  useEffect51(() => {\n    setSaving(false);\n  }, [fastRefreshes]);\n  return /* @__PURE__ */ jsxs76(Fragment21, {\n    children: [\n      /* @__PURE__ */ jsx159(VisualControlHandleHeader, {\n        originalFileName\n      }),\n      /* @__PURE__ */ jsx159(Spacing, {\n        block: true,\n        y: 0.5\n      }),\n      /* @__PURE__ */ jsx159(RevisionContextProvider, {\n        children: /* @__PURE__ */ jsx159(ZodSwitch, {\n          mayPad: true,\n          schema: value.schema,\n          showSaveButton: !disableSave,\n          saving,\n          saveDisabledByParent: false,\n          onSave,\n          jsonPath: [keyName],\n          value: localValue.value,\n          defaultValue: value.valueInCode,\n          setValue: onChange,\n          onRemove: null\n        })\n      })\n    ]\n  });\n};\n\n// src/components/VisualControls/VisualControlsContent.tsx\nimport { jsx as jsx160, jsxs as jsxs77 } from \"react/jsx-runtime\";\nvar container33 = {\n  overflowY: \"auto\"\n};\nvar VisualControlsContent = () => {\n  const { handles } = useContext47(VisualControlsContext);\n  const entries = Object.entries(handles);\n  return /* @__PURE__ */ jsx160(\"div\", {\n    style: container33,\n    className: VERTICAL_SCROLLBAR_CLASSNAME,\n    children: entries.map(([key, value], i) => {\n      return /* @__PURE__ */ jsxs77(React107.Fragment, {\n        children: [\n          /* @__PURE__ */ jsx160(VisualControlHandle, {\n            keyName: key,\n            value\n          }),\n          i === entries.length - 1 ? null : /* @__PURE__ */ jsx160(SchemaSeparationLine, {})\n        ]\n      }, key);\n    })\n  });\n};\n\n// src/components/OptionsPanel.tsx\nimport { jsx as jsx161, jsxs as jsxs78 } from \"react/jsx-runtime\";\nvar localStorageKey3 = \"remotion.sidebarPanel\";\nvar getSelectedPanel2 = (readOnlyStudio) => {\n  if (readOnlyStudio) {\n    return \"input-props\";\n  }\n  const panel2 = localStorage.getItem(localStorageKey3);\n  if (panel2 === \"renders\") {\n    return \"renders\";\n  }\n  if (panel2 === \"visual-controls\") {\n    return \"visual-controls\";\n  }\n  return \"input-props\";\n};\nvar tabsContainer3 = {\n  backgroundColor: BACKGROUND\n};\nvar persistSelectedOptionsSidebarPanel2 = (panel2) => {\n  localStorage.setItem(localStorageKey3, panel2);\n};\nvar optionsSidebarTabs = createRef9();\nvar OptionsPanel = ({ readOnlyStudio }) => {\n  const { props, updateProps, resetUnsaved } = useContext48(Internals37.EditorPropsContext);\n  const [saving, setSaving] = useState56(false);\n  const isMobileLayout = useMobileLayout();\n  const visualControlsTabActivated = useContext48(VisualControlsTabActivatedContext);\n  const container34 = useMemo90(() => ({\n    height: \"100%\",\n    width: \"100%\",\n    display: \"flex\",\n    position: isMobileLayout ? \"relative\" : \"absolute\",\n    flexDirection: \"column\",\n    flex: 1\n  }), [isMobileLayout]);\n  const [panel2, setPanel] = useState56(() => getSelectedPanel2(readOnlyStudio));\n  const onPropsSelected = useCallback81(() => {\n    setPanel(\"input-props\");\n    persistSelectedOptionsSidebarPanel2(\"input-props\");\n  }, []);\n  const onRendersSelected = useCallback81(() => {\n    setPanel(\"renders\");\n    persistSelectedOptionsSidebarPanel2(\"renders\");\n  }, []);\n  const onVisualControlsSelected = useCallback81(() => {\n    setPanel(\"visual-controls\");\n    persistSelectedOptionsSidebarPanel2(\"visual-controls\");\n  }, []);\n  useImperativeHandle12(optionsSidebarTabs, () => {\n    return {\n      selectRendersPanel: () => {\n        setPanel(\"renders\");\n        persistSelectedOptionsSidebarPanel2(\"renders\");\n      }\n    };\n  }, []);\n  const { compositions, canvasContent } = useContext48(Internals37.CompositionManager);\n  const composition = useMemo90(() => {\n    if (canvasContent === null || canvasContent.type !== \"composition\") {\n      return null;\n    }\n    for (const comp of compositions) {\n      if (comp.id === canvasContent.compositionId) {\n        return comp;\n      }\n    }\n    return null;\n  }, [canvasContent, compositions]);\n  const setDefaultProps = useCallback81((newProps) => {\n    if (composition === null) {\n      return;\n    }\n    window.remotion_ignoreFastRefreshUpdate = null;\n    updateProps({\n      id: composition.id,\n      defaultProps: composition.defaultProps,\n      newProps\n    });\n  }, [composition, updateProps]);\n  const currentDefaultProps = useMemo90(() => {\n    if (composition === null) {\n      return {};\n    }\n    return props[composition.id] ?? composition.defaultProps ?? {};\n  }, [composition, props]);\n  const unsavedChangesExist = useMemo90(() => {\n    if (composition === null || composition.defaultProps === undefined) {\n      return false;\n    }\n    return !deepEqual(composition.defaultProps, currentDefaultProps);\n  }, [currentDefaultProps, composition]);\n  const reset = useCallback81((e) => {\n    if (e.detail.resetUnsaved) {\n      resetUnsaved(e.detail.resetUnsaved);\n    }\n  }, [resetUnsaved]);\n  useEffect52(() => {\n    window.addEventListener(Internals37.PROPS_UPDATED_EXTERNALLY, reset);\n    return () => {\n      window.removeEventListener(Internals37.PROPS_UPDATED_EXTERNALLY, reset);\n    };\n  }, [reset]);\n  return /* @__PURE__ */ jsxs78(\"div\", {\n    style: container34,\n    className: \"css-reset\",\n    children: [\n      /* @__PURE__ */ jsx161(\"div\", {\n        style: tabsContainer3,\n        children: /* @__PURE__ */ jsxs78(Tabs, {\n          children: [\n            visualControlsTabActivated ? /* @__PURE__ */ jsx161(Tab, {\n              selected: panel2 === \"visual-controls\",\n              onClick: onVisualControlsSelected,\n              children: \"Controls\"\n            }) : null,\n            composition ? /* @__PURE__ */ jsxs78(Tab, {\n              selected: panel2 === \"input-props\",\n              onClick: onPropsSelected,\n              style: { justifyContent: \"space-between\" },\n              children: [\n                \"Props\",\n                unsavedChangesExist ? /* @__PURE__ */ jsx161(GlobalPropsEditorUpdateButton, {\n                  compositionId: composition.id,\n                  currentDefaultProps\n                }) : null\n              ]\n            }) : null,\n            readOnlyStudio ? null : /* @__PURE__ */ jsx161(RendersTab, {\n              onClick: onRendersSelected,\n              selected: panel2 === \"renders\"\n            })\n          ]\n        })\n      }),\n      panel2 === `input-props` && composition ? /* @__PURE__ */ jsx161(DataEditor, {\n        unresolvedComposition: composition,\n        defaultProps: currentDefaultProps,\n        setDefaultProps,\n        mayShowSaveButton: true,\n        propsEditType: \"default-props\",\n        saving,\n        setSaving,\n        readOnlyStudio\n      }, composition.id) : panel2 === \"visual-controls\" && visualControlsTabActivated ? /* @__PURE__ */ jsx161(VisualControlsContent, {}) : readOnlyStudio ? null : /* @__PURE__ */ jsx161(RenderQueue, {})\n    ]\n  });\n};\n\n// src/components/PreviewToolbar.tsx\nimport { useContext as useContext55, useEffect as useEffect59, useRef as useRef32, useState as useState60 } from \"react\";\nimport { Internals as Internals45 } from \"remotion\";\n\n// src/helpers/should-show-render-button.ts\nvar shouldShowRenderButton = (readOnlyStudio) => {\n  if (readOnlyStudio) {\n    return SHOW_BROWSER_RENDERING;\n  }\n  return true;\n};\n\n// src/state/loop.ts\nvar key = \"remotion.loop\";\nvar persistLoopOption = (option) => {\n  localStorage.setItem(key, String(option));\n};\nvar loadLoopOption = () => {\n  const item2 = localStorage.getItem(key);\n  return item2 !== \"false\";\n};\n\n// src/components/CheckboardToggle.tsx\nimport { useCallback as useCallback82, useContext as useContext49 } from \"react\";\nimport { NoReactInternals as NoReactInternals13 } from \"remotion/no-react\";\nimport { jsx as jsx162 } from \"react/jsx-runtime\";\nvar accessibilityLabel2 = [\n  \"Show transparency as checkerboard\",\n  areKeyboardShortcutsDisabled() ? null : \"(T)\"\n].filter(NoReactInternals13.truthy).join(\" \");\nvar CheckboardToggle = () => {\n  const { checkerboard, setCheckerboard } = useContext49(CheckerboardContext);\n  const onClick = useCallback82(() => {\n    setCheckerboard((c) => {\n      return !c;\n    });\n  }, [setCheckerboard]);\n  return /* @__PURE__ */ jsx162(ControlButton, {\n    title: accessibilityLabel2,\n    \"aria-label\": accessibilityLabel2,\n    onClick,\n    children: /* @__PURE__ */ jsx162(\"svg\", {\n      \"aria-hidden\": \"true\",\n      focusable: \"false\",\n      \"data-prefix\": \"fas\",\n      \"data-icon\": \"game-board-alt\",\n      className: \"svg-inline--fa fa-game-board-alt fa-w-16\",\n      role: \"img\",\n      xmlns: \"http://www.w3.org/2000/svg\",\n      viewBox: \"0 0 512 512\",\n      style: { width: 16, height: 16 },\n      children: /* @__PURE__ */ jsx162(\"path\", {\n        fill: checkerboard ? BLUE : \"white\",\n        d: \"M480 0H32A32 32 0 0 0 0 32v448a32 32 0 0 0 32 32h448a32 32 0 0 0 32-32V32a32 32 0 0 0-32-32zm-32 256H256v192H64V256h192V64h192z\"\n      })\n    })\n  });\n};\n\n// src/components/FpsCounter.tsx\nimport {\n  useEffect as useEffect53,\n  useLayoutEffect,\n  useMemo as useMemo91,\n  useRef as useRef30,\n  useState as useState57\n} from \"react\";\nimport { Internals as Internals38 } from \"remotion\";\nimport { jsxs as jsxs79 } from \"react/jsx-runtime\";\nvar label6 = {\n  color: \"white\",\n  fontSize: 15,\n  fontFamily: \"Arial, Helvetica, sans-serif\",\n  whiteSpace: \"nowrap\"\n};\nvar pushWithMaxSize = (arr, value, maxSize) => {\n  arr.push(value);\n  return arr.slice(-maxSize);\n};\nvar FpsCounter = ({ playbackSpeed }) => {\n  const videoConfig = Internals38.useUnsafeVideoConfig();\n  const [playing] = Internals38.Timeline.usePlayingState();\n  const frame2 = Internals38.Timeline.useTimelinePosition();\n  const [marker, rerender] = useState57({});\n  const [fps, setFps] = useState57(0);\n  const previousUpdates = useRef30([]);\n  const fpsRef = useRef30(0);\n  const playingRef = useRef30(playing);\n  useLayoutEffect(() => {\n    fpsRef.current = 0;\n    previousUpdates.current = [];\n    playingRef.current = playing;\n  }, [playing]);\n  useLayoutEffect(() => {\n    if (playingRef.current === false)\n      return;\n    previousUpdates.current = pushWithMaxSize(previousUpdates.current, performance.now(), 15);\n    if (previousUpdates.current.length < 2)\n      return;\n    const diff = Math.max(...previousUpdates.current) - Math.min(...previousUpdates.current);\n    const averageDistanceBetween = diff / (previousUpdates.current.length - 1);\n    fpsRef.current = 1000 / averageDistanceBetween;\n    if (previousUpdates.current.length === 2)\n      setFps(fpsRef.current);\n  }, [frame2]);\n  useEffect53(() => {\n    if (playing) {\n      const t = setTimeout(() => {\n        rerender({});\n        setFps(fpsRef.current);\n      }, 1000);\n      return () => clearTimeout(t);\n    }\n  }, [marker, playing]);\n  const style9 = useMemo91(() => {\n    if (!videoConfig) {\n      return {};\n    }\n    const expectedFps = Math.abs(playbackSpeed) * videoConfig.fps;\n    return {\n      ...label6,\n      color: fps < expectedFps * 0.9 ? \"red\" : \"white\"\n    };\n  }, [fps, playbackSpeed, videoConfig]);\n  if (fps === 0) {\n    return null;\n  }\n  if (playing === false) {\n    return null;\n  }\n  if (videoConfig === null) {\n    return null;\n  }\n  return /* @__PURE__ */ jsxs79(\"div\", {\n    style: style9,\n    children: [\n      fps.toFixed(1),\n      \" FPS\"\n    ]\n  });\n};\n\n// src/components/FullscreenToggle.tsx\nimport { useCallback as useCallback83, useContext as useContext50, useEffect as useEffect54 } from \"react\";\nimport { Internals as Internals39 } from \"remotion\";\nimport { NoReactInternals as NoReactInternals14 } from \"remotion/no-react\";\nimport { jsx as jsx163 } from \"react/jsx-runtime\";\nvar accessibilityLabel3 = [\n  \"Enter fullscreen preview\",\n  areKeyboardShortcutsDisabled() ? null : \"(F)\"\n].filter(NoReactInternals14.truthy).join(\" \");\nvar FullScreenToggle = () => {\n  const keybindings = useKeybinding();\n  const { setSize } = useContext50(Internals39.PreviewSizeContext);\n  const onClick = useCallback83(() => {\n    drawRef.current?.requestFullscreen();\n    if (document.fullscreenElement)\n      setSize(() => ({\n        size: \"auto\",\n        translation: {\n          x: 0,\n          y: 0\n        }\n      }));\n  }, [setSize]);\n  useEffect54(() => {\n    const f = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"f\",\n      callback: onClick,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      f.unregister();\n    };\n  }, [keybindings, onClick]);\n  return /* @__PURE__ */ jsx163(ControlButton, {\n    title: accessibilityLabel3,\n    \"aria-label\": accessibilityLabel3,\n    onClick,\n    children: /* @__PURE__ */ jsx163(\"svg\", {\n      style: { width: 18, height: 18 },\n      viewBox: \"0 0 448 512\",\n      fill: \"#fff\",\n      children: /* @__PURE__ */ jsx163(\"path\", {\n        d: \"M0 180V56c0-13.3 10.7-24 24-24h124c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12H64v84c0 6.6-5.4 12-12 12H12c-6.6 0-12-5.4-12-12zM288 44v40c0 6.6 5.4 12 12 12h84v84c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12V56c0-13.3-10.7-24-24-24H300c-6.6 0-12 5.4-12 12zm148 276h-40c-6.6 0-12 5.4-12 12v84h-84c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h124c13.3 0 24-10.7 24-24V332c0-6.6-5.4-12-12-12zM160 468v-40c0-6.6-5.4-12-12-12H64v-84c0-6.6-5.4-12-12-12H12c-6.6 0-12 5.4-12 12v124c0 13.3 10.7 24 24 24h124c6.6 0 12-5.4 12-12z\"\n      })\n    })\n  });\n};\n\n// src/components/LoopToggle.tsx\nimport { useCallback as useCallback84 } from \"react\";\nimport { jsx as jsx164 } from \"react/jsx-runtime\";\nvar accessibilityLabel4 = \"Loop video\";\nvar LoopToggle = ({ loop, setLoop }) => {\n  const onClick = useCallback84(() => {\n    setLoop((c) => {\n      persistLoopOption(!c);\n      return !c;\n    });\n  }, [setLoop]);\n  return /* @__PURE__ */ jsx164(ControlButton, {\n    title: accessibilityLabel4,\n    \"aria-label\": accessibilityLabel4,\n    onClick,\n    children: /* @__PURE__ */ jsx164(\"svg\", {\n      viewBox: \"0 0 512 512\",\n      style: { width: 18, height: 18 },\n      children: /* @__PURE__ */ jsx164(\"path\", {\n        fill: loop ? BLUE : \"white\",\n        d: \"M493.544 181.463c11.956 22.605 18.655 48.4 18.452 75.75C511.339 345.365 438.56 416 350.404 416H192v47.495c0 22.475-26.177 32.268-40.971 17.475l-80-80c-9.372-9.373-9.372-24.569 0-33.941l80-80C166.138 271.92 192 282.686 192 304v48h158.875c52.812 0 96.575-42.182 97.12-94.992.155-15.045-3.17-29.312-9.218-42.046-4.362-9.185-2.421-20.124 4.8-27.284 4.745-4.706 8.641-8.555 11.876-11.786 11.368-11.352 30.579-8.631 38.091 5.571zM64.005 254.992c.545-52.81 44.308-94.992 97.12-94.992H320v47.505c0 22.374 26.121 32.312 40.971 17.465l80-80c9.372-9.373 9.372-24.569 0-33.941l-80-80C346.014 16.077 320 26.256 320 48.545V96H161.596C73.44 96 .661 166.635.005 254.788c-.204 27.35 6.495 53.145 18.452 75.75 7.512 14.202 26.723 16.923 38.091 5.57 3.235-3.231 7.13-7.08 11.876-11.786 7.22-7.16 9.162-18.098 4.8-27.284-6.049-12.735-9.374-27.001-9.219-42.046z\"\n      })\n    })\n  });\n};\n\n// src/components/MuteToggle.tsx\nimport { useCallback as useCallback85 } from \"react\";\n\n// src/icons/media-volume.tsx\nimport { jsx as jsx165 } from \"react/jsx-runtime\";\nvar size3 = 22;\nvar VolumeOffIcon = () => {\n  return /* @__PURE__ */ jsx165(\"svg\", {\n    width: size3,\n    height: size3,\n    viewBox: \"0 0 24 24\",\n    children: /* @__PURE__ */ jsx165(\"path\", {\n      d: \"M3.63 3.63a.996.996 0 000 1.41L7.29 8.7 7 9H4c-.55 0-1 .45-1 1v4c0 .55.45 1 1 1h3l3.29 3.29c.63.63 1.71.18 1.71-.71v-4.17l4.18 4.18c-.49.37-1.02.68-1.6.91-.36.15-.58.53-.58.92 0 .72.73 1.18 1.39.91.8-.33 1.55-.77 2.22-1.31l1.34 1.34a.996.996 0 101.41-1.41L5.05 3.63c-.39-.39-1.02-.39-1.42 0zM19 12c0 .82-.15 1.61-.41 2.34l1.53 1.53c.56-1.17.88-2.48.88-3.87 0-3.83-2.4-7.11-5.78-8.4-.59-.23-1.22.23-1.22.86v.19c0 .38.25.71.61.85C17.18 6.54 19 9.06 19 12zm-8.71-6.29l-.17.17L12 7.76V6.41c0-.89-1.08-1.33-1.71-.7zM16.5 12A4.5 4.5 0 0014 7.97v1.79l2.48 2.48c.01-.08.02-.16.02-.24z\",\n      fill: BLUE\n    })\n  });\n};\nvar VolumeOnIcon = () => {\n  return /* @__PURE__ */ jsx165(\"svg\", {\n    width: size3,\n    height: size3,\n    viewBox: \"0 0 24 24\",\n    children: /* @__PURE__ */ jsx165(\"path\", {\n      d: \"M3 10v4c0 .55.45 1 1 1h3l3.29 3.29c.63.63 1.71.18 1.71-.71V6.41c0-.89-1.08-1.34-1.71-.71L7 9H4c-.55 0-1 .45-1 1zm13.5 2A4.5 4.5 0 0014 7.97v8.05c1.48-.73 2.5-2.25 2.5-4.02zM14 4.45v.2c0 .38.25.71.6.85C17.18 6.53 19 9.06 19 12s-1.82 5.47-4.4 6.5c-.36.14-.6.47-.6.85v.2c0 .63.63 1.07 1.21.85C18.6 19.11 21 15.84 21 12s-2.4-7.11-5.79-8.4c-.58-.23-1.21.22-1.21.85z\",\n      fill: \"#fff\"\n    })\n  });\n};\n\n// src/state/mute.ts\nvar key2 = \"remotion.mute\";\nvar persistMuteOption = (option) => {\n  localStorage.setItem(key2, String(option));\n};\nvar loadMuteOption = () => {\n  const item2 = localStorage.getItem(key2);\n  return item2 === \"true\";\n};\n\n// src/components/MuteToggle.tsx\nimport { jsx as jsx166 } from \"react/jsx-runtime\";\nvar MuteToggle = ({ muted, setMuted }) => {\n  const onClick = useCallback85(() => {\n    setMuted((m) => {\n      persistMuteOption(!m);\n      return !m;\n    });\n  }, [setMuted]);\n  const accessibilityLabel5 = muted ? \"Unmute video\" : \"Mute video\";\n  return /* @__PURE__ */ jsx166(ControlButton, {\n    title: accessibilityLabel5,\n    \"aria-label\": accessibilityLabel5,\n    onClick,\n    children: muted ? /* @__PURE__ */ jsx166(VolumeOffIcon, {}) : /* @__PURE__ */ jsx166(VolumeOnIcon, {})\n  });\n};\n\n// src/components/PlayPause.tsx\nimport { PlayerInternals as PlayerInternals12 } from \"@remotion/player\";\nimport { useCallback as useCallback86, useEffect as useEffect55, useState as useState58 } from \"react\";\nimport { Internals as Internals40 } from \"remotion\";\n\n// src/icons/jump-to-start.tsx\nimport { jsx as jsx167 } from \"react/jsx-runtime\";\nvar JumpToStart = (props) => {\n  return /* @__PURE__ */ jsx167(\"svg\", {\n    xmlns: \"http://www.w3.org/2000/svg\",\n    viewBox: \"0 0 512 512\",\n    ...props,\n    children: /* @__PURE__ */ jsx167(\"path\", {\n      fill: \"currentColor\",\n      d: \"M0 415.1V96.03c0-17.67 14.33-31.1 31.1-31.1C49.67 64.03 64 78.36 64 96.03v131.8l171.5-156.5C256.1 54.28 288 68.66 288 96.03v131.9l171.5-156.5C480.1 54.28 512 68.66 512 96.03v319.9c0 27.37-31.88 41.74-52.5 24.62L288 285.2v130.7c0 27.37-31.88 41.74-52.5 24.62L64 285.2v130.7c0 17.67-14.33 31.1-31.1 31.1C14.33 447.1 0 433.6 0 415.1z\"\n    })\n  });\n};\n\n// src/icons/pause.tsx\nimport { jsx as jsx168 } from \"react/jsx-runtime\";\nvar Pause = (props) => /* @__PURE__ */ jsx168(\"svg\", {\n  ...props,\n  \"aria-hidden\": \"true\",\n  focusable: \"false\",\n  \"data-prefix\": \"fas\",\n  \"data-icon\": \"pause\",\n  className: \"svg-inline--fa fa-pause fa-w-14\",\n  role: \"img\",\n  xmlns: \"http://www.w3.org/2000/svg\",\n  viewBox: \"0 0 448 512\",\n  children: /* @__PURE__ */ jsx168(\"path\", {\n    fill: \"currentColor\",\n    d: \"M144 479H48c-26.5 0-48-21.5-48-48V79c0-26.5 21.5-48 48-48h96c26.5 0 48 21.5 48 48v352c0 26.5-21.5 48-48 48zm304-48V79c0-26.5-21.5-48-48-48h-96c-26.5 0-48 21.5-48 48v352c0 26.5 21.5 48 48 48h96c26.5 0 48-21.5 48-48z\"\n  })\n});\n\n// src/icons/play.tsx\nimport { jsx as jsx169 } from \"react/jsx-runtime\";\nvar Play = (props) => /* @__PURE__ */ jsx169(\"svg\", {\n  ...props,\n  \"aria-hidden\": \"true\",\n  focusable: \"false\",\n  \"data-prefix\": \"fas\",\n  \"data-icon\": \"play\",\n  className: \"svg-inline--fa fa-play fa-w-14\",\n  role: \"img\",\n  xmlns: \"http://www.w3.org/2000/svg\",\n  viewBox: \"0 0 448 512\",\n  children: /* @__PURE__ */ jsx169(\"path\", {\n    fill: \"currentColor\",\n    d: \"M424.4 214.7L72.4 6.6C43.8-10.3 0 6.1 0 47.9V464c0 37.5 40.7 60.1 72.4 41.3l352-208c31.4-18.5 31.5-64.1 0-82.6z\"\n  })\n});\n\n// src/icons/step-back.tsx\nimport { jsx as jsx170 } from \"react/jsx-runtime\";\nvar StepBack = (props) => {\n  return /* @__PURE__ */ jsx170(\"svg\", {\n    viewBox: \"0 0 448 512\",\n    ...props,\n    children: /* @__PURE__ */ jsx170(\"path\", {\n      fill: \"currentColor\",\n      d: \"M64 468V44c0-6.6 5.4-12 12-12h48c6.6 0 12 5.4 12 12v176.4l195.5-181C352.1 22.3 384 36.6 384 64v384c0 27.4-31.9 41.7-52.5 24.6L136 292.7V468c0 6.6-5.4 12-12 12H76c-6.6 0-12-5.4-12-12z\"\n    })\n  });\n};\n\n// src/icons/step-forward.tsx\nimport { jsx as jsx171 } from \"react/jsx-runtime\";\nvar StepForward = (props) => {\n  return /* @__PURE__ */ jsx171(\"svg\", {\n    viewBox: \"0 0 448 512\",\n    ...props,\n    children: /* @__PURE__ */ jsx171(\"path\", {\n      fill: \"currentColor\",\n      d: \"M384 44v424c0 6.6-5.4 12-12 12h-48c-6.6 0-12-5.4-12-12V291.6l-195.5 181C95.9 489.7 64 475.4 64 448V64c0-27.4 31.9-41.7 52.5-24.6L312 219.3V44c0-6.6 5.4-12 12-12h48c6.6 0 12 5.4 12 12z\"\n    })\n  });\n};\n\n// src/components/PlayPause.tsx\nimport { jsx as jsx172, jsxs as jsxs80, Fragment as Fragment22 } from \"react/jsx-runtime\";\nvar backStyle = {\n  height: 18,\n  color: \"white\"\n};\nvar forwardBackStyle = {\n  height: 16,\n  color: \"white\"\n};\nvar iconButton = {\n  height: 14,\n  width: 14,\n  color: \"white\"\n};\nvar PlayPause = ({ playbackRate, loop, bufferStateDelayInMilliseconds }) => {\n  const { inFrame, outFrame } = useTimelineInOutFramePosition();\n  const videoConfig = Internals40.useUnsafeVideoConfig();\n  const [showBufferIndicator, setShowBufferState] = useState58(false);\n  const {\n    playing,\n    play,\n    pause,\n    pauseAndReturnToPlayStart,\n    frameBack,\n    seek,\n    frameForward,\n    isLastFrame,\n    isFirstFrame,\n    emitter,\n    getCurrentFrame: getCurrentFrame2\n  } = PlayerInternals12.usePlayer();\n  PlayerInternals12.usePlayback({\n    loop,\n    playbackRate,\n    moveToBeginningWhenEnded: true,\n    inFrame,\n    outFrame,\n    getCurrentFrame: getCurrentFrame2,\n    browserMediaControlsBehavior: {\n      mode: \"register-media-session\"\n    }\n  });\n  const isStill = useIsStill();\n  useEffect55(() => {\n    if (isStill) {\n      pause();\n    }\n  }, [isStill, pause]);\n  const onSpace = useCallback86((e) => {\n    if (playing) {\n      pause();\n    } else {\n      play();\n    }\n    e.preventDefault();\n  }, [pause, play, playing]);\n  const onEnter = useCallback86((e) => {\n    if (playing) {\n      e.preventDefault();\n      pauseAndReturnToPlayStart();\n    }\n  }, [pauseAndReturnToPlayStart, playing]);\n  const onArrowLeft = useCallback86((e) => {\n    e.preventDefault();\n    if (e.altKey) {\n      seek(0);\n      ensureFrameIsInViewport({\n        direction: \"fit-left\",\n        durationInFrames: getCurrentDuration(),\n        frame: 0\n      });\n    } else if (e.shiftKey) {\n      frameBack(getCurrentFps());\n      ensureFrameIsInViewport({\n        direction: \"fit-left\",\n        durationInFrames: getCurrentDuration(),\n        frame: Math.max(0, getCurrentFrame2() - getCurrentFps())\n      });\n    } else {\n      frameBack(1);\n      ensureFrameIsInViewport({\n        direction: \"fit-left\",\n        durationInFrames: getCurrentDuration(),\n        frame: Math.max(0, getCurrentFrame2() - 1)\n      });\n    }\n  }, [frameBack, seek, getCurrentFrame2]);\n  const onArrowRight = useCallback86((e) => {\n    if (e.altKey) {\n      seek(getCurrentDuration() - 1);\n      ensureFrameIsInViewport({\n        direction: \"fit-right\",\n        durationInFrames: getCurrentDuration() - 1,\n        frame: getCurrentDuration() - 1\n      });\n    } else if (e.shiftKey) {\n      frameForward(getCurrentFps());\n      ensureFrameIsInViewport({\n        direction: \"fit-right\",\n        durationInFrames: getCurrentDuration(),\n        frame: Math.min(getCurrentDuration() - 1, getCurrentFrame2() + getCurrentFps())\n      });\n    } else {\n      frameForward(1);\n      ensureFrameIsInViewport({\n        direction: \"fit-right\",\n        durationInFrames: getCurrentDuration(),\n        frame: Math.min(getCurrentDuration() - 1, getCurrentFrame2() + 1)\n      });\n    }\n    e.preventDefault();\n  }, [frameForward, seek, getCurrentFrame2]);\n  const oneFrameBack = useCallback86(() => {\n    frameBack(1);\n  }, [frameBack]);\n  const oneFrameForward = useCallback86(() => {\n    frameForward(1);\n  }, [frameForward]);\n  const jumpToStart = useCallback86(() => {\n    seek(inFrame ?? 0);\n  }, [seek, inFrame]);\n  const jumpToEnd = useCallback86(() => {\n    seek(outFrame ?? getCurrentDuration() - 1);\n  }, [seek, outFrame]);\n  const keybindings = useKeybinding();\n  useEffect55(() => {\n    const arrowLeft = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"ArrowLeft\",\n      callback: onArrowLeft,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const arrowRight = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"ArrowRight\",\n      callback: onArrowRight,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const space = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \" \",\n      callback: onSpace,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const enter = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"enter\",\n      callback: onEnter,\n      commandCtrlKey: false,\n      preventDefault: false,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const a = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"a\",\n      callback: jumpToStart,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const e = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"e\",\n      callback: jumpToEnd,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      arrowLeft.unregister();\n      arrowRight.unregister();\n      space.unregister();\n      enter.unregister();\n      a.unregister();\n      e.unregister();\n    };\n  }, [\n    jumpToEnd,\n    jumpToStart,\n    keybindings,\n    onArrowLeft,\n    onArrowRight,\n    onEnter,\n    onSpace\n  ]);\n  useEffect55(() => {\n    let timeout = null;\n    let stopped = false;\n    const onBuffer = () => {\n      requestAnimationFrame(() => {\n        stopped = false;\n        timeout = setTimeout(() => {\n          if (!stopped) {\n            setShowBufferState(true);\n          }\n        }, bufferStateDelayInMilliseconds);\n      });\n    };\n    const onResume = () => {\n      requestAnimationFrame(() => {\n        setShowBufferState(false);\n        stopped = true;\n        if (timeout) {\n          clearTimeout(timeout);\n        }\n      });\n    };\n    emitter.addEventListener(\"waiting\", onBuffer);\n    emitter.addEventListener(\"resume\", onResume);\n    return () => {\n      emitter.removeEventListener(\"waiting\", onBuffer);\n      emitter.removeEventListener(\"resume\", onResume);\n      setShowBufferState(false);\n      if (timeout) {\n        clearTimeout(timeout);\n      }\n      stopped = true;\n    };\n  }, [bufferStateDelayInMilliseconds, emitter]);\n  return /* @__PURE__ */ jsxs80(Fragment22, {\n    children: [\n      /* @__PURE__ */ jsx172(ControlButton, {\n        \"aria-label\": \"Jump to beginning\",\n        title: \"Jump to beginning\",\n        disabled: !videoConfig || isFirstFrame,\n        onClick: jumpToStart,\n        children: /* @__PURE__ */ jsx172(JumpToStart, {\n          style: backStyle\n        })\n      }),\n      /* @__PURE__ */ jsx172(ControlButton, {\n        \"aria-label\": \"Step back one frame\",\n        title: \"Step back one frame\",\n        disabled: !videoConfig || isFirstFrame,\n        onClick: oneFrameBack,\n        children: /* @__PURE__ */ jsx172(StepBack, {\n          style: forwardBackStyle\n        })\n      }),\n      /* @__PURE__ */ jsx172(ControlButton, {\n        \"aria-label\": playing ? \"Pause\" : \"Play\",\n        title: playing ? \"Pause\" : \"Play\",\n        onClick: playing ? pause : play,\n        disabled: !videoConfig,\n        children: playing ? showBufferIndicator ? /* @__PURE__ */ jsx172(PlayerInternals12.BufferingIndicator, {\n          type: \"studio\"\n        }) : /* @__PURE__ */ jsx172(Pause, {\n          style: iconButton\n        }) : /* @__PURE__ */ jsx172(Play, {\n          style: iconButton\n        })\n      }),\n      /* @__PURE__ */ jsx172(ControlButton, {\n        \"aria-label\": \"Step forward one frame\",\n        title: \"Step forward one frame\",\n        disabled: !videoConfig || isLastFrame,\n        onClick: oneFrameForward,\n        children: /* @__PURE__ */ jsx172(StepForward, {\n          style: forwardBackStyle\n        })\n      })\n    ]\n  });\n};\n\n// src/components/PlaybackKeyboardShortcutsManager.tsx\nimport { PlayerInternals as PlayerInternals13 } from \"@remotion/player\";\nimport { useCallback as useCallback87, useEffect as useEffect56 } from \"react\";\nvar PlaybackKeyboardShortcutsManager = ({ setPlaybackRate }) => {\n  const keybindings = useKeybinding();\n  const { play, pause, playing } = PlayerInternals13.usePlayer();\n  const onJKey = useCallback87(() => {\n    setPlaybackRate((prevPlaybackRate) => {\n      if (!playing) {\n        return -1;\n      }\n      if (prevPlaybackRate > -1) {\n        return -1;\n      }\n      if (prevPlaybackRate > -2) {\n        return -2;\n      }\n      return -4;\n    });\n    play();\n  }, [play, playing, setPlaybackRate]);\n  const onKKey = useCallback87(() => {\n    setPlaybackRate(1);\n    pause();\n  }, [pause, setPlaybackRate]);\n  const onLKey = useCallback87(() => {\n    setPlaybackRate((prevPlaybackRate) => {\n      if (!playing) {\n        return 1;\n      }\n      if (prevPlaybackRate < 1) {\n        return 1;\n      }\n      if (prevPlaybackRate < 2) {\n        return 2;\n      }\n      return 4;\n    });\n    play();\n  }, [play, playing, setPlaybackRate]);\n  useEffect56(() => {\n    const jKey = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"j\",\n      callback: onJKey,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const kKey = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"k\",\n      callback: onKKey,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const lKey = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"l\",\n      callback: onLKey,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      jKey.unregister();\n      kKey.unregister();\n      lKey.unregister();\n    };\n  }, [keybindings, onJKey, onKKey, onLKey]);\n  return null;\n};\n\n// src/components/PlaybackRatePersistor.tsx\nimport { useContext as useContext51, useEffect as useEffect57 } from \"react\";\nimport { Internals as Internals41 } from \"remotion\";\n\n// src/state/playbackrate.ts\nvar key3 = \"remotion.playbackrate\";\nvar persistPlaybackRate = (option) => {\n  localStorage.setItem(key3, String(option));\n};\nvar loadPlaybackRate = () => {\n  if (typeof window !== \"undefined\") {\n    return 1;\n  }\n  const item2 = localStorage.getItem(key3);\n  if (item2 === null) {\n    return 1;\n  }\n  return Number(item2);\n};\n\n// src/components/PlaybackRatePersistor.tsx\nvar PlaybackRatePersistor = () => {\n  const { setPlaybackRate, playbackRate } = useContext51(Internals41.TimelineContext);\n  useEffect57(() => {\n    setPlaybackRate(loadPlaybackRate());\n  }, [setPlaybackRate]);\n  useEffect57(() => {\n    persistPlaybackRate(playbackRate);\n  }, [playbackRate]);\n  return null;\n};\n\n// src/components/PlaybackRateSelector.tsx\nimport { useContext as useContext52, useMemo as useMemo92 } from \"react\";\nimport { Internals as Internals42 } from \"remotion\";\nimport { jsx as jsx173 } from \"react/jsx-runtime\";\nvar commonPlaybackRates = [\n  -4,\n  -2,\n  -1,\n  -0.5,\n  -0.25,\n  0.25,\n  0.5,\n  1,\n  1.5,\n  2,\n  4\n];\nvar getPlaybackRateLabel = (playbackRate) => {\n  return `${playbackRate}x`;\n};\nvar accessibilityLabel5 = \"Change the playback rate\";\nvar comboStyle2 = { width: 80 };\nvar PlaybackRateSelector = ({ playbackRate, setPlaybackRate }) => {\n  const { canvasContent } = useContext52(Internals42.CompositionManager);\n  const isStill = useIsStill();\n  const style9 = useMemo92(() => {\n    return {\n      padding: CONTROL_BUTTON_PADDING\n    };\n  }, []);\n  const items = useMemo92(() => {\n    const divider = {\n      type: \"divider\",\n      id: \"divider\"\n    };\n    const values = commonPlaybackRates.map((newPlaybackRate) => {\n      return {\n        id: String(newPlaybackRate),\n        label: getPlaybackRateLabel(newPlaybackRate),\n        onClick: () => {\n          return setPlaybackRate(() => {\n            persistPlaybackRate(newPlaybackRate);\n            return newPlaybackRate;\n          });\n        },\n        type: \"item\",\n        value: newPlaybackRate,\n        keyHint: null,\n        leftItem: String(playbackRate) === String(newPlaybackRate) ? /* @__PURE__ */ jsx173(Checkmark, {}) : null,\n        subMenu: null,\n        quickSwitcherLabel: null\n      };\n    });\n    const middle = Math.floor(commonPlaybackRates.length / 2);\n    return [...values.slice(0, middle), divider, ...values.slice(middle)];\n  }, [playbackRate, setPlaybackRate]);\n  if (isStill || canvasContent === null || canvasContent.type === \"asset\") {\n    return null;\n  }\n  return /* @__PURE__ */ jsx173(\"div\", {\n    style: style9,\n    \"aria-label\": accessibilityLabel5,\n    children: /* @__PURE__ */ jsx173(Combobox, {\n      title: accessibilityLabel5,\n      style: comboStyle2,\n      selectedId: String(playbackRate),\n      values: items\n    })\n  });\n};\n\n// src/components/RenderButton.tsx\nimport { PlayerInternals as PlayerInternals14 } from \"@remotion/player\";\nimport {\n  useCallback as useCallback88,\n  useContext as useContext53,\n  useEffect as useEffect58,\n  useMemo as useMemo93,\n  useRef as useRef31,\n  useState as useState59\n} from \"react\";\nimport ReactDOM8 from \"react-dom\";\nimport { Internals as Internals43 } from \"remotion\";\nimport { jsx as jsx174, jsxs as jsxs81, Fragment as Fragment23 } from \"react/jsx-runtime\";\nvar splitButtonContainer = {\n  display: \"inline-flex\",\n  flexDirection: \"row\",\n  alignItems: \"stretch\",\n  borderRadius: 4,\n  border: `1px solid ${INPUT_BORDER_COLOR_UNHOVERED}`,\n  backgroundColor: INPUT_BACKGROUND,\n  overflow: \"hidden\"\n};\nvar mainButtonStyle = {\n  paddingLeft: 7,\n  paddingRight: 7,\n  paddingTop: 7,\n  paddingBottom: 7,\n  background: \"transparent\",\n  border: \"none\",\n  color: \"white\",\n  cursor: \"pointer\",\n  display: \"flex\",\n  alignItems: \"center\",\n  fontSize: 14,\n  fontFamily: \"inherit\"\n};\nvar dividerStyle = {\n  width: 1,\n  backgroundColor: INPUT_BORDER_COLOR_UNHOVERED,\n  alignSelf: \"stretch\"\n};\nvar dropdownTriggerStyle = {\n  paddingLeft: 6,\n  paddingRight: 6,\n  paddingTop: 7,\n  paddingBottom: 7,\n  background: \"transparent\",\n  border: \"none\",\n  color: \"white\",\n  cursor: \"pointer\",\n  display: \"flex\",\n  alignItems: \"center\"\n};\nvar mainButtonContent = {\n  paddingLeft: 4,\n  paddingRight: 6\n};\nvar label7 = {\n  fontSize: 14\n};\nvar RENDER_TYPE_STORAGE_KEY = \"remotion.renderType\";\nvar getInitialRenderType = (readOnlyStudio) => {\n  if (!SHOW_BROWSER_RENDERING) {\n    return \"server-render\";\n  }\n  if (readOnlyStudio) {\n    return \"client-render\";\n  }\n  try {\n    const stored = localStorage.getItem(RENDER_TYPE_STORAGE_KEY);\n    if (stored === \"server-render\" || stored === \"client-render\") {\n      return stored;\n    }\n  } catch {}\n  return \"server-render\";\n};\nvar RenderButton = ({\n  readOnlyStudio\n}) => {\n  const { inFrame, outFrame } = useTimelineInOutFramePosition();\n  const { setSelectedModal } = useContext53(ModalsContext);\n  const [renderType, setRenderType] = useState59(() => getInitialRenderType(readOnlyStudio));\n  const [dropdownOpened, setDropdownOpened] = useState59(false);\n  const dropdownRef = useRef31(null);\n  const containerRef = useRef31(null);\n  const { currentZIndex } = useZIndex();\n  const size4 = PlayerInternals14.useElementSize(dropdownRef, {\n    triggerOnWindowResize: true,\n    shouldApplyCssTransforms: true\n  });\n  const refresh = size4?.refresh;\n  const connectionStatus = useContext53(StudioServerConnectionCtx).previewServerState.type;\n  const shortcut = areKeyboardShortcutsDisabled() ? \"\" : \"(R)\";\n  const tooltip = connectionStatus === \"connected\" ? \"Export the current composition \" + shortcut : \"Connect to the Studio server to render\";\n  const iconStyle4 = useMemo93(() => {\n    return {\n      style: {\n        height: 16,\n        color: \"currentColor\"\n      }\n    };\n  }, []);\n  const video = Internals43.useVideo();\n  const getCurrentFrame2 = PlayerInternals14.useFrameImperative();\n  const { props } = useContext53(Internals43.EditorPropsContext);\n  const openServerRenderModal = useCallback88(() => {\n    if (!video) {\n      return null;\n    }\n    const defaults = window.remotion_renderDefaults;\n    if (!defaults) {\n      throw new TypeError(\"Expected defaults\");\n    }\n    setSelectedModal({\n      type: \"server-render\",\n      compositionId: video.id,\n      initialFrame: getCurrentFrame2(),\n      initialStillImageFormat: defaults.stillImageFormat,\n      initialVideoImageFormat: null,\n      initialJpegQuality: defaults.jpegQuality,\n      initialScale: window.remotion_renderDefaults?.scale ?? 1,\n      initialLogLevel: defaults.logLevel,\n      initialConcurrency: defaults.concurrency,\n      maxConcurrency: defaults.maxConcurrency,\n      minConcurrency: defaults.minConcurrency,\n      initialMuted: defaults.muted,\n      initialEnforceAudioTrack: defaults.enforceAudioTrack,\n      initialProResProfile: defaults.proResProfile,\n      initialx264Preset: defaults.x264Preset,\n      initialPixelFormat: null,\n      initialAudioBitrate: defaults.audioBitrate,\n      initialVideoBitrate: defaults.videoBitrate,\n      initialEveryNthFrame: defaults.everyNthFrame,\n      initialNumberOfGifLoops: defaults.numberOfGifLoops,\n      initialDelayRenderTimeout: defaults.delayRenderTimeout,\n      defaultConfigurationAudioCodec: defaults.audioCodec,\n      initialEnvVariables: window.process.env,\n      initialDisableWebSecurity: defaults.disableWebSecurity,\n      initialDarkMode: defaults.darkMode,\n      initialOpenGlRenderer: defaults.openGlRenderer,\n      initialHeadless: defaults.headless,\n      initialIgnoreCertificateErrors: defaults.ignoreCertificateErrors,\n      initialOffthreadVideoCacheSizeInBytes: defaults.offthreadVideoCacheSizeInBytes,\n      initialOffthreadVideoThreads: defaults.offthreadVideoThreads,\n      defaultProps: props[video.id] ?? video.defaultProps,\n      inFrameMark: inFrame,\n      outFrameMark: outFrame,\n      initialColorSpace: defaults.colorSpace,\n      initialMultiProcessOnLinux: defaults.multiProcessOnLinux,\n      defaultConfigurationVideoCodec: defaults.codec,\n      initialEncodingBufferSize: defaults.encodingBufferSize,\n      initialEncodingMaxRate: defaults.encodingMaxRate,\n      initialUserAgent: defaults.userAgent,\n      initialBeep: defaults.beepOnFinish,\n      initialRepro: defaults.repro,\n      initialForSeamlessAacConcatenation: defaults.forSeamlessAacConcatenation,\n      renderTypeOfLastRender: null,\n      defaulMetadata: defaults.metadata,\n      initialHardwareAcceleration: defaults.hardwareAcceleration,\n      initialChromeMode: defaults.chromeMode,\n      initialMediaCacheSizeInBytes: defaults.mediaCacheSizeInBytes,\n      renderDefaults: defaults\n    });\n  }, [video, setSelectedModal, getCurrentFrame2, props, inFrame, outFrame]);\n  const openClientRenderModal = useCallback88(() => {\n    if (!video) {\n      return null;\n    }\n    const defaults = window.remotion_renderDefaults;\n    if (!defaults) {\n      throw new TypeError(\"Expected defaults\");\n    }\n    setSelectedModal({\n      type: \"web-render\",\n      compositionId: video.id,\n      initialFrame: getCurrentFrame2(),\n      defaultProps: props[video.id] ?? video.defaultProps,\n      inFrameMark: inFrame,\n      outFrameMark: outFrame,\n      initialLogLevel: defaults.logLevel,\n      initialLicenseKey: defaults.publicLicenseKey\n    });\n  }, [video, setSelectedModal, getCurrentFrame2, props, inFrame, outFrame]);\n  const onClick = useCallback88(() => {\n    if (!SHOW_BROWSER_RENDERING || renderType === \"server-render\") {\n      openServerRenderModal();\n    } else {\n      openClientRenderModal();\n    }\n  }, [renderType, openServerRenderModal, openClientRenderModal]);\n  const onHideDropdown = useCallback88(() => {\n    setDropdownOpened(false);\n  }, []);\n  const handleRenderTypeChange = useCallback88((newType) => {\n    setRenderType(newType);\n    try {\n      localStorage.setItem(RENDER_TYPE_STORAGE_KEY, newType);\n    } catch {}\n    setDropdownOpened(false);\n    if (newType === \"server-render\") {\n      openServerRenderModal();\n    } else {\n      openClientRenderModal();\n    }\n  }, [openServerRenderModal, openClientRenderModal]);\n  const dropdownValues = useMemo93(() => {\n    return [\n      {\n        type: \"item\",\n        id: \"server-render\",\n        label: \"Server-side render\",\n        value: \"server-render\",\n        onClick: () => handleRenderTypeChange(\"server-render\"),\n        keyHint: null,\n        leftItem: null,\n        subMenu: null,\n        quickSwitcherLabel: null\n      },\n      {\n        type: \"item\",\n        id: \"client-render\",\n        label: \"Client-side render\",\n        value: \"client-render\",\n        onClick: () => handleRenderTypeChange(\"client-render\"),\n        keyHint: null,\n        leftItem: null,\n        subMenu: null,\n        quickSwitcherLabel: null\n      }\n    ];\n  }, [handleRenderTypeChange]);\n  useEffect58(() => {\n    const { current } = dropdownRef;\n    if (!current) {\n      return;\n    }\n    const onPointerDown = () => {\n      return setDropdownOpened((o) => {\n        if (!o) {\n          refresh?.();\n        }\n        return !o;\n      });\n    };\n    const onClickDropdown = (e) => {\n      e.stopPropagation();\n      const isKeyboardInitiated = e.detail === 0;\n      if (!isKeyboardInitiated) {\n        return;\n      }\n      return setDropdownOpened((o) => {\n        if (!o) {\n          refresh?.();\n          window.addEventListener(\"pointerup\", (evt) => {\n            if (!isMenuItem(evt.target)) {\n              setDropdownOpened(false);\n            }\n          }, {\n            once: true\n          });\n        }\n        return !o;\n      });\n    };\n    current.addEventListener(\"pointerdown\", onPointerDown);\n    current.addEventListener(\"click\", onClickDropdown);\n    return () => {\n      current.removeEventListener(\"pointerdown\", onPointerDown);\n      current.removeEventListener(\"click\", onClickDropdown);\n    };\n  }, [refresh]);\n  const spaceToBottom = useMemo93(() => {\n    const margin2 = 10;\n    if (size4 && dropdownOpened) {\n      return size4.windowSize.height - (size4.top + size4.height) - margin2;\n    }\n    return 0;\n  }, [dropdownOpened, size4]);\n  const spaceToTop = useMemo93(() => {\n    const margin2 = 10;\n    if (size4 && dropdownOpened) {\n      return size4.top - margin2;\n    }\n    return 0;\n  }, [dropdownOpened, size4]);\n  const derivedMaxHeight = useMemo93(() => {\n    return spaceToTop > spaceToBottom ? spaceToTop : spaceToBottom;\n  }, [spaceToBottom, spaceToTop]);\n  const portalStyle = useMemo93(() => {\n    if (!dropdownOpened || !size4) {\n      return null;\n    }\n    const verticalLayout = spaceToTop > spaceToBottom ? \"bottom\" : \"top\";\n    return {\n      ...verticalLayout === \"top\" ? {\n        ...menuContainerTowardsBottom,\n        top: size4.top + size4.height\n      } : {\n        ...menuContainerTowardsTop,\n        bottom: size4.windowSize.height - size4.top\n      },\n      right: size4.windowSize.width - size4.left - size4.width\n    };\n  }, [dropdownOpened, size4, spaceToBottom, spaceToTop]);\n  const containerStyle3 = useMemo93(() => {\n    return {\n      ...splitButtonContainer,\n      borderColor: INPUT_BORDER_COLOR_UNHOVERED,\n      opacity: connectionStatus !== \"connected\" ? 0.7 : 1,\n      cursor: connectionStatus !== \"connected\" ? \"inherit\" : \"pointer\"\n    };\n  }, [connectionStatus]);\n  const renderLabel = renderType === \"server-render\" ? \"Render\" : \"Render on web\";\n  const shouldShowDropdown = useMemo93(() => {\n    if (readOnlyStudio) {\n      return false;\n    }\n    if (!SHOW_BROWSER_RENDERING) {\n      return false;\n    }\n    return true;\n  }, [readOnlyStudio]);\n  if (!video) {\n    return null;\n  }\n  return /* @__PURE__ */ jsxs81(Fragment23, {\n    children: [\n      /* @__PURE__ */ jsx174(\"button\", {\n        style: { display: \"none\" },\n        id: \"render-modal-button-server\",\n        disabled: connectionStatus !== \"connected\" && renderType === \"server-render\",\n        onClick: openServerRenderModal,\n        type: \"button\"\n      }),\n      \" \",\n      /* @__PURE__ */ jsx174(\"button\", {\n        style: { display: \"none\" },\n        id: \"render-modal-button-client\",\n        disabled: connectionStatus !== \"connected\" && renderType === \"server-render\",\n        onClick: openClientRenderModal,\n        type: \"button\"\n      }),\n      /* @__PURE__ */ jsxs81(\"div\", {\n        ref: containerRef,\n        style: containerStyle3,\n        title: tooltip,\n        children: [\n          /* @__PURE__ */ jsx174(\"button\", {\n            type: \"button\",\n            style: mainButtonStyle,\n            onClick,\n            id: \"render-modal-button\",\n            disabled: connectionStatus !== \"connected\" && renderType === \"server-render\",\n            children: /* @__PURE__ */ jsxs81(Row, {\n              align: \"center\",\n              style: mainButtonContent,\n              children: [\n                /* @__PURE__ */ jsx174(ThinRenderIcon, {\n                  fill: \"currentcolor\",\n                  svgProps: iconStyle4\n                }),\n                /* @__PURE__ */ jsx174(Spacing, {\n                  x: 1\n                }),\n                /* @__PURE__ */ jsx174(\"span\", {\n                  style: label7,\n                  children: renderLabel\n                })\n              ]\n            })\n          }),\n          shouldShowDropdown ? /* @__PURE__ */ jsxs81(Fragment23, {\n            children: [\n              /* @__PURE__ */ jsx174(\"div\", {\n                style: dividerStyle\n              }),\n              /* @__PURE__ */ jsx174(\"button\", {\n                ref: dropdownRef,\n                type: \"button\",\n                style: dropdownTriggerStyle,\n                disabled: connectionStatus !== \"connected\",\n                className: MENU_INITIATOR_CLASSNAME,\n                children: /* @__PURE__ */ jsx174(CaretDown, {})\n              })\n            ]\n          }) : null\n        ]\n      }),\n      portalStyle ? ReactDOM8.createPortal(/* @__PURE__ */ jsx174(\"div\", {\n        style: fullScreenOverlay,\n        children: /* @__PURE__ */ jsx174(\"div\", {\n          style: outerPortal,\n          className: \"css-reset\",\n          children: /* @__PURE__ */ jsx174(HigherZIndex, {\n            onOutsideClick: onHideDropdown,\n            onEscape: onHideDropdown,\n            children: /* @__PURE__ */ jsx174(\"div\", {\n              style: portalStyle,\n              children: /* @__PURE__ */ jsx174(MenuContent, {\n                onNextMenu: () => {},\n                onPreviousMenu: () => {},\n                values: dropdownValues,\n                onHide: onHideDropdown,\n                leaveLeftSpace: false,\n                preselectIndex: dropdownValues.findIndex((v) => v.id === renderType),\n                topItemCanBeUnselected: false,\n                fixedHeight: derivedMaxHeight\n              })\n            })\n          })\n        })\n      }), getPortal(currentZIndex)) : null\n    ]\n  });\n};\n\n// src/components/Timeline/TimelineZoomControls.tsx\nimport { useCallback as useCallback89, useContext as useContext54 } from \"react\";\nimport { Internals as Internals44 } from \"remotion\";\n\n// src/icons/minus.tsx\nimport { jsx as jsx175 } from \"react/jsx-runtime\";\nvar Minus = (props) => {\n  return /* @__PURE__ */ jsx175(\"svg\", {\n    ...props,\n    xmlns: \"http://www.w3.org/2000/svg\",\n    viewBox: \"0 0 448 512\",\n    children: /* @__PURE__ */ jsx175(\"path\", {\n      fill: \"currentColor\",\n      d: \"M400 288h-352c-17.69 0-32-14.32-32-32.01s14.31-31.99 32-31.99h352c17.69 0 32 14.3 32 31.99S417.7 288 400 288z\"\n    })\n  });\n};\n\n// src/components/Timeline/TimelineZoomControls.tsx\nimport { jsx as jsx176, jsxs as jsxs82 } from \"react/jsx-runtime\";\nvar container34 = {\n  color: \"black\",\n  flexDirection: \"row\",\n  display: \"flex\",\n  alignItems: \"center\"\n};\nvar buttonStyle3 = {\n  fontSize: 24\n};\nvar iconStyle4 = {\n  color: \"white\",\n  width: 14\n};\nvar TimelineZoomControls = () => {\n  const { canvasContent } = useContext54(Internals44.CompositionManager);\n  const { setZoom, zoom: zoomMap } = useContext54(TimelineZoomCtx);\n  const { tabIndex } = useZIndex();\n  const onMinusClicked = useCallback89(() => {\n    if (canvasContent === null || canvasContent.type !== \"composition\") {\n      return;\n    }\n    setZoom(canvasContent.compositionId, (z) => Math.max(TIMELINE_MIN_ZOOM, z - 0.2));\n  }, [canvasContent, setZoom]);\n  const onPlusClicked = useCallback89(() => {\n    if (canvasContent === null || canvasContent.type !== \"composition\") {\n      return;\n    }\n    setZoom(canvasContent.compositionId, (z) => Math.min(TIMELINE_MAX_ZOOM, z + 0.2));\n  }, [canvasContent, setZoom]);\n  const onChange = useCallback89((e) => {\n    if (canvasContent === null || canvasContent.type !== \"composition\") {\n      return;\n    }\n    setZoom(canvasContent.compositionId, () => Number(e.target.value));\n  }, [canvasContent, setZoom]);\n  const isStill = useIsStill();\n  if (isStill || canvasContent === null || canvasContent.type !== \"composition\") {\n    return null;\n  }\n  const zoom = zoomMap[canvasContent.compositionId] ?? TIMELINE_MIN_ZOOM;\n  return /* @__PURE__ */ jsxs82(\"div\", {\n    style: container34,\n    children: [\n      /* @__PURE__ */ jsx176(ControlButton, {\n        onClick: onMinusClicked,\n        style: buttonStyle3,\n        title: \"Zoom out timeline\",\n        role: \"ControlButton\",\n        type: \"button\",\n        disabled: TIMELINE_MIN_ZOOM === zoom,\n        children: /* @__PURE__ */ jsx176(Minus, {\n          style: iconStyle4\n        })\n      }),\n      /* @__PURE__ */ jsx176(Spacing, {\n        x: 0.5\n      }),\n      /* @__PURE__ */ jsx176(\"input\", {\n        title: `Timeline zoom (${zoom}x)`,\n        alt: `Timeline zoom (${zoom}x)`,\n        type: \"range\",\n        min: TIMELINE_MIN_ZOOM,\n        step: 0.1,\n        value: zoom,\n        max: TIMELINE_MAX_ZOOM,\n        onChange,\n        className: \"__remotion-timeline-slider\",\n        tabIndex\n      }),\n      /* @__PURE__ */ jsx176(Spacing, {\n        x: 0.5\n      }),\n      /* @__PURE__ */ jsx176(ControlButton, {\n        onClick: onPlusClicked,\n        style: buttonStyle3,\n        title: \"Zoom in timeline\",\n        role: \"button\",\n        type: \"button\",\n        disabled: TIMELINE_MAX_ZOOM === zoom,\n        children: /* @__PURE__ */ jsx176(Plus, {\n          color: \"currentcolor\",\n          style: iconStyle4\n        })\n      })\n    ]\n  });\n};\n\n// src/components/PreviewToolbar.tsx\nimport { jsx as jsx177, jsxs as jsxs83, Fragment as Fragment24 } from \"react/jsx-runtime\";\nvar container35 = {\n  display: \"flex\",\n  justifyContent: \"center\",\n  borderTop: \"1px solid rgba(0, 0, 0, 0.5)\",\n  paddingTop: 2,\n  paddingBottom: 2,\n  alignItems: \"center\",\n  flexDirection: \"row\",\n  background: BACKGROUND\n};\nvar mobileContainer = {\n  ...container35,\n  position: \"relative\",\n  overflowY: \"auto\",\n  justifyContent: \"flex-start\"\n};\nvar scrollIndicatorLeft = {\n  position: \"fixed\",\n  display: \"none\",\n  top: 0,\n  left: 0,\n  width: 40,\n  height: \"100%\",\n  pointerEvents: \"none\",\n  background: `linear-gradient(to right, ${BACKGROUND}, ${BACKGROUND__TRANSPARENT})`\n};\nvar scrollIndicatorRight = {\n  position: \"fixed\",\n  display: \"none\",\n  top: 0,\n  right: 0,\n  width: 40,\n  height: \"100%\",\n  pointerEvents: \"none\",\n  background: `linear-gradient(to left, ${BACKGROUND}, ${BACKGROUND__TRANSPARENT})`\n};\nvar sideContainer = {\n  width: 300,\n  height: 38,\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar padding2 = {\n  width: TIMELINE_PADDING\n};\nvar PreviewToolbar = ({ readOnlyStudio, bufferStateDelayInMilliseconds }) => {\n  const { playbackRate, setPlaybackRate } = useContext55(Internals45.TimelineContext);\n  const { mediaMuted } = useContext55(Internals45.MediaVolumeContext);\n  const { setMediaMuted } = useContext55(Internals45.SetMediaVolumeContext);\n  const isVideoComposition = useIsVideoComposition();\n  const previewToolbarRef = useRef32(null);\n  const leftScrollIndicatorRef = useRef32(null);\n  const rightScrollIndicatorRef = useRef32(null);\n  const isStill = useIsStill();\n  const [loop, setLoop] = useState60(loadLoopOption());\n  const isFullscreenSupported = checkFullscreenSupport();\n  const isMobileLayout = useMobileLayout();\n  useEffect59(() => {\n    if (isMobileLayout && previewToolbarRef.current) {\n      const updateScrollableIndicatorProps = (target) => {\n        const boundingBox = target.getBoundingClientRect();\n        const { scrollLeft, scrollWidth, clientWidth } = target;\n        const scrollRight = scrollWidth - clientWidth - scrollLeft;\n        if (!leftScrollIndicatorRef.current || !rightScrollIndicatorRef.current) {\n          return;\n        }\n        if (scrollLeft !== 0) {\n          Object.assign(leftScrollIndicatorRef.current.style, {\n            display: \"block\",\n            height: `${boundingBox.height}px`,\n            top: `${boundingBox.top}px`,\n            left: `${boundingBox.left}px`\n          });\n        } else {\n          Object.assign(leftScrollIndicatorRef.current.style, {\n            display: \"none\"\n          });\n        }\n        if (scrollRight !== 0) {\n          const itemWidth = rightScrollIndicatorRef.current?.clientWidth || 0;\n          Object.assign(rightScrollIndicatorRef.current.style, {\n            display: \"block\",\n            height: `${boundingBox.height}px`,\n            top: `${boundingBox.top}px`,\n            left: `${boundingBox.left + boundingBox.width - itemWidth}px`\n          });\n        } else {\n          Object.assign(rightScrollIndicatorRef.current.style, {\n            display: \"none\"\n          });\n        }\n      };\n      const previewToolbar = previewToolbarRef.current;\n      const scrollHandler = () => {\n        updateScrollableIndicatorProps(previewToolbar);\n      };\n      previewToolbar.addEventListener(\"scroll\", scrollHandler);\n      scrollHandler();\n      return () => {\n        previewToolbar.removeEventListener(\"scroll\", scrollHandler);\n      };\n    }\n  });\n  return /* @__PURE__ */ jsxs83(\"div\", {\n    ref: previewToolbarRef,\n    style: isMobileLayout ? mobileContainer : container35,\n    className: \"css-reset\",\n    children: [\n      /* @__PURE__ */ jsx177(\"div\", {\n        ref: leftScrollIndicatorRef,\n        style: scrollIndicatorLeft\n      }),\n      isMobileLayout ? null : /* @__PURE__ */ jsxs83(Fragment24, {\n        children: [\n          /* @__PURE__ */ jsxs83(\"div\", {\n            style: sideContainer,\n            children: [\n              /* @__PURE__ */ jsx177(\"div\", {\n                style: padding2\n              }),\n              /* @__PURE__ */ jsx177(TimelineZoomControls, {})\n            ]\n          }),\n          /* @__PURE__ */ jsx177(Flex, {}),\n          /* @__PURE__ */ jsx177(SizeSelector, {}),\n          isStill || isVideoComposition ? /* @__PURE__ */ jsx177(PlaybackRateSelector, {\n            setPlaybackRate,\n            playbackRate\n          }) : null\n        ]\n      }),\n      isVideoComposition ? /* @__PURE__ */ jsxs83(Fragment24, {\n        children: [\n          /* @__PURE__ */ jsx177(Spacing, {\n            x: 2\n          }),\n          /* @__PURE__ */ jsx177(PlayPause, {\n            bufferStateDelayInMilliseconds,\n            loop,\n            playbackRate\n          }),\n          /* @__PURE__ */ jsx177(Spacing, {\n            x: 2\n          }),\n          /* @__PURE__ */ jsx177(LoopToggle, {\n            loop,\n            setLoop\n          }),\n          /* @__PURE__ */ jsx177(MuteToggle, {\n            muted: mediaMuted,\n            setMuted: setMediaMuted\n          }),\n          /* @__PURE__ */ jsx177(Spacing, {\n            x: 2\n          }),\n          /* @__PURE__ */ jsx177(TimelineInOutPointToggle, {}),\n          /* @__PURE__ */ jsx177(Spacing, {\n            x: 2\n          })\n        ]\n      }) : null,\n      /* @__PURE__ */ jsx177(CheckboardToggle, {}),\n      /* @__PURE__ */ jsx177(Spacing, {\n        x: 1\n      }),\n      isFullscreenSupported && /* @__PURE__ */ jsx177(FullScreenToggle, {}),\n      /* @__PURE__ */ jsx177(Flex, {}),\n      isMobileLayout && /* @__PURE__ */ jsxs83(Fragment24, {\n        children: [\n          /* @__PURE__ */ jsx177(Flex, {}),\n          /* @__PURE__ */ jsx177(SizeSelector, {}),\n          isStill || isVideoComposition ? /* @__PURE__ */ jsx177(PlaybackRateSelector, {\n            setPlaybackRate,\n            playbackRate\n          }) : null\n        ]\n      }),\n      /* @__PURE__ */ jsxs83(\"div\", {\n        style: sideContainer,\n        children: [\n          /* @__PURE__ */ jsx177(Flex, {}),\n          !isMobileLayout && /* @__PURE__ */ jsx177(FpsCounter, {\n            playbackSpeed: playbackRate\n          }),\n          /* @__PURE__ */ jsx177(Spacing, {\n            x: 2\n          }),\n          shouldShowRenderButton(readOnlyStudio) ? /* @__PURE__ */ jsx177(RenderButton, {\n            readOnlyStudio\n          }) : null,\n          /* @__PURE__ */ jsx177(Spacing, {\n            x: 1.5\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx177(PlaybackKeyboardShortcutsManager, {\n        setPlaybackRate\n      }),\n      /* @__PURE__ */ jsx177(PlaybackRatePersistor, {}),\n      /* @__PURE__ */ jsx177(\"div\", {\n        ref: rightScrollIndicatorRef,\n        style: scrollIndicatorRight\n      })\n    ]\n  });\n};\n\n// src/components/Splitter/SplitterContainer.tsx\nimport { useMemo as useMemo94, useRef as useRef33, useState as useState61 } from \"react\";\n\n// src/state/timeline.ts\nvar localStorageKey4 = (id) => `remotion.editor.timelineFlex.${id}`;\nvar persistTimelineFlex = (value, id) => {\n  localStorage.setItem(localStorageKey4(id), String(value));\n};\nvar loadTimelineFlex = (id) => {\n  const item2 = localStorage.getItem(localStorageKey4(id));\n  return item2 ? parseFloat(item2) : null;\n};\nvar useTimelineFlex = (id) => {\n  return [\n    loadTimelineFlex(id),\n    (value) => persistTimelineFlex(value, id)\n  ];\n};\n\n// src/components/Splitter/SplitterContext.tsx\nimport React117 from \"react\";\nvar SplitterContext = React117.createContext({\n  flexValue: 1,\n  ref: { current: null },\n  setFlexValue: () => {\n    return;\n  },\n  isDragging: { current: false },\n  orientation: \"horizontal\",\n  maxFlex: 1,\n  minFlex: 1,\n  defaultFlex: 1,\n  id: \"--\",\n  persistFlex: () => {\n    return;\n  }\n});\n\n// src/components/Splitter/SplitterContainer.tsx\nimport { jsx as jsx178 } from \"react/jsx-runtime\";\nvar containerRow = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  flex: 1,\n  height: \"100%\",\n  width: \"100%\"\n};\nvar containerColumn = {\n  display: \"flex\",\n  flexDirection: \"column\",\n  flex: 1,\n  height: 0\n};\nvar SplitterContainer = ({ orientation, children, defaultFlex, maxFlex, minFlex, id }) => {\n  const [initialTimelineFlex, persistFlex] = useTimelineFlex(id);\n  const [flexValue, setFlexValue] = useState61(initialTimelineFlex ?? defaultFlex);\n  const ref = useRef33(null);\n  const isDragging = useRef33(false);\n  const value = useMemo94(() => {\n    return {\n      flexValue,\n      ref,\n      setFlexValue,\n      isDragging,\n      orientation,\n      id,\n      maxFlex,\n      minFlex,\n      defaultFlex,\n      persistFlex\n    };\n  }, [\n    defaultFlex,\n    flexValue,\n    id,\n    maxFlex,\n    minFlex,\n    orientation,\n    persistFlex,\n    ref\n  ]);\n  return /* @__PURE__ */ jsx178(SplitterContext.Provider, {\n    value,\n    children: /* @__PURE__ */ jsx178(\"div\", {\n      ref,\n      style: orientation === \"horizontal\" ? containerColumn : containerRow,\n      children\n    })\n  });\n};\n\n// src/components/Splitter/SplitterElement.tsx\nimport { useContext as useContext56, useMemo as useMemo95 } from \"react\";\nimport { interpolateColors, random } from \"remotion\";\nimport { jsx as jsx179, jsxs as jsxs84, Fragment as Fragment25 } from \"react/jsx-runtime\";\nvar SplitterElement = ({ children, type, sticky }) => {\n  const context = useContext56(SplitterContext);\n  const style9 = useMemo95(() => {\n    return {\n      flex: (type === \"flexer\" ? context.flexValue : 1 - context.flexValue) * 1000,\n      display: \"flex\",\n      position: \"relative\",\n      overflow: \"hidden\",\n      flexDirection: \"column\"\n    };\n  }, [context.flexValue, type]);\n  const stickStyle = useMemo95(() => {\n    return {\n      position: \"absolute\",\n      left: (type === \"flexer\" ? 0 : context.flexValue) * 100 + \"%\",\n      width: (type === \"flexer\" ? context.flexValue : 1 - context.flexValue) * 100 + \"%\",\n      backgroundColor: interpolateColors(random(context.flexValue), [0, 1], [\"red\", \"blue\"])\n    };\n  }, [context.flexValue, type]);\n  return /* @__PURE__ */ jsxs84(Fragment25, {\n    children: [\n      /* @__PURE__ */ jsx179(\"div\", {\n        style: style9,\n        children\n      }),\n      /* @__PURE__ */ jsx179(\"div\", {\n        style: stickStyle,\n        children: sticky ?? null\n      })\n    ]\n  });\n};\n\n// src/components/Splitter/SplitterHandle.tsx\nimport { PlayerInternals as PlayerInternals15 } from \"@remotion/player\";\nimport { useContext as useContext57, useEffect as useEffect60, useRef as useRef34, useState as useState62 } from \"react\";\nimport { jsx as jsx180 } from \"react/jsx-runtime\";\nvar SPLITTER_HANDLE_SIZE = 3;\nvar containerRow2 = {\n  height: SPLITTER_HANDLE_SIZE\n};\nvar containerColumn2 = {\n  width: SPLITTER_HANDLE_SIZE\n};\nvar SplitterHandle = ({ allowToCollapse, onCollapse }) => {\n  const context = useContext57(SplitterContext);\n  if (!context) {\n    throw new Error(\"Cannot find splitter context\");\n  }\n  const [lastPointerUp, setLastPointerUp] = useState62(() => Date.now());\n  const ref = useRef34(null);\n  useEffect60(() => {\n    if (context.isDragging.current) {\n      return;\n    }\n    const { current } = ref;\n    if (!current) {\n      return;\n    }\n    const getNewValue = (e, clamp) => {\n      if (!context.isDragging.current) {\n        throw new Error(\"cannot get value if not dragging\");\n      }\n      if (!context.ref.current) {\n        throw new Error(\"domRect is not mounted\");\n      }\n      const { width, height } = context.ref.current.getBoundingClientRect();\n      const change = (() => {\n        if (context.orientation === \"vertical\") {\n          return (e.clientX - context.isDragging.current.x) / (width - SPLITTER_HANDLE_SIZE);\n        }\n        return (e.clientY - context.isDragging.current.y) / (height - SPLITTER_HANDLE_SIZE);\n      })();\n      const newFlex = context.flexValue + change;\n      if (clamp) {\n        return Math.min(context.maxFlex, Math.max(context.minFlex, newFlex));\n      }\n      return newFlex;\n    };\n    const onPointerDown = (e) => {\n      if (e.button !== 0) {\n        return;\n      }\n      context.isDragging.current = {\n        x: e.clientX,\n        y: e.clientY\n      };\n      ref.current?.classList.add(\"remotion-splitter-active\");\n      window.addEventListener(\"pointerup\", (ev) => {\n        if (!context.isDragging.current) {\n          return;\n        }\n        context.persistFlex(getNewValue(ev, true));\n        cleanup();\n        setLastPointerUp(Date.now());\n      }, { once: true });\n      window.addEventListener(\"pointermove\", onPointerMove);\n    };\n    const onPointerMove = (e) => {\n      if (context.isDragging.current) {\n        const val = getNewValue(e, true);\n        context.setFlexValue(val);\n        if (allowToCollapse === \"left\") {\n          const unclamped = getNewValue(e, false);\n          if (unclamped < context.minFlex / 2) {\n            cleanup();\n            onCollapse();\n            setLastPointerUp(Date.now());\n          }\n        }\n        if (allowToCollapse === \"right\") {\n          const unclamped = 1 - getNewValue(e, false);\n          if (unclamped < (1 - context.maxFlex) / 2) {\n            cleanup();\n            onCollapse();\n            setLastPointerUp(Date.now());\n          }\n        }\n      }\n    };\n    const cleanup = () => {\n      context.isDragging.current = false;\n      ref.current?.classList.remove(\"remotion-splitter-active\");\n      current.removeEventListener(\"pointerdown\", onPointerDown);\n      window.removeEventListener(\"pointermove\", onPointerMove);\n      PlayerInternals15.updateAllElementsSizes();\n    };\n    current.addEventListener(\"pointerdown\", onPointerDown);\n    return () => {\n      if (!context.isDragging.current) {\n        cleanup();\n      }\n    };\n  }, [allowToCollapse, context, context.flexValue, lastPointerUp, onCollapse]);\n  useEffect60(() => {\n    const { current } = ref;\n    if (!current) {\n      return;\n    }\n    let isMouseDown = false;\n    const onMouseDown = () => {\n      isMouseDown = true;\n    };\n    const onMouseUp = () => {\n      isMouseDown = false;\n    };\n    const onMouseEnter = (e) => {\n      if (e.button !== 0) {\n        return;\n      }\n      if (isMouseDown) {\n        return;\n      }\n      current.classList.add(\"remotion-splitter-hover\");\n    };\n    const onMouseLeave = (e) => {\n      if (e.button !== 0) {\n        return;\n      }\n      current.classList.remove(\"remotion-splitter-hover\");\n    };\n    current.addEventListener(\"mouseenter\", onMouseEnter);\n    current.addEventListener(\"mouseleave\", onMouseLeave);\n    window.addEventListener(\"mousedown\", onMouseDown);\n    window.addEventListener(\"mouseup\", onMouseUp);\n    return () => {\n      current.removeEventListener(\"mouseenter\", onMouseEnter);\n      current.removeEventListener(\"mouseleave\", onMouseLeave);\n      window.removeEventListener(\"mousedown\", onMouseDown);\n      window.removeEventListener(\"mouseup\", onMouseUp);\n    };\n  }, []);\n  return /* @__PURE__ */ jsx180(\"div\", {\n    ref,\n    className: [\n      \"remotion-splitter\",\n      context.orientation === \"horizontal\" ? \"remotion-splitter-horizontal\" : \"remotion-splitter-vertical\"\n    ].join(\" \"),\n    style: context.orientation === \"horizontal\" ? containerRow2 : containerColumn2\n  });\n};\n\n// src/components/TopPanel.tsx\nimport { jsx as jsx181, jsxs as jsxs85 } from \"react/jsx-runtime\";\nvar container36 = {\n  height: \"100%\",\n  width: \"100%\",\n  display: \"flex\",\n  flexDirection: \"column\",\n  flex: 1\n};\nvar row4 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  flex: 1,\n  minHeight: 0\n};\nvar useResponsiveSidebarStatus = () => {\n  const { sidebarCollapsedStateLeft } = useContext58(SidebarContext);\n  const responsiveLeftStatus = useBreakpoint(1200) ? \"collapsed\" : \"expanded\";\n  const actualStateLeft = useMemo96(() => {\n    if (sidebarCollapsedStateLeft === \"collapsed\") {\n      return \"collapsed\";\n    }\n    if (sidebarCollapsedStateLeft === \"expanded\") {\n      return \"expanded\";\n    }\n    return responsiveLeftStatus;\n  }, [sidebarCollapsedStateLeft, responsiveLeftStatus]);\n  return actualStateLeft;\n};\nvar TopPanel = ({ readOnlyStudio, onMounted, drawRef: drawRef2, bufferStateDelayInMilliseconds }) => {\n  const { setSidebarCollapsedState, sidebarCollapsedStateRight } = useContext58(SidebarContext);\n  const rulersAreVisible = useIsRulerVisible();\n  const actualStateLeft = useResponsiveSidebarStatus();\n  const actualStateRight = useMemo96(() => {\n    if (sidebarCollapsedStateRight === \"collapsed\") {\n      return \"collapsed\";\n    }\n    return \"expanded\";\n  }, [sidebarCollapsedStateRight]);\n  useEffect61(() => {\n    onMounted();\n  }, [onMounted]);\n  const canvasContainerStyle = useMemo96(() => ({\n    flex: 1,\n    display: \"flex\",\n    paddingTop: rulersAreVisible ? RULER_WIDTH : 0,\n    paddingLeft: rulersAreVisible ? RULER_WIDTH : 0\n  }), [rulersAreVisible]);\n  const onCollapseLeft = useCallback90(() => {\n    setSidebarCollapsedState({ left: \"collapsed\", right: null });\n  }, [setSidebarCollapsedState]);\n  const onCollapseRight = useCallback90(() => {\n    setSidebarCollapsedState({ left: null, right: \"collapsed\" });\n  }, [setSidebarCollapsedState]);\n  const isMobileLayout = useMobileLayout();\n  return /* @__PURE__ */ jsxs85(\"div\", {\n    style: container36,\n    children: [\n      /* @__PURE__ */ jsx181(\"div\", {\n        style: row4,\n        children: /* @__PURE__ */ jsxs85(SplitterContainer, {\n          minFlex: 0.15,\n          maxFlex: 0.4,\n          defaultFlex: 0.2,\n          id: \"sidebar-to-preview\",\n          orientation: \"vertical\",\n          children: [\n            actualStateLeft === \"expanded\" ? isMobileLayout ? /* @__PURE__ */ jsx181(MobilePanel, {\n              onClose: onCollapseLeft,\n              children: /* @__PURE__ */ jsx181(ExplorerPanel, {\n                readOnlyStudio\n              })\n            }) : /* @__PURE__ */ jsx181(SplitterElement, {\n              sticky: null,\n              type: \"flexer\",\n              children: /* @__PURE__ */ jsx181(ExplorerPanel, {\n                readOnlyStudio\n              })\n            }) : null,\n            actualStateLeft === \"expanded\" ? /* @__PURE__ */ jsx181(SplitterHandle, {\n              allowToCollapse: \"left\",\n              onCollapse: onCollapseLeft\n            }) : null,\n            /* @__PURE__ */ jsx181(SplitterElement, {\n              sticky: null,\n              type: \"anti-flexer\",\n              children: /* @__PURE__ */ jsxs85(SplitterContainer, {\n                minFlex: 0.5,\n                maxFlex: 0.8,\n                defaultFlex: 0.7,\n                id: \"canvas-to-right-sidebar\",\n                orientation: \"vertical\",\n                children: [\n                  /* @__PURE__ */ jsx181(SplitterElement, {\n                    sticky: null,\n                    type: \"flexer\",\n                    children: /* @__PURE__ */ jsx181(\"div\", {\n                      ref: drawRef2,\n                      style: canvasContainerStyle,\n                      children: /* @__PURE__ */ jsx181(CanvasIfSizeIsAvailable, {})\n                    })\n                  }),\n                  actualStateRight === \"expanded\" ? /* @__PURE__ */ jsx181(SplitterHandle, {\n                    allowToCollapse: \"right\",\n                    onCollapse: onCollapseRight\n                  }) : null,\n                  actualStateRight === \"expanded\" ? isMobileLayout ? /* @__PURE__ */ jsx181(MobilePanel, {\n                    onClose: onCollapseRight,\n                    children: /* @__PURE__ */ jsx181(OptionsPanel, {\n                      readOnlyStudio\n                    })\n                  }) : /* @__PURE__ */ jsx181(SplitterElement, {\n                    sticky: null,\n                    type: \"anti-flexer\",\n                    children: /* @__PURE__ */ jsx181(OptionsPanel, {\n                      readOnlyStudio\n                    })\n                  }) : null\n                ]\n              })\n            })\n          ]\n        })\n      }),\n      /* @__PURE__ */ jsx181(PreviewToolbar, {\n        bufferStateDelayInMilliseconds,\n        readOnlyStudio\n      }),\n      /* @__PURE__ */ jsx181(CurrentCompositionKeybindings, {\n        readOnlyStudio\n      }),\n      /* @__PURE__ */ jsx181(TitleUpdater, {})\n    ]\n  });\n};\n\n// src/components/SidebarCollapserControls.tsx\nimport { jsx as jsx182, jsxs as jsxs86, Fragment as Fragment26 } from \"react/jsx-runtime\";\nvar style9 = {\n  width: 16,\n  height: 16,\n  minWidth: 16,\n  border: \"1px solid currentColor\",\n  borderRadius: 3,\n  color: \"currentColor\",\n  position: \"relative\"\n};\nvar SidebarCollapserControls = () => {\n  const { setSidebarCollapsedState, sidebarCollapsedStateRight } = useContext59(SidebarContext);\n  const keybindings = useKeybinding();\n  const leftSidebarStatus = useResponsiveSidebarStatus();\n  const leftIcon = useCallback91((color) => {\n    return {\n      width: \"35%\",\n      height: \"100%\",\n      borderRight: \"1px solid \" + color,\n      background: leftSidebarStatus === \"expanded\" ? color : \"transparent\"\n    };\n  }, [leftSidebarStatus]);\n  const rightIcon = useCallback91((color) => {\n    return {\n      width: \"35%\",\n      height: \"100%\",\n      right: 0,\n      position: \"absolute\",\n      borderLeft: \"1px solid \" + color,\n      background: sidebarCollapsedStateRight === \"expanded\" ? color : \"transparent\"\n    };\n  }, [sidebarCollapsedStateRight]);\n  const toggleLeft = useCallback91(() => {\n    setSidebarCollapsedState({\n      left: (s) => {\n        if (s === \"responsive\") {\n          return leftSidebarStatus === \"collapsed\" ? \"expanded\" : \"collapsed\";\n        }\n        return s === \"collapsed\" ? \"expanded\" : \"collapsed\";\n      },\n      right: null\n    });\n  }, [leftSidebarStatus, setSidebarCollapsedState]);\n  const toggleRight = useCallback91(() => {\n    setSidebarCollapsedState({\n      right: (s) => s === \"collapsed\" ? \"expanded\" : \"collapsed\",\n      left: null\n    });\n  }, [setSidebarCollapsedState]);\n  const toggleBoth = useCallback91(() => {\n    if (sidebarCollapsedStateRight === leftSidebarStatus) {\n      setSidebarCollapsedState({\n        left: (s) => {\n          if (s === \"responsive\") {\n            return leftSidebarStatus === \"collapsed\" ? \"expanded\" : \"collapsed\";\n          }\n          return s === \"collapsed\" ? \"expanded\" : \"collapsed\";\n        },\n        right: (s) => s === \"collapsed\" ? \"expanded\" : \"collapsed\"\n      });\n    } else if (sidebarCollapsedStateRight === \"expanded\") {\n      toggleRight();\n    } else if (leftSidebarStatus === \"expanded\") {\n      toggleLeft();\n    }\n  }, [\n    leftSidebarStatus,\n    setSidebarCollapsedState,\n    sidebarCollapsedStateRight,\n    toggleLeft,\n    toggleRight\n  ]);\n  useEffect62(() => {\n    const left3 = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"b\",\n      commandCtrlKey: true,\n      callback: toggleLeft,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const right2 = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"j\",\n      commandCtrlKey: true,\n      callback: toggleRight,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const zen = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"g\",\n      commandCtrlKey: true,\n      callback: toggleBoth,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      left3.unregister();\n      right2.unregister();\n      zen.unregister();\n    };\n  }, [keybindings, toggleBoth, toggleLeft, toggleRight]);\n  const toggleLeftTooltip = areKeyboardShortcutsDisabled() ? \"Toggle Left Sidebar\" : `Toggle Left Sidebar (${cmdOrCtrlCharacter}+B)`;\n  const toggleRightTooltip = areKeyboardShortcutsDisabled() ? \"Toggle Right Sidebar\" : `Toggle Right Sidebar (${cmdOrCtrlCharacter}+J)`;\n  const colorStyle = useCallback91((color) => {\n    return {\n      ...style9,\n      color\n    };\n  }, []);\n  const toggleLeftAction = useCallback91((color) => {\n    return /* @__PURE__ */ jsx182(\"div\", {\n      style: colorStyle(color),\n      title: toggleLeftTooltip,\n      children: /* @__PURE__ */ jsx182(\"div\", {\n        style: leftIcon(color)\n      })\n    });\n  }, [colorStyle, leftIcon, toggleLeftTooltip]);\n  const toggleRightAction = useCallback91((color) => {\n    return /* @__PURE__ */ jsx182(\"div\", {\n      style: colorStyle(color),\n      title: toggleRightTooltip,\n      children: /* @__PURE__ */ jsx182(\"div\", {\n        style: rightIcon(color)\n      })\n    });\n  }, [colorStyle, rightIcon, toggleRightTooltip]);\n  return /* @__PURE__ */ jsxs86(Fragment26, {\n    children: [\n      /* @__PURE__ */ jsx182(InlineAction, {\n        onClick: toggleLeft,\n        renderAction: toggleLeftAction\n      }),\n      /* @__PURE__ */ jsx182(InlineAction, {\n        onClick: toggleRight,\n        renderAction: toggleRightAction\n      })\n    ]\n  });\n};\n\n// src/components/UpdateCheck.tsx\nimport {\n  useCallback as useCallback92,\n  useContext as useContext60,\n  useEffect as useEffect63,\n  useMemo as useMemo97,\n  useState as useState63\n} from \"react\";\nimport { VERSION } from \"remotion\";\nimport { jsx as jsx183 } from \"react/jsx-runtime\";\nvar buttonStyle4 = {\n  appearance: \"none\",\n  color: BLUE,\n  border: \"none\",\n  fontWeight: \"bold\",\n  backgroundColor: \"transparent\",\n  cursor: \"pointer\",\n  fontSize: 14,\n  display: \"inline-flex\",\n  justifyContent: \"center\"\n};\nvar UpdateCheck = () => {\n  const [info, setInfo] = useState63(null);\n  const { setSelectedModal } = useContext60(ModalsContext);\n  const { tabIndex } = useZIndex();\n  const [knownBugs, setKnownBugs] = useState63(null);\n  const hasKnownBugs = useMemo97(() => {\n    return knownBugs && knownBugs.length > 0;\n  }, [knownBugs]);\n  const checkForUpdates = useCallback92(() => {\n    const controller = new AbortController;\n    updateAvailable(controller.signal).then((d) => {\n      setInfo(d);\n    }).catch((err) => {\n      if (err.message.includes(\"aborted\")) {\n        return;\n      }\n      console.log(\"Could not check for updates\", err);\n    });\n    return controller;\n  }, []);\n  const checkForBugs = useCallback92(() => {\n    const controller = new AbortController;\n    fetch(`https://bugs.remotion.dev/api/${VERSION}`, {\n      signal: controller.signal\n    }).then(async (res) => {\n      const body = await res.json();\n      setKnownBugs(body.bugs);\n    }).catch((err) => {\n      if (err.message.includes(\"aborted\")) {\n        return;\n      }\n      console.log(\"Could not check for bugs in this version\", err);\n    });\n    return controller;\n  }, []);\n  useEffect63(() => {\n    const abortUpdate = checkForUpdates();\n    const abortBugs = checkForBugs();\n    return () => {\n      abortUpdate.abort();\n      abortBugs.abort();\n    };\n  }, [checkForBugs, checkForUpdates]);\n  const openModal = useCallback92(() => {\n    setSelectedModal({\n      type: \"update\",\n      info,\n      knownBugs\n    });\n  }, [info, knownBugs, setSelectedModal]);\n  const dynButtonStyle = useMemo97(() => {\n    return {\n      ...buttonStyle4,\n      color: hasKnownBugs ? WARNING_COLOR : LIGHT_TEXT\n    };\n  }, [hasKnownBugs]);\n  if (!info) {\n    return null;\n  }\n  if (!info.updateAvailable) {\n    return null;\n  }\n  return /* @__PURE__ */ jsx183(\"button\", {\n    tabIndex,\n    style: dynButtonStyle,\n    onClick: openModal,\n    type: \"button\",\n    title: hasKnownBugs ? \"Bugfixes available\" : \"Update available\",\n    children: hasKnownBugs ? \"Bugfixes available\" : /* @__PURE__ */ jsx183(\"svg\", {\n      xmlns: \"http://www.w3.org/2000/svg\",\n      style: {\n        height: 16,\n        width: 16\n      },\n      viewBox: \"0 0 512 512\",\n      children: /* @__PURE__ */ jsx183(\"path\", {\n        fill: \"currentcolor\",\n        d: \"M256 48a208 208 0 1 1 0 416 208 208 0 1 1 0-416zm0 464A256 256 0 1 0 256 0a256 256 0 1 0 0 512zM135.1 217.4c-4.5 4.2-7.1 10.1-7.1 16.3c0 12.3 10 22.3 22.3 22.3H208v96c0 17.7 14.3 32 32 32h32c17.7 0 32-14.3 32-32V256h57.7c12.3 0 22.3-10 22.3-22.3c0-6.2-2.6-12.1-7.1-16.3L269.8 117.5c-3.8-3.5-8.7-5.5-13.8-5.5s-10.1 2-13.8 5.5L135.1 217.4z\"\n      })\n    })\n  });\n};\n\n// src/components/MenuToolbar.tsx\nimport { jsx as jsx184, jsxs as jsxs87 } from \"react/jsx-runtime\";\nvar row5 = {\n  alignItems: \"center\",\n  flexDirection: \"row\",\n  display: \"flex\",\n  color: \"white\",\n  borderBottom: \"1px solid black\",\n  fontSize: 13,\n  paddingLeft: 6,\n  paddingRight: 10,\n  backgroundColor: BACKGROUND\n};\nvar flex2 = {\n  flex: 1\n};\nvar MenuToolbar = ({ readOnlyStudio }) => {\n  const [selected, setSelected] = useState64(null);\n  const mobileLayout = useMobileLayout();\n  const fixedWidthRight = useMemo98(() => {\n    return {\n      ...mobileLayout ? { width: \"fit-content\" } : {\n        width: \"330px\"\n      },\n      display: \"flex\",\n      alignItems: \"center\",\n      justifyContent: \"flex-end\"\n    };\n  }, [mobileLayout]);\n  const fixedWidthLeft = useMemo98(() => {\n    return {\n      ...mobileLayout ? { minWidth: \"0px\" } : {\n        minWidth: \"330px\"\n      },\n      display: \"flex\",\n      alignItems: \"center\",\n      justifyContent: \"flex-start\"\n    };\n  }, [mobileLayout]);\n  const itemClicked = useCallback93((itemId) => {\n    setSelected(itemId);\n  }, [setSelected]);\n  const itemHovered = useCallback93((itemId) => {\n    if (selected) {\n      setSelected(itemId);\n    }\n  }, [selected, setSelected]);\n  const closeMenu = useCallback93(() => {\n    setSelected(null);\n  }, []);\n  const structure = useMenuStructure(closeMenu, readOnlyStudio);\n  const menus = useMemo98(() => {\n    return structure.map((s) => s.id);\n  }, [structure]);\n  const onPreviousMenu = useCallback93(() => {\n    setSelected((s) => {\n      if (s === null) {\n        return null;\n      }\n      return menus[(menus.indexOf(s) + 1) % menus.length];\n    });\n  }, [menus]);\n  const onNextMenu = useCallback93(() => {\n    setSelected((s) => {\n      if (s === null) {\n        return null;\n      }\n      if (menus.indexOf(s) === 0) {\n        return menus[menus.length - 1];\n      }\n      return menus[(menus.indexOf(s) - 1) % menus.length];\n    });\n  }, [menus]);\n  const onItemQuit = useCallback93(() => {\n    setSelected(null);\n  }, [setSelected]);\n  return /* @__PURE__ */ jsxs87(Row, {\n    align: \"center\",\n    className: \"css-reset\",\n    style: row5,\n    children: [\n      /* @__PURE__ */ jsxs87(\"div\", {\n        style: fixedWidthLeft,\n        children: [\n          structure.map((s) => {\n            return /* @__PURE__ */ jsx184(MenuItem, {\n              selected: selected === s.id,\n              onItemSelected: itemClicked,\n              onItemHovered: itemHovered,\n              id: s.id,\n              label: s.label,\n              onItemQuit,\n              menu: s,\n              onPreviousMenu,\n              onNextMenu,\n              leaveLeftPadding: s.leaveLeftPadding\n            }, s.id);\n          }),\n          readOnlyStudio ? null : /* @__PURE__ */ jsx184(UpdateCheck, {})\n        ]\n      }),\n      /* @__PURE__ */ jsx184(\"div\", {\n        style: flex2\n      }),\n      /* @__PURE__ */ jsx184(MenuBuildIndicator, {}),\n      /* @__PURE__ */ jsx184(\"div\", {\n        style: flex2\n      }),\n      /* @__PURE__ */ jsx184(\"div\", {\n        style: fixedWidthRight,\n        children: /* @__PURE__ */ jsx184(SidebarCollapserControls, {})\n      }),\n      /* @__PURE__ */ jsx184(Spacing, {\n        x: 1\n      })\n    ]\n  });\n};\n\n// src/components/Timeline/Timeline.tsx\nimport { useContext as useContext69, useMemo as useMemo109 } from \"react\";\nimport { Internals as Internals54 } from \"remotion\";\n\n// src/helpers/get-sequence-visible-range.ts\nvar getCascadedStart = (sequence, sequences) => {\n  if (!sequence.parent) {\n    return sequence.from;\n  }\n  const parent = sequences.find((s) => s.id === sequence.parent);\n  if (!parent) {\n    throw new TypeError(\"Parent not found for sequence \" + sequence.id);\n  }\n  return getCascadedStart(parent, sequences) + sequence.from;\n};\nvar getTimelineVisibleStart = (sequence, sequences) => {\n  const cascadedStart = Math.max(0, getCascadedStart(sequence, sequences));\n  if (!sequence.parent) {\n    return cascadedStart;\n  }\n  const parent = sequences.find((s) => s.id === sequence.parent);\n  if (!parent) {\n    throw new TypeError(\"Parent not found for sequence \" + sequence.id);\n  }\n  const timelineVisibleStart = getTimelineVisibleStart(parent, sequences);\n  return Math.max(timelineVisibleStart, cascadedStart);\n};\nvar getTimelineVisibleDuration = (sequence, sequences) => {\n  const visibleDuration = sequence.duration + Math.min(sequence.from, 0);\n  if (!sequence.parent) {\n    return visibleDuration;\n  }\n  const parent = sequences.find((s) => s.id === sequence.parent);\n  if (!parent) {\n    throw new TypeError(\"Parent not found for sequence \" + sequence.id);\n  }\n  return Math.min(visibleDuration, getTimelineVisibleDuration(parent, sequences));\n};\n\n// src/helpers/get-timeline-nestedness.ts\nvar getTimelineNestedLevel = (sequence, allSequences, depth) => {\n  if (!sequence.parent) {\n    return depth;\n  }\n  const parentSequence = allSequences.find((s) => s.id === sequence.parent);\n  if (!parentSequence) {\n    throw new Error(\"has parentId but no parent\");\n  }\n  return getTimelineNestedLevel(parentSequence, allSequences, depth + 1);\n};\n\n// src/helpers/get-timeline-sequence-hash.ts\nvar getTimelineSequenceHash = (sequence, allSequences, hashesUsedInRoot, cache) => {\n  if (cache[sequence.id]) {\n    return cache[sequence.id];\n  }\n  const parent = allSequences.find((a) => a.id === sequence.parent);\n  const baseHash = [\n    parent ? getTimelineSequenceHash(parent, allSequences, hashesUsedInRoot, cache) : null,\n    sequence.displayName,\n    sequence.duration,\n    sequence.from,\n    sequence.type,\n    sequence.type === \"audio\" ? sequence.src : null,\n    sequence.type === \"audio\" ? sequence.volume : null,\n    sequence.type === \"video\" ? sequence.src : null,\n    sequence.type === \"video\" ? sequence.volume : null\n  ].join(\"-\");\n  const actualHash = baseHash + hashesUsedInRoot[sequence.rootId].filter((h) => h === baseHash).length;\n  hashesUsedInRoot[sequence.rootId].push(baseHash);\n  cache[sequence.id] = actualHash;\n  return actualHash;\n};\n\n// src/helpers/get-timeline-sequence-sort-key.ts\nvar getTimelineSequenceSequenceSortKey = (track, tracks, sameHashes = {}) => {\n  const firstSequenceWithSameHash = tracks.find((t) => sameHashes[track.hash].includes(t.sequence.id));\n  const id = String(firstSequenceWithSameHash.sequence.nonce).padStart(6, \"0\");\n  if (!track.sequence.parent) {\n    return id;\n  }\n  const parent = tracks.find((t) => t.sequence.id === track.sequence.parent);\n  if (!parent) {\n    return id;\n  }\n  const firstParentWithSameHash = tracks.find((a) => {\n    return sameHashes[parent.hash].includes(a.sequence.id);\n  });\n  if (!firstParentWithSameHash) {\n    throw new Error(\"could not find parent: \" + track.sequence.parent);\n  }\n  return `${getTimelineSequenceSequenceSortKey(firstParentWithSameHash, tracks, sameHashes)}-${id}`;\n};\n\n// src/helpers/calculate-timeline.ts\nvar calculateTimeline = ({\n  sequences,\n  sequenceDuration\n}) => {\n  const tracks = [];\n  if (sequences.length === 0) {\n    return [\n      {\n        sequence: {\n          displayName: \"\",\n          duration: sequenceDuration,\n          from: 0,\n          id: \"seq\",\n          parent: null,\n          type: \"sequence\",\n          rootId: \"-\",\n          showInTimeline: true,\n          nonce: 0,\n          loopDisplay: undefined,\n          stack: null,\n          premountDisplay: null,\n          postmountDisplay: null\n        },\n        depth: 0,\n        hash: \"-\"\n      }\n    ];\n  }\n  const sameHashes = {};\n  const hashesUsedInRoot = {};\n  const cache = {};\n  for (let i = 0;i < sequences.length; i++) {\n    const sequence = sequences[i];\n    if (!hashesUsedInRoot[sequence.rootId]) {\n      hashesUsedInRoot[sequence.rootId] = [];\n    }\n    const actualHash = getTimelineSequenceHash(sequence, sequences, hashesUsedInRoot, cache);\n    if (!sameHashes[actualHash]) {\n      sameHashes[actualHash] = [];\n    }\n    sameHashes[actualHash].push(sequence.id);\n    const cascadedStart = getCascadedStart(sequence, sequences);\n    const visibleStart = getTimelineVisibleStart(sequence, sequences);\n    const visibleDuration = getTimelineVisibleDuration(sequence, sequences);\n    tracks.push({\n      sequence: {\n        ...sequence,\n        from: visibleStart,\n        duration: visibleDuration\n      },\n      depth: getTimelineNestedLevel(sequence, sequences, 0),\n      hash: actualHash,\n      cascadedStart,\n      cascadedDuration: sequence.duration\n    });\n  }\n  const uniqueTracks = [];\n  for (const track of tracks) {\n    if (!uniqueTracks.find((t) => t.hash === track.hash)) {\n      const { cascadedDuration, cascadedStart, ...cleanTrack } = track;\n      uniqueTracks.push(cleanTrack);\n    }\n  }\n  return uniqueTracks.sort((a, b) => {\n    const sortKeyA = getTimelineSequenceSequenceSortKey(a, tracks, sameHashes);\n    const sortKeyB = getTimelineSequenceSequenceSortKey(b, tracks, sameHashes);\n    return sortKeyA.localeCompare(sortKeyB);\n  });\n};\n\n// src/components/Timeline/MaxTimelineTracks.tsx\nimport { DEFAULT_TIMELINE_TRACKS } from \"@remotion/studio-shared\";\nimport { jsxs as jsxs88 } from \"react/jsx-runtime\";\nvar MAX_TIMELINE_TRACKS = typeof process.env.MAX_TIMELINE_TRACKS === \"undefined\" || process.env.MAX_TIMELINE_TRACKS === null ? DEFAULT_TIMELINE_TRACKS : Number(process.env.MAX_TIMELINE_TRACKS);\nvar MAX_TIMELINE_TRACKS_NOTICE_HEIGHT = 24;\nvar container37 = {\n  height: MAX_TIMELINE_TRACKS_NOTICE_HEIGHT,\n  display: \"flex\",\n  alignItems: \"center\",\n  color: \"rgba(255, 255, 255, 0.6)\",\n  fontFamily: \"sans-serif\",\n  fontSize: 12,\n  backgroundColor: \"rgba(255, 255, 255, 0.1)\",\n  paddingLeft: TIMELINE_PADDING + 5\n};\nvar MaxTimelineTracksReached = () => {\n  return /* @__PURE__ */ jsxs88(\"div\", {\n    style: container37,\n    children: [\n      \"Limited display to \",\n      MAX_TIMELINE_TRACKS,\n      \" tracks to sustain performance.\",\n      \"\",\n      \"You can change this by setting Config.setMaxTimelineTracks() in your remotion.config.ts file.\"\n    ]\n  });\n};\n\n// src/components/Timeline/TimelineDragHandler.tsx\nimport { PlayerInternals as PlayerInternals16 } from \"@remotion/player\";\nimport {\n  useCallback as useCallback94,\n  useContext as useContext63,\n  useEffect as useEffect64,\n  useMemo as useMemo100,\n  useRef as useRef35,\n  useState as useState65\n} from \"react\";\nimport { Internals as Internals47, useVideoConfig as useVideoConfig4 } from \"remotion\";\n\n// src/components/Timeline/TimelineInOutPointer.tsx\nimport { createRef as createRef10, useContext as useContext61 } from \"react\";\nimport { Internals as Internals46 } from \"remotion\";\nimport { jsx as jsx185, jsxs as jsxs89, Fragment as Fragment27 } from \"react/jsx-runtime\";\nvar areaHighlight = {\n  position: \"absolute\",\n  backgroundColor: \"rgba(0, 0, 0, 0.5)\",\n  height: \"100%\",\n  bottom: 0,\n  top: 0\n};\nvar inMarkerAreaRef = createRef10();\nvar outMarkerAreaRef = createRef10();\nvar TimelineInOutPointer = () => {\n  const { inFrame, outFrame } = useTimelineInOutFramePosition();\n  const videoConfig = Internals46.useUnsafeVideoConfig();\n  const timelineWidth = useContext61(TimelineWidthContext);\n  if (!videoConfig || timelineWidth === null) {\n    return null;\n  }\n  return /* @__PURE__ */ jsxs89(Fragment27, {\n    children: [\n      inFrame !== null && /* @__PURE__ */ jsx185(\"div\", {\n        ref: inMarkerAreaRef,\n        style: {\n          ...areaHighlight,\n          left: 0,\n          width: getXPositionOfItemInTimelineImperatively(inFrame, videoConfig.durationInFrames, timelineWidth)\n        }\n      }),\n      outFrame !== null && /* @__PURE__ */ jsx185(\"div\", {\n        ref: outMarkerAreaRef,\n        style: {\n          ...areaHighlight,\n          left: getXPositionOfItemInTimelineImperatively(outFrame, videoConfig.durationInFrames, timelineWidth),\n          width: timelineWidth - getXPositionOfItemInTimelineImperatively(outFrame, videoConfig.durationInFrames, timelineWidth)\n        }\n      })\n    ]\n  });\n};\n\n// src/components/Timeline/TimelineInOutPointerHandle.tsx\nimport { createRef as createRef11, useContext as useContext62, useMemo as useMemo99 } from \"react\";\nimport { useVideoConfig as useVideoConfig3 } from \"remotion\";\nimport { jsx as jsx186 } from \"react/jsx-runtime\";\nvar line3 = {\n  height: \"100%\",\n  width: 1,\n  position: \"absolute\",\n  backgroundColor: \"rgba(255, 255, 255, 0.1)\",\n  cursor: \"ew-resize\",\n  paddingLeft: 1,\n  paddingRight: 1\n};\nvar inPointerHandle = createRef11();\nvar outPointerHandle = createRef11();\nvar InnerTimelineInOutPointerHandle = ({ atFrame, dragging, timelineWidth, type }) => {\n  const videoConfig = useVideoConfig3();\n  const style10 = useMemo99(() => {\n    return {\n      ...line3,\n      backgroundColor: dragging ? LIGHT_TRANSPARENT : \"rgba(255, 255, 255, 0.1)\",\n      transform: `translateX(${getXPositionOfItemInTimelineImperatively(atFrame, videoConfig.durationInFrames, timelineWidth)}px)`\n    };\n  }, [atFrame, dragging, timelineWidth, videoConfig.durationInFrames]);\n  return /* @__PURE__ */ jsx186(\"div\", {\n    ref: type === \"in\" ? inPointerHandle : outPointerHandle,\n    style: style10\n  });\n};\nvar TimelineInOutPointerHandle = ({\n  dragging,\n  type,\n  atFrame\n}) => {\n  const timelineWidth = useContext62(TimelineWidthContext);\n  if (timelineWidth === null) {\n    return null;\n  }\n  return /* @__PURE__ */ jsx186(InnerTimelineInOutPointerHandle, {\n    atFrame,\n    dragging,\n    timelineWidth,\n    type\n  });\n};\n\n// src/components/Timeline/TimelineDragHandler.tsx\nimport { jsx as jsx187, jsxs as jsxs90 } from \"react/jsx-runtime\";\nvar inner = {\n  overflowY: \"auto\",\n  overflowX: \"hidden\"\n};\nvar container38 = {\n  userSelect: \"none\",\n  WebkitUserSelect: \"none\",\n  position: \"absolute\",\n  height: \"100%\",\n  top: 0\n};\nvar style10 = {\n  width: \"100%\",\n  height: \"100%\",\n  userSelect: \"none\",\n  WebkitUserSelect: \"none\"\n};\nvar getClientXWithScroll = (x) => {\n  return x + scrollableRef.current?.scrollLeft;\n};\nvar TimelineDragHandler = () => {\n  const video = Internals47.useUnsafeVideoConfig();\n  const { zoom: zoomMap } = useContext63(TimelineZoomCtx);\n  const { canvasContent } = useContext63(Internals47.CompositionManager);\n  const containerStyle3 = useMemo100(() => {\n    if (!canvasContent || canvasContent.type !== \"composition\") {\n      return {};\n    }\n    const zoom = zoomMap[canvasContent.compositionId] ?? TIMELINE_MIN_ZOOM;\n    return {\n      ...container38,\n      width: 100 * zoom + \"%\"\n    };\n  }, [canvasContent, zoomMap]);\n  if (!canvasContent || canvasContent.type !== \"composition\") {\n    return null;\n  }\n  return /* @__PURE__ */ jsx187(\"div\", {\n    ref: sliderAreaRef,\n    style: containerStyle3,\n    children: video ? /* @__PURE__ */ jsx187(Inner2, {}) : null\n  });\n};\nvar Inner2 = () => {\n  const videoConfig = useVideoConfig4();\n  const size4 = PlayerInternals16.useElementSize(scrollableRef, {\n    triggerOnWindowResize: true,\n    shouldApplyCssTransforms: true\n  });\n  const { isHighestContext } = useZIndex();\n  const setFrame = Internals47.useTimelineSetFrame();\n  const [inOutDragging, setInOutDragging] = useState65({\n    dragging: false\n  });\n  const timelineWidth = useContext63(TimelineWidthContext);\n  const get = useCallback94((frame2) => {\n    if (timelineWidth === null) {\n      throw new Error(\"timeline width is not yet determined\");\n    }\n    return getXPositionOfItemInTimelineImperatively(frame2, videoConfig.durationInFrames, timelineWidth);\n  }, [timelineWidth, videoConfig.durationInFrames]);\n  const width = scrollableRef.current?.scrollWidth ?? 0;\n  const left3 = size4?.left ?? 0;\n  const { inFrame, outFrame } = useTimelineInOutFramePosition();\n  const { setInAndOutFrames } = useTimelineSetInOutFramePosition();\n  const [dragging, setDragging] = useState65({\n    dragging: false\n  });\n  const { playing, play, pause, seek } = PlayerInternals16.usePlayer();\n  const scroller = useRef35(null);\n  const stopInterval = () => {\n    if (scroller.current) {\n      clearInterval(scroller.current);\n      scroller.current = null;\n    }\n  };\n  const onPointerDown = useCallback94((e) => {\n    if (e.button !== 0) {\n      return;\n    }\n    if (!isHighestContext) {\n      return;\n    }\n    stopInterval();\n    if (!videoConfig) {\n      return;\n    }\n    if (e.target === inPointerHandle.current) {\n      if (inFrame === null) {\n        throw new Error(\"expected outframe\");\n      }\n      const inMarker = get(inFrame);\n      const outMarker = outFrame === null ? Infinity : get(outFrame - 1);\n      setInOutDragging({\n        dragging: \"in\",\n        initialOffset: getClientXWithScroll(e.clientX),\n        boundaries: [-Infinity, outMarker - inMarker]\n      });\n      return;\n    }\n    if (e.target === outPointerHandle.current) {\n      if (outFrame === null) {\n        throw new Error(\"expected outframe\");\n      }\n      const outMarker = get(outFrame);\n      const inMarker = inFrame === null ? -Infinity : get(inFrame + 1);\n      setInOutDragging({\n        dragging: \"out\",\n        initialOffset: getClientXWithScroll(e.clientX),\n        boundaries: [inMarker - outMarker, Infinity]\n      });\n      return;\n    }\n    if (e.button !== 0) {\n      return;\n    }\n    const frame2 = getFrameFromX({\n      clientX: getClientXWithScroll(e.clientX) - left3,\n      durationInFrames: videoConfig.durationInFrames,\n      width,\n      extrapolate: \"clamp\"\n    });\n    seek(frame2);\n    setDragging({\n      dragging: true,\n      wasPlaying: playing\n    });\n    pause();\n  }, [\n    isHighestContext,\n    videoConfig,\n    left3,\n    width,\n    seek,\n    playing,\n    pause,\n    inFrame,\n    get,\n    outFrame\n  ]);\n  const onPointerMoveScrubbing = useCallback94((e) => {\n    if (!videoConfig) {\n      return;\n    }\n    if (!dragging.dragging) {\n      return;\n    }\n    const isRightOfArea = e.clientX >= scrollableRef.current?.clientWidth + left3 - TIMELINE_PADDING;\n    const isLeftOfArea = e.clientX <= left3;\n    const frame2 = getFrameFromX({\n      clientX: getClientXWithScroll(e.clientX) - left3,\n      durationInFrames: videoConfig.durationInFrames,\n      width,\n      extrapolate: \"clamp\"\n    });\n    if (isLeftOfArea && canScrollTimelineIntoDirection().canScrollLeft) {\n      if (scroller.current) {\n        return;\n      }\n      const scrollEvery = () => {\n        if (!canScrollTimelineIntoDirection().canScrollLeft) {\n          stopInterval();\n          return;\n        }\n        const nextFrame = getFrameWhileScrollingLeft({\n          durationInFrames: videoConfig.durationInFrames,\n          width\n        });\n        const scrollPos = getScrollPositionForCursorOnLeftEdge({\n          nextFrame,\n          durationInFrames: videoConfig.durationInFrames\n        });\n        redrawTimelineSliderFast.current?.draw(nextFrame);\n        seek(nextFrame);\n        scrollToTimelineXOffset(scrollPos);\n      };\n      scrollEvery();\n      scroller.current = setInterval(() => {\n        scrollEvery();\n      }, 100);\n    } else if (isRightOfArea && canScrollTimelineIntoDirection().canScrollRight) {\n      if (scroller.current) {\n        return;\n      }\n      const scrollEvery = () => {\n        if (!canScrollTimelineIntoDirection().canScrollRight) {\n          stopInterval();\n          return;\n        }\n        const nextFrame = getFrameWhileScrollingRight({\n          durationInFrames: videoConfig.durationInFrames,\n          width\n        });\n        const scrollPos = getScrollPositionForCursorOnRightEdge({\n          nextFrame,\n          durationInFrames: videoConfig.durationInFrames\n        });\n        redrawTimelineSliderFast.current?.draw(nextFrame);\n        seek(nextFrame);\n        scrollToTimelineXOffset(scrollPos);\n      };\n      scrollEvery();\n      scroller.current = setInterval(() => {\n        scrollEvery();\n      }, 100);\n    } else {\n      stopInterval();\n      seek(frame2);\n    }\n  }, [videoConfig, dragging.dragging, left3, width, seek]);\n  const onPointerMoveInOut = useCallback94((e) => {\n    if (!videoConfig) {\n      return;\n    }\n    if (!inOutDragging.dragging) {\n      return;\n    }\n    const offset = Math.max(inOutDragging.boundaries[0], Math.min(inOutDragging.boundaries[1], getClientXWithScroll(e.clientX) - inOutDragging.initialOffset));\n    if (inOutDragging.dragging === \"in\") {\n      if (!inPointerHandle.current) {\n        throw new Error(\"in pointer handle\");\n      }\n      if (!inMarkerAreaRef.current) {\n        throw new Error(\"expected inMarkerAreaRef\");\n      }\n      if (!inFrame) {\n        throw new Error(\"expected inframes\");\n      }\n      inPointerHandle.current.style.transform = `translateX(${get(inFrame) + offset}px)`;\n      inMarkerAreaRef.current.style.width = String(get(inFrame) + offset) + \"px\";\n    }\n    if (inOutDragging.dragging === \"out\") {\n      if (!outPointerHandle.current) {\n        throw new Error(\"in pointer handle\");\n      }\n      if (!outMarkerAreaRef.current) {\n        throw new Error(\"in outMarkerAreaRef\");\n      }\n      if (!outFrame) {\n        throw new Error(\"expected outframes\");\n      }\n      outPointerHandle.current.style.transform = `translateX(${get(outFrame) + offset}px)`;\n      outMarkerAreaRef.current.style.left = String(get(outFrame) + offset) + \"px\";\n      outMarkerAreaRef.current.style.width = String(width - get(outFrame) - offset) + \"px\";\n    }\n  }, [get, inFrame, inOutDragging, outFrame, videoConfig, width]);\n  const onPointerUpScrubbing = useCallback94((e) => {\n    stopInterval();\n    if (!videoConfig) {\n      return;\n    }\n    if (!dragging.dragging) {\n      return;\n    }\n    setDragging({\n      dragging: false\n    });\n    const frame2 = getFrameFromX({\n      clientX: getClientXWithScroll(e.clientX) - left3,\n      durationInFrames: videoConfig.durationInFrames,\n      width,\n      extrapolate: \"clamp\"\n    });\n    setFrame((c) => {\n      const newObj = { ...c, [videoConfig.id]: frame2 };\n      Internals47.persistCurrentFrame(newObj);\n      return newObj;\n    });\n    if (dragging.wasPlaying) {\n      play();\n    }\n  }, [dragging, left3, play, videoConfig, setFrame, width]);\n  const onPointerUpInOut = useCallback94((e) => {\n    if (!videoConfig) {\n      return;\n    }\n    if (!inOutDragging.dragging) {\n      return;\n    }\n    setInOutDragging({\n      dragging: false\n    });\n    const frame2 = getFrameFromX({\n      clientX: getClientXWithScroll(e.clientX) - left3,\n      durationInFrames: videoConfig.durationInFrames,\n      width,\n      extrapolate: \"extend\"\n    });\n    if (inOutDragging.dragging === \"in\") {\n      if (frame2 < 1) {\n        return setInAndOutFrames((prev) => ({\n          ...prev,\n          [videoConfig.id]: {\n            ...prev[videoConfig.id] ?? defaultInOutValue,\n            inFrame: null\n          }\n        }));\n      }\n      const maxFrame = outFrame === null ? Infinity : outFrame - 1;\n      setInAndOutFrames((prev) => ({\n        ...prev,\n        [videoConfig.id]: {\n          ...prev[videoConfig.id] ?? defaultInOutValue,\n          inFrame: Math.min(maxFrame, frame2)\n        }\n      }));\n    } else {\n      if (frame2 > videoConfig.durationInFrames - 2) {\n        return setInAndOutFrames((prev) => ({\n          ...prev,\n          [videoConfig.id]: {\n            ...prev[videoConfig.id] ?? defaultInOutValue,\n            outFrame: null\n          }\n        }));\n      }\n      const minFrame = inFrame === null ? -Infinity : inFrame + 1;\n      setInAndOutFrames((prev) => ({\n        ...prev,\n        [videoConfig.id]: {\n          ...prev[videoConfig.id] ?? defaultInOutValue,\n          outFrame: Math.max(minFrame, frame2)\n        }\n      }));\n    }\n  }, [\n    inFrame,\n    inOutDragging.dragging,\n    left3,\n    outFrame,\n    setInAndOutFrames,\n    videoConfig,\n    width\n  ]);\n  useEffect64(() => {\n    if (!dragging.dragging) {\n      return;\n    }\n    window.addEventListener(\"pointermove\", onPointerMoveScrubbing);\n    window.addEventListener(\"pointerup\", onPointerUpScrubbing);\n    return () => {\n      window.removeEventListener(\"pointermove\", onPointerMoveScrubbing);\n      window.removeEventListener(\"pointerup\", onPointerUpScrubbing);\n    };\n  }, [dragging.dragging, onPointerMoveScrubbing, onPointerUpScrubbing]);\n  useEffect64(() => {\n    if (inOutDragging.dragging === false) {\n      return;\n    }\n    window.addEventListener(\"pointermove\", onPointerMoveInOut);\n    window.addEventListener(\"pointerup\", onPointerUpInOut);\n    return () => {\n      window.removeEventListener(\"pointermove\", onPointerMoveInOut);\n      window.removeEventListener(\"pointerup\", onPointerUpInOut);\n    };\n  }, [inOutDragging.dragging, onPointerMoveInOut, onPointerUpInOut]);\n  const inContextMenu = useMemo100(() => {\n    return [\n      {\n        id: \"hide-in\",\n        keyHint: null,\n        label: \"Clear In marker\",\n        leftItem: null,\n        onClick: (_, e) => {\n          e?.stopPropagation();\n          e?.preventDefault();\n          setInAndOutFrames((prev) => ({\n            ...prev,\n            [videoConfig.id]: {\n              ...prev[videoConfig.id] ?? defaultInOutValue,\n              inFrame: null\n            }\n          }));\n        },\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: \"hide-in\"\n      }\n    ];\n  }, [setInAndOutFrames, videoConfig.id]);\n  const outContextMenu = useMemo100(() => {\n    return [\n      {\n        id: \"hide-out\",\n        keyHint: null,\n        label: \"Clear Out marker\",\n        leftItem: null,\n        onClick: (_, e) => {\n          e?.stopPropagation();\n          e?.preventDefault();\n          setInAndOutFrames((prev) => ({\n            ...prev,\n            [videoConfig.id]: {\n              ...prev[videoConfig.id] ?? defaultInOutValue,\n              outFrame: null\n            }\n          }));\n        },\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: \"hide-out\"\n      }\n    ];\n  }, [setInAndOutFrames, videoConfig.id]);\n  return /* @__PURE__ */ jsxs90(\"div\", {\n    style: style10,\n    onPointerDown,\n    children: [\n      /* @__PURE__ */ jsx187(\"div\", {\n        style: inner,\n        className: VERTICAL_SCROLLBAR_CLASSNAME\n      }),\n      inFrame !== null && /* @__PURE__ */ jsx187(ContextMenu, {\n        values: inContextMenu,\n        children: /* @__PURE__ */ jsx187(TimelineInOutPointerHandle, {\n          type: \"in\",\n          atFrame: inFrame,\n          dragging: inOutDragging.dragging === \"in\"\n        })\n      }),\n      outFrame !== null && /* @__PURE__ */ jsx187(ContextMenu, {\n        values: outContextMenu,\n        children: /* @__PURE__ */ jsx187(TimelineInOutPointerHandle, {\n          type: \"out\",\n          dragging: inOutDragging.dragging === \"out\",\n          atFrame: outFrame\n        })\n      })\n    ]\n  });\n};\n\n// src/components/Timeline/TimelineList.tsx\nimport { PlayerInternals as PlayerInternals18 } from \"@remotion/player\";\nimport { useRef as useRef38 } from \"react\";\n\n// src/components/Timeline/TimelineListItem.tsx\nimport { useCallback as useCallback97, useContext as useContext65, useMemo as useMemo102 } from \"react\";\nimport { Internals as Internals48 } from \"remotion\";\n\n// src/components/Timeline/TimelineLayerEye.tsx\nimport { useCallback as useCallback95 } from \"react\";\nimport { jsx as jsx188 } from \"react/jsx-runtime\";\nvar eyeIcon = {\n  width: 12,\n  color: \"currentColor\",\n  pointerEvents: \"none\"\n};\nvar speakerIcon = {\n  ...eyeIcon,\n  height: 10,\n  marginLeft: -1\n};\nvar container39 = {\n  height: 16,\n  width: 16,\n  borderRadius: 2,\n  backgroundColor: \"rgba(0, 0, 0, 0.4)\",\n  display: \"inline-flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  marginRight: 6,\n  flexShrink: 0\n};\nvar layerPointedDown = null;\nvar TimelineLayerEye = ({ onInvoked, hidden, type }) => {\n  const renderAction = useCallback95((color) => {\n    if (hidden) {\n      return null;\n    }\n    if (type === \"speaker\") {\n      return /* @__PURE__ */ jsx188(\"svg\", {\n        viewBox: \"0 0 10 14\",\n        fill: \"none\",\n        style: speakerIcon,\n        children: /* @__PURE__ */ jsx188(\"path\", {\n          d: \"M9.40938 0.0869018C9.76875 0.249402 10 0.605652 10 0.999402V12.9994C10 13.3932 9.76875 13.7494 9.40938 13.9119C9.05 14.0744 8.62813 14.0088 8.33438 13.7463L4.11875 9.9994H2C0.896875 9.9994 0 9.10253 0 7.9994V5.9994C0 4.89628 0.896875 3.9994 2 3.9994H4.11875L8.33438 0.252527C8.62813 -0.0099732 9.05 -0.0724732 9.40938 0.0869018Z\",\n          fill: color\n        })\n      });\n    }\n    return /* @__PURE__ */ jsx188(\"svg\", {\n      style: eyeIcon,\n      viewBox: \"0 0 24 16\",\n      fill: \"none\",\n      children: /* @__PURE__ */ jsx188(\"path\", {\n        d: \"M24 7.551C24 7.551 19.748 16 12.015 16C4.835 16 0 7.551 0 7.551C0 7.551 4.446 0 12.015 0C19.709 0 24 7.551 24 7.551ZM17 8C17 5.243 14.757 3 12 3C9.243 3 7 5.243 7 8C7 10.757 9.243 13 12 13C14.757 13 17 10.757 17 8Z\",\n        fill: color\n      })\n    });\n  }, [hidden, type]);\n  const onPointerDown = useCallback95((e) => {\n    if (e.button !== 0) {\n      return;\n    }\n    layerPointedDown = hidden ? \"enable\" : \"disable\";\n    onInvoked(layerPointedDown);\n    window.addEventListener(\"pointerup\", () => {\n      layerPointedDown = null;\n    }, { once: true });\n  }, [hidden, onInvoked]);\n  const onPointerEnter = useCallback95(() => {\n    if (layerPointedDown) {\n      onInvoked(layerPointedDown);\n    }\n  }, [onInvoked]);\n  return /* @__PURE__ */ jsx188(\"div\", {\n    style: container39,\n    onPointerEnter,\n    onPointerDown,\n    children: renderAction(LIGHT_COLOR)\n  });\n};\n\n// src/components/Timeline/TimelineStack/index.tsx\nimport { SOURCE_MAP_ENDPOINT } from \"@remotion/studio-shared\";\nimport {\n  useCallback as useCallback96,\n  useContext as useContext64,\n  useEffect as useEffect65,\n  useMemo as useMemo101,\n  useState as useState66\n} from \"react\";\nimport { SourceMapConsumer as SourceMapConsumer3 } from \"source-map\";\nimport { jsx as jsx189, jsxs as jsxs91, Fragment as Fragment28 } from \"react/jsx-runtime\";\nvar publicPath = window.remotion_publicPath === \"/\" ? \"\" : window.remotion_publicPath;\nvar withoutSlashInTheEnd = publicPath.endsWith(\"/\") ? publicPath.slice(0, -1) : publicPath;\nSourceMapConsumer3.initialize({\n  \"lib/mappings.wasm\": withoutSlashInTheEnd + SOURCE_MAP_ENDPOINT\n});\nvar TimelineStack = ({ isCompact, sequence }) => {\n  const [originalLocation, setOriginalLocation] = useState66(null);\n  const [stackHovered, setStackHovered] = useState66(false);\n  const [titleHovered, setTitleHovered] = useState66(false);\n  const [opening, setOpening] = useState66(false);\n  const selectAsset = useSelectAsset();\n  const connectionStatus = useContext64(StudioServerConnectionCtx).previewServerState.type;\n  const assetPath = useMemo101(() => {\n    if (sequence.type !== \"video\" && sequence.type !== \"audio\") {\n      return null;\n    }\n    const isStatic = sequence.src.startsWith(window.remotion_staticBase);\n    if (!isStatic) {\n      return null;\n    }\n    const relativePath = sequence.src.replace(window.remotion_staticBase + \"/\", \"\");\n    return relativePath;\n  }, [sequence]);\n  const navigateToAsset = useCallback96((asset) => {\n    selectAsset(asset);\n    pushUrl(`/assets/${asset}`);\n  }, [selectAsset]);\n  const openEditor = useCallback96(async (location2) => {\n    if (!window.remotion_editorName) {\n      return;\n    }\n    setOpening(true);\n    try {\n      await openOriginalPositionInEditor(location2);\n    } catch (err) {\n      showNotification(err.message, 2000);\n    } finally {\n      setOpening(false);\n    }\n  }, []);\n  const canOpenInEditor = window.remotion_editorName && connectionStatus === \"connected\" && originalLocation;\n  const canOpenInGitHub = window.remotion_gitSource && originalLocation;\n  const titleHoverable = isCompact && (canOpenInEditor || canOpenInGitHub) || assetPath;\n  const stackHoverable = !isCompact && (canOpenInEditor || canOpenInGitHub);\n  const onClickTitle = useCallback96(() => {\n    if (!titleHoverable) {\n      return null;\n    }\n    if (assetPath) {\n      navigateToAsset(assetPath);\n      return;\n    }\n    if (!originalLocation) {\n      return;\n    }\n    if (canOpenInEditor) {\n      openEditor(originalLocation);\n      return;\n    }\n    if (canOpenInGitHub) {\n      window.open(getGitRefUrl(window.remotion_gitSource, originalLocation), \"_blank\");\n    }\n  }, [\n    assetPath,\n    canOpenInEditor,\n    canOpenInGitHub,\n    navigateToAsset,\n    openEditor,\n    originalLocation,\n    titleHoverable\n  ]);\n  const onClickStack = useCallback96(() => {\n    if (!originalLocation) {\n      return;\n    }\n    if (canOpenInEditor) {\n      openEditor(originalLocation);\n      return;\n    }\n    if (canOpenInGitHub) {\n      window.open(getGitRefUrl(window.remotion_gitSource, originalLocation), \"_blank\");\n    }\n  }, [canOpenInEditor, canOpenInGitHub, openEditor, originalLocation]);\n  useEffect65(() => {\n    if (!sequence.stack) {\n      return;\n    }\n    getOriginalLocationFromStack(sequence.stack, \"sequence\").then((frame2) => {\n      setOriginalLocation(frame2);\n    }).catch((err) => {\n      console.error(\"Could not get original location of Sequence\", err);\n    });\n  }, [sequence.stack]);\n  const onStackPointerEnter = useCallback96(() => {\n    setStackHovered(true);\n  }, []);\n  const onStackPointerLeave = useCallback96(() => {\n    setStackHovered(false);\n  }, []);\n  const onTitlePointerEnter = useCallback96(() => {\n    setTitleHovered(true);\n  }, []);\n  const onTitlePointerLeave = useCallback96(() => {\n    setTitleHovered(false);\n  }, []);\n  const style11 = useMemo101(() => {\n    return {\n      fontSize: 12,\n      color: opening ? VERY_LIGHT_TEXT : stackHovered && stackHoverable ? LIGHT_TEXT : VERY_LIGHT_TEXT,\n      marginLeft: 10,\n      cursor: stackHoverable ? \"pointer\" : undefined,\n      display: \"flex\",\n      flexDirection: \"row\",\n      alignItems: \"center\",\n      whiteSpace: \"nowrap\",\n      textOverflow: \"ellipsis\",\n      overflow: \"hidden\",\n      flexShrink: 1e5\n    };\n  }, [opening, stackHovered, stackHoverable]);\n  const titleStyle2 = useMemo101(() => {\n    const hoverEffect = titleHovered && titleHoverable;\n    return {\n      fontSize: 12,\n      whiteSpace: \"nowrap\",\n      textOverflow: \"ellipsis\",\n      overflow: \"hidden\",\n      lineHeight: 1,\n      color: opening && isCompact ? VERY_LIGHT_TEXT : LIGHT_COLOR,\n      userSelect: \"none\",\n      WebkitUserSelect: \"none\",\n      borderBottom: hoverEffect ? \"1px solid #fff\" : \"none\",\n      cursor: hoverEffect ? \"pointer\" : undefined\n    };\n  }, [titleHoverable, isCompact, opening, titleHovered]);\n  const text = sequence.displayName.length > 1000 ? sequence.displayName.slice(0, 1000) + \"...\" : sequence.displayName;\n  return /* @__PURE__ */ jsxs91(Fragment28, {\n    children: [\n      /* @__PURE__ */ jsx189(\"div\", {\n        onPointerEnter: onTitlePointerEnter,\n        onPointerLeave: onTitlePointerLeave,\n        title: originalLocation ? getOriginalSourceAttribution(originalLocation) : text || \"<Sequence>\",\n        style: titleStyle2,\n        onClick: onClickTitle,\n        children: text || \"<Sequence>\"\n      }),\n      isCompact || !originalLocation ? null : /* @__PURE__ */ jsx189(\"div\", {\n        onPointerEnter: onStackPointerEnter,\n        onPointerLeave: onStackPointerLeave,\n        onClick: onClickStack,\n        style: style11,\n        children: getOriginalSourceAttribution(originalLocation)\n      }),\n      opening ? /* @__PURE__ */ jsxs91(Fragment28, {\n        children: [\n          /* @__PURE__ */ jsx189(Spacing, {\n            x: 0.5\n          }),\n          /* @__PURE__ */ jsx189(Spinner, {\n            duration: 0.5,\n            size: 12\n          })\n        ]\n      }) : null\n    ]\n  });\n};\n\n// src/components/Timeline/TimelineListItem.tsx\nimport { jsx as jsx190, jsxs as jsxs92 } from \"react/jsx-runtime\";\nvar SPACING = 5;\nvar space = {\n  width: SPACING,\n  flexShrink: 0\n};\nvar TimelineListItem = ({ nestedDepth, sequence, isCompact }) => {\n  const { hidden, setHidden } = useContext65(Internals48.SequenceVisibilityToggleContext);\n  const padder = useMemo102(() => {\n    return {\n      width: Number(SPACING * 1.5) * nestedDepth,\n      flexShrink: 0\n    };\n  }, [nestedDepth]);\n  const isItemHidden = useMemo102(() => {\n    return hidden[sequence.id] ?? false;\n  }, [hidden, sequence.id]);\n  const onToggleVisibility = useCallback97((type) => {\n    setHidden((prev) => {\n      return {\n        ...prev,\n        [sequence.id]: type !== \"enable\"\n      };\n    });\n  }, [sequence.id, setHidden]);\n  const outer2 = useMemo102(() => {\n    return {\n      height: getTimelineLayerHeight(sequence.type === \"video\" ? \"video\" : \"other\") + TIMELINE_ITEM_BORDER_BOTTOM,\n      color: \"white\",\n      fontFamily: \"Arial, Helvetica, sans-serif\",\n      display: \"flex\",\n      flexDirection: \"row\",\n      alignItems: \"center\",\n      wordBreak: \"break-all\",\n      textAlign: \"left\",\n      paddingLeft: SPACING,\n      borderBottom: `1px solid ${TIMELINE_TRACK_SEPARATOR}`\n    };\n  }, [sequence.type]);\n  return /* @__PURE__ */ jsxs92(\"div\", {\n    style: outer2,\n    children: [\n      /* @__PURE__ */ jsx190(TimelineLayerEye, {\n        type: sequence.type === \"audio\" ? \"speaker\" : \"eye\",\n        hidden: isItemHidden,\n        onInvoked: onToggleVisibility\n      }),\n      /* @__PURE__ */ jsx190(\"div\", {\n        style: padder\n      }),\n      sequence.parent && nestedDepth > 0 ? /* @__PURE__ */ jsx190(\"div\", {\n        style: space\n      }) : null,\n      /* @__PURE__ */ jsx190(TimelineStack, {\n        sequence,\n        isCompact\n      })\n    ]\n  });\n};\n\n// src/components/Timeline/TimelineTimeIndicators.tsx\nimport { useContext as useContext66, useEffect as useEffect67, useMemo as useMemo103, useRef as useRef37 } from \"react\";\nimport { Internals as Internals50 } from \"remotion\";\n\n// src/components/TimeValue.tsx\nimport { PlayerInternals as PlayerInternals17 } from \"@remotion/player\";\nimport {\n  useCallback as useCallback98,\n  useEffect as useEffect66,\n  useImperativeHandle as useImperativeHandle13,\n  useRef as useRef36\n} from \"react\";\nimport { Internals as Internals49, useCurrentFrame } from \"remotion\";\nimport { jsx as jsx191, jsxs as jsxs93 } from \"react/jsx-runtime\";\nvar text = {\n  color: \"white\",\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  fontVariantNumeric: \"tabular-nums\",\n  lineHeight: 1,\n  width: \"100%\",\n  userSelect: \"none\",\n  WebkitUserSelect: \"none\"\n};\nvar time = {\n  display: \"inline-block\",\n  fontSize: 16,\n  lineHeight: 1,\n  fontFamily: \"monospace\"\n};\nvar frameStyle = {\n  color: LIGHT_TEXT,\n  fontWeight: 500,\n  lineHeight: 1,\n  fontSize: 16,\n  fontFamily: \"monospace\",\n  paddingRight: 10\n};\nvar TimeValue = () => {\n  const frame2 = useCurrentFrame();\n  const config = Internals49.useUnsafeVideoConfig();\n  const isStill = useIsStill();\n  const { seek, play, pause, toggle } = PlayerInternals17.usePlayer();\n  const keybindings = useKeybinding();\n  const ref = useRef36(null);\n  const onTextChange = useCallback98((newVal) => {\n    seek(parseInt(newVal, 10));\n  }, [seek]);\n  const onValueChange = useCallback98((val) => {\n    seek(val);\n  }, [seek]);\n  useImperativeHandle13(Internals49.timeValueRef, () => ({\n    goToFrame: () => {\n      ref.current?.click();\n    },\n    seek,\n    play,\n    pause,\n    toggle\n  }), [seek, play, pause, toggle]);\n  useEffect66(() => {\n    const gKey = keybindings.registerKeybinding({\n      event: \"keypress\",\n      key: \"g\",\n      callback: () => {\n        ref.current?.click();\n      },\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      gKey.unregister();\n    };\n  }, [keybindings]);\n  if (!config) {\n    return null;\n  }\n  if (isStill) {\n    return null;\n  }\n  return /* @__PURE__ */ jsxs93(\"div\", {\n    style: text,\n    children: [\n      /* @__PURE__ */ jsx191(\"div\", {\n        style: time,\n        children: renderFrame(frame2, config.fps)\n      }),\n      /* @__PURE__ */ jsx191(Spacing, {\n        x: 2\n      }),\n      /* @__PURE__ */ jsx191(Flex, {}),\n      /* @__PURE__ */ jsx191(InputDragger, {\n        ref,\n        value: frame2,\n        onTextChange,\n        onValueChange,\n        rightAlign: true,\n        status: \"ok\",\n        style: frameStyle\n      })\n    ]\n  });\n};\n\n// src/components/Timeline/TimelineTimeIndicators.tsx\nimport { jsx as jsx192 } from \"react/jsx-runtime\";\nvar TIMELINE_TIME_INDICATOR_HEIGHT = 39;\nvar container40 = {\n  height: TIMELINE_TIME_INDICATOR_HEIGHT - 4,\n  boxShadow: `0 0 4px ${TIMELINE_BACKGROUND}`,\n  position: \"absolute\",\n  backgroundColor: TIMELINE_BACKGROUND,\n  top: 0\n};\nvar tick = {\n  width: 1,\n  backgroundColor: \"rgba(255, 255, 255, 0.15)\",\n  height: 20,\n  position: \"absolute\"\n};\nvar secondTick = {\n  ...tick,\n  height: 15\n};\nvar tickLabel = {\n  fontSize: 12,\n  marginLeft: 8,\n  marginTop: 7,\n  color: LIGHT_TEXT\n};\nvar timeValue = {\n  height: TIMELINE_TIME_INDICATOR_HEIGHT,\n  position: \"absolute\",\n  top: 0,\n  width: \"100%\",\n  paddingLeft: 10,\n  display: \"flex\",\n  alignItems: \"center\",\n  backgroundColor: BACKGROUND,\n  borderBottom: `${TIMELINE_ITEM_BORDER_BOTTOM}px solid ${TIMELINE_TRACK_SEPARATOR}`\n};\nvar TimelineTimePlaceholders = () => {\n  return /* @__PURE__ */ jsx192(\"div\", {\n    style: timeValue,\n    children: /* @__PURE__ */ jsx192(TimeValue, {})\n  });\n};\nvar TimelineTimePadding = () => {\n  return /* @__PURE__ */ jsx192(\"div\", {\n    style: {\n      height: TIMELINE_TIME_INDICATOR_HEIGHT\n    }\n  });\n};\nvar TimelineTimeIndicators = () => {\n  const sliderTrack = useContext66(TimelineWidthContext);\n  const video = Internals50.useVideo();\n  if (sliderTrack === null) {\n    return null;\n  }\n  if (video === null) {\n    return null;\n  }\n  return /* @__PURE__ */ jsx192(Inner3, {\n    durationInFrames: video.durationInFrames,\n    fps: video.fps,\n    windowWidth: sliderTrack\n  });\n};\nvar Inner3 = ({ windowWidth, durationInFrames, fps }) => {\n  const ref = useRef37(null);\n  useEffect67(() => {\n    const currentRef = ref.current;\n    if (!currentRef) {\n      return;\n    }\n    const { current } = timelineVerticalScroll;\n    if (!current) {\n      return;\n    }\n    const onScroll = () => {\n      currentRef.style.top = current.scrollTop + \"px\";\n    };\n    current.addEventListener(\"scroll\", onScroll);\n    return () => {\n      current.removeEventListener(\"scroll\", onScroll);\n    };\n  }, []);\n  const style11 = useMemo103(() => {\n    return {\n      ...container40,\n      width: windowWidth - SPLITTER_HANDLE_SIZE / 2,\n      overflow: \"hidden\",\n      marginLeft: SPLITTER_HANDLE_SIZE / 2,\n      pointerEvents: \"none\"\n    };\n  }, [windowWidth]);\n  const ticks = useMemo103(() => {\n    const frameInterval = getFrameIncrementFromWidth(durationInFrames, windowWidth);\n    const MIN_SPACING_BETWEEN_TICKS_PX = 5;\n    const seconds = Math.floor(durationInFrames / fps);\n    const secondMarkerEveryNth = Math.ceil(MIN_SPACING_BETWEEN_TICKS_PX * fps / (frameInterval * fps));\n    const frameMarkerEveryNth = Math.ceil(MIN_SPACING_BETWEEN_TICKS_PX / frameInterval);\n    const secondTicks = new Array(seconds).fill(true).map((_, index) => {\n      return {\n        frame: index * fps,\n        style: {\n          ...secondTick,\n          left: frameInterval * index * fps + TIMELINE_PADDING - SPLITTER_HANDLE_SIZE / 2\n        },\n        showTime: index > 0\n      };\n    }).filter((_, idx) => idx % secondMarkerEveryNth === 0);\n    const frameTicks = new Array(durationInFrames).fill(true).map((_, index) => {\n      return {\n        frame: index,\n        style: {\n          ...tick,\n          left: frameInterval * index + TIMELINE_PADDING - SPLITTER_HANDLE_SIZE / 2,\n          height: index % fps === 0 ? 10 : index / frameMarkerEveryNth % 2 === 0 ? 5 : 2\n        },\n        showTime: false\n      };\n    }).filter((_, idx) => idx % frameMarkerEveryNth === 0);\n    const hasTicks = [];\n    return [...secondTicks, ...frameTicks].filter((t) => {\n      const alreadyUsed = hasTicks.find((ht) => ht === t.frame) !== undefined;\n      hasTicks.push(t.frame);\n      return !alreadyUsed;\n    });\n  }, [durationInFrames, fps, windowWidth]);\n  return /* @__PURE__ */ jsx192(\"div\", {\n    ref,\n    style: style11,\n    children: ticks.map((t) => {\n      return /* @__PURE__ */ jsx192(\"div\", {\n        style: t.style,\n        children: t.showTime ? /* @__PURE__ */ jsx192(\"div\", {\n          style: tickLabel,\n          children: renderFrame(t.frame, fps)\n        }) : null\n      }, t.frame);\n    })\n  });\n};\n\n// src/components/Timeline/TimelineList.tsx\nimport { jsx as jsx193, jsxs as jsxs94 } from \"react/jsx-runtime\";\nvar container41 = {\n  flex: 1,\n  background: BACKGROUND\n};\nvar TimelineList = ({ timeline }) => {\n  const ref = useRef38(null);\n  const size4 = PlayerInternals18.useElementSize(ref, {\n    shouldApplyCssTransforms: false,\n    triggerOnWindowResize: false\n  });\n  const isCompact = size4 ? size4.width < 250 : false;\n  return /* @__PURE__ */ jsxs94(\"div\", {\n    ref,\n    style: container41,\n    children: [\n      /* @__PURE__ */ jsx193(TimelineTimePadding, {}),\n      timeline.map((track) => {\n        return /* @__PURE__ */ jsx193(\"div\", {\n          children: /* @__PURE__ */ jsx193(TimelineListItem, {\n            nestedDepth: track.depth,\n            sequence: track.sequence,\n            isCompact\n          }, track.sequence.id)\n        }, track.sequence.id);\n      })\n    ]\n  });\n};\n\n// src/components/Timeline/TimelinePlayCursorSyncer.tsx\nimport { useContext as useContext67, useEffect as useEffect68 } from \"react\";\nimport { Internals as Internals51 } from \"remotion\";\nvar lastTimelinePositionWhileScrolling = null;\nvar TimelinePlayCursorSyncer = () => {\n  const video = Internals51.useVideo();\n  const timelineContext = useContext67(Internals51.TimelineContext);\n  const timelinePosition = Internals51.Timeline.useTimelinePosition();\n  const { canvasContent } = useContext67(Internals51.CompositionManager);\n  const { zoom: zoomMap } = useContext67(TimelineZoomCtx);\n  const compositionId = canvasContent && canvasContent.type === \"composition\" ? canvasContent.compositionId : null;\n  const zoom = compositionId ? zoomMap[compositionId] ?? TIMELINE_MIN_ZOOM : null;\n  if (zoom && video) {\n    setCurrentFrame(timelinePosition);\n    setCurrentZoom(zoom);\n    setCurrentDuration(video.durationInFrames);\n    setCurrentFps(video.fps);\n  }\n  const playing = timelineContext.playing ?? false;\n  useEffect68(() => {\n    if (!video) {\n      return;\n    }\n    if (!playing) {\n      return;\n    }\n    ensureFrameIsInViewport({\n      direction: timelineContext.playbackRate > 0 ? \"page-right\" : \"page-left\",\n      durationInFrames: video.durationInFrames,\n      frame: timelinePosition\n    });\n  }, [playing, timelineContext, timelinePosition, video]);\n  useEffect68(() => {\n    const { current } = scrollableRef;\n    if (!current) {\n      return;\n    }\n    if (playing) {\n      lastTimelinePositionWhileScrolling = {\n        scrollLeft: current.scrollLeft,\n        frame: getCurrentFrame(),\n        zoomLevel: getCurrentZoom(),\n        durationInFrames: getCurrentDuration()\n      };\n    } else if (lastTimelinePositionWhileScrolling !== null) {\n      if (isCursorInViewport({\n        frame: getCurrentFrame(),\n        durationInFrames: getCurrentDuration()\n      })) {\n        return;\n      }\n      if (lastTimelinePositionWhileScrolling.zoomLevel === getCurrentZoom() && lastTimelinePositionWhileScrolling.durationInFrames === getCurrentDuration()) {\n        current.scrollLeft = lastTimelinePositionWhileScrolling.scrollLeft;\n      } else {\n        ensureFrameIsInViewport({\n          direction: \"center\",\n          durationInFrames: getCurrentDuration(),\n          frame: lastTimelinePositionWhileScrolling.frame\n        });\n      }\n    }\n  }, [playing]);\n  return null;\n};\n\n// src/components/Timeline/TimelineScrollable.tsx\nimport { useMemo as useMemo104 } from \"react\";\nimport { jsx as jsx194 } from \"react/jsx-runtime\";\nvar outer2 = {\n  width: \"100%\",\n  height: \"100%\",\n  overflowX: \"auto\",\n  overflowY: \"hidden\",\n  position: \"relative\",\n  backgroundColor: TIMELINE_BACKGROUND\n};\nvar TimelineScrollable = ({ children }) => {\n  const containerStyle3 = useMemo104(() => {\n    return {\n      width: \"100%\",\n      minHeight: \"100%\"\n    };\n  }, []);\n  return /* @__PURE__ */ jsx194(\"div\", {\n    ref: scrollableRef,\n    style: outer2,\n    className: HORIZONTAL_SCROLLBAR_CLASSNAME,\n    children: /* @__PURE__ */ jsx194(\"div\", {\n      style: containerStyle3,\n      children\n    })\n  });\n};\n\n// src/components/Timeline/TimelineTracks.tsx\nimport { useMemo as useMemo108 } from \"react\";\n\n// src/components/Timeline/TimelineSequence.tsx\nimport { useContext as useContext68, useMemo as useMemo107 } from \"react\";\nimport { Internals as Internals53, useCurrentFrame as useCurrentFrame2 } from \"remotion\";\n\n// src/helpers/get-timeline-sequence-layout.ts\nvar SEQUENCE_BORDER_WIDTH = 1;\nvar getWidthOfTrack = ({\n  durationInFrames,\n  lastFrame,\n  windowWidth,\n  spatialDuration,\n  nonNegativeMarginLeft\n}) => {\n  const fullWidth9 = windowWidth - TIMELINE_PADDING * 2;\n  const base = durationInFrames === Infinity || lastFrame === 0 ? fullWidth9 : spatialDuration / lastFrame * fullWidth9;\n  return base - SEQUENCE_BORDER_WIDTH + nonNegativeMarginLeft;\n};\nvar getTimelineSequenceLayout = ({\n  durationInFrames,\n  startFrom,\n  maxMediaDuration,\n  startFromMedia,\n  video,\n  windowWidth,\n  premountDisplay,\n  postmountDisplay\n}) => {\n  const maxMediaSequenceDuration = (maxMediaDuration ?? Infinity) - startFromMedia;\n  const lastFrame = (video.durationInFrames ?? 1) - 1;\n  let spatialDuration = Math.min(maxMediaSequenceDuration, durationInFrames - 1, lastFrame - startFrom);\n  const shouldAddHalfAFrameAtEnd = startFrom + durationInFrames < lastFrame;\n  const shouldAddHalfAFrameAtStart = startFrom > 0;\n  if (shouldAddHalfAFrameAtEnd) {\n    spatialDuration += 0.5;\n  }\n  if (shouldAddHalfAFrameAtStart) {\n    spatialDuration += 0.5;\n  }\n  const startFromWithOffset = shouldAddHalfAFrameAtStart ? startFrom - 0.5 : startFrom;\n  const marginLeft = lastFrame === 0 ? 0 : startFromWithOffset / lastFrame * (windowWidth - TIMELINE_PADDING * 2);\n  const nonNegativeMarginLeft = Math.min(marginLeft, 0);\n  const width = getWidthOfTrack({\n    durationInFrames,\n    lastFrame,\n    nonNegativeMarginLeft,\n    spatialDuration,\n    windowWidth\n  });\n  const premountWidth = premountDisplay ? getWidthOfTrack({\n    durationInFrames: premountDisplay,\n    lastFrame,\n    nonNegativeMarginLeft,\n    spatialDuration: premountDisplay,\n    windowWidth\n  }) : null;\n  const postmountWidth = postmountDisplay ? getWidthOfTrack({\n    durationInFrames: postmountDisplay,\n    lastFrame,\n    nonNegativeMarginLeft,\n    spatialDuration: postmountDisplay,\n    windowWidth\n  }) : null;\n  return {\n    marginLeft: Math.max(marginLeft, 0) - (premountWidth ?? 0),\n    width: width + (premountWidth ?? 0) + (postmountWidth ?? 0),\n    premountWidth,\n    postmountWidth\n  };\n};\n\n// src/helpers/use-max-media-duration.ts\nimport { getVideoMetadata as getVideoMetadata2 } from \"@remotion/media-utils\";\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/misc.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nfunction assert(x) {\n  if (!x) {\n    throw new Error(\"Assertion failed.\");\n  }\n}\nvar normalizeRotation = (rotation) => {\n  const mappedRotation = (rotation % 360 + 360) % 360;\n  if (mappedRotation === 0 || mappedRotation === 90 || mappedRotation === 180 || mappedRotation === 270) {\n    return mappedRotation;\n  } else {\n    throw new Error(`Invalid rotation ${rotation}.`);\n  }\n};\nvar last = (arr) => {\n  return arr && arr[arr.length - 1];\n};\nclass Bitstream {\n  constructor(bytes) {\n    this.bytes = bytes;\n    this.pos = 0;\n  }\n  seekToByte(byteOffset) {\n    this.pos = 8 * byteOffset;\n  }\n  readBit() {\n    const byteIndex = Math.floor(this.pos / 8);\n    const byte = this.bytes[byteIndex] ?? 0;\n    const bitIndex = 7 - (this.pos & 7);\n    const bit = (byte & 1 << bitIndex) >> bitIndex;\n    this.pos++;\n    return bit;\n  }\n  readBits(n) {\n    if (n === 1) {\n      return this.readBit();\n    }\n    let result = 0;\n    for (let i = 0;i < n; i++) {\n      result <<= 1;\n      result |= this.readBit();\n    }\n    return result;\n  }\n  writeBits(n, value) {\n    const end = this.pos + n;\n    for (let i = this.pos;i < end; i++) {\n      const byteIndex = Math.floor(i / 8);\n      let byte = this.bytes[byteIndex];\n      const bitIndex = 7 - (i & 7);\n      byte &= ~(1 << bitIndex);\n      byte |= (value & 1 << end - i - 1) >> end - i - 1 << bitIndex;\n      this.bytes[byteIndex] = byte;\n    }\n    this.pos = end;\n  }\n  readAlignedByte() {\n    if (this.pos % 8 !== 0) {\n      throw new Error(\"Bitstream is not byte-aligned.\");\n    }\n    const byteIndex = this.pos / 8;\n    const byte = this.bytes[byteIndex] ?? 0;\n    this.pos += 8;\n    return byte;\n  }\n  skipBits(n) {\n    this.pos += n;\n  }\n  getBitsLeft() {\n    return this.bytes.length * 8 - this.pos;\n  }\n  clone() {\n    const clone = new Bitstream(this.bytes);\n    clone.pos = this.pos;\n    return clone;\n  }\n}\nvar readExpGolomb = (bitstream) => {\n  let leadingZeroBits = 0;\n  while (bitstream.readBits(1) === 0 && leadingZeroBits < 32) {\n    leadingZeroBits++;\n  }\n  if (leadingZeroBits >= 32) {\n    throw new Error(\"Invalid exponential-Golomb code.\");\n  }\n  const result = (1 << leadingZeroBits) - 1 + bitstream.readBits(leadingZeroBits);\n  return result;\n};\nvar readSignedExpGolomb = (bitstream) => {\n  const codeNum = readExpGolomb(bitstream);\n  return (codeNum & 1) === 0 ? -(codeNum >> 1) : codeNum + 1 >> 1;\n};\nvar toUint8Array = (source) => {\n  if (source.constructor === Uint8Array) {\n    return source;\n  } else if (ArrayBuffer.isView(source)) {\n    return new Uint8Array(source.buffer, source.byteOffset, source.byteLength);\n  } else {\n    return new Uint8Array(source);\n  }\n};\nvar toDataView = (source) => {\n  if (source.constructor === DataView) {\n    return source;\n  } else if (ArrayBuffer.isView(source)) {\n    return new DataView(source.buffer, source.byteOffset, source.byteLength);\n  } else {\n    return new DataView(source);\n  }\n};\nvar textDecoder = /* @__PURE__ */ new TextDecoder;\nvar invertObject = (object) => {\n  return Object.fromEntries(Object.entries(object).map(([key4, value]) => [value, key4]));\n};\nvar COLOR_PRIMARIES_MAP = {\n  bt709: 1,\n  bt470bg: 5,\n  smpte170m: 6,\n  bt2020: 9,\n  smpte432: 12\n};\nvar COLOR_PRIMARIES_MAP_INVERSE = /* @__PURE__ */ invertObject(COLOR_PRIMARIES_MAP);\nvar TRANSFER_CHARACTERISTICS_MAP = {\n  bt709: 1,\n  smpte170m: 6,\n  linear: 8,\n  \"iec61966-2-1\": 13,\n  pq: 16,\n  hlg: 18\n};\nvar TRANSFER_CHARACTERISTICS_MAP_INVERSE = /* @__PURE__ */ invertObject(TRANSFER_CHARACTERISTICS_MAP);\nvar MATRIX_COEFFICIENTS_MAP = {\n  rgb: 0,\n  bt709: 1,\n  bt470bg: 5,\n  smpte170m: 6,\n  \"bt2020-ncl\": 9\n};\nvar MATRIX_COEFFICIENTS_MAP_INVERSE = /* @__PURE__ */ invertObject(MATRIX_COEFFICIENTS_MAP);\nvar isAllowSharedBufferSource = (x) => {\n  return x instanceof ArrayBuffer || typeof SharedArrayBuffer !== \"undefined\" && x instanceof SharedArrayBuffer || ArrayBuffer.isView(x);\n};\n\nclass AsyncMutex {\n  constructor() {\n    this.currentPromise = Promise.resolve();\n    this.pending = 0;\n  }\n  async acquire() {\n    let resolver;\n    const nextPromise = new Promise((resolve) => {\n      let resolved = false;\n      resolver = () => {\n        if (resolved) {\n          return;\n        }\n        resolve();\n        this.pending--;\n        resolved = true;\n      };\n    });\n    const currentPromiseAlias = this.currentPromise;\n    this.currentPromise = nextPromise;\n    this.pending++;\n    await currentPromiseAlias;\n    return resolver;\n  }\n}\nvar bytesToHexString = (bytes) => {\n  return [...bytes].map((x) => x.toString(16).padStart(2, \"0\")).join(\"\");\n};\nvar reverseBitsU32 = (x) => {\n  x = x >> 1 & 1431655765 | (x & 1431655765) << 1;\n  x = x >> 2 & 858993459 | (x & 858993459) << 2;\n  x = x >> 4 & 252645135 | (x & 252645135) << 4;\n  x = x >> 8 & 16711935 | (x & 16711935) << 8;\n  x = x >> 16 & 65535 | (x & 65535) << 16;\n  return x >>> 0;\n};\nvar binarySearchExact = (arr, key4, valueGetter) => {\n  let low = 0;\n  let high = arr.length - 1;\n  let ans = -1;\n  while (low <= high) {\n    const mid = low + high >> 1;\n    const midVal = valueGetter(arr[mid]);\n    if (midVal === key4) {\n      ans = mid;\n      high = mid - 1;\n    } else if (midVal < key4) {\n      low = mid + 1;\n    } else {\n      high = mid - 1;\n    }\n  }\n  return ans;\n};\nvar binarySearchLessOrEqual = (arr, key4, valueGetter) => {\n  let low = 0;\n  let high = arr.length - 1;\n  let ans = -1;\n  while (low <= high) {\n    const mid = low + (high - low + 1) / 2 | 0;\n    const midVal = valueGetter(arr[mid]);\n    if (midVal <= key4) {\n      ans = mid;\n      low = mid + 1;\n    } else {\n      high = mid - 1;\n    }\n  }\n  return ans;\n};\nvar insertSorted = (arr, item2, valueGetter) => {\n  const insertionIndex = binarySearchLessOrEqual(arr, valueGetter(item2), valueGetter);\n  arr.splice(insertionIndex + 1, 0, item2);\n};\nvar promiseWithResolvers = () => {\n  let resolve;\n  let reject;\n  const promise = new Promise((res, rej) => {\n    resolve = res;\n    reject = rej;\n  });\n  return { promise, resolve, reject };\n};\nvar findLast = (arr, predicate) => {\n  for (let i = arr.length - 1;i >= 0; i--) {\n    if (predicate(arr[i])) {\n      return arr[i];\n    }\n  }\n  return;\n};\nvar findLastIndex = (arr, predicate) => {\n  for (let i = arr.length - 1;i >= 0; i--) {\n    if (predicate(arr[i])) {\n      return i;\n    }\n  }\n  return -1;\n};\nvar toAsyncIterator = async function* (source) {\n  if (Symbol.iterator in source) {\n    yield* source[Symbol.iterator]();\n  } else {\n    yield* source[Symbol.asyncIterator]();\n  }\n};\nvar validateAnyIterable = (iterable) => {\n  if (!(Symbol.iterator in iterable) && !(Symbol.asyncIterator in iterable)) {\n    throw new TypeError(\"Argument must be an iterable or async iterable.\");\n  }\n};\nvar assertNever = (x) => {\n  throw new Error(`Unexpected value: ${x}`);\n};\nvar getUint24 = (view, byteOffset, littleEndian) => {\n  const byte1 = view.getUint8(byteOffset);\n  const byte2 = view.getUint8(byteOffset + 1);\n  const byte3 = view.getUint8(byteOffset + 2);\n  if (littleEndian) {\n    return byte1 | byte2 << 8 | byte3 << 16;\n  } else {\n    return byte1 << 16 | byte2 << 8 | byte3;\n  }\n};\nvar setUint24 = (view, byteOffset, value, littleEndian) => {\n  value = value >>> 0;\n  value = value & 16777215;\n  if (littleEndian) {\n    view.setUint8(byteOffset, value & 255);\n    view.setUint8(byteOffset + 1, value >>> 8 & 255);\n    view.setUint8(byteOffset + 2, value >>> 16 & 255);\n  } else {\n    view.setUint8(byteOffset, value >>> 16 & 255);\n    view.setUint8(byteOffset + 1, value >>> 8 & 255);\n    view.setUint8(byteOffset + 2, value & 255);\n  }\n};\nvar clamp = (value, min, max) => {\n  return Math.max(min, Math.min(max, value));\n};\nvar UNDETERMINED_LANGUAGE = \"und\";\nvar roundIfAlmostInteger = (value) => {\n  const rounded = Math.round(value);\n  if (Math.abs(value / rounded - 1) < 10 * Number.EPSILON) {\n    return rounded;\n  } else {\n    return value;\n  }\n};\nvar roundToMultiple = (value, multiple) => {\n  return Math.round(value / multiple) * multiple;\n};\nvar ilog = (x) => {\n  let ret = 0;\n  while (x) {\n    ret++;\n    x >>= 1;\n  }\n  return ret;\n};\nvar ISO_639_2_REGEX = /^[a-z]{3}$/;\nvar isIso639Dash2LanguageCode = (x) => {\n  return ISO_639_2_REGEX.test(x);\n};\nvar SECOND_TO_MICROSECOND_FACTOR = 1e6 * (1 + Number.EPSILON);\nvar mergeRequestInit = (init1, init2) => {\n  const merged = { ...init1, ...init2 };\n  if (init1.headers || init2.headers) {\n    const headers1 = init1.headers ? normalizeHeaders(init1.headers) : {};\n    const headers2 = init2.headers ? normalizeHeaders(init2.headers) : {};\n    const mergedHeaders = { ...headers1 };\n    Object.entries(headers2).forEach(([key22, value2]) => {\n      const existingKey = Object.keys(mergedHeaders).find((key1) => key1.toLowerCase() === key22.toLowerCase());\n      if (existingKey) {\n        delete mergedHeaders[existingKey];\n      }\n      mergedHeaders[key22] = value2;\n    });\n    merged.headers = mergedHeaders;\n  }\n  return merged;\n};\nvar normalizeHeaders = (headers) => {\n  if (headers instanceof Headers) {\n    const result = {};\n    headers.forEach((value, key4) => {\n      result[key4] = value;\n    });\n    return result;\n  }\n  if (Array.isArray(headers)) {\n    const result = {};\n    headers.forEach(([key4, value]) => {\n      result[key4] = value;\n    });\n    return result;\n  }\n  return headers;\n};\nvar retriedFetch = async (fetchFn, url, requestInit, getRetryDelay, shouldStop) => {\n  let attempts = 0;\n  while (true) {\n    try {\n      return await fetchFn(url, requestInit);\n    } catch (error) {\n      if (shouldStop()) {\n        throw error;\n      }\n      attempts++;\n      const retryDelayInSeconds = getRetryDelay(attempts, error, url);\n      if (retryDelayInSeconds === null) {\n        throw error;\n      }\n      console.error(\"Retrying failed fetch. Error:\", error);\n      if (!Number.isFinite(retryDelayInSeconds) || retryDelayInSeconds < 0) {\n        throw new TypeError(\"Retry delay must be a non-negative finite number.\");\n      }\n      if (retryDelayInSeconds > 0) {\n        await new Promise((resolve) => setTimeout(resolve, 1000 * retryDelayInSeconds));\n      }\n      if (shouldStop()) {\n        throw error;\n      }\n    }\n  }\n};\nclass CallSerializer {\n  constructor() {\n    this.currentPromise = Promise.resolve();\n  }\n  call(fn) {\n    return this.currentPromise = this.currentPromise.then(fn);\n  }\n}\nvar isWebKitCache = null;\nvar isWebKit = () => {\n  if (isWebKitCache !== null) {\n    return isWebKitCache;\n  }\n  return isWebKitCache = !!(typeof navigator !== \"undefined\" && (navigator.vendor?.match(/apple/i) || /AppleWebKit/.test(navigator.userAgent) && !/Chrome/.test(navigator.userAgent) || /\\b(iPad|iPhone|iPod)\\b/.test(navigator.userAgent)));\n};\nvar isFirefoxCache = null;\nvar isFirefox = () => {\n  if (isFirefoxCache !== null) {\n    return isFirefoxCache;\n  }\n  return isFirefoxCache = typeof navigator !== \"undefined\" && navigator.userAgent?.includes(\"Firefox\");\n};\nvar isChromiumCache = null;\nvar isChromium = () => {\n  if (isChromiumCache !== null) {\n    return isChromiumCache;\n  }\n  return isChromiumCache = !!(typeof navigator !== \"undefined\" && (navigator.vendor?.includes(\"Google Inc\") || /Chrome/.test(navigator.userAgent)));\n};\nvar chromiumVersionCache = null;\nvar getChromiumVersion = () => {\n  if (chromiumVersionCache !== null) {\n    return chromiumVersionCache;\n  }\n  if (typeof navigator === \"undefined\") {\n    return null;\n  }\n  const match = /\\bChrome\\/(\\d+)/.exec(navigator.userAgent);\n  if (!match) {\n    return null;\n  }\n  return chromiumVersionCache = Number(match[1]);\n};\nvar coalesceIndex = (a, b) => {\n  return a !== -1 ? a : b;\n};\nvar closedIntervalsOverlap = (startA, endA, startB, endB) => {\n  return startA <= endB && startB <= endA;\n};\nvar base64ToBytes = (base64) => {\n  const decoded = atob(base64);\n  const bytes = new Uint8Array(decoded.length);\n  for (let i = 0;i < decoded.length; i++) {\n    bytes[i] = decoded.charCodeAt(i);\n  }\n  return bytes;\n};\nvar polyfillSymbolDispose = () => {\n  Symbol.dispose ??= Symbol(\"Symbol.dispose\");\n};\nvar isNumber = (x) => {\n  return typeof x === \"number\" && !Number.isNaN(x);\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/metadata.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\nclass RichImageData {\n  constructor(data, mimeType) {\n    this.data = data;\n    this.mimeType = mimeType;\n    if (!(data instanceof Uint8Array)) {\n      throw new TypeError(\"data must be a Uint8Array.\");\n    }\n    if (typeof mimeType !== \"string\") {\n      throw new TypeError(\"mimeType must be a string.\");\n    }\n  }\n}\n\nclass AttachedFile {\n  constructor(data, mimeType, name, description) {\n    this.data = data;\n    this.mimeType = mimeType;\n    this.name = name;\n    this.description = description;\n    if (!(data instanceof Uint8Array)) {\n      throw new TypeError(\"data must be a Uint8Array.\");\n    }\n    if (mimeType !== undefined && typeof mimeType !== \"string\") {\n      throw new TypeError(\"mimeType, when provided, must be a string.\");\n    }\n    if (name !== undefined && typeof name !== \"string\") {\n      throw new TypeError(\"name, when provided, must be a string.\");\n    }\n    if (description !== undefined && typeof description !== \"string\") {\n      throw new TypeError(\"description, when provided, must be a string.\");\n    }\n  }\n}\nvar DEFAULT_TRACK_DISPOSITION = {\n  default: true,\n  forced: false,\n  original: false,\n  commentary: false,\n  hearingImpaired: false,\n  visuallyImpaired: false\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/codec.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar PCM_AUDIO_CODECS = [\n  \"pcm-s16\",\n  \"pcm-s16be\",\n  \"pcm-s24\",\n  \"pcm-s24be\",\n  \"pcm-s32\",\n  \"pcm-s32be\",\n  \"pcm-f32\",\n  \"pcm-f32be\",\n  \"pcm-f64\",\n  \"pcm-f64be\",\n  \"pcm-u8\",\n  \"pcm-s8\",\n  \"ulaw\",\n  \"alaw\"\n];\nvar NON_PCM_AUDIO_CODECS = [\n  \"aac\",\n  \"opus\",\n  \"mp3\",\n  \"vorbis\",\n  \"flac\"\n];\nvar AUDIO_CODECS = [\n  ...NON_PCM_AUDIO_CODECS,\n  ...PCM_AUDIO_CODECS\n];\nvar AVC_LEVEL_TABLE = [\n  { maxMacroblocks: 99, maxBitrate: 64000, maxDpbMbs: 396, level: 10 },\n  { maxMacroblocks: 396, maxBitrate: 192000, maxDpbMbs: 900, level: 11 },\n  { maxMacroblocks: 396, maxBitrate: 384000, maxDpbMbs: 2376, level: 12 },\n  { maxMacroblocks: 396, maxBitrate: 768000, maxDpbMbs: 2376, level: 13 },\n  { maxMacroblocks: 396, maxBitrate: 2000000, maxDpbMbs: 2376, level: 20 },\n  { maxMacroblocks: 792, maxBitrate: 4000000, maxDpbMbs: 4752, level: 21 },\n  { maxMacroblocks: 1620, maxBitrate: 4000000, maxDpbMbs: 8100, level: 22 },\n  { maxMacroblocks: 1620, maxBitrate: 1e7, maxDpbMbs: 8100, level: 30 },\n  { maxMacroblocks: 3600, maxBitrate: 14000000, maxDpbMbs: 18000, level: 31 },\n  { maxMacroblocks: 5120, maxBitrate: 20000000, maxDpbMbs: 20480, level: 32 },\n  { maxMacroblocks: 8192, maxBitrate: 20000000, maxDpbMbs: 32768, level: 40 },\n  { maxMacroblocks: 8192, maxBitrate: 50000000, maxDpbMbs: 32768, level: 41 },\n  { maxMacroblocks: 8704, maxBitrate: 50000000, maxDpbMbs: 34816, level: 42 },\n  { maxMacroblocks: 22080, maxBitrate: 135000000, maxDpbMbs: 110400, level: 50 },\n  { maxMacroblocks: 36864, maxBitrate: 240000000, maxDpbMbs: 184320, level: 51 },\n  { maxMacroblocks: 36864, maxBitrate: 240000000, maxDpbMbs: 184320, level: 52 },\n  { maxMacroblocks: 139264, maxBitrate: 240000000, maxDpbMbs: 696320, level: 60 },\n  { maxMacroblocks: 139264, maxBitrate: 480000000, maxDpbMbs: 696320, level: 61 },\n  { maxMacroblocks: 139264, maxBitrate: 800000000, maxDpbMbs: 696320, level: 62 }\n];\nvar VP9_LEVEL_TABLE = [\n  { maxPictureSize: 36864, maxBitrate: 200000, level: 10 },\n  { maxPictureSize: 73728, maxBitrate: 800000, level: 11 },\n  { maxPictureSize: 122880, maxBitrate: 1800000, level: 20 },\n  { maxPictureSize: 245760, maxBitrate: 3600000, level: 21 },\n  { maxPictureSize: 552960, maxBitrate: 7200000, level: 30 },\n  { maxPictureSize: 983040, maxBitrate: 12000000, level: 31 },\n  { maxPictureSize: 2228224, maxBitrate: 18000000, level: 40 },\n  { maxPictureSize: 2228224, maxBitrate: 30000000, level: 41 },\n  { maxPictureSize: 8912896, maxBitrate: 60000000, level: 50 },\n  { maxPictureSize: 8912896, maxBitrate: 120000000, level: 51 },\n  { maxPictureSize: 8912896, maxBitrate: 180000000, level: 52 },\n  { maxPictureSize: 35651584, maxBitrate: 180000000, level: 60 },\n  { maxPictureSize: 35651584, maxBitrate: 240000000, level: 61 },\n  { maxPictureSize: 35651584, maxBitrate: 480000000, level: 62 }\n];\nvar VP9_DEFAULT_SUFFIX = \".01.01.01.01.00\";\nvar AV1_DEFAULT_SUFFIX = \".0.110.01.01.01.0\";\nvar extractVideoCodecString = (trackInfo) => {\n  const { codec, codecDescription, colorSpace, avcCodecInfo, hevcCodecInfo, vp9CodecInfo, av1CodecInfo } = trackInfo;\n  if (codec === \"avc\") {\n    assert(trackInfo.avcType !== null);\n    if (avcCodecInfo) {\n      const bytes = new Uint8Array([\n        avcCodecInfo.avcProfileIndication,\n        avcCodecInfo.profileCompatibility,\n        avcCodecInfo.avcLevelIndication\n      ]);\n      return `avc${trackInfo.avcType}.${bytesToHexString(bytes)}`;\n    }\n    if (!codecDescription || codecDescription.byteLength < 4) {\n      throw new TypeError(\"AVC decoder description is not provided or is not at least 4 bytes long.\");\n    }\n    return `avc${trackInfo.avcType}.${bytesToHexString(codecDescription.subarray(1, 4))}`;\n  } else if (codec === \"hevc\") {\n    let generalProfileSpace;\n    let generalProfileIdc;\n    let compatibilityFlags;\n    let generalTierFlag;\n    let generalLevelIdc;\n    let constraintFlags;\n    if (hevcCodecInfo) {\n      generalProfileSpace = hevcCodecInfo.generalProfileSpace;\n      generalProfileIdc = hevcCodecInfo.generalProfileIdc;\n      compatibilityFlags = reverseBitsU32(hevcCodecInfo.generalProfileCompatibilityFlags);\n      generalTierFlag = hevcCodecInfo.generalTierFlag;\n      generalLevelIdc = hevcCodecInfo.generalLevelIdc;\n      constraintFlags = [...hevcCodecInfo.generalConstraintIndicatorFlags];\n    } else {\n      if (!codecDescription || codecDescription.byteLength < 23) {\n        throw new TypeError(\"HEVC decoder description is not provided or is not at least 23 bytes long.\");\n      }\n      const view = toDataView(codecDescription);\n      const profileByte = view.getUint8(1);\n      generalProfileSpace = profileByte >> 6 & 3;\n      generalProfileIdc = profileByte & 31;\n      compatibilityFlags = reverseBitsU32(view.getUint32(2));\n      generalTierFlag = profileByte >> 5 & 1;\n      generalLevelIdc = view.getUint8(12);\n      constraintFlags = [];\n      for (let i = 0;i < 6; i++) {\n        constraintFlags.push(view.getUint8(6 + i));\n      }\n    }\n    let codecString = \"hev1.\";\n    codecString += [\"\", \"A\", \"B\", \"C\"][generalProfileSpace] + generalProfileIdc;\n    codecString += \".\";\n    codecString += compatibilityFlags.toString(16).toUpperCase();\n    codecString += \".\";\n    codecString += generalTierFlag === 0 ? \"L\" : \"H\";\n    codecString += generalLevelIdc;\n    while (constraintFlags.length > 0 && constraintFlags[constraintFlags.length - 1] === 0) {\n      constraintFlags.pop();\n    }\n    if (constraintFlags.length > 0) {\n      codecString += \".\";\n      codecString += constraintFlags.map((x) => x.toString(16).toUpperCase()).join(\".\");\n    }\n    return codecString;\n  } else if (codec === \"vp8\") {\n    return \"vp8\";\n  } else if (codec === \"vp9\") {\n    if (!vp9CodecInfo) {\n      const pictureSize = trackInfo.width * trackInfo.height;\n      let level2 = last(VP9_LEVEL_TABLE).level;\n      for (const entry of VP9_LEVEL_TABLE) {\n        if (pictureSize <= entry.maxPictureSize) {\n          level2 = entry.level;\n          break;\n        }\n      }\n      return `vp09.00.${level2.toString().padStart(2, \"0\")}.08`;\n    }\n    const profile = vp9CodecInfo.profile.toString().padStart(2, \"0\");\n    const level = vp9CodecInfo.level.toString().padStart(2, \"0\");\n    const bitDepth = vp9CodecInfo.bitDepth.toString().padStart(2, \"0\");\n    const chromaSubsampling = vp9CodecInfo.chromaSubsampling.toString().padStart(2, \"0\");\n    const colourPrimaries = vp9CodecInfo.colourPrimaries.toString().padStart(2, \"0\");\n    const transferCharacteristics = vp9CodecInfo.transferCharacteristics.toString().padStart(2, \"0\");\n    const matrixCoefficients = vp9CodecInfo.matrixCoefficients.toString().padStart(2, \"0\");\n    const videoFullRangeFlag = vp9CodecInfo.videoFullRangeFlag.toString().padStart(2, \"0\");\n    let string = `vp09.${profile}.${level}.${bitDepth}.${chromaSubsampling}`;\n    string += `.${colourPrimaries}.${transferCharacteristics}.${matrixCoefficients}.${videoFullRangeFlag}`;\n    if (string.endsWith(VP9_DEFAULT_SUFFIX)) {\n      string = string.slice(0, -VP9_DEFAULT_SUFFIX.length);\n    }\n    return string;\n  } else if (codec === \"av1\") {\n    if (!av1CodecInfo) {\n      const pictureSize = trackInfo.width * trackInfo.height;\n      let level2 = last(VP9_LEVEL_TABLE).level;\n      for (const entry of VP9_LEVEL_TABLE) {\n        if (pictureSize <= entry.maxPictureSize) {\n          level2 = entry.level;\n          break;\n        }\n      }\n      return `av01.0.${level2.toString().padStart(2, \"0\")}M.08`;\n    }\n    const profile = av1CodecInfo.profile;\n    const level = av1CodecInfo.level.toString().padStart(2, \"0\");\n    const tier = av1CodecInfo.tier ? \"H\" : \"M\";\n    const bitDepth = av1CodecInfo.bitDepth.toString().padStart(2, \"0\");\n    const monochrome = av1CodecInfo.monochrome ? \"1\" : \"0\";\n    const chromaSubsampling = 100 * av1CodecInfo.chromaSubsamplingX + 10 * av1CodecInfo.chromaSubsamplingY + 1 * (av1CodecInfo.chromaSubsamplingX && av1CodecInfo.chromaSubsamplingY ? av1CodecInfo.chromaSamplePosition : 0);\n    const colorPrimaries = colorSpace?.primaries ? COLOR_PRIMARIES_MAP[colorSpace.primaries] : 1;\n    const transferCharacteristics = colorSpace?.transfer ? TRANSFER_CHARACTERISTICS_MAP[colorSpace.transfer] : 1;\n    const matrixCoefficients = colorSpace?.matrix ? MATRIX_COEFFICIENTS_MAP[colorSpace.matrix] : 1;\n    const videoFullRangeFlag = colorSpace?.fullRange ? 1 : 0;\n    let string = `av01.${profile}.${level}${tier}.${bitDepth}`;\n    string += `.${monochrome}.${chromaSubsampling.toString().padStart(3, \"0\")}`;\n    string += `.${colorPrimaries.toString().padStart(2, \"0\")}`;\n    string += `.${transferCharacteristics.toString().padStart(2, \"0\")}`;\n    string += `.${matrixCoefficients.toString().padStart(2, \"0\")}`;\n    string += `.${videoFullRangeFlag}`;\n    if (string.endsWith(AV1_DEFAULT_SUFFIX)) {\n      string = string.slice(0, -AV1_DEFAULT_SUFFIX.length);\n    }\n    return string;\n  }\n  throw new TypeError(`Unhandled codec '${codec}'.`);\n};\nvar extractAudioCodecString = (trackInfo) => {\n  const { codec, codecDescription, aacCodecInfo } = trackInfo;\n  if (codec === \"aac\") {\n    if (!aacCodecInfo) {\n      throw new TypeError(\"AAC codec info must be provided.\");\n    }\n    if (aacCodecInfo.isMpeg2) {\n      return \"mp4a.67\";\n    } else {\n      let objectType;\n      if (aacCodecInfo.objectType !== null) {\n        objectType = aacCodecInfo.objectType;\n      } else {\n        const audioSpecificConfig = parseAacAudioSpecificConfig(codecDescription);\n        objectType = audioSpecificConfig.objectType;\n      }\n      return `mp4a.40.${objectType}`;\n    }\n  } else if (codec === \"mp3\") {\n    return \"mp3\";\n  } else if (codec === \"opus\") {\n    return \"opus\";\n  } else if (codec === \"vorbis\") {\n    return \"vorbis\";\n  } else if (codec === \"flac\") {\n    return \"flac\";\n  } else if (codec && PCM_AUDIO_CODECS.includes(codec)) {\n    return codec;\n  }\n  throw new TypeError(`Unhandled codec '${codec}'.`);\n};\nvar aacFrequencyTable = [\n  96000,\n  88200,\n  64000,\n  48000,\n  44100,\n  32000,\n  24000,\n  22050,\n  16000,\n  12000,\n  11025,\n  8000,\n  7350\n];\nvar aacChannelMap = [-1, 1, 2, 3, 4, 5, 6, 8];\nvar parseAacAudioSpecificConfig = (bytes) => {\n  if (!bytes || bytes.byteLength < 2) {\n    throw new TypeError(\"AAC description must be at least 2 bytes long.\");\n  }\n  const bitstream = new Bitstream(bytes);\n  let objectType = bitstream.readBits(5);\n  if (objectType === 31) {\n    objectType = 32 + bitstream.readBits(6);\n  }\n  const frequencyIndex = bitstream.readBits(4);\n  let sampleRate = null;\n  if (frequencyIndex === 15) {\n    sampleRate = bitstream.readBits(24);\n  } else {\n    if (frequencyIndex < aacFrequencyTable.length) {\n      sampleRate = aacFrequencyTable[frequencyIndex];\n    }\n  }\n  const channelConfiguration = bitstream.readBits(4);\n  let numberOfChannels = null;\n  if (channelConfiguration >= 1 && channelConfiguration <= 7) {\n    numberOfChannels = aacChannelMap[channelConfiguration];\n  }\n  return {\n    objectType,\n    frequencyIndex,\n    sampleRate,\n    channelConfiguration,\n    numberOfChannels\n  };\n};\nvar OPUS_SAMPLE_RATE = 48000;\nvar PCM_CODEC_REGEX = /^pcm-([usf])(\\d+)+(be)?$/;\nvar parsePcmCodec = (codec) => {\n  assert(PCM_AUDIO_CODECS.includes(codec));\n  if (codec === \"ulaw\") {\n    return { dataType: \"ulaw\", sampleSize: 1, littleEndian: true, silentValue: 255 };\n  } else if (codec === \"alaw\") {\n    return { dataType: \"alaw\", sampleSize: 1, littleEndian: true, silentValue: 213 };\n  }\n  const match = PCM_CODEC_REGEX.exec(codec);\n  assert(match);\n  let dataType;\n  if (match[1] === \"u\") {\n    dataType = \"unsigned\";\n  } else if (match[1] === \"s\") {\n    dataType = \"signed\";\n  } else {\n    dataType = \"float\";\n  }\n  const sampleSize = Number(match[2]) / 8;\n  const littleEndian = match[3] !== \"be\";\n  const silentValue = codec === \"pcm-u8\" ? 2 ** 7 : 0;\n  return { dataType, sampleSize, littleEndian, silentValue };\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/codec-data.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar AvcNalUnitType;\n(function(AvcNalUnitType2) {\n  AvcNalUnitType2[AvcNalUnitType2[\"NON_IDR_SLICE\"] = 1] = \"NON_IDR_SLICE\";\n  AvcNalUnitType2[AvcNalUnitType2[\"SLICE_DPA\"] = 2] = \"SLICE_DPA\";\n  AvcNalUnitType2[AvcNalUnitType2[\"SLICE_DPB\"] = 3] = \"SLICE_DPB\";\n  AvcNalUnitType2[AvcNalUnitType2[\"SLICE_DPC\"] = 4] = \"SLICE_DPC\";\n  AvcNalUnitType2[AvcNalUnitType2[\"IDR\"] = 5] = \"IDR\";\n  AvcNalUnitType2[AvcNalUnitType2[\"SEI\"] = 6] = \"SEI\";\n  AvcNalUnitType2[AvcNalUnitType2[\"SPS\"] = 7] = \"SPS\";\n  AvcNalUnitType2[AvcNalUnitType2[\"PPS\"] = 8] = \"PPS\";\n  AvcNalUnitType2[AvcNalUnitType2[\"AUD\"] = 9] = \"AUD\";\n  AvcNalUnitType2[AvcNalUnitType2[\"SPS_EXT\"] = 13] = \"SPS_EXT\";\n})(AvcNalUnitType || (AvcNalUnitType = {}));\nvar HevcNalUnitType;\n(function(HevcNalUnitType2) {\n  HevcNalUnitType2[HevcNalUnitType2[\"RASL_N\"] = 8] = \"RASL_N\";\n  HevcNalUnitType2[HevcNalUnitType2[\"RASL_R\"] = 9] = \"RASL_R\";\n  HevcNalUnitType2[HevcNalUnitType2[\"BLA_W_LP\"] = 16] = \"BLA_W_LP\";\n  HevcNalUnitType2[HevcNalUnitType2[\"RSV_IRAP_VCL23\"] = 23] = \"RSV_IRAP_VCL23\";\n  HevcNalUnitType2[HevcNalUnitType2[\"VPS_NUT\"] = 32] = \"VPS_NUT\";\n  HevcNalUnitType2[HevcNalUnitType2[\"SPS_NUT\"] = 33] = \"SPS_NUT\";\n  HevcNalUnitType2[HevcNalUnitType2[\"PPS_NUT\"] = 34] = \"PPS_NUT\";\n  HevcNalUnitType2[HevcNalUnitType2[\"AUD_NUT\"] = 35] = \"AUD_NUT\";\n  HevcNalUnitType2[HevcNalUnitType2[\"PREFIX_SEI_NUT\"] = 39] = \"PREFIX_SEI_NUT\";\n  HevcNalUnitType2[HevcNalUnitType2[\"SUFFIX_SEI_NUT\"] = 40] = \"SUFFIX_SEI_NUT\";\n})(HevcNalUnitType || (HevcNalUnitType = {}));\nvar iterateNalUnitsInAnnexB = function* (packetData) {\n  let i = 0;\n  let nalStart = -1;\n  while (i < packetData.length - 2) {\n    const zeroIndex = packetData.indexOf(0, i);\n    if (zeroIndex === -1 || zeroIndex >= packetData.length - 2) {\n      break;\n    }\n    i = zeroIndex;\n    let startCodeLength = 0;\n    if (i + 3 < packetData.length && packetData[i + 1] === 0 && packetData[i + 2] === 0 && packetData[i + 3] === 1) {\n      startCodeLength = 4;\n    } else if (packetData[i + 1] === 0 && packetData[i + 2] === 1) {\n      startCodeLength = 3;\n    }\n    if (startCodeLength === 0) {\n      i++;\n      continue;\n    }\n    if (nalStart !== -1 && i > nalStart) {\n      yield {\n        offset: nalStart,\n        length: i - nalStart\n      };\n    }\n    nalStart = i + startCodeLength;\n    i = nalStart;\n  }\n  if (nalStart !== -1 && nalStart < packetData.length) {\n    yield {\n      offset: nalStart,\n      length: packetData.length - nalStart\n    };\n  }\n};\nvar iterateNalUnitsInLengthPrefixed = function* (packetData, lengthSize) {\n  let offset = 0;\n  const dataView = new DataView(packetData.buffer, packetData.byteOffset, packetData.byteLength);\n  while (offset + lengthSize <= packetData.length) {\n    let nalUnitLength;\n    if (lengthSize === 1) {\n      nalUnitLength = dataView.getUint8(offset);\n    } else if (lengthSize === 2) {\n      nalUnitLength = dataView.getUint16(offset, false);\n    } else if (lengthSize === 3) {\n      nalUnitLength = getUint24(dataView, offset, false);\n    } else {\n      assert(lengthSize === 4);\n      nalUnitLength = dataView.getUint32(offset, false);\n    }\n    offset += lengthSize;\n    yield {\n      offset,\n      length: nalUnitLength\n    };\n    offset += nalUnitLength;\n  }\n};\nvar iterateAvcNalUnits = (packetData, decoderConfig) => {\n  if (decoderConfig.description) {\n    const bytes = toUint8Array(decoderConfig.description);\n    const lengthSizeMinusOne = bytes[4] & 3;\n    const lengthSize = lengthSizeMinusOne + 1;\n    return iterateNalUnitsInLengthPrefixed(packetData, lengthSize);\n  } else {\n    return iterateNalUnitsInAnnexB(packetData);\n  }\n};\nvar iterateAvcNalUnitsAnnexB = function* (packetData) {\n  yield* iterateNalUnitsInAnnexB(packetData);\n};\nvar extractNalUnitTypeForAvc = (byte) => {\n  return byte & 31;\n};\nvar removeEmulationPreventionBytes = (data) => {\n  const result = [];\n  const len = data.length;\n  for (let i = 0;i < len; i++) {\n    if (i + 2 < len && data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 3) {\n      result.push(0, 0);\n      i += 2;\n    } else {\n      result.push(data[i]);\n    }\n  }\n  return new Uint8Array(result);\n};\nvar ANNEX_B_START_CODE = new Uint8Array([0, 0, 0, 1]);\nvar concatNalUnitsInAnnexB = (nalUnits) => {\n  const totalLength = nalUnits.reduce((a, b) => a + ANNEX_B_START_CODE.byteLength + b.byteLength, 0);\n  const result = new Uint8Array(totalLength);\n  let offset = 0;\n  for (const nalUnit of nalUnits) {\n    result.set(ANNEX_B_START_CODE, offset);\n    offset += ANNEX_B_START_CODE.byteLength;\n    result.set(nalUnit, offset);\n    offset += nalUnit.byteLength;\n  }\n  return result;\n};\nvar concatNalUnitsInLengthPrefixed = (nalUnits, lengthSize) => {\n  const totalLength = nalUnits.reduce((a, b) => a + lengthSize + b.byteLength, 0);\n  const result = new Uint8Array(totalLength);\n  let offset = 0;\n  for (const nalUnit of nalUnits) {\n    const dataView = new DataView(result.buffer, result.byteOffset, result.byteLength);\n    switch (lengthSize) {\n      case 1:\n        dataView.setUint8(offset, nalUnit.byteLength);\n        break;\n      case 2:\n        dataView.setUint16(offset, nalUnit.byteLength, false);\n        break;\n      case 3:\n        setUint24(dataView, offset, nalUnit.byteLength, false);\n        break;\n      case 4:\n        dataView.setUint32(offset, nalUnit.byteLength, false);\n        break;\n    }\n    offset += lengthSize;\n    result.set(nalUnit, offset);\n    offset += nalUnit.byteLength;\n  }\n  return result;\n};\nvar concatAvcNalUnits = (nalUnits, decoderConfig) => {\n  if (decoderConfig.description) {\n    const bytes = toUint8Array(decoderConfig.description);\n    const lengthSizeMinusOne = bytes[4] & 3;\n    const lengthSize = lengthSizeMinusOne + 1;\n    return concatNalUnitsInLengthPrefixed(nalUnits, lengthSize);\n  } else {\n    return concatNalUnitsInAnnexB(nalUnits);\n  }\n};\nvar extractAvcDecoderConfigurationRecord = (packetData) => {\n  try {\n    const spsUnits = [];\n    const ppsUnits = [];\n    const spsExtUnits = [];\n    for (const loc of iterateAvcNalUnitsAnnexB(packetData)) {\n      const nalUnit = packetData.subarray(loc.offset, loc.offset + loc.length);\n      const type = extractNalUnitTypeForAvc(nalUnit[0]);\n      if (type === AvcNalUnitType.SPS) {\n        spsUnits.push(nalUnit);\n      } else if (type === AvcNalUnitType.PPS) {\n        ppsUnits.push(nalUnit);\n      } else if (type === AvcNalUnitType.SPS_EXT) {\n        spsExtUnits.push(nalUnit);\n      }\n    }\n    if (spsUnits.length === 0) {\n      return null;\n    }\n    if (ppsUnits.length === 0) {\n      return null;\n    }\n    const spsData = spsUnits[0];\n    const spsInfo = parseAvcSps(spsData);\n    assert(spsInfo !== null);\n    const hasExtendedData = spsInfo.profileIdc === 100 || spsInfo.profileIdc === 110 || spsInfo.profileIdc === 122 || spsInfo.profileIdc === 144;\n    return {\n      configurationVersion: 1,\n      avcProfileIndication: spsInfo.profileIdc,\n      profileCompatibility: spsInfo.constraintFlags,\n      avcLevelIndication: spsInfo.levelIdc,\n      lengthSizeMinusOne: 3,\n      sequenceParameterSets: spsUnits,\n      pictureParameterSets: ppsUnits,\n      chromaFormat: hasExtendedData ? spsInfo.chromaFormatIdc : null,\n      bitDepthLumaMinus8: hasExtendedData ? spsInfo.bitDepthLumaMinus8 : null,\n      bitDepthChromaMinus8: hasExtendedData ? spsInfo.bitDepthChromaMinus8 : null,\n      sequenceParameterSetExt: hasExtendedData ? spsExtUnits : null\n    };\n  } catch (error) {\n    console.error(\"Error building AVC Decoder Configuration Record:\", error);\n    return null;\n  }\n};\nvar deserializeAvcDecoderConfigurationRecord = (data) => {\n  try {\n    const view = toDataView(data);\n    let offset = 0;\n    const configurationVersion = view.getUint8(offset++);\n    const avcProfileIndication = view.getUint8(offset++);\n    const profileCompatibility = view.getUint8(offset++);\n    const avcLevelIndication = view.getUint8(offset++);\n    const lengthSizeMinusOne = view.getUint8(offset++) & 3;\n    const numOfSequenceParameterSets = view.getUint8(offset++) & 31;\n    const sequenceParameterSets = [];\n    for (let i = 0;i < numOfSequenceParameterSets; i++) {\n      const length = view.getUint16(offset, false);\n      offset += 2;\n      sequenceParameterSets.push(data.subarray(offset, offset + length));\n      offset += length;\n    }\n    const numOfPictureParameterSets = view.getUint8(offset++);\n    const pictureParameterSets = [];\n    for (let i = 0;i < numOfPictureParameterSets; i++) {\n      const length = view.getUint16(offset, false);\n      offset += 2;\n      pictureParameterSets.push(data.subarray(offset, offset + length));\n      offset += length;\n    }\n    const record = {\n      configurationVersion,\n      avcProfileIndication,\n      profileCompatibility,\n      avcLevelIndication,\n      lengthSizeMinusOne,\n      sequenceParameterSets,\n      pictureParameterSets,\n      chromaFormat: null,\n      bitDepthLumaMinus8: null,\n      bitDepthChromaMinus8: null,\n      sequenceParameterSetExt: null\n    };\n    if ((avcProfileIndication === 100 || avcProfileIndication === 110 || avcProfileIndication === 122 || avcProfileIndication === 144) && offset + 4 <= data.length) {\n      const chromaFormat = view.getUint8(offset++) & 3;\n      const bitDepthLumaMinus8 = view.getUint8(offset++) & 7;\n      const bitDepthChromaMinus8 = view.getUint8(offset++) & 7;\n      const numOfSequenceParameterSetExt = view.getUint8(offset++);\n      record.chromaFormat = chromaFormat;\n      record.bitDepthLumaMinus8 = bitDepthLumaMinus8;\n      record.bitDepthChromaMinus8 = bitDepthChromaMinus8;\n      const sequenceParameterSetExt = [];\n      for (let i = 0;i < numOfSequenceParameterSetExt; i++) {\n        const length = view.getUint16(offset, false);\n        offset += 2;\n        sequenceParameterSetExt.push(data.subarray(offset, offset + length));\n        offset += length;\n      }\n      record.sequenceParameterSetExt = sequenceParameterSetExt;\n    }\n    return record;\n  } catch (error) {\n    console.error(\"Error deserializing AVC Decoder Configuration Record:\", error);\n    return null;\n  }\n};\nvar parseAvcSps = (sps) => {\n  try {\n    const bitstream = new Bitstream(removeEmulationPreventionBytes(sps));\n    bitstream.skipBits(1);\n    bitstream.skipBits(2);\n    const nalUnitType = bitstream.readBits(5);\n    if (nalUnitType !== 7) {\n      return null;\n    }\n    const profileIdc = bitstream.readAlignedByte();\n    const constraintFlags = bitstream.readAlignedByte();\n    const levelIdc = bitstream.readAlignedByte();\n    readExpGolomb(bitstream);\n    let chromaFormatIdc = 1;\n    let bitDepthLumaMinus8 = 0;\n    let bitDepthChromaMinus8 = 0;\n    let separateColourPlaneFlag = 0;\n    if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {\n      chromaFormatIdc = readExpGolomb(bitstream);\n      if (chromaFormatIdc === 3) {\n        separateColourPlaneFlag = bitstream.readBits(1);\n      }\n      bitDepthLumaMinus8 = readExpGolomb(bitstream);\n      bitDepthChromaMinus8 = readExpGolomb(bitstream);\n      bitstream.skipBits(1);\n      const seqScalingMatrixPresentFlag = bitstream.readBits(1);\n      if (seqScalingMatrixPresentFlag) {\n        for (let i = 0;i < (chromaFormatIdc !== 3 ? 8 : 12); i++) {\n          const seqScalingListPresentFlag = bitstream.readBits(1);\n          if (seqScalingListPresentFlag) {\n            const sizeOfScalingList = i < 6 ? 16 : 64;\n            let lastScale = 8;\n            let nextScale = 8;\n            for (let j = 0;j < sizeOfScalingList; j++) {\n              if (nextScale !== 0) {\n                const deltaScale = readSignedExpGolomb(bitstream);\n                nextScale = (lastScale + deltaScale + 256) % 256;\n              }\n              lastScale = nextScale === 0 ? lastScale : nextScale;\n            }\n          }\n        }\n      }\n    }\n    readExpGolomb(bitstream);\n    const picOrderCntType = readExpGolomb(bitstream);\n    if (picOrderCntType === 0) {\n      readExpGolomb(bitstream);\n    } else if (picOrderCntType === 1) {\n      bitstream.skipBits(1);\n      readSignedExpGolomb(bitstream);\n      readSignedExpGolomb(bitstream);\n      const numRefFramesInPicOrderCntCycle = readExpGolomb(bitstream);\n      for (let i = 0;i < numRefFramesInPicOrderCntCycle; i++) {\n        readSignedExpGolomb(bitstream);\n      }\n    }\n    readExpGolomb(bitstream);\n    bitstream.skipBits(1);\n    const picWidthInMbsMinus1 = readExpGolomb(bitstream);\n    const picHeightInMapUnitsMinus1 = readExpGolomb(bitstream);\n    const codedWidth = 16 * (picWidthInMbsMinus1 + 1);\n    const codedHeight = 16 * (picHeightInMapUnitsMinus1 + 1);\n    let displayWidth = codedWidth;\n    let displayHeight = codedHeight;\n    const frameMbsOnlyFlag = bitstream.readBits(1);\n    if (!frameMbsOnlyFlag) {\n      bitstream.skipBits(1);\n    }\n    bitstream.skipBits(1);\n    const frameCroppingFlag = bitstream.readBits(1);\n    if (frameCroppingFlag) {\n      const frameCropLeftOffset = readExpGolomb(bitstream);\n      const frameCropRightOffset = readExpGolomb(bitstream);\n      const frameCropTopOffset = readExpGolomb(bitstream);\n      const frameCropBottomOffset = readExpGolomb(bitstream);\n      let cropUnitX;\n      let cropUnitY;\n      const chromaArrayType = separateColourPlaneFlag === 0 ? chromaFormatIdc : 0;\n      if (chromaArrayType === 0) {\n        cropUnitX = 1;\n        cropUnitY = 2 - frameMbsOnlyFlag;\n      } else {\n        const subWidthC = chromaFormatIdc === 3 ? 1 : 2;\n        const subHeightC = chromaFormatIdc === 1 ? 2 : 1;\n        cropUnitX = subWidthC;\n        cropUnitY = subHeightC * (2 - frameMbsOnlyFlag);\n      }\n      displayWidth -= cropUnitX * (frameCropLeftOffset + frameCropRightOffset);\n      displayHeight -= cropUnitY * (frameCropTopOffset + frameCropBottomOffset);\n    }\n    let colourPrimaries = 2;\n    let transferCharacteristics = 2;\n    let matrixCoefficients = 2;\n    let fullRangeFlag = 0;\n    let numReorderFrames = null;\n    let maxDecFrameBuffering = null;\n    const vuiParametersPresentFlag = bitstream.readBits(1);\n    if (vuiParametersPresentFlag) {\n      const aspectRatioInfoPresentFlag = bitstream.readBits(1);\n      if (aspectRatioInfoPresentFlag) {\n        const aspectRatioIdc = bitstream.readBits(8);\n        if (aspectRatioIdc === 255) {\n          bitstream.skipBits(16);\n          bitstream.skipBits(16);\n        }\n      }\n      const overscanInfoPresentFlag = bitstream.readBits(1);\n      if (overscanInfoPresentFlag) {\n        bitstream.skipBits(1);\n      }\n      const videoSignalTypePresentFlag = bitstream.readBits(1);\n      if (videoSignalTypePresentFlag) {\n        bitstream.skipBits(3);\n        fullRangeFlag = bitstream.readBits(1);\n        const colourDescriptionPresentFlag = bitstream.readBits(1);\n        if (colourDescriptionPresentFlag) {\n          colourPrimaries = bitstream.readBits(8);\n          transferCharacteristics = bitstream.readBits(8);\n          matrixCoefficients = bitstream.readBits(8);\n        }\n      }\n      const chromaLocInfoPresentFlag = bitstream.readBits(1);\n      if (chromaLocInfoPresentFlag) {\n        readExpGolomb(bitstream);\n        readExpGolomb(bitstream);\n      }\n      const timingInfoPresentFlag = bitstream.readBits(1);\n      if (timingInfoPresentFlag) {\n        bitstream.skipBits(32);\n        bitstream.skipBits(32);\n        bitstream.skipBits(1);\n      }\n      const nalHrdParametersPresentFlag = bitstream.readBits(1);\n      if (nalHrdParametersPresentFlag) {\n        skipAvcHrdParameters(bitstream);\n      }\n      const vclHrdParametersPresentFlag = bitstream.readBits(1);\n      if (vclHrdParametersPresentFlag) {\n        skipAvcHrdParameters(bitstream);\n      }\n      if (nalHrdParametersPresentFlag || vclHrdParametersPresentFlag) {\n        bitstream.skipBits(1);\n      }\n      bitstream.skipBits(1);\n      const bitstreamRestrictionFlag = bitstream.readBits(1);\n      if (bitstreamRestrictionFlag) {\n        bitstream.skipBits(1);\n        readExpGolomb(bitstream);\n        readExpGolomb(bitstream);\n        readExpGolomb(bitstream);\n        readExpGolomb(bitstream);\n        numReorderFrames = readExpGolomb(bitstream);\n        maxDecFrameBuffering = readExpGolomb(bitstream);\n      }\n    }\n    if (numReorderFrames === null) {\n      assert(maxDecFrameBuffering === null);\n      const constraintSet3Flag = constraintFlags & 16;\n      if ((profileIdc === 44 || profileIdc === 86 || profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244) && constraintSet3Flag) {\n        numReorderFrames = 0;\n        maxDecFrameBuffering = 0;\n      } else {\n        const picWidthInMbs = picWidthInMbsMinus1 + 1;\n        const picHeightInMapUnits = picHeightInMapUnitsMinus1 + 1;\n        const frameHeightInMbs = (2 - frameMbsOnlyFlag) * picHeightInMapUnits;\n        const levelInfo = AVC_LEVEL_TABLE.find((x) => x.level >= levelIdc) ?? last(AVC_LEVEL_TABLE);\n        const maxDpbFrames = Math.min(Math.floor(levelInfo.maxDpbMbs / (picWidthInMbs * frameHeightInMbs)), 16);\n        numReorderFrames = maxDpbFrames;\n        maxDecFrameBuffering = maxDpbFrames;\n      }\n    }\n    assert(maxDecFrameBuffering !== null);\n    return {\n      profileIdc,\n      constraintFlags,\n      levelIdc,\n      frameMbsOnlyFlag,\n      chromaFormatIdc,\n      bitDepthLumaMinus8,\n      bitDepthChromaMinus8,\n      codedWidth,\n      codedHeight,\n      displayWidth,\n      displayHeight,\n      colourPrimaries,\n      matrixCoefficients,\n      transferCharacteristics,\n      fullRangeFlag,\n      numReorderFrames,\n      maxDecFrameBuffering\n    };\n  } catch (error) {\n    console.error(\"Error parsing AVC SPS:\", error);\n    return null;\n  }\n};\nvar skipAvcHrdParameters = (bitstream) => {\n  const cpb_cnt_minus1 = readExpGolomb(bitstream);\n  bitstream.skipBits(4);\n  bitstream.skipBits(4);\n  for (let i = 0;i <= cpb_cnt_minus1; i++) {\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    bitstream.skipBits(1);\n  }\n  bitstream.skipBits(5);\n  bitstream.skipBits(5);\n  bitstream.skipBits(5);\n  bitstream.skipBits(5);\n};\nvar iterateHevcNalUnits = (packetData, decoderConfig) => {\n  if (decoderConfig.description) {\n    const bytes = toUint8Array(decoderConfig.description);\n    const lengthSizeMinusOne = bytes[21] & 3;\n    const lengthSize = lengthSizeMinusOne + 1;\n    return iterateNalUnitsInLengthPrefixed(packetData, lengthSize);\n  } else {\n    return iterateNalUnitsInAnnexB(packetData);\n  }\n};\nvar iterateHevcNalUnitsAnnexB = function* (packetData) {\n  yield* iterateNalUnitsInAnnexB(packetData);\n};\nvar extractNalUnitTypeForHevc = (byte) => {\n  return byte >> 1 & 63;\n};\nvar parseHevcSps = (sps) => {\n  try {\n    const bitstream = new Bitstream(removeEmulationPreventionBytes(sps));\n    bitstream.skipBits(16);\n    bitstream.readBits(4);\n    const spsMaxSubLayersMinus1 = bitstream.readBits(3);\n    const spsTemporalIdNestingFlag = bitstream.readBits(1);\n    const { general_profile_space, general_tier_flag, general_profile_idc, general_profile_compatibility_flags, general_constraint_indicator_flags, general_level_idc } = parseProfileTierLevel(bitstream, spsMaxSubLayersMinus1);\n    readExpGolomb(bitstream);\n    const chromaFormatIdc = readExpGolomb(bitstream);\n    let separateColourPlaneFlag = 0;\n    if (chromaFormatIdc === 3) {\n      separateColourPlaneFlag = bitstream.readBits(1);\n    }\n    const picWidthInLumaSamples = readExpGolomb(bitstream);\n    const picHeightInLumaSamples = readExpGolomb(bitstream);\n    let displayWidth = picWidthInLumaSamples;\n    let displayHeight = picHeightInLumaSamples;\n    if (bitstream.readBits(1)) {\n      const confWinLeftOffset = readExpGolomb(bitstream);\n      const confWinRightOffset = readExpGolomb(bitstream);\n      const confWinTopOffset = readExpGolomb(bitstream);\n      const confWinBottomOffset = readExpGolomb(bitstream);\n      let subWidthC = 1;\n      let subHeightC = 1;\n      const chromaArrayType = separateColourPlaneFlag === 0 ? chromaFormatIdc : 0;\n      if (chromaArrayType === 1) {\n        subWidthC = 2;\n        subHeightC = 2;\n      } else if (chromaArrayType === 2) {\n        subWidthC = 2;\n        subHeightC = 1;\n      }\n      displayWidth -= (confWinLeftOffset + confWinRightOffset) * subWidthC;\n      displayHeight -= (confWinTopOffset + confWinBottomOffset) * subHeightC;\n    }\n    const bitDepthLumaMinus8 = readExpGolomb(bitstream);\n    const bitDepthChromaMinus8 = readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    const spsSubLayerOrderingInfoPresentFlag = bitstream.readBits(1);\n    const startI = spsSubLayerOrderingInfoPresentFlag ? 0 : spsMaxSubLayersMinus1;\n    let spsMaxNumReorderPics = 0;\n    for (let i = startI;i <= spsMaxSubLayersMinus1; i++) {\n      readExpGolomb(bitstream);\n      spsMaxNumReorderPics = readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n    }\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    if (bitstream.readBits(1)) {\n      if (bitstream.readBits(1)) {\n        skipScalingListData(bitstream);\n      }\n    }\n    bitstream.skipBits(1);\n    bitstream.skipBits(1);\n    if (bitstream.readBits(1)) {\n      bitstream.skipBits(4);\n      bitstream.skipBits(4);\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      bitstream.skipBits(1);\n    }\n    const numShortTermRefPicSets = readExpGolomb(bitstream);\n    skipAllStRefPicSets(bitstream, numShortTermRefPicSets);\n    if (bitstream.readBits(1)) {\n      const numLongTermRefPicsSps = readExpGolomb(bitstream);\n      for (let i = 0;i < numLongTermRefPicsSps; i++) {\n        readExpGolomb(bitstream);\n        bitstream.skipBits(1);\n      }\n    }\n    bitstream.skipBits(1);\n    bitstream.skipBits(1);\n    let colourPrimaries = 2;\n    let transferCharacteristics = 2;\n    let matrixCoefficients = 2;\n    let fullRangeFlag = 0;\n    let minSpatialSegmentationIdc = 0;\n    if (bitstream.readBits(1)) {\n      const vui = parseHevcVui(bitstream, spsMaxSubLayersMinus1);\n      colourPrimaries = vui.colourPrimaries;\n      transferCharacteristics = vui.transferCharacteristics;\n      matrixCoefficients = vui.matrixCoefficients;\n      fullRangeFlag = vui.fullRangeFlag;\n      minSpatialSegmentationIdc = vui.minSpatialSegmentationIdc;\n    }\n    return {\n      displayWidth,\n      displayHeight,\n      colourPrimaries,\n      transferCharacteristics,\n      matrixCoefficients,\n      fullRangeFlag,\n      maxDecFrameBuffering: spsMaxNumReorderPics + 1,\n      spsMaxSubLayersMinus1,\n      spsTemporalIdNestingFlag,\n      generalProfileSpace: general_profile_space,\n      generalTierFlag: general_tier_flag,\n      generalProfileIdc: general_profile_idc,\n      generalProfileCompatibilityFlags: general_profile_compatibility_flags,\n      generalConstraintIndicatorFlags: general_constraint_indicator_flags,\n      generalLevelIdc: general_level_idc,\n      chromaFormatIdc,\n      bitDepthLumaMinus8,\n      bitDepthChromaMinus8,\n      minSpatialSegmentationIdc\n    };\n  } catch (error) {\n    console.error(\"Error parsing HEVC SPS:\", error);\n    return null;\n  }\n};\nvar extractHevcDecoderConfigurationRecord = (packetData) => {\n  try {\n    const vpsUnits = [];\n    const spsUnits = [];\n    const ppsUnits = [];\n    const seiUnits = [];\n    for (const loc of iterateHevcNalUnitsAnnexB(packetData)) {\n      const nalUnit = packetData.subarray(loc.offset, loc.offset + loc.length);\n      const type = extractNalUnitTypeForHevc(nalUnit[0]);\n      if (type === HevcNalUnitType.VPS_NUT) {\n        vpsUnits.push(nalUnit);\n      } else if (type === HevcNalUnitType.SPS_NUT) {\n        spsUnits.push(nalUnit);\n      } else if (type === HevcNalUnitType.PPS_NUT) {\n        ppsUnits.push(nalUnit);\n      } else if (type === HevcNalUnitType.PREFIX_SEI_NUT || type === HevcNalUnitType.SUFFIX_SEI_NUT) {\n        seiUnits.push(nalUnit);\n      }\n    }\n    if (spsUnits.length === 0 || ppsUnits.length === 0)\n      return null;\n    const spsInfo = parseHevcSps(spsUnits[0]);\n    if (!spsInfo)\n      return null;\n    let parallelismType = 0;\n    if (ppsUnits.length > 0) {\n      const pps = ppsUnits[0];\n      const ppsBitstream = new Bitstream(removeEmulationPreventionBytes(pps));\n      ppsBitstream.skipBits(16);\n      readExpGolomb(ppsBitstream);\n      readExpGolomb(ppsBitstream);\n      ppsBitstream.skipBits(1);\n      ppsBitstream.skipBits(1);\n      ppsBitstream.skipBits(3);\n      ppsBitstream.skipBits(1);\n      ppsBitstream.skipBits(1);\n      readExpGolomb(ppsBitstream);\n      readExpGolomb(ppsBitstream);\n      readSignedExpGolomb(ppsBitstream);\n      ppsBitstream.skipBits(1);\n      ppsBitstream.skipBits(1);\n      if (ppsBitstream.readBits(1)) {\n        readExpGolomb(ppsBitstream);\n      }\n      readSignedExpGolomb(ppsBitstream);\n      readSignedExpGolomb(ppsBitstream);\n      ppsBitstream.skipBits(1);\n      ppsBitstream.skipBits(1);\n      ppsBitstream.skipBits(1);\n      ppsBitstream.skipBits(1);\n      const tiles_enabled_flag = ppsBitstream.readBits(1);\n      const entropy_coding_sync_enabled_flag = ppsBitstream.readBits(1);\n      if (!tiles_enabled_flag && !entropy_coding_sync_enabled_flag)\n        parallelismType = 0;\n      else if (tiles_enabled_flag && !entropy_coding_sync_enabled_flag)\n        parallelismType = 2;\n      else if (!tiles_enabled_flag && entropy_coding_sync_enabled_flag)\n        parallelismType = 3;\n      else\n        parallelismType = 0;\n    }\n    const arrays = [\n      ...vpsUnits.length ? [\n        {\n          arrayCompleteness: 1,\n          nalUnitType: HevcNalUnitType.VPS_NUT,\n          nalUnits: vpsUnits\n        }\n      ] : [],\n      ...spsUnits.length ? [\n        {\n          arrayCompleteness: 1,\n          nalUnitType: HevcNalUnitType.SPS_NUT,\n          nalUnits: spsUnits\n        }\n      ] : [],\n      ...ppsUnits.length ? [\n        {\n          arrayCompleteness: 1,\n          nalUnitType: HevcNalUnitType.PPS_NUT,\n          nalUnits: ppsUnits\n        }\n      ] : [],\n      ...seiUnits.length ? [\n        {\n          arrayCompleteness: 1,\n          nalUnitType: extractNalUnitTypeForHevc(seiUnits[0][0]),\n          nalUnits: seiUnits\n        }\n      ] : []\n    ];\n    const record = {\n      configurationVersion: 1,\n      generalProfileSpace: spsInfo.generalProfileSpace,\n      generalTierFlag: spsInfo.generalTierFlag,\n      generalProfileIdc: spsInfo.generalProfileIdc,\n      generalProfileCompatibilityFlags: spsInfo.generalProfileCompatibilityFlags,\n      generalConstraintIndicatorFlags: spsInfo.generalConstraintIndicatorFlags,\n      generalLevelIdc: spsInfo.generalLevelIdc,\n      minSpatialSegmentationIdc: spsInfo.minSpatialSegmentationIdc,\n      parallelismType,\n      chromaFormatIdc: spsInfo.chromaFormatIdc,\n      bitDepthLumaMinus8: spsInfo.bitDepthLumaMinus8,\n      bitDepthChromaMinus8: spsInfo.bitDepthChromaMinus8,\n      avgFrameRate: 0,\n      constantFrameRate: 0,\n      numTemporalLayers: spsInfo.spsMaxSubLayersMinus1 + 1,\n      temporalIdNested: spsInfo.spsTemporalIdNestingFlag,\n      lengthSizeMinusOne: 3,\n      arrays\n    };\n    return record;\n  } catch (error) {\n    console.error(\"Error building HEVC Decoder Configuration Record:\", error);\n    return null;\n  }\n};\nvar parseProfileTierLevel = (bitstream, maxNumSubLayersMinus1) => {\n  const general_profile_space = bitstream.readBits(2);\n  const general_tier_flag = bitstream.readBits(1);\n  const general_profile_idc = bitstream.readBits(5);\n  let general_profile_compatibility_flags = 0;\n  for (let i = 0;i < 32; i++) {\n    general_profile_compatibility_flags = general_profile_compatibility_flags << 1 | bitstream.readBits(1);\n  }\n  const general_constraint_indicator_flags = new Uint8Array(6);\n  for (let i = 0;i < 6; i++) {\n    general_constraint_indicator_flags[i] = bitstream.readBits(8);\n  }\n  const general_level_idc = bitstream.readBits(8);\n  const sub_layer_profile_present_flag = [];\n  const sub_layer_level_present_flag = [];\n  for (let i = 0;i < maxNumSubLayersMinus1; i++) {\n    sub_layer_profile_present_flag.push(bitstream.readBits(1));\n    sub_layer_level_present_flag.push(bitstream.readBits(1));\n  }\n  if (maxNumSubLayersMinus1 > 0) {\n    for (let i = maxNumSubLayersMinus1;i < 8; i++) {\n      bitstream.skipBits(2);\n    }\n  }\n  for (let i = 0;i < maxNumSubLayersMinus1; i++) {\n    if (sub_layer_profile_present_flag[i])\n      bitstream.skipBits(88);\n    if (sub_layer_level_present_flag[i])\n      bitstream.skipBits(8);\n  }\n  return {\n    general_profile_space,\n    general_tier_flag,\n    general_profile_idc,\n    general_profile_compatibility_flags,\n    general_constraint_indicator_flags,\n    general_level_idc\n  };\n};\nvar skipScalingListData = (bitstream) => {\n  for (let sizeId = 0;sizeId < 4; sizeId++) {\n    for (let matrixId = 0;matrixId < (sizeId === 3 ? 2 : 6); matrixId++) {\n      const scaling_list_pred_mode_flag = bitstream.readBits(1);\n      if (!scaling_list_pred_mode_flag) {\n        readExpGolomb(bitstream);\n      } else {\n        const coefNum = Math.min(64, 1 << 4 + (sizeId << 1));\n        if (sizeId > 1) {\n          readSignedExpGolomb(bitstream);\n        }\n        for (let i = 0;i < coefNum; i++) {\n          readSignedExpGolomb(bitstream);\n        }\n      }\n    }\n  }\n};\nvar skipAllStRefPicSets = (bitstream, num_short_term_ref_pic_sets) => {\n  const NumDeltaPocs = [];\n  for (let stRpsIdx = 0;stRpsIdx < num_short_term_ref_pic_sets; stRpsIdx++) {\n    NumDeltaPocs[stRpsIdx] = skipStRefPicSet(bitstream, stRpsIdx, num_short_term_ref_pic_sets, NumDeltaPocs);\n  }\n};\nvar skipStRefPicSet = (bitstream, stRpsIdx, num_short_term_ref_pic_sets, NumDeltaPocs) => {\n  let NumDeltaPocsThis = 0;\n  let inter_ref_pic_set_prediction_flag = 0;\n  let RefRpsIdx = 0;\n  if (stRpsIdx !== 0) {\n    inter_ref_pic_set_prediction_flag = bitstream.readBits(1);\n  }\n  if (inter_ref_pic_set_prediction_flag) {\n    if (stRpsIdx === num_short_term_ref_pic_sets) {\n      const delta_idx_minus1 = readExpGolomb(bitstream);\n      RefRpsIdx = stRpsIdx - (delta_idx_minus1 + 1);\n    } else {\n      RefRpsIdx = stRpsIdx - 1;\n    }\n    bitstream.readBits(1);\n    readExpGolomb(bitstream);\n    const numDelta = NumDeltaPocs[RefRpsIdx] ?? 0;\n    for (let j = 0;j <= numDelta; j++) {\n      const used_by_curr_pic_flag = bitstream.readBits(1);\n      if (!used_by_curr_pic_flag) {\n        bitstream.readBits(1);\n      }\n    }\n    NumDeltaPocsThis = NumDeltaPocs[RefRpsIdx];\n  } else {\n    const num_negative_pics = readExpGolomb(bitstream);\n    const num_positive_pics = readExpGolomb(bitstream);\n    for (let i = 0;i < num_negative_pics; i++) {\n      readExpGolomb(bitstream);\n      bitstream.readBits(1);\n    }\n    for (let i = 0;i < num_positive_pics; i++) {\n      readExpGolomb(bitstream);\n      bitstream.readBits(1);\n    }\n    NumDeltaPocsThis = num_negative_pics + num_positive_pics;\n  }\n  return NumDeltaPocsThis;\n};\nvar parseHevcVui = (bitstream, sps_max_sub_layers_minus1) => {\n  let colourPrimaries = 2;\n  let transferCharacteristics = 2;\n  let matrixCoefficients = 2;\n  let fullRangeFlag = 0;\n  let minSpatialSegmentationIdc = 0;\n  if (bitstream.readBits(1)) {\n    const aspect_ratio_idc = bitstream.readBits(8);\n    if (aspect_ratio_idc === 255) {\n      bitstream.readBits(16);\n      bitstream.readBits(16);\n    }\n  }\n  if (bitstream.readBits(1)) {\n    bitstream.readBits(1);\n  }\n  if (bitstream.readBits(1)) {\n    bitstream.readBits(3);\n    fullRangeFlag = bitstream.readBits(1);\n    if (bitstream.readBits(1)) {\n      colourPrimaries = bitstream.readBits(8);\n      transferCharacteristics = bitstream.readBits(8);\n      matrixCoefficients = bitstream.readBits(8);\n    }\n  }\n  if (bitstream.readBits(1)) {\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n  }\n  bitstream.readBits(1);\n  bitstream.readBits(1);\n  bitstream.readBits(1);\n  if (bitstream.readBits(1)) {\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n  }\n  if (bitstream.readBits(1)) {\n    bitstream.readBits(32);\n    bitstream.readBits(32);\n    if (bitstream.readBits(1)) {\n      readExpGolomb(bitstream);\n    }\n    if (bitstream.readBits(1)) {\n      skipHevcHrdParameters(bitstream, true, sps_max_sub_layers_minus1);\n    }\n  }\n  if (bitstream.readBits(1)) {\n    bitstream.readBits(1);\n    bitstream.readBits(1);\n    bitstream.readBits(1);\n    minSpatialSegmentationIdc = readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n  }\n  return {\n    colourPrimaries,\n    transferCharacteristics,\n    matrixCoefficients,\n    fullRangeFlag,\n    minSpatialSegmentationIdc\n  };\n};\nvar skipHevcHrdParameters = (bitstream, commonInfPresentFlag, maxNumSubLayersMinus1) => {\n  let nal_hrd_parameters_present_flag = false;\n  let vcl_hrd_parameters_present_flag = false;\n  let sub_pic_hrd_params_present_flag = false;\n  if (commonInfPresentFlag) {\n    nal_hrd_parameters_present_flag = bitstream.readBits(1) === 1;\n    vcl_hrd_parameters_present_flag = bitstream.readBits(1) === 1;\n    if (nal_hrd_parameters_present_flag || vcl_hrd_parameters_present_flag) {\n      sub_pic_hrd_params_present_flag = bitstream.readBits(1) === 1;\n      if (sub_pic_hrd_params_present_flag) {\n        bitstream.readBits(8);\n        bitstream.readBits(5);\n        bitstream.readBits(1);\n        bitstream.readBits(5);\n      }\n      bitstream.readBits(4);\n      bitstream.readBits(4);\n      if (sub_pic_hrd_params_present_flag) {\n        bitstream.readBits(4);\n      }\n      bitstream.readBits(5);\n      bitstream.readBits(5);\n      bitstream.readBits(5);\n    }\n  }\n  for (let i = 0;i <= maxNumSubLayersMinus1; i++) {\n    const fixed_pic_rate_general_flag = bitstream.readBits(1) === 1;\n    let fixed_pic_rate_within_cvs_flag = true;\n    if (!fixed_pic_rate_general_flag) {\n      fixed_pic_rate_within_cvs_flag = bitstream.readBits(1) === 1;\n    }\n    let low_delay_hrd_flag = false;\n    if (fixed_pic_rate_within_cvs_flag) {\n      readExpGolomb(bitstream);\n    } else {\n      low_delay_hrd_flag = bitstream.readBits(1) === 1;\n    }\n    let CpbCnt = 1;\n    if (!low_delay_hrd_flag) {\n      const cpb_cnt_minus1 = readExpGolomb(bitstream);\n      CpbCnt = cpb_cnt_minus1 + 1;\n    }\n    if (nal_hrd_parameters_present_flag) {\n      skipSubLayerHrdParameters(bitstream, CpbCnt, sub_pic_hrd_params_present_flag);\n    }\n    if (vcl_hrd_parameters_present_flag) {\n      skipSubLayerHrdParameters(bitstream, CpbCnt, sub_pic_hrd_params_present_flag);\n    }\n  }\n};\nvar skipSubLayerHrdParameters = (bitstream, CpbCnt, sub_pic_hrd_params_present_flag) => {\n  for (let i = 0;i < CpbCnt; i++) {\n    readExpGolomb(bitstream);\n    readExpGolomb(bitstream);\n    if (sub_pic_hrd_params_present_flag) {\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n    }\n    bitstream.readBits(1);\n  }\n};\nvar extractVp9CodecInfoFromPacket = (packet) => {\n  const bitstream = new Bitstream(packet);\n  const frameMarker = bitstream.readBits(2);\n  if (frameMarker !== 2) {\n    return null;\n  }\n  const profileLowBit = bitstream.readBits(1);\n  const profileHighBit = bitstream.readBits(1);\n  const profile = (profileHighBit << 1) + profileLowBit;\n  if (profile === 3) {\n    bitstream.skipBits(1);\n  }\n  const showExistingFrame = bitstream.readBits(1);\n  if (showExistingFrame === 1) {\n    return null;\n  }\n  const frameType = bitstream.readBits(1);\n  if (frameType !== 0) {\n    return null;\n  }\n  bitstream.skipBits(2);\n  const syncCode = bitstream.readBits(24);\n  if (syncCode !== 4817730) {\n    return null;\n  }\n  let bitDepth = 8;\n  if (profile >= 2) {\n    const tenOrTwelveBit = bitstream.readBits(1);\n    bitDepth = tenOrTwelveBit ? 12 : 10;\n  }\n  const colorSpace = bitstream.readBits(3);\n  let chromaSubsampling = 0;\n  let videoFullRangeFlag = 0;\n  if (colorSpace !== 7) {\n    const colorRange = bitstream.readBits(1);\n    videoFullRangeFlag = colorRange;\n    if (profile === 1 || profile === 3) {\n      const subsamplingX = bitstream.readBits(1);\n      const subsamplingY = bitstream.readBits(1);\n      chromaSubsampling = !subsamplingX && !subsamplingY ? 3 : subsamplingX && !subsamplingY ? 2 : 1;\n      bitstream.skipBits(1);\n    } else {\n      chromaSubsampling = 1;\n    }\n  } else {\n    chromaSubsampling = 3;\n    videoFullRangeFlag = 1;\n  }\n  const widthMinusOne = bitstream.readBits(16);\n  const heightMinusOne = bitstream.readBits(16);\n  const width = widthMinusOne + 1;\n  const height = heightMinusOne + 1;\n  const pictureSize = width * height;\n  let level = last(VP9_LEVEL_TABLE).level;\n  for (const entry of VP9_LEVEL_TABLE) {\n    if (pictureSize <= entry.maxPictureSize) {\n      level = entry.level;\n      break;\n    }\n  }\n  const matrixCoefficients = colorSpace === 7 ? 0 : colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;\n  const colourPrimaries = colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;\n  const transferCharacteristics = colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;\n  return {\n    profile,\n    level,\n    bitDepth,\n    chromaSubsampling,\n    videoFullRangeFlag,\n    colourPrimaries,\n    transferCharacteristics,\n    matrixCoefficients\n  };\n};\nvar iterateAv1PacketObus = function* (packet) {\n  const bitstream = new Bitstream(packet);\n  const readLeb128 = () => {\n    let value = 0;\n    for (let i = 0;i < 8; i++) {\n      const byte = bitstream.readAlignedByte();\n      value |= (byte & 127) << i * 7;\n      if (!(byte & 128)) {\n        break;\n      }\n      if (i === 7 && byte & 128) {\n        return null;\n      }\n    }\n    if (value >= 2 ** 32 - 1) {\n      return null;\n    }\n    return value;\n  };\n  while (bitstream.getBitsLeft() >= 8) {\n    bitstream.skipBits(1);\n    const obuType = bitstream.readBits(4);\n    const obuExtension = bitstream.readBits(1);\n    const obuHasSizeField = bitstream.readBits(1);\n    bitstream.skipBits(1);\n    if (obuExtension) {\n      bitstream.skipBits(8);\n    }\n    let obuSize;\n    if (obuHasSizeField) {\n      const obuSizeValue = readLeb128();\n      if (obuSizeValue === null)\n        return;\n      obuSize = obuSizeValue;\n    } else {\n      obuSize = Math.floor(bitstream.getBitsLeft() / 8);\n    }\n    assert(bitstream.pos % 8 === 0);\n    yield {\n      type: obuType,\n      data: packet.subarray(bitstream.pos / 8, bitstream.pos / 8 + obuSize)\n    };\n    bitstream.skipBits(obuSize * 8);\n  }\n};\nvar extractAv1CodecInfoFromPacket = (packet) => {\n  for (const { type, data } of iterateAv1PacketObus(packet)) {\n    if (type !== 1) {\n      continue;\n    }\n    const bitstream = new Bitstream(data);\n    const seqProfile = bitstream.readBits(3);\n    const stillPicture = bitstream.readBits(1);\n    const reducedStillPictureHeader = bitstream.readBits(1);\n    let seqLevel = 0;\n    let seqTier = 0;\n    let bufferDelayLengthMinus1 = 0;\n    if (reducedStillPictureHeader) {\n      seqLevel = bitstream.readBits(5);\n    } else {\n      const timingInfoPresentFlag = bitstream.readBits(1);\n      if (timingInfoPresentFlag) {\n        bitstream.skipBits(32);\n        bitstream.skipBits(32);\n        const equalPictureInterval = bitstream.readBits(1);\n        if (equalPictureInterval) {\n          return null;\n        }\n      }\n      const decoderModelInfoPresentFlag = bitstream.readBits(1);\n      if (decoderModelInfoPresentFlag) {\n        bufferDelayLengthMinus1 = bitstream.readBits(5);\n        bitstream.skipBits(32);\n        bitstream.skipBits(5);\n        bitstream.skipBits(5);\n      }\n      const operatingPointsCntMinus1 = bitstream.readBits(5);\n      for (let i = 0;i <= operatingPointsCntMinus1; i++) {\n        bitstream.skipBits(12);\n        const seqLevelIdx = bitstream.readBits(5);\n        if (i === 0) {\n          seqLevel = seqLevelIdx;\n        }\n        if (seqLevelIdx > 7) {\n          const seqTierTemp = bitstream.readBits(1);\n          if (i === 0) {\n            seqTier = seqTierTemp;\n          }\n        }\n        if (decoderModelInfoPresentFlag) {\n          const decoderModelPresentForThisOp = bitstream.readBits(1);\n          if (decoderModelPresentForThisOp) {\n            const n = bufferDelayLengthMinus1 + 1;\n            bitstream.skipBits(n);\n            bitstream.skipBits(n);\n            bitstream.skipBits(1);\n          }\n        }\n        const initialDisplayDelayPresentFlag = bitstream.readBits(1);\n        if (initialDisplayDelayPresentFlag) {\n          bitstream.skipBits(4);\n        }\n      }\n    }\n    const frameWidthBitsMinus1 = bitstream.readBits(4);\n    const frameHeightBitsMinus1 = bitstream.readBits(4);\n    const n1 = frameWidthBitsMinus1 + 1;\n    bitstream.skipBits(n1);\n    const n2 = frameHeightBitsMinus1 + 1;\n    bitstream.skipBits(n2);\n    let frameIdNumbersPresentFlag = 0;\n    if (reducedStillPictureHeader) {\n      frameIdNumbersPresentFlag = 0;\n    } else {\n      frameIdNumbersPresentFlag = bitstream.readBits(1);\n    }\n    if (frameIdNumbersPresentFlag) {\n      bitstream.skipBits(4);\n      bitstream.skipBits(3);\n    }\n    bitstream.skipBits(1);\n    bitstream.skipBits(1);\n    bitstream.skipBits(1);\n    if (!reducedStillPictureHeader) {\n      bitstream.skipBits(1);\n      bitstream.skipBits(1);\n      bitstream.skipBits(1);\n      bitstream.skipBits(1);\n      const enableOrderHint = bitstream.readBits(1);\n      if (enableOrderHint) {\n        bitstream.skipBits(1);\n        bitstream.skipBits(1);\n      }\n      const seqChooseScreenContentTools = bitstream.readBits(1);\n      let seqForceScreenContentTools = 0;\n      if (seqChooseScreenContentTools) {\n        seqForceScreenContentTools = 2;\n      } else {\n        seqForceScreenContentTools = bitstream.readBits(1);\n      }\n      if (seqForceScreenContentTools > 0) {\n        const seqChooseIntegerMv = bitstream.readBits(1);\n        if (!seqChooseIntegerMv) {\n          bitstream.skipBits(1);\n        }\n      }\n      if (enableOrderHint) {\n        bitstream.skipBits(3);\n      }\n    }\n    bitstream.skipBits(1);\n    bitstream.skipBits(1);\n    bitstream.skipBits(1);\n    const highBitdepth = bitstream.readBits(1);\n    let bitDepth = 8;\n    if (seqProfile === 2 && highBitdepth) {\n      const twelveBit = bitstream.readBits(1);\n      bitDepth = twelveBit ? 12 : 10;\n    } else if (seqProfile <= 2) {\n      bitDepth = highBitdepth ? 10 : 8;\n    }\n    let monochrome = 0;\n    if (seqProfile !== 1) {\n      monochrome = bitstream.readBits(1);\n    }\n    let chromaSubsamplingX = 1;\n    let chromaSubsamplingY = 1;\n    let chromaSamplePosition = 0;\n    if (!monochrome) {\n      if (seqProfile === 0) {\n        chromaSubsamplingX = 1;\n        chromaSubsamplingY = 1;\n      } else if (seqProfile === 1) {\n        chromaSubsamplingX = 0;\n        chromaSubsamplingY = 0;\n      } else {\n        if (bitDepth === 12) {\n          chromaSubsamplingX = bitstream.readBits(1);\n          if (chromaSubsamplingX) {\n            chromaSubsamplingY = bitstream.readBits(1);\n          }\n        }\n      }\n      if (chromaSubsamplingX && chromaSubsamplingY) {\n        chromaSamplePosition = bitstream.readBits(2);\n      }\n    }\n    return {\n      profile: seqProfile,\n      level: seqLevel,\n      tier: seqTier,\n      bitDepth,\n      monochrome,\n      chromaSubsamplingX,\n      chromaSubsamplingY,\n      chromaSamplePosition\n    };\n  }\n  return null;\n};\nvar parseOpusIdentificationHeader = (bytes) => {\n  const view = toDataView(bytes);\n  const outputChannelCount = view.getUint8(9);\n  const preSkip = view.getUint16(10, true);\n  const inputSampleRate = view.getUint32(12, true);\n  const outputGain = view.getInt16(16, true);\n  const channelMappingFamily = view.getUint8(18);\n  let channelMappingTable = null;\n  if (channelMappingFamily) {\n    channelMappingTable = bytes.subarray(19, 19 + 2 + outputChannelCount);\n  }\n  return {\n    outputChannelCount,\n    preSkip,\n    inputSampleRate,\n    outputGain,\n    channelMappingFamily,\n    channelMappingTable\n  };\n};\nvar OPUS_FRAME_DURATION_TABLE = [\n  480,\n  960,\n  1920,\n  2880,\n  480,\n  960,\n  1920,\n  2880,\n  480,\n  960,\n  1920,\n  2880,\n  480,\n  960,\n  480,\n  960,\n  120,\n  240,\n  480,\n  960,\n  120,\n  240,\n  480,\n  960,\n  120,\n  240,\n  480,\n  960,\n  120,\n  240,\n  480,\n  960\n];\nvar parseOpusTocByte = (packet) => {\n  const config = packet[0] >> 3;\n  return {\n    durationInSamples: OPUS_FRAME_DURATION_TABLE[config]\n  };\n};\nvar parseModesFromVorbisSetupPacket = (setupHeader) => {\n  if (setupHeader.length < 7) {\n    throw new Error(\"Setup header is too short.\");\n  }\n  if (setupHeader[0] !== 5) {\n    throw new Error(\"Wrong packet type in Setup header.\");\n  }\n  const signature = String.fromCharCode(...setupHeader.slice(1, 7));\n  if (signature !== \"vorbis\") {\n    throw new Error(\"Invalid packet signature in Setup header.\");\n  }\n  const bufSize = setupHeader.length;\n  const revBuffer = new Uint8Array(bufSize);\n  for (let i = 0;i < bufSize; i++) {\n    revBuffer[i] = setupHeader[bufSize - 1 - i];\n  }\n  const bitstream = new Bitstream(revBuffer);\n  let gotFramingBit = 0;\n  while (bitstream.getBitsLeft() > 97) {\n    if (bitstream.readBits(1) === 1) {\n      gotFramingBit = bitstream.pos;\n      break;\n    }\n  }\n  if (gotFramingBit === 0) {\n    throw new Error(\"Invalid Setup header: framing bit not found.\");\n  }\n  let modeCount = 0;\n  let gotModeHeader = false;\n  let lastModeCount = 0;\n  while (bitstream.getBitsLeft() >= 97) {\n    const tempPos = bitstream.pos;\n    const a = bitstream.readBits(8);\n    const b = bitstream.readBits(16);\n    const c = bitstream.readBits(16);\n    if (a > 63 || b !== 0 || c !== 0) {\n      bitstream.pos = tempPos;\n      break;\n    }\n    bitstream.skipBits(1);\n    modeCount++;\n    if (modeCount > 64) {\n      break;\n    }\n    const bsClone = bitstream.clone();\n    const candidate = bsClone.readBits(6) + 1;\n    if (candidate === modeCount) {\n      gotModeHeader = true;\n      lastModeCount = modeCount;\n    }\n  }\n  if (!gotModeHeader) {\n    throw new Error(\"Invalid Setup header: mode header not found.\");\n  }\n  if (lastModeCount > 63) {\n    throw new Error(`Unsupported mode count: ${lastModeCount}.`);\n  }\n  const finalModeCount = lastModeCount;\n  bitstream.pos = 0;\n  bitstream.skipBits(gotFramingBit);\n  const modeBlockflags = Array(finalModeCount).fill(0);\n  for (let i = finalModeCount - 1;i >= 0; i--) {\n    bitstream.skipBits(40);\n    modeBlockflags[i] = bitstream.readBits(1);\n  }\n  return { modeBlockflags };\n};\nvar determineVideoPacketType = (codec, decoderConfig, packetData) => {\n  switch (codec) {\n    case \"avc\":\n      {\n        for (const loc of iterateAvcNalUnits(packetData, decoderConfig)) {\n          const nalTypeByte = packetData[loc.offset];\n          const type = extractNalUnitTypeForAvc(nalTypeByte);\n          if (type >= AvcNalUnitType.NON_IDR_SLICE && type <= AvcNalUnitType.SLICE_DPC) {\n            return \"delta\";\n          }\n          if (type === AvcNalUnitType.IDR) {\n            return \"key\";\n          }\n          if (type === AvcNalUnitType.SEI && (!isChromium() || getChromiumVersion() >= 144)) {\n            const nalUnit = packetData.subarray(loc.offset, loc.offset + loc.length);\n            const bytes = removeEmulationPreventionBytes(nalUnit);\n            let pos = 1;\n            do {\n              let payloadType = 0;\n              while (true) {\n                const nextByte = bytes[pos++];\n                if (nextByte === undefined)\n                  break;\n                payloadType += nextByte;\n                if (nextByte < 255) {\n                  break;\n                }\n              }\n              let payloadSize = 0;\n              while (true) {\n                const nextByte = bytes[pos++];\n                if (nextByte === undefined)\n                  break;\n                payloadSize += nextByte;\n                if (nextByte < 255) {\n                  break;\n                }\n              }\n              const PAYLOAD_TYPE_RECOVERY_POINT = 6;\n              if (payloadType === PAYLOAD_TYPE_RECOVERY_POINT) {\n                const bitstream = new Bitstream(bytes);\n                bitstream.pos = 8 * pos;\n                const recoveryFrameCount = readExpGolomb(bitstream);\n                const exactMatchFlag = bitstream.readBits(1);\n                if (recoveryFrameCount === 0 && exactMatchFlag === 1) {\n                  return \"key\";\n                }\n              }\n              pos += payloadSize;\n            } while (pos < bytes.length - 1);\n          }\n        }\n        return \"delta\";\n      }\n      ;\n    case \"hevc\":\n      {\n        for (const loc of iterateHevcNalUnits(packetData, decoderConfig)) {\n          const type = extractNalUnitTypeForHevc(packetData[loc.offset]);\n          if (type < HevcNalUnitType.BLA_W_LP) {\n            return \"delta\";\n          }\n          if (type <= HevcNalUnitType.RSV_IRAP_VCL23) {\n            return \"key\";\n          }\n        }\n        return \"delta\";\n      }\n      ;\n    case \"vp8\":\n      {\n        const frameType = packetData[0] & 1;\n        return frameType === 0 ? \"key\" : \"delta\";\n      }\n      ;\n    case \"vp9\":\n      {\n        const bitstream = new Bitstream(packetData);\n        if (bitstream.readBits(2) !== 2) {\n          return null;\n        }\n        const profileLowBit = bitstream.readBits(1);\n        const profileHighBit = bitstream.readBits(1);\n        const profile = (profileHighBit << 1) + profileLowBit;\n        if (profile === 3) {\n          bitstream.skipBits(1);\n        }\n        const showExistingFrame = bitstream.readBits(1);\n        if (showExistingFrame) {\n          return null;\n        }\n        const frameType = bitstream.readBits(1);\n        return frameType === 0 ? \"key\" : \"delta\";\n      }\n      ;\n    case \"av1\":\n      {\n        let reducedStillPictureHeader = false;\n        for (const { type, data } of iterateAv1PacketObus(packetData)) {\n          if (type === 1) {\n            const bitstream = new Bitstream(data);\n            bitstream.skipBits(4);\n            reducedStillPictureHeader = !!bitstream.readBits(1);\n          } else if (type === 3 || type === 6 || type === 7) {\n            if (reducedStillPictureHeader) {\n              return \"key\";\n            }\n            const bitstream = new Bitstream(data);\n            const showExistingFrame = bitstream.readBits(1);\n            if (showExistingFrame) {\n              return null;\n            }\n            const frameType = bitstream.readBits(2);\n            return frameType === 0 ? \"key\" : \"delta\";\n          }\n        }\n        return null;\n      }\n      ;\n    default:\n      {\n        assertNever(codec);\n        assert(false);\n      }\n      ;\n  }\n};\nvar FlacBlockType;\n(function(FlacBlockType2) {\n  FlacBlockType2[FlacBlockType2[\"STREAMINFO\"] = 0] = \"STREAMINFO\";\n  FlacBlockType2[FlacBlockType2[\"VORBIS_COMMENT\"] = 4] = \"VORBIS_COMMENT\";\n  FlacBlockType2[FlacBlockType2[\"PICTURE\"] = 6] = \"PICTURE\";\n})(FlacBlockType || (FlacBlockType = {}));\nvar readVorbisComments = (bytes, metadataTags) => {\n  const commentView = toDataView(bytes);\n  let commentPos = 0;\n  const vendorStringLength = commentView.getUint32(commentPos, true);\n  commentPos += 4;\n  const vendorString = textDecoder.decode(bytes.subarray(commentPos, commentPos + vendorStringLength));\n  commentPos += vendorStringLength;\n  if (vendorStringLength > 0) {\n    metadataTags.raw ??= {};\n    metadataTags.raw[\"vendor\"] ??= vendorString;\n  }\n  const listLength = commentView.getUint32(commentPos, true);\n  commentPos += 4;\n  for (let i = 0;i < listLength; i++) {\n    const stringLength = commentView.getUint32(commentPos, true);\n    commentPos += 4;\n    const string = textDecoder.decode(bytes.subarray(commentPos, commentPos + stringLength));\n    commentPos += stringLength;\n    const separatorIndex = string.indexOf(\"=\");\n    if (separatorIndex === -1) {\n      continue;\n    }\n    const key4 = string.slice(0, separatorIndex).toUpperCase();\n    const value = string.slice(separatorIndex + 1);\n    metadataTags.raw ??= {};\n    metadataTags.raw[key4] ??= value;\n    switch (key4) {\n      case \"TITLE\":\n        {\n          metadataTags.title ??= value;\n        }\n        ;\n        break;\n      case \"DESCRIPTION\":\n        {\n          metadataTags.description ??= value;\n        }\n        ;\n        break;\n      case \"ARTIST\":\n        {\n          metadataTags.artist ??= value;\n        }\n        ;\n        break;\n      case \"ALBUM\":\n        {\n          metadataTags.album ??= value;\n        }\n        ;\n        break;\n      case \"ALBUMARTIST\":\n        {\n          metadataTags.albumArtist ??= value;\n        }\n        ;\n        break;\n      case \"COMMENT\":\n        {\n          metadataTags.comment ??= value;\n        }\n        ;\n        break;\n      case \"LYRICS\":\n        {\n          metadataTags.lyrics ??= value;\n        }\n        ;\n        break;\n      case \"TRACKNUMBER\":\n        {\n          const parts = value.split(\"/\");\n          const trackNum = Number.parseInt(parts[0], 10);\n          const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);\n          if (Number.isInteger(trackNum) && trackNum > 0) {\n            metadataTags.trackNumber ??= trackNum;\n          }\n          if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {\n            metadataTags.tracksTotal ??= tracksTotal;\n          }\n        }\n        ;\n        break;\n      case \"TRACKTOTAL\":\n        {\n          const tracksTotal = Number.parseInt(value, 10);\n          if (Number.isInteger(tracksTotal) && tracksTotal > 0) {\n            metadataTags.tracksTotal ??= tracksTotal;\n          }\n        }\n        ;\n        break;\n      case \"DISCNUMBER\":\n        {\n          const parts = value.split(\"/\");\n          const discNum = Number.parseInt(parts[0], 10);\n          const discsTotal = parts[1] && Number.parseInt(parts[1], 10);\n          if (Number.isInteger(discNum) && discNum > 0) {\n            metadataTags.discNumber ??= discNum;\n          }\n          if (discsTotal && Number.isInteger(discsTotal) && discsTotal > 0) {\n            metadataTags.discsTotal ??= discsTotal;\n          }\n        }\n        ;\n        break;\n      case \"DISCTOTAL\":\n        {\n          const discsTotal = Number.parseInt(value, 10);\n          if (Number.isInteger(discsTotal) && discsTotal > 0) {\n            metadataTags.discsTotal ??= discsTotal;\n          }\n        }\n        ;\n        break;\n      case \"DATE\":\n        {\n          const date = new Date(value);\n          if (!Number.isNaN(date.getTime())) {\n            metadataTags.date ??= date;\n          }\n        }\n        ;\n        break;\n      case \"GENRE\":\n        {\n          metadataTags.genre ??= value;\n        }\n        ;\n        break;\n      case \"METADATA_BLOCK_PICTURE\":\n        {\n          const decoded = base64ToBytes(value);\n          const view = toDataView(decoded);\n          const pictureType = view.getUint32(0, false);\n          const mediaTypeLength = view.getUint32(4, false);\n          const mediaType = String.fromCharCode(...decoded.subarray(8, 8 + mediaTypeLength));\n          const descriptionLength = view.getUint32(8 + mediaTypeLength, false);\n          const description = textDecoder.decode(decoded.subarray(12 + mediaTypeLength, 12 + mediaTypeLength + descriptionLength));\n          const dataLength = view.getUint32(mediaTypeLength + descriptionLength + 28);\n          const data = decoded.subarray(mediaTypeLength + descriptionLength + 32, mediaTypeLength + descriptionLength + 32 + dataLength);\n          metadataTags.images ??= [];\n          metadataTags.images.push({\n            data,\n            mimeType: mediaType,\n            kind: pictureType === 3 ? \"coverFront\" : pictureType === 4 ? \"coverBack\" : \"unknown\",\n            name: undefined,\n            description: description || undefined\n          });\n        }\n        ;\n        break;\n    }\n  }\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/demuxer.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\nclass Demuxer {\n  constructor(input2) {\n    this.input = input2;\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/custom-coder.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar customVideoDecoders = [];\nvar customAudioDecoders = [];\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/packet.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar PLACEHOLDER_DATA = /* @__PURE__ */ new Uint8Array(0);\n\nclass EncodedPacket {\n  constructor(data, type, timestamp, duration, sequenceNumber = -1, byteLength, sideData) {\n    this.data = data;\n    this.type = type;\n    this.timestamp = timestamp;\n    this.duration = duration;\n    this.sequenceNumber = sequenceNumber;\n    if (data === PLACEHOLDER_DATA && byteLength === undefined) {\n      throw new Error(\"Internal error: byteLength must be explicitly provided when constructing metadata-only packets.\");\n    }\n    if (byteLength === undefined) {\n      byteLength = data.byteLength;\n    }\n    if (!(data instanceof Uint8Array)) {\n      throw new TypeError(\"data must be a Uint8Array.\");\n    }\n    if (type !== \"key\" && type !== \"delta\") {\n      throw new TypeError('type must be either \"key\" or \"delta\".');\n    }\n    if (!Number.isFinite(timestamp)) {\n      throw new TypeError(\"timestamp must be a number.\");\n    }\n    if (!Number.isFinite(duration) || duration < 0) {\n      throw new TypeError(\"duration must be a non-negative number.\");\n    }\n    if (!Number.isFinite(sequenceNumber)) {\n      throw new TypeError(\"sequenceNumber must be a number.\");\n    }\n    if (!Number.isInteger(byteLength) || byteLength < 0) {\n      throw new TypeError(\"byteLength must be a non-negative integer.\");\n    }\n    if (sideData !== undefined && (typeof sideData !== \"object\" || !sideData)) {\n      throw new TypeError(\"sideData, when provided, must be an object.\");\n    }\n    if (sideData?.alpha !== undefined && !(sideData.alpha instanceof Uint8Array)) {\n      throw new TypeError(\"sideData.alpha, when provided, must be a Uint8Array.\");\n    }\n    if (sideData?.alphaByteLength !== undefined && (!Number.isInteger(sideData.alphaByteLength) || sideData.alphaByteLength < 0)) {\n      throw new TypeError(\"sideData.alphaByteLength, when provided, must be a non-negative integer.\");\n    }\n    this.byteLength = byteLength;\n    this.sideData = sideData ?? {};\n    if (this.sideData.alpha && this.sideData.alphaByteLength === undefined) {\n      this.sideData.alphaByteLength = this.sideData.alpha.byteLength;\n    }\n  }\n  get isMetadataOnly() {\n    return this.data === PLACEHOLDER_DATA;\n  }\n  get microsecondTimestamp() {\n    return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.timestamp);\n  }\n  get microsecondDuration() {\n    return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.duration);\n  }\n  toEncodedVideoChunk() {\n    if (this.isMetadataOnly) {\n      throw new TypeError(\"Metadata-only packets cannot be converted to a video chunk.\");\n    }\n    if (typeof EncodedVideoChunk === \"undefined\") {\n      throw new Error(\"Your browser does not support EncodedVideoChunk.\");\n    }\n    return new EncodedVideoChunk({\n      data: this.data,\n      type: this.type,\n      timestamp: this.microsecondTimestamp,\n      duration: this.microsecondDuration\n    });\n  }\n  alphaToEncodedVideoChunk(type = this.type) {\n    if (!this.sideData.alpha) {\n      throw new TypeError(\"This packet does not contain alpha side data.\");\n    }\n    if (this.isMetadataOnly) {\n      throw new TypeError(\"Metadata-only packets cannot be converted to a video chunk.\");\n    }\n    if (typeof EncodedVideoChunk === \"undefined\") {\n      throw new Error(\"Your browser does not support EncodedVideoChunk.\");\n    }\n    return new EncodedVideoChunk({\n      data: this.sideData.alpha,\n      type,\n      timestamp: this.microsecondTimestamp,\n      duration: this.microsecondDuration\n    });\n  }\n  toEncodedAudioChunk() {\n    if (this.isMetadataOnly) {\n      throw new TypeError(\"Metadata-only packets cannot be converted to an audio chunk.\");\n    }\n    if (typeof EncodedAudioChunk === \"undefined\") {\n      throw new Error(\"Your browser does not support EncodedAudioChunk.\");\n    }\n    return new EncodedAudioChunk({\n      data: this.data,\n      type: this.type,\n      timestamp: this.microsecondTimestamp,\n      duration: this.microsecondDuration\n    });\n  }\n  static fromEncodedChunk(chunk, sideData) {\n    if (!(chunk instanceof EncodedVideoChunk || chunk instanceof EncodedAudioChunk)) {\n      throw new TypeError(\"chunk must be an EncodedVideoChunk or EncodedAudioChunk.\");\n    }\n    const data = new Uint8Array(chunk.byteLength);\n    chunk.copyTo(data);\n    return new EncodedPacket(data, chunk.type, chunk.timestamp / 1e6, (chunk.duration ?? 0) / 1e6, undefined, undefined, sideData);\n  }\n  clone(options) {\n    if (options !== undefined && (typeof options !== \"object\" || options === null)) {\n      throw new TypeError(\"options, when provided, must be an object.\");\n    }\n    if (options?.data !== undefined && !(options.data instanceof Uint8Array)) {\n      throw new TypeError(\"options.data, when provided, must be a Uint8Array.\");\n    }\n    if (options?.type !== undefined && options.type !== \"key\" && options.type !== \"delta\") {\n      throw new TypeError('options.type, when provided, must be either \"key\" or \"delta\".');\n    }\n    if (options?.timestamp !== undefined && !Number.isFinite(options.timestamp)) {\n      throw new TypeError(\"options.timestamp, when provided, must be a number.\");\n    }\n    if (options?.duration !== undefined && !Number.isFinite(options.duration)) {\n      throw new TypeError(\"options.duration, when provided, must be a number.\");\n    }\n    if (options?.sequenceNumber !== undefined && !Number.isFinite(options.sequenceNumber)) {\n      throw new TypeError(\"options.sequenceNumber, when provided, must be a number.\");\n    }\n    if (options?.sideData !== undefined && (typeof options.sideData !== \"object\" || options.sideData === null)) {\n      throw new TypeError(\"options.sideData, when provided, must be an object.\");\n    }\n    return new EncodedPacket(options?.data ?? this.data, options?.type ?? this.type, options?.timestamp ?? this.timestamp, options?.duration ?? this.duration, options?.sequenceNumber ?? this.sequenceNumber, this.byteLength, options?.sideData ?? this.sideData);\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/sample.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\npolyfillSymbolDispose();\nvar lastVideoGcErrorLog = -Infinity;\nvar lastAudioGcErrorLog = -Infinity;\nvar finalizationRegistry = null;\nif (typeof FinalizationRegistry !== \"undefined\") {\n  finalizationRegistry = new FinalizationRegistry((value) => {\n    const now = Date.now();\n    if (value.type === \"video\") {\n      if (now - lastVideoGcErrorLog >= 1000) {\n        console.error(`A VideoSample was garbage collected without first being closed. For proper resource management,` + ` make sure to call close() on all your VideoSamples as soon as you're done using them.`);\n        lastVideoGcErrorLog = now;\n      }\n      if (typeof VideoFrame !== \"undefined\" && value.data instanceof VideoFrame) {\n        value.data.close();\n      }\n    } else {\n      if (now - lastAudioGcErrorLog >= 1000) {\n        console.error(`An AudioSample was garbage collected without first being closed. For proper resource management,` + ` make sure to call close() on all your AudioSamples as soon as you're done using them.`);\n        lastAudioGcErrorLog = now;\n      }\n      if (typeof AudioData !== \"undefined\" && value.data instanceof AudioData) {\n        value.data.close();\n      }\n    }\n  });\n}\nvar VIDEO_SAMPLE_PIXEL_FORMATS = [\n  \"I420\",\n  \"I420P10\",\n  \"I420P12\",\n  \"I420A\",\n  \"I420AP10\",\n  \"I420AP12\",\n  \"I422\",\n  \"I422P10\",\n  \"I422P12\",\n  \"I422A\",\n  \"I422AP10\",\n  \"I422AP12\",\n  \"I444\",\n  \"I444P10\",\n  \"I444P12\",\n  \"I444A\",\n  \"I444AP10\",\n  \"I444AP12\",\n  \"NV12\",\n  \"RGBA\",\n  \"RGBX\",\n  \"BGRA\",\n  \"BGRX\"\n];\nvar VIDEO_SAMPLE_PIXEL_FORMATS_SET = new Set(VIDEO_SAMPLE_PIXEL_FORMATS);\n\nclass VideoSample {\n  get displayWidth() {\n    return this.rotation % 180 === 0 ? this.codedWidth : this.codedHeight;\n  }\n  get displayHeight() {\n    return this.rotation % 180 === 0 ? this.codedHeight : this.codedWidth;\n  }\n  get microsecondTimestamp() {\n    return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.timestamp);\n  }\n  get microsecondDuration() {\n    return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.duration);\n  }\n  get hasAlpha() {\n    return this.format && this.format.includes(\"A\");\n  }\n  constructor(data, init) {\n    this._closed = false;\n    if (data instanceof ArrayBuffer || typeof SharedArrayBuffer !== \"undefined\" && data instanceof SharedArrayBuffer || ArrayBuffer.isView(data)) {\n      if (!init || typeof init !== \"object\") {\n        throw new TypeError(\"init must be an object.\");\n      }\n      if (init.format === undefined || !VIDEO_SAMPLE_PIXEL_FORMATS_SET.has(init.format)) {\n        throw new TypeError(\"init.format must be one of: \" + VIDEO_SAMPLE_PIXEL_FORMATS.join(\", \"));\n      }\n      if (!Number.isInteger(init.codedWidth) || init.codedWidth <= 0) {\n        throw new TypeError(\"init.codedWidth must be a positive integer.\");\n      }\n      if (!Number.isInteger(init.codedHeight) || init.codedHeight <= 0) {\n        throw new TypeError(\"init.codedHeight must be a positive integer.\");\n      }\n      if (init.rotation !== undefined && ![0, 90, 180, 270].includes(init.rotation)) {\n        throw new TypeError(\"init.rotation, when provided, must be 0, 90, 180, or 270.\");\n      }\n      if (!Number.isFinite(init.timestamp)) {\n        throw new TypeError(\"init.timestamp must be a number.\");\n      }\n      if (init.duration !== undefined && (!Number.isFinite(init.duration) || init.duration < 0)) {\n        throw new TypeError(\"init.duration, when provided, must be a non-negative number.\");\n      }\n      this._data = toUint8Array(data).slice();\n      this._layout = init.layout ?? createDefaultPlaneLayout(init.format, init.codedWidth, init.codedHeight);\n      this.format = init.format;\n      this.codedWidth = init.codedWidth;\n      this.codedHeight = init.codedHeight;\n      this.rotation = init.rotation ?? 0;\n      this.timestamp = init.timestamp;\n      this.duration = init.duration ?? 0;\n      this.colorSpace = new VideoSampleColorSpace(init.colorSpace);\n    } else if (typeof VideoFrame !== \"undefined\" && data instanceof VideoFrame) {\n      if (init?.rotation !== undefined && ![0, 90, 180, 270].includes(init.rotation)) {\n        throw new TypeError(\"init.rotation, when provided, must be 0, 90, 180, or 270.\");\n      }\n      if (init?.timestamp !== undefined && !Number.isFinite(init?.timestamp)) {\n        throw new TypeError(\"init.timestamp, when provided, must be a number.\");\n      }\n      if (init?.duration !== undefined && (!Number.isFinite(init.duration) || init.duration < 0)) {\n        throw new TypeError(\"init.duration, when provided, must be a non-negative number.\");\n      }\n      this._data = data;\n      this._layout = null;\n      this.format = data.format;\n      this.codedWidth = data.displayWidth;\n      this.codedHeight = data.displayHeight;\n      this.rotation = init?.rotation ?? 0;\n      this.timestamp = init?.timestamp ?? data.timestamp / 1e6;\n      this.duration = init?.duration ?? (data.duration ?? 0) / 1e6;\n      this.colorSpace = new VideoSampleColorSpace(data.colorSpace);\n    } else if (typeof HTMLImageElement !== \"undefined\" && data instanceof HTMLImageElement || typeof SVGImageElement !== \"undefined\" && data instanceof SVGImageElement || typeof ImageBitmap !== \"undefined\" && data instanceof ImageBitmap || typeof HTMLVideoElement !== \"undefined\" && data instanceof HTMLVideoElement || typeof HTMLCanvasElement !== \"undefined\" && data instanceof HTMLCanvasElement || typeof OffscreenCanvas !== \"undefined\" && data instanceof OffscreenCanvas) {\n      if (!init || typeof init !== \"object\") {\n        throw new TypeError(\"init must be an object.\");\n      }\n      if (init.rotation !== undefined && ![0, 90, 180, 270].includes(init.rotation)) {\n        throw new TypeError(\"init.rotation, when provided, must be 0, 90, 180, or 270.\");\n      }\n      if (!Number.isFinite(init.timestamp)) {\n        throw new TypeError(\"init.timestamp must be a number.\");\n      }\n      if (init.duration !== undefined && (!Number.isFinite(init.duration) || init.duration < 0)) {\n        throw new TypeError(\"init.duration, when provided, must be a non-negative number.\");\n      }\n      if (typeof VideoFrame !== \"undefined\") {\n        return new VideoSample(new VideoFrame(data, {\n          timestamp: Math.trunc(init.timestamp * SECOND_TO_MICROSECOND_FACTOR),\n          duration: Math.trunc((init.duration ?? 0) * SECOND_TO_MICROSECOND_FACTOR) || undefined\n        }), init);\n      }\n      let width = 0;\n      let height = 0;\n      if (\"naturalWidth\" in data) {\n        width = data.naturalWidth;\n        height = data.naturalHeight;\n      } else if (\"videoWidth\" in data) {\n        width = data.videoWidth;\n        height = data.videoHeight;\n      } else if (\"width\" in data) {\n        width = Number(data.width);\n        height = Number(data.height);\n      }\n      if (!width || !height) {\n        throw new TypeError(\"Could not determine dimensions.\");\n      }\n      const canvas = new OffscreenCanvas(width, height);\n      const context = canvas.getContext(\"2d\", {\n        alpha: isFirefox(),\n        willReadFrequently: true\n      });\n      assert(context);\n      context.drawImage(data, 0, 0);\n      this._data = canvas;\n      this._layout = null;\n      this.format = \"RGBX\";\n      this.codedWidth = width;\n      this.codedHeight = height;\n      this.rotation = init.rotation ?? 0;\n      this.timestamp = init.timestamp;\n      this.duration = init.duration ?? 0;\n      this.colorSpace = new VideoSampleColorSpace({\n        matrix: \"rgb\",\n        primaries: \"bt709\",\n        transfer: \"iec61966-2-1\",\n        fullRange: true\n      });\n    } else {\n      throw new TypeError(\"Invalid data type: Must be a BufferSource or CanvasImageSource.\");\n    }\n    finalizationRegistry?.register(this, { type: \"video\", data: this._data }, this);\n  }\n  clone() {\n    if (this._closed) {\n      throw new Error(\"VideoSample is closed.\");\n    }\n    assert(this._data !== null);\n    if (isVideoFrame(this._data)) {\n      return new VideoSample(this._data.clone(), {\n        timestamp: this.timestamp,\n        duration: this.duration,\n        rotation: this.rotation\n      });\n    } else if (this._data instanceof Uint8Array) {\n      assert(this._layout);\n      return new VideoSample(this._data, {\n        format: this.format,\n        layout: this._layout,\n        codedWidth: this.codedWidth,\n        codedHeight: this.codedHeight,\n        timestamp: this.timestamp,\n        duration: this.duration,\n        colorSpace: this.colorSpace,\n        rotation: this.rotation\n      });\n    } else {\n      return new VideoSample(this._data, {\n        format: this.format,\n        codedWidth: this.codedWidth,\n        codedHeight: this.codedHeight,\n        timestamp: this.timestamp,\n        duration: this.duration,\n        colorSpace: this.colorSpace,\n        rotation: this.rotation\n      });\n    }\n  }\n  close() {\n    if (this._closed) {\n      return;\n    }\n    finalizationRegistry?.unregister(this);\n    if (isVideoFrame(this._data)) {\n      this._data.close();\n    } else {\n      this._data = null;\n    }\n    this._closed = true;\n  }\n  allocationSize(options = {}) {\n    validateVideoFrameCopyToOptions(options);\n    if (this._closed) {\n      throw new Error(\"VideoSample is closed.\");\n    }\n    if (this.format === null) {\n      throw new Error(\"Cannot get allocation size when format is null. Sorry!\");\n    }\n    assert(this._data !== null);\n    if (!isVideoFrame(this._data)) {\n      if (options.colorSpace || options.format && options.format !== this.format || options.layout || options.rect) {\n        const videoFrame = this.toVideoFrame();\n        const size4 = videoFrame.allocationSize(options);\n        videoFrame.close();\n        return size4;\n      }\n    }\n    if (isVideoFrame(this._data)) {\n      return this._data.allocationSize(options);\n    } else if (this._data instanceof Uint8Array) {\n      return this._data.byteLength;\n    } else {\n      return this.codedWidth * this.codedHeight * 4;\n    }\n  }\n  async copyTo(destination, options = {}) {\n    if (!isAllowSharedBufferSource(destination)) {\n      throw new TypeError(\"destination must be an ArrayBuffer or an ArrayBuffer view.\");\n    }\n    validateVideoFrameCopyToOptions(options);\n    if (this._closed) {\n      throw new Error(\"VideoSample is closed.\");\n    }\n    if (this.format === null) {\n      throw new Error(\"Cannot copy video sample data when format is null. Sorry!\");\n    }\n    assert(this._data !== null);\n    if (!isVideoFrame(this._data)) {\n      if (options.colorSpace || options.format && options.format !== this.format || options.layout || options.rect) {\n        const videoFrame = this.toVideoFrame();\n        const layout = await videoFrame.copyTo(destination, options);\n        videoFrame.close();\n        return layout;\n      }\n    }\n    if (isVideoFrame(this._data)) {\n      return this._data.copyTo(destination, options);\n    } else if (this._data instanceof Uint8Array) {\n      assert(this._layout);\n      const dest = toUint8Array(destination);\n      dest.set(this._data);\n      return this._layout;\n    } else {\n      const canvas = this._data;\n      const context = canvas.getContext(\"2d\");\n      assert(context);\n      const imageData = context.getImageData(0, 0, this.codedWidth, this.codedHeight);\n      const dest = toUint8Array(destination);\n      dest.set(imageData.data);\n      return [{\n        offset: 0,\n        stride: 4 * this.codedWidth\n      }];\n    }\n  }\n  toVideoFrame() {\n    if (this._closed) {\n      throw new Error(\"VideoSample is closed.\");\n    }\n    assert(this._data !== null);\n    if (isVideoFrame(this._data)) {\n      return new VideoFrame(this._data, {\n        timestamp: this.microsecondTimestamp,\n        duration: this.microsecondDuration || undefined\n      });\n    } else if (this._data instanceof Uint8Array) {\n      return new VideoFrame(this._data, {\n        format: this.format,\n        codedWidth: this.codedWidth,\n        codedHeight: this.codedHeight,\n        timestamp: this.microsecondTimestamp,\n        duration: this.microsecondDuration || undefined,\n        colorSpace: this.colorSpace\n      });\n    } else {\n      return new VideoFrame(this._data, {\n        timestamp: this.microsecondTimestamp,\n        duration: this.microsecondDuration || undefined\n      });\n    }\n  }\n  draw(context, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8) {\n    let sx = 0;\n    let sy = 0;\n    let sWidth = this.displayWidth;\n    let sHeight = this.displayHeight;\n    let dx = 0;\n    let dy = 0;\n    let dWidth = this.displayWidth;\n    let dHeight = this.displayHeight;\n    if (arg5 !== undefined) {\n      sx = arg1;\n      sy = arg2;\n      sWidth = arg3;\n      sHeight = arg4;\n      dx = arg5;\n      dy = arg6;\n      if (arg7 !== undefined) {\n        dWidth = arg7;\n        dHeight = arg8;\n      } else {\n        dWidth = sWidth;\n        dHeight = sHeight;\n      }\n    } else {\n      dx = arg1;\n      dy = arg2;\n      if (arg3 !== undefined) {\n        dWidth = arg3;\n        dHeight = arg4;\n      }\n    }\n    if (!(typeof CanvasRenderingContext2D !== \"undefined\" && context instanceof CanvasRenderingContext2D || typeof OffscreenCanvasRenderingContext2D !== \"undefined\" && context instanceof OffscreenCanvasRenderingContext2D)) {\n      throw new TypeError(\"context must be a CanvasRenderingContext2D or OffscreenCanvasRenderingContext2D.\");\n    }\n    if (!Number.isFinite(sx)) {\n      throw new TypeError(\"sx must be a number.\");\n    }\n    if (!Number.isFinite(sy)) {\n      throw new TypeError(\"sy must be a number.\");\n    }\n    if (!Number.isFinite(sWidth) || sWidth < 0) {\n      throw new TypeError(\"sWidth must be a non-negative number.\");\n    }\n    if (!Number.isFinite(sHeight) || sHeight < 0) {\n      throw new TypeError(\"sHeight must be a non-negative number.\");\n    }\n    if (!Number.isFinite(dx)) {\n      throw new TypeError(\"dx must be a number.\");\n    }\n    if (!Number.isFinite(dy)) {\n      throw new TypeError(\"dy must be a number.\");\n    }\n    if (!Number.isFinite(dWidth) || dWidth < 0) {\n      throw new TypeError(\"dWidth must be a non-negative number.\");\n    }\n    if (!Number.isFinite(dHeight) || dHeight < 0) {\n      throw new TypeError(\"dHeight must be a non-negative number.\");\n    }\n    if (this._closed) {\n      throw new Error(\"VideoSample is closed.\");\n    }\n    ({ sx, sy, sWidth, sHeight } = this._rotateSourceRegion(sx, sy, sWidth, sHeight, this.rotation));\n    const source = this.toCanvasImageSource();\n    context.save();\n    const centerX = dx + dWidth / 2;\n    const centerY = dy + dHeight / 2;\n    context.translate(centerX, centerY);\n    context.rotate(this.rotation * Math.PI / 180);\n    const aspectRatioChange = this.rotation % 180 === 0 ? 1 : dWidth / dHeight;\n    context.scale(1 / aspectRatioChange, aspectRatioChange);\n    context.drawImage(source, sx, sy, sWidth, sHeight, -dWidth / 2, -dHeight / 2, dWidth, dHeight);\n    context.restore();\n  }\n  drawWithFit(context, options) {\n    if (!(typeof CanvasRenderingContext2D !== \"undefined\" && context instanceof CanvasRenderingContext2D || typeof OffscreenCanvasRenderingContext2D !== \"undefined\" && context instanceof OffscreenCanvasRenderingContext2D)) {\n      throw new TypeError(\"context must be a CanvasRenderingContext2D or OffscreenCanvasRenderingContext2D.\");\n    }\n    if (!options || typeof options !== \"object\") {\n      throw new TypeError(\"options must be an object.\");\n    }\n    if (![\"fill\", \"contain\", \"cover\"].includes(options.fit)) {\n      throw new TypeError(\"options.fit must be 'fill', 'contain', or 'cover'.\");\n    }\n    if (options.rotation !== undefined && ![0, 90, 180, 270].includes(options.rotation)) {\n      throw new TypeError(\"options.rotation, when provided, must be 0, 90, 180, or 270.\");\n    }\n    if (options.crop !== undefined) {\n      validateCropRectangle(options.crop, \"options.\");\n    }\n    const canvasWidth = context.canvas.width;\n    const canvasHeight = context.canvas.height;\n    const rotation = options.rotation ?? this.rotation;\n    const [rotatedWidth, rotatedHeight] = rotation % 180 === 0 ? [this.codedWidth, this.codedHeight] : [this.codedHeight, this.codedWidth];\n    if (options.crop) {\n      clampCropRectangle(options.crop, rotatedWidth, rotatedHeight);\n    }\n    let dx;\n    let dy;\n    let newWidth;\n    let newHeight;\n    const { sx, sy, sWidth, sHeight } = this._rotateSourceRegion(options.crop?.left ?? 0, options.crop?.top ?? 0, options.crop?.width ?? rotatedWidth, options.crop?.height ?? rotatedHeight, rotation);\n    if (options.fit === \"fill\") {\n      dx = 0;\n      dy = 0;\n      newWidth = canvasWidth;\n      newHeight = canvasHeight;\n    } else {\n      const [sampleWidth, sampleHeight] = options.crop ? [options.crop.width, options.crop.height] : [rotatedWidth, rotatedHeight];\n      const scale = options.fit === \"contain\" ? Math.min(canvasWidth / sampleWidth, canvasHeight / sampleHeight) : Math.max(canvasWidth / sampleWidth, canvasHeight / sampleHeight);\n      newWidth = sampleWidth * scale;\n      newHeight = sampleHeight * scale;\n      dx = (canvasWidth - newWidth) / 2;\n      dy = (canvasHeight - newHeight) / 2;\n    }\n    context.save();\n    const aspectRatioChange = rotation % 180 === 0 ? 1 : newWidth / newHeight;\n    context.translate(canvasWidth / 2, canvasHeight / 2);\n    context.rotate(rotation * Math.PI / 180);\n    context.scale(1 / aspectRatioChange, aspectRatioChange);\n    context.translate(-canvasWidth / 2, -canvasHeight / 2);\n    context.drawImage(this.toCanvasImageSource(), sx, sy, sWidth, sHeight, dx, dy, newWidth, newHeight);\n    context.restore();\n  }\n  _rotateSourceRegion(sx, sy, sWidth, sHeight, rotation) {\n    if (rotation === 90) {\n      [sx, sy, sWidth, sHeight] = [\n        sy,\n        this.codedHeight - sx - sWidth,\n        sHeight,\n        sWidth\n      ];\n    } else if (rotation === 180) {\n      [sx, sy] = [\n        this.codedWidth - sx - sWidth,\n        this.codedHeight - sy - sHeight\n      ];\n    } else if (rotation === 270) {\n      [sx, sy, sWidth, sHeight] = [\n        this.codedWidth - sy - sHeight,\n        sx,\n        sHeight,\n        sWidth\n      ];\n    }\n    return { sx, sy, sWidth, sHeight };\n  }\n  toCanvasImageSource() {\n    if (this._closed) {\n      throw new Error(\"VideoSample is closed.\");\n    }\n    assert(this._data !== null);\n    if (this._data instanceof Uint8Array) {\n      const videoFrame = this.toVideoFrame();\n      queueMicrotask(() => videoFrame.close());\n      return videoFrame;\n    } else {\n      return this._data;\n    }\n  }\n  setRotation(newRotation) {\n    if (![0, 90, 180, 270].includes(newRotation)) {\n      throw new TypeError(\"newRotation must be 0, 90, 180, or 270.\");\n    }\n    this.rotation = newRotation;\n  }\n  setTimestamp(newTimestamp) {\n    if (!Number.isFinite(newTimestamp)) {\n      throw new TypeError(\"newTimestamp must be a number.\");\n    }\n    this.timestamp = newTimestamp;\n  }\n  setDuration(newDuration) {\n    if (!Number.isFinite(newDuration) || newDuration < 0) {\n      throw new TypeError(\"newDuration must be a non-negative number.\");\n    }\n    this.duration = newDuration;\n  }\n  [Symbol.dispose]() {\n    this.close();\n  }\n}\n\nclass VideoSampleColorSpace {\n  constructor(init) {\n    this.primaries = init?.primaries ?? null;\n    this.transfer = init?.transfer ?? null;\n    this.matrix = init?.matrix ?? null;\n    this.fullRange = init?.fullRange ?? null;\n  }\n  toJSON() {\n    return {\n      primaries: this.primaries,\n      transfer: this.transfer,\n      matrix: this.matrix,\n      fullRange: this.fullRange\n    };\n  }\n}\nvar isVideoFrame = (x) => {\n  return typeof VideoFrame !== \"undefined\" && x instanceof VideoFrame;\n};\nvar clampCropRectangle = (crop, outerWidth, outerHeight) => {\n  crop.left = Math.min(crop.left, outerWidth);\n  crop.top = Math.min(crop.top, outerHeight);\n  crop.width = Math.min(crop.width, outerWidth - crop.left);\n  crop.height = Math.min(crop.height, outerHeight - crop.top);\n  assert(crop.width >= 0);\n  assert(crop.height >= 0);\n};\nvar validateCropRectangle = (crop, prefix) => {\n  if (!crop || typeof crop !== \"object\") {\n    throw new TypeError(prefix + \"crop, when provided, must be an object.\");\n  }\n  if (!Number.isInteger(crop.left) || crop.left < 0) {\n    throw new TypeError(prefix + \"crop.left must be a non-negative integer.\");\n  }\n  if (!Number.isInteger(crop.top) || crop.top < 0) {\n    throw new TypeError(prefix + \"crop.top must be a non-negative integer.\");\n  }\n  if (!Number.isInteger(crop.width) || crop.width < 0) {\n    throw new TypeError(prefix + \"crop.width must be a non-negative integer.\");\n  }\n  if (!Number.isInteger(crop.height) || crop.height < 0) {\n    throw new TypeError(prefix + \"crop.height must be a non-negative integer.\");\n  }\n};\nvar validateVideoFrameCopyToOptions = (options) => {\n  if (!options || typeof options !== \"object\") {\n    throw new TypeError(\"options must be an object.\");\n  }\n  if (options.colorSpace !== undefined && ![\"display-p3\", \"srgb\"].includes(options.colorSpace)) {\n    throw new TypeError(\"options.colorSpace, when provided, must be 'display-p3' or 'srgb'.\");\n  }\n  if (options.format !== undefined && typeof options.format !== \"string\") {\n    throw new TypeError(\"options.format, when provided, must be a string.\");\n  }\n  if (options.layout !== undefined) {\n    if (!Array.isArray(options.layout)) {\n      throw new TypeError(\"options.layout, when provided, must be an array.\");\n    }\n    for (const plane of options.layout) {\n      if (!plane || typeof plane !== \"object\") {\n        throw new TypeError(\"Each entry in options.layout must be an object.\");\n      }\n      if (!Number.isInteger(plane.offset) || plane.offset < 0) {\n        throw new TypeError(\"plane.offset must be a non-negative integer.\");\n      }\n      if (!Number.isInteger(plane.stride) || plane.stride < 0) {\n        throw new TypeError(\"plane.stride must be a non-negative integer.\");\n      }\n    }\n  }\n  if (options.rect !== undefined) {\n    if (!options.rect || typeof options.rect !== \"object\") {\n      throw new TypeError(\"options.rect, when provided, must be an object.\");\n    }\n    if (options.rect.x !== undefined && (!Number.isInteger(options.rect.x) || options.rect.x < 0)) {\n      throw new TypeError(\"options.rect.x, when provided, must be a non-negative integer.\");\n    }\n    if (options.rect.y !== undefined && (!Number.isInteger(options.rect.y) || options.rect.y < 0)) {\n      throw new TypeError(\"options.rect.y, when provided, must be a non-negative integer.\");\n    }\n    if (options.rect.width !== undefined && (!Number.isInteger(options.rect.width) || options.rect.width < 0)) {\n      throw new TypeError(\"options.rect.width, when provided, must be a non-negative integer.\");\n    }\n    if (options.rect.height !== undefined && (!Number.isInteger(options.rect.height) || options.rect.height < 0)) {\n      throw new TypeError(\"options.rect.height, when provided, must be a non-negative integer.\");\n    }\n  }\n};\nvar createDefaultPlaneLayout = (format, codedWidth, codedHeight) => {\n  const planes = getPlaneConfigs(format);\n  const layouts = [];\n  let currentOffset = 0;\n  for (const plane of planes) {\n    const planeWidth = Math.ceil(codedWidth / plane.widthDivisor);\n    const planeHeight = Math.ceil(codedHeight / plane.heightDivisor);\n    const stride = planeWidth * plane.sampleBytes;\n    const planeSize = stride * planeHeight;\n    layouts.push({\n      offset: currentOffset,\n      stride\n    });\n    currentOffset += planeSize;\n  }\n  return layouts;\n};\nvar getPlaneConfigs = (format) => {\n  const yuv = (yBytes, uvBytes, subX, subY, hasAlpha) => {\n    const configs = [\n      { sampleBytes: yBytes, widthDivisor: 1, heightDivisor: 1 },\n      { sampleBytes: uvBytes, widthDivisor: subX, heightDivisor: subY },\n      { sampleBytes: uvBytes, widthDivisor: subX, heightDivisor: subY }\n    ];\n    if (hasAlpha) {\n      configs.push({ sampleBytes: yBytes, widthDivisor: 1, heightDivisor: 1 });\n    }\n    return configs;\n  };\n  switch (format) {\n    case \"I420\":\n      return yuv(1, 1, 2, 2, false);\n    case \"I420P10\":\n    case \"I420P12\":\n      return yuv(2, 2, 2, 2, false);\n    case \"I420A\":\n      return yuv(1, 1, 2, 2, true);\n    case \"I420AP10\":\n    case \"I420AP12\":\n      return yuv(2, 2, 2, 2, true);\n    case \"I422\":\n      return yuv(1, 1, 2, 1, false);\n    case \"I422P10\":\n    case \"I422P12\":\n      return yuv(2, 2, 2, 1, false);\n    case \"I422A\":\n      return yuv(1, 1, 2, 1, true);\n    case \"I422AP10\":\n    case \"I422AP12\":\n      return yuv(2, 2, 2, 1, true);\n    case \"I444\":\n      return yuv(1, 1, 1, 1, false);\n    case \"I444P10\":\n    case \"I444P12\":\n      return yuv(2, 2, 1, 1, false);\n    case \"I444A\":\n      return yuv(1, 1, 1, 1, true);\n    case \"I444AP10\":\n    case \"I444AP12\":\n      return yuv(2, 2, 1, 1, true);\n    case \"NV12\":\n      return [\n        { sampleBytes: 1, widthDivisor: 1, heightDivisor: 1 },\n        { sampleBytes: 2, widthDivisor: 2, heightDivisor: 2 }\n      ];\n    case \"RGBA\":\n    case \"RGBX\":\n    case \"BGRA\":\n    case \"BGRX\":\n      return [\n        { sampleBytes: 4, widthDivisor: 1, heightDivisor: 1 }\n      ];\n    default:\n      assertNever(format);\n      assert(false);\n  }\n};\nvar AUDIO_SAMPLE_FORMATS = new Set([\"f32\", \"f32-planar\", \"s16\", \"s16-planar\", \"s32\", \"s32-planar\", \"u8\", \"u8-planar\"]);\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/media-sink.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar validatePacketRetrievalOptions = (options) => {\n  if (!options || typeof options !== \"object\") {\n    throw new TypeError(\"options must be an object.\");\n  }\n  if (options.metadataOnly !== undefined && typeof options.metadataOnly !== \"boolean\") {\n    throw new TypeError(\"options.metadataOnly, when defined, must be a boolean.\");\n  }\n  if (options.verifyKeyPackets !== undefined && typeof options.verifyKeyPackets !== \"boolean\") {\n    throw new TypeError(\"options.verifyKeyPackets, when defined, must be a boolean.\");\n  }\n  if (options.verifyKeyPackets && options.metadataOnly) {\n    throw new TypeError(\"options.verifyKeyPackets and options.metadataOnly cannot be enabled together.\");\n  }\n};\nvar validateTimestamp = (timestamp) => {\n  if (!isNumber(timestamp)) {\n    throw new TypeError(\"timestamp must be a number.\");\n  }\n};\nvar maybeFixPacketType = (track, promise, options) => {\n  if (options.verifyKeyPackets) {\n    return promise.then(async (packet) => {\n      if (!packet || packet.type === \"delta\") {\n        return packet;\n      }\n      const determinedType = await track.determinePacketType(packet);\n      if (determinedType) {\n        packet.type = determinedType;\n      }\n      return packet;\n    });\n  } else {\n    return promise;\n  }\n};\n\nclass EncodedPacketSink {\n  constructor(track) {\n    if (!(track instanceof InputTrack)) {\n      throw new TypeError(\"track must be an InputTrack.\");\n    }\n    this._track = track;\n  }\n  getFirstPacket(options = {}) {\n    validatePacketRetrievalOptions(options);\n    if (this._track.input._disposed) {\n      throw new InputDisposedError;\n    }\n    return maybeFixPacketType(this._track, this._track._backing.getFirstPacket(options), options);\n  }\n  getPacket(timestamp, options = {}) {\n    validateTimestamp(timestamp);\n    validatePacketRetrievalOptions(options);\n    if (this._track.input._disposed) {\n      throw new InputDisposedError;\n    }\n    return maybeFixPacketType(this._track, this._track._backing.getPacket(timestamp, options), options);\n  }\n  getNextPacket(packet, options = {}) {\n    if (!(packet instanceof EncodedPacket)) {\n      throw new TypeError(\"packet must be an EncodedPacket.\");\n    }\n    validatePacketRetrievalOptions(options);\n    if (this._track.input._disposed) {\n      throw new InputDisposedError;\n    }\n    return maybeFixPacketType(this._track, this._track._backing.getNextPacket(packet, options), options);\n  }\n  async getKeyPacket(timestamp, options = {}) {\n    validateTimestamp(timestamp);\n    validatePacketRetrievalOptions(options);\n    if (this._track.input._disposed) {\n      throw new InputDisposedError;\n    }\n    if (!options.verifyKeyPackets) {\n      return this._track._backing.getKeyPacket(timestamp, options);\n    }\n    const packet = await this._track._backing.getKeyPacket(timestamp, options);\n    if (!packet) {\n      return packet;\n    }\n    assert(packet.type === \"key\");\n    const determinedType = await this._track.determinePacketType(packet);\n    if (determinedType === \"delta\") {\n      return this.getKeyPacket(packet.timestamp - 1 / this._track.timeResolution, options);\n    }\n    return packet;\n  }\n  async getNextKeyPacket(packet, options = {}) {\n    if (!(packet instanceof EncodedPacket)) {\n      throw new TypeError(\"packet must be an EncodedPacket.\");\n    }\n    validatePacketRetrievalOptions(options);\n    if (this._track.input._disposed) {\n      throw new InputDisposedError;\n    }\n    if (!options.verifyKeyPackets) {\n      return this._track._backing.getNextKeyPacket(packet, options);\n    }\n    const nextPacket = await this._track._backing.getNextKeyPacket(packet, options);\n    if (!nextPacket) {\n      return nextPacket;\n    }\n    assert(nextPacket.type === \"key\");\n    const determinedType = await this._track.determinePacketType(nextPacket);\n    if (determinedType === \"delta\") {\n      return this.getNextKeyPacket(nextPacket, options);\n    }\n    return nextPacket;\n  }\n  packets(startPacket, endPacket, options = {}) {\n    if (startPacket !== undefined && !(startPacket instanceof EncodedPacket)) {\n      throw new TypeError(\"startPacket must be an EncodedPacket.\");\n    }\n    if (startPacket !== undefined && startPacket.isMetadataOnly && !options?.metadataOnly) {\n      throw new TypeError(\"startPacket can only be metadata-only if options.metadataOnly is enabled.\");\n    }\n    if (endPacket !== undefined && !(endPacket instanceof EncodedPacket)) {\n      throw new TypeError(\"endPacket must be an EncodedPacket.\");\n    }\n    validatePacketRetrievalOptions(options);\n    if (this._track.input._disposed) {\n      throw new InputDisposedError;\n    }\n    const packetQueue = [];\n    let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers();\n    let { promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers();\n    let ended = false;\n    let terminated = false;\n    let outOfBandError = null;\n    const timestamps = [];\n    const maxQueueSize = () => Math.max(2, timestamps.length);\n    (async () => {\n      let packet = startPacket ?? await this.getFirstPacket(options);\n      while (packet && !terminated && !this._track.input._disposed) {\n        if (endPacket && packet.sequenceNumber >= endPacket?.sequenceNumber) {\n          break;\n        }\n        if (packetQueue.length > maxQueueSize()) {\n          ({ promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers());\n          await queueDequeue;\n          continue;\n        }\n        packetQueue.push(packet);\n        onQueueNotEmpty();\n        ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers());\n        packet = await this.getNextPacket(packet, options);\n      }\n      ended = true;\n      onQueueNotEmpty();\n    })().catch((error) => {\n      if (!outOfBandError) {\n        outOfBandError = error;\n        onQueueNotEmpty();\n      }\n    });\n    const track = this._track;\n    return {\n      async next() {\n        while (true) {\n          if (track.input._disposed) {\n            throw new InputDisposedError;\n          } else if (terminated) {\n            return { value: undefined, done: true };\n          } else if (outOfBandError) {\n            throw outOfBandError;\n          } else if (packetQueue.length > 0) {\n            const value = packetQueue.shift();\n            const now = performance.now();\n            timestamps.push(now);\n            while (timestamps.length > 0 && now - timestamps[0] >= 1000) {\n              timestamps.shift();\n            }\n            onQueueDequeue();\n            return { value, done: false };\n          } else if (ended) {\n            return { value: undefined, done: true };\n          } else {\n            await queueNotEmpty;\n          }\n        }\n      },\n      async return() {\n        terminated = true;\n        onQueueDequeue();\n        onQueueNotEmpty();\n        return { value: undefined, done: true };\n      },\n      async throw(error) {\n        throw error;\n      },\n      [Symbol.asyncIterator]() {\n        return this;\n      }\n    };\n  }\n}\n\nclass DecoderWrapper {\n  constructor(onSample, onError) {\n    this.onSample = onSample;\n    this.onError = onError;\n  }\n}\n\nclass BaseMediaSampleSink {\n  mediaSamplesInRange(startTimestamp = 0, endTimestamp = Infinity) {\n    validateTimestamp(startTimestamp);\n    validateTimestamp(endTimestamp);\n    const sampleQueue = [];\n    let firstSampleQueued = false;\n    let lastSample = null;\n    let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers();\n    let { promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers();\n    let decoderIsFlushed = false;\n    let ended = false;\n    let terminated = false;\n    let outOfBandError = null;\n    (async () => {\n      const decoder = await this._createDecoder((sample) => {\n        onQueueDequeue();\n        if (sample.timestamp >= endTimestamp) {\n          ended = true;\n        }\n        if (ended) {\n          sample.close();\n          return;\n        }\n        if (lastSample) {\n          if (sample.timestamp > startTimestamp) {\n            sampleQueue.push(lastSample);\n            firstSampleQueued = true;\n          } else {\n            lastSample.close();\n          }\n        }\n        if (sample.timestamp >= startTimestamp) {\n          sampleQueue.push(sample);\n          firstSampleQueued = true;\n        }\n        lastSample = firstSampleQueued ? null : sample;\n        if (sampleQueue.length > 0) {\n          onQueueNotEmpty();\n          ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers());\n        }\n      }, (error) => {\n        if (!outOfBandError) {\n          outOfBandError = error;\n          onQueueNotEmpty();\n        }\n      });\n      const packetSink = this._createPacketSink();\n      const keyPacket = await packetSink.getKeyPacket(startTimestamp, { verifyKeyPackets: true }) ?? await packetSink.getFirstPacket();\n      let currentPacket = keyPacket;\n      const endPacket = undefined;\n      const packets = packetSink.packets(keyPacket ?? undefined, endPacket);\n      await packets.next();\n      while (currentPacket && !ended && !this._track.input._disposed) {\n        const maxQueueSize = computeMaxQueueSize(sampleQueue.length);\n        if (sampleQueue.length + decoder.getDecodeQueueSize() > maxQueueSize) {\n          ({ promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers());\n          await queueDequeue;\n          continue;\n        }\n        decoder.decode(currentPacket);\n        const packetResult = await packets.next();\n        if (packetResult.done) {\n          break;\n        }\n        currentPacket = packetResult.value;\n      }\n      await packets.return();\n      if (!terminated && !this._track.input._disposed) {\n        await decoder.flush();\n      }\n      decoder.close();\n      if (!firstSampleQueued && lastSample) {\n        sampleQueue.push(lastSample);\n      }\n      decoderIsFlushed = true;\n      onQueueNotEmpty();\n    })().catch((error) => {\n      if (!outOfBandError) {\n        outOfBandError = error;\n        onQueueNotEmpty();\n      }\n    });\n    const track = this._track;\n    const closeSamples = () => {\n      lastSample?.close();\n      for (const sample of sampleQueue) {\n        sample.close();\n      }\n    };\n    return {\n      async next() {\n        while (true) {\n          if (track.input._disposed) {\n            closeSamples();\n            throw new InputDisposedError;\n          } else if (terminated) {\n            return { value: undefined, done: true };\n          } else if (outOfBandError) {\n            closeSamples();\n            throw outOfBandError;\n          } else if (sampleQueue.length > 0) {\n            const value = sampleQueue.shift();\n            onQueueDequeue();\n            return { value, done: false };\n          } else if (!decoderIsFlushed) {\n            await queueNotEmpty;\n          } else {\n            return { value: undefined, done: true };\n          }\n        }\n      },\n      async return() {\n        terminated = true;\n        ended = true;\n        onQueueDequeue();\n        onQueueNotEmpty();\n        closeSamples();\n        return { value: undefined, done: true };\n      },\n      async throw(error) {\n        throw error;\n      },\n      [Symbol.asyncIterator]() {\n        return this;\n      }\n    };\n  }\n  mediaSamplesAtTimestamps(timestamps) {\n    validateAnyIterable(timestamps);\n    const timestampIterator = toAsyncIterator(timestamps);\n    const timestampsOfInterest = [];\n    const sampleQueue = [];\n    let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers();\n    let { promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers();\n    let decoderIsFlushed = false;\n    let terminated = false;\n    let outOfBandError = null;\n    const pushToQueue = (sample) => {\n      sampleQueue.push(sample);\n      onQueueNotEmpty();\n      ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers());\n    };\n    (async () => {\n      const decoder = await this._createDecoder((sample) => {\n        onQueueDequeue();\n        if (terminated) {\n          sample.close();\n          return;\n        }\n        let sampleUses = 0;\n        while (timestampsOfInterest.length > 0 && sample.timestamp - timestampsOfInterest[0] > -0.0000000001) {\n          sampleUses++;\n          timestampsOfInterest.shift();\n        }\n        if (sampleUses > 0) {\n          for (let i = 0;i < sampleUses; i++) {\n            pushToQueue(i < sampleUses - 1 ? sample.clone() : sample);\n          }\n        } else {\n          sample.close();\n        }\n      }, (error) => {\n        if (!outOfBandError) {\n          outOfBandError = error;\n          onQueueNotEmpty();\n        }\n      });\n      const packetSink = this._createPacketSink();\n      let lastPacket = null;\n      let lastKeyPacket = null;\n      let maxSequenceNumber = -1;\n      const decodePackets = async () => {\n        assert(lastKeyPacket);\n        let currentPacket = lastKeyPacket;\n        decoder.decode(currentPacket);\n        while (currentPacket.sequenceNumber < maxSequenceNumber) {\n          const maxQueueSize = computeMaxQueueSize(sampleQueue.length);\n          while (sampleQueue.length + decoder.getDecodeQueueSize() > maxQueueSize && !terminated) {\n            ({ promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers());\n            await queueDequeue;\n          }\n          if (terminated) {\n            break;\n          }\n          const nextPacket = await packetSink.getNextPacket(currentPacket);\n          assert(nextPacket);\n          decoder.decode(nextPacket);\n          currentPacket = nextPacket;\n        }\n        maxSequenceNumber = -1;\n      };\n      const flushDecoder = async () => {\n        await decoder.flush();\n        for (let i = 0;i < timestampsOfInterest.length; i++) {\n          pushToQueue(null);\n        }\n        timestampsOfInterest.length = 0;\n      };\n      for await (const timestamp of timestampIterator) {\n        validateTimestamp(timestamp);\n        if (terminated || this._track.input._disposed) {\n          break;\n        }\n        const targetPacket = await packetSink.getPacket(timestamp);\n        const keyPacket = targetPacket && await packetSink.getKeyPacket(timestamp, { verifyKeyPackets: true });\n        if (!keyPacket) {\n          if (maxSequenceNumber !== -1) {\n            await decodePackets();\n            await flushDecoder();\n          }\n          pushToQueue(null);\n          lastPacket = null;\n          continue;\n        }\n        if (lastPacket && (keyPacket.sequenceNumber !== lastKeyPacket.sequenceNumber || targetPacket.timestamp < lastPacket.timestamp)) {\n          await decodePackets();\n          await flushDecoder();\n        }\n        timestampsOfInterest.push(targetPacket.timestamp);\n        maxSequenceNumber = Math.max(targetPacket.sequenceNumber, maxSequenceNumber);\n        lastPacket = targetPacket;\n        lastKeyPacket = keyPacket;\n      }\n      if (!terminated && !this._track.input._disposed) {\n        if (maxSequenceNumber !== -1) {\n          await decodePackets();\n        }\n        await flushDecoder();\n      }\n      decoder.close();\n      decoderIsFlushed = true;\n      onQueueNotEmpty();\n    })().catch((error) => {\n      if (!outOfBandError) {\n        outOfBandError = error;\n        onQueueNotEmpty();\n      }\n    });\n    const track = this._track;\n    const closeSamples = () => {\n      for (const sample of sampleQueue) {\n        sample?.close();\n      }\n    };\n    return {\n      async next() {\n        while (true) {\n          if (track.input._disposed) {\n            closeSamples();\n            throw new InputDisposedError;\n          } else if (terminated) {\n            return { value: undefined, done: true };\n          } else if (outOfBandError) {\n            closeSamples();\n            throw outOfBandError;\n          } else if (sampleQueue.length > 0) {\n            const value = sampleQueue.shift();\n            assert(value !== undefined);\n            onQueueDequeue();\n            return { value, done: false };\n          } else if (!decoderIsFlushed) {\n            await queueNotEmpty;\n          } else {\n            return { value: undefined, done: true };\n          }\n        }\n      },\n      async return() {\n        terminated = true;\n        onQueueDequeue();\n        onQueueNotEmpty();\n        closeSamples();\n        return { value: undefined, done: true };\n      },\n      async throw(error) {\n        throw error;\n      },\n      [Symbol.asyncIterator]() {\n        return this;\n      }\n    };\n  }\n}\nvar computeMaxQueueSize = (decodedSampleQueueSize) => {\n  return decodedSampleQueueSize === 0 ? 40 : 8;\n};\n\nclass VideoDecoderWrapper extends DecoderWrapper {\n  constructor(onSample, onError, codec, decoderConfig, rotation, timeResolution) {\n    super(onSample, onError);\n    this.codec = codec;\n    this.decoderConfig = decoderConfig;\n    this.rotation = rotation;\n    this.timeResolution = timeResolution;\n    this.decoder = null;\n    this.customDecoder = null;\n    this.customDecoderCallSerializer = new CallSerializer;\n    this.customDecoderQueueSize = 0;\n    this.inputTimestamps = [];\n    this.sampleQueue = [];\n    this.currentPacketIndex = 0;\n    this.raslSkipped = false;\n    this.alphaDecoder = null;\n    this.alphaHadKeyframe = false;\n    this.colorQueue = [];\n    this.alphaQueue = [];\n    this.merger = null;\n    this.mergerCreationFailed = false;\n    this.decodedAlphaChunkCount = 0;\n    this.alphaDecoderQueueSize = 0;\n    this.nullAlphaFrameQueue = [];\n    this.currentAlphaPacketIndex = 0;\n    this.alphaRaslSkipped = false;\n    const MatchingCustomDecoder = customVideoDecoders.find((x) => x.supports(codec, decoderConfig));\n    if (MatchingCustomDecoder) {\n      this.customDecoder = new MatchingCustomDecoder;\n      this.customDecoder.codec = codec;\n      this.customDecoder.config = decoderConfig;\n      this.customDecoder.onSample = (sample) => {\n        if (!(sample instanceof VideoSample)) {\n          throw new TypeError(\"The argument passed to onSample must be a VideoSample.\");\n        }\n        this.finalizeAndEmitSample(sample);\n      };\n      this.customDecoderCallSerializer.call(() => this.customDecoder.init());\n    } else {\n      const colorHandler = (frame2) => {\n        if (this.alphaQueue.length > 0) {\n          const alphaFrame = this.alphaQueue.shift();\n          assert(alphaFrame !== undefined);\n          this.mergeAlpha(frame2, alphaFrame);\n        } else {\n          this.colorQueue.push(frame2);\n        }\n      };\n      if (codec === \"avc\" && this.decoderConfig.description && isChromium()) {\n        const record = deserializeAvcDecoderConfigurationRecord(toUint8Array(this.decoderConfig.description));\n        if (record && record.sequenceParameterSets.length > 0) {\n          const sps = parseAvcSps(record.sequenceParameterSets[0]);\n          if (sps && sps.frameMbsOnlyFlag === 0) {\n            this.decoderConfig = {\n              ...this.decoderConfig,\n              hardwareAcceleration: \"prefer-software\"\n            };\n          }\n        }\n      }\n      const stack2 = new Error(\"Decoding error\").stack;\n      this.decoder = new VideoDecoder({\n        output: (frame2) => {\n          try {\n            colorHandler(frame2);\n          } catch (error) {\n            this.onError(error);\n          }\n        },\n        error: (error) => {\n          error.stack = stack2;\n          this.onError(error);\n        }\n      });\n      this.decoder.configure(this.decoderConfig);\n    }\n  }\n  getDecodeQueueSize() {\n    if (this.customDecoder) {\n      return this.customDecoderQueueSize;\n    } else {\n      assert(this.decoder);\n      return Math.max(this.decoder.decodeQueueSize, this.alphaDecoder?.decodeQueueSize ?? 0);\n    }\n  }\n  decode(packet) {\n    if (this.codec === \"hevc\" && this.currentPacketIndex > 0 && !this.raslSkipped) {\n      if (this.hasHevcRaslPicture(packet.data)) {\n        return;\n      }\n      this.raslSkipped = true;\n    }\n    if (this.customDecoder) {\n      this.customDecoderQueueSize++;\n      this.customDecoderCallSerializer.call(() => this.customDecoder.decode(packet)).then(() => this.customDecoderQueueSize--);\n    } else {\n      assert(this.decoder);\n      if (!isWebKit()) {\n        insertSorted(this.inputTimestamps, packet.timestamp, (x) => x);\n      }\n      if (isChromium() && this.currentPacketIndex === 0 && this.codec === \"avc\") {\n        const filteredNalUnits = [];\n        for (const loc of iterateAvcNalUnits(packet.data, this.decoderConfig)) {\n          const type = extractNalUnitTypeForAvc(packet.data[loc.offset]);\n          if (!(type >= 20 && type <= 31)) {\n            filteredNalUnits.push(packet.data.subarray(loc.offset, loc.offset + loc.length));\n          }\n        }\n        const newData = concatAvcNalUnits(filteredNalUnits, this.decoderConfig);\n        packet = new EncodedPacket(newData, packet.type, packet.timestamp, packet.duration);\n      }\n      this.decoder.decode(packet.toEncodedVideoChunk());\n      this.decodeAlphaData(packet);\n    }\n    this.currentPacketIndex++;\n  }\n  decodeAlphaData(packet) {\n    if (!packet.sideData.alpha || this.mergerCreationFailed) {\n      this.pushNullAlphaFrame();\n      return;\n    }\n    if (!this.merger) {\n      try {\n        this.merger = new ColorAlphaMerger;\n      } catch (error) {\n        console.error(\"Due to an error, only color data will be decoded.\", error);\n        this.mergerCreationFailed = true;\n        this.decodeAlphaData(packet);\n        return;\n      }\n    }\n    if (!this.alphaDecoder) {\n      const alphaHandler = (frame2) => {\n        this.alphaDecoderQueueSize--;\n        if (this.colorQueue.length > 0) {\n          const colorFrame = this.colorQueue.shift();\n          assert(colorFrame !== undefined);\n          this.mergeAlpha(colorFrame, frame2);\n        } else {\n          this.alphaQueue.push(frame2);\n        }\n        this.decodedAlphaChunkCount++;\n        while (this.nullAlphaFrameQueue.length > 0 && this.nullAlphaFrameQueue[0] === this.decodedAlphaChunkCount) {\n          this.nullAlphaFrameQueue.shift();\n          if (this.colorQueue.length > 0) {\n            const colorFrame = this.colorQueue.shift();\n            assert(colorFrame !== undefined);\n            this.mergeAlpha(colorFrame, null);\n          } else {\n            this.alphaQueue.push(null);\n          }\n        }\n      };\n      const stack2 = new Error(\"Decoding error\").stack;\n      this.alphaDecoder = new VideoDecoder({\n        output: (frame2) => {\n          try {\n            alphaHandler(frame2);\n          } catch (error) {\n            this.onError(error);\n          }\n        },\n        error: (error) => {\n          error.stack = stack2;\n          this.onError(error);\n        }\n      });\n      this.alphaDecoder.configure(this.decoderConfig);\n    }\n    const type = determineVideoPacketType(this.codec, this.decoderConfig, packet.sideData.alpha);\n    if (!this.alphaHadKeyframe) {\n      this.alphaHadKeyframe = type === \"key\";\n    }\n    if (this.alphaHadKeyframe) {\n      if (this.codec === \"hevc\" && this.currentAlphaPacketIndex > 0 && !this.alphaRaslSkipped) {\n        if (this.hasHevcRaslPicture(packet.sideData.alpha)) {\n          this.pushNullAlphaFrame();\n          return;\n        }\n        this.alphaRaslSkipped = true;\n      }\n      this.currentAlphaPacketIndex++;\n      this.alphaDecoder.decode(packet.alphaToEncodedVideoChunk(type ?? packet.type));\n      this.alphaDecoderQueueSize++;\n    } else {\n      this.pushNullAlphaFrame();\n    }\n  }\n  pushNullAlphaFrame() {\n    if (this.alphaDecoderQueueSize === 0) {\n      this.alphaQueue.push(null);\n    } else {\n      this.nullAlphaFrameQueue.push(this.decodedAlphaChunkCount + this.alphaDecoderQueueSize);\n    }\n  }\n  hasHevcRaslPicture(packetData) {\n    for (const loc of iterateHevcNalUnits(packetData, this.decoderConfig)) {\n      const type = extractNalUnitTypeForHevc(packetData[loc.offset]);\n      if (type === HevcNalUnitType.RASL_N || type === HevcNalUnitType.RASL_R) {\n        return true;\n      }\n    }\n    return false;\n  }\n  sampleHandler(sample) {\n    if (isWebKit()) {\n      if (this.sampleQueue.length > 0 && sample.timestamp >= last(this.sampleQueue).timestamp) {\n        for (const sample2 of this.sampleQueue) {\n          this.finalizeAndEmitSample(sample2);\n        }\n        this.sampleQueue.length = 0;\n      }\n      insertSorted(this.sampleQueue, sample, (x) => x.timestamp);\n    } else {\n      const timestamp = this.inputTimestamps.shift();\n      assert(timestamp !== undefined);\n      sample.setTimestamp(timestamp);\n      this.finalizeAndEmitSample(sample);\n    }\n  }\n  finalizeAndEmitSample(sample) {\n    sample.setTimestamp(Math.round(sample.timestamp * this.timeResolution) / this.timeResolution);\n    sample.setDuration(Math.round(sample.duration * this.timeResolution) / this.timeResolution);\n    sample.setRotation(this.rotation);\n    this.onSample(sample);\n  }\n  mergeAlpha(color, alpha) {\n    if (!alpha) {\n      const finalSample2 = new VideoSample(color);\n      this.sampleHandler(finalSample2);\n      return;\n    }\n    assert(this.merger);\n    this.merger.update(color, alpha);\n    color.close();\n    alpha.close();\n    const finalFrame = new VideoFrame(this.merger.canvas, {\n      timestamp: color.timestamp,\n      duration: color.duration ?? undefined\n    });\n    const finalSample = new VideoSample(finalFrame);\n    this.sampleHandler(finalSample);\n  }\n  async flush() {\n    if (this.customDecoder) {\n      await this.customDecoderCallSerializer.call(() => this.customDecoder.flush());\n    } else {\n      assert(this.decoder);\n      await Promise.all([\n        this.decoder.flush(),\n        this.alphaDecoder?.flush()\n      ]);\n      this.colorQueue.forEach((x) => x.close());\n      this.colorQueue.length = 0;\n      this.alphaQueue.forEach((x) => x?.close());\n      this.alphaQueue.length = 0;\n      this.alphaHadKeyframe = false;\n      this.decodedAlphaChunkCount = 0;\n      this.alphaDecoderQueueSize = 0;\n      this.nullAlphaFrameQueue.length = 0;\n      this.currentAlphaPacketIndex = 0;\n      this.alphaRaslSkipped = false;\n    }\n    if (isWebKit()) {\n      for (const sample of this.sampleQueue) {\n        this.finalizeAndEmitSample(sample);\n      }\n      this.sampleQueue.length = 0;\n    }\n    this.currentPacketIndex = 0;\n    this.raslSkipped = false;\n  }\n  close() {\n    if (this.customDecoder) {\n      this.customDecoderCallSerializer.call(() => this.customDecoder.close());\n    } else {\n      assert(this.decoder);\n      this.decoder.close();\n      this.alphaDecoder?.close();\n      this.colorQueue.forEach((x) => x.close());\n      this.colorQueue.length = 0;\n      this.alphaQueue.forEach((x) => x?.close());\n      this.alphaQueue.length = 0;\n      this.merger?.close();\n    }\n    for (const sample of this.sampleQueue) {\n      sample.close();\n    }\n    this.sampleQueue.length = 0;\n  }\n}\n\nclass ColorAlphaMerger {\n  constructor() {\n    if (typeof OffscreenCanvas !== \"undefined\") {\n      this.canvas = new OffscreenCanvas(300, 150);\n    } else {\n      this.canvas = document.createElement(\"canvas\");\n    }\n    const gl = this.canvas.getContext(\"webgl2\", {\n      premultipliedAlpha: false\n    });\n    if (!gl) {\n      throw new Error(\"Couldn't acquire WebGL 2 context.\");\n    }\n    this.gl = gl;\n    this.program = this.createProgram();\n    this.vao = this.createVAO();\n    this.colorTexture = this.createTexture();\n    this.alphaTexture = this.createTexture();\n    this.gl.useProgram(this.program);\n    this.gl.uniform1i(this.gl.getUniformLocation(this.program, \"u_colorTexture\"), 0);\n    this.gl.uniform1i(this.gl.getUniformLocation(this.program, \"u_alphaTexture\"), 1);\n  }\n  createProgram() {\n    const vertexShader = this.createShader(this.gl.VERTEX_SHADER, `#version 300 es\n\t\t\tin vec2 a_position;\n\t\t\tin vec2 a_texCoord;\n\t\t\tout vec2 v_texCoord;\n\t\t\t\n\t\t\tvoid main() {\n\t\t\t\tgl_Position = vec4(a_position, 0.0, 1.0);\n\t\t\t\tv_texCoord = a_texCoord;\n\t\t\t}\n\t\t`);\n    const fragmentShader = this.createShader(this.gl.FRAGMENT_SHADER, `#version 300 es\n\t\t\tprecision highp float;\n\t\t\t\n\t\t\tuniform sampler2D u_colorTexture;\n\t\t\tuniform sampler2D u_alphaTexture;\n\t\t\tin vec2 v_texCoord;\n\t\t\tout vec4 fragColor;\n\t\t\t\n\t\t\tvoid main() {\n\t\t\t\tvec3 color = texture(u_colorTexture, v_texCoord).rgb;\n\t\t\t\tfloat alpha = texture(u_alphaTexture, v_texCoord).r;\n\t\t\t\tfragColor = vec4(color, alpha);\n\t\t\t}\n\t\t`);\n    const program = this.gl.createProgram();\n    this.gl.attachShader(program, vertexShader);\n    this.gl.attachShader(program, fragmentShader);\n    this.gl.linkProgram(program);\n    return program;\n  }\n  createShader(type, source) {\n    const shader = this.gl.createShader(type);\n    this.gl.shaderSource(shader, source);\n    this.gl.compileShader(shader);\n    return shader;\n  }\n  createVAO() {\n    const vao = this.gl.createVertexArray();\n    this.gl.bindVertexArray(vao);\n    const vertices = new Float32Array([\n      -1,\n      -1,\n      0,\n      1,\n      1,\n      -1,\n      1,\n      1,\n      -1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      0\n    ]);\n    const buffer = this.gl.createBuffer();\n    this.gl.bindBuffer(this.gl.ARRAY_BUFFER, buffer);\n    this.gl.bufferData(this.gl.ARRAY_BUFFER, vertices, this.gl.STATIC_DRAW);\n    const positionLocation = this.gl.getAttribLocation(this.program, \"a_position\");\n    const texCoordLocation = this.gl.getAttribLocation(this.program, \"a_texCoord\");\n    this.gl.enableVertexAttribArray(positionLocation);\n    this.gl.vertexAttribPointer(positionLocation, 2, this.gl.FLOAT, false, 16, 0);\n    this.gl.enableVertexAttribArray(texCoordLocation);\n    this.gl.vertexAttribPointer(texCoordLocation, 2, this.gl.FLOAT, false, 16, 8);\n    return vao;\n  }\n  createTexture() {\n    const texture = this.gl.createTexture();\n    this.gl.bindTexture(this.gl.TEXTURE_2D, texture);\n    this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);\n    this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);\n    this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR);\n    this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR);\n    return texture;\n  }\n  update(color, alpha) {\n    if (color.displayWidth !== this.canvas.width || color.displayHeight !== this.canvas.height) {\n      this.canvas.width = color.displayWidth;\n      this.canvas.height = color.displayHeight;\n    }\n    this.gl.activeTexture(this.gl.TEXTURE0);\n    this.gl.bindTexture(this.gl.TEXTURE_2D, this.colorTexture);\n    this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, color);\n    this.gl.activeTexture(this.gl.TEXTURE1);\n    this.gl.bindTexture(this.gl.TEXTURE_2D, this.alphaTexture);\n    this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, alpha);\n    this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);\n    this.gl.clear(this.gl.COLOR_BUFFER_BIT);\n    this.gl.bindVertexArray(this.vao);\n    this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);\n  }\n  close() {\n    this.gl.getExtension(\"WEBGL_lose_context\")?.loseContext();\n    this.gl = null;\n  }\n}\n\nclass VideoSampleSink extends BaseMediaSampleSink {\n  constructor(videoTrack) {\n    if (!(videoTrack instanceof InputVideoTrack)) {\n      throw new TypeError(\"videoTrack must be an InputVideoTrack.\");\n    }\n    super();\n    this._track = videoTrack;\n  }\n  async _createDecoder(onSample, onError) {\n    if (!await this._track.canDecode()) {\n      throw new Error(\"This video track cannot be decoded by this browser. Make sure to check decodability before using\" + \" a track.\");\n    }\n    const codec = this._track.codec;\n    const rotation = this._track.rotation;\n    const decoderConfig = await this._track.getDecoderConfig();\n    const timeResolution = this._track.timeResolution;\n    assert(codec && decoderConfig);\n    return new VideoDecoderWrapper(onSample, onError, codec, decoderConfig, rotation, timeResolution);\n  }\n  _createPacketSink() {\n    return new EncodedPacketSink(this._track);\n  }\n  async getSample(timestamp) {\n    validateTimestamp(timestamp);\n    for await (const sample of this.mediaSamplesAtTimestamps([timestamp])) {\n      return sample;\n    }\n    throw new Error(\"Internal error: Iterator returned nothing.\");\n  }\n  samples(startTimestamp = 0, endTimestamp = Infinity) {\n    return this.mediaSamplesInRange(startTimestamp, endTimestamp);\n  }\n  samplesAtTimestamps(timestamps) {\n    return this.mediaSamplesAtTimestamps(timestamps);\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/input-track.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\nclass InputTrack {\n  constructor(input2, backing) {\n    this.input = input2;\n    this._backing = backing;\n  }\n  isVideoTrack() {\n    return this instanceof InputVideoTrack;\n  }\n  isAudioTrack() {\n    return this instanceof InputAudioTrack;\n  }\n  get id() {\n    return this._backing.getId();\n  }\n  get internalCodecId() {\n    return this._backing.getInternalCodecId();\n  }\n  get languageCode() {\n    return this._backing.getLanguageCode();\n  }\n  get name() {\n    return this._backing.getName();\n  }\n  get timeResolution() {\n    return this._backing.getTimeResolution();\n  }\n  get disposition() {\n    return this._backing.getDisposition();\n  }\n  getFirstTimestamp() {\n    return this._backing.getFirstTimestamp();\n  }\n  computeDuration() {\n    return this._backing.computeDuration();\n  }\n  async computePacketStats(targetPacketCount = Infinity) {\n    const sink = new EncodedPacketSink(this);\n    let startTimestamp = Infinity;\n    let endTimestamp = -Infinity;\n    let packetCount = 0;\n    let totalPacketBytes = 0;\n    for await (const packet of sink.packets(undefined, undefined, { metadataOnly: true })) {\n      if (packetCount >= targetPacketCount && packet.timestamp >= endTimestamp) {\n        break;\n      }\n      startTimestamp = Math.min(startTimestamp, packet.timestamp);\n      endTimestamp = Math.max(endTimestamp, packet.timestamp + packet.duration);\n      packetCount++;\n      totalPacketBytes += packet.byteLength;\n    }\n    return {\n      packetCount,\n      averagePacketRate: packetCount ? Number((packetCount / (endTimestamp - startTimestamp)).toPrecision(16)) : 0,\n      averageBitrate: packetCount ? Number((8 * totalPacketBytes / (endTimestamp - startTimestamp)).toPrecision(16)) : 0\n    };\n  }\n}\n\nclass InputVideoTrack extends InputTrack {\n  constructor(input2, backing) {\n    super(input2, backing);\n    this._backing = backing;\n  }\n  get type() {\n    return \"video\";\n  }\n  get codec() {\n    return this._backing.getCodec();\n  }\n  get codedWidth() {\n    return this._backing.getCodedWidth();\n  }\n  get codedHeight() {\n    return this._backing.getCodedHeight();\n  }\n  get rotation() {\n    return this._backing.getRotation();\n  }\n  get displayWidth() {\n    const rotation = this._backing.getRotation();\n    return rotation % 180 === 0 ? this._backing.getCodedWidth() : this._backing.getCodedHeight();\n  }\n  get displayHeight() {\n    const rotation = this._backing.getRotation();\n    return rotation % 180 === 0 ? this._backing.getCodedHeight() : this._backing.getCodedWidth();\n  }\n  getColorSpace() {\n    return this._backing.getColorSpace();\n  }\n  async hasHighDynamicRange() {\n    const colorSpace = await this._backing.getColorSpace();\n    return colorSpace.primaries === \"bt2020\" || colorSpace.primaries === \"smpte432\" || colorSpace.transfer === \"pg\" || colorSpace.transfer === \"hlg\" || colorSpace.matrix === \"bt2020-ncl\";\n  }\n  canBeTransparent() {\n    return this._backing.canBeTransparent();\n  }\n  getDecoderConfig() {\n    return this._backing.getDecoderConfig();\n  }\n  async getCodecParameterString() {\n    const decoderConfig = await this._backing.getDecoderConfig();\n    return decoderConfig?.codec ?? null;\n  }\n  async canDecode() {\n    try {\n      const decoderConfig = await this._backing.getDecoderConfig();\n      if (!decoderConfig) {\n        return false;\n      }\n      const codec = this._backing.getCodec();\n      assert(codec !== null);\n      if (customVideoDecoders.some((x) => x.supports(codec, decoderConfig))) {\n        return true;\n      }\n      if (typeof VideoDecoder === \"undefined\") {\n        return false;\n      }\n      const support = await VideoDecoder.isConfigSupported(decoderConfig);\n      return support.supported === true;\n    } catch (error) {\n      console.error(\"Error during decodability check:\", error);\n      return false;\n    }\n  }\n  async determinePacketType(packet) {\n    if (!(packet instanceof EncodedPacket)) {\n      throw new TypeError(\"packet must be an EncodedPacket.\");\n    }\n    if (packet.isMetadataOnly) {\n      throw new TypeError(\"packet must not be metadata-only to determine its type.\");\n    }\n    if (this.codec === null) {\n      return null;\n    }\n    const decoderConfig = await this.getDecoderConfig();\n    assert(decoderConfig);\n    return determineVideoPacketType(this.codec, decoderConfig, packet.data);\n  }\n}\n\nclass InputAudioTrack extends InputTrack {\n  constructor(input2, backing) {\n    super(input2, backing);\n    this._backing = backing;\n  }\n  get type() {\n    return \"audio\";\n  }\n  get codec() {\n    return this._backing.getCodec();\n  }\n  get numberOfChannels() {\n    return this._backing.getNumberOfChannels();\n  }\n  get sampleRate() {\n    return this._backing.getSampleRate();\n  }\n  getDecoderConfig() {\n    return this._backing.getDecoderConfig();\n  }\n  async getCodecParameterString() {\n    const decoderConfig = await this._backing.getDecoderConfig();\n    return decoderConfig?.codec ?? null;\n  }\n  async canDecode() {\n    try {\n      const decoderConfig = await this._backing.getDecoderConfig();\n      if (!decoderConfig) {\n        return false;\n      }\n      const codec = this._backing.getCodec();\n      assert(codec !== null);\n      if (customAudioDecoders.some((x) => x.supports(codec, decoderConfig))) {\n        return true;\n      }\n      if (decoderConfig.codec.startsWith(\"pcm-\")) {\n        return true;\n      } else {\n        if (typeof AudioDecoder === \"undefined\") {\n          return false;\n        }\n        const support = await AudioDecoder.isConfigSupported(decoderConfig);\n        return support.supported === true;\n      }\n    } catch (error) {\n      console.error(\"Error during decodability check:\", error);\n      return false;\n    }\n  }\n  async determinePacketType(packet) {\n    if (!(packet instanceof EncodedPacket)) {\n      throw new TypeError(\"packet must be an EncodedPacket.\");\n    }\n    if (this.codec === null) {\n      return null;\n    }\n    return \"key\";\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/isobmff/isobmff-misc.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar buildIsobmffMimeType = (info) => {\n  const base = info.hasVideo ? \"video/\" : info.hasAudio ? \"audio/\" : \"application/\";\n  let string = base + (info.isQuickTime ? \"quicktime\" : \"mp4\");\n  if (info.codecStrings.length > 0) {\n    const uniqueCodecMimeTypes = [...new Set(info.codecStrings)];\n    string += `; codecs=\"${uniqueCodecMimeTypes.join(\", \")}\"`;\n  }\n  return string;\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/isobmff/isobmff-reader.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar MIN_BOX_HEADER_SIZE = 8;\nvar MAX_BOX_HEADER_SIZE = 16;\nvar readBoxHeader = (slice) => {\n  let totalSize = readU32Be(slice);\n  const name = readAscii(slice, 4);\n  let headerSize = 8;\n  const hasLargeSize = totalSize === 1;\n  if (hasLargeSize) {\n    totalSize = readU64Be(slice);\n    headerSize = 16;\n  }\n  const contentSize = totalSize - headerSize;\n  if (contentSize < 0) {\n    return null;\n  }\n  return { name, totalSize, headerSize, contentSize };\n};\nvar readFixed_16_16 = (slice) => {\n  return readI32Be(slice) / 65536;\n};\nvar readFixed_2_30 = (slice) => {\n  return readI32Be(slice) / 1073741824;\n};\nvar readIsomVariableInteger = (slice) => {\n  let result = 0;\n  for (let i = 0;i < 4; i++) {\n    result <<= 7;\n    const nextByte = readU8(slice);\n    result |= nextByte & 127;\n    if ((nextByte & 128) === 0) {\n      break;\n    }\n  }\n  return result;\n};\nvar readMetadataStringShort = (slice) => {\n  let stringLength = readU16Be(slice);\n  slice.skip(2);\n  stringLength = Math.min(stringLength, slice.remainingLength);\n  return textDecoder.decode(readBytes(slice, stringLength));\n};\nvar readDataBox = (slice) => {\n  const header2 = readBoxHeader(slice);\n  if (!header2 || header2.name !== \"data\") {\n    return null;\n  }\n  if (slice.remainingLength < 8) {\n    return null;\n  }\n  const typeIndicator = readU32Be(slice);\n  slice.skip(4);\n  const data = readBytes(slice, header2.contentSize - 8);\n  switch (typeIndicator) {\n    case 1:\n      return textDecoder.decode(data);\n    case 2:\n      return new TextDecoder(\"utf-16be\").decode(data);\n    case 13:\n      return new RichImageData(data, \"image/jpeg\");\n    case 14:\n      return new RichImageData(data, \"image/png\");\n    case 27:\n      return new RichImageData(data, \"image/bmp\");\n    default:\n      return data;\n  }\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/isobmff/isobmff-demuxer.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\nclass IsobmffDemuxer extends Demuxer {\n  constructor(input2) {\n    super(input2);\n    this.moovSlice = null;\n    this.currentTrack = null;\n    this.tracks = [];\n    this.metadataPromise = null;\n    this.movieTimescale = -1;\n    this.movieDurationInTimescale = -1;\n    this.isQuickTime = false;\n    this.metadataTags = {};\n    this.currentMetadataKeys = null;\n    this.isFragmented = false;\n    this.fragmentTrackDefaults = [];\n    this.currentFragment = null;\n    this.lastReadFragment = null;\n    this.reader = input2._reader;\n  }\n  async computeDuration() {\n    const tracks = await this.getTracks();\n    const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));\n    return Math.max(0, ...trackDurations);\n  }\n  async getTracks() {\n    await this.readMetadata();\n    return this.tracks.map((track) => track.inputTrack);\n  }\n  async getMimeType() {\n    await this.readMetadata();\n    const codecStrings = await Promise.all(this.tracks.map((x) => x.inputTrack.getCodecParameterString()));\n    return buildIsobmffMimeType({\n      isQuickTime: this.isQuickTime,\n      hasVideo: this.tracks.some((x) => x.info?.type === \"video\"),\n      hasAudio: this.tracks.some((x) => x.info?.type === \"audio\"),\n      codecStrings: codecStrings.filter(Boolean)\n    });\n  }\n  async getMetadataTags() {\n    await this.readMetadata();\n    return this.metadataTags;\n  }\n  readMetadata() {\n    return this.metadataPromise ??= (async () => {\n      let currentPos = 0;\n      while (true) {\n        let slice = this.reader.requestSliceRange(currentPos, MIN_BOX_HEADER_SIZE, MAX_BOX_HEADER_SIZE);\n        if (slice instanceof Promise)\n          slice = await slice;\n        if (!slice)\n          break;\n        const startPos = currentPos;\n        const boxInfo = readBoxHeader(slice);\n        if (!boxInfo) {\n          break;\n        }\n        if (boxInfo.name === \"ftyp\") {\n          const majorBrand = readAscii(slice, 4);\n          this.isQuickTime = majorBrand === \"qt  \";\n        } else if (boxInfo.name === \"moov\") {\n          let moovSlice = this.reader.requestSlice(slice.filePos, boxInfo.contentSize);\n          if (moovSlice instanceof Promise)\n            moovSlice = await moovSlice;\n          if (!moovSlice)\n            break;\n          this.moovSlice = moovSlice;\n          this.readContiguousBoxes(this.moovSlice);\n          this.tracks.sort((a, b) => Number(b.disposition.default) - Number(a.disposition.default));\n          for (const track of this.tracks) {\n            const previousSegmentDurationsInSeconds = track.editListPreviousSegmentDurations / this.movieTimescale;\n            track.editListOffset -= Math.round(previousSegmentDurationsInSeconds * track.timescale);\n          }\n          break;\n        }\n        currentPos = startPos + boxInfo.totalSize;\n      }\n      if (this.isFragmented && this.reader.fileSize !== null) {\n        let lastWordSlice = this.reader.requestSlice(this.reader.fileSize - 4, 4);\n        if (lastWordSlice instanceof Promise)\n          lastWordSlice = await lastWordSlice;\n        assert(lastWordSlice);\n        const lastWord = readU32Be(lastWordSlice);\n        const potentialMfraPos = this.reader.fileSize - lastWord;\n        if (potentialMfraPos >= 0 && potentialMfraPos <= this.reader.fileSize - MAX_BOX_HEADER_SIZE) {\n          let mfraHeaderSlice = this.reader.requestSliceRange(potentialMfraPos, MIN_BOX_HEADER_SIZE, MAX_BOX_HEADER_SIZE);\n          if (mfraHeaderSlice instanceof Promise)\n            mfraHeaderSlice = await mfraHeaderSlice;\n          if (mfraHeaderSlice) {\n            const boxInfo = readBoxHeader(mfraHeaderSlice);\n            if (boxInfo && boxInfo.name === \"mfra\") {\n              let mfraSlice = this.reader.requestSlice(mfraHeaderSlice.filePos, boxInfo.contentSize);\n              if (mfraSlice instanceof Promise)\n                mfraSlice = await mfraSlice;\n              if (mfraSlice) {\n                this.readContiguousBoxes(mfraSlice);\n              }\n            }\n          }\n        }\n      }\n    })();\n  }\n  getSampleTableForTrack(internalTrack) {\n    if (internalTrack.sampleTable) {\n      return internalTrack.sampleTable;\n    }\n    const sampleTable = {\n      sampleTimingEntries: [],\n      sampleCompositionTimeOffsets: [],\n      sampleSizes: [],\n      keySampleIndices: null,\n      chunkOffsets: [],\n      sampleToChunk: [],\n      presentationTimestamps: null,\n      presentationTimestampIndexMap: null\n    };\n    internalTrack.sampleTable = sampleTable;\n    assert(this.moovSlice);\n    const stblContainerSlice = this.moovSlice.slice(internalTrack.sampleTableByteOffset);\n    this.currentTrack = internalTrack;\n    this.traverseBox(stblContainerSlice);\n    this.currentTrack = null;\n    const isPcmCodec = internalTrack.info?.type === \"audio\" && internalTrack.info.codec && PCM_AUDIO_CODECS.includes(internalTrack.info.codec);\n    if (isPcmCodec && sampleTable.sampleCompositionTimeOffsets.length === 0) {\n      assert(internalTrack.info?.type === \"audio\");\n      const pcmInfo = parsePcmCodec(internalTrack.info.codec);\n      const newSampleTimingEntries = [];\n      const newSampleSizes = [];\n      for (let i = 0;i < sampleTable.sampleToChunk.length; i++) {\n        const chunkEntry = sampleTable.sampleToChunk[i];\n        const nextEntry = sampleTable.sampleToChunk[i + 1];\n        const chunkCount = (nextEntry ? nextEntry.startChunkIndex : sampleTable.chunkOffsets.length) - chunkEntry.startChunkIndex;\n        for (let j = 0;j < chunkCount; j++) {\n          const startSampleIndex = chunkEntry.startSampleIndex + j * chunkEntry.samplesPerChunk;\n          const endSampleIndex = startSampleIndex + chunkEntry.samplesPerChunk;\n          const startTimingEntryIndex = binarySearchLessOrEqual(sampleTable.sampleTimingEntries, startSampleIndex, (x) => x.startIndex);\n          const startTimingEntry = sampleTable.sampleTimingEntries[startTimingEntryIndex];\n          const endTimingEntryIndex = binarySearchLessOrEqual(sampleTable.sampleTimingEntries, endSampleIndex, (x) => x.startIndex);\n          const endTimingEntry = sampleTable.sampleTimingEntries[endTimingEntryIndex];\n          const firstSampleTimestamp = startTimingEntry.startDecodeTimestamp + (startSampleIndex - startTimingEntry.startIndex) * startTimingEntry.delta;\n          const lastSampleTimestamp = endTimingEntry.startDecodeTimestamp + (endSampleIndex - endTimingEntry.startIndex) * endTimingEntry.delta;\n          const delta = lastSampleTimestamp - firstSampleTimestamp;\n          const lastSampleTimingEntry = last(newSampleTimingEntries);\n          if (lastSampleTimingEntry && lastSampleTimingEntry.delta === delta) {\n            lastSampleTimingEntry.count++;\n          } else {\n            newSampleTimingEntries.push({\n              startIndex: chunkEntry.startChunkIndex + j,\n              startDecodeTimestamp: firstSampleTimestamp,\n              count: 1,\n              delta\n            });\n          }\n          const chunkSize = chunkEntry.samplesPerChunk * pcmInfo.sampleSize * internalTrack.info.numberOfChannels;\n          newSampleSizes.push(chunkSize);\n        }\n        chunkEntry.startSampleIndex = chunkEntry.startChunkIndex;\n        chunkEntry.samplesPerChunk = 1;\n      }\n      sampleTable.sampleTimingEntries = newSampleTimingEntries;\n      sampleTable.sampleSizes = newSampleSizes;\n    }\n    if (sampleTable.sampleCompositionTimeOffsets.length > 0) {\n      sampleTable.presentationTimestamps = [];\n      for (const entry of sampleTable.sampleTimingEntries) {\n        for (let i = 0;i < entry.count; i++) {\n          sampleTable.presentationTimestamps.push({\n            presentationTimestamp: entry.startDecodeTimestamp + i * entry.delta,\n            sampleIndex: entry.startIndex + i\n          });\n        }\n      }\n      for (const entry of sampleTable.sampleCompositionTimeOffsets) {\n        for (let i = 0;i < entry.count; i++) {\n          const sampleIndex = entry.startIndex + i;\n          const sample = sampleTable.presentationTimestamps[sampleIndex];\n          if (!sample) {\n            continue;\n          }\n          sample.presentationTimestamp += entry.offset;\n        }\n      }\n      sampleTable.presentationTimestamps.sort((a, b) => a.presentationTimestamp - b.presentationTimestamp);\n      sampleTable.presentationTimestampIndexMap = Array(sampleTable.presentationTimestamps.length).fill(-1);\n      for (let i = 0;i < sampleTable.presentationTimestamps.length; i++) {\n        sampleTable.presentationTimestampIndexMap[sampleTable.presentationTimestamps[i].sampleIndex] = i;\n      }\n    } else {}\n    return sampleTable;\n  }\n  async readFragment(startPos) {\n    if (this.lastReadFragment?.moofOffset === startPos) {\n      return this.lastReadFragment;\n    }\n    let headerSlice = this.reader.requestSliceRange(startPos, MIN_BOX_HEADER_SIZE, MAX_BOX_HEADER_SIZE);\n    if (headerSlice instanceof Promise)\n      headerSlice = await headerSlice;\n    assert(headerSlice);\n    const moofBoxInfo = readBoxHeader(headerSlice);\n    assert(moofBoxInfo?.name === \"moof\");\n    let entireSlice = this.reader.requestSlice(startPos, moofBoxInfo.totalSize);\n    if (entireSlice instanceof Promise)\n      entireSlice = await entireSlice;\n    assert(entireSlice);\n    this.traverseBox(entireSlice);\n    const fragment = this.lastReadFragment;\n    assert(fragment && fragment.moofOffset === startPos);\n    for (const [, trackData] of fragment.trackData) {\n      const track = trackData.track;\n      const { fragmentPositionCache } = track;\n      if (!trackData.startTimestampIsFinal) {\n        const lookupEntry = track.fragmentLookupTable.find((x) => x.moofOffset === fragment.moofOffset);\n        if (lookupEntry) {\n          offsetFragmentTrackDataByTimestamp(trackData, lookupEntry.timestamp);\n        } else {\n          const lastCacheIndex = binarySearchLessOrEqual(fragmentPositionCache, fragment.moofOffset - 1, (x) => x.moofOffset);\n          if (lastCacheIndex !== -1) {\n            const lastCache = fragmentPositionCache[lastCacheIndex];\n            offsetFragmentTrackDataByTimestamp(trackData, lastCache.endTimestamp);\n          } else {}\n        }\n        trackData.startTimestampIsFinal = true;\n      }\n      const insertionIndex = binarySearchLessOrEqual(fragmentPositionCache, trackData.startTimestamp, (x) => x.startTimestamp);\n      if (insertionIndex === -1 || fragmentPositionCache[insertionIndex].moofOffset !== fragment.moofOffset) {\n        fragmentPositionCache.splice(insertionIndex + 1, 0, {\n          moofOffset: fragment.moofOffset,\n          startTimestamp: trackData.startTimestamp,\n          endTimestamp: trackData.endTimestamp\n        });\n      }\n    }\n    return fragment;\n  }\n  readContiguousBoxes(slice) {\n    const startIndex = slice.filePos;\n    while (slice.filePos - startIndex <= slice.length - MIN_BOX_HEADER_SIZE) {\n      const foundBox = this.traverseBox(slice);\n      if (!foundBox) {\n        break;\n      }\n    }\n  }\n  *iterateContiguousBoxes(slice) {\n    const startIndex = slice.filePos;\n    while (slice.filePos - startIndex <= slice.length - MIN_BOX_HEADER_SIZE) {\n      const startPos = slice.filePos;\n      const boxInfo = readBoxHeader(slice);\n      if (!boxInfo) {\n        break;\n      }\n      yield { boxInfo, slice };\n      slice.filePos = startPos + boxInfo.totalSize;\n    }\n  }\n  traverseBox(slice) {\n    const startPos = slice.filePos;\n    const boxInfo = readBoxHeader(slice);\n    if (!boxInfo) {\n      return false;\n    }\n    const contentStartPos = slice.filePos;\n    const boxEndPos = startPos + boxInfo.totalSize;\n    switch (boxInfo.name) {\n      case \"mdia\":\n      case \"minf\":\n      case \"dinf\":\n      case \"mfra\":\n      case \"edts\":\n        {\n          this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n        }\n        ;\n        break;\n      case \"mvhd\":\n        {\n          const version = readU8(slice);\n          slice.skip(3);\n          if (version === 1) {\n            slice.skip(8 + 8);\n            this.movieTimescale = readU32Be(slice);\n            this.movieDurationInTimescale = readU64Be(slice);\n          } else {\n            slice.skip(4 + 4);\n            this.movieTimescale = readU32Be(slice);\n            this.movieDurationInTimescale = readU32Be(slice);\n          }\n        }\n        ;\n        break;\n      case \"trak\":\n        {\n          const track = {\n            id: -1,\n            demuxer: this,\n            inputTrack: null,\n            disposition: {\n              ...DEFAULT_TRACK_DISPOSITION\n            },\n            info: null,\n            timescale: -1,\n            durationInMovieTimescale: -1,\n            durationInMediaTimescale: -1,\n            rotation: 0,\n            internalCodecId: null,\n            name: null,\n            languageCode: UNDETERMINED_LANGUAGE,\n            sampleTableByteOffset: -1,\n            sampleTable: null,\n            fragmentLookupTable: [],\n            currentFragmentState: null,\n            fragmentPositionCache: [],\n            editListPreviousSegmentDurations: 0,\n            editListOffset: 0\n          };\n          this.currentTrack = track;\n          this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n          if (track.id !== -1 && track.timescale !== -1 && track.info !== null) {\n            if (track.info.type === \"video\" && track.info.width !== -1) {\n              const videoTrack = track;\n              track.inputTrack = new InputVideoTrack(this.input, new IsobmffVideoTrackBacking(videoTrack));\n              this.tracks.push(track);\n            } else if (track.info.type === \"audio\" && track.info.numberOfChannels !== -1) {\n              const audioTrack = track;\n              track.inputTrack = new InputAudioTrack(this.input, new IsobmffAudioTrackBacking(audioTrack));\n              this.tracks.push(track);\n            }\n          }\n          this.currentTrack = null;\n        }\n        ;\n        break;\n      case \"tkhd\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          const version = readU8(slice);\n          const flags = readU24Be(slice);\n          const trackEnabled = !!(flags & 1);\n          track.disposition.default = trackEnabled;\n          if (version === 0) {\n            slice.skip(8);\n            track.id = readU32Be(slice);\n            slice.skip(4);\n            track.durationInMovieTimescale = readU32Be(slice);\n          } else if (version === 1) {\n            slice.skip(16);\n            track.id = readU32Be(slice);\n            slice.skip(4);\n            track.durationInMovieTimescale = readU64Be(slice);\n          } else {\n            throw new Error(`Incorrect track header version ${version}.`);\n          }\n          slice.skip(2 * 4 + 2 + 2 + 2 + 2);\n          const matrix = [\n            readFixed_16_16(slice),\n            readFixed_16_16(slice),\n            readFixed_2_30(slice),\n            readFixed_16_16(slice),\n            readFixed_16_16(slice),\n            readFixed_2_30(slice),\n            readFixed_16_16(slice),\n            readFixed_16_16(slice),\n            readFixed_2_30(slice)\n          ];\n          const rotation = normalizeRotation(roundToMultiple(extractRotationFromMatrix(matrix), 90));\n          assert(rotation === 0 || rotation === 90 || rotation === 180 || rotation === 270);\n          track.rotation = rotation;\n        }\n        ;\n        break;\n      case \"elst\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          const version = readU8(slice);\n          slice.skip(3);\n          let relevantEntryFound = false;\n          let previousSegmentDurations = 0;\n          const entryCount = readU32Be(slice);\n          for (let i = 0;i < entryCount; i++) {\n            const segmentDuration = version === 1 ? readU64Be(slice) : readU32Be(slice);\n            const mediaTime = version === 1 ? readI64Be(slice) : readI32Be(slice);\n            const mediaRate = readFixed_16_16(slice);\n            if (segmentDuration === 0) {\n              continue;\n            }\n            if (relevantEntryFound) {\n              console.warn(\"Unsupported edit list: multiple edits are not currently supported. Only using first edit.\");\n              break;\n            }\n            if (mediaTime === -1) {\n              previousSegmentDurations += segmentDuration;\n              continue;\n            }\n            if (mediaRate !== 1) {\n              console.warn(\"Unsupported edit list entry: media rate must be 1.\");\n              break;\n            }\n            track.editListPreviousSegmentDurations = previousSegmentDurations;\n            track.editListOffset = mediaTime;\n            relevantEntryFound = true;\n          }\n        }\n        ;\n        break;\n      case \"mdhd\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          const version = readU8(slice);\n          slice.skip(3);\n          if (version === 0) {\n            slice.skip(8);\n            track.timescale = readU32Be(slice);\n            track.durationInMediaTimescale = readU32Be(slice);\n          } else if (version === 1) {\n            slice.skip(16);\n            track.timescale = readU32Be(slice);\n            track.durationInMediaTimescale = readU64Be(slice);\n          }\n          let language = readU16Be(slice);\n          if (language > 0) {\n            track.languageCode = \"\";\n            for (let i = 0;i < 3; i++) {\n              track.languageCode = String.fromCharCode(96 + (language & 31)) + track.languageCode;\n              language >>= 5;\n            }\n            if (!isIso639Dash2LanguageCode(track.languageCode)) {\n              track.languageCode = UNDETERMINED_LANGUAGE;\n            }\n          }\n        }\n        ;\n        break;\n      case \"hdlr\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          slice.skip(8);\n          const handlerType = readAscii(slice, 4);\n          if (handlerType === \"vide\") {\n            track.info = {\n              type: \"video\",\n              width: -1,\n              height: -1,\n              codec: null,\n              codecDescription: null,\n              colorSpace: null,\n              avcType: null,\n              avcCodecInfo: null,\n              hevcCodecInfo: null,\n              vp9CodecInfo: null,\n              av1CodecInfo: null\n            };\n          } else if (handlerType === \"soun\") {\n            track.info = {\n              type: \"audio\",\n              numberOfChannels: -1,\n              sampleRate: -1,\n              codec: null,\n              codecDescription: null,\n              aacCodecInfo: null\n            };\n          }\n        }\n        ;\n        break;\n      case \"stbl\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          track.sampleTableByteOffset = startPos;\n          this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n        }\n        ;\n        break;\n      case \"stsd\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          if (track.info === null || track.sampleTable) {\n            break;\n          }\n          const stsdVersion = readU8(slice);\n          slice.skip(3);\n          const entries = readU32Be(slice);\n          for (let i = 0;i < entries; i++) {\n            const sampleBoxStartPos = slice.filePos;\n            const sampleBoxInfo = readBoxHeader(slice);\n            if (!sampleBoxInfo) {\n              break;\n            }\n            track.internalCodecId = sampleBoxInfo.name;\n            const lowercaseBoxName = sampleBoxInfo.name.toLowerCase();\n            if (track.info.type === \"video\") {\n              if (lowercaseBoxName === \"avc1\" || lowercaseBoxName === \"avc3\") {\n                track.info.codec = \"avc\";\n                track.info.avcType = lowercaseBoxName === \"avc1\" ? 1 : 3;\n              } else if (lowercaseBoxName === \"hvc1\" || lowercaseBoxName === \"hev1\") {\n                track.info.codec = \"hevc\";\n              } else if (lowercaseBoxName === \"vp08\") {\n                track.info.codec = \"vp8\";\n              } else if (lowercaseBoxName === \"vp09\") {\n                track.info.codec = \"vp9\";\n              } else if (lowercaseBoxName === \"av01\") {\n                track.info.codec = \"av1\";\n              } else {\n                console.warn(`Unsupported video codec (sample entry type '${sampleBoxInfo.name}').`);\n              }\n              slice.skip(6 * 1 + 2 + 2 + 2 + 3 * 4);\n              track.info.width = readU16Be(slice);\n              track.info.height = readU16Be(slice);\n              slice.skip(4 + 4 + 4 + 2 + 32 + 2 + 2);\n              this.readContiguousBoxes(slice.slice(slice.filePos, sampleBoxStartPos + sampleBoxInfo.totalSize - slice.filePos));\n            } else {\n              if (lowercaseBoxName === \"mp4a\") {} else if (lowercaseBoxName === \"opus\") {\n                track.info.codec = \"opus\";\n              } else if (lowercaseBoxName === \"flac\") {\n                track.info.codec = \"flac\";\n              } else if (lowercaseBoxName === \"twos\" || lowercaseBoxName === \"sowt\" || lowercaseBoxName === \"raw \" || lowercaseBoxName === \"in24\" || lowercaseBoxName === \"in32\" || lowercaseBoxName === \"fl32\" || lowercaseBoxName === \"fl64\" || lowercaseBoxName === \"lpcm\" || lowercaseBoxName === \"ipcm\" || lowercaseBoxName === \"fpcm\") {} else if (lowercaseBoxName === \"ulaw\") {\n                track.info.codec = \"ulaw\";\n              } else if (lowercaseBoxName === \"alaw\") {\n                track.info.codec = \"alaw\";\n              } else {\n                console.warn(`Unsupported audio codec (sample entry type '${sampleBoxInfo.name}').`);\n              }\n              slice.skip(6 * 1 + 2);\n              const version = readU16Be(slice);\n              slice.skip(3 * 2);\n              let channelCount = readU16Be(slice);\n              let sampleSize = readU16Be(slice);\n              slice.skip(2 * 2);\n              let sampleRate = readU32Be(slice) / 65536;\n              if (stsdVersion === 0 && version > 0) {\n                if (version === 1) {\n                  slice.skip(4);\n                  sampleSize = 8 * readU32Be(slice);\n                  slice.skip(2 * 4);\n                } else if (version === 2) {\n                  slice.skip(4);\n                  sampleRate = readF64Be(slice);\n                  channelCount = readU32Be(slice);\n                  slice.skip(4);\n                  sampleSize = readU32Be(slice);\n                  const flags = readU32Be(slice);\n                  slice.skip(2 * 4);\n                  if (lowercaseBoxName === \"lpcm\") {\n                    const bytesPerSample = sampleSize + 7 >> 3;\n                    const isFloat = Boolean(flags & 1);\n                    const isBigEndian = Boolean(flags & 2);\n                    const sFlags = flags & 4 ? -1 : 0;\n                    if (sampleSize > 0 && sampleSize <= 64) {\n                      if (isFloat) {\n                        if (sampleSize === 32) {\n                          track.info.codec = isBigEndian ? \"pcm-f32be\" : \"pcm-f32\";\n                        }\n                      } else {\n                        if (sFlags & 1 << bytesPerSample - 1) {\n                          if (bytesPerSample === 1) {\n                            track.info.codec = \"pcm-s8\";\n                          } else if (bytesPerSample === 2) {\n                            track.info.codec = isBigEndian ? \"pcm-s16be\" : \"pcm-s16\";\n                          } else if (bytesPerSample === 3) {\n                            track.info.codec = isBigEndian ? \"pcm-s24be\" : \"pcm-s24\";\n                          } else if (bytesPerSample === 4) {\n                            track.info.codec = isBigEndian ? \"pcm-s32be\" : \"pcm-s32\";\n                          }\n                        } else {\n                          if (bytesPerSample === 1) {\n                            track.info.codec = \"pcm-u8\";\n                          }\n                        }\n                      }\n                    }\n                    if (track.info.codec === null) {\n                      console.warn(\"Unsupported PCM format.\");\n                    }\n                  }\n                }\n              }\n              if (track.info.codec === \"opus\") {\n                sampleRate = OPUS_SAMPLE_RATE;\n              }\n              track.info.numberOfChannels = channelCount;\n              track.info.sampleRate = sampleRate;\n              if (lowercaseBoxName === \"twos\") {\n                if (sampleSize === 8) {\n                  track.info.codec = \"pcm-s8\";\n                } else if (sampleSize === 16) {\n                  track.info.codec = \"pcm-s16be\";\n                } else {\n                  console.warn(`Unsupported sample size ${sampleSize} for codec 'twos'.`);\n                  track.info.codec = null;\n                }\n              } else if (lowercaseBoxName === \"sowt\") {\n                if (sampleSize === 8) {\n                  track.info.codec = \"pcm-s8\";\n                } else if (sampleSize === 16) {\n                  track.info.codec = \"pcm-s16\";\n                } else {\n                  console.warn(`Unsupported sample size ${sampleSize} for codec 'sowt'.`);\n                  track.info.codec = null;\n                }\n              } else if (lowercaseBoxName === \"raw \") {\n                track.info.codec = \"pcm-u8\";\n              } else if (lowercaseBoxName === \"in24\") {\n                track.info.codec = \"pcm-s24be\";\n              } else if (lowercaseBoxName === \"in32\") {\n                track.info.codec = \"pcm-s32be\";\n              } else if (lowercaseBoxName === \"fl32\") {\n                track.info.codec = \"pcm-f32be\";\n              } else if (lowercaseBoxName === \"fl64\") {\n                track.info.codec = \"pcm-f64be\";\n              } else if (lowercaseBoxName === \"ipcm\") {\n                track.info.codec = \"pcm-s16be\";\n              } else if (lowercaseBoxName === \"fpcm\") {\n                track.info.codec = \"pcm-f32be\";\n              }\n              this.readContiguousBoxes(slice.slice(slice.filePos, sampleBoxStartPos + sampleBoxInfo.totalSize - slice.filePos));\n            }\n          }\n        }\n        ;\n        break;\n      case \"avcC\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.info);\n          track.info.codecDescription = readBytes(slice, boxInfo.contentSize);\n        }\n        ;\n        break;\n      case \"hvcC\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.info);\n          track.info.codecDescription = readBytes(slice, boxInfo.contentSize);\n        }\n        ;\n        break;\n      case \"vpcC\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.info?.type === \"video\");\n          slice.skip(4);\n          const profile = readU8(slice);\n          const level = readU8(slice);\n          const thirdByte = readU8(slice);\n          const bitDepth = thirdByte >> 4;\n          const chromaSubsampling = thirdByte >> 1 & 7;\n          const videoFullRangeFlag = thirdByte & 1;\n          const colourPrimaries = readU8(slice);\n          const transferCharacteristics = readU8(slice);\n          const matrixCoefficients = readU8(slice);\n          track.info.vp9CodecInfo = {\n            profile,\n            level,\n            bitDepth,\n            chromaSubsampling,\n            videoFullRangeFlag,\n            colourPrimaries,\n            transferCharacteristics,\n            matrixCoefficients\n          };\n        }\n        ;\n        break;\n      case \"av1C\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.info?.type === \"video\");\n          slice.skip(1);\n          const secondByte = readU8(slice);\n          const profile = secondByte >> 5;\n          const level = secondByte & 31;\n          const thirdByte = readU8(slice);\n          const tier = thirdByte >> 7;\n          const highBitDepth = thirdByte >> 6 & 1;\n          const twelveBit = thirdByte >> 5 & 1;\n          const monochrome = thirdByte >> 4 & 1;\n          const chromaSubsamplingX = thirdByte >> 3 & 1;\n          const chromaSubsamplingY = thirdByte >> 2 & 1;\n          const chromaSamplePosition = thirdByte & 3;\n          const bitDepth = profile === 2 && highBitDepth ? twelveBit ? 12 : 10 : highBitDepth ? 10 : 8;\n          track.info.av1CodecInfo = {\n            profile,\n            level,\n            tier,\n            bitDepth,\n            monochrome,\n            chromaSubsamplingX,\n            chromaSubsamplingY,\n            chromaSamplePosition\n          };\n        }\n        ;\n        break;\n      case \"colr\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.info?.type === \"video\");\n          const colourType = readAscii(slice, 4);\n          if (colourType !== \"nclx\") {\n            break;\n          }\n          const colourPrimaries = readU16Be(slice);\n          const transferCharacteristics = readU16Be(slice);\n          const matrixCoefficients = readU16Be(slice);\n          const fullRangeFlag = Boolean(readU8(slice) & 128);\n          track.info.colorSpace = {\n            primaries: COLOR_PRIMARIES_MAP_INVERSE[colourPrimaries],\n            transfer: TRANSFER_CHARACTERISTICS_MAP_INVERSE[transferCharacteristics],\n            matrix: MATRIX_COEFFICIENTS_MAP_INVERSE[matrixCoefficients],\n            fullRange: fullRangeFlag\n          };\n        }\n        ;\n        break;\n      case \"wave\":\n        {\n          this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n        }\n        ;\n        break;\n      case \"esds\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.info?.type === \"audio\");\n          slice.skip(4);\n          const tag = readU8(slice);\n          assert(tag === 3);\n          readIsomVariableInteger(slice);\n          slice.skip(2);\n          const mixed = readU8(slice);\n          const streamDependenceFlag = (mixed & 128) !== 0;\n          const urlFlag = (mixed & 64) !== 0;\n          const ocrStreamFlag = (mixed & 32) !== 0;\n          if (streamDependenceFlag) {\n            slice.skip(2);\n          }\n          if (urlFlag) {\n            const urlLength = readU8(slice);\n            slice.skip(urlLength);\n          }\n          if (ocrStreamFlag) {\n            slice.skip(2);\n          }\n          const decoderConfigTag = readU8(slice);\n          assert(decoderConfigTag === 4);\n          const decoderConfigDescriptorLength = readIsomVariableInteger(slice);\n          const payloadStart = slice.filePos;\n          const objectTypeIndication = readU8(slice);\n          if (objectTypeIndication === 64 || objectTypeIndication === 103) {\n            track.info.codec = \"aac\";\n            track.info.aacCodecInfo = {\n              isMpeg2: objectTypeIndication === 103,\n              objectType: null\n            };\n          } else if (objectTypeIndication === 105 || objectTypeIndication === 107) {\n            track.info.codec = \"mp3\";\n          } else if (objectTypeIndication === 221) {\n            track.info.codec = \"vorbis\";\n          } else {\n            console.warn(`Unsupported audio codec (objectTypeIndication ${objectTypeIndication}) - discarding track.`);\n          }\n          slice.skip(1 + 3 + 4 + 4);\n          if (decoderConfigDescriptorLength > slice.filePos - payloadStart) {\n            const decoderSpecificInfoTag = readU8(slice);\n            assert(decoderSpecificInfoTag === 5);\n            const decoderSpecificInfoLength = readIsomVariableInteger(slice);\n            track.info.codecDescription = readBytes(slice, decoderSpecificInfoLength);\n            if (track.info.codec === \"aac\") {\n              const audioSpecificConfig = parseAacAudioSpecificConfig(track.info.codecDescription);\n              if (audioSpecificConfig.numberOfChannels !== null) {\n                track.info.numberOfChannels = audioSpecificConfig.numberOfChannels;\n              }\n              if (audioSpecificConfig.sampleRate !== null) {\n                track.info.sampleRate = audioSpecificConfig.sampleRate;\n              }\n            }\n          }\n        }\n        ;\n        break;\n      case \"enda\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.info?.type === \"audio\");\n          const littleEndian = readU16Be(slice) & 255;\n          if (littleEndian) {\n            if (track.info.codec === \"pcm-s16be\") {\n              track.info.codec = \"pcm-s16\";\n            } else if (track.info.codec === \"pcm-s24be\") {\n              track.info.codec = \"pcm-s24\";\n            } else if (track.info.codec === \"pcm-s32be\") {\n              track.info.codec = \"pcm-s32\";\n            } else if (track.info.codec === \"pcm-f32be\") {\n              track.info.codec = \"pcm-f32\";\n            } else if (track.info.codec === \"pcm-f64be\") {\n              track.info.codec = \"pcm-f64\";\n            }\n          }\n        }\n        ;\n        break;\n      case \"pcmC\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.info?.type === \"audio\");\n          slice.skip(1 + 3);\n          const formatFlags = readU8(slice);\n          const isLittleEndian = Boolean(formatFlags & 1);\n          const pcmSampleSize = readU8(slice);\n          if (track.info.codec === \"pcm-s16be\") {\n            if (isLittleEndian) {\n              if (pcmSampleSize === 16) {\n                track.info.codec = \"pcm-s16\";\n              } else if (pcmSampleSize === 24) {\n                track.info.codec = \"pcm-s24\";\n              } else if (pcmSampleSize === 32) {\n                track.info.codec = \"pcm-s32\";\n              } else {\n                console.warn(`Invalid ipcm sample size ${pcmSampleSize}.`);\n                track.info.codec = null;\n              }\n            } else {\n              if (pcmSampleSize === 16) {\n                track.info.codec = \"pcm-s16be\";\n              } else if (pcmSampleSize === 24) {\n                track.info.codec = \"pcm-s24be\";\n              } else if (pcmSampleSize === 32) {\n                track.info.codec = \"pcm-s32be\";\n              } else {\n                console.warn(`Invalid ipcm sample size ${pcmSampleSize}.`);\n                track.info.codec = null;\n              }\n            }\n          } else if (track.info.codec === \"pcm-f32be\") {\n            if (isLittleEndian) {\n              if (pcmSampleSize === 32) {\n                track.info.codec = \"pcm-f32\";\n              } else if (pcmSampleSize === 64) {\n                track.info.codec = \"pcm-f64\";\n              } else {\n                console.warn(`Invalid fpcm sample size ${pcmSampleSize}.`);\n                track.info.codec = null;\n              }\n            } else {\n              if (pcmSampleSize === 32) {\n                track.info.codec = \"pcm-f32be\";\n              } else if (pcmSampleSize === 64) {\n                track.info.codec = \"pcm-f64be\";\n              } else {\n                console.warn(`Invalid fpcm sample size ${pcmSampleSize}.`);\n                track.info.codec = null;\n              }\n            }\n          }\n          break;\n        }\n        ;\n      case \"dOps\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.info?.type === \"audio\");\n          slice.skip(1);\n          const outputChannelCount = readU8(slice);\n          const preSkip = readU16Be(slice);\n          const inputSampleRate = readU32Be(slice);\n          const outputGain = readI16Be(slice);\n          const channelMappingFamily = readU8(slice);\n          let channelMappingTable;\n          if (channelMappingFamily !== 0) {\n            channelMappingTable = readBytes(slice, 2 + outputChannelCount);\n          } else {\n            channelMappingTable = new Uint8Array(0);\n          }\n          const description = new Uint8Array(8 + 1 + 1 + 2 + 4 + 2 + 1 + channelMappingTable.byteLength);\n          const view = new DataView(description.buffer);\n          view.setUint32(0, 1332770163, false);\n          view.setUint32(4, 1214603620, false);\n          view.setUint8(8, 1);\n          view.setUint8(9, outputChannelCount);\n          view.setUint16(10, preSkip, true);\n          view.setUint32(12, inputSampleRate, true);\n          view.setInt16(16, outputGain, true);\n          view.setUint8(18, channelMappingFamily);\n          description.set(channelMappingTable, 19);\n          track.info.codecDescription = description;\n          track.info.numberOfChannels = outputChannelCount;\n        }\n        ;\n        break;\n      case \"dfLa\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.info?.type === \"audio\");\n          slice.skip(4);\n          const BLOCK_TYPE_MASK = 127;\n          const LAST_METADATA_BLOCK_FLAG_MASK = 128;\n          const startPos2 = slice.filePos;\n          while (slice.filePos < boxEndPos) {\n            const flagAndType = readU8(slice);\n            const metadataBlockLength = readU24Be(slice);\n            const type = flagAndType & BLOCK_TYPE_MASK;\n            if (type === FlacBlockType.STREAMINFO) {\n              slice.skip(10);\n              const word = readU32Be(slice);\n              const sampleRate = word >>> 12;\n              const numberOfChannels = (word >> 9 & 7) + 1;\n              track.info.sampleRate = sampleRate;\n              track.info.numberOfChannels = numberOfChannels;\n              slice.skip(20);\n            } else {\n              slice.skip(metadataBlockLength);\n            }\n            if (flagAndType & LAST_METADATA_BLOCK_FLAG_MASK) {\n              break;\n            }\n          }\n          const endPos = slice.filePos;\n          slice.filePos = startPos2;\n          const bytes = readBytes(slice, endPos - startPos2);\n          const description = new Uint8Array(4 + bytes.byteLength);\n          const view = new DataView(description.buffer);\n          view.setUint32(0, 1716281667, false);\n          description.set(bytes, 4);\n          track.info.codecDescription = description;\n        }\n        ;\n        break;\n      case \"stts\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          if (!track.sampleTable) {\n            break;\n          }\n          slice.skip(4);\n          const entryCount = readU32Be(slice);\n          let currentIndex = 0;\n          let currentTimestamp = 0;\n          for (let i = 0;i < entryCount; i++) {\n            const sampleCount = readU32Be(slice);\n            const sampleDelta = readU32Be(slice);\n            track.sampleTable.sampleTimingEntries.push({\n              startIndex: currentIndex,\n              startDecodeTimestamp: currentTimestamp,\n              count: sampleCount,\n              delta: sampleDelta\n            });\n            currentIndex += sampleCount;\n            currentTimestamp += sampleCount * sampleDelta;\n          }\n        }\n        ;\n        break;\n      case \"ctts\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          if (!track.sampleTable) {\n            break;\n          }\n          slice.skip(1 + 3);\n          const entryCount = readU32Be(slice);\n          let sampleIndex = 0;\n          for (let i = 0;i < entryCount; i++) {\n            const sampleCount = readU32Be(slice);\n            const sampleOffset = readI32Be(slice);\n            track.sampleTable.sampleCompositionTimeOffsets.push({\n              startIndex: sampleIndex,\n              count: sampleCount,\n              offset: sampleOffset\n            });\n            sampleIndex += sampleCount;\n          }\n        }\n        ;\n        break;\n      case \"stsz\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          if (!track.sampleTable) {\n            break;\n          }\n          slice.skip(4);\n          const sampleSize = readU32Be(slice);\n          const sampleCount = readU32Be(slice);\n          if (sampleSize === 0) {\n            for (let i = 0;i < sampleCount; i++) {\n              const sampleSize2 = readU32Be(slice);\n              track.sampleTable.sampleSizes.push(sampleSize2);\n            }\n          } else {\n            track.sampleTable.sampleSizes.push(sampleSize);\n          }\n        }\n        ;\n        break;\n      case \"stz2\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          if (!track.sampleTable) {\n            break;\n          }\n          slice.skip(4);\n          slice.skip(3);\n          const fieldSize = readU8(slice);\n          const sampleCount = readU32Be(slice);\n          const bytes = readBytes(slice, Math.ceil(sampleCount * fieldSize / 8));\n          const bitstream = new Bitstream(bytes);\n          for (let i = 0;i < sampleCount; i++) {\n            const sampleSize = bitstream.readBits(fieldSize);\n            track.sampleTable.sampleSizes.push(sampleSize);\n          }\n        }\n        ;\n        break;\n      case \"stss\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          if (!track.sampleTable) {\n            break;\n          }\n          slice.skip(4);\n          track.sampleTable.keySampleIndices = [];\n          const entryCount = readU32Be(slice);\n          for (let i = 0;i < entryCount; i++) {\n            const sampleIndex = readU32Be(slice) - 1;\n            track.sampleTable.keySampleIndices.push(sampleIndex);\n          }\n          if (track.sampleTable.keySampleIndices[0] !== 0) {\n            track.sampleTable.keySampleIndices.unshift(0);\n          }\n        }\n        ;\n        break;\n      case \"stsc\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          if (!track.sampleTable) {\n            break;\n          }\n          slice.skip(4);\n          const entryCount = readU32Be(slice);\n          for (let i = 0;i < entryCount; i++) {\n            const startChunkIndex = readU32Be(slice) - 1;\n            const samplesPerChunk = readU32Be(slice);\n            const sampleDescriptionIndex = readU32Be(slice);\n            track.sampleTable.sampleToChunk.push({\n              startSampleIndex: -1,\n              startChunkIndex,\n              samplesPerChunk,\n              sampleDescriptionIndex\n            });\n          }\n          let startSampleIndex = 0;\n          for (let i = 0;i < track.sampleTable.sampleToChunk.length; i++) {\n            track.sampleTable.sampleToChunk[i].startSampleIndex = startSampleIndex;\n            if (i < track.sampleTable.sampleToChunk.length - 1) {\n              const nextChunk = track.sampleTable.sampleToChunk[i + 1];\n              const chunkCount = nextChunk.startChunkIndex - track.sampleTable.sampleToChunk[i].startChunkIndex;\n              startSampleIndex += chunkCount * track.sampleTable.sampleToChunk[i].samplesPerChunk;\n            }\n          }\n        }\n        ;\n        break;\n      case \"stco\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          if (!track.sampleTable) {\n            break;\n          }\n          slice.skip(4);\n          const entryCount = readU32Be(slice);\n          for (let i = 0;i < entryCount; i++) {\n            const chunkOffset = readU32Be(slice);\n            track.sampleTable.chunkOffsets.push(chunkOffset);\n          }\n        }\n        ;\n        break;\n      case \"co64\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          if (!track.sampleTable) {\n            break;\n          }\n          slice.skip(4);\n          const entryCount = readU32Be(slice);\n          for (let i = 0;i < entryCount; i++) {\n            const chunkOffset = readU64Be(slice);\n            track.sampleTable.chunkOffsets.push(chunkOffset);\n          }\n        }\n        ;\n        break;\n      case \"mvex\":\n        {\n          this.isFragmented = true;\n          this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n        }\n        ;\n        break;\n      case \"mehd\":\n        {\n          const version = readU8(slice);\n          slice.skip(3);\n          const fragmentDuration = version === 1 ? readU64Be(slice) : readU32Be(slice);\n          this.movieDurationInTimescale = fragmentDuration;\n        }\n        ;\n        break;\n      case \"trex\":\n        {\n          slice.skip(4);\n          const trackId = readU32Be(slice);\n          const defaultSampleDescriptionIndex = readU32Be(slice);\n          const defaultSampleDuration = readU32Be(slice);\n          const defaultSampleSize = readU32Be(slice);\n          const defaultSampleFlags = readU32Be(slice);\n          this.fragmentTrackDefaults.push({\n            trackId,\n            defaultSampleDescriptionIndex,\n            defaultSampleDuration,\n            defaultSampleSize,\n            defaultSampleFlags\n          });\n        }\n        ;\n        break;\n      case \"tfra\":\n        {\n          const version = readU8(slice);\n          slice.skip(3);\n          const trackId = readU32Be(slice);\n          const track = this.tracks.find((x) => x.id === trackId);\n          if (!track) {\n            break;\n          }\n          const word = readU32Be(slice);\n          const lengthSizeOfTrafNum = (word & 48) >> 4;\n          const lengthSizeOfTrunNum = (word & 12) >> 2;\n          const lengthSizeOfSampleNum = word & 3;\n          const functions = [readU8, readU16Be, readU24Be, readU32Be];\n          const readTrafNum = functions[lengthSizeOfTrafNum];\n          const readTrunNum = functions[lengthSizeOfTrunNum];\n          const readSampleNum = functions[lengthSizeOfSampleNum];\n          const numberOfEntries = readU32Be(slice);\n          for (let i = 0;i < numberOfEntries; i++) {\n            const time2 = version === 1 ? readU64Be(slice) : readU32Be(slice);\n            const moofOffset = version === 1 ? readU64Be(slice) : readU32Be(slice);\n            readTrafNum(slice);\n            readTrunNum(slice);\n            readSampleNum(slice);\n            track.fragmentLookupTable.push({\n              timestamp: time2,\n              moofOffset\n            });\n          }\n          track.fragmentLookupTable.sort((a, b) => a.timestamp - b.timestamp);\n          for (let i = 0;i < track.fragmentLookupTable.length - 1; i++) {\n            const entry1 = track.fragmentLookupTable[i];\n            const entry2 = track.fragmentLookupTable[i + 1];\n            if (entry1.timestamp === entry2.timestamp) {\n              track.fragmentLookupTable.splice(i + 1, 1);\n              i--;\n            }\n          }\n        }\n        ;\n        break;\n      case \"moof\":\n        {\n          this.currentFragment = {\n            moofOffset: startPos,\n            moofSize: boxInfo.totalSize,\n            implicitBaseDataOffset: startPos,\n            trackData: new Map\n          };\n          this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n          this.lastReadFragment = this.currentFragment;\n          this.currentFragment = null;\n        }\n        ;\n        break;\n      case \"traf\":\n        {\n          assert(this.currentFragment);\n          this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n          if (this.currentTrack) {\n            const trackData = this.currentFragment.trackData.get(this.currentTrack.id);\n            if (trackData) {\n              const { currentFragmentState } = this.currentTrack;\n              assert(currentFragmentState);\n              if (currentFragmentState.startTimestamp !== null) {\n                offsetFragmentTrackDataByTimestamp(trackData, currentFragmentState.startTimestamp);\n                trackData.startTimestampIsFinal = true;\n              }\n            }\n            this.currentTrack.currentFragmentState = null;\n            this.currentTrack = null;\n          }\n        }\n        ;\n        break;\n      case \"tfhd\":\n        {\n          assert(this.currentFragment);\n          slice.skip(1);\n          const flags = readU24Be(slice);\n          const baseDataOffsetPresent = Boolean(flags & 1);\n          const sampleDescriptionIndexPresent = Boolean(flags & 2);\n          const defaultSampleDurationPresent = Boolean(flags & 8);\n          const defaultSampleSizePresent = Boolean(flags & 16);\n          const defaultSampleFlagsPresent = Boolean(flags & 32);\n          const durationIsEmpty = Boolean(flags & 65536);\n          const defaultBaseIsMoof = Boolean(flags & 131072);\n          const trackId = readU32Be(slice);\n          const track = this.tracks.find((x) => x.id === trackId);\n          if (!track) {\n            break;\n          }\n          const defaults = this.fragmentTrackDefaults.find((x) => x.trackId === trackId);\n          this.currentTrack = track;\n          track.currentFragmentState = {\n            baseDataOffset: this.currentFragment.implicitBaseDataOffset,\n            sampleDescriptionIndex: defaults?.defaultSampleDescriptionIndex ?? null,\n            defaultSampleDuration: defaults?.defaultSampleDuration ?? null,\n            defaultSampleSize: defaults?.defaultSampleSize ?? null,\n            defaultSampleFlags: defaults?.defaultSampleFlags ?? null,\n            startTimestamp: null\n          };\n          if (baseDataOffsetPresent) {\n            track.currentFragmentState.baseDataOffset = readU64Be(slice);\n          } else if (defaultBaseIsMoof) {\n            track.currentFragmentState.baseDataOffset = this.currentFragment.moofOffset;\n          }\n          if (sampleDescriptionIndexPresent) {\n            track.currentFragmentState.sampleDescriptionIndex = readU32Be(slice);\n          }\n          if (defaultSampleDurationPresent) {\n            track.currentFragmentState.defaultSampleDuration = readU32Be(slice);\n          }\n          if (defaultSampleSizePresent) {\n            track.currentFragmentState.defaultSampleSize = readU32Be(slice);\n          }\n          if (defaultSampleFlagsPresent) {\n            track.currentFragmentState.defaultSampleFlags = readU32Be(slice);\n          }\n          if (durationIsEmpty) {\n            track.currentFragmentState.defaultSampleDuration = 0;\n          }\n        }\n        ;\n        break;\n      case \"tfdt\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(track.currentFragmentState);\n          const version = readU8(slice);\n          slice.skip(3);\n          const baseMediaDecodeTime = version === 0 ? readU32Be(slice) : readU64Be(slice);\n          track.currentFragmentState.startTimestamp = baseMediaDecodeTime;\n        }\n        ;\n        break;\n      case \"trun\":\n        {\n          const track = this.currentTrack;\n          if (!track) {\n            break;\n          }\n          assert(this.currentFragment);\n          assert(track.currentFragmentState);\n          if (this.currentFragment.trackData.has(track.id)) {\n            console.warn(\"Can't have two trun boxes for the same track in one fragment. Ignoring...\");\n            break;\n          }\n          const version = readU8(slice);\n          const flags = readU24Be(slice);\n          const dataOffsetPresent = Boolean(flags & 1);\n          const firstSampleFlagsPresent = Boolean(flags & 4);\n          const sampleDurationPresent = Boolean(flags & 256);\n          const sampleSizePresent = Boolean(flags & 512);\n          const sampleFlagsPresent = Boolean(flags & 1024);\n          const sampleCompositionTimeOffsetsPresent = Boolean(flags & 2048);\n          const sampleCount = readU32Be(slice);\n          let dataOffset = track.currentFragmentState.baseDataOffset;\n          if (dataOffsetPresent) {\n            dataOffset += readI32Be(slice);\n          }\n          let firstSampleFlags = null;\n          if (firstSampleFlagsPresent) {\n            firstSampleFlags = readU32Be(slice);\n          }\n          let currentOffset = dataOffset;\n          if (sampleCount === 0) {\n            this.currentFragment.implicitBaseDataOffset = currentOffset;\n            break;\n          }\n          let currentTimestamp = 0;\n          const trackData = {\n            track,\n            startTimestamp: 0,\n            endTimestamp: 0,\n            firstKeyFrameTimestamp: null,\n            samples: [],\n            presentationTimestamps: [],\n            startTimestampIsFinal: false\n          };\n          this.currentFragment.trackData.set(track.id, trackData);\n          for (let i = 0;i < sampleCount; i++) {\n            let sampleDuration;\n            if (sampleDurationPresent) {\n              sampleDuration = readU32Be(slice);\n            } else {\n              assert(track.currentFragmentState.defaultSampleDuration !== null);\n              sampleDuration = track.currentFragmentState.defaultSampleDuration;\n            }\n            let sampleSize;\n            if (sampleSizePresent) {\n              sampleSize = readU32Be(slice);\n            } else {\n              assert(track.currentFragmentState.defaultSampleSize !== null);\n              sampleSize = track.currentFragmentState.defaultSampleSize;\n            }\n            let sampleFlags;\n            if (sampleFlagsPresent) {\n              sampleFlags = readU32Be(slice);\n            } else {\n              assert(track.currentFragmentState.defaultSampleFlags !== null);\n              sampleFlags = track.currentFragmentState.defaultSampleFlags;\n            }\n            if (i === 0 && firstSampleFlags !== null) {\n              sampleFlags = firstSampleFlags;\n            }\n            let sampleCompositionTimeOffset = 0;\n            if (sampleCompositionTimeOffsetsPresent) {\n              if (version === 0) {\n                sampleCompositionTimeOffset = readU32Be(slice);\n              } else {\n                sampleCompositionTimeOffset = readI32Be(slice);\n              }\n            }\n            const isKeyFrame = !(sampleFlags & 65536);\n            trackData.samples.push({\n              presentationTimestamp: currentTimestamp + sampleCompositionTimeOffset,\n              duration: sampleDuration,\n              byteOffset: currentOffset,\n              byteSize: sampleSize,\n              isKeyFrame\n            });\n            currentOffset += sampleSize;\n            currentTimestamp += sampleDuration;\n          }\n          trackData.presentationTimestamps = trackData.samples.map((x, i) => ({ presentationTimestamp: x.presentationTimestamp, sampleIndex: i })).sort((a, b) => a.presentationTimestamp - b.presentationTimestamp);\n          for (let i = 0;i < trackData.presentationTimestamps.length; i++) {\n            const currentEntry = trackData.presentationTimestamps[i];\n            const currentSample = trackData.samples[currentEntry.sampleIndex];\n            if (trackData.firstKeyFrameTimestamp === null && currentSample.isKeyFrame) {\n              trackData.firstKeyFrameTimestamp = currentSample.presentationTimestamp;\n            }\n            if (i < trackData.presentationTimestamps.length - 1) {\n              const nextEntry = trackData.presentationTimestamps[i + 1];\n              currentSample.duration = nextEntry.presentationTimestamp - currentEntry.presentationTimestamp;\n            }\n          }\n          const firstSample = trackData.samples[trackData.presentationTimestamps[0].sampleIndex];\n          const lastSample = trackData.samples[last(trackData.presentationTimestamps).sampleIndex];\n          trackData.startTimestamp = firstSample.presentationTimestamp;\n          trackData.endTimestamp = lastSample.presentationTimestamp + lastSample.duration;\n          this.currentFragment.implicitBaseDataOffset = currentOffset;\n        }\n        ;\n        break;\n      case \"udta\":\n        {\n          const iterator = this.iterateContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n          for (const { boxInfo: boxInfo2, slice: slice2 } of iterator) {\n            if (boxInfo2.name !== \"meta\" && !this.currentTrack) {\n              const startPos2 = slice2.filePos;\n              this.metadataTags.raw ??= {};\n              if (boxInfo2.name[0] === \"\") {\n                this.metadataTags.raw[boxInfo2.name] ??= readMetadataStringShort(slice2);\n              } else {\n                this.metadataTags.raw[boxInfo2.name] ??= readBytes(slice2, boxInfo2.contentSize);\n              }\n              slice2.filePos = startPos2;\n            }\n            switch (boxInfo2.name) {\n              case \"meta\":\n                {\n                  slice2.skip(-boxInfo2.headerSize);\n                  this.traverseBox(slice2);\n                }\n                ;\n                break;\n              case \"nam\":\n              case \"name\":\n                {\n                  if (this.currentTrack) {\n                    this.currentTrack.name = textDecoder.decode(readBytes(slice2, boxInfo2.contentSize));\n                  } else {\n                    this.metadataTags.title ??= readMetadataStringShort(slice2);\n                  }\n                }\n                ;\n                break;\n              case \"des\":\n                {\n                  if (!this.currentTrack) {\n                    this.metadataTags.description ??= readMetadataStringShort(slice2);\n                  }\n                }\n                ;\n                break;\n              case \"ART\":\n                {\n                  if (!this.currentTrack) {\n                    this.metadataTags.artist ??= readMetadataStringShort(slice2);\n                  }\n                }\n                ;\n                break;\n              case \"alb\":\n                {\n                  if (!this.currentTrack) {\n                    this.metadataTags.album ??= readMetadataStringShort(slice2);\n                  }\n                }\n                ;\n                break;\n              case \"albr\":\n                {\n                  if (!this.currentTrack) {\n                    this.metadataTags.albumArtist ??= readMetadataStringShort(slice2);\n                  }\n                }\n                ;\n                break;\n              case \"gen\":\n                {\n                  if (!this.currentTrack) {\n                    this.metadataTags.genre ??= readMetadataStringShort(slice2);\n                  }\n                }\n                ;\n                break;\n              case \"day\":\n                {\n                  if (!this.currentTrack) {\n                    const date = new Date(readMetadataStringShort(slice2));\n                    if (!Number.isNaN(date.getTime())) {\n                      this.metadataTags.date ??= date;\n                    }\n                  }\n                }\n                ;\n                break;\n              case \"cmt\":\n                {\n                  if (!this.currentTrack) {\n                    this.metadataTags.comment ??= readMetadataStringShort(slice2);\n                  }\n                }\n                ;\n                break;\n              case \"lyr\":\n                {\n                  if (!this.currentTrack) {\n                    this.metadataTags.lyrics ??= readMetadataStringShort(slice2);\n                  }\n                }\n                ;\n                break;\n            }\n          }\n        }\n        ;\n        break;\n      case \"meta\":\n        {\n          if (this.currentTrack) {\n            break;\n          }\n          const word = readU32Be(slice);\n          const isQuickTime = word !== 0;\n          this.currentMetadataKeys = new Map;\n          if (isQuickTime) {\n            this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n          } else {\n            this.readContiguousBoxes(slice.slice(contentStartPos + 4, boxInfo.contentSize - 4));\n          }\n          this.currentMetadataKeys = null;\n        }\n        ;\n        break;\n      case \"keys\":\n        {\n          if (!this.currentMetadataKeys) {\n            break;\n          }\n          slice.skip(4);\n          const entryCount = readU32Be(slice);\n          for (let i = 0;i < entryCount; i++) {\n            const keySize = readU32Be(slice);\n            slice.skip(4);\n            const keyName = textDecoder.decode(readBytes(slice, keySize - 8));\n            this.currentMetadataKeys.set(i + 1, keyName);\n          }\n        }\n        ;\n        break;\n      case \"ilst\":\n        {\n          if (!this.currentMetadataKeys) {\n            break;\n          }\n          const iterator = this.iterateContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n          for (const { boxInfo: boxInfo2, slice: slice2 } of iterator) {\n            let metadataKey = boxInfo2.name;\n            const nameAsNumber = (metadataKey.charCodeAt(0) << 24) + (metadataKey.charCodeAt(1) << 16) + (metadataKey.charCodeAt(2) << 8) + metadataKey.charCodeAt(3);\n            if (this.currentMetadataKeys.has(nameAsNumber)) {\n              metadataKey = this.currentMetadataKeys.get(nameAsNumber);\n            }\n            const data = readDataBox(slice2);\n            this.metadataTags.raw ??= {};\n            this.metadataTags.raw[metadataKey] ??= data;\n            switch (metadataKey) {\n              case \"nam\":\n              case \"titl\":\n              case \"com.apple.quicktime.title\":\n              case \"title\":\n                {\n                  if (typeof data === \"string\") {\n                    this.metadataTags.title ??= data;\n                  }\n                }\n                ;\n                break;\n              case \"des\":\n              case \"desc\":\n              case \"dscp\":\n              case \"com.apple.quicktime.description\":\n              case \"description\":\n                {\n                  if (typeof data === \"string\") {\n                    this.metadataTags.description ??= data;\n                  }\n                }\n                ;\n                break;\n              case \"ART\":\n              case \"com.apple.quicktime.artist\":\n              case \"artist\":\n                {\n                  if (typeof data === \"string\") {\n                    this.metadataTags.artist ??= data;\n                  }\n                }\n                ;\n                break;\n              case \"alb\":\n              case \"albm\":\n              case \"com.apple.quicktime.album\":\n              case \"album\":\n                {\n                  if (typeof data === \"string\") {\n                    this.metadataTags.album ??= data;\n                  }\n                }\n                ;\n                break;\n              case \"aART\":\n              case \"album_artist\":\n                {\n                  if (typeof data === \"string\") {\n                    this.metadataTags.albumArtist ??= data;\n                  }\n                }\n                ;\n                break;\n              case \"cmt\":\n              case \"com.apple.quicktime.comment\":\n              case \"comment\":\n                {\n                  if (typeof data === \"string\") {\n                    this.metadataTags.comment ??= data;\n                  }\n                }\n                ;\n                break;\n              case \"gen\":\n              case \"gnre\":\n              case \"com.apple.quicktime.genre\":\n              case \"genre\":\n                {\n                  if (typeof data === \"string\") {\n                    this.metadataTags.genre ??= data;\n                  }\n                }\n                ;\n                break;\n              case \"lyr\":\n              case \"lyrics\":\n                {\n                  if (typeof data === \"string\") {\n                    this.metadataTags.lyrics ??= data;\n                  }\n                }\n                ;\n                break;\n              case \"day\":\n              case \"rldt\":\n              case \"com.apple.quicktime.creationdate\":\n              case \"date\":\n                {\n                  if (typeof data === \"string\") {\n                    const date = new Date(data);\n                    if (!Number.isNaN(date.getTime())) {\n                      this.metadataTags.date ??= date;\n                    }\n                  }\n                }\n                ;\n                break;\n              case \"covr\":\n              case \"com.apple.quicktime.artwork\":\n                {\n                  if (data instanceof RichImageData) {\n                    this.metadataTags.images ??= [];\n                    this.metadataTags.images.push({\n                      data: data.data,\n                      kind: \"coverFront\",\n                      mimeType: data.mimeType\n                    });\n                  } else if (data instanceof Uint8Array) {\n                    this.metadataTags.images ??= [];\n                    this.metadataTags.images.push({\n                      data,\n                      kind: \"coverFront\",\n                      mimeType: \"image/*\"\n                    });\n                  }\n                }\n                ;\n                break;\n              case \"track\":\n                {\n                  if (typeof data === \"string\") {\n                    const parts = data.split(\"/\");\n                    const trackNum = Number.parseInt(parts[0], 10);\n                    const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);\n                    if (Number.isInteger(trackNum) && trackNum > 0) {\n                      this.metadataTags.trackNumber ??= trackNum;\n                    }\n                    if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {\n                      this.metadataTags.tracksTotal ??= tracksTotal;\n                    }\n                  }\n                }\n                ;\n                break;\n              case \"trkn\":\n                {\n                  if (data instanceof Uint8Array && data.length >= 6) {\n                    const view = toDataView(data);\n                    const trackNumber = view.getUint16(2, false);\n                    const tracksTotal = view.getUint16(4, false);\n                    if (trackNumber > 0) {\n                      this.metadataTags.trackNumber ??= trackNumber;\n                    }\n                    if (tracksTotal > 0) {\n                      this.metadataTags.tracksTotal ??= tracksTotal;\n                    }\n                  }\n                }\n                ;\n                break;\n              case \"disc\":\n              case \"disk\":\n                {\n                  if (data instanceof Uint8Array && data.length >= 6) {\n                    const view = toDataView(data);\n                    const discNumber = view.getUint16(2, false);\n                    const discNumberMax = view.getUint16(4, false);\n                    if (discNumber > 0) {\n                      this.metadataTags.discNumber ??= discNumber;\n                    }\n                    if (discNumberMax > 0) {\n                      this.metadataTags.discsTotal ??= discNumberMax;\n                    }\n                  }\n                }\n                ;\n                break;\n            }\n          }\n        }\n        ;\n        break;\n    }\n    slice.filePos = boxEndPos;\n    return true;\n  }\n}\n\nclass IsobmffTrackBacking {\n  constructor(internalTrack) {\n    this.internalTrack = internalTrack;\n    this.packetToSampleIndex = new WeakMap;\n    this.packetToFragmentLocation = new WeakMap;\n  }\n  getId() {\n    return this.internalTrack.id;\n  }\n  getCodec() {\n    throw new Error(\"Not implemented on base class.\");\n  }\n  getInternalCodecId() {\n    return this.internalTrack.internalCodecId;\n  }\n  getName() {\n    return this.internalTrack.name;\n  }\n  getLanguageCode() {\n    return this.internalTrack.languageCode;\n  }\n  getTimeResolution() {\n    return this.internalTrack.timescale;\n  }\n  getDisposition() {\n    return this.internalTrack.disposition;\n  }\n  async computeDuration() {\n    const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n    return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n  }\n  async getFirstTimestamp() {\n    const firstPacket = await this.getFirstPacket({ metadataOnly: true });\n    return firstPacket?.timestamp ?? 0;\n  }\n  async getFirstPacket(options) {\n    const regularPacket = await this.fetchPacketForSampleIndex(0, options);\n    if (regularPacket || !this.internalTrack.demuxer.isFragmented) {\n      return regularPacket;\n    }\n    return this.performFragmentedLookup(null, (fragment) => {\n      const trackData = fragment.trackData.get(this.internalTrack.id);\n      if (trackData) {\n        return {\n          sampleIndex: 0,\n          correctSampleFound: true\n        };\n      }\n      return {\n        sampleIndex: -1,\n        correctSampleFound: false\n      };\n    }, -Infinity, Infinity, options);\n  }\n  mapTimestampIntoTimescale(timestamp) {\n    return roundIfAlmostInteger(timestamp * this.internalTrack.timescale) + this.internalTrack.editListOffset;\n  }\n  async getPacket(timestamp, options) {\n    const timestampInTimescale = this.mapTimestampIntoTimescale(timestamp);\n    const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);\n    const sampleIndex = getSampleIndexForTimestamp(sampleTable, timestampInTimescale);\n    const regularPacket = await this.fetchPacketForSampleIndex(sampleIndex, options);\n    if (!sampleTableIsEmpty(sampleTable) || !this.internalTrack.demuxer.isFragmented) {\n      return regularPacket;\n    }\n    return this.performFragmentedLookup(null, (fragment) => {\n      const trackData = fragment.trackData.get(this.internalTrack.id);\n      if (!trackData) {\n        return { sampleIndex: -1, correctSampleFound: false };\n      }\n      const index = binarySearchLessOrEqual(trackData.presentationTimestamps, timestampInTimescale, (x) => x.presentationTimestamp);\n      const sampleIndex2 = index !== -1 ? trackData.presentationTimestamps[index].sampleIndex : -1;\n      const correctSampleFound = index !== -1 && timestampInTimescale < trackData.endTimestamp;\n      return { sampleIndex: sampleIndex2, correctSampleFound };\n    }, timestampInTimescale, timestampInTimescale, options);\n  }\n  async getNextPacket(packet, options) {\n    const regularSampleIndex = this.packetToSampleIndex.get(packet);\n    if (regularSampleIndex !== undefined) {\n      return this.fetchPacketForSampleIndex(regularSampleIndex + 1, options);\n    }\n    const locationInFragment = this.packetToFragmentLocation.get(packet);\n    if (locationInFragment === undefined) {\n      throw new Error(\"Packet was not created from this track.\");\n    }\n    return this.performFragmentedLookup(locationInFragment.fragment, (fragment) => {\n      if (fragment === locationInFragment.fragment) {\n        const trackData = fragment.trackData.get(this.internalTrack.id);\n        if (locationInFragment.sampleIndex + 1 < trackData.samples.length) {\n          return {\n            sampleIndex: locationInFragment.sampleIndex + 1,\n            correctSampleFound: true\n          };\n        }\n      } else {\n        const trackData = fragment.trackData.get(this.internalTrack.id);\n        if (trackData) {\n          return {\n            sampleIndex: 0,\n            correctSampleFound: true\n          };\n        }\n      }\n      return {\n        sampleIndex: -1,\n        correctSampleFound: false\n      };\n    }, -Infinity, Infinity, options);\n  }\n  async getKeyPacket(timestamp, options) {\n    const timestampInTimescale = this.mapTimestampIntoTimescale(timestamp);\n    const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);\n    const sampleIndex = getKeyframeSampleIndexForTimestamp(sampleTable, timestampInTimescale);\n    const regularPacket = await this.fetchPacketForSampleIndex(sampleIndex, options);\n    if (!sampleTableIsEmpty(sampleTable) || !this.internalTrack.demuxer.isFragmented) {\n      return regularPacket;\n    }\n    return this.performFragmentedLookup(null, (fragment) => {\n      const trackData = fragment.trackData.get(this.internalTrack.id);\n      if (!trackData) {\n        return { sampleIndex: -1, correctSampleFound: false };\n      }\n      const index = findLastIndex(trackData.presentationTimestamps, (x) => {\n        const sample = trackData.samples[x.sampleIndex];\n        return sample.isKeyFrame && x.presentationTimestamp <= timestampInTimescale;\n      });\n      const sampleIndex2 = index !== -1 ? trackData.presentationTimestamps[index].sampleIndex : -1;\n      const correctSampleFound = index !== -1 && timestampInTimescale < trackData.endTimestamp;\n      return { sampleIndex: sampleIndex2, correctSampleFound };\n    }, timestampInTimescale, timestampInTimescale, options);\n  }\n  async getNextKeyPacket(packet, options) {\n    const regularSampleIndex = this.packetToSampleIndex.get(packet);\n    if (regularSampleIndex !== undefined) {\n      const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);\n      const nextKeyFrameSampleIndex = getNextKeyframeIndexForSample(sampleTable, regularSampleIndex);\n      return this.fetchPacketForSampleIndex(nextKeyFrameSampleIndex, options);\n    }\n    const locationInFragment = this.packetToFragmentLocation.get(packet);\n    if (locationInFragment === undefined) {\n      throw new Error(\"Packet was not created from this track.\");\n    }\n    return this.performFragmentedLookup(locationInFragment.fragment, (fragment) => {\n      if (fragment === locationInFragment.fragment) {\n        const trackData = fragment.trackData.get(this.internalTrack.id);\n        const nextKeyFrameIndex = trackData.samples.findIndex((x, i) => x.isKeyFrame && i > locationInFragment.sampleIndex);\n        if (nextKeyFrameIndex !== -1) {\n          return {\n            sampleIndex: nextKeyFrameIndex,\n            correctSampleFound: true\n          };\n        }\n      } else {\n        const trackData = fragment.trackData.get(this.internalTrack.id);\n        if (trackData && trackData.firstKeyFrameTimestamp !== null) {\n          const keyFrameIndex = trackData.samples.findIndex((x) => x.isKeyFrame);\n          assert(keyFrameIndex !== -1);\n          return {\n            sampleIndex: keyFrameIndex,\n            correctSampleFound: true\n          };\n        }\n      }\n      return {\n        sampleIndex: -1,\n        correctSampleFound: false\n      };\n    }, -Infinity, Infinity, options);\n  }\n  async fetchPacketForSampleIndex(sampleIndex, options) {\n    if (sampleIndex === -1) {\n      return null;\n    }\n    const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);\n    const sampleInfo = getSampleInfo(sampleTable, sampleIndex);\n    if (!sampleInfo) {\n      return null;\n    }\n    let data;\n    if (options.metadataOnly) {\n      data = PLACEHOLDER_DATA;\n    } else {\n      let slice = this.internalTrack.demuxer.reader.requestSlice(sampleInfo.sampleOffset, sampleInfo.sampleSize);\n      if (slice instanceof Promise)\n        slice = await slice;\n      assert(slice);\n      data = readBytes(slice, sampleInfo.sampleSize);\n    }\n    const timestamp = (sampleInfo.presentationTimestamp - this.internalTrack.editListOffset) / this.internalTrack.timescale;\n    const duration = sampleInfo.duration / this.internalTrack.timescale;\n    const packet = new EncodedPacket(data, sampleInfo.isKeyFrame ? \"key\" : \"delta\", timestamp, duration, sampleIndex, sampleInfo.sampleSize);\n    this.packetToSampleIndex.set(packet, sampleIndex);\n    return packet;\n  }\n  async fetchPacketInFragment(fragment, sampleIndex, options) {\n    if (sampleIndex === -1) {\n      return null;\n    }\n    const trackData = fragment.trackData.get(this.internalTrack.id);\n    const fragmentSample = trackData.samples[sampleIndex];\n    assert(fragmentSample);\n    let data;\n    if (options.metadataOnly) {\n      data = PLACEHOLDER_DATA;\n    } else {\n      let slice = this.internalTrack.demuxer.reader.requestSlice(fragmentSample.byteOffset, fragmentSample.byteSize);\n      if (slice instanceof Promise)\n        slice = await slice;\n      assert(slice);\n      data = readBytes(slice, fragmentSample.byteSize);\n    }\n    const timestamp = (fragmentSample.presentationTimestamp - this.internalTrack.editListOffset) / this.internalTrack.timescale;\n    const duration = fragmentSample.duration / this.internalTrack.timescale;\n    const packet = new EncodedPacket(data, fragmentSample.isKeyFrame ? \"key\" : \"delta\", timestamp, duration, fragment.moofOffset + sampleIndex, fragmentSample.byteSize);\n    this.packetToFragmentLocation.set(packet, { fragment, sampleIndex });\n    return packet;\n  }\n  async performFragmentedLookup(startFragment, getMatchInFragment, searchTimestamp, latestTimestamp, options) {\n    const demuxer = this.internalTrack.demuxer;\n    let currentFragment = null;\n    let bestFragment = null;\n    let bestSampleIndex = -1;\n    if (startFragment) {\n      const { sampleIndex, correctSampleFound } = getMatchInFragment(startFragment);\n      if (correctSampleFound) {\n        return this.fetchPacketInFragment(startFragment, sampleIndex, options);\n      }\n      if (sampleIndex !== -1) {\n        bestFragment = startFragment;\n        bestSampleIndex = sampleIndex;\n      }\n    }\n    const lookupEntryIndex = binarySearchLessOrEqual(this.internalTrack.fragmentLookupTable, searchTimestamp, (x) => x.timestamp);\n    const lookupEntry = lookupEntryIndex !== -1 ? this.internalTrack.fragmentLookupTable[lookupEntryIndex] : null;\n    const positionCacheIndex = binarySearchLessOrEqual(this.internalTrack.fragmentPositionCache, searchTimestamp, (x) => x.startTimestamp);\n    const positionCacheEntry = positionCacheIndex !== -1 ? this.internalTrack.fragmentPositionCache[positionCacheIndex] : null;\n    const lookupEntryPosition = Math.max(lookupEntry?.moofOffset ?? 0, positionCacheEntry?.moofOffset ?? 0) || null;\n    let currentPos;\n    if (!startFragment) {\n      currentPos = lookupEntryPosition ?? 0;\n    } else {\n      if (lookupEntryPosition === null || startFragment.moofOffset >= lookupEntryPosition) {\n        currentPos = startFragment.moofOffset + startFragment.moofSize;\n        currentFragment = startFragment;\n      } else {\n        currentPos = lookupEntryPosition;\n      }\n    }\n    while (true) {\n      if (currentFragment) {\n        const trackData = currentFragment.trackData.get(this.internalTrack.id);\n        if (trackData && trackData.startTimestamp > latestTimestamp) {\n          break;\n        }\n      }\n      let slice = demuxer.reader.requestSliceRange(currentPos, MIN_BOX_HEADER_SIZE, MAX_BOX_HEADER_SIZE);\n      if (slice instanceof Promise)\n        slice = await slice;\n      if (!slice)\n        break;\n      const boxStartPos = currentPos;\n      const boxInfo = readBoxHeader(slice);\n      if (!boxInfo) {\n        break;\n      }\n      if (boxInfo.name === \"moof\") {\n        currentFragment = await demuxer.readFragment(boxStartPos);\n        const { sampleIndex, correctSampleFound } = getMatchInFragment(currentFragment);\n        if (correctSampleFound) {\n          return this.fetchPacketInFragment(currentFragment, sampleIndex, options);\n        }\n        if (sampleIndex !== -1) {\n          bestFragment = currentFragment;\n          bestSampleIndex = sampleIndex;\n        }\n      }\n      currentPos = boxStartPos + boxInfo.totalSize;\n    }\n    if (lookupEntry && (!bestFragment || bestFragment.moofOffset < lookupEntry.moofOffset)) {\n      const previousLookupEntry = this.internalTrack.fragmentLookupTable[lookupEntryIndex - 1];\n      assert(!previousLookupEntry || previousLookupEntry.timestamp < lookupEntry.timestamp);\n      const newSearchTimestamp = previousLookupEntry?.timestamp ?? -Infinity;\n      return this.performFragmentedLookup(null, getMatchInFragment, newSearchTimestamp, latestTimestamp, options);\n    }\n    if (bestFragment) {\n      return this.fetchPacketInFragment(bestFragment, bestSampleIndex, options);\n    }\n    return null;\n  }\n}\n\nclass IsobmffVideoTrackBacking extends IsobmffTrackBacking {\n  constructor(internalTrack) {\n    super(internalTrack);\n    this.decoderConfigPromise = null;\n    this.internalTrack = internalTrack;\n  }\n  getCodec() {\n    return this.internalTrack.info.codec;\n  }\n  getCodedWidth() {\n    return this.internalTrack.info.width;\n  }\n  getCodedHeight() {\n    return this.internalTrack.info.height;\n  }\n  getRotation() {\n    return this.internalTrack.rotation;\n  }\n  async getColorSpace() {\n    return {\n      primaries: this.internalTrack.info.colorSpace?.primaries,\n      transfer: this.internalTrack.info.colorSpace?.transfer,\n      matrix: this.internalTrack.info.colorSpace?.matrix,\n      fullRange: this.internalTrack.info.colorSpace?.fullRange\n    };\n  }\n  async canBeTransparent() {\n    return false;\n  }\n  async getDecoderConfig() {\n    if (!this.internalTrack.info.codec) {\n      return null;\n    }\n    return this.decoderConfigPromise ??= (async () => {\n      if (this.internalTrack.info.codec === \"vp9\" && !this.internalTrack.info.vp9CodecInfo) {\n        const firstPacket = await this.getFirstPacket({});\n        this.internalTrack.info.vp9CodecInfo = firstPacket && extractVp9CodecInfoFromPacket(firstPacket.data);\n      } else if (this.internalTrack.info.codec === \"av1\" && !this.internalTrack.info.av1CodecInfo) {\n        const firstPacket = await this.getFirstPacket({});\n        this.internalTrack.info.av1CodecInfo = firstPacket && extractAv1CodecInfoFromPacket(firstPacket.data);\n      }\n      return {\n        codec: extractVideoCodecString(this.internalTrack.info),\n        codedWidth: this.internalTrack.info.width,\n        codedHeight: this.internalTrack.info.height,\n        description: this.internalTrack.info.codecDescription ?? undefined,\n        colorSpace: this.internalTrack.info.colorSpace ?? undefined\n      };\n    })();\n  }\n}\n\nclass IsobmffAudioTrackBacking extends IsobmffTrackBacking {\n  constructor(internalTrack) {\n    super(internalTrack);\n    this.decoderConfig = null;\n    this.internalTrack = internalTrack;\n  }\n  getCodec() {\n    return this.internalTrack.info.codec;\n  }\n  getNumberOfChannels() {\n    return this.internalTrack.info.numberOfChannels;\n  }\n  getSampleRate() {\n    return this.internalTrack.info.sampleRate;\n  }\n  async getDecoderConfig() {\n    if (!this.internalTrack.info.codec) {\n      return null;\n    }\n    return this.decoderConfig ??= {\n      codec: extractAudioCodecString(this.internalTrack.info),\n      numberOfChannels: this.internalTrack.info.numberOfChannels,\n      sampleRate: this.internalTrack.info.sampleRate,\n      description: this.internalTrack.info.codecDescription ?? undefined\n    };\n  }\n}\nvar getSampleIndexForTimestamp = (sampleTable, timescaleUnits) => {\n  if (sampleTable.presentationTimestamps) {\n    const index = binarySearchLessOrEqual(sampleTable.presentationTimestamps, timescaleUnits, (x) => x.presentationTimestamp);\n    if (index === -1) {\n      return -1;\n    }\n    return sampleTable.presentationTimestamps[index].sampleIndex;\n  } else {\n    const index = binarySearchLessOrEqual(sampleTable.sampleTimingEntries, timescaleUnits, (x) => x.startDecodeTimestamp);\n    if (index === -1) {\n      return -1;\n    }\n    const entry = sampleTable.sampleTimingEntries[index];\n    return entry.startIndex + Math.min(Math.floor((timescaleUnits - entry.startDecodeTimestamp) / entry.delta), entry.count - 1);\n  }\n};\nvar getKeyframeSampleIndexForTimestamp = (sampleTable, timescaleUnits) => {\n  if (!sampleTable.keySampleIndices) {\n    return getSampleIndexForTimestamp(sampleTable, timescaleUnits);\n  }\n  if (sampleTable.presentationTimestamps) {\n    const index = binarySearchLessOrEqual(sampleTable.presentationTimestamps, timescaleUnits, (x) => x.presentationTimestamp);\n    if (index === -1) {\n      return -1;\n    }\n    for (let i = index;i >= 0; i--) {\n      const sampleIndex = sampleTable.presentationTimestamps[i].sampleIndex;\n      const isKeyFrame = binarySearchExact(sampleTable.keySampleIndices, sampleIndex, (x) => x) !== -1;\n      if (isKeyFrame) {\n        return sampleIndex;\n      }\n    }\n    return -1;\n  } else {\n    const sampleIndex = getSampleIndexForTimestamp(sampleTable, timescaleUnits);\n    const index = binarySearchLessOrEqual(sampleTable.keySampleIndices, sampleIndex, (x) => x);\n    return sampleTable.keySampleIndices[index] ?? -1;\n  }\n};\nvar getSampleInfo = (sampleTable, sampleIndex) => {\n  const timingEntryIndex = binarySearchLessOrEqual(sampleTable.sampleTimingEntries, sampleIndex, (x) => x.startIndex);\n  const timingEntry = sampleTable.sampleTimingEntries[timingEntryIndex];\n  if (!timingEntry || timingEntry.startIndex + timingEntry.count <= sampleIndex) {\n    return null;\n  }\n  const decodeTimestamp = timingEntry.startDecodeTimestamp + (sampleIndex - timingEntry.startIndex) * timingEntry.delta;\n  let presentationTimestamp = decodeTimestamp;\n  const offsetEntryIndex = binarySearchLessOrEqual(sampleTable.sampleCompositionTimeOffsets, sampleIndex, (x) => x.startIndex);\n  const offsetEntry = sampleTable.sampleCompositionTimeOffsets[offsetEntryIndex];\n  if (offsetEntry && sampleIndex - offsetEntry.startIndex < offsetEntry.count) {\n    presentationTimestamp += offsetEntry.offset;\n  }\n  const sampleSize = sampleTable.sampleSizes[Math.min(sampleIndex, sampleTable.sampleSizes.length - 1)];\n  const chunkEntryIndex = binarySearchLessOrEqual(sampleTable.sampleToChunk, sampleIndex, (x) => x.startSampleIndex);\n  const chunkEntry = sampleTable.sampleToChunk[chunkEntryIndex];\n  assert(chunkEntry);\n  const chunkIndex = chunkEntry.startChunkIndex + Math.floor((sampleIndex - chunkEntry.startSampleIndex) / chunkEntry.samplesPerChunk);\n  const chunkOffset = sampleTable.chunkOffsets[chunkIndex];\n  const startSampleIndexOfChunk = chunkEntry.startSampleIndex + (chunkIndex - chunkEntry.startChunkIndex) * chunkEntry.samplesPerChunk;\n  let chunkSize = 0;\n  let sampleOffset = chunkOffset;\n  if (sampleTable.sampleSizes.length === 1) {\n    sampleOffset += sampleSize * (sampleIndex - startSampleIndexOfChunk);\n    chunkSize += sampleSize * chunkEntry.samplesPerChunk;\n  } else {\n    for (let i = startSampleIndexOfChunk;i < startSampleIndexOfChunk + chunkEntry.samplesPerChunk; i++) {\n      const sampleSize2 = sampleTable.sampleSizes[i];\n      if (i < sampleIndex) {\n        sampleOffset += sampleSize2;\n      }\n      chunkSize += sampleSize2;\n    }\n  }\n  let duration = timingEntry.delta;\n  if (sampleTable.presentationTimestamps) {\n    const presentationIndex = sampleTable.presentationTimestampIndexMap[sampleIndex];\n    assert(presentationIndex !== undefined);\n    if (presentationIndex < sampleTable.presentationTimestamps.length - 1) {\n      const nextEntry = sampleTable.presentationTimestamps[presentationIndex + 1];\n      const nextPresentationTimestamp = nextEntry.presentationTimestamp;\n      duration = nextPresentationTimestamp - presentationTimestamp;\n    }\n  }\n  return {\n    presentationTimestamp,\n    duration,\n    sampleOffset,\n    sampleSize,\n    chunkOffset,\n    chunkSize,\n    isKeyFrame: sampleTable.keySampleIndices ? binarySearchExact(sampleTable.keySampleIndices, sampleIndex, (x) => x) !== -1 : true\n  };\n};\nvar getNextKeyframeIndexForSample = (sampleTable, sampleIndex) => {\n  if (!sampleTable.keySampleIndices) {\n    return sampleIndex + 1;\n  }\n  const index = binarySearchLessOrEqual(sampleTable.keySampleIndices, sampleIndex, (x) => x);\n  return sampleTable.keySampleIndices[index + 1] ?? -1;\n};\nvar offsetFragmentTrackDataByTimestamp = (trackData, timestamp) => {\n  trackData.startTimestamp += timestamp;\n  trackData.endTimestamp += timestamp;\n  for (const sample of trackData.samples) {\n    sample.presentationTimestamp += timestamp;\n  }\n  for (const entry of trackData.presentationTimestamps) {\n    entry.presentationTimestamp += timestamp;\n  }\n};\nvar extractRotationFromMatrix = (matrix) => {\n  const [m11, , , m21] = matrix;\n  const scaleX = Math.hypot(m11, m21);\n  const cosTheta = m11 / scaleX;\n  const sinTheta = m21 / scaleX;\n  const result = -Math.atan2(sinTheta, cosTheta) * (180 / Math.PI);\n  if (!Number.isFinite(result)) {\n    return 0;\n  }\n  return result;\n};\nvar sampleTableIsEmpty = (sampleTable) => {\n  return sampleTable.sampleSizes.length === 0;\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/matroska/ebml.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar EBMLId;\n(function(EBMLId2) {\n  EBMLId2[EBMLId2[\"EBML\"] = 440786851] = \"EBML\";\n  EBMLId2[EBMLId2[\"EBMLVersion\"] = 17030] = \"EBMLVersion\";\n  EBMLId2[EBMLId2[\"EBMLReadVersion\"] = 17143] = \"EBMLReadVersion\";\n  EBMLId2[EBMLId2[\"EBMLMaxIDLength\"] = 17138] = \"EBMLMaxIDLength\";\n  EBMLId2[EBMLId2[\"EBMLMaxSizeLength\"] = 17139] = \"EBMLMaxSizeLength\";\n  EBMLId2[EBMLId2[\"DocType\"] = 17026] = \"DocType\";\n  EBMLId2[EBMLId2[\"DocTypeVersion\"] = 17031] = \"DocTypeVersion\";\n  EBMLId2[EBMLId2[\"DocTypeReadVersion\"] = 17029] = \"DocTypeReadVersion\";\n  EBMLId2[EBMLId2[\"Void\"] = 236] = \"Void\";\n  EBMLId2[EBMLId2[\"Segment\"] = 408125543] = \"Segment\";\n  EBMLId2[EBMLId2[\"SeekHead\"] = 290298740] = \"SeekHead\";\n  EBMLId2[EBMLId2[\"Seek\"] = 19899] = \"Seek\";\n  EBMLId2[EBMLId2[\"SeekID\"] = 21419] = \"SeekID\";\n  EBMLId2[EBMLId2[\"SeekPosition\"] = 21420] = \"SeekPosition\";\n  EBMLId2[EBMLId2[\"Duration\"] = 17545] = \"Duration\";\n  EBMLId2[EBMLId2[\"Info\"] = 357149030] = \"Info\";\n  EBMLId2[EBMLId2[\"TimestampScale\"] = 2807729] = \"TimestampScale\";\n  EBMLId2[EBMLId2[\"MuxingApp\"] = 19840] = \"MuxingApp\";\n  EBMLId2[EBMLId2[\"WritingApp\"] = 22337] = \"WritingApp\";\n  EBMLId2[EBMLId2[\"Tracks\"] = 374648427] = \"Tracks\";\n  EBMLId2[EBMLId2[\"TrackEntry\"] = 174] = \"TrackEntry\";\n  EBMLId2[EBMLId2[\"TrackNumber\"] = 215] = \"TrackNumber\";\n  EBMLId2[EBMLId2[\"TrackUID\"] = 29637] = \"TrackUID\";\n  EBMLId2[EBMLId2[\"TrackType\"] = 131] = \"TrackType\";\n  EBMLId2[EBMLId2[\"FlagEnabled\"] = 185] = \"FlagEnabled\";\n  EBMLId2[EBMLId2[\"FlagDefault\"] = 136] = \"FlagDefault\";\n  EBMLId2[EBMLId2[\"FlagForced\"] = 21930] = \"FlagForced\";\n  EBMLId2[EBMLId2[\"FlagOriginal\"] = 21934] = \"FlagOriginal\";\n  EBMLId2[EBMLId2[\"FlagHearingImpaired\"] = 21931] = \"FlagHearingImpaired\";\n  EBMLId2[EBMLId2[\"FlagVisualImpaired\"] = 21932] = \"FlagVisualImpaired\";\n  EBMLId2[EBMLId2[\"FlagCommentary\"] = 21935] = \"FlagCommentary\";\n  EBMLId2[EBMLId2[\"FlagLacing\"] = 156] = \"FlagLacing\";\n  EBMLId2[EBMLId2[\"Name\"] = 21358] = \"Name\";\n  EBMLId2[EBMLId2[\"Language\"] = 2274716] = \"Language\";\n  EBMLId2[EBMLId2[\"LanguageBCP47\"] = 2274717] = \"LanguageBCP47\";\n  EBMLId2[EBMLId2[\"CodecID\"] = 134] = \"CodecID\";\n  EBMLId2[EBMLId2[\"CodecPrivate\"] = 25506] = \"CodecPrivate\";\n  EBMLId2[EBMLId2[\"CodecDelay\"] = 22186] = \"CodecDelay\";\n  EBMLId2[EBMLId2[\"SeekPreRoll\"] = 22203] = \"SeekPreRoll\";\n  EBMLId2[EBMLId2[\"DefaultDuration\"] = 2352003] = \"DefaultDuration\";\n  EBMLId2[EBMLId2[\"Video\"] = 224] = \"Video\";\n  EBMLId2[EBMLId2[\"PixelWidth\"] = 176] = \"PixelWidth\";\n  EBMLId2[EBMLId2[\"PixelHeight\"] = 186] = \"PixelHeight\";\n  EBMLId2[EBMLId2[\"AlphaMode\"] = 21440] = \"AlphaMode\";\n  EBMLId2[EBMLId2[\"Audio\"] = 225] = \"Audio\";\n  EBMLId2[EBMLId2[\"SamplingFrequency\"] = 181] = \"SamplingFrequency\";\n  EBMLId2[EBMLId2[\"Channels\"] = 159] = \"Channels\";\n  EBMLId2[EBMLId2[\"BitDepth\"] = 25188] = \"BitDepth\";\n  EBMLId2[EBMLId2[\"SimpleBlock\"] = 163] = \"SimpleBlock\";\n  EBMLId2[EBMLId2[\"BlockGroup\"] = 160] = \"BlockGroup\";\n  EBMLId2[EBMLId2[\"Block\"] = 161] = \"Block\";\n  EBMLId2[EBMLId2[\"BlockAdditions\"] = 30113] = \"BlockAdditions\";\n  EBMLId2[EBMLId2[\"BlockMore\"] = 166] = \"BlockMore\";\n  EBMLId2[EBMLId2[\"BlockAdditional\"] = 165] = \"BlockAdditional\";\n  EBMLId2[EBMLId2[\"BlockAddID\"] = 238] = \"BlockAddID\";\n  EBMLId2[EBMLId2[\"BlockDuration\"] = 155] = \"BlockDuration\";\n  EBMLId2[EBMLId2[\"ReferenceBlock\"] = 251] = \"ReferenceBlock\";\n  EBMLId2[EBMLId2[\"Cluster\"] = 524531317] = \"Cluster\";\n  EBMLId2[EBMLId2[\"Timestamp\"] = 231] = \"Timestamp\";\n  EBMLId2[EBMLId2[\"Cues\"] = 475249515] = \"Cues\";\n  EBMLId2[EBMLId2[\"CuePoint\"] = 187] = \"CuePoint\";\n  EBMLId2[EBMLId2[\"CueTime\"] = 179] = \"CueTime\";\n  EBMLId2[EBMLId2[\"CueTrackPositions\"] = 183] = \"CueTrackPositions\";\n  EBMLId2[EBMLId2[\"CueTrack\"] = 247] = \"CueTrack\";\n  EBMLId2[EBMLId2[\"CueClusterPosition\"] = 241] = \"CueClusterPosition\";\n  EBMLId2[EBMLId2[\"Colour\"] = 21936] = \"Colour\";\n  EBMLId2[EBMLId2[\"MatrixCoefficients\"] = 21937] = \"MatrixCoefficients\";\n  EBMLId2[EBMLId2[\"TransferCharacteristics\"] = 21946] = \"TransferCharacteristics\";\n  EBMLId2[EBMLId2[\"Primaries\"] = 21947] = \"Primaries\";\n  EBMLId2[EBMLId2[\"Range\"] = 21945] = \"Range\";\n  EBMLId2[EBMLId2[\"Projection\"] = 30320] = \"Projection\";\n  EBMLId2[EBMLId2[\"ProjectionType\"] = 30321] = \"ProjectionType\";\n  EBMLId2[EBMLId2[\"ProjectionPoseRoll\"] = 30325] = \"ProjectionPoseRoll\";\n  EBMLId2[EBMLId2[\"Attachments\"] = 423732329] = \"Attachments\";\n  EBMLId2[EBMLId2[\"AttachedFile\"] = 24999] = \"AttachedFile\";\n  EBMLId2[EBMLId2[\"FileDescription\"] = 18046] = \"FileDescription\";\n  EBMLId2[EBMLId2[\"FileName\"] = 18030] = \"FileName\";\n  EBMLId2[EBMLId2[\"FileMediaType\"] = 18016] = \"FileMediaType\";\n  EBMLId2[EBMLId2[\"FileData\"] = 18012] = \"FileData\";\n  EBMLId2[EBMLId2[\"FileUID\"] = 18094] = \"FileUID\";\n  EBMLId2[EBMLId2[\"Chapters\"] = 272869232] = \"Chapters\";\n  EBMLId2[EBMLId2[\"Tags\"] = 307544935] = \"Tags\";\n  EBMLId2[EBMLId2[\"Tag\"] = 29555] = \"Tag\";\n  EBMLId2[EBMLId2[\"Targets\"] = 25536] = \"Targets\";\n  EBMLId2[EBMLId2[\"TargetTypeValue\"] = 26826] = \"TargetTypeValue\";\n  EBMLId2[EBMLId2[\"TargetType\"] = 25546] = \"TargetType\";\n  EBMLId2[EBMLId2[\"TagTrackUID\"] = 25541] = \"TagTrackUID\";\n  EBMLId2[EBMLId2[\"TagEditionUID\"] = 25545] = \"TagEditionUID\";\n  EBMLId2[EBMLId2[\"TagChapterUID\"] = 25540] = \"TagChapterUID\";\n  EBMLId2[EBMLId2[\"TagAttachmentUID\"] = 25542] = \"TagAttachmentUID\";\n  EBMLId2[EBMLId2[\"SimpleTag\"] = 26568] = \"SimpleTag\";\n  EBMLId2[EBMLId2[\"TagName\"] = 17827] = \"TagName\";\n  EBMLId2[EBMLId2[\"TagLanguage\"] = 17530] = \"TagLanguage\";\n  EBMLId2[EBMLId2[\"TagString\"] = 17543] = \"TagString\";\n  EBMLId2[EBMLId2[\"TagBinary\"] = 17541] = \"TagBinary\";\n  EBMLId2[EBMLId2[\"ContentEncodings\"] = 28032] = \"ContentEncodings\";\n  EBMLId2[EBMLId2[\"ContentEncoding\"] = 25152] = \"ContentEncoding\";\n  EBMLId2[EBMLId2[\"ContentEncodingOrder\"] = 20529] = \"ContentEncodingOrder\";\n  EBMLId2[EBMLId2[\"ContentEncodingScope\"] = 20530] = \"ContentEncodingScope\";\n  EBMLId2[EBMLId2[\"ContentCompression\"] = 20532] = \"ContentCompression\";\n  EBMLId2[EBMLId2[\"ContentCompAlgo\"] = 16980] = \"ContentCompAlgo\";\n  EBMLId2[EBMLId2[\"ContentCompSettings\"] = 16981] = \"ContentCompSettings\";\n  EBMLId2[EBMLId2[\"ContentEncryption\"] = 20533] = \"ContentEncryption\";\n})(EBMLId || (EBMLId = {}));\nvar LEVEL_0_EBML_IDS = [\n  EBMLId.EBML,\n  EBMLId.Segment\n];\nvar LEVEL_1_EBML_IDS = [\n  EBMLId.SeekHead,\n  EBMLId.Info,\n  EBMLId.Cluster,\n  EBMLId.Tracks,\n  EBMLId.Cues,\n  EBMLId.Attachments,\n  EBMLId.Chapters,\n  EBMLId.Tags\n];\nvar LEVEL_0_AND_1_EBML_IDS = [\n  ...LEVEL_0_EBML_IDS,\n  ...LEVEL_1_EBML_IDS\n];\nvar MAX_VAR_INT_SIZE = 8;\nvar MIN_HEADER_SIZE = 2;\nvar MAX_HEADER_SIZE = 2 * MAX_VAR_INT_SIZE;\nvar readVarIntSize = (slice) => {\n  if (slice.remainingLength < 1) {\n    return null;\n  }\n  const firstByte = readU8(slice);\n  slice.skip(-1);\n  if (firstByte === 0) {\n    return null;\n  }\n  let width = 1;\n  let mask = 128;\n  while ((firstByte & mask) === 0) {\n    width++;\n    mask >>= 1;\n  }\n  if (slice.remainingLength < width) {\n    return null;\n  }\n  return width;\n};\nvar readVarInt = (slice) => {\n  if (slice.remainingLength < 1) {\n    return null;\n  }\n  const firstByte = readU8(slice);\n  if (firstByte === 0) {\n    return null;\n  }\n  let width = 1;\n  let mask = 1 << 7;\n  while ((firstByte & mask) === 0) {\n    width++;\n    mask >>= 1;\n  }\n  if (slice.remainingLength < width - 1) {\n    return null;\n  }\n  let value = firstByte & mask - 1;\n  for (let i = 1;i < width; i++) {\n    value *= 1 << 8;\n    value += readU8(slice);\n  }\n  return value;\n};\nvar readUnsignedInt = (slice, width) => {\n  if (width < 1 || width > 8) {\n    throw new Error(\"Bad unsigned int size \" + width);\n  }\n  let value = 0;\n  for (let i = 0;i < width; i++) {\n    value *= 1 << 8;\n    value += readU8(slice);\n  }\n  return value;\n};\nvar readUnsignedBigInt = (slice, width) => {\n  if (width < 1) {\n    throw new Error(\"Bad unsigned int size \" + width);\n  }\n  let value = 0n;\n  for (let i = 0;i < width; i++) {\n    value <<= 8n;\n    value += BigInt(readU8(slice));\n  }\n  return value;\n};\nvar readElementId = (slice) => {\n  const size4 = readVarIntSize(slice);\n  if (size4 === null) {\n    return null;\n  }\n  if (slice.remainingLength < size4) {\n    return null;\n  }\n  const id = readUnsignedInt(slice, size4);\n  return id;\n};\nvar readElementSize = (slice) => {\n  if (slice.remainingLength < 1) {\n    return null;\n  }\n  const firstByte = readU8(slice);\n  if (firstByte === 255) {\n    return;\n  }\n  slice.skip(-1);\n  const size4 = readVarInt(slice);\n  if (size4 === null) {\n    return null;\n  }\n  if (size4 === 72057594037927940) {\n    return;\n  }\n  return size4;\n};\nvar readElementHeader = (slice) => {\n  assert(slice.remainingLength >= MIN_HEADER_SIZE);\n  const id = readElementId(slice);\n  if (id === null) {\n    return null;\n  }\n  const size4 = readElementSize(slice);\n  if (size4 === null) {\n    return null;\n  }\n  return { id, size: size4 };\n};\nvar readAsciiString = (slice, length) => {\n  const bytes = readBytes(slice, length);\n  let strLength = 0;\n  while (strLength < length && bytes[strLength] !== 0) {\n    strLength += 1;\n  }\n  return String.fromCharCode(...bytes.subarray(0, strLength));\n};\nvar readUnicodeString = (slice, length) => {\n  const bytes = readBytes(slice, length);\n  let strLength = 0;\n  while (strLength < length && bytes[strLength] !== 0) {\n    strLength += 1;\n  }\n  return textDecoder.decode(bytes.subarray(0, strLength));\n};\nvar readFloat = (slice, width) => {\n  if (width === 0) {\n    return 0;\n  }\n  if (width !== 4 && width !== 8) {\n    throw new Error(\"Bad float size \" + width);\n  }\n  return width === 4 ? readF32Be(slice) : readF64Be(slice);\n};\nvar searchForNextElementId = async (reader, startPos, ids, until) => {\n  const idsSet = new Set(ids);\n  let currentPos = startPos;\n  while (until === null || currentPos < until) {\n    let slice = reader.requestSliceRange(currentPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      break;\n    const elementHeader = readElementHeader(slice);\n    if (!elementHeader) {\n      break;\n    }\n    if (idsSet.has(elementHeader.id)) {\n      return { pos: currentPos, found: true };\n    }\n    assertDefinedSize(elementHeader.size);\n    currentPos = slice.filePos + elementHeader.size;\n  }\n  return { pos: until !== null && until > currentPos ? until : currentPos, found: false };\n};\nvar resync = async (reader, startPos, ids, until) => {\n  const CHUNK_SIZE = 2 ** 16;\n  const idsSet = new Set(ids);\n  let currentPos = startPos;\n  while (currentPos < until) {\n    let slice = reader.requestSliceRange(currentPos, 0, Math.min(CHUNK_SIZE, until - currentPos));\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      break;\n    if (slice.length < MAX_VAR_INT_SIZE)\n      break;\n    for (let i = 0;i < slice.length - MAX_VAR_INT_SIZE; i++) {\n      slice.filePos = currentPos;\n      const elementId = readElementId(slice);\n      if (elementId !== null && idsSet.has(elementId)) {\n        return currentPos;\n      }\n      currentPos++;\n    }\n  }\n  return null;\n};\nvar CODEC_STRING_MAP = {\n  avc: \"V_MPEG4/ISO/AVC\",\n  hevc: \"V_MPEGH/ISO/HEVC\",\n  vp8: \"V_VP8\",\n  vp9: \"V_VP9\",\n  av1: \"V_AV1\",\n  aac: \"A_AAC\",\n  mp3: \"A_MPEG/L3\",\n  opus: \"A_OPUS\",\n  vorbis: \"A_VORBIS\",\n  flac: \"A_FLAC\",\n  \"pcm-u8\": \"A_PCM/INT/LIT\",\n  \"pcm-s16\": \"A_PCM/INT/LIT\",\n  \"pcm-s16be\": \"A_PCM/INT/BIG\",\n  \"pcm-s24\": \"A_PCM/INT/LIT\",\n  \"pcm-s24be\": \"A_PCM/INT/BIG\",\n  \"pcm-s32\": \"A_PCM/INT/LIT\",\n  \"pcm-s32be\": \"A_PCM/INT/BIG\",\n  \"pcm-f32\": \"A_PCM/FLOAT/IEEE\",\n  \"pcm-f64\": \"A_PCM/FLOAT/IEEE\",\n  webvtt: \"S_TEXT/WEBVTT\"\n};\nfunction assertDefinedSize(size4) {\n  if (size4 === undefined) {\n    throw new Error(\"Undefined element size is used in a place where it is not supported.\");\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/matroska/matroska-misc.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar buildMatroskaMimeType = (info) => {\n  const base = info.hasVideo ? \"video/\" : info.hasAudio ? \"audio/\" : \"application/\";\n  let string = base + (info.isWebM ? \"webm\" : \"x-matroska\");\n  if (info.codecStrings.length > 0) {\n    const uniqueCodecMimeTypes = [...new Set(info.codecStrings.filter(Boolean))];\n    string += `; codecs=\"${uniqueCodecMimeTypes.join(\", \")}\"`;\n  }\n  return string;\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/matroska/matroska-demuxer.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar BlockLacing;\n(function(BlockLacing2) {\n  BlockLacing2[BlockLacing2[\"None\"] = 0] = \"None\";\n  BlockLacing2[BlockLacing2[\"Xiph\"] = 1] = \"Xiph\";\n  BlockLacing2[BlockLacing2[\"FixedSize\"] = 2] = \"FixedSize\";\n  BlockLacing2[BlockLacing2[\"Ebml\"] = 3] = \"Ebml\";\n})(BlockLacing || (BlockLacing = {}));\nvar ContentEncodingScope;\n(function(ContentEncodingScope2) {\n  ContentEncodingScope2[ContentEncodingScope2[\"Block\"] = 1] = \"Block\";\n  ContentEncodingScope2[ContentEncodingScope2[\"Private\"] = 2] = \"Private\";\n  ContentEncodingScope2[ContentEncodingScope2[\"Next\"] = 4] = \"Next\";\n})(ContentEncodingScope || (ContentEncodingScope = {}));\nvar ContentCompAlgo;\n(function(ContentCompAlgo2) {\n  ContentCompAlgo2[ContentCompAlgo2[\"Zlib\"] = 0] = \"Zlib\";\n  ContentCompAlgo2[ContentCompAlgo2[\"Bzlib\"] = 1] = \"Bzlib\";\n  ContentCompAlgo2[ContentCompAlgo2[\"lzo1x\"] = 2] = \"lzo1x\";\n  ContentCompAlgo2[ContentCompAlgo2[\"HeaderStripping\"] = 3] = \"HeaderStripping\";\n})(ContentCompAlgo || (ContentCompAlgo = {}));\nvar METADATA_ELEMENTS = [\n  { id: EBMLId.SeekHead, flag: \"seekHeadSeen\" },\n  { id: EBMLId.Info, flag: \"infoSeen\" },\n  { id: EBMLId.Tracks, flag: \"tracksSeen\" },\n  { id: EBMLId.Cues, flag: \"cuesSeen\" }\n];\nvar MAX_RESYNC_LENGTH = 10 * 2 ** 20;\n\nclass MatroskaDemuxer extends Demuxer {\n  constructor(input2) {\n    super(input2);\n    this.readMetadataPromise = null;\n    this.segments = [];\n    this.currentSegment = null;\n    this.currentTrack = null;\n    this.currentCluster = null;\n    this.currentBlock = null;\n    this.currentBlockAdditional = null;\n    this.currentCueTime = null;\n    this.currentDecodingInstruction = null;\n    this.currentTagTargetIsMovie = true;\n    this.currentSimpleTagName = null;\n    this.currentAttachedFile = null;\n    this.isWebM = false;\n    this.reader = input2._reader;\n  }\n  async computeDuration() {\n    const tracks = await this.getTracks();\n    const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));\n    return Math.max(0, ...trackDurations);\n  }\n  async getTracks() {\n    await this.readMetadata();\n    return this.segments.flatMap((segment) => segment.tracks.map((track) => track.inputTrack));\n  }\n  async getMimeType() {\n    await this.readMetadata();\n    const tracks = await this.getTracks();\n    const codecStrings = await Promise.all(tracks.map((x) => x.getCodecParameterString()));\n    return buildMatroskaMimeType({\n      isWebM: this.isWebM,\n      hasVideo: this.segments.some((segment) => segment.tracks.some((x) => x.info?.type === \"video\")),\n      hasAudio: this.segments.some((segment) => segment.tracks.some((x) => x.info?.type === \"audio\")),\n      codecStrings: codecStrings.filter(Boolean)\n    });\n  }\n  async getMetadataTags() {\n    await this.readMetadata();\n    for (const segment of this.segments) {\n      if (!segment.metadataTagsCollected) {\n        if (this.reader.fileSize !== null) {\n          await this.loadSegmentMetadata(segment);\n        } else {}\n        segment.metadataTagsCollected = true;\n      }\n    }\n    let metadataTags = {};\n    for (const segment of this.segments) {\n      metadataTags = { ...metadataTags, ...segment.metadataTags };\n    }\n    return metadataTags;\n  }\n  readMetadata() {\n    return this.readMetadataPromise ??= (async () => {\n      let currentPos = 0;\n      while (true) {\n        let slice = this.reader.requestSliceRange(currentPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n        if (slice instanceof Promise)\n          slice = await slice;\n        if (!slice)\n          break;\n        const header2 = readElementHeader(slice);\n        if (!header2) {\n          break;\n        }\n        const id = header2.id;\n        let size4 = header2.size;\n        const dataStartPos = slice.filePos;\n        if (id === EBMLId.EBML) {\n          assertDefinedSize(size4);\n          let slice2 = this.reader.requestSlice(dataStartPos, size4);\n          if (slice2 instanceof Promise)\n            slice2 = await slice2;\n          if (!slice2)\n            break;\n          this.readContiguousElements(slice2);\n        } else if (id === EBMLId.Segment) {\n          await this.readSegment(dataStartPos, size4);\n          if (size4 === undefined) {\n            break;\n          }\n          if (this.reader.fileSize === null) {\n            break;\n          }\n        } else if (id === EBMLId.Cluster) {\n          if (this.reader.fileSize === null) {\n            break;\n          }\n          if (size4 === undefined) {\n            const nextElementPos = await searchForNextElementId(this.reader, dataStartPos, LEVEL_0_AND_1_EBML_IDS, this.reader.fileSize);\n            size4 = nextElementPos.pos - dataStartPos;\n          }\n          const lastSegment = last(this.segments);\n          if (lastSegment) {\n            lastSegment.elementEndPos = dataStartPos + size4;\n          }\n        }\n        assertDefinedSize(size4);\n        currentPos = dataStartPos + size4;\n      }\n    })();\n  }\n  async readSegment(segmentDataStart, dataSize) {\n    this.currentSegment = {\n      seekHeadSeen: false,\n      infoSeen: false,\n      tracksSeen: false,\n      cuesSeen: false,\n      tagsSeen: false,\n      attachmentsSeen: false,\n      timestampScale: -1,\n      timestampFactor: -1,\n      duration: -1,\n      seekEntries: [],\n      tracks: [],\n      cuePoints: [],\n      dataStartPos: segmentDataStart,\n      elementEndPos: dataSize === undefined ? null : segmentDataStart + dataSize,\n      clusterSeekStartPos: segmentDataStart,\n      lastReadCluster: null,\n      metadataTags: {},\n      metadataTagsCollected: false\n    };\n    this.segments.push(this.currentSegment);\n    let currentPos = segmentDataStart;\n    while (this.currentSegment.elementEndPos === null || currentPos < this.currentSegment.elementEndPos) {\n      let slice = this.reader.requestSliceRange(currentPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n      if (slice instanceof Promise)\n        slice = await slice;\n      if (!slice)\n        break;\n      const elementStartPos = currentPos;\n      const header2 = readElementHeader(slice);\n      if (!header2 || !LEVEL_1_EBML_IDS.includes(header2.id) && header2.id !== EBMLId.Void) {\n        const nextPos = await resync(this.reader, elementStartPos, LEVEL_1_EBML_IDS, Math.min(this.currentSegment.elementEndPos ?? Infinity, elementStartPos + MAX_RESYNC_LENGTH));\n        if (nextPos) {\n          currentPos = nextPos;\n          continue;\n        } else {\n          break;\n        }\n      }\n      const { id, size: size4 } = header2;\n      const dataStartPos = slice.filePos;\n      const metadataElementIndex = METADATA_ELEMENTS.findIndex((x) => x.id === id);\n      if (metadataElementIndex !== -1) {\n        const field = METADATA_ELEMENTS[metadataElementIndex].flag;\n        this.currentSegment[field] = true;\n        assertDefinedSize(size4);\n        let slice2 = this.reader.requestSlice(dataStartPos, size4);\n        if (slice2 instanceof Promise)\n          slice2 = await slice2;\n        if (slice2) {\n          this.readContiguousElements(slice2);\n        }\n      } else if (id === EBMLId.Tags || id === EBMLId.Attachments) {\n        if (id === EBMLId.Tags) {\n          this.currentSegment.tagsSeen = true;\n        } else {\n          this.currentSegment.attachmentsSeen = true;\n        }\n        assertDefinedSize(size4);\n        let slice2 = this.reader.requestSlice(dataStartPos, size4);\n        if (slice2 instanceof Promise)\n          slice2 = await slice2;\n        if (slice2) {\n          this.readContiguousElements(slice2);\n        }\n      } else if (id === EBMLId.Cluster) {\n        this.currentSegment.clusterSeekStartPos = elementStartPos;\n        break;\n      }\n      if (size4 === undefined) {\n        break;\n      } else {\n        currentPos = dataStartPos + size4;\n      }\n    }\n    this.currentSegment.seekEntries.sort((a, b) => a.segmentPosition - b.segmentPosition);\n    if (this.reader.fileSize !== null) {\n      for (const seekEntry of this.currentSegment.seekEntries) {\n        const target = METADATA_ELEMENTS.find((x) => x.id === seekEntry.id);\n        if (!target) {\n          continue;\n        }\n        if (this.currentSegment[target.flag])\n          continue;\n        let slice = this.reader.requestSliceRange(segmentDataStart + seekEntry.segmentPosition, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n        if (slice instanceof Promise)\n          slice = await slice;\n        if (!slice)\n          continue;\n        const header2 = readElementHeader(slice);\n        if (!header2)\n          continue;\n        const { id, size: size4 } = header2;\n        if (id !== target.id)\n          continue;\n        assertDefinedSize(size4);\n        this.currentSegment[target.flag] = true;\n        let dataSlice = this.reader.requestSlice(slice.filePos, size4);\n        if (dataSlice instanceof Promise)\n          dataSlice = await dataSlice;\n        if (!dataSlice)\n          continue;\n        this.readContiguousElements(dataSlice);\n      }\n    }\n    if (this.currentSegment.timestampScale === -1) {\n      this.currentSegment.timestampScale = 1e6;\n      this.currentSegment.timestampFactor = 1e9 / 1e6;\n    }\n    for (const track of this.currentSegment.tracks) {\n      if (track.defaultDurationNs !== null) {\n        track.defaultDuration = this.currentSegment.timestampFactor * track.defaultDurationNs / 1e9;\n      }\n    }\n    this.currentSegment.tracks.sort((a, b) => Number(b.disposition.default) - Number(a.disposition.default));\n    const idToTrack = new Map(this.currentSegment.tracks.map((x) => [x.id, x]));\n    for (const cuePoint of this.currentSegment.cuePoints) {\n      const track = idToTrack.get(cuePoint.trackId);\n      if (track) {\n        track.cuePoints.push(cuePoint);\n      }\n    }\n    for (const track of this.currentSegment.tracks) {\n      track.cuePoints.sort((a, b) => a.time - b.time);\n      for (let i = 0;i < track.cuePoints.length - 1; i++) {\n        const cuePoint1 = track.cuePoints[i];\n        const cuePoint2 = track.cuePoints[i + 1];\n        if (cuePoint1.time === cuePoint2.time) {\n          track.cuePoints.splice(i + 1, 1);\n          i--;\n        }\n      }\n    }\n    let trackWithMostCuePoints = null;\n    let maxCuePointCount = -Infinity;\n    for (const track of this.currentSegment.tracks) {\n      if (track.cuePoints.length > maxCuePointCount) {\n        maxCuePointCount = track.cuePoints.length;\n        trackWithMostCuePoints = track;\n      }\n    }\n    for (const track of this.currentSegment.tracks) {\n      if (track.cuePoints.length === 0) {\n        track.cuePoints = trackWithMostCuePoints.cuePoints;\n      }\n    }\n    this.currentSegment = null;\n  }\n  async readCluster(startPos, segment) {\n    if (segment.lastReadCluster?.elementStartPos === startPos) {\n      return segment.lastReadCluster;\n    }\n    let headerSlice = this.reader.requestSliceRange(startPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n    if (headerSlice instanceof Promise)\n      headerSlice = await headerSlice;\n    assert(headerSlice);\n    const elementStartPos = startPos;\n    const elementHeader = readElementHeader(headerSlice);\n    assert(elementHeader);\n    const id = elementHeader.id;\n    assert(id === EBMLId.Cluster);\n    let size4 = elementHeader.size;\n    const dataStartPos = headerSlice.filePos;\n    if (size4 === undefined) {\n      const nextElementPos = await searchForNextElementId(this.reader, dataStartPos, LEVEL_0_AND_1_EBML_IDS, segment.elementEndPos);\n      size4 = nextElementPos.pos - dataStartPos;\n    }\n    let dataSlice = this.reader.requestSlice(dataStartPos, size4);\n    if (dataSlice instanceof Promise)\n      dataSlice = await dataSlice;\n    const cluster = {\n      segment,\n      elementStartPos,\n      elementEndPos: dataStartPos + size4,\n      dataStartPos,\n      timestamp: -1,\n      trackData: new Map\n    };\n    this.currentCluster = cluster;\n    if (dataSlice) {\n      const endPos = this.readContiguousElements(dataSlice, LEVEL_0_AND_1_EBML_IDS);\n      cluster.elementEndPos = endPos;\n    }\n    for (const [, trackData] of cluster.trackData) {\n      const track = trackData.track;\n      assert(trackData.blocks.length > 0);\n      let hasLacedBlocks = false;\n      for (let i = 0;i < trackData.blocks.length; i++) {\n        const block = trackData.blocks[i];\n        block.timestamp += cluster.timestamp;\n        hasLacedBlocks ||= block.lacing !== BlockLacing.None;\n      }\n      trackData.presentationTimestamps = trackData.blocks.map((block, i) => ({ timestamp: block.timestamp, blockIndex: i })).sort((a, b) => a.timestamp - b.timestamp);\n      for (let i = 0;i < trackData.presentationTimestamps.length; i++) {\n        const currentEntry = trackData.presentationTimestamps[i];\n        const currentBlock = trackData.blocks[currentEntry.blockIndex];\n        if (trackData.firstKeyFrameTimestamp === null && currentBlock.isKeyFrame) {\n          trackData.firstKeyFrameTimestamp = currentBlock.timestamp;\n        }\n        if (i < trackData.presentationTimestamps.length - 1) {\n          const nextEntry = trackData.presentationTimestamps[i + 1];\n          currentBlock.duration = nextEntry.timestamp - currentBlock.timestamp;\n        } else if (currentBlock.duration === 0) {\n          if (track.defaultDuration != null) {\n            if (currentBlock.lacing === BlockLacing.None) {\n              currentBlock.duration = track.defaultDuration;\n            } else {}\n          }\n        }\n      }\n      if (hasLacedBlocks) {\n        this.expandLacedBlocks(trackData.blocks, track);\n        trackData.presentationTimestamps = trackData.blocks.map((block, i) => ({ timestamp: block.timestamp, blockIndex: i })).sort((a, b) => a.timestamp - b.timestamp);\n      }\n      const firstBlock = trackData.blocks[trackData.presentationTimestamps[0].blockIndex];\n      const lastBlock = trackData.blocks[last(trackData.presentationTimestamps).blockIndex];\n      trackData.startTimestamp = firstBlock.timestamp;\n      trackData.endTimestamp = lastBlock.timestamp + lastBlock.duration;\n      const insertionIndex = binarySearchLessOrEqual(track.clusterPositionCache, trackData.startTimestamp, (x) => x.startTimestamp);\n      if (insertionIndex === -1 || track.clusterPositionCache[insertionIndex].elementStartPos !== elementStartPos) {\n        track.clusterPositionCache.splice(insertionIndex + 1, 0, {\n          elementStartPos: cluster.elementStartPos,\n          startTimestamp: trackData.startTimestamp\n        });\n      }\n    }\n    segment.lastReadCluster = cluster;\n    return cluster;\n  }\n  getTrackDataInCluster(cluster, trackNumber) {\n    let trackData = cluster.trackData.get(trackNumber);\n    if (!trackData) {\n      const track = cluster.segment.tracks.find((x) => x.id === trackNumber);\n      if (!track) {\n        return null;\n      }\n      trackData = {\n        track,\n        startTimestamp: 0,\n        endTimestamp: 0,\n        firstKeyFrameTimestamp: null,\n        blocks: [],\n        presentationTimestamps: []\n      };\n      cluster.trackData.set(trackNumber, trackData);\n    }\n    return trackData;\n  }\n  expandLacedBlocks(blocks, track) {\n    for (let blockIndex = 0;blockIndex < blocks.length; blockIndex++) {\n      const originalBlock = blocks[blockIndex];\n      if (originalBlock.lacing === BlockLacing.None) {\n        continue;\n      }\n      if (!originalBlock.decoded) {\n        originalBlock.data = this.decodeBlockData(track, originalBlock.data);\n        originalBlock.decoded = true;\n      }\n      const slice = FileSlice.tempFromBytes(originalBlock.data);\n      const frameSizes = [];\n      const frameCount = readU8(slice) + 1;\n      switch (originalBlock.lacing) {\n        case BlockLacing.Xiph:\n          {\n            let totalUsedSize = 0;\n            for (let i = 0;i < frameCount - 1; i++) {\n              let frameSize = 0;\n              while (slice.bufferPos < slice.length) {\n                const value = readU8(slice);\n                frameSize += value;\n                if (value < 255) {\n                  frameSizes.push(frameSize);\n                  totalUsedSize += frameSize;\n                  break;\n                }\n              }\n            }\n            frameSizes.push(slice.length - (slice.bufferPos + totalUsedSize));\n          }\n          ;\n          break;\n        case BlockLacing.FixedSize:\n          {\n            const totalDataSize = slice.length - 1;\n            const frameSize = Math.floor(totalDataSize / frameCount);\n            for (let i = 0;i < frameCount; i++) {\n              frameSizes.push(frameSize);\n            }\n          }\n          ;\n          break;\n        case BlockLacing.Ebml:\n          {\n            const firstResult = readVarInt(slice);\n            assert(firstResult !== null);\n            let currentSize = firstResult;\n            frameSizes.push(currentSize);\n            let totalUsedSize = currentSize;\n            for (let i = 1;i < frameCount - 1; i++) {\n              const startPos = slice.bufferPos;\n              const diffResult = readVarInt(slice);\n              assert(diffResult !== null);\n              const unsignedDiff = diffResult;\n              const width = slice.bufferPos - startPos;\n              const bias = (1 << width * 7 - 1) - 1;\n              const diff = unsignedDiff - bias;\n              currentSize += diff;\n              frameSizes.push(currentSize);\n              totalUsedSize += currentSize;\n            }\n            frameSizes.push(slice.length - (slice.bufferPos + totalUsedSize));\n          }\n          ;\n          break;\n        default:\n          assert(false);\n      }\n      assert(frameSizes.length === frameCount);\n      blocks.splice(blockIndex, 1);\n      const blockDuration = originalBlock.duration || frameCount * (track.defaultDuration ?? 0);\n      for (let i = 0;i < frameCount; i++) {\n        const frameSize = frameSizes[i];\n        const frameData = readBytes(slice, frameSize);\n        const frameTimestamp = originalBlock.timestamp + blockDuration * i / frameCount;\n        const frameDuration = blockDuration / frameCount;\n        blocks.splice(blockIndex + i, 0, {\n          timestamp: frameTimestamp,\n          duration: frameDuration,\n          isKeyFrame: originalBlock.isKeyFrame,\n          data: frameData,\n          lacing: BlockLacing.None,\n          decoded: true,\n          mainAdditional: originalBlock.mainAdditional\n        });\n      }\n      blockIndex += frameCount;\n      blockIndex--;\n    }\n  }\n  async loadSegmentMetadata(segment) {\n    for (const seekEntry of segment.seekEntries) {\n      if (seekEntry.id === EBMLId.Tags && !segment.tagsSeen) {} else if (seekEntry.id === EBMLId.Attachments && !segment.attachmentsSeen) {} else {\n        continue;\n      }\n      let slice = this.reader.requestSliceRange(segment.dataStartPos + seekEntry.segmentPosition, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n      if (slice instanceof Promise)\n        slice = await slice;\n      if (!slice)\n        continue;\n      const header2 = readElementHeader(slice);\n      if (!header2 || header2.id !== seekEntry.id)\n        continue;\n      const { size: size4 } = header2;\n      assertDefinedSize(size4);\n      assert(!this.currentSegment);\n      this.currentSegment = segment;\n      let dataSlice = this.reader.requestSlice(slice.filePos, size4);\n      if (dataSlice instanceof Promise)\n        dataSlice = await dataSlice;\n      if (dataSlice) {\n        this.readContiguousElements(dataSlice);\n      }\n      this.currentSegment = null;\n      if (seekEntry.id === EBMLId.Tags) {\n        segment.tagsSeen = true;\n      } else if (seekEntry.id === EBMLId.Attachments) {\n        segment.attachmentsSeen = true;\n      }\n    }\n  }\n  readContiguousElements(slice, stopIds) {\n    while (slice.remainingLength >= MIN_HEADER_SIZE) {\n      const startPos = slice.filePos;\n      const foundElement = this.traverseElement(slice, stopIds);\n      if (!foundElement) {\n        return startPos;\n      }\n    }\n    return slice.filePos;\n  }\n  traverseElement(slice, stopIds) {\n    const header2 = readElementHeader(slice);\n    if (!header2) {\n      return false;\n    }\n    if (stopIds && stopIds.includes(header2.id)) {\n      return false;\n    }\n    const { id, size: size4 } = header2;\n    const dataStartPos = slice.filePos;\n    assertDefinedSize(size4);\n    switch (id) {\n      case EBMLId.DocType:\n        {\n          this.isWebM = readAsciiString(slice, size4) === \"webm\";\n        }\n        ;\n        break;\n      case EBMLId.Seek:\n        {\n          if (!this.currentSegment)\n            break;\n          const seekEntry = { id: -1, segmentPosition: -1 };\n          this.currentSegment.seekEntries.push(seekEntry);\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n          if (seekEntry.id === -1 || seekEntry.segmentPosition === -1) {\n            this.currentSegment.seekEntries.pop();\n          }\n        }\n        ;\n        break;\n      case EBMLId.SeekID:\n        {\n          const lastSeekEntry = this.currentSegment?.seekEntries[this.currentSegment.seekEntries.length - 1];\n          if (!lastSeekEntry)\n            break;\n          lastSeekEntry.id = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.SeekPosition:\n        {\n          const lastSeekEntry = this.currentSegment?.seekEntries[this.currentSegment.seekEntries.length - 1];\n          if (!lastSeekEntry)\n            break;\n          lastSeekEntry.segmentPosition = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.TimestampScale:\n        {\n          if (!this.currentSegment)\n            break;\n          this.currentSegment.timestampScale = readUnsignedInt(slice, size4);\n          this.currentSegment.timestampFactor = 1e9 / this.currentSegment.timestampScale;\n        }\n        ;\n        break;\n      case EBMLId.Duration:\n        {\n          if (!this.currentSegment)\n            break;\n          this.currentSegment.duration = readFloat(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.TrackEntry:\n        {\n          if (!this.currentSegment)\n            break;\n          this.currentTrack = {\n            id: -1,\n            segment: this.currentSegment,\n            demuxer: this,\n            clusterPositionCache: [],\n            cuePoints: [],\n            disposition: {\n              ...DEFAULT_TRACK_DISPOSITION\n            },\n            inputTrack: null,\n            codecId: null,\n            codecPrivate: null,\n            defaultDuration: null,\n            defaultDurationNs: null,\n            name: null,\n            languageCode: UNDETERMINED_LANGUAGE,\n            decodingInstructions: [],\n            info: null\n          };\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n          if (!this.currentTrack) {\n            break;\n          }\n          if (this.currentTrack.decodingInstructions.some((instruction) => {\n            return instruction.data?.type !== \"decompress\" || instruction.scope !== ContentEncodingScope.Block || instruction.data.algorithm !== ContentCompAlgo.HeaderStripping;\n          })) {\n            console.warn(`Track #${this.currentTrack.id} has an unsupported content encoding; dropping.`);\n            this.currentTrack = null;\n          }\n          if (this.currentTrack && this.currentTrack.id !== -1 && this.currentTrack.codecId && this.currentTrack.info) {\n            const slashIndex = this.currentTrack.codecId.indexOf(\"/\");\n            const codecIdWithoutSuffix = slashIndex === -1 ? this.currentTrack.codecId : this.currentTrack.codecId.slice(0, slashIndex);\n            if (this.currentTrack.info.type === \"video\" && this.currentTrack.info.width !== -1 && this.currentTrack.info.height !== -1) {\n              if (this.currentTrack.codecId === CODEC_STRING_MAP.avc) {\n                this.currentTrack.info.codec = \"avc\";\n                this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n              } else if (this.currentTrack.codecId === CODEC_STRING_MAP.hevc) {\n                this.currentTrack.info.codec = \"hevc\";\n                this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n              } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.vp8) {\n                this.currentTrack.info.codec = \"vp8\";\n              } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.vp9) {\n                this.currentTrack.info.codec = \"vp9\";\n              } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.av1) {\n                this.currentTrack.info.codec = \"av1\";\n              }\n              const videoTrack = this.currentTrack;\n              const inputTrack = new InputVideoTrack(this.input, new MatroskaVideoTrackBacking(videoTrack));\n              this.currentTrack.inputTrack = inputTrack;\n              this.currentSegment.tracks.push(this.currentTrack);\n            } else if (this.currentTrack.info.type === \"audio\" && this.currentTrack.info.numberOfChannels !== -1 && this.currentTrack.info.sampleRate !== -1) {\n              if (codecIdWithoutSuffix === CODEC_STRING_MAP.aac) {\n                this.currentTrack.info.codec = \"aac\";\n                this.currentTrack.info.aacCodecInfo = {\n                  isMpeg2: this.currentTrack.codecId.includes(\"MPEG2\"),\n                  objectType: null\n                };\n                this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n              } else if (this.currentTrack.codecId === CODEC_STRING_MAP.mp3) {\n                this.currentTrack.info.codec = \"mp3\";\n              } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.opus) {\n                this.currentTrack.info.codec = \"opus\";\n                this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n                this.currentTrack.info.sampleRate = OPUS_SAMPLE_RATE;\n              } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.vorbis) {\n                this.currentTrack.info.codec = \"vorbis\";\n                this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n              } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.flac) {\n                this.currentTrack.info.codec = \"flac\";\n                this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n              } else if (this.currentTrack.codecId === \"A_PCM/INT/LIT\") {\n                if (this.currentTrack.info.bitDepth === 8) {\n                  this.currentTrack.info.codec = \"pcm-u8\";\n                } else if (this.currentTrack.info.bitDepth === 16) {\n                  this.currentTrack.info.codec = \"pcm-s16\";\n                } else if (this.currentTrack.info.bitDepth === 24) {\n                  this.currentTrack.info.codec = \"pcm-s24\";\n                } else if (this.currentTrack.info.bitDepth === 32) {\n                  this.currentTrack.info.codec = \"pcm-s32\";\n                }\n              } else if (this.currentTrack.codecId === \"A_PCM/INT/BIG\") {\n                if (this.currentTrack.info.bitDepth === 8) {\n                  this.currentTrack.info.codec = \"pcm-u8\";\n                } else if (this.currentTrack.info.bitDepth === 16) {\n                  this.currentTrack.info.codec = \"pcm-s16be\";\n                } else if (this.currentTrack.info.bitDepth === 24) {\n                  this.currentTrack.info.codec = \"pcm-s24be\";\n                } else if (this.currentTrack.info.bitDepth === 32) {\n                  this.currentTrack.info.codec = \"pcm-s32be\";\n                }\n              } else if (this.currentTrack.codecId === \"A_PCM/FLOAT/IEEE\") {\n                if (this.currentTrack.info.bitDepth === 32) {\n                  this.currentTrack.info.codec = \"pcm-f32\";\n                } else if (this.currentTrack.info.bitDepth === 64) {\n                  this.currentTrack.info.codec = \"pcm-f64\";\n                }\n              }\n              const audioTrack = this.currentTrack;\n              const inputTrack = new InputAudioTrack(this.input, new MatroskaAudioTrackBacking(audioTrack));\n              this.currentTrack.inputTrack = inputTrack;\n              this.currentSegment.tracks.push(this.currentTrack);\n            }\n          }\n          this.currentTrack = null;\n        }\n        ;\n        break;\n      case EBMLId.TrackNumber:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.id = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.TrackType:\n        {\n          if (!this.currentTrack)\n            break;\n          const type = readUnsignedInt(slice, size4);\n          if (type === 1) {\n            this.currentTrack.info = {\n              type: \"video\",\n              width: -1,\n              height: -1,\n              rotation: 0,\n              codec: null,\n              codecDescription: null,\n              colorSpace: null,\n              alphaMode: false\n            };\n          } else if (type === 2) {\n            this.currentTrack.info = {\n              type: \"audio\",\n              numberOfChannels: -1,\n              sampleRate: -1,\n              bitDepth: -1,\n              codec: null,\n              codecDescription: null,\n              aacCodecInfo: null\n            };\n          }\n        }\n        ;\n        break;\n      case EBMLId.FlagEnabled:\n        {\n          if (!this.currentTrack)\n            break;\n          const enabled = readUnsignedInt(slice, size4);\n          if (!enabled) {\n            this.currentTrack = null;\n          }\n        }\n        ;\n        break;\n      case EBMLId.FlagDefault:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.disposition.default = !!readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.FlagForced:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.disposition.forced = !!readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.FlagOriginal:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.disposition.original = !!readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.FlagHearingImpaired:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.disposition.hearingImpaired = !!readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.FlagVisualImpaired:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.disposition.visuallyImpaired = !!readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.FlagCommentary:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.disposition.commentary = !!readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.CodecID:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.codecId = readAsciiString(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.CodecPrivate:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.codecPrivate = readBytes(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.DefaultDuration:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.defaultDurationNs = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.Name:\n        {\n          if (!this.currentTrack)\n            break;\n          this.currentTrack.name = readUnicodeString(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.Language:\n        {\n          if (!this.currentTrack)\n            break;\n          if (this.currentTrack.languageCode !== UNDETERMINED_LANGUAGE) {\n            break;\n          }\n          this.currentTrack.languageCode = readAsciiString(slice, size4);\n          if (!isIso639Dash2LanguageCode(this.currentTrack.languageCode)) {\n            this.currentTrack.languageCode = UNDETERMINED_LANGUAGE;\n          }\n        }\n        ;\n        break;\n      case EBMLId.LanguageBCP47:\n        {\n          if (!this.currentTrack)\n            break;\n          const bcp47 = readAsciiString(slice, size4);\n          const languageSubtag = bcp47.split(\"-\")[0];\n          if (languageSubtag) {\n            this.currentTrack.languageCode = languageSubtag;\n          } else {\n            this.currentTrack.languageCode = UNDETERMINED_LANGUAGE;\n          }\n        }\n        ;\n        break;\n      case EBMLId.Video:\n        {\n          if (this.currentTrack?.info?.type !== \"video\")\n            break;\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n        }\n        ;\n        break;\n      case EBMLId.PixelWidth:\n        {\n          if (this.currentTrack?.info?.type !== \"video\")\n            break;\n          this.currentTrack.info.width = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.PixelHeight:\n        {\n          if (this.currentTrack?.info?.type !== \"video\")\n            break;\n          this.currentTrack.info.height = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.AlphaMode:\n        {\n          if (this.currentTrack?.info?.type !== \"video\")\n            break;\n          this.currentTrack.info.alphaMode = readUnsignedInt(slice, size4) === 1;\n        }\n        ;\n        break;\n      case EBMLId.Colour:\n        {\n          if (this.currentTrack?.info?.type !== \"video\")\n            break;\n          this.currentTrack.info.colorSpace = {};\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n        }\n        ;\n        break;\n      case EBMLId.MatrixCoefficients:\n        {\n          if (this.currentTrack?.info?.type !== \"video\" || !this.currentTrack.info.colorSpace)\n            break;\n          const matrixCoefficients = readUnsignedInt(slice, size4);\n          const mapped = MATRIX_COEFFICIENTS_MAP_INVERSE[matrixCoefficients] ?? null;\n          this.currentTrack.info.colorSpace.matrix = mapped;\n        }\n        ;\n        break;\n      case EBMLId.Range:\n        {\n          if (this.currentTrack?.info?.type !== \"video\" || !this.currentTrack.info.colorSpace)\n            break;\n          this.currentTrack.info.colorSpace.fullRange = readUnsignedInt(slice, size4) === 2;\n        }\n        ;\n        break;\n      case EBMLId.TransferCharacteristics:\n        {\n          if (this.currentTrack?.info?.type !== \"video\" || !this.currentTrack.info.colorSpace)\n            break;\n          const transferCharacteristics = readUnsignedInt(slice, size4);\n          const mapped = TRANSFER_CHARACTERISTICS_MAP_INVERSE[transferCharacteristics] ?? null;\n          this.currentTrack.info.colorSpace.transfer = mapped;\n        }\n        ;\n        break;\n      case EBMLId.Primaries:\n        {\n          if (this.currentTrack?.info?.type !== \"video\" || !this.currentTrack.info.colorSpace)\n            break;\n          const primaries = readUnsignedInt(slice, size4);\n          const mapped = COLOR_PRIMARIES_MAP_INVERSE[primaries] ?? null;\n          this.currentTrack.info.colorSpace.primaries = mapped;\n        }\n        ;\n        break;\n      case EBMLId.Projection:\n        {\n          if (this.currentTrack?.info?.type !== \"video\")\n            break;\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n        }\n        ;\n        break;\n      case EBMLId.ProjectionPoseRoll:\n        {\n          if (this.currentTrack?.info?.type !== \"video\")\n            break;\n          const rotation = readFloat(slice, size4);\n          const flippedRotation = -rotation;\n          try {\n            this.currentTrack.info.rotation = normalizeRotation(flippedRotation);\n          } catch {}\n        }\n        ;\n        break;\n      case EBMLId.Audio:\n        {\n          if (this.currentTrack?.info?.type !== \"audio\")\n            break;\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n        }\n        ;\n        break;\n      case EBMLId.SamplingFrequency:\n        {\n          if (this.currentTrack?.info?.type !== \"audio\")\n            break;\n          this.currentTrack.info.sampleRate = readFloat(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.Channels:\n        {\n          if (this.currentTrack?.info?.type !== \"audio\")\n            break;\n          this.currentTrack.info.numberOfChannels = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.BitDepth:\n        {\n          if (this.currentTrack?.info?.type !== \"audio\")\n            break;\n          this.currentTrack.info.bitDepth = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.CuePoint:\n        {\n          if (!this.currentSegment)\n            break;\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n          this.currentCueTime = null;\n        }\n        ;\n        break;\n      case EBMLId.CueTime:\n        {\n          this.currentCueTime = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.CueTrackPositions:\n        {\n          if (this.currentCueTime === null)\n            break;\n          assert(this.currentSegment);\n          const cuePoint = { time: this.currentCueTime, trackId: -1, clusterPosition: -1 };\n          this.currentSegment.cuePoints.push(cuePoint);\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n          if (cuePoint.trackId === -1 || cuePoint.clusterPosition === -1) {\n            this.currentSegment.cuePoints.pop();\n          }\n        }\n        ;\n        break;\n      case EBMLId.CueTrack:\n        {\n          const lastCuePoint = this.currentSegment?.cuePoints[this.currentSegment.cuePoints.length - 1];\n          if (!lastCuePoint)\n            break;\n          lastCuePoint.trackId = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.CueClusterPosition:\n        {\n          const lastCuePoint = this.currentSegment?.cuePoints[this.currentSegment.cuePoints.length - 1];\n          if (!lastCuePoint)\n            break;\n          assert(this.currentSegment);\n          lastCuePoint.clusterPosition = this.currentSegment.dataStartPos + readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.Timestamp:\n        {\n          if (!this.currentCluster)\n            break;\n          this.currentCluster.timestamp = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.SimpleBlock:\n        {\n          if (!this.currentCluster)\n            break;\n          const trackNumber = readVarInt(slice);\n          if (trackNumber === null)\n            break;\n          const trackData = this.getTrackDataInCluster(this.currentCluster, trackNumber);\n          if (!trackData)\n            break;\n          const relativeTimestamp = readI16Be(slice);\n          const flags = readU8(slice);\n          const lacing = flags >> 1 & 3;\n          let isKeyFrame = !!(flags & 128);\n          if (trackData.track.info?.type === \"audio\" && trackData.track.info.codec) {\n            isKeyFrame = true;\n          }\n          const blockData = readBytes(slice, size4 - (slice.filePos - dataStartPos));\n          const hasDecodingInstructions = trackData.track.decodingInstructions.length > 0;\n          trackData.blocks.push({\n            timestamp: relativeTimestamp,\n            duration: 0,\n            isKeyFrame,\n            data: blockData,\n            lacing,\n            decoded: !hasDecodingInstructions,\n            mainAdditional: null\n          });\n        }\n        ;\n        break;\n      case EBMLId.BlockGroup:\n        {\n          if (!this.currentCluster)\n            break;\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n          this.currentBlock = null;\n        }\n        ;\n        break;\n      case EBMLId.Block:\n        {\n          if (!this.currentCluster)\n            break;\n          const trackNumber = readVarInt(slice);\n          if (trackNumber === null)\n            break;\n          const trackData = this.getTrackDataInCluster(this.currentCluster, trackNumber);\n          if (!trackData)\n            break;\n          const relativeTimestamp = readI16Be(slice);\n          const flags = readU8(slice);\n          const lacing = flags >> 1 & 3;\n          const blockData = readBytes(slice, size4 - (slice.filePos - dataStartPos));\n          const hasDecodingInstructions = trackData.track.decodingInstructions.length > 0;\n          this.currentBlock = {\n            timestamp: relativeTimestamp,\n            duration: 0,\n            isKeyFrame: true,\n            data: blockData,\n            lacing,\n            decoded: !hasDecodingInstructions,\n            mainAdditional: null\n          };\n          trackData.blocks.push(this.currentBlock);\n        }\n        ;\n        break;\n      case EBMLId.BlockAdditions:\n        {\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n        }\n        ;\n        break;\n      case EBMLId.BlockMore:\n        {\n          if (!this.currentBlock)\n            break;\n          this.currentBlockAdditional = {\n            addId: 1,\n            data: null\n          };\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n          if (this.currentBlockAdditional.data && this.currentBlockAdditional.addId === 1) {\n            this.currentBlock.mainAdditional = this.currentBlockAdditional.data;\n          }\n          this.currentBlockAdditional = null;\n        }\n        ;\n        break;\n      case EBMLId.BlockAdditional:\n        {\n          if (!this.currentBlockAdditional)\n            break;\n          this.currentBlockAdditional.data = readBytes(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.BlockAddID:\n        {\n          if (!this.currentBlockAdditional)\n            break;\n          this.currentBlockAdditional.addId = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.BlockDuration:\n        {\n          if (!this.currentBlock)\n            break;\n          this.currentBlock.duration = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.ReferenceBlock:\n        {\n          if (!this.currentBlock)\n            break;\n          this.currentBlock.isKeyFrame = false;\n        }\n        ;\n        break;\n      case EBMLId.Tag:\n        {\n          this.currentTagTargetIsMovie = true;\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n        }\n        ;\n        break;\n      case EBMLId.Targets:\n        {\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n        }\n        ;\n        break;\n      case EBMLId.TargetTypeValue:\n        {\n          const targetTypeValue = readUnsignedInt(slice, size4);\n          if (targetTypeValue !== 50) {\n            this.currentTagTargetIsMovie = false;\n          }\n        }\n        ;\n        break;\n      case EBMLId.TagTrackUID:\n      case EBMLId.TagEditionUID:\n      case EBMLId.TagChapterUID:\n      case EBMLId.TagAttachmentUID:\n        {\n          this.currentTagTargetIsMovie = false;\n        }\n        ;\n        break;\n      case EBMLId.SimpleTag:\n        {\n          if (!this.currentTagTargetIsMovie)\n            break;\n          this.currentSimpleTagName = null;\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n        }\n        ;\n        break;\n      case EBMLId.TagName:\n        {\n          this.currentSimpleTagName = readUnicodeString(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.TagString:\n        {\n          if (!this.currentSimpleTagName)\n            break;\n          const value = readUnicodeString(slice, size4);\n          this.processTagValue(this.currentSimpleTagName, value);\n        }\n        ;\n        break;\n      case EBMLId.TagBinary:\n        {\n          if (!this.currentSimpleTagName)\n            break;\n          const value = readBytes(slice, size4);\n          this.processTagValue(this.currentSimpleTagName, value);\n        }\n        ;\n        break;\n      case EBMLId.AttachedFile:\n        {\n          if (!this.currentSegment)\n            break;\n          this.currentAttachedFile = {\n            fileUid: null,\n            fileName: null,\n            fileMediaType: null,\n            fileData: null,\n            fileDescription: null\n          };\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n          const tags = this.currentSegment.metadataTags;\n          if (this.currentAttachedFile.fileUid && this.currentAttachedFile.fileData) {\n            tags.raw ??= {};\n            tags.raw[this.currentAttachedFile.fileUid.toString()] = new AttachedFile(this.currentAttachedFile.fileData, this.currentAttachedFile.fileMediaType ?? undefined, this.currentAttachedFile.fileName ?? undefined, this.currentAttachedFile.fileDescription ?? undefined);\n          }\n          if (this.currentAttachedFile.fileMediaType?.startsWith(\"image/\") && this.currentAttachedFile.fileData) {\n            const fileName = this.currentAttachedFile.fileName;\n            let kind = \"unknown\";\n            if (fileName) {\n              const lowerName = fileName.toLowerCase();\n              if (lowerName.startsWith(\"cover.\")) {\n                kind = \"coverFront\";\n              } else if (lowerName.startsWith(\"back.\")) {\n                kind = \"coverBack\";\n              }\n            }\n            tags.images ??= [];\n            tags.images.push({\n              data: this.currentAttachedFile.fileData,\n              mimeType: this.currentAttachedFile.fileMediaType,\n              kind,\n              name: this.currentAttachedFile.fileName ?? undefined,\n              description: this.currentAttachedFile.fileDescription ?? undefined\n            });\n          }\n          this.currentAttachedFile = null;\n        }\n        ;\n        break;\n      case EBMLId.FileUID:\n        {\n          if (!this.currentAttachedFile)\n            break;\n          this.currentAttachedFile.fileUid = readUnsignedBigInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.FileName:\n        {\n          if (!this.currentAttachedFile)\n            break;\n          this.currentAttachedFile.fileName = readUnicodeString(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.FileMediaType:\n        {\n          if (!this.currentAttachedFile)\n            break;\n          this.currentAttachedFile.fileMediaType = readAsciiString(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.FileData:\n        {\n          if (!this.currentAttachedFile)\n            break;\n          this.currentAttachedFile.fileData = readBytes(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.FileDescription:\n        {\n          if (!this.currentAttachedFile)\n            break;\n          this.currentAttachedFile.fileDescription = readUnicodeString(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.ContentEncodings:\n        {\n          if (!this.currentTrack)\n            break;\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n          this.currentTrack.decodingInstructions.sort((a, b) => b.order - a.order);\n        }\n        ;\n        break;\n      case EBMLId.ContentEncoding:\n        {\n          this.currentDecodingInstruction = {\n            order: 0,\n            scope: ContentEncodingScope.Block,\n            data: null\n          };\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n          if (this.currentDecodingInstruction.data) {\n            this.currentTrack.decodingInstructions.push(this.currentDecodingInstruction);\n          }\n          this.currentDecodingInstruction = null;\n        }\n        ;\n        break;\n      case EBMLId.ContentEncodingOrder:\n        {\n          if (!this.currentDecodingInstruction)\n            break;\n          this.currentDecodingInstruction.order = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.ContentEncodingScope:\n        {\n          if (!this.currentDecodingInstruction)\n            break;\n          this.currentDecodingInstruction.scope = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.ContentCompression:\n        {\n          if (!this.currentDecodingInstruction)\n            break;\n          this.currentDecodingInstruction.data = {\n            type: \"decompress\",\n            algorithm: ContentCompAlgo.Zlib,\n            settings: null\n          };\n          this.readContiguousElements(slice.slice(dataStartPos, size4));\n        }\n        ;\n        break;\n      case EBMLId.ContentCompAlgo:\n        {\n          if (this.currentDecodingInstruction?.data?.type !== \"decompress\")\n            break;\n          this.currentDecodingInstruction.data.algorithm = readUnsignedInt(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.ContentCompSettings:\n        {\n          if (this.currentDecodingInstruction?.data?.type !== \"decompress\")\n            break;\n          this.currentDecodingInstruction.data.settings = readBytes(slice, size4);\n        }\n        ;\n        break;\n      case EBMLId.ContentEncryption:\n        {\n          if (!this.currentDecodingInstruction)\n            break;\n          this.currentDecodingInstruction.data = {\n            type: \"decrypt\"\n          };\n        }\n        ;\n        break;\n    }\n    slice.filePos = dataStartPos + size4;\n    return true;\n  }\n  decodeBlockData(track, rawData) {\n    assert(track.decodingInstructions.length > 0);\n    let currentData = rawData;\n    for (const instruction of track.decodingInstructions) {\n      assert(instruction.data);\n      switch (instruction.data.type) {\n        case \"decompress\":\n          {\n            switch (instruction.data.algorithm) {\n              case ContentCompAlgo.HeaderStripping:\n                {\n                  if (instruction.data.settings && instruction.data.settings.length > 0) {\n                    const prefix = instruction.data.settings;\n                    const newData = new Uint8Array(prefix.length + currentData.length);\n                    newData.set(prefix, 0);\n                    newData.set(currentData, prefix.length);\n                    currentData = newData;\n                  }\n                }\n                ;\n                break;\n              default:\n                {}\n                ;\n            }\n          }\n          ;\n          break;\n        default:\n          {}\n          ;\n      }\n    }\n    return currentData;\n  }\n  processTagValue(name, value) {\n    if (!this.currentSegment?.metadataTags)\n      return;\n    const metadataTags = this.currentSegment.metadataTags;\n    metadataTags.raw ??= {};\n    metadataTags.raw[name] ??= value;\n    if (typeof value === \"string\") {\n      switch (name.toLowerCase()) {\n        case \"title\":\n          {\n            metadataTags.title ??= value;\n          }\n          ;\n          break;\n        case \"description\":\n          {\n            metadataTags.description ??= value;\n          }\n          ;\n          break;\n        case \"artist\":\n          {\n            metadataTags.artist ??= value;\n          }\n          ;\n          break;\n        case \"album\":\n          {\n            metadataTags.album ??= value;\n          }\n          ;\n          break;\n        case \"album_artist\":\n          {\n            metadataTags.albumArtist ??= value;\n          }\n          ;\n          break;\n        case \"genre\":\n          {\n            metadataTags.genre ??= value;\n          }\n          ;\n          break;\n        case \"comment\":\n          {\n            metadataTags.comment ??= value;\n          }\n          ;\n          break;\n        case \"lyrics\":\n          {\n            metadataTags.lyrics ??= value;\n          }\n          ;\n          break;\n        case \"date\":\n          {\n            const date = new Date(value);\n            if (!Number.isNaN(date.getTime())) {\n              metadataTags.date ??= date;\n            }\n          }\n          ;\n          break;\n        case \"track_number\":\n        case \"part_number\":\n          {\n            const parts = value.split(\"/\");\n            const trackNum = Number.parseInt(parts[0], 10);\n            const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);\n            if (Number.isInteger(trackNum) && trackNum > 0) {\n              metadataTags.trackNumber ??= trackNum;\n            }\n            if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {\n              metadataTags.tracksTotal ??= tracksTotal;\n            }\n          }\n          ;\n          break;\n        case \"disc_number\":\n        case \"disc\":\n          {\n            const discParts = value.split(\"/\");\n            const discNum = Number.parseInt(discParts[0], 10);\n            const discsTotal = discParts[1] && Number.parseInt(discParts[1], 10);\n            if (Number.isInteger(discNum) && discNum > 0) {\n              metadataTags.discNumber ??= discNum;\n            }\n            if (discsTotal && Number.isInteger(discsTotal) && discsTotal > 0) {\n              metadataTags.discsTotal ??= discsTotal;\n            }\n          }\n          ;\n          break;\n      }\n    }\n  }\n}\n\nclass MatroskaTrackBacking {\n  constructor(internalTrack) {\n    this.internalTrack = internalTrack;\n    this.packetToClusterLocation = new WeakMap;\n  }\n  getId() {\n    return this.internalTrack.id;\n  }\n  getCodec() {\n    throw new Error(\"Not implemented on base class.\");\n  }\n  getInternalCodecId() {\n    return this.internalTrack.codecId;\n  }\n  async computeDuration() {\n    const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n    return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n  }\n  getName() {\n    return this.internalTrack.name;\n  }\n  getLanguageCode() {\n    return this.internalTrack.languageCode;\n  }\n  async getFirstTimestamp() {\n    const firstPacket = await this.getFirstPacket({ metadataOnly: true });\n    return firstPacket?.timestamp ?? 0;\n  }\n  getTimeResolution() {\n    return this.internalTrack.segment.timestampFactor;\n  }\n  getDisposition() {\n    return this.internalTrack.disposition;\n  }\n  async getFirstPacket(options) {\n    return this.performClusterLookup(null, (cluster) => {\n      const trackData = cluster.trackData.get(this.internalTrack.id);\n      if (trackData) {\n        return {\n          blockIndex: 0,\n          correctBlockFound: true\n        };\n      }\n      return {\n        blockIndex: -1,\n        correctBlockFound: false\n      };\n    }, -Infinity, Infinity, options);\n  }\n  intoTimescale(timestamp) {\n    return roundIfAlmostInteger(timestamp * this.internalTrack.segment.timestampFactor);\n  }\n  async getPacket(timestamp, options) {\n    const timestampInTimescale = this.intoTimescale(timestamp);\n    return this.performClusterLookup(null, (cluster) => {\n      const trackData = cluster.trackData.get(this.internalTrack.id);\n      if (!trackData) {\n        return { blockIndex: -1, correctBlockFound: false };\n      }\n      const index = binarySearchLessOrEqual(trackData.presentationTimestamps, timestampInTimescale, (x) => x.timestamp);\n      const blockIndex = index !== -1 ? trackData.presentationTimestamps[index].blockIndex : -1;\n      const correctBlockFound = index !== -1 && timestampInTimescale < trackData.endTimestamp;\n      return { blockIndex, correctBlockFound };\n    }, timestampInTimescale, timestampInTimescale, options);\n  }\n  async getNextPacket(packet, options) {\n    const locationInCluster = this.packetToClusterLocation.get(packet);\n    if (locationInCluster === undefined) {\n      throw new Error(\"Packet was not created from this track.\");\n    }\n    return this.performClusterLookup(locationInCluster.cluster, (cluster) => {\n      if (cluster === locationInCluster.cluster) {\n        const trackData = cluster.trackData.get(this.internalTrack.id);\n        if (locationInCluster.blockIndex + 1 < trackData.blocks.length) {\n          return {\n            blockIndex: locationInCluster.blockIndex + 1,\n            correctBlockFound: true\n          };\n        }\n      } else {\n        const trackData = cluster.trackData.get(this.internalTrack.id);\n        if (trackData) {\n          return {\n            blockIndex: 0,\n            correctBlockFound: true\n          };\n        }\n      }\n      return {\n        blockIndex: -1,\n        correctBlockFound: false\n      };\n    }, -Infinity, Infinity, options);\n  }\n  async getKeyPacket(timestamp, options) {\n    const timestampInTimescale = this.intoTimescale(timestamp);\n    return this.performClusterLookup(null, (cluster) => {\n      const trackData = cluster.trackData.get(this.internalTrack.id);\n      if (!trackData) {\n        return { blockIndex: -1, correctBlockFound: false };\n      }\n      const index = findLastIndex(trackData.presentationTimestamps, (x) => {\n        const block = trackData.blocks[x.blockIndex];\n        return block.isKeyFrame && x.timestamp <= timestampInTimescale;\n      });\n      const blockIndex = index !== -1 ? trackData.presentationTimestamps[index].blockIndex : -1;\n      const correctBlockFound = index !== -1 && timestampInTimescale < trackData.endTimestamp;\n      return { blockIndex, correctBlockFound };\n    }, timestampInTimescale, timestampInTimescale, options);\n  }\n  async getNextKeyPacket(packet, options) {\n    const locationInCluster = this.packetToClusterLocation.get(packet);\n    if (locationInCluster === undefined) {\n      throw new Error(\"Packet was not created from this track.\");\n    }\n    return this.performClusterLookup(locationInCluster.cluster, (cluster) => {\n      if (cluster === locationInCluster.cluster) {\n        const trackData = cluster.trackData.get(this.internalTrack.id);\n        const nextKeyFrameIndex = trackData.blocks.findIndex((x, i) => x.isKeyFrame && i > locationInCluster.blockIndex);\n        if (nextKeyFrameIndex !== -1) {\n          return {\n            blockIndex: nextKeyFrameIndex,\n            correctBlockFound: true\n          };\n        }\n      } else {\n        const trackData = cluster.trackData.get(this.internalTrack.id);\n        if (trackData && trackData.firstKeyFrameTimestamp !== null) {\n          const keyFrameIndex = trackData.blocks.findIndex((x) => x.isKeyFrame);\n          assert(keyFrameIndex !== -1);\n          return {\n            blockIndex: keyFrameIndex,\n            correctBlockFound: true\n          };\n        }\n      }\n      return {\n        blockIndex: -1,\n        correctBlockFound: false\n      };\n    }, -Infinity, Infinity, options);\n  }\n  async fetchPacketInCluster(cluster, blockIndex, options) {\n    if (blockIndex === -1) {\n      return null;\n    }\n    const trackData = cluster.trackData.get(this.internalTrack.id);\n    const block = trackData.blocks[blockIndex];\n    assert(block);\n    if (!block.decoded) {\n      block.data = this.internalTrack.demuxer.decodeBlockData(this.internalTrack, block.data);\n      block.decoded = true;\n    }\n    const data = options.metadataOnly ? PLACEHOLDER_DATA : block.data;\n    const timestamp = block.timestamp / this.internalTrack.segment.timestampFactor;\n    const duration = block.duration / this.internalTrack.segment.timestampFactor;\n    const sideData = {};\n    if (block.mainAdditional && this.internalTrack.info?.type === \"video\" && this.internalTrack.info.alphaMode) {\n      sideData.alpha = options.metadataOnly ? PLACEHOLDER_DATA : block.mainAdditional;\n      sideData.alphaByteLength = block.mainAdditional.byteLength;\n    }\n    const packet = new EncodedPacket(data, block.isKeyFrame ? \"key\" : \"delta\", timestamp, duration, cluster.dataStartPos + blockIndex, block.data.byteLength, sideData);\n    this.packetToClusterLocation.set(packet, { cluster, blockIndex });\n    return packet;\n  }\n  async performClusterLookup(startCluster, getMatchInCluster, searchTimestamp, latestTimestamp, options) {\n    const { demuxer, segment } = this.internalTrack;\n    let currentCluster = null;\n    let bestCluster = null;\n    let bestBlockIndex = -1;\n    if (startCluster) {\n      const { blockIndex, correctBlockFound } = getMatchInCluster(startCluster);\n      if (correctBlockFound) {\n        return this.fetchPacketInCluster(startCluster, blockIndex, options);\n      }\n      if (blockIndex !== -1) {\n        bestCluster = startCluster;\n        bestBlockIndex = blockIndex;\n      }\n    }\n    const cuePointIndex = binarySearchLessOrEqual(this.internalTrack.cuePoints, searchTimestamp, (x) => x.time);\n    const cuePoint = cuePointIndex !== -1 ? this.internalTrack.cuePoints[cuePointIndex] : null;\n    const positionCacheIndex = binarySearchLessOrEqual(this.internalTrack.clusterPositionCache, searchTimestamp, (x) => x.startTimestamp);\n    const positionCacheEntry = positionCacheIndex !== -1 ? this.internalTrack.clusterPositionCache[positionCacheIndex] : null;\n    const lookupEntryPosition = Math.max(cuePoint?.clusterPosition ?? 0, positionCacheEntry?.elementStartPos ?? 0) || null;\n    let currentPos;\n    if (!startCluster) {\n      currentPos = lookupEntryPosition ?? segment.clusterSeekStartPos;\n    } else {\n      if (lookupEntryPosition === null || startCluster.elementStartPos >= lookupEntryPosition) {\n        currentPos = startCluster.elementEndPos;\n        currentCluster = startCluster;\n      } else {\n        currentPos = lookupEntryPosition;\n      }\n    }\n    while (segment.elementEndPos === null || currentPos <= segment.elementEndPos - MIN_HEADER_SIZE) {\n      if (currentCluster) {\n        const trackData = currentCluster.trackData.get(this.internalTrack.id);\n        if (trackData && trackData.startTimestamp > latestTimestamp) {\n          break;\n        }\n      }\n      let slice = demuxer.reader.requestSliceRange(currentPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n      if (slice instanceof Promise)\n        slice = await slice;\n      if (!slice)\n        break;\n      const elementStartPos = currentPos;\n      const elementHeader = readElementHeader(slice);\n      if (!elementHeader || !LEVEL_1_EBML_IDS.includes(elementHeader.id) && elementHeader.id !== EBMLId.Void) {\n        const nextPos = await resync(demuxer.reader, elementStartPos, LEVEL_1_EBML_IDS, Math.min(segment.elementEndPos ?? Infinity, elementStartPos + MAX_RESYNC_LENGTH));\n        if (nextPos) {\n          currentPos = nextPos;\n          continue;\n        } else {\n          break;\n        }\n      }\n      const id = elementHeader.id;\n      let size4 = elementHeader.size;\n      const dataStartPos = slice.filePos;\n      if (id === EBMLId.Cluster) {\n        currentCluster = await demuxer.readCluster(elementStartPos, segment);\n        size4 = currentCluster.elementEndPos - dataStartPos;\n        const { blockIndex, correctBlockFound } = getMatchInCluster(currentCluster);\n        if (correctBlockFound) {\n          return this.fetchPacketInCluster(currentCluster, blockIndex, options);\n        }\n        if (blockIndex !== -1) {\n          bestCluster = currentCluster;\n          bestBlockIndex = blockIndex;\n        }\n      }\n      if (size4 === undefined) {\n        assert(id !== EBMLId.Cluster);\n        const nextElementPos = await searchForNextElementId(demuxer.reader, dataStartPos, LEVEL_0_AND_1_EBML_IDS, segment.elementEndPos);\n        size4 = nextElementPos.pos - dataStartPos;\n      }\n      const endPos = dataStartPos + size4;\n      if (segment.elementEndPos === null) {\n        let slice2 = demuxer.reader.requestSliceRange(endPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n        if (slice2 instanceof Promise)\n          slice2 = await slice2;\n        if (!slice2)\n          break;\n        const elementId = readElementId(slice2);\n        if (elementId === EBMLId.Segment) {\n          segment.elementEndPos = endPos;\n          break;\n        }\n      }\n      currentPos = endPos;\n    }\n    if (cuePoint && (!bestCluster || bestCluster.elementStartPos < cuePoint.clusterPosition)) {\n      const previousCuePoint = this.internalTrack.cuePoints[cuePointIndex - 1];\n      assert(!previousCuePoint || previousCuePoint.time < cuePoint.time);\n      const newSearchTimestamp = previousCuePoint?.time ?? -Infinity;\n      return this.performClusterLookup(null, getMatchInCluster, newSearchTimestamp, latestTimestamp, options);\n    }\n    if (bestCluster) {\n      return this.fetchPacketInCluster(bestCluster, bestBlockIndex, options);\n    }\n    return null;\n  }\n}\n\nclass MatroskaVideoTrackBacking extends MatroskaTrackBacking {\n  constructor(internalTrack) {\n    super(internalTrack);\n    this.decoderConfigPromise = null;\n    this.internalTrack = internalTrack;\n  }\n  getCodec() {\n    return this.internalTrack.info.codec;\n  }\n  getCodedWidth() {\n    return this.internalTrack.info.width;\n  }\n  getCodedHeight() {\n    return this.internalTrack.info.height;\n  }\n  getRotation() {\n    return this.internalTrack.info.rotation;\n  }\n  async getColorSpace() {\n    return {\n      primaries: this.internalTrack.info.colorSpace?.primaries,\n      transfer: this.internalTrack.info.colorSpace?.transfer,\n      matrix: this.internalTrack.info.colorSpace?.matrix,\n      fullRange: this.internalTrack.info.colorSpace?.fullRange\n    };\n  }\n  async canBeTransparent() {\n    return this.internalTrack.info.alphaMode;\n  }\n  async getDecoderConfig() {\n    if (!this.internalTrack.info.codec) {\n      return null;\n    }\n    return this.decoderConfigPromise ??= (async () => {\n      let firstPacket = null;\n      const needsPacketForAdditionalInfo = this.internalTrack.info.codec === \"vp9\" || this.internalTrack.info.codec === \"av1\" || this.internalTrack.info.codec === \"avc\" && !this.internalTrack.info.codecDescription || this.internalTrack.info.codec === \"hevc\" && !this.internalTrack.info.codecDescription;\n      if (needsPacketForAdditionalInfo) {\n        firstPacket = await this.getFirstPacket({});\n      }\n      return {\n        codec: extractVideoCodecString({\n          width: this.internalTrack.info.width,\n          height: this.internalTrack.info.height,\n          codec: this.internalTrack.info.codec,\n          codecDescription: this.internalTrack.info.codecDescription,\n          colorSpace: this.internalTrack.info.colorSpace,\n          avcType: 1,\n          avcCodecInfo: this.internalTrack.info.codec === \"avc\" && firstPacket ? extractAvcDecoderConfigurationRecord(firstPacket.data) : null,\n          hevcCodecInfo: this.internalTrack.info.codec === \"hevc\" && firstPacket ? extractHevcDecoderConfigurationRecord(firstPacket.data) : null,\n          vp9CodecInfo: this.internalTrack.info.codec === \"vp9\" && firstPacket ? extractVp9CodecInfoFromPacket(firstPacket.data) : null,\n          av1CodecInfo: this.internalTrack.info.codec === \"av1\" && firstPacket ? extractAv1CodecInfoFromPacket(firstPacket.data) : null\n        }),\n        codedWidth: this.internalTrack.info.width,\n        codedHeight: this.internalTrack.info.height,\n        description: this.internalTrack.info.codecDescription ?? undefined,\n        colorSpace: this.internalTrack.info.colorSpace ?? undefined\n      };\n    })();\n  }\n}\n\nclass MatroskaAudioTrackBacking extends MatroskaTrackBacking {\n  constructor(internalTrack) {\n    super(internalTrack);\n    this.decoderConfig = null;\n    this.internalTrack = internalTrack;\n  }\n  getCodec() {\n    return this.internalTrack.info.codec;\n  }\n  getNumberOfChannels() {\n    return this.internalTrack.info.numberOfChannels;\n  }\n  getSampleRate() {\n    return this.internalTrack.info.sampleRate;\n  }\n  async getDecoderConfig() {\n    if (!this.internalTrack.info.codec) {\n      return null;\n    }\n    return this.decoderConfig ??= {\n      codec: extractAudioCodecString({\n        codec: this.internalTrack.info.codec,\n        codecDescription: this.internalTrack.info.codecDescription,\n        aacCodecInfo: this.internalTrack.info.aacCodecInfo\n      }),\n      numberOfChannels: this.internalTrack.info.numberOfChannels,\n      sampleRate: this.internalTrack.info.sampleRate,\n      description: this.internalTrack.info.codecDescription ?? undefined\n    };\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/shared/mp3-misc.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar FRAME_HEADER_SIZE = 4;\nvar SAMPLING_RATES = [44100, 48000, 32000];\nvar KILOBIT_RATES = [\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  32,\n  40,\n  48,\n  56,\n  64,\n  80,\n  96,\n  112,\n  128,\n  160,\n  192,\n  224,\n  256,\n  320,\n  -1,\n  -1,\n  32,\n  48,\n  56,\n  64,\n  80,\n  96,\n  112,\n  128,\n  160,\n  192,\n  224,\n  256,\n  320,\n  384,\n  -1,\n  -1,\n  32,\n  64,\n  96,\n  128,\n  160,\n  192,\n  224,\n  256,\n  288,\n  320,\n  352,\n  384,\n  416,\n  448,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  8,\n  16,\n  24,\n  32,\n  40,\n  48,\n  56,\n  64,\n  80,\n  96,\n  112,\n  128,\n  144,\n  160,\n  -1,\n  -1,\n  8,\n  16,\n  24,\n  32,\n  40,\n  48,\n  56,\n  64,\n  80,\n  96,\n  112,\n  128,\n  144,\n  160,\n  -1,\n  -1,\n  32,\n  48,\n  56,\n  64,\n  80,\n  96,\n  112,\n  128,\n  144,\n  160,\n  176,\n  192,\n  224,\n  256,\n  -1\n];\nvar XING = 1483304551;\nvar INFO = 1231971951;\nvar computeMp3FrameSize = (lowSamplingFrequency, layer, bitrate, sampleRate, padding3) => {\n  if (layer === 0) {\n    return 0;\n  } else if (layer === 1) {\n    return Math.floor(144 * bitrate / (sampleRate << lowSamplingFrequency)) + padding3;\n  } else if (layer === 2) {\n    return Math.floor(144 * bitrate / sampleRate) + padding3;\n  } else {\n    return (Math.floor(12 * bitrate / sampleRate) + padding3) * 4;\n  }\n};\nvar getXingOffset = (mpegVersionId, channel) => {\n  return mpegVersionId === 3 ? channel === 3 ? 21 : 36 : channel === 3 ? 13 : 21;\n};\nvar readMp3FrameHeader = (word, remainingBytes) => {\n  const firstByte = word >>> 24;\n  const secondByte = word >>> 16 & 255;\n  const thirdByte = word >>> 8 & 255;\n  const fourthByte = word & 255;\n  if (firstByte !== 255 && secondByte !== 255 && thirdByte !== 255 && fourthByte !== 255) {\n    return {\n      header: null,\n      bytesAdvanced: 4\n    };\n  }\n  if (firstByte !== 255) {\n    return { header: null, bytesAdvanced: 1 };\n  }\n  if ((secondByte & 224) !== 224) {\n    return { header: null, bytesAdvanced: 1 };\n  }\n  let lowSamplingFrequency = 0;\n  let mpeg25 = 0;\n  if (secondByte & 1 << 4) {\n    lowSamplingFrequency = secondByte & 1 << 3 ? 0 : 1;\n  } else {\n    lowSamplingFrequency = 1;\n    mpeg25 = 1;\n  }\n  const mpegVersionId = secondByte >> 3 & 3;\n  const layer = secondByte >> 1 & 3;\n  const bitrateIndex = thirdByte >> 4 & 15;\n  const frequencyIndex = (thirdByte >> 2 & 3) % 3;\n  const padding3 = thirdByte >> 1 & 1;\n  const channel = fourthByte >> 6 & 3;\n  const modeExtension = fourthByte >> 4 & 3;\n  const copyright = fourthByte >> 3 & 1;\n  const original = fourthByte >> 2 & 1;\n  const emphasis = fourthByte & 3;\n  const kilobitRate = KILOBIT_RATES[lowSamplingFrequency * 16 * 4 + layer * 16 + bitrateIndex];\n  if (kilobitRate === -1) {\n    return { header: null, bytesAdvanced: 1 };\n  }\n  const bitrate = kilobitRate * 1000;\n  const sampleRate = SAMPLING_RATES[frequencyIndex] >> lowSamplingFrequency + mpeg25;\n  const frameLength = computeMp3FrameSize(lowSamplingFrequency, layer, bitrate, sampleRate, padding3);\n  if (remainingBytes !== null && remainingBytes < frameLength) {\n    return { header: null, bytesAdvanced: 1 };\n  }\n  let audioSamplesInFrame;\n  if (mpegVersionId === 3) {\n    audioSamplesInFrame = layer === 3 ? 384 : 1152;\n  } else {\n    if (layer === 3) {\n      audioSamplesInFrame = 384;\n    } else if (layer === 2) {\n      audioSamplesInFrame = 1152;\n    } else {\n      audioSamplesInFrame = 576;\n    }\n  }\n  return {\n    header: {\n      totalSize: frameLength,\n      mpegVersionId,\n      layer,\n      bitrate,\n      frequencyIndex,\n      sampleRate,\n      channel,\n      modeExtension,\n      copyright,\n      original,\n      emphasis,\n      audioSamplesInFrame\n    },\n    bytesAdvanced: 1\n  };\n};\nvar decodeSynchsafe = (synchsafed) => {\n  let mask = 2130706432;\n  let unsynchsafed = 0;\n  while (mask !== 0) {\n    unsynchsafed >>= 1;\n    unsynchsafed |= synchsafed & mask;\n    mask >>= 8;\n  }\n  return unsynchsafed;\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/id3.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar Id3V2HeaderFlags;\n(function(Id3V2HeaderFlags2) {\n  Id3V2HeaderFlags2[Id3V2HeaderFlags2[\"Unsynchronisation\"] = 128] = \"Unsynchronisation\";\n  Id3V2HeaderFlags2[Id3V2HeaderFlags2[\"ExtendedHeader\"] = 64] = \"ExtendedHeader\";\n  Id3V2HeaderFlags2[Id3V2HeaderFlags2[\"ExperimentalIndicator\"] = 32] = \"ExperimentalIndicator\";\n  Id3V2HeaderFlags2[Id3V2HeaderFlags2[\"Footer\"] = 16] = \"Footer\";\n})(Id3V2HeaderFlags || (Id3V2HeaderFlags = {}));\nvar Id3V2TextEncoding;\n(function(Id3V2TextEncoding2) {\n  Id3V2TextEncoding2[Id3V2TextEncoding2[\"ISO_8859_1\"] = 0] = \"ISO_8859_1\";\n  Id3V2TextEncoding2[Id3V2TextEncoding2[\"UTF_16_WITH_BOM\"] = 1] = \"UTF_16_WITH_BOM\";\n  Id3V2TextEncoding2[Id3V2TextEncoding2[\"UTF_16_BE_NO_BOM\"] = 2] = \"UTF_16_BE_NO_BOM\";\n  Id3V2TextEncoding2[Id3V2TextEncoding2[\"UTF_8\"] = 3] = \"UTF_8\";\n})(Id3V2TextEncoding || (Id3V2TextEncoding = {}));\nvar ID3_V1_TAG_SIZE = 128;\nvar ID3_V2_HEADER_SIZE = 10;\nvar ID3_V1_GENRES = [\n  \"Blues\",\n  \"Classic rock\",\n  \"Country\",\n  \"Dance\",\n  \"Disco\",\n  \"Funk\",\n  \"Grunge\",\n  \"Hip-hop\",\n  \"Jazz\",\n  \"Metal\",\n  \"New age\",\n  \"Oldies\",\n  \"Other\",\n  \"Pop\",\n  \"Rhythm and blues\",\n  \"Rap\",\n  \"Reggae\",\n  \"Rock\",\n  \"Techno\",\n  \"Industrial\",\n  \"Alternative\",\n  \"Ska\",\n  \"Death metal\",\n  \"Pranks\",\n  \"Soundtrack\",\n  \"Euro-techno\",\n  \"Ambient\",\n  \"Trip-hop\",\n  \"Vocal\",\n  \"Jazz & funk\",\n  \"Fusion\",\n  \"Trance\",\n  \"Classical\",\n  \"Instrumental\",\n  \"Acid\",\n  \"House\",\n  \"Game\",\n  \"Sound clip\",\n  \"Gospel\",\n  \"Noise\",\n  \"Alternative rock\",\n  \"Bass\",\n  \"Soul\",\n  \"Punk\",\n  \"Space\",\n  \"Meditative\",\n  \"Instrumental pop\",\n  \"Instrumental rock\",\n  \"Ethnic\",\n  \"Gothic\",\n  \"Darkwave\",\n  \"Techno-industrial\",\n  \"Electronic\",\n  \"Pop-folk\",\n  \"Eurodance\",\n  \"Dream\",\n  \"Southern rock\",\n  \"Comedy\",\n  \"Cult\",\n  \"Gangsta\",\n  \"Top 40\",\n  \"Christian rap\",\n  \"Pop/funk\",\n  \"Jungle music\",\n  \"Native US\",\n  \"Cabaret\",\n  \"New wave\",\n  \"Psychedelic\",\n  \"Rave\",\n  \"Showtunes\",\n  \"Trailer\",\n  \"Lo-fi\",\n  \"Tribal\",\n  \"Acid punk\",\n  \"Acid jazz\",\n  \"Polka\",\n  \"Retro\",\n  \"Musical\",\n  \"Rock 'n' roll\",\n  \"Hard rock\",\n  \"Folk\",\n  \"Folk rock\",\n  \"National folk\",\n  \"Swing\",\n  \"Fast fusion\",\n  \"Bebop\",\n  \"Latin\",\n  \"Revival\",\n  \"Celtic\",\n  \"Bluegrass\",\n  \"Avantgarde\",\n  \"Gothic rock\",\n  \"Progressive rock\",\n  \"Psychedelic rock\",\n  \"Symphonic rock\",\n  \"Slow rock\",\n  \"Big band\",\n  \"Chorus\",\n  \"Easy listening\",\n  \"Acoustic\",\n  \"Humour\",\n  \"Speech\",\n  \"Chanson\",\n  \"Opera\",\n  \"Chamber music\",\n  \"Sonata\",\n  \"Symphony\",\n  \"Booty bass\",\n  \"Primus\",\n  \"Porn groove\",\n  \"Satire\",\n  \"Slow jam\",\n  \"Club\",\n  \"Tango\",\n  \"Samba\",\n  \"Folklore\",\n  \"Ballad\",\n  \"Power ballad\",\n  \"Rhythmic Soul\",\n  \"Freestyle\",\n  \"Duet\",\n  \"Punk rock\",\n  \"Drum solo\",\n  \"A cappella\",\n  \"Euro-house\",\n  \"Dance hall\",\n  \"Goa music\",\n  \"Drum & bass\",\n  \"Club-house\",\n  \"Hardcore techno\",\n  \"Terror\",\n  \"Indie\",\n  \"Britpop\",\n  \"Negerpunk\",\n  \"Polsk punk\",\n  \"Beat\",\n  \"Christian gangsta rap\",\n  \"Heavy metal\",\n  \"Black metal\",\n  \"Crossover\",\n  \"Contemporary Christian\",\n  \"Christian rock\",\n  \"Merengue\",\n  \"Salsa\",\n  \"Thrash metal\",\n  \"Anime\",\n  \"Jpop\",\n  \"Synthpop\",\n  \"Christmas\",\n  \"Art rock\",\n  \"Baroque\",\n  \"Bhangra\",\n  \"Big beat\",\n  \"Breakbeat\",\n  \"Chillout\",\n  \"Downtempo\",\n  \"Dub\",\n  \"EBM\",\n  \"Eclectic\",\n  \"Electro\",\n  \"Electroclash\",\n  \"Emo\",\n  \"Experimental\",\n  \"Garage\",\n  \"Global\",\n  \"IDM\",\n  \"Illbient\",\n  \"Industro-Goth\",\n  \"Jam Band\",\n  \"Krautrock\",\n  \"Leftfield\",\n  \"Lounge\",\n  \"Math rock\",\n  \"New romantic\",\n  \"Nu-breakz\",\n  \"Post-punk\",\n  \"Post-rock\",\n  \"Psytrance\",\n  \"Shoegaze\",\n  \"Space rock\",\n  \"Trop rock\",\n  \"World music\",\n  \"Neoclassical\",\n  \"Audiobook\",\n  \"Audio theatre\",\n  \"Neue Deutsche Welle\",\n  \"Podcast\",\n  \"Indie rock\",\n  \"G-Funk\",\n  \"Dubstep\",\n  \"Garage rock\",\n  \"Psybient\"\n];\nvar parseId3V1Tag = (slice, tags) => {\n  const startPos = slice.filePos;\n  tags.raw ??= {};\n  tags.raw[\"TAG\"] ??= readBytes(slice, ID3_V1_TAG_SIZE - 3);\n  slice.filePos = startPos;\n  const title4 = readId3V1String(slice, 30);\n  if (title4)\n    tags.title ??= title4;\n  const artist = readId3V1String(slice, 30);\n  if (artist)\n    tags.artist ??= artist;\n  const album = readId3V1String(slice, 30);\n  if (album)\n    tags.album ??= album;\n  const yearText = readId3V1String(slice, 4);\n  const year = Number.parseInt(yearText, 10);\n  if (Number.isInteger(year) && year > 0) {\n    tags.date ??= new Date(year, 0, 1);\n  }\n  const commentBytes = readBytes(slice, 30);\n  let comment;\n  if (commentBytes[28] === 0 && commentBytes[29] !== 0) {\n    const trackNum = commentBytes[29];\n    if (trackNum > 0) {\n      tags.trackNumber ??= trackNum;\n    }\n    slice.skip(-30);\n    comment = readId3V1String(slice, 28);\n    slice.skip(2);\n  } else {\n    slice.skip(-30);\n    comment = readId3V1String(slice, 30);\n  }\n  if (comment)\n    tags.comment ??= comment;\n  const genreIndex = readU8(slice);\n  if (genreIndex < ID3_V1_GENRES.length) {\n    tags.genre ??= ID3_V1_GENRES[genreIndex];\n  }\n};\nvar readId3V1String = (slice, length) => {\n  const bytes = readBytes(slice, length);\n  const endIndex = coalesceIndex(bytes.indexOf(0), bytes.length);\n  const relevantBytes = bytes.subarray(0, endIndex);\n  let str = \"\";\n  for (let i = 0;i < relevantBytes.length; i++) {\n    str += String.fromCharCode(relevantBytes[i]);\n  }\n  return str.trimEnd();\n};\nvar readId3V2Header = (slice) => {\n  const startPos = slice.filePos;\n  const tag = readAscii(slice, 3);\n  const majorVersion = readU8(slice);\n  const revision = readU8(slice);\n  const flags = readU8(slice);\n  const sizeRaw = readU32Be(slice);\n  if (tag !== \"ID3\" || majorVersion === 255 || revision === 255 || (sizeRaw & 2155905152) !== 0) {\n    slice.filePos = startPos;\n    return null;\n  }\n  const size4 = decodeSynchsafe(sizeRaw);\n  return { majorVersion, revision, flags, size: size4 };\n};\nvar parseId3V2Tag = (slice, header2, tags) => {\n  if (![2, 3, 4].includes(header2.majorVersion)) {\n    console.warn(`Unsupported ID3v2 major version: ${header2.majorVersion}`);\n    return;\n  }\n  const bytes = readBytes(slice, header2.size);\n  const reader = new Id3V2Reader(header2, bytes);\n  if (header2.flags & Id3V2HeaderFlags.Footer) {\n    reader.removeFooter();\n  }\n  if (header2.flags & Id3V2HeaderFlags.Unsynchronisation && header2.majorVersion === 3) {\n    reader.ununsynchronizeAll();\n  }\n  if (header2.flags & Id3V2HeaderFlags.ExtendedHeader) {\n    const extendedHeaderSize = reader.readU32();\n    if (header2.majorVersion === 3) {\n      reader.pos += extendedHeaderSize;\n    } else {\n      reader.pos += extendedHeaderSize - 4;\n    }\n  }\n  while (reader.pos <= reader.bytes.length - reader.frameHeaderSize()) {\n    const frame2 = reader.readId3V2Frame();\n    if (!frame2) {\n      break;\n    }\n    const frameStartPos = reader.pos;\n    const frameEndPos = reader.pos + frame2.size;\n    let frameEncrypted = false;\n    let frameCompressed = false;\n    let frameUnsynchronized = false;\n    if (header2.majorVersion === 3) {\n      frameEncrypted = !!(frame2.flags & 1 << 6);\n      frameCompressed = !!(frame2.flags & 1 << 7);\n    } else if (header2.majorVersion === 4) {\n      frameEncrypted = !!(frame2.flags & 1 << 2);\n      frameCompressed = !!(frame2.flags & 1 << 3);\n      frameUnsynchronized = !!(frame2.flags & 1 << 1) || !!(header2.flags & Id3V2HeaderFlags.Unsynchronisation);\n    }\n    if (frameEncrypted) {\n      console.warn(`Skipping encrypted ID3v2 frame ${frame2.id}`);\n      reader.pos = frameEndPos;\n      continue;\n    }\n    if (frameCompressed) {\n      console.warn(`Skipping compressed ID3v2 frame ${frame2.id}`);\n      reader.pos = frameEndPos;\n      continue;\n    }\n    if (frameUnsynchronized) {\n      reader.ununsynchronizeRegion(reader.pos, frameEndPos);\n    }\n    tags.raw ??= {};\n    if (frame2.id[0] === \"T\") {\n      tags.raw[frame2.id] ??= reader.readId3V2EncodingAndText(frameEndPos);\n    } else {\n      tags.raw[frame2.id] ??= reader.readBytes(frame2.size);\n    }\n    reader.pos = frameStartPos;\n    switch (frame2.id) {\n      case \"TIT2\":\n      case \"TT2\":\n        {\n          tags.title ??= reader.readId3V2EncodingAndText(frameEndPos);\n        }\n        ;\n        break;\n      case \"TIT3\":\n      case \"TT3\":\n        {\n          tags.description ??= reader.readId3V2EncodingAndText(frameEndPos);\n        }\n        ;\n        break;\n      case \"TPE1\":\n      case \"TP1\":\n        {\n          tags.artist ??= reader.readId3V2EncodingAndText(frameEndPos);\n        }\n        ;\n        break;\n      case \"TALB\":\n      case \"TAL\":\n        {\n          tags.album ??= reader.readId3V2EncodingAndText(frameEndPos);\n        }\n        ;\n        break;\n      case \"TPE2\":\n      case \"TP2\":\n        {\n          tags.albumArtist ??= reader.readId3V2EncodingAndText(frameEndPos);\n        }\n        ;\n        break;\n      case \"TRCK\":\n      case \"TRK\":\n        {\n          const trackText = reader.readId3V2EncodingAndText(frameEndPos);\n          const parts = trackText.split(\"/\");\n          const trackNum = Number.parseInt(parts[0], 10);\n          const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);\n          if (Number.isInteger(trackNum) && trackNum > 0) {\n            tags.trackNumber ??= trackNum;\n          }\n          if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {\n            tags.tracksTotal ??= tracksTotal;\n          }\n        }\n        ;\n        break;\n      case \"TPOS\":\n      case \"TPA\":\n        {\n          const discText = reader.readId3V2EncodingAndText(frameEndPos);\n          const parts = discText.split(\"/\");\n          const discNum = Number.parseInt(parts[0], 10);\n          const discsTotal = parts[1] && Number.parseInt(parts[1], 10);\n          if (Number.isInteger(discNum) && discNum > 0) {\n            tags.discNumber ??= discNum;\n          }\n          if (discsTotal && Number.isInteger(discsTotal) && discsTotal > 0) {\n            tags.discsTotal ??= discsTotal;\n          }\n        }\n        ;\n        break;\n      case \"TCON\":\n      case \"TCO\":\n        {\n          const genreText = reader.readId3V2EncodingAndText(frameEndPos);\n          let match = /^\\((\\d+)\\)/.exec(genreText);\n          if (match) {\n            const genreNumber = Number.parseInt(match[1]);\n            if (ID3_V1_GENRES[genreNumber] !== undefined) {\n              tags.genre ??= ID3_V1_GENRES[genreNumber];\n              break;\n            }\n          }\n          match = /^\\d+$/.exec(genreText);\n          if (match) {\n            const genreNumber = Number.parseInt(match[0]);\n            if (ID3_V1_GENRES[genreNumber] !== undefined) {\n              tags.genre ??= ID3_V1_GENRES[genreNumber];\n              break;\n            }\n          }\n          tags.genre ??= genreText;\n        }\n        ;\n        break;\n      case \"TDRC\":\n      case \"TDAT\":\n        {\n          const dateText = reader.readId3V2EncodingAndText(frameEndPos);\n          const date = new Date(dateText);\n          if (!Number.isNaN(date.getTime())) {\n            tags.date ??= date;\n          }\n        }\n        ;\n        break;\n      case \"TYER\":\n      case \"TYE\":\n        {\n          const yearText = reader.readId3V2EncodingAndText(frameEndPos);\n          const year = Number.parseInt(yearText, 10);\n          if (Number.isInteger(year)) {\n            tags.date ??= new Date(year, 0, 1);\n          }\n        }\n        ;\n        break;\n      case \"USLT\":\n      case \"ULT\":\n        {\n          const encoding = reader.readU8();\n          reader.pos += 3;\n          reader.readId3V2Text(encoding, frameEndPos);\n          tags.lyrics ??= reader.readId3V2Text(encoding, frameEndPos);\n        }\n        ;\n        break;\n      case \"COMM\":\n      case \"COM\":\n        {\n          const encoding = reader.readU8();\n          reader.pos += 3;\n          reader.readId3V2Text(encoding, frameEndPos);\n          tags.comment ??= reader.readId3V2Text(encoding, frameEndPos);\n        }\n        ;\n        break;\n      case \"APIC\":\n      case \"PIC\":\n        {\n          const encoding = reader.readId3V2TextEncoding();\n          let mimeType;\n          if (header2.majorVersion === 2) {\n            const imageFormat = reader.readAscii(3);\n            mimeType = imageFormat === \"PNG\" ? \"image/png\" : imageFormat === \"JPG\" ? \"image/jpeg\" : \"image/*\";\n          } else {\n            mimeType = reader.readId3V2Text(encoding, frameEndPos);\n          }\n          const pictureType = reader.readU8();\n          const description = reader.readId3V2Text(encoding, frameEndPos).trimEnd();\n          const imageDataSize = frameEndPos - reader.pos;\n          if (imageDataSize >= 0) {\n            const imageData = reader.readBytes(imageDataSize);\n            if (!tags.images)\n              tags.images = [];\n            tags.images.push({\n              data: imageData,\n              mimeType,\n              kind: pictureType === 3 ? \"coverFront\" : pictureType === 4 ? \"coverBack\" : \"unknown\",\n              description\n            });\n          }\n        }\n        ;\n        break;\n      default:\n        {\n          reader.pos += frame2.size;\n        }\n        ;\n        break;\n    }\n    reader.pos = frameEndPos;\n  }\n};\n\nclass Id3V2Reader {\n  constructor(header2, bytes) {\n    this.header = header2;\n    this.bytes = bytes;\n    this.pos = 0;\n    this.view = new DataView(bytes.buffer, bytes.byteOffset, bytes.byteLength);\n  }\n  frameHeaderSize() {\n    return this.header.majorVersion === 2 ? 6 : 10;\n  }\n  ununsynchronizeAll() {\n    const newBytes = [];\n    for (let i = 0;i < this.bytes.length; i++) {\n      const value1 = this.bytes[i];\n      newBytes.push(value1);\n      if (value1 === 255 && i !== this.bytes.length - 1) {\n        const value2 = this.bytes[i];\n        if (value2 === 0) {\n          i++;\n        }\n      }\n    }\n    this.bytes = new Uint8Array(newBytes);\n    this.view = new DataView(this.bytes.buffer);\n  }\n  ununsynchronizeRegion(start, end) {\n    const newBytes = [];\n    for (let i = start;i < end; i++) {\n      const value1 = this.bytes[i];\n      newBytes.push(value1);\n      if (value1 === 255 && i !== end - 1) {\n        const value2 = this.bytes[i + 1];\n        if (value2 === 0) {\n          i++;\n        }\n      }\n    }\n    const before = this.bytes.subarray(0, start);\n    const after = this.bytes.subarray(end);\n    this.bytes = new Uint8Array(before.length + newBytes.length + after.length);\n    this.bytes.set(before, 0);\n    this.bytes.set(newBytes, before.length);\n    this.bytes.set(after, before.length + newBytes.length);\n    this.view = new DataView(this.bytes.buffer);\n  }\n  removeFooter() {\n    this.bytes = this.bytes.subarray(0, this.bytes.length - ID3_V2_HEADER_SIZE);\n    this.view = new DataView(this.bytes.buffer);\n  }\n  readBytes(length) {\n    const slice = this.bytes.subarray(this.pos, this.pos + length);\n    this.pos += length;\n    return slice;\n  }\n  readU8() {\n    const value = this.view.getUint8(this.pos);\n    this.pos += 1;\n    return value;\n  }\n  readU16() {\n    const value = this.view.getUint16(this.pos, false);\n    this.pos += 2;\n    return value;\n  }\n  readU24() {\n    const high = this.view.getUint16(this.pos, false);\n    const low = this.view.getUint8(this.pos + 1);\n    this.pos += 3;\n    return high * 256 + low;\n  }\n  readU32() {\n    const value = this.view.getUint32(this.pos, false);\n    this.pos += 4;\n    return value;\n  }\n  readAscii(length) {\n    let str = \"\";\n    for (let i = 0;i < length; i++) {\n      str += String.fromCharCode(this.view.getUint8(this.pos + i));\n    }\n    this.pos += length;\n    return str;\n  }\n  readId3V2Frame() {\n    if (this.header.majorVersion === 2) {\n      const id = this.readAscii(3);\n      if (id === \"\\x00\\x00\\x00\") {\n        return null;\n      }\n      const size4 = this.readU24();\n      return { id, size: size4, flags: 0 };\n    } else {\n      const id = this.readAscii(4);\n      if (id === \"\\x00\\x00\\x00\\x00\") {\n        return null;\n      }\n      const sizeRaw = this.readU32();\n      let size4 = this.header.majorVersion === 4 ? decodeSynchsafe(sizeRaw) : sizeRaw;\n      const flags = this.readU16();\n      const headerEndPos = this.pos;\n      const isSizeValid = (size5) => {\n        const nextPos = this.pos + size5;\n        if (nextPos > this.bytes.length) {\n          return false;\n        }\n        if (nextPos <= this.bytes.length - this.frameHeaderSize()) {\n          this.pos += size5;\n          const nextId = this.readAscii(4);\n          if (nextId !== \"\\x00\\x00\\x00\\x00\" && !/[0-9A-Z]{4}/.test(nextId)) {\n            return false;\n          }\n        }\n        return true;\n      };\n      if (!isSizeValid(size4)) {\n        const otherSize = this.header.majorVersion === 4 ? sizeRaw : decodeSynchsafe(sizeRaw);\n        if (isSizeValid(otherSize)) {\n          size4 = otherSize;\n        }\n      }\n      this.pos = headerEndPos;\n      return { id, size: size4, flags };\n    }\n  }\n  readId3V2TextEncoding() {\n    const number = this.readU8();\n    if (number > 3) {\n      throw new Error(`Unsupported text encoding: ${number}`);\n    }\n    return number;\n  }\n  readId3V2Text(encoding, until) {\n    const startPos = this.pos;\n    const data = this.readBytes(until - this.pos);\n    switch (encoding) {\n      case Id3V2TextEncoding.ISO_8859_1: {\n        let str = \"\";\n        for (let i = 0;i < data.length; i++) {\n          const value = data[i];\n          if (value === 0) {\n            this.pos = startPos + i + 1;\n            break;\n          }\n          str += String.fromCharCode(value);\n        }\n        return str;\n      }\n      case Id3V2TextEncoding.UTF_16_WITH_BOM: {\n        if (data[0] === 255 && data[1] === 254) {\n          const decoder = new TextDecoder(\"utf-16le\");\n          const endIndex = coalesceIndex(data.findIndex((x, i) => x === 0 && data[i + 1] === 0 && i % 2 === 0), data.length);\n          this.pos = startPos + Math.min(endIndex + 2, data.length);\n          return decoder.decode(data.subarray(2, endIndex));\n        } else if (data[0] === 254 && data[1] === 255) {\n          const decoder = new TextDecoder(\"utf-16be\");\n          const endIndex = coalesceIndex(data.findIndex((x, i) => x === 0 && data[i + 1] === 0 && i % 2 === 0), data.length);\n          this.pos = startPos + Math.min(endIndex + 2, data.length);\n          return decoder.decode(data.subarray(2, endIndex));\n        } else {\n          const endIndex = coalesceIndex(data.findIndex((x) => x === 0), data.length);\n          this.pos = startPos + Math.min(endIndex + 1, data.length);\n          return textDecoder.decode(data.subarray(0, endIndex));\n        }\n      }\n      case Id3V2TextEncoding.UTF_16_BE_NO_BOM: {\n        const decoder = new TextDecoder(\"utf-16be\");\n        const endIndex = coalesceIndex(data.findIndex((x, i) => x === 0 && data[i + 1] === 0 && i % 2 === 0), data.length);\n        this.pos = startPos + Math.min(endIndex + 2, data.length);\n        return decoder.decode(data.subarray(0, endIndex));\n      }\n      case Id3V2TextEncoding.UTF_8: {\n        const endIndex = coalesceIndex(data.findIndex((x) => x === 0), data.length);\n        this.pos = startPos + Math.min(endIndex + 1, data.length);\n        return textDecoder.decode(data.subarray(0, endIndex));\n      }\n    }\n  }\n  readId3V2EncodingAndText(until) {\n    if (this.pos >= until) {\n      return \"\";\n    }\n    const encoding = this.readId3V2TextEncoding();\n    return this.readId3V2Text(encoding, until);\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/mp3/mp3-reader.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar readNextMp3FrameHeader = async (reader, startPos, until) => {\n  let currentPos = startPos;\n  while (until === null || currentPos < until) {\n    let slice = reader.requestSlice(currentPos, FRAME_HEADER_SIZE);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      break;\n    const word = readU32Be(slice);\n    const result = readMp3FrameHeader(word, reader.fileSize !== null ? reader.fileSize - currentPos : null);\n    if (result.header) {\n      return { header: result.header, startPos: currentPos };\n    }\n    currentPos += result.bytesAdvanced;\n  }\n  return null;\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/mp3/mp3-demuxer.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\nclass Mp3Demuxer extends Demuxer {\n  constructor(input2) {\n    super(input2);\n    this.metadataPromise = null;\n    this.firstFrameHeader = null;\n    this.loadedSamples = [];\n    this.metadataTags = null;\n    this.tracks = [];\n    this.readingMutex = new AsyncMutex;\n    this.lastSampleLoaded = false;\n    this.lastLoadedPos = 0;\n    this.nextTimestampInSamples = 0;\n    this.reader = input2._reader;\n  }\n  async readMetadata() {\n    return this.metadataPromise ??= (async () => {\n      while (!this.firstFrameHeader && !this.lastSampleLoaded) {\n        await this.advanceReader();\n      }\n      if (!this.firstFrameHeader) {\n        throw new Error(\"No valid MP3 frame found.\");\n      }\n      this.tracks = [new InputAudioTrack(this.input, new Mp3AudioTrackBacking(this))];\n    })();\n  }\n  async advanceReader() {\n    if (this.lastLoadedPos === 0) {\n      while (true) {\n        let slice2 = this.reader.requestSlice(this.lastLoadedPos, ID3_V2_HEADER_SIZE);\n        if (slice2 instanceof Promise)\n          slice2 = await slice2;\n        if (!slice2) {\n          this.lastSampleLoaded = true;\n          return;\n        }\n        const id3V2Header = readId3V2Header(slice2);\n        if (!id3V2Header) {\n          break;\n        }\n        this.lastLoadedPos = slice2.filePos + id3V2Header.size;\n      }\n    }\n    const result = await readNextMp3FrameHeader(this.reader, this.lastLoadedPos, this.reader.fileSize);\n    if (!result) {\n      this.lastSampleLoaded = true;\n      return;\n    }\n    const header2 = result.header;\n    this.lastLoadedPos = result.startPos + header2.totalSize - 1;\n    const xingOffset = getXingOffset(header2.mpegVersionId, header2.channel);\n    let slice = this.reader.requestSlice(result.startPos + xingOffset, 4);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (slice) {\n      const word = readU32Be(slice);\n      const isXing = word === XING || word === INFO;\n      if (isXing) {\n        return;\n      }\n    }\n    if (!this.firstFrameHeader) {\n      this.firstFrameHeader = header2;\n    }\n    if (header2.sampleRate !== this.firstFrameHeader.sampleRate) {\n      console.warn(`MP3 changed sample rate mid-file: ${this.firstFrameHeader.sampleRate} Hz to ${header2.sampleRate} Hz.` + ` Might be a bug, so please report this file.`);\n    }\n    const sampleDuration = header2.audioSamplesInFrame / this.firstFrameHeader.sampleRate;\n    const sample = {\n      timestamp: this.nextTimestampInSamples / this.firstFrameHeader.sampleRate,\n      duration: sampleDuration,\n      dataStart: result.startPos,\n      dataSize: header2.totalSize\n    };\n    this.loadedSamples.push(sample);\n    this.nextTimestampInSamples += header2.audioSamplesInFrame;\n    return;\n  }\n  async getMimeType() {\n    return \"audio/mpeg\";\n  }\n  async getTracks() {\n    await this.readMetadata();\n    return this.tracks;\n  }\n  async computeDuration() {\n    await this.readMetadata();\n    const track = this.tracks[0];\n    assert(track);\n    return track.computeDuration();\n  }\n  async getMetadataTags() {\n    const release = await this.readingMutex.acquire();\n    try {\n      await this.readMetadata();\n      if (this.metadataTags) {\n        return this.metadataTags;\n      }\n      this.metadataTags = {};\n      let currentPos = 0;\n      let id3V2HeaderFound = false;\n      while (true) {\n        let headerSlice = this.reader.requestSlice(currentPos, ID3_V2_HEADER_SIZE);\n        if (headerSlice instanceof Promise)\n          headerSlice = await headerSlice;\n        if (!headerSlice)\n          break;\n        const id3V2Header = readId3V2Header(headerSlice);\n        if (!id3V2Header) {\n          break;\n        }\n        id3V2HeaderFound = true;\n        let contentSlice = this.reader.requestSlice(headerSlice.filePos, id3V2Header.size);\n        if (contentSlice instanceof Promise)\n          contentSlice = await contentSlice;\n        if (!contentSlice)\n          break;\n        parseId3V2Tag(contentSlice, id3V2Header, this.metadataTags);\n        currentPos = headerSlice.filePos + id3V2Header.size;\n      }\n      if (!id3V2HeaderFound && this.reader.fileSize !== null && this.reader.fileSize >= ID3_V1_TAG_SIZE) {\n        let slice = this.reader.requestSlice(this.reader.fileSize - ID3_V1_TAG_SIZE, ID3_V1_TAG_SIZE);\n        if (slice instanceof Promise)\n          slice = await slice;\n        assert(slice);\n        const tag = readAscii(slice, 3);\n        if (tag === \"TAG\") {\n          parseId3V1Tag(slice, this.metadataTags);\n        }\n      }\n      return this.metadataTags;\n    } finally {\n      release();\n    }\n  }\n}\n\nclass Mp3AudioTrackBacking {\n  constructor(demuxer) {\n    this.demuxer = demuxer;\n  }\n  getId() {\n    return 1;\n  }\n  async getFirstTimestamp() {\n    return 0;\n  }\n  getTimeResolution() {\n    assert(this.demuxer.firstFrameHeader);\n    return this.demuxer.firstFrameHeader.sampleRate / this.demuxer.firstFrameHeader.audioSamplesInFrame;\n  }\n  async computeDuration() {\n    const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n    return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n  }\n  getName() {\n    return null;\n  }\n  getLanguageCode() {\n    return UNDETERMINED_LANGUAGE;\n  }\n  getCodec() {\n    return \"mp3\";\n  }\n  getInternalCodecId() {\n    return null;\n  }\n  getNumberOfChannels() {\n    assert(this.demuxer.firstFrameHeader);\n    return this.demuxer.firstFrameHeader.channel === 3 ? 1 : 2;\n  }\n  getSampleRate() {\n    assert(this.demuxer.firstFrameHeader);\n    return this.demuxer.firstFrameHeader.sampleRate;\n  }\n  getDisposition() {\n    return {\n      ...DEFAULT_TRACK_DISPOSITION\n    };\n  }\n  async getDecoderConfig() {\n    assert(this.demuxer.firstFrameHeader);\n    return {\n      codec: \"mp3\",\n      numberOfChannels: this.demuxer.firstFrameHeader.channel === 3 ? 1 : 2,\n      sampleRate: this.demuxer.firstFrameHeader.sampleRate\n    };\n  }\n  async getPacketAtIndex(sampleIndex, options) {\n    if (sampleIndex === -1) {\n      return null;\n    }\n    const rawSample = this.demuxer.loadedSamples[sampleIndex];\n    if (!rawSample) {\n      return null;\n    }\n    let data;\n    if (options.metadataOnly) {\n      data = PLACEHOLDER_DATA;\n    } else {\n      let slice = this.demuxer.reader.requestSlice(rawSample.dataStart, rawSample.dataSize);\n      if (slice instanceof Promise)\n        slice = await slice;\n      if (!slice) {\n        return null;\n      }\n      data = readBytes(slice, rawSample.dataSize);\n    }\n    return new EncodedPacket(data, \"key\", rawSample.timestamp, rawSample.duration, sampleIndex, rawSample.dataSize);\n  }\n  getFirstPacket(options) {\n    return this.getPacketAtIndex(0, options);\n  }\n  async getNextPacket(packet, options) {\n    const release = await this.demuxer.readingMutex.acquire();\n    try {\n      const sampleIndex = binarySearchExact(this.demuxer.loadedSamples, packet.timestamp, (x) => x.timestamp);\n      if (sampleIndex === -1) {\n        throw new Error(\"Packet was not created from this track.\");\n      }\n      const nextIndex = sampleIndex + 1;\n      while (nextIndex >= this.demuxer.loadedSamples.length && !this.demuxer.lastSampleLoaded) {\n        await this.demuxer.advanceReader();\n      }\n      return this.getPacketAtIndex(nextIndex, options);\n    } finally {\n      release();\n    }\n  }\n  async getPacket(timestamp, options) {\n    const release = await this.demuxer.readingMutex.acquire();\n    try {\n      while (true) {\n        const index = binarySearchLessOrEqual(this.demuxer.loadedSamples, timestamp, (x) => x.timestamp);\n        if (index === -1 && this.demuxer.loadedSamples.length > 0) {\n          return null;\n        }\n        if (this.demuxer.lastSampleLoaded) {\n          return this.getPacketAtIndex(index, options);\n        }\n        if (index >= 0 && index + 1 < this.demuxer.loadedSamples.length) {\n          return this.getPacketAtIndex(index, options);\n        }\n        await this.demuxer.advanceReader();\n      }\n    } finally {\n      release();\n    }\n  }\n  getKeyPacket(timestamp, options) {\n    return this.getPacket(timestamp, options);\n  }\n  getNextKeyPacket(packet, options) {\n    return this.getNextPacket(packet, options);\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/ogg/ogg-misc.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar OGGS = 1399285583;\nvar OGG_CRC_POLYNOMIAL = 79764919;\nvar OGG_CRC_TABLE = new Uint32Array(256);\nfor (let n = 0;n < 256; n++) {\n  let crc = n << 24;\n  for (let k = 0;k < 8; k++) {\n    crc = crc & 2147483648 ? crc << 1 ^ OGG_CRC_POLYNOMIAL : crc << 1;\n  }\n  OGG_CRC_TABLE[n] = crc >>> 0 & 4294967295;\n}\nvar computeOggPageCrc = (bytes) => {\n  const view = toDataView(bytes);\n  const originalChecksum = view.getUint32(22, true);\n  view.setUint32(22, 0, true);\n  let crc = 0;\n  for (let i = 0;i < bytes.length; i++) {\n    const byte = bytes[i];\n    crc = (crc << 8 ^ OGG_CRC_TABLE[crc >>> 24 ^ byte]) >>> 0;\n  }\n  view.setUint32(22, originalChecksum, true);\n  return crc;\n};\nvar extractSampleMetadata = (data, codecInfo, vorbisLastBlocksize) => {\n  let durationInSamples = 0;\n  let currentBlocksize = null;\n  if (data.length > 0) {\n    if (codecInfo.codec === \"vorbis\") {\n      assert(codecInfo.vorbisInfo);\n      const vorbisModeCount = codecInfo.vorbisInfo.modeBlockflags.length;\n      const bitCount = ilog(vorbisModeCount - 1);\n      const modeMask = (1 << bitCount) - 1 << 1;\n      const modeNumber = (data[0] & modeMask) >> 1;\n      if (modeNumber >= codecInfo.vorbisInfo.modeBlockflags.length) {\n        throw new Error(\"Invalid mode number.\");\n      }\n      let prevBlocksize = vorbisLastBlocksize;\n      const blockflag = codecInfo.vorbisInfo.modeBlockflags[modeNumber];\n      currentBlocksize = codecInfo.vorbisInfo.blocksizes[blockflag];\n      if (blockflag === 1) {\n        const prevMask = (modeMask | 1) + 1;\n        const flag = data[0] & prevMask ? 1 : 0;\n        prevBlocksize = codecInfo.vorbisInfo.blocksizes[flag];\n      }\n      durationInSamples = prevBlocksize !== null ? prevBlocksize + currentBlocksize >> 2 : 0;\n    } else if (codecInfo.codec === \"opus\") {\n      const toc = parseOpusTocByte(data);\n      durationInSamples = toc.durationInSamples;\n    }\n  }\n  return {\n    durationInSamples,\n    vorbisBlockSize: currentBlocksize\n  };\n};\nvar buildOggMimeType = (info) => {\n  let string = \"audio/ogg\";\n  if (info.codecStrings) {\n    const uniqueCodecMimeTypes = [...new Set(info.codecStrings)];\n    string += `; codecs=\"${uniqueCodecMimeTypes.join(\", \")}\"`;\n  }\n  return string;\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/ogg/ogg-reader.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar MIN_PAGE_HEADER_SIZE = 27;\nvar MAX_PAGE_HEADER_SIZE = 27 + 255;\nvar MAX_PAGE_SIZE = MAX_PAGE_HEADER_SIZE + 255 * 255;\nvar readPageHeader = (slice) => {\n  const startPos = slice.filePos;\n  const capturePattern = readU32Le(slice);\n  if (capturePattern !== OGGS) {\n    return null;\n  }\n  slice.skip(1);\n  const headerType = readU8(slice);\n  const granulePosition = readI64Le(slice);\n  const serialNumber = readU32Le(slice);\n  const sequenceNumber = readU32Le(slice);\n  const checksum = readU32Le(slice);\n  const numberPageSegments = readU8(slice);\n  const lacingValues = new Uint8Array(numberPageSegments);\n  for (let i = 0;i < numberPageSegments; i++) {\n    lacingValues[i] = readU8(slice);\n  }\n  const headerSize = 27 + numberPageSegments;\n  const dataSize = lacingValues.reduce((a, b) => a + b, 0);\n  const totalSize = headerSize + dataSize;\n  return {\n    headerStartPos: startPos,\n    totalSize,\n    dataStartPos: startPos + headerSize,\n    dataSize,\n    headerType,\n    granulePosition,\n    serialNumber,\n    sequenceNumber,\n    checksum,\n    lacingValues\n  };\n};\nvar findNextPageHeader = (slice, until) => {\n  while (slice.filePos < until - (4 - 1)) {\n    const word = readU32Le(slice);\n    const firstByte = word & 255;\n    const secondByte = word >>> 8 & 255;\n    const thirdByte = word >>> 16 & 255;\n    const fourthByte = word >>> 24 & 255;\n    const O = 79;\n    if (firstByte !== O && secondByte !== O && thirdByte !== O && fourthByte !== O) {\n      continue;\n    }\n    slice.skip(-4);\n    if (word === OGGS) {\n      return true;\n    }\n    slice.skip(1);\n  }\n  return false;\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/ogg/ogg-demuxer.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\nclass OggDemuxer extends Demuxer {\n  constructor(input2) {\n    super(input2);\n    this.metadataPromise = null;\n    this.bitstreams = [];\n    this.tracks = [];\n    this.metadataTags = {};\n    this.reader = input2._reader;\n  }\n  async readMetadata() {\n    return this.metadataPromise ??= (async () => {\n      let currentPos = 0;\n      while (true) {\n        let slice = this.reader.requestSliceRange(currentPos, MIN_PAGE_HEADER_SIZE, MAX_PAGE_HEADER_SIZE);\n        if (slice instanceof Promise)\n          slice = await slice;\n        if (!slice)\n          break;\n        const page = readPageHeader(slice);\n        if (!page) {\n          break;\n        }\n        const isBos = !!(page.headerType & 2);\n        if (!isBos) {\n          break;\n        }\n        this.bitstreams.push({\n          serialNumber: page.serialNumber,\n          bosPage: page,\n          description: null,\n          numberOfChannels: -1,\n          sampleRate: -1,\n          codecInfo: {\n            codec: null,\n            vorbisInfo: null,\n            opusInfo: null\n          },\n          lastMetadataPacket: null\n        });\n        currentPos = page.headerStartPos + page.totalSize;\n      }\n      for (const bitstream of this.bitstreams) {\n        const firstPacket = await this.readPacket(bitstream.bosPage, 0);\n        if (!firstPacket) {\n          continue;\n        }\n        if (firstPacket.data.byteLength >= 7 && firstPacket.data[0] === 1 && firstPacket.data[1] === 118 && firstPacket.data[2] === 111 && firstPacket.data[3] === 114 && firstPacket.data[4] === 98 && firstPacket.data[5] === 105 && firstPacket.data[6] === 115) {\n          await this.readVorbisMetadata(firstPacket, bitstream);\n        } else if (firstPacket.data.byteLength >= 8 && firstPacket.data[0] === 79 && firstPacket.data[1] === 112 && firstPacket.data[2] === 117 && firstPacket.data[3] === 115 && firstPacket.data[4] === 72 && firstPacket.data[5] === 101 && firstPacket.data[6] === 97 && firstPacket.data[7] === 100) {\n          await this.readOpusMetadata(firstPacket, bitstream);\n        }\n        if (bitstream.codecInfo.codec !== null) {\n          this.tracks.push(new InputAudioTrack(this.input, new OggAudioTrackBacking(bitstream, this)));\n        }\n      }\n    })();\n  }\n  async readVorbisMetadata(firstPacket, bitstream) {\n    let nextPacketPosition = await this.findNextPacketStart(firstPacket);\n    if (!nextPacketPosition) {\n      return;\n    }\n    const secondPacket = await this.readPacket(nextPacketPosition.startPage, nextPacketPosition.startSegmentIndex);\n    if (!secondPacket) {\n      return;\n    }\n    nextPacketPosition = await this.findNextPacketStart(secondPacket);\n    if (!nextPacketPosition) {\n      return;\n    }\n    const thirdPacket = await this.readPacket(nextPacketPosition.startPage, nextPacketPosition.startSegmentIndex);\n    if (!thirdPacket) {\n      return;\n    }\n    if (secondPacket.data[0] !== 3 || thirdPacket.data[0] !== 5) {\n      return;\n    }\n    const lacingValues = [];\n    const addBytesToSegmentTable = (bytes) => {\n      while (true) {\n        lacingValues.push(Math.min(255, bytes));\n        if (bytes < 255) {\n          break;\n        }\n        bytes -= 255;\n      }\n    };\n    addBytesToSegmentTable(firstPacket.data.length);\n    addBytesToSegmentTable(secondPacket.data.length);\n    const description = new Uint8Array(1 + lacingValues.length + firstPacket.data.length + secondPacket.data.length + thirdPacket.data.length);\n    description[0] = 2;\n    description.set(lacingValues, 1);\n    description.set(firstPacket.data, 1 + lacingValues.length);\n    description.set(secondPacket.data, 1 + lacingValues.length + firstPacket.data.length);\n    description.set(thirdPacket.data, 1 + lacingValues.length + firstPacket.data.length + secondPacket.data.length);\n    bitstream.codecInfo.codec = \"vorbis\";\n    bitstream.description = description;\n    bitstream.lastMetadataPacket = thirdPacket;\n    const view = toDataView(firstPacket.data);\n    bitstream.numberOfChannels = view.getUint8(11);\n    bitstream.sampleRate = view.getUint32(12, true);\n    const blockSizeByte = view.getUint8(28);\n    bitstream.codecInfo.vorbisInfo = {\n      blocksizes: [\n        1 << (blockSizeByte & 15),\n        1 << (blockSizeByte >> 4)\n      ],\n      modeBlockflags: parseModesFromVorbisSetupPacket(thirdPacket.data).modeBlockflags\n    };\n    readVorbisComments(secondPacket.data.subarray(7), this.metadataTags);\n  }\n  async readOpusMetadata(firstPacket, bitstream) {\n    const nextPacketPosition = await this.findNextPacketStart(firstPacket);\n    if (!nextPacketPosition) {\n      return;\n    }\n    const secondPacket = await this.readPacket(nextPacketPosition.startPage, nextPacketPosition.startSegmentIndex);\n    if (!secondPacket) {\n      return;\n    }\n    bitstream.codecInfo.codec = \"opus\";\n    bitstream.description = firstPacket.data;\n    bitstream.lastMetadataPacket = secondPacket;\n    const header2 = parseOpusIdentificationHeader(firstPacket.data);\n    bitstream.numberOfChannels = header2.outputChannelCount;\n    bitstream.sampleRate = OPUS_SAMPLE_RATE;\n    bitstream.codecInfo.opusInfo = {\n      preSkip: header2.preSkip\n    };\n    readVorbisComments(secondPacket.data.subarray(8), this.metadataTags);\n  }\n  async readPacket(startPage, startSegmentIndex) {\n    assert(startSegmentIndex < startPage.lacingValues.length);\n    let startDataOffset = 0;\n    for (let i = 0;i < startSegmentIndex; i++) {\n      startDataOffset += startPage.lacingValues[i];\n    }\n    let currentPage = startPage;\n    let currentDataOffset = startDataOffset;\n    let currentSegmentIndex = startSegmentIndex;\n    const chunks = [];\n    outer:\n      while (true) {\n        let pageSlice = this.reader.requestSlice(currentPage.dataStartPos, currentPage.dataSize);\n        if (pageSlice instanceof Promise)\n          pageSlice = await pageSlice;\n        assert(pageSlice);\n        const pageData = readBytes(pageSlice, currentPage.dataSize);\n        while (true) {\n          if (currentSegmentIndex === currentPage.lacingValues.length) {\n            chunks.push(pageData.subarray(startDataOffset, currentDataOffset));\n            break;\n          }\n          const lacingValue = currentPage.lacingValues[currentSegmentIndex];\n          currentDataOffset += lacingValue;\n          if (lacingValue < 255) {\n            chunks.push(pageData.subarray(startDataOffset, currentDataOffset));\n            break outer;\n          }\n          currentSegmentIndex++;\n        }\n        let currentPos = currentPage.headerStartPos + currentPage.totalSize;\n        while (true) {\n          let headerSlice = this.reader.requestSliceRange(currentPos, MIN_PAGE_HEADER_SIZE, MAX_PAGE_HEADER_SIZE);\n          if (headerSlice instanceof Promise)\n            headerSlice = await headerSlice;\n          if (!headerSlice) {\n            return null;\n          }\n          const nextPage = readPageHeader(headerSlice);\n          if (!nextPage) {\n            return null;\n          }\n          currentPage = nextPage;\n          if (currentPage.serialNumber === startPage.serialNumber) {\n            break;\n          }\n          currentPos = currentPage.headerStartPos + currentPage.totalSize;\n        }\n        startDataOffset = 0;\n        currentDataOffset = 0;\n        currentSegmentIndex = 0;\n      }\n    const totalPacketSize = chunks.reduce((sum, chunk) => sum + chunk.length, 0);\n    if (totalPacketSize === 0) {\n      return null;\n    }\n    const packetData = new Uint8Array(totalPacketSize);\n    let offset = 0;\n    for (let i = 0;i < chunks.length; i++) {\n      const chunk = chunks[i];\n      packetData.set(chunk, offset);\n      offset += chunk.length;\n    }\n    return {\n      data: packetData,\n      endPage: currentPage,\n      endSegmentIndex: currentSegmentIndex\n    };\n  }\n  async findNextPacketStart(lastPacket) {\n    if (lastPacket.endSegmentIndex < lastPacket.endPage.lacingValues.length - 1) {\n      return { startPage: lastPacket.endPage, startSegmentIndex: lastPacket.endSegmentIndex + 1 };\n    }\n    const isEos = !!(lastPacket.endPage.headerType & 4);\n    if (isEos) {\n      return null;\n    }\n    let currentPos = lastPacket.endPage.headerStartPos + lastPacket.endPage.totalSize;\n    while (true) {\n      let slice = this.reader.requestSliceRange(currentPos, MIN_PAGE_HEADER_SIZE, MAX_PAGE_HEADER_SIZE);\n      if (slice instanceof Promise)\n        slice = await slice;\n      if (!slice) {\n        return null;\n      }\n      const nextPage = readPageHeader(slice);\n      if (!nextPage) {\n        return null;\n      }\n      if (nextPage.serialNumber === lastPacket.endPage.serialNumber) {\n        return { startPage: nextPage, startSegmentIndex: 0 };\n      }\n      currentPos = nextPage.headerStartPos + nextPage.totalSize;\n    }\n  }\n  async getMimeType() {\n    await this.readMetadata();\n    const codecStrings = await Promise.all(this.tracks.map((x) => x.getCodecParameterString()));\n    return buildOggMimeType({\n      codecStrings: codecStrings.filter(Boolean)\n    });\n  }\n  async getTracks() {\n    await this.readMetadata();\n    return this.tracks;\n  }\n  async computeDuration() {\n    const tracks = await this.getTracks();\n    const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));\n    return Math.max(0, ...trackDurations);\n  }\n  async getMetadataTags() {\n    await this.readMetadata();\n    return this.metadataTags;\n  }\n}\n\nclass OggAudioTrackBacking {\n  constructor(bitstream, demuxer) {\n    this.bitstream = bitstream;\n    this.demuxer = demuxer;\n    this.encodedPacketToMetadata = new WeakMap;\n    this.sequentialScanCache = [];\n    this.sequentialScanMutex = new AsyncMutex;\n    this.internalSampleRate = bitstream.codecInfo.codec === \"opus\" ? OPUS_SAMPLE_RATE : bitstream.sampleRate;\n  }\n  getId() {\n    return this.bitstream.serialNumber;\n  }\n  getNumberOfChannels() {\n    return this.bitstream.numberOfChannels;\n  }\n  getSampleRate() {\n    return this.bitstream.sampleRate;\n  }\n  getTimeResolution() {\n    return this.bitstream.sampleRate;\n  }\n  getCodec() {\n    return this.bitstream.codecInfo.codec;\n  }\n  getInternalCodecId() {\n    return null;\n  }\n  async getDecoderConfig() {\n    assert(this.bitstream.codecInfo.codec);\n    return {\n      codec: this.bitstream.codecInfo.codec,\n      numberOfChannels: this.bitstream.numberOfChannels,\n      sampleRate: this.bitstream.sampleRate,\n      description: this.bitstream.description ?? undefined\n    };\n  }\n  getName() {\n    return null;\n  }\n  getLanguageCode() {\n    return UNDETERMINED_LANGUAGE;\n  }\n  getDisposition() {\n    return {\n      ...DEFAULT_TRACK_DISPOSITION\n    };\n  }\n  async getFirstTimestamp() {\n    return 0;\n  }\n  async computeDuration() {\n    const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n    return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n  }\n  granulePositionToTimestampInSamples(granulePosition) {\n    if (this.bitstream.codecInfo.codec === \"opus\") {\n      assert(this.bitstream.codecInfo.opusInfo);\n      return granulePosition - this.bitstream.codecInfo.opusInfo.preSkip;\n    }\n    return granulePosition;\n  }\n  createEncodedPacketFromOggPacket(packet, additional, options) {\n    if (!packet) {\n      return null;\n    }\n    const { durationInSamples, vorbisBlockSize } = extractSampleMetadata(packet.data, this.bitstream.codecInfo, additional.vorbisLastBlocksize);\n    const encodedPacket = new EncodedPacket(options.metadataOnly ? PLACEHOLDER_DATA : packet.data, \"key\", Math.max(0, additional.timestampInSamples) / this.internalSampleRate, durationInSamples / this.internalSampleRate, packet.endPage.headerStartPos + packet.endSegmentIndex, packet.data.byteLength);\n    this.encodedPacketToMetadata.set(encodedPacket, {\n      packet,\n      timestampInSamples: additional.timestampInSamples,\n      durationInSamples,\n      vorbisLastBlockSize: additional.vorbisLastBlocksize,\n      vorbisBlockSize\n    });\n    return encodedPacket;\n  }\n  async getFirstPacket(options) {\n    assert(this.bitstream.lastMetadataPacket);\n    const packetPosition = await this.demuxer.findNextPacketStart(this.bitstream.lastMetadataPacket);\n    if (!packetPosition) {\n      return null;\n    }\n    let timestampInSamples = 0;\n    if (this.bitstream.codecInfo.codec === \"opus\") {\n      assert(this.bitstream.codecInfo.opusInfo);\n      timestampInSamples -= this.bitstream.codecInfo.opusInfo.preSkip;\n    }\n    const packet = await this.demuxer.readPacket(packetPosition.startPage, packetPosition.startSegmentIndex);\n    return this.createEncodedPacketFromOggPacket(packet, {\n      timestampInSamples,\n      vorbisLastBlocksize: null\n    }, options);\n  }\n  async getNextPacket(prevPacket, options) {\n    const prevMetadata = this.encodedPacketToMetadata.get(prevPacket);\n    if (!prevMetadata) {\n      throw new Error(\"Packet was not created from this track.\");\n    }\n    const packetPosition = await this.demuxer.findNextPacketStart(prevMetadata.packet);\n    if (!packetPosition) {\n      return null;\n    }\n    const timestampInSamples = prevMetadata.timestampInSamples + prevMetadata.durationInSamples;\n    const packet = await this.demuxer.readPacket(packetPosition.startPage, packetPosition.startSegmentIndex);\n    return this.createEncodedPacketFromOggPacket(packet, {\n      timestampInSamples,\n      vorbisLastBlocksize: prevMetadata.vorbisBlockSize\n    }, options);\n  }\n  async getPacket(timestamp, options) {\n    if (this.demuxer.reader.fileSize === null) {\n      return this.getPacketSequential(timestamp, options);\n    }\n    const timestampInSamples = roundIfAlmostInteger(timestamp * this.internalSampleRate);\n    if (timestampInSamples === 0) {\n      return this.getFirstPacket(options);\n    }\n    if (timestampInSamples < 0) {\n      return null;\n    }\n    assert(this.bitstream.lastMetadataPacket);\n    const startPosition = await this.demuxer.findNextPacketStart(this.bitstream.lastMetadataPacket);\n    if (!startPosition) {\n      return null;\n    }\n    let lowPage = startPosition.startPage;\n    let high = this.demuxer.reader.fileSize;\n    const lowPages = [lowPage];\n    outer:\n      while (lowPage.headerStartPos + lowPage.totalSize < high) {\n        const low = lowPage.headerStartPos;\n        const mid = Math.floor((low + high) / 2);\n        let searchStartPos = mid;\n        while (true) {\n          const until = Math.min(searchStartPos + MAX_PAGE_SIZE, high - MIN_PAGE_HEADER_SIZE);\n          let searchSlice = this.demuxer.reader.requestSlice(searchStartPos, until - searchStartPos);\n          if (searchSlice instanceof Promise)\n            searchSlice = await searchSlice;\n          assert(searchSlice);\n          const found = findNextPageHeader(searchSlice, until);\n          if (!found) {\n            high = mid + MIN_PAGE_HEADER_SIZE;\n            continue outer;\n          }\n          let headerSlice = this.demuxer.reader.requestSliceRange(searchSlice.filePos, MIN_PAGE_HEADER_SIZE, MAX_PAGE_HEADER_SIZE);\n          if (headerSlice instanceof Promise)\n            headerSlice = await headerSlice;\n          assert(headerSlice);\n          const page = readPageHeader(headerSlice);\n          assert(page);\n          let pageValid = false;\n          if (page.serialNumber === this.bitstream.serialNumber) {\n            pageValid = true;\n          } else {\n            let pageSlice = this.demuxer.reader.requestSlice(page.headerStartPos, page.totalSize);\n            if (pageSlice instanceof Promise)\n              pageSlice = await pageSlice;\n            assert(pageSlice);\n            const bytes = readBytes(pageSlice, page.totalSize);\n            const crc = computeOggPageCrc(bytes);\n            pageValid = crc === page.checksum;\n          }\n          if (!pageValid) {\n            searchStartPos = page.headerStartPos + 4;\n            continue;\n          }\n          if (pageValid && page.serialNumber !== this.bitstream.serialNumber) {\n            searchStartPos = page.headerStartPos + page.totalSize;\n            continue;\n          }\n          const isContinuationPage = page.granulePosition === -1;\n          if (isContinuationPage) {\n            searchStartPos = page.headerStartPos + page.totalSize;\n            continue;\n          }\n          if (this.granulePositionToTimestampInSamples(page.granulePosition) > timestampInSamples) {\n            high = page.headerStartPos;\n          } else {\n            lowPage = page;\n            lowPages.push(page);\n          }\n          continue outer;\n        }\n      }\n    let lowerPage = startPosition.startPage;\n    for (const otherLowPage of lowPages) {\n      if (otherLowPage.granulePosition === lowPage.granulePosition) {\n        break;\n      }\n      if (!lowerPage || otherLowPage.headerStartPos > lowerPage.headerStartPos) {\n        lowerPage = otherLowPage;\n      }\n    }\n    let currentPage = lowerPage;\n    const previousPages = [currentPage];\n    while (true) {\n      if (currentPage.serialNumber === this.bitstream.serialNumber && currentPage.granulePosition === lowPage.granulePosition) {\n        break;\n      }\n      const nextPos = currentPage.headerStartPos + currentPage.totalSize;\n      let slice = this.demuxer.reader.requestSliceRange(nextPos, MIN_PAGE_HEADER_SIZE, MAX_PAGE_HEADER_SIZE);\n      if (slice instanceof Promise)\n        slice = await slice;\n      assert(slice);\n      const nextPage = readPageHeader(slice);\n      assert(nextPage);\n      currentPage = nextPage;\n      if (currentPage.serialNumber === this.bitstream.serialNumber) {\n        previousPages.push(currentPage);\n      }\n    }\n    assert(currentPage.granulePosition !== -1);\n    let currentSegmentIndex = null;\n    let currentTimestampInSamples;\n    let currentTimestampIsCorrect;\n    let endPage = currentPage;\n    let endSegmentIndex = 0;\n    if (currentPage.headerStartPos === startPosition.startPage.headerStartPos) {\n      currentTimestampInSamples = this.granulePositionToTimestampInSamples(0);\n      currentTimestampIsCorrect = true;\n      currentSegmentIndex = 0;\n    } else {\n      currentTimestampInSamples = 0;\n      currentTimestampIsCorrect = false;\n      for (let i = currentPage.lacingValues.length - 1;i >= 0; i--) {\n        const value = currentPage.lacingValues[i];\n        if (value < 255) {\n          currentSegmentIndex = i + 1;\n          break;\n        }\n      }\n      if (currentSegmentIndex === null) {\n        throw new Error(\"Invalid page with granule position: no packets end on this page.\");\n      }\n      endSegmentIndex = currentSegmentIndex - 1;\n      const pseudopacket = {\n        data: PLACEHOLDER_DATA,\n        endPage,\n        endSegmentIndex\n      };\n      const nextPosition = await this.demuxer.findNextPacketStart(pseudopacket);\n      if (nextPosition) {\n        const endPosition = findPreviousPacketEndPosition(previousPages, currentPage, currentSegmentIndex);\n        assert(endPosition);\n        const startPosition2 = findPacketStartPosition(previousPages, endPosition.page, endPosition.segmentIndex);\n        if (startPosition2) {\n          currentPage = startPosition2.page;\n          currentSegmentIndex = startPosition2.segmentIndex;\n        }\n      } else {\n        while (true) {\n          const endPosition = findPreviousPacketEndPosition(previousPages, currentPage, currentSegmentIndex);\n          if (!endPosition) {\n            break;\n          }\n          const startPosition2 = findPacketStartPosition(previousPages, endPosition.page, endPosition.segmentIndex);\n          if (!startPosition2) {\n            break;\n          }\n          currentPage = startPosition2.page;\n          currentSegmentIndex = startPosition2.segmentIndex;\n          if (endPosition.page.headerStartPos !== endPage.headerStartPos) {\n            endPage = endPosition.page;\n            endSegmentIndex = endPosition.segmentIndex;\n            break;\n          }\n        }\n      }\n    }\n    let lastEncodedPacket = null;\n    let lastEncodedPacketMetadata = null;\n    while (currentPage !== null) {\n      assert(currentSegmentIndex !== null);\n      const packet = await this.demuxer.readPacket(currentPage, currentSegmentIndex);\n      if (!packet) {\n        break;\n      }\n      const skipPacket = currentPage.headerStartPos === startPosition.startPage.headerStartPos && currentSegmentIndex < startPosition.startSegmentIndex;\n      if (!skipPacket) {\n        let encodedPacket = this.createEncodedPacketFromOggPacket(packet, {\n          timestampInSamples: currentTimestampInSamples,\n          vorbisLastBlocksize: lastEncodedPacketMetadata?.vorbisBlockSize ?? null\n        }, options);\n        assert(encodedPacket);\n        let encodedPacketMetadata = this.encodedPacketToMetadata.get(encodedPacket);\n        assert(encodedPacketMetadata);\n        if (!currentTimestampIsCorrect && packet.endPage.headerStartPos === endPage.headerStartPos && packet.endSegmentIndex === endSegmentIndex) {\n          currentTimestampInSamples = this.granulePositionToTimestampInSamples(currentPage.granulePosition);\n          currentTimestampIsCorrect = true;\n          encodedPacket = this.createEncodedPacketFromOggPacket(packet, {\n            timestampInSamples: currentTimestampInSamples - encodedPacketMetadata.durationInSamples,\n            vorbisLastBlocksize: lastEncodedPacketMetadata?.vorbisBlockSize ?? null\n          }, options);\n          assert(encodedPacket);\n          encodedPacketMetadata = this.encodedPacketToMetadata.get(encodedPacket);\n          assert(encodedPacketMetadata);\n        } else {\n          currentTimestampInSamples += encodedPacketMetadata.durationInSamples;\n        }\n        lastEncodedPacket = encodedPacket;\n        lastEncodedPacketMetadata = encodedPacketMetadata;\n        if (currentTimestampIsCorrect && (Math.max(currentTimestampInSamples, 0) > timestampInSamples || Math.max(encodedPacketMetadata.timestampInSamples, 0) === timestampInSamples)) {\n          break;\n        }\n      }\n      const nextPosition = await this.demuxer.findNextPacketStart(packet);\n      if (!nextPosition) {\n        break;\n      }\n      currentPage = nextPosition.startPage;\n      currentSegmentIndex = nextPosition.startSegmentIndex;\n    }\n    return lastEncodedPacket;\n  }\n  async getPacketSequential(timestamp, options) {\n    const release = await this.sequentialScanMutex.acquire();\n    try {\n      const timestampInSamples = roundIfAlmostInteger(timestamp * this.internalSampleRate);\n      timestamp = timestampInSamples / this.internalSampleRate;\n      const index = binarySearchLessOrEqual(this.sequentialScanCache, timestampInSamples, (x) => x.timestampInSamples);\n      let currentPacket;\n      if (index !== -1) {\n        const cacheEntry = this.sequentialScanCache[index];\n        currentPacket = this.createEncodedPacketFromOggPacket(cacheEntry.packet, {\n          timestampInSamples: cacheEntry.timestampInSamples,\n          vorbisLastBlocksize: cacheEntry.vorbisLastBlockSize\n        }, options);\n      } else {\n        currentPacket = await this.getFirstPacket(options);\n      }\n      let i = 0;\n      while (currentPacket && currentPacket.timestamp < timestamp) {\n        const nextPacket = await this.getNextPacket(currentPacket, options);\n        if (!nextPacket || nextPacket.timestamp > timestamp) {\n          break;\n        }\n        currentPacket = nextPacket;\n        i++;\n        if (i === 100) {\n          i = 0;\n          const metadata = this.encodedPacketToMetadata.get(currentPacket);\n          assert(metadata);\n          if (this.sequentialScanCache.length > 0) {\n            assert(last(this.sequentialScanCache).timestampInSamples <= metadata.timestampInSamples);\n          }\n          this.sequentialScanCache.push(metadata);\n        }\n      }\n      return currentPacket;\n    } finally {\n      release();\n    }\n  }\n  getKeyPacket(timestamp, options) {\n    return this.getPacket(timestamp, options);\n  }\n  getNextKeyPacket(packet, options) {\n    return this.getNextPacket(packet, options);\n  }\n}\nvar findPacketStartPosition = (pageList, endPage, endSegmentIndex) => {\n  let page = endPage;\n  let segmentIndex = endSegmentIndex;\n  outer:\n    while (true) {\n      segmentIndex--;\n      for (segmentIndex;segmentIndex >= 0; segmentIndex--) {\n        const lacingValue = page.lacingValues[segmentIndex];\n        if (lacingValue < 255) {\n          segmentIndex++;\n          break outer;\n        }\n      }\n      assert(segmentIndex === -1);\n      const pageStartsWithFreshPacket = !(page.headerType & 1);\n      if (pageStartsWithFreshPacket) {\n        segmentIndex = 0;\n        break;\n      }\n      const previousPage = findLast(pageList, (x) => x.headerStartPos < page.headerStartPos);\n      if (!previousPage) {\n        return null;\n      }\n      page = previousPage;\n      segmentIndex = page.lacingValues.length;\n    }\n  assert(segmentIndex !== -1);\n  if (segmentIndex === page.lacingValues.length) {\n    const nextPage = pageList[pageList.indexOf(page) + 1];\n    assert(nextPage);\n    page = nextPage;\n    segmentIndex = 0;\n  }\n  return { page, segmentIndex };\n};\nvar findPreviousPacketEndPosition = (pageList, startPage, startSegmentIndex) => {\n  if (startSegmentIndex > 0) {\n    return { page: startPage, segmentIndex: startSegmentIndex - 1 };\n  }\n  const previousPage = findLast(pageList, (x) => x.headerStartPos < startPage.headerStartPos);\n  if (!previousPage) {\n    return null;\n  }\n  return { page: previousPage, segmentIndex: previousPage.lacingValues.length - 1 };\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/wave/wave-demuxer.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar WaveFormat;\n(function(WaveFormat2) {\n  WaveFormat2[WaveFormat2[\"PCM\"] = 1] = \"PCM\";\n  WaveFormat2[WaveFormat2[\"IEEE_FLOAT\"] = 3] = \"IEEE_FLOAT\";\n  WaveFormat2[WaveFormat2[\"ALAW\"] = 6] = \"ALAW\";\n  WaveFormat2[WaveFormat2[\"MULAW\"] = 7] = \"MULAW\";\n  WaveFormat2[WaveFormat2[\"EXTENSIBLE\"] = 65534] = \"EXTENSIBLE\";\n})(WaveFormat || (WaveFormat = {}));\n\nclass WaveDemuxer extends Demuxer {\n  constructor(input2) {\n    super(input2);\n    this.metadataPromise = null;\n    this.dataStart = -1;\n    this.dataSize = -1;\n    this.audioInfo = null;\n    this.tracks = [];\n    this.lastKnownPacketIndex = 0;\n    this.metadataTags = {};\n    this.reader = input2._reader;\n  }\n  async readMetadata() {\n    return this.metadataPromise ??= (async () => {\n      let slice = this.reader.requestSlice(0, 12);\n      if (slice instanceof Promise)\n        slice = await slice;\n      assert(slice);\n      const riffType = readAscii(slice, 4);\n      const littleEndian = riffType !== \"RIFX\";\n      const isRf64 = riffType === \"RF64\";\n      const outerChunkSize = readU32(slice, littleEndian);\n      let totalFileSize = isRf64 ? this.reader.fileSize : Math.min(outerChunkSize + 8, this.reader.fileSize ?? Infinity);\n      const format = readAscii(slice, 4);\n      if (format !== \"WAVE\") {\n        throw new Error(\"Invalid WAVE file - wrong format\");\n      }\n      let chunksRead = 0;\n      let dataChunkSize = null;\n      let currentPos = slice.filePos;\n      while (totalFileSize === null || currentPos < totalFileSize) {\n        let slice2 = this.reader.requestSlice(currentPos, 8);\n        if (slice2 instanceof Promise)\n          slice2 = await slice2;\n        if (!slice2)\n          break;\n        const chunkId = readAscii(slice2, 4);\n        const chunkSize = readU32(slice2, littleEndian);\n        const startPos = slice2.filePos;\n        if (isRf64 && chunksRead === 0 && chunkId !== \"ds64\") {\n          throw new Error('Invalid RF64 file: First chunk must be \"ds64\".');\n        }\n        if (chunkId === \"fmt \") {\n          await this.parseFmtChunk(startPos, chunkSize, littleEndian);\n        } else if (chunkId === \"data\") {\n          dataChunkSize ??= chunkSize;\n          this.dataStart = slice2.filePos;\n          this.dataSize = Math.min(dataChunkSize, (totalFileSize ?? Infinity) - this.dataStart);\n          if (this.reader.fileSize === null) {\n            break;\n          }\n        } else if (chunkId === \"ds64\") {\n          let ds64Slice = this.reader.requestSlice(startPos, chunkSize);\n          if (ds64Slice instanceof Promise)\n            ds64Slice = await ds64Slice;\n          if (!ds64Slice)\n            break;\n          const riffChunkSize = readU64(ds64Slice, littleEndian);\n          dataChunkSize = readU64(ds64Slice, littleEndian);\n          totalFileSize = Math.min(riffChunkSize + 8, this.reader.fileSize ?? Infinity);\n        } else if (chunkId === \"LIST\") {\n          await this.parseListChunk(startPos, chunkSize, littleEndian);\n        } else if (chunkId === \"ID3 \" || chunkId === \"id3 \") {\n          await this.parseId3Chunk(startPos, chunkSize);\n        }\n        currentPos = startPos + chunkSize + (chunkSize & 1);\n        chunksRead++;\n      }\n      if (!this.audioInfo) {\n        throw new Error('Invalid WAVE file - missing \"fmt \" chunk');\n      }\n      if (this.dataStart === -1) {\n        throw new Error('Invalid WAVE file - missing \"data\" chunk');\n      }\n      const blockSize = this.audioInfo.blockSizeInBytes;\n      this.dataSize = Math.floor(this.dataSize / blockSize) * blockSize;\n      this.tracks.push(new InputAudioTrack(this.input, new WaveAudioTrackBacking(this)));\n    })();\n  }\n  async parseFmtChunk(startPos, size4, littleEndian) {\n    let slice = this.reader.requestSlice(startPos, size4);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return;\n    let formatTag = readU16(slice, littleEndian);\n    const numChannels = readU16(slice, littleEndian);\n    const sampleRate = readU32(slice, littleEndian);\n    slice.skip(4);\n    const blockAlign = readU16(slice, littleEndian);\n    let bitsPerSample;\n    if (size4 === 14) {\n      bitsPerSample = 8;\n    } else {\n      bitsPerSample = readU16(slice, littleEndian);\n    }\n    if (size4 >= 18 && formatTag !== 357) {\n      const cbSize = readU16(slice, littleEndian);\n      const remainingSize = size4 - 18;\n      const extensionSize = Math.min(remainingSize, cbSize);\n      if (extensionSize >= 22 && formatTag === WaveFormat.EXTENSIBLE) {\n        slice.skip(2 + 4);\n        const subFormat = readBytes(slice, 16);\n        formatTag = subFormat[0] | subFormat[1] << 8;\n      }\n    }\n    if (formatTag === WaveFormat.MULAW || formatTag === WaveFormat.ALAW) {\n      bitsPerSample = 8;\n    }\n    this.audioInfo = {\n      format: formatTag,\n      numberOfChannels: numChannels,\n      sampleRate,\n      sampleSizeInBytes: Math.ceil(bitsPerSample / 8),\n      blockSizeInBytes: blockAlign\n    };\n  }\n  async parseListChunk(startPos, size4, littleEndian) {\n    let slice = this.reader.requestSlice(startPos, size4);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return;\n    const infoType = readAscii(slice, 4);\n    if (infoType !== \"INFO\" && infoType !== \"INF0\") {\n      return;\n    }\n    let currentPos = slice.filePos;\n    while (currentPos <= startPos + size4 - 8) {\n      slice.filePos = currentPos;\n      const chunkName = readAscii(slice, 4);\n      const chunkSize = readU32(slice, littleEndian);\n      const bytes = readBytes(slice, chunkSize);\n      let stringLength = 0;\n      for (let i = 0;i < bytes.length; i++) {\n        if (bytes[i] === 0) {\n          break;\n        }\n        stringLength++;\n      }\n      const value = String.fromCharCode(...bytes.subarray(0, stringLength));\n      this.metadataTags.raw ??= {};\n      this.metadataTags.raw[chunkName] = value;\n      switch (chunkName) {\n        case \"INAM\":\n        case \"TITL\":\n          {\n            this.metadataTags.title ??= value;\n          }\n          ;\n          break;\n        case \"TIT3\":\n          {\n            this.metadataTags.description ??= value;\n          }\n          ;\n          break;\n        case \"IART\":\n          {\n            this.metadataTags.artist ??= value;\n          }\n          ;\n          break;\n        case \"IPRD\":\n          {\n            this.metadataTags.album ??= value;\n          }\n          ;\n          break;\n        case \"IPRT\":\n        case \"ITRK\":\n        case \"TRCK\":\n          {\n            const parts = value.split(\"/\");\n            const trackNum = Number.parseInt(parts[0], 10);\n            const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);\n            if (Number.isInteger(trackNum) && trackNum > 0) {\n              this.metadataTags.trackNumber ??= trackNum;\n            }\n            if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {\n              this.metadataTags.tracksTotal ??= tracksTotal;\n            }\n          }\n          ;\n          break;\n        case \"ICRD\":\n        case \"IDIT\":\n          {\n            const date = new Date(value);\n            if (!Number.isNaN(date.getTime())) {\n              this.metadataTags.date ??= date;\n            }\n          }\n          ;\n          break;\n        case \"YEAR\":\n          {\n            const year = Number.parseInt(value, 10);\n            if (Number.isInteger(year) && year > 0) {\n              this.metadataTags.date ??= new Date(year, 0, 1);\n            }\n          }\n          ;\n          break;\n        case \"IGNR\":\n        case \"GENR\":\n          {\n            this.metadataTags.genre ??= value;\n          }\n          ;\n          break;\n        case \"ICMT\":\n        case \"CMNT\":\n        case \"COMM\":\n          {\n            this.metadataTags.comment ??= value;\n          }\n          ;\n          break;\n      }\n      currentPos += 8 + chunkSize + (chunkSize & 1);\n    }\n  }\n  async parseId3Chunk(startPos, size4) {\n    let slice = this.reader.requestSlice(startPos, size4);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return;\n    const id3V2Header = readId3V2Header(slice);\n    if (id3V2Header) {\n      const contentSlice = slice.slice(startPos + 10, id3V2Header.size);\n      parseId3V2Tag(contentSlice, id3V2Header, this.metadataTags);\n    }\n  }\n  getCodec() {\n    assert(this.audioInfo);\n    if (this.audioInfo.format === WaveFormat.MULAW) {\n      return \"ulaw\";\n    }\n    if (this.audioInfo.format === WaveFormat.ALAW) {\n      return \"alaw\";\n    }\n    if (this.audioInfo.format === WaveFormat.PCM) {\n      if (this.audioInfo.sampleSizeInBytes === 1) {\n        return \"pcm-u8\";\n      } else if (this.audioInfo.sampleSizeInBytes === 2) {\n        return \"pcm-s16\";\n      } else if (this.audioInfo.sampleSizeInBytes === 3) {\n        return \"pcm-s24\";\n      } else if (this.audioInfo.sampleSizeInBytes === 4) {\n        return \"pcm-s32\";\n      }\n    }\n    if (this.audioInfo.format === WaveFormat.IEEE_FLOAT) {\n      if (this.audioInfo.sampleSizeInBytes === 4) {\n        return \"pcm-f32\";\n      }\n    }\n    return null;\n  }\n  async getMimeType() {\n    return \"audio/wav\";\n  }\n  async computeDuration() {\n    await this.readMetadata();\n    const track = this.tracks[0];\n    assert(track);\n    return track.computeDuration();\n  }\n  async getTracks() {\n    await this.readMetadata();\n    return this.tracks;\n  }\n  async getMetadataTags() {\n    await this.readMetadata();\n    return this.metadataTags;\n  }\n}\nvar PACKET_SIZE_IN_FRAMES = 2048;\n\nclass WaveAudioTrackBacking {\n  constructor(demuxer) {\n    this.demuxer = demuxer;\n  }\n  getId() {\n    return 1;\n  }\n  getCodec() {\n    return this.demuxer.getCodec();\n  }\n  getInternalCodecId() {\n    assert(this.demuxer.audioInfo);\n    return this.demuxer.audioInfo.format;\n  }\n  async getDecoderConfig() {\n    const codec = this.demuxer.getCodec();\n    if (!codec) {\n      return null;\n    }\n    assert(this.demuxer.audioInfo);\n    return {\n      codec,\n      numberOfChannels: this.demuxer.audioInfo.numberOfChannels,\n      sampleRate: this.demuxer.audioInfo.sampleRate\n    };\n  }\n  async computeDuration() {\n    const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n    return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n  }\n  getNumberOfChannels() {\n    assert(this.demuxer.audioInfo);\n    return this.demuxer.audioInfo.numberOfChannels;\n  }\n  getSampleRate() {\n    assert(this.demuxer.audioInfo);\n    return this.demuxer.audioInfo.sampleRate;\n  }\n  getTimeResolution() {\n    assert(this.demuxer.audioInfo);\n    return this.demuxer.audioInfo.sampleRate;\n  }\n  getName() {\n    return null;\n  }\n  getLanguageCode() {\n    return UNDETERMINED_LANGUAGE;\n  }\n  getDisposition() {\n    return {\n      ...DEFAULT_TRACK_DISPOSITION\n    };\n  }\n  async getFirstTimestamp() {\n    return 0;\n  }\n  async getPacketAtIndex(packetIndex, options) {\n    assert(this.demuxer.audioInfo);\n    const startOffset = packetIndex * PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes;\n    if (startOffset >= this.demuxer.dataSize) {\n      return null;\n    }\n    const sizeInBytes = Math.min(PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes, this.demuxer.dataSize - startOffset);\n    if (this.demuxer.reader.fileSize === null) {\n      let slice = this.demuxer.reader.requestSlice(this.demuxer.dataStart + startOffset, sizeInBytes);\n      if (slice instanceof Promise)\n        slice = await slice;\n      if (!slice) {\n        return null;\n      }\n    }\n    let data;\n    if (options.metadataOnly) {\n      data = PLACEHOLDER_DATA;\n    } else {\n      let slice = this.demuxer.reader.requestSlice(this.demuxer.dataStart + startOffset, sizeInBytes);\n      if (slice instanceof Promise)\n        slice = await slice;\n      assert(slice);\n      data = readBytes(slice, sizeInBytes);\n    }\n    const timestamp = packetIndex * PACKET_SIZE_IN_FRAMES / this.demuxer.audioInfo.sampleRate;\n    const duration = sizeInBytes / this.demuxer.audioInfo.blockSizeInBytes / this.demuxer.audioInfo.sampleRate;\n    this.demuxer.lastKnownPacketIndex = Math.max(packetIndex, timestamp);\n    return new EncodedPacket(data, \"key\", timestamp, duration, packetIndex, sizeInBytes);\n  }\n  getFirstPacket(options) {\n    return this.getPacketAtIndex(0, options);\n  }\n  async getPacket(timestamp, options) {\n    assert(this.demuxer.audioInfo);\n    const packetIndex = Math.floor(Math.min(timestamp * this.demuxer.audioInfo.sampleRate / PACKET_SIZE_IN_FRAMES, (this.demuxer.dataSize - 1) / (PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes)));\n    const packet = await this.getPacketAtIndex(packetIndex, options);\n    if (packet) {\n      return packet;\n    }\n    if (packetIndex === 0) {\n      return null;\n    }\n    assert(this.demuxer.reader.fileSize === null);\n    let currentPacket = await this.getPacketAtIndex(this.demuxer.lastKnownPacketIndex, options);\n    while (currentPacket) {\n      const nextPacket = await this.getNextPacket(currentPacket, options);\n      if (!nextPacket) {\n        break;\n      }\n      currentPacket = nextPacket;\n    }\n    return currentPacket;\n  }\n  getNextPacket(packet, options) {\n    assert(this.demuxer.audioInfo);\n    const packetIndex = Math.round(packet.timestamp * this.demuxer.audioInfo.sampleRate / PACKET_SIZE_IN_FRAMES);\n    return this.getPacketAtIndex(packetIndex + 1, options);\n  }\n  getKeyPacket(timestamp, options) {\n    return this.getPacket(timestamp, options);\n  }\n  getNextKeyPacket(packet, options) {\n    return this.getNextPacket(packet, options);\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/adts/adts-reader.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar MIN_ADTS_FRAME_HEADER_SIZE = 7;\nvar MAX_ADTS_FRAME_HEADER_SIZE = 9;\nvar readAdtsFrameHeader = (slice) => {\n  const startPos = slice.filePos;\n  const bytes = readBytes(slice, 9);\n  const bitstream = new Bitstream(bytes);\n  const syncword = bitstream.readBits(12);\n  if (syncword !== 4095) {\n    return null;\n  }\n  bitstream.skipBits(1);\n  const layer = bitstream.readBits(2);\n  if (layer !== 0) {\n    return null;\n  }\n  const protectionAbsence = bitstream.readBits(1);\n  const objectType = bitstream.readBits(2) + 1;\n  const samplingFrequencyIndex = bitstream.readBits(4);\n  if (samplingFrequencyIndex === 15) {\n    return null;\n  }\n  bitstream.skipBits(1);\n  const channelConfiguration = bitstream.readBits(3);\n  if (channelConfiguration === 0) {\n    throw new Error(\"ADTS frames with channel configuration 0 are not supported.\");\n  }\n  bitstream.skipBits(1);\n  bitstream.skipBits(1);\n  bitstream.skipBits(1);\n  bitstream.skipBits(1);\n  const frameLength = bitstream.readBits(13);\n  bitstream.skipBits(11);\n  const numberOfAacFrames = bitstream.readBits(2) + 1;\n  if (numberOfAacFrames !== 1) {\n    throw new Error(\"ADTS frames with more than one AAC frame are not supported.\");\n  }\n  let crcCheck = null;\n  if (protectionAbsence === 1) {\n    slice.filePos -= 2;\n  } else {\n    crcCheck = bitstream.readBits(16);\n  }\n  return {\n    objectType,\n    samplingFrequencyIndex,\n    channelConfiguration,\n    frameLength,\n    numberOfAacFrames,\n    crcCheck,\n    startPos\n  };\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/adts/adts-demuxer.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar SAMPLES_PER_AAC_FRAME = 1024;\n\nclass AdtsDemuxer extends Demuxer {\n  constructor(input2) {\n    super(input2);\n    this.metadataPromise = null;\n    this.firstFrameHeader = null;\n    this.loadedSamples = [];\n    this.tracks = [];\n    this.readingMutex = new AsyncMutex;\n    this.lastSampleLoaded = false;\n    this.lastLoadedPos = 0;\n    this.nextTimestampInSamples = 0;\n    this.reader = input2._reader;\n  }\n  async readMetadata() {\n    return this.metadataPromise ??= (async () => {\n      while (!this.firstFrameHeader && !this.lastSampleLoaded) {\n        await this.advanceReader();\n      }\n      assert(this.firstFrameHeader);\n      this.tracks = [new InputAudioTrack(this.input, new AdtsAudioTrackBacking(this))];\n    })();\n  }\n  async advanceReader() {\n    let slice = this.reader.requestSliceRange(this.lastLoadedPos, MIN_ADTS_FRAME_HEADER_SIZE, MAX_ADTS_FRAME_HEADER_SIZE);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice) {\n      this.lastSampleLoaded = true;\n      return;\n    }\n    const header2 = readAdtsFrameHeader(slice);\n    if (!header2) {\n      this.lastSampleLoaded = true;\n      return;\n    }\n    if (this.reader.fileSize !== null && header2.startPos + header2.frameLength > this.reader.fileSize) {\n      this.lastSampleLoaded = true;\n      return;\n    }\n    if (!this.firstFrameHeader) {\n      this.firstFrameHeader = header2;\n    }\n    const sampleRate = aacFrequencyTable[header2.samplingFrequencyIndex];\n    assert(sampleRate !== undefined);\n    const sampleDuration = SAMPLES_PER_AAC_FRAME / sampleRate;\n    const sample = {\n      timestamp: this.nextTimestampInSamples / sampleRate,\n      duration: sampleDuration,\n      dataStart: header2.startPos,\n      dataSize: header2.frameLength\n    };\n    this.loadedSamples.push(sample);\n    this.nextTimestampInSamples += SAMPLES_PER_AAC_FRAME;\n    this.lastLoadedPos = header2.startPos + header2.frameLength;\n  }\n  async getMimeType() {\n    return \"audio/aac\";\n  }\n  async getTracks() {\n    await this.readMetadata();\n    return this.tracks;\n  }\n  async computeDuration() {\n    await this.readMetadata();\n    const track = this.tracks[0];\n    assert(track);\n    return track.computeDuration();\n  }\n  async getMetadataTags() {\n    return {};\n  }\n}\n\nclass AdtsAudioTrackBacking {\n  constructor(demuxer) {\n    this.demuxer = demuxer;\n  }\n  getId() {\n    return 1;\n  }\n  async getFirstTimestamp() {\n    return 0;\n  }\n  getTimeResolution() {\n    const sampleRate = this.getSampleRate();\n    return sampleRate / SAMPLES_PER_AAC_FRAME;\n  }\n  async computeDuration() {\n    const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n    return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n  }\n  getName() {\n    return null;\n  }\n  getLanguageCode() {\n    return UNDETERMINED_LANGUAGE;\n  }\n  getCodec() {\n    return \"aac\";\n  }\n  getInternalCodecId() {\n    assert(this.demuxer.firstFrameHeader);\n    return this.demuxer.firstFrameHeader.objectType;\n  }\n  getNumberOfChannels() {\n    assert(this.demuxer.firstFrameHeader);\n    const numberOfChannels = aacChannelMap[this.demuxer.firstFrameHeader.channelConfiguration];\n    assert(numberOfChannels !== undefined);\n    return numberOfChannels;\n  }\n  getSampleRate() {\n    assert(this.demuxer.firstFrameHeader);\n    const sampleRate = aacFrequencyTable[this.demuxer.firstFrameHeader.samplingFrequencyIndex];\n    assert(sampleRate !== undefined);\n    return sampleRate;\n  }\n  getDisposition() {\n    return {\n      ...DEFAULT_TRACK_DISPOSITION\n    };\n  }\n  async getDecoderConfig() {\n    assert(this.demuxer.firstFrameHeader);\n    return {\n      codec: `mp4a.40.${this.demuxer.firstFrameHeader.objectType}`,\n      numberOfChannels: this.getNumberOfChannels(),\n      sampleRate: this.getSampleRate()\n    };\n  }\n  async getPacketAtIndex(sampleIndex, options) {\n    if (sampleIndex === -1) {\n      return null;\n    }\n    const rawSample = this.demuxer.loadedSamples[sampleIndex];\n    if (!rawSample) {\n      return null;\n    }\n    let data;\n    if (options.metadataOnly) {\n      data = PLACEHOLDER_DATA;\n    } else {\n      let slice = this.demuxer.reader.requestSlice(rawSample.dataStart, rawSample.dataSize);\n      if (slice instanceof Promise)\n        slice = await slice;\n      if (!slice) {\n        return null;\n      }\n      data = readBytes(slice, rawSample.dataSize);\n    }\n    return new EncodedPacket(data, \"key\", rawSample.timestamp, rawSample.duration, sampleIndex, rawSample.dataSize);\n  }\n  getFirstPacket(options) {\n    return this.getPacketAtIndex(0, options);\n  }\n  async getNextPacket(packet, options) {\n    const release = await this.demuxer.readingMutex.acquire();\n    try {\n      const sampleIndex = binarySearchExact(this.demuxer.loadedSamples, packet.timestamp, (x) => x.timestamp);\n      if (sampleIndex === -1) {\n        throw new Error(\"Packet was not created from this track.\");\n      }\n      const nextIndex = sampleIndex + 1;\n      while (nextIndex >= this.demuxer.loadedSamples.length && !this.demuxer.lastSampleLoaded) {\n        await this.demuxer.advanceReader();\n      }\n      return this.getPacketAtIndex(nextIndex, options);\n    } finally {\n      release();\n    }\n  }\n  async getPacket(timestamp, options) {\n    const release = await this.demuxer.readingMutex.acquire();\n    try {\n      while (true) {\n        const index = binarySearchLessOrEqual(this.demuxer.loadedSamples, timestamp, (x) => x.timestamp);\n        if (index === -1 && this.demuxer.loadedSamples.length > 0) {\n          return null;\n        }\n        if (this.demuxer.lastSampleLoaded) {\n          return this.getPacketAtIndex(index, options);\n        }\n        if (index >= 0 && index + 1 < this.demuxer.loadedSamples.length) {\n          return this.getPacketAtIndex(index, options);\n        }\n        await this.demuxer.advanceReader();\n      }\n    } finally {\n      release();\n    }\n  }\n  getKeyPacket(timestamp, options) {\n    return this.getPacket(timestamp, options);\n  }\n  getNextKeyPacket(packet, options) {\n    return this.getNextPacket(packet, options);\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/flac/flac-misc.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar getBlockSizeOrUncommon = (bits) => {\n  if (bits === 0) {\n    return null;\n  } else if (bits === 1) {\n    return 192;\n  } else if (bits >= 2 && bits <= 5) {\n    return 144 * 2 ** bits;\n  } else if (bits === 6) {\n    return \"uncommon-u8\";\n  } else if (bits === 7) {\n    return \"uncommon-u16\";\n  } else if (bits >= 8 && bits <= 15) {\n    return 2 ** bits;\n  } else {\n    return null;\n  }\n};\nvar getSampleRateOrUncommon = (sampleRateBits, streamInfoSampleRate) => {\n  switch (sampleRateBits) {\n    case 0:\n      return streamInfoSampleRate;\n    case 1:\n      return 88200;\n    case 2:\n      return 176400;\n    case 3:\n      return 192000;\n    case 4:\n      return 8000;\n    case 5:\n      return 16000;\n    case 6:\n      return 22050;\n    case 7:\n      return 24000;\n    case 8:\n      return 32000;\n    case 9:\n      return 44100;\n    case 10:\n      return 48000;\n    case 11:\n      return 96000;\n    case 12:\n      return \"uncommon-u8\";\n    case 13:\n      return \"uncommon-u16\";\n    case 14:\n      return \"uncommon-u16-10\";\n    default:\n      return null;\n  }\n};\nvar readCodedNumber = (fileSlice) => {\n  let ones = 0;\n  const bitstream1 = new Bitstream(readBytes(fileSlice, 1));\n  while (bitstream1.readBits(1) === 1) {\n    ones++;\n  }\n  if (ones === 0) {\n    return bitstream1.readBits(7);\n  }\n  const bitArray = [];\n  const extraBytes = ones - 1;\n  const bitstream2 = new Bitstream(readBytes(fileSlice, extraBytes));\n  const firstByteBits = 8 - ones - 1;\n  for (let i = 0;i < firstByteBits; i++) {\n    bitArray.unshift(bitstream1.readBits(1));\n  }\n  for (let i = 0;i < extraBytes; i++) {\n    for (let j = 0;j < 8; j++) {\n      const val = bitstream2.readBits(1);\n      if (j < 2) {\n        continue;\n      }\n      bitArray.unshift(val);\n    }\n  }\n  const encoded = bitArray.reduce((acc, bit, index) => {\n    return acc | bit << index;\n  }, 0);\n  return encoded;\n};\nvar readBlockSize = (slice, blockSizeBits) => {\n  if (blockSizeBits === \"uncommon-u16\") {\n    return readU16Be(slice) + 1;\n  } else if (blockSizeBits === \"uncommon-u8\") {\n    return readU8(slice) + 1;\n  } else if (typeof blockSizeBits === \"number\") {\n    return blockSizeBits;\n  } else {\n    assertNever(blockSizeBits);\n    assert(false);\n  }\n};\nvar readSampleRate = (slice, sampleRateOrUncommon) => {\n  if (sampleRateOrUncommon === \"uncommon-u16\") {\n    return readU16Be(slice);\n  }\n  if (sampleRateOrUncommon === \"uncommon-u16-10\") {\n    return readU16Be(slice) * 10;\n  }\n  if (sampleRateOrUncommon === \"uncommon-u8\") {\n    return readU8(slice);\n  }\n  if (typeof sampleRateOrUncommon === \"number\") {\n    return sampleRateOrUncommon;\n  }\n  return null;\n};\nvar calculateCrc8 = (data) => {\n  const polynomial = 7;\n  let crc = 0;\n  for (const byte of data) {\n    crc ^= byte;\n    for (let i = 0;i < 8; i++) {\n      if ((crc & 128) !== 0) {\n        crc = crc << 1 ^ polynomial;\n      } else {\n        crc <<= 1;\n      }\n      crc &= 255;\n    }\n  }\n  return crc;\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/flac/flac-demuxer.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\nclass FlacDemuxer extends Demuxer {\n  constructor(input2) {\n    super(input2);\n    this.loadedSamples = [];\n    this.metadataPromise = null;\n    this.track = null;\n    this.metadataTags = {};\n    this.audioInfo = null;\n    this.lastLoadedPos = null;\n    this.blockingBit = null;\n    this.readingMutex = new AsyncMutex;\n    this.lastSampleLoaded = false;\n    this.reader = input2._reader;\n  }\n  async computeDuration() {\n    await this.readMetadata();\n    assert(this.track);\n    return this.track.computeDuration();\n  }\n  async getMetadataTags() {\n    await this.readMetadata();\n    return this.metadataTags;\n  }\n  async getTracks() {\n    await this.readMetadata();\n    assert(this.track);\n    return [this.track];\n  }\n  async getMimeType() {\n    return \"audio/flac\";\n  }\n  async readMetadata() {\n    let currentPos = 4;\n    return this.metadataPromise ??= (async () => {\n      while (this.reader.fileSize === null || currentPos < this.reader.fileSize) {\n        let sizeSlice = this.reader.requestSlice(currentPos, 4);\n        if (sizeSlice instanceof Promise)\n          sizeSlice = await sizeSlice;\n        currentPos += 4;\n        if (sizeSlice === null) {\n          throw new Error(`Metadata block at position ${currentPos} is too small! Corrupted file.`);\n        }\n        assert(sizeSlice);\n        const byte = readU8(sizeSlice);\n        const size4 = readU24Be(sizeSlice);\n        const isLastMetadata = (byte & 128) !== 0;\n        const metaBlockType = byte & 127;\n        switch (metaBlockType) {\n          case FlacBlockType.STREAMINFO: {\n            let streamInfoBlock = this.reader.requestSlice(currentPos, size4);\n            if (streamInfoBlock instanceof Promise)\n              streamInfoBlock = await streamInfoBlock;\n            assert(streamInfoBlock);\n            if (streamInfoBlock === null) {\n              throw new Error(`StreamInfo block at position ${currentPos} is too small! Corrupted file.`);\n            }\n            const streamInfoBytes = readBytes(streamInfoBlock, 34);\n            const bitstream = new Bitstream(streamInfoBytes);\n            const minimumBlockSize = bitstream.readBits(16);\n            const maximumBlockSize = bitstream.readBits(16);\n            const minimumFrameSize = bitstream.readBits(24);\n            const maximumFrameSize = bitstream.readBits(24);\n            const sampleRate = bitstream.readBits(20);\n            const numberOfChannels = bitstream.readBits(3) + 1;\n            bitstream.readBits(5);\n            const totalSamples = bitstream.readBits(36);\n            bitstream.skipBits(16 * 8);\n            const description = new Uint8Array(42);\n            description.set(new Uint8Array([102, 76, 97, 67]), 0);\n            description.set(new Uint8Array([128, 0, 0, 34]), 4);\n            description.set(streamInfoBytes, 8);\n            this.audioInfo = {\n              numberOfChannels,\n              sampleRate,\n              totalSamples,\n              minimumBlockSize,\n              maximumBlockSize,\n              minimumFrameSize,\n              maximumFrameSize,\n              description\n            };\n            this.track = new InputAudioTrack(this.input, new FlacAudioTrackBacking(this));\n            break;\n          }\n          case FlacBlockType.VORBIS_COMMENT: {\n            let vorbisCommentBlock = this.reader.requestSlice(currentPos, size4);\n            if (vorbisCommentBlock instanceof Promise)\n              vorbisCommentBlock = await vorbisCommentBlock;\n            assert(vorbisCommentBlock);\n            readVorbisComments(readBytes(vorbisCommentBlock, size4), this.metadataTags);\n            break;\n          }\n          case FlacBlockType.PICTURE: {\n            let pictureBlock = this.reader.requestSlice(currentPos, size4);\n            if (pictureBlock instanceof Promise)\n              pictureBlock = await pictureBlock;\n            assert(pictureBlock);\n            const pictureType = readU32Be(pictureBlock);\n            const mediaTypeLength = readU32Be(pictureBlock);\n            const mediaType = textDecoder.decode(readBytes(pictureBlock, mediaTypeLength));\n            const descriptionLength = readU32Be(pictureBlock);\n            const description = textDecoder.decode(readBytes(pictureBlock, descriptionLength));\n            pictureBlock.skip(4 + 4 + 4 + 4);\n            const dataLength = readU32Be(pictureBlock);\n            const data = readBytes(pictureBlock, dataLength);\n            this.metadataTags.images ??= [];\n            this.metadataTags.images.push({\n              data,\n              mimeType: mediaType,\n              kind: pictureType === 3 ? \"coverFront\" : pictureType === 4 ? \"coverBack\" : \"unknown\",\n              description\n            });\n            break;\n          }\n          default:\n            break;\n        }\n        currentPos += size4;\n        if (isLastMetadata) {\n          this.lastLoadedPos = currentPos;\n          break;\n        }\n      }\n    })();\n  }\n  async readNextFlacFrame({ startPos, isFirstPacket }) {\n    assert(this.audioInfo);\n    const minimumHeaderLength = 6;\n    const maximumHeaderSize = 16;\n    const maximumSliceLength = this.audioInfo.maximumFrameSize + maximumHeaderSize;\n    const slice = await this.reader.requestSliceRange(startPos, this.audioInfo.minimumFrameSize, maximumSliceLength);\n    if (!slice) {\n      return null;\n    }\n    const frameHeader = this.readFlacFrameHeader({\n      slice,\n      isFirstPacket\n    });\n    if (!frameHeader) {\n      return null;\n    }\n    slice.filePos = startPos + this.audioInfo.minimumFrameSize;\n    while (true) {\n      if (slice.filePos > slice.end - minimumHeaderLength) {\n        return {\n          num: frameHeader.num,\n          blockSize: frameHeader.blockSize,\n          sampleRate: frameHeader.sampleRate,\n          size: slice.end - startPos,\n          isLastFrame: true\n        };\n      }\n      const nextByte = readU8(slice);\n      if (nextByte === 255) {\n        const positionBeforeReading = slice.filePos;\n        const byteAfterNextByte = readU8(slice);\n        const expected = this.blockingBit === 1 ? 249 : 248;\n        if (byteAfterNextByte !== expected) {\n          slice.filePos = positionBeforeReading;\n          continue;\n        }\n        slice.skip(-2);\n        const lengthIfNextFlacFrameHeaderIsLegit = slice.filePos - startPos;\n        const nextFrameHeader = this.readFlacFrameHeader({\n          slice,\n          isFirstPacket: false\n        });\n        if (!nextFrameHeader) {\n          slice.filePos = positionBeforeReading;\n          continue;\n        }\n        if (this.blockingBit === 0) {\n          if (nextFrameHeader.num - frameHeader.num !== 1) {\n            slice.filePos = positionBeforeReading;\n            continue;\n          }\n        } else {\n          if (nextFrameHeader.num - frameHeader.num !== frameHeader.blockSize) {\n            slice.filePos = positionBeforeReading;\n            continue;\n          }\n        }\n        return {\n          num: frameHeader.num,\n          blockSize: frameHeader.blockSize,\n          sampleRate: frameHeader.sampleRate,\n          size: lengthIfNextFlacFrameHeaderIsLegit,\n          isLastFrame: false\n        };\n      }\n    }\n  }\n  readFlacFrameHeader({ slice, isFirstPacket }) {\n    const startOffset = slice.filePos;\n    const bytes = readBytes(slice, 4);\n    const bitstream = new Bitstream(bytes);\n    const bits = bitstream.readBits(15);\n    if (bits !== 32764) {\n      return null;\n    }\n    if (this.blockingBit === null) {\n      assert(isFirstPacket);\n      const newBlockingBit = bitstream.readBits(1);\n      this.blockingBit = newBlockingBit;\n    } else if (this.blockingBit === 1) {\n      assert(!isFirstPacket);\n      const newBlockingBit = bitstream.readBits(1);\n      if (newBlockingBit !== 1) {\n        return null;\n      }\n    } else if (this.blockingBit === 0) {\n      assert(!isFirstPacket);\n      const newBlockingBit = bitstream.readBits(1);\n      if (newBlockingBit !== 0) {\n        return null;\n      }\n    } else {\n      throw new Error(\"Invalid blocking bit\");\n    }\n    const blockSizeOrUncommon = getBlockSizeOrUncommon(bitstream.readBits(4));\n    if (!blockSizeOrUncommon) {\n      return null;\n    }\n    assert(this.audioInfo);\n    const sampleRateOrUncommon = getSampleRateOrUncommon(bitstream.readBits(4), this.audioInfo.sampleRate);\n    if (!sampleRateOrUncommon) {\n      return null;\n    }\n    bitstream.readBits(4);\n    bitstream.readBits(3);\n    const reservedZero = bitstream.readBits(1);\n    if (reservedZero !== 0) {\n      return null;\n    }\n    const num = readCodedNumber(slice);\n    const blockSize = readBlockSize(slice, blockSizeOrUncommon);\n    const sampleRate = readSampleRate(slice, sampleRateOrUncommon);\n    if (sampleRate === null) {\n      return null;\n    }\n    if (sampleRate !== this.audioInfo.sampleRate) {\n      return null;\n    }\n    const size4 = slice.filePos - startOffset;\n    const crc = readU8(slice);\n    slice.skip(-size4);\n    slice.skip(-1);\n    const crcCalculated = calculateCrc8(readBytes(slice, size4));\n    if (crc !== crcCalculated) {\n      return null;\n    }\n    return { num, blockSize, sampleRate };\n  }\n  async advanceReader() {\n    await this.readMetadata();\n    assert(this.lastLoadedPos !== null);\n    assert(this.audioInfo);\n    const startPos = this.lastLoadedPos;\n    const frame2 = await this.readNextFlacFrame({\n      startPos,\n      isFirstPacket: this.loadedSamples.length === 0\n    });\n    if (!frame2) {\n      this.lastSampleLoaded = true;\n      return;\n    }\n    const lastSample = this.loadedSamples[this.loadedSamples.length - 1];\n    const blockOffset = lastSample ? lastSample.blockOffset + lastSample.blockSize : 0;\n    const sample = {\n      blockOffset,\n      blockSize: frame2.blockSize,\n      byteOffset: startPos,\n      byteSize: frame2.size\n    };\n    this.lastLoadedPos = this.lastLoadedPos + frame2.size;\n    this.loadedSamples.push(sample);\n    if (frame2.isLastFrame) {\n      this.lastSampleLoaded = true;\n      return;\n    }\n  }\n}\n\nclass FlacAudioTrackBacking {\n  constructor(demuxer) {\n    this.demuxer = demuxer;\n  }\n  getId() {\n    return 1;\n  }\n  getCodec() {\n    return \"flac\";\n  }\n  getInternalCodecId() {\n    return null;\n  }\n  getNumberOfChannels() {\n    assert(this.demuxer.audioInfo);\n    return this.demuxer.audioInfo.numberOfChannels;\n  }\n  async computeDuration() {\n    const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n    return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n  }\n  getSampleRate() {\n    assert(this.demuxer.audioInfo);\n    return this.demuxer.audioInfo.sampleRate;\n  }\n  getName() {\n    return null;\n  }\n  getLanguageCode() {\n    return UNDETERMINED_LANGUAGE;\n  }\n  getTimeResolution() {\n    assert(this.demuxer.audioInfo);\n    return this.demuxer.audioInfo.sampleRate;\n  }\n  getDisposition() {\n    return {\n      ...DEFAULT_TRACK_DISPOSITION\n    };\n  }\n  async getFirstTimestamp() {\n    return 0;\n  }\n  async getDecoderConfig() {\n    assert(this.demuxer.audioInfo);\n    return {\n      codec: \"flac\",\n      numberOfChannels: this.demuxer.audioInfo.numberOfChannels,\n      sampleRate: this.demuxer.audioInfo.sampleRate,\n      description: this.demuxer.audioInfo.description\n    };\n  }\n  async getPacket(timestamp, options) {\n    assert(this.demuxer.audioInfo);\n    if (timestamp < 0) {\n      throw new Error(\"Timestamp cannot be negative\");\n    }\n    const release = await this.demuxer.readingMutex.acquire();\n    try {\n      while (true) {\n        const packetIndex = binarySearchLessOrEqual(this.demuxer.loadedSamples, timestamp, (x) => x.blockOffset / this.demuxer.audioInfo.sampleRate);\n        if (packetIndex === -1) {\n          await this.demuxer.advanceReader();\n          continue;\n        }\n        const packet = this.demuxer.loadedSamples[packetIndex];\n        const sampleTimestamp = packet.blockOffset / this.demuxer.audioInfo.sampleRate;\n        const sampleDuration = packet.blockSize / this.demuxer.audioInfo.sampleRate;\n        if (sampleTimestamp + sampleDuration <= timestamp) {\n          if (this.demuxer.lastSampleLoaded) {\n            return this.getPacketAtIndex(this.demuxer.loadedSamples.length - 1, options);\n          }\n          await this.demuxer.advanceReader();\n          continue;\n        }\n        return this.getPacketAtIndex(packetIndex, options);\n      }\n    } finally {\n      release();\n    }\n  }\n  async getNextPacket(packet, options) {\n    const release = await this.demuxer.readingMutex.acquire();\n    try {\n      const nextIndex = packet.sequenceNumber + 1;\n      if (this.demuxer.lastSampleLoaded && nextIndex >= this.demuxer.loadedSamples.length) {\n        return null;\n      }\n      while (nextIndex >= this.demuxer.loadedSamples.length && !this.demuxer.lastSampleLoaded) {\n        await this.demuxer.advanceReader();\n      }\n      return this.getPacketAtIndex(nextIndex, options);\n    } finally {\n      release();\n    }\n  }\n  getKeyPacket(timestamp, options) {\n    return this.getPacket(timestamp, options);\n  }\n  getNextKeyPacket(packet, options) {\n    return this.getNextPacket(packet, options);\n  }\n  async getPacketAtIndex(sampleIndex, options) {\n    const rawSample = this.demuxer.loadedSamples[sampleIndex];\n    if (!rawSample) {\n      return null;\n    }\n    let data;\n    if (options.metadataOnly) {\n      data = PLACEHOLDER_DATA;\n    } else {\n      let slice = this.demuxer.reader.requestSlice(rawSample.byteOffset, rawSample.byteSize);\n      if (slice instanceof Promise)\n        slice = await slice;\n      if (!slice) {\n        return null;\n      }\n      data = readBytes(slice, rawSample.byteSize);\n    }\n    assert(this.demuxer.audioInfo);\n    const timestamp = rawSample.blockOffset / this.demuxer.audioInfo.sampleRate;\n    const duration = rawSample.blockSize / this.demuxer.audioInfo.sampleRate;\n    return new EncodedPacket(data, \"key\", timestamp, duration, sampleIndex, rawSample.byteSize);\n  }\n  async getFirstPacket(options) {\n    while (this.demuxer.loadedSamples.length === 0 && !this.demuxer.lastSampleLoaded) {\n      await this.demuxer.advanceReader();\n    }\n    return this.getPacketAtIndex(0, options);\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/mpeg-ts/mpeg-ts-misc.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar TIMESCALE = 90000;\nvar TS_PACKET_SIZE = 188;\nvar buildMpegTsMimeType = (codecStrings) => {\n  let string = \"video/MP2T\";\n  const uniqueCodecStrings = [...new Set(codecStrings.filter(Boolean))];\n  if (uniqueCodecStrings.length > 0) {\n    string += `; codecs=\"${uniqueCodecStrings.join(\", \")}\"`;\n  }\n  return string;\n};\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/mpeg-ts/mpeg-ts-demuxer.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nvar MISSING_PES_PACKET_ERROR = \"No PES packet found where one was expected.\";\n\nclass MpegTsDemuxer extends Demuxer {\n  constructor(input2) {\n    super(input2);\n    this.metadataPromise = null;\n    this.elementaryStreams = [];\n    this.tracks = [];\n    this.packetOffset = 0;\n    this.packetStride = -1;\n    this.reader = input2._reader;\n  }\n  async readMetadata() {\n    return this.metadataPromise ??= (async () => {\n      const lengthToCheck = TS_PACKET_SIZE + 16 + 1;\n      let startingSlice = this.reader.requestSlice(0, lengthToCheck);\n      if (startingSlice instanceof Promise)\n        startingSlice = await startingSlice;\n      assert(startingSlice);\n      const startingBytes = readBytes(startingSlice, lengthToCheck);\n      if (startingBytes[0] === 71 && startingBytes[TS_PACKET_SIZE] === 71) {\n        this.packetOffset = 0;\n        this.packetStride = TS_PACKET_SIZE;\n      } else if (startingBytes[0] === 71 && startingBytes[TS_PACKET_SIZE + 16] === 71) {\n        this.packetOffset = 0;\n        this.packetStride = TS_PACKET_SIZE + 16;\n      } else if (startingBytes[4] === 71 && startingBytes[4 + TS_PACKET_SIZE] === 71) {\n        this.packetOffset = 4;\n        this.packetStride = TS_PACKET_SIZE;\n      } else {\n        throw new Error(\"Unreachable.\");\n      }\n      let currentPos = this.packetOffset;\n      let programMapPid = null;\n      let hasProgramAssociationTable = false;\n      let hasProgramMap = false;\n      while (true) {\n        const section = await this.readSection(currentPos, true);\n        if (!section) {\n          break;\n        }\n        const BYTES_BEFORE_SECTION_LENGTH = 3;\n        const BITS_IN_CRC_32 = 32;\n        if (section.pid === 0 && !hasProgramAssociationTable) {\n          const bitstream = new Bitstream(section.payload);\n          const pointerField = bitstream.readAlignedByte();\n          bitstream.skipBits(8 * pointerField);\n          bitstream.skipBits(14);\n          const sectionLength = bitstream.readBits(10);\n          bitstream.skipBits(40);\n          while (8 * (sectionLength + BYTES_BEFORE_SECTION_LENGTH) - bitstream.pos > BITS_IN_CRC_32) {\n            const programNumber = bitstream.readBits(16);\n            bitstream.skipBits(3);\n            if (programNumber !== 0) {\n              if (programMapPid !== null) {\n                throw new Error(\"Only files with a single program are supported.\");\n              } else {\n                programMapPid = bitstream.readBits(13);\n              }\n            }\n          }\n          if (programMapPid === null) {\n            throw new Error(\"Program Association Table must link to a Program Map Table.\");\n          }\n          hasProgramAssociationTable = true;\n        } else if (section.pid === programMapPid && !hasProgramMap) {\n          const bitstream = new Bitstream(section.payload);\n          const pointerField = bitstream.readAlignedByte();\n          bitstream.skipBits(8 * pointerField);\n          bitstream.skipBits(12);\n          const sectionLength = bitstream.readBits(12);\n          bitstream.skipBits(43);\n          const pcrPid = bitstream.readBits(13);\n          bitstream.skipBits(6);\n          const programInfoLength = bitstream.readBits(10);\n          bitstream.skipBits(8 * programInfoLength);\n          while (8 * (sectionLength + BYTES_BEFORE_SECTION_LENGTH) - bitstream.pos > BITS_IN_CRC_32) {\n            const streamType = bitstream.readBits(8);\n            bitstream.skipBits(3);\n            const elementaryPid = bitstream.readBits(13);\n            bitstream.skipBits(6);\n            const esInfoLength = bitstream.readBits(10);\n            bitstream.skipBits(8 * esInfoLength);\n            let info = null;\n            switch (streamType) {\n              case 3:\n              case 4:\n              case 15:\n                {\n                  const codec = streamType === 15 ? \"aac\" : \"mp3\";\n                  info = {\n                    type: \"audio\",\n                    codec,\n                    aacCodecInfo: null,\n                    numberOfChannels: -1,\n                    sampleRate: -1\n                  };\n                }\n                ;\n                break;\n              case 27:\n              case 36:\n                {\n                  const codec = streamType === 27 ? \"avc\" : \"hevc\";\n                  info = {\n                    type: \"video\",\n                    codec,\n                    avcCodecInfo: null,\n                    hevcCodecInfo: null,\n                    colorSpace: {\n                      primaries: null,\n                      transfer: null,\n                      matrix: null,\n                      fullRange: null\n                    },\n                    width: -1,\n                    height: -1,\n                    reorderSize: -1\n                  };\n                }\n                ;\n                break;\n              default: {}\n            }\n            if (info) {\n              this.elementaryStreams.push({\n                demuxer: this,\n                pid: elementaryPid,\n                streamType,\n                initialized: false,\n                firstSection: null,\n                info\n              });\n            }\n          }\n          hasProgramMap = true;\n        } else {\n          const elementaryStream = this.elementaryStreams.find((x) => x.pid === section.pid);\n          if (elementaryStream && !elementaryStream.initialized) {\n            const pesPacket = readPesPacket(section);\n            if (!pesPacket) {\n              throw new Error(`Couldn't read first PES packet for Elementary Stream with PID ${elementaryStream.pid}`);\n            }\n            elementaryStream.firstSection = section;\n            if (elementaryStream.info.type === \"video\") {\n              if (elementaryStream.info.codec === \"avc\") {\n                elementaryStream.info.avcCodecInfo = extractAvcDecoderConfigurationRecord(pesPacket.data);\n                if (!elementaryStream.info.avcCodecInfo) {\n                  throw new Error(\"Invalid AVC video stream; could not extract AVCDecoderConfigurationRecord\" + \" from first packet.\");\n                }\n                const spsUnit = elementaryStream.info.avcCodecInfo.sequenceParameterSets[0];\n                assert(spsUnit);\n                const spsInfo = parseAvcSps(spsUnit);\n                elementaryStream.info.width = spsInfo.displayWidth;\n                elementaryStream.info.height = spsInfo.displayHeight;\n                elementaryStream.info.colorSpace = {\n                  primaries: COLOR_PRIMARIES_MAP_INVERSE[spsInfo.colourPrimaries],\n                  transfer: TRANSFER_CHARACTERISTICS_MAP_INVERSE[spsInfo.transferCharacteristics],\n                  matrix: MATRIX_COEFFICIENTS_MAP_INVERSE[spsInfo.matrixCoefficients],\n                  fullRange: !!spsInfo.fullRangeFlag\n                };\n                elementaryStream.info.reorderSize = spsInfo.maxDecFrameBuffering;\n                elementaryStream.initialized = true;\n              } else if (elementaryStream.info.codec === \"hevc\") {\n                elementaryStream.info.hevcCodecInfo = extractHevcDecoderConfigurationRecord(pesPacket.data);\n                if (!elementaryStream.info.hevcCodecInfo) {\n                  throw new Error(\"Invalid HEVC video stream; could not extract HVCDecoderConfigurationRecord\" + \" from first packet.\");\n                }\n                const spsArray = elementaryStream.info.hevcCodecInfo.arrays.find((a) => a.nalUnitType === HevcNalUnitType.SPS_NUT);\n                const spsUnit = spsArray.nalUnits[0];\n                assert(spsUnit);\n                const spsInfo = parseHevcSps(spsUnit);\n                elementaryStream.info.width = spsInfo.displayWidth;\n                elementaryStream.info.height = spsInfo.displayHeight;\n                elementaryStream.info.colorSpace = {\n                  primaries: COLOR_PRIMARIES_MAP_INVERSE[spsInfo.colourPrimaries],\n                  transfer: TRANSFER_CHARACTERISTICS_MAP_INVERSE[spsInfo.transferCharacteristics],\n                  matrix: MATRIX_COEFFICIENTS_MAP_INVERSE[spsInfo.matrixCoefficients],\n                  fullRange: !!spsInfo.fullRangeFlag\n                };\n                elementaryStream.info.reorderSize = spsInfo.maxDecFrameBuffering;\n                elementaryStream.initialized = true;\n              } else {\n                throw new Error(\"Unhandled.\");\n              }\n            } else {\n              if (elementaryStream.info.codec === \"aac\") {\n                const slice = FileSlice.tempFromBytes(pesPacket.data);\n                const header2 = readAdtsFrameHeader(slice);\n                if (!header2) {\n                  throw new Error(\"Invalid AAC audio stream; could not read ADTS frame header from first packet.\");\n                }\n                elementaryStream.info.aacCodecInfo = {\n                  isMpeg2: false,\n                  objectType: header2.objectType\n                };\n                elementaryStream.info.numberOfChannels = aacChannelMap[header2.channelConfiguration];\n                elementaryStream.info.sampleRate = aacFrequencyTable[header2.samplingFrequencyIndex];\n                elementaryStream.initialized = true;\n              } else if (elementaryStream.info.codec === \"mp3\") {\n                const word = readU32Be(FileSlice.tempFromBytes(pesPacket.data));\n                const result = readMp3FrameHeader(word, pesPacket.data.byteLength);\n                if (!result.header) {\n                  throw new Error(\"Invalid MP3 audio stream; could not read frame header from first packet.\");\n                }\n                elementaryStream.info.numberOfChannels = result.header.channel === 3 ? 1 : 2;\n                elementaryStream.info.sampleRate = result.header.sampleRate;\n                elementaryStream.initialized = true;\n              } else {\n                throw new Error(\"Unhandled.\");\n              }\n            }\n          }\n        }\n        const isDone = hasProgramMap && this.elementaryStreams.every((x) => x.initialized);\n        if (isDone) {\n          break;\n        }\n        assert(section.endPos !== null);\n        currentPos = section.endPos;\n      }\n      for (const stream of this.elementaryStreams) {\n        if (stream.info.type === \"video\") {\n          this.tracks.push(new InputVideoTrack(this.input, new MpegTsVideoTrackBacking(stream)));\n        } else {\n          this.tracks.push(new InputAudioTrack(this.input, new MpegTsAudioTrackBacking(stream)));\n        }\n      }\n    })();\n  }\n  async getTracks() {\n    await this.readMetadata();\n    return this.tracks;\n  }\n  async getMetadataTags() {\n    return {};\n  }\n  async computeDuration() {\n    const tracks = await this.getTracks();\n    const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));\n    return Math.max(0, ...trackDurations);\n  }\n  async getMimeType() {\n    await this.readMetadata();\n    const tracks = await this.getTracks();\n    const codecStrings = await Promise.all(tracks.map((x) => x.getCodecParameterString()));\n    return buildMpegTsMimeType(codecStrings);\n  }\n  async readSection(startPos, full) {\n    let endPos = startPos;\n    let currentPos = startPos;\n    const chunks = [];\n    let chunksByteLength = 0;\n    let firstPacket = null;\n    while (true) {\n      const packet = await this.readPacket(currentPos);\n      currentPos += this.packetStride;\n      if (!packet) {\n        break;\n      }\n      if (!firstPacket) {\n        if (packet.payloadUnitStartIndicator === 0) {\n          break;\n        }\n        firstPacket = packet;\n      } else {\n        if (packet.pid !== firstPacket.pid) {\n          continue;\n        }\n        if (packet.payloadUnitStartIndicator === 1) {\n          break;\n        }\n      }\n      const hasAdaptationField = !!(packet.adaptationFieldControl & 2);\n      const hasPayload = !!(packet.adaptationFieldControl & 1);\n      let adaptationFieldLength = 0;\n      if (hasAdaptationField) {\n        adaptationFieldLength = 1 + packet.body[0];\n      }\n      if (hasPayload) {\n        if (adaptationFieldLength === 0) {\n          chunks.push(packet.body);\n          chunksByteLength += packet.body.byteLength;\n        } else {\n          chunks.push(packet.body.subarray(adaptationFieldLength));\n          chunksByteLength += packet.body.byteLength - adaptationFieldLength;\n        }\n      }\n      endPos = currentPos;\n      if (!full && chunksByteLength >= 64) {\n        break;\n      }\n    }\n    if (!firstPacket) {\n      return null;\n    }\n    let merged;\n    if (chunks.length === 1) {\n      merged = chunks[0];\n    } else {\n      const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);\n      merged = new Uint8Array(totalLength);\n      let offset = 0;\n      for (const chunk of chunks) {\n        merged.set(chunk, offset);\n        offset += chunk.length;\n      }\n    }\n    return {\n      startPos,\n      endPos: full ? endPos : null,\n      pid: firstPacket.pid,\n      payload: merged\n    };\n  }\n  async readPacketHeader(pos) {\n    let slice = this.reader.requestSlice(pos, 4);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice) {\n      return null;\n    }\n    const syncByte = readU8(slice);\n    if (syncByte !== 71) {\n      throw new Error(\"Invalid TS packet sync byte. Likely an internal bug, please report this file.\");\n    }\n    const nextTwoBytes = readU16Be(slice);\n    const transportErrorIndicator = nextTwoBytes >> 15;\n    const payloadUnitStartIndicator = nextTwoBytes >> 14 & 1;\n    const transportPriority = nextTwoBytes >> 13 & 1;\n    const pid = nextTwoBytes & 8191;\n    const nextByte = readU8(slice);\n    const transportScramblingControl = nextByte >> 6;\n    const adaptationFieldControl = nextByte >> 4 & 3;\n    const continuityCounter = nextByte & 15;\n    return {\n      payloadUnitStartIndicator,\n      pid,\n      adaptationFieldControl\n    };\n  }\n  async readPacket(pos) {\n    let slice = this.reader.requestSlice(pos, TS_PACKET_SIZE);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice) {\n      return null;\n    }\n    const bytes = readBytes(slice, TS_PACKET_SIZE);\n    const syncByte = bytes[0];\n    if (syncByte !== 71) {\n      throw new Error(\"Invalid TS packet sync byte. Likely an internal bug, please report this file.\");\n    }\n    const nextTwoBytes = (bytes[1] << 8) + bytes[2];\n    const transportErrorIndicator = nextTwoBytes >> 15;\n    const payloadUnitStartIndicator = nextTwoBytes >> 14 & 1;\n    const transportPriority = nextTwoBytes >> 13 & 1;\n    const pid = nextTwoBytes & 8191;\n    const nextByte = bytes[3];\n    const transportScramblingControl = nextByte >> 6;\n    const adaptationFieldControl = nextByte >> 4 & 3;\n    const continuityCounter = nextByte & 15;\n    return {\n      payloadUnitStartIndicator,\n      pid,\n      adaptationFieldControl,\n      body: bytes.subarray(4)\n    };\n  }\n}\nvar readPesPacketHeader = (section) => {\n  const bitstream = new Bitstream(section.payload);\n  const startCodePrefix = bitstream.readBits(24);\n  if (startCodePrefix !== 1) {\n    return null;\n  }\n  const streamId = bitstream.readBits(8);\n  bitstream.skipBits(16);\n  if (streamId === 188 || streamId === 190 || streamId === 191 || streamId === 240 || streamId === 241 || streamId === 255 || streamId === 242 || streamId === 248) {\n    return null;\n  }\n  bitstream.skipBits(8);\n  const ptsDtsFlags = bitstream.readBits(2);\n  bitstream.skipBits(14);\n  let pts = 0;\n  if (ptsDtsFlags === 2 || ptsDtsFlags === 3) {\n    bitstream.skipBits(4);\n    pts += bitstream.readBits(3) * (1 << 30);\n    bitstream.skipBits(1);\n    pts += bitstream.readBits(15) * (1 << 15);\n    bitstream.skipBits(1);\n    pts += bitstream.readBits(15);\n  } else {\n    throw new Error(\"PES packets without PTS are not currently supported. If you think this file should be supported,\" + \" please report it.\");\n  }\n  return {\n    sectionStartPos: section.startPos,\n    sectionEndPos: section.endPos,\n    pts\n  };\n};\nvar readPesPacket = (section) => {\n  assert(section.endPos !== null);\n  const header2 = readPesPacketHeader(section);\n  if (!header2) {\n    return null;\n  }\n  const bitstream = new Bitstream(section.payload);\n  bitstream.skipBits(32);\n  const pesPacketLength = bitstream.readBits(16);\n  const BYTES_UNTIL_END_OF_PES_PACKET_LENGTH = 6;\n  bitstream.skipBits(16);\n  const pesHeaderDataLength = bitstream.readBits(8);\n  const pesHeaderEndPos = bitstream.pos + 8 * pesHeaderDataLength;\n  bitstream.pos = pesHeaderEndPos;\n  const bytePos = pesHeaderEndPos / 8;\n  assert(Number.isInteger(bytePos));\n  const data = section.payload.subarray(bytePos, pesPacketLength > 0 ? BYTES_UNTIL_END_OF_PES_PACKET_LENGTH + pesPacketLength : section.payload.byteLength);\n  return {\n    ...header2,\n    data\n  };\n};\n\nclass MpegTsTrackBacking {\n  constructor(elementaryStream) {\n    this.elementaryStream = elementaryStream;\n    this.referencePesPackets = [];\n    this.endReferencePesPacketAdded = false;\n    this.packetBuffers = new WeakMap;\n    this.packetSectionStarts = new WeakMap;\n    this.mutex = new AsyncMutex;\n  }\n  getId() {\n    return this.elementaryStream.pid;\n  }\n  getCodec() {\n    throw new Error(\"Not implemented on base class.\");\n  }\n  getInternalCodecId() {\n    return this.elementaryStream.streamType;\n  }\n  getName() {\n    return null;\n  }\n  getLanguageCode() {\n    return UNDETERMINED_LANGUAGE;\n  }\n  getDisposition() {\n    return DEFAULT_TRACK_DISPOSITION;\n  }\n  getTimeResolution() {\n    return TIMESCALE;\n  }\n  async computeDuration() {\n    const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n    return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n  }\n  async getFirstTimestamp() {\n    const firstPacket = await this.getFirstPacket({ metadataOnly: true });\n    return firstPacket?.timestamp ?? 0;\n  }\n  createEncodedPacket(suppliedPacket, duration, options) {\n    return new EncodedPacket(options.metadataOnly ? PLACEHOLDER_DATA : suppliedPacket.data, this.getPacketType(suppliedPacket.data), suppliedPacket.pts / TIMESCALE, Math.max(duration / TIMESCALE, 0), suppliedPacket.sequenceNumber, suppliedPacket.data.byteLength);\n  }\n  maybeInsertReferencePacket(pesPacketHeader, force, dropIfMutexLocked) {\n    if (dropIfMutexLocked && this.mutex.pending > 0) {\n      return;\n    }\n    const index = binarySearchLessOrEqual(this.referencePesPackets, pesPacketHeader.pts, (x) => x.pts);\n    if (index >= 0) {\n      const entry = this.referencePesPackets[index];\n      if (pesPacketHeader.sectionStartPos <= entry.sectionStartPos) {\n        return false;\n      }\n      if (!force && pesPacketHeader.pts - entry.pts < TIMESCALE / 2) {\n        return false;\n      }\n      if (index < this.referencePesPackets.length - 1) {\n        const nextEntry = this.referencePesPackets[index + 1];\n        if (nextEntry.sectionStartPos < pesPacketHeader.sectionStartPos) {\n          return false;\n        }\n        if (!force && nextEntry.pts - pesPacketHeader.pts < TIMESCALE / 2) {\n          return false;\n        }\n      }\n    }\n    this.referencePesPackets.splice(index + 1, 0, pesPacketHeader);\n    return true;\n  }\n  async getFirstPacket(options) {\n    const section = this.elementaryStream.firstSection;\n    assert(section);\n    const pesPacket = readPesPacket(section);\n    assert(pesPacket);\n    const context = new PacketReadingContext(this, pesPacket, true);\n    const buffer = new PacketBuffer(this, context);\n    const result = await buffer.readNext();\n    if (!result) {\n      return null;\n    }\n    const packet = this.createEncodedPacket(result.packet, result.duration, options);\n    this.packetBuffers.set(packet, buffer);\n    this.packetSectionStarts.set(packet, result.packet.sectionStartPos);\n    return packet;\n  }\n  async getNextPacket(packet, options) {\n    let buffer = this.packetBuffers.get(packet);\n    if (buffer) {\n      const result = await buffer.readNext();\n      if (!result) {\n        return null;\n      }\n      this.packetBuffers.delete(packet);\n      const newPacket = this.createEncodedPacket(result.packet, result.duration, options);\n      this.packetBuffers.set(newPacket, buffer);\n      this.packetSectionStarts.set(newPacket, result.packet.sectionStartPos);\n      return newPacket;\n    }\n    const sectionStartPos = this.packetSectionStarts.get(packet);\n    if (sectionStartPos === undefined) {\n      throw new Error(\"Packet was not created from this track.\");\n    }\n    const demuxer = this.elementaryStream.demuxer;\n    const section = await demuxer.readSection(sectionStartPos, true);\n    assert(section);\n    const pesPacket = readPesPacket(section);\n    assert(pesPacket);\n    const context = new PacketReadingContext(this, pesPacket, true);\n    buffer = new PacketBuffer(this, context);\n    const targetSequenceNumber = packet.sequenceNumber;\n    while (true) {\n      const result = await buffer.readNext();\n      if (!result) {\n        return null;\n      }\n      if (result.packet.sequenceNumber > targetSequenceNumber) {\n        const newPacket = this.createEncodedPacket(result.packet, result.duration, options);\n        this.packetBuffers.set(newPacket, buffer);\n        this.packetSectionStarts.set(newPacket, result.packet.sectionStartPos);\n        return newPacket;\n      }\n    }\n  }\n  async getNextKeyPacket(packet, options) {\n    let currentPacket = packet;\n    while (true) {\n      currentPacket = await this.getNextPacket(currentPacket, options);\n      if (!currentPacket) {\n        return null;\n      }\n      if (currentPacket.type === \"key\") {\n        return currentPacket;\n      }\n    }\n  }\n  getPacket(timestamp, options) {\n    return this.doPacketLookup(timestamp, false, options);\n  }\n  getKeyPacket(timestamp, options) {\n    return this.doPacketLookup(timestamp, true, options);\n  }\n  async doPacketLookup(timestamp, keyframesOnly, options) {\n    const searchPts = roundIfAlmostInteger(timestamp * TIMESCALE);\n    const demuxer = this.elementaryStream.demuxer;\n    const reader = demuxer.reader;\n    const release = await this.mutex.acquire();\n    let currentPesPacketHeader;\n    try {\n      if (this.referencePesPackets.length === 0) {\n        const section2 = this.elementaryStream.firstSection;\n        assert(section2);\n        const pesPacketHeader = readPesPacketHeader(section2);\n        assert(pesPacketHeader);\n        this.maybeInsertReferencePacket(pesPacketHeader, false, false);\n        assert(this.referencePesPackets.length === 1);\n      }\n      let currentIndex = binarySearchLessOrEqual(this.referencePesPackets, searchPts, (x) => x.pts);\n      if (currentIndex === -1) {\n        return null;\n      }\n      const needsToLookForLastPacket = reader.fileSize !== null && currentIndex === this.referencePesPackets.length - 1 && !this.endReferencePesPacketAdded;\n      if (needsToLookForLastPacket) {\n        let currentPos = reader.fileSize - demuxer.packetStride + demuxer.packetOffset;\n        let packetHeader = await demuxer.readPacketHeader(currentPos);\n        if (!packetHeader) {\n          return null;\n        }\n        while (packetHeader.pid !== this.elementaryStream.pid || packetHeader.payloadUnitStartIndicator === 0) {\n          currentPos -= demuxer.packetStride;\n          const previousPacketHeader = await demuxer.readPacketHeader(currentPos);\n          if (!previousPacketHeader) {\n            return null;\n          }\n          packetHeader = previousPacketHeader;\n        }\n        const section2 = await demuxer.readSection(currentPos, false);\n        assert(section2);\n        const pesPacketHeader = readPesPacketHeader(section2);\n        if (!pesPacketHeader) {\n          throw new Error(MISSING_PES_PACKET_ERROR);\n        }\n        this.maybeInsertReferencePacket(pesPacketHeader, true, false);\n        this.endReferencePesPacketAdded = true;\n      }\n      currentIndex = binarySearchLessOrEqual(this.referencePesPackets, searchPts, (x) => x.pts);\n      assert(currentIndex !== -1);\n      while (reader.fileSize !== null) {\n        const currentEntry = this.referencePesPackets[currentIndex];\n        const nextEntry = this.referencePesPackets[currentIndex + 1];\n        if (searchPts - currentEntry.pts < TIMESCALE || !nextEntry) {\n          break;\n        }\n        const midpoint = roundToMultiple((currentEntry.sectionStartPos + nextEntry.sectionStartPos) / 2, demuxer.packetStride) + demuxer.packetOffset;\n        let currentPos = midpoint;\n        let packetHeader = await demuxer.readPacketHeader(currentPos);\n        assert(packetHeader);\n        while (currentPos < nextEntry.sectionStartPos && (packetHeader.pid !== this.elementaryStream.pid || packetHeader.payloadUnitStartIndicator === 0)) {\n          currentPos += demuxer.packetStride;\n          const previousPacketHeader = await demuxer.readPacketHeader(currentPos);\n          if (!previousPacketHeader) {\n            return null;\n          }\n          packetHeader = previousPacketHeader;\n        }\n        if (currentPos >= nextEntry.sectionStartPos) {\n          break;\n        }\n        const section2 = await demuxer.readSection(currentPos, false);\n        assert(section2);\n        const pesPacketHeader = readPesPacketHeader(section2);\n        if (!pesPacketHeader) {\n          throw new Error(MISSING_PES_PACKET_ERROR);\n        }\n        const addedPoint = this.maybeInsertReferencePacket(pesPacketHeader, false, false);\n        if (!addedPoint) {\n          break;\n        }\n        if (pesPacketHeader.pts <= searchPts) {\n          currentIndex++;\n        }\n      }\n      currentPesPacketHeader = this.referencePesPackets[currentIndex];\n      assert(currentPesPacketHeader.pts <= searchPts);\n    } finally {\n      release();\n    }\n    release();\n    outer:\n      while (true) {\n        let currentPos = currentPesPacketHeader.sectionStartPos + demuxer.packetStride;\n        while (true) {\n          const packetHeader = await demuxer.readPacketHeader(currentPos);\n          if (!packetHeader) {\n            break outer;\n          }\n          if (packetHeader.pid === this.elementaryStream.pid && packetHeader.payloadUnitStartIndicator === 1) {\n            break;\n          }\n          currentPos += demuxer.packetStride;\n        }\n        const nextSection = await demuxer.readSection(currentPos, false);\n        if (!nextSection) {\n          break;\n        }\n        const nextPesPacketHeader = readPesPacketHeader(nextSection);\n        if (!nextPesPacketHeader) {\n          throw new Error(MISSING_PES_PACKET_ERROR);\n        }\n        if (nextPesPacketHeader.pts > searchPts) {\n          break;\n        }\n        currentPesPacketHeader = nextPesPacketHeader;\n        if (reader.fileSize === null) {\n          this.maybeInsertReferencePacket(nextPesPacketHeader, false, true);\n        }\n      }\n    const reorderSize = this.getReorderSize();\n    for (let i = 0;i < reorderSize; i++) {\n      let pos = currentPesPacketHeader.sectionStartPos - demuxer.packetStride;\n      while (true) {\n        const packetHeader = await demuxer.readPacketHeader(pos);\n        if (!packetHeader) {\n          break;\n        }\n        if (packetHeader.pid === this.elementaryStream.pid && packetHeader.payloadUnitStartIndicator === 1) {\n          const headerSection = await demuxer.readSection(pos, false);\n          assert(headerSection);\n          const header2 = readPesPacketHeader(headerSection);\n          if (!header2) {\n            throw new Error(MISSING_PES_PACKET_ERROR);\n          }\n          currentPesPacketHeader = header2;\n          break;\n        }\n        pos -= demuxer.packetStride;\n      }\n    }\n    const section = await demuxer.readSection(currentPesPacketHeader.sectionStartPos, true);\n    assert(section);\n    const pesPacket = readPesPacket(section);\n    assert(pesPacket);\n    const context = new PacketReadingContext(this, pesPacket, true);\n    const buffer = new PacketBuffer(this, context);\n    while (true) {\n      const topPts = last(buffer.presentationOrderPackets)?.pts ?? -Infinity;\n      if (topPts >= searchPts) {\n        break;\n      }\n      const didRead = await buffer.readNextDecodeOrderPacket();\n      if (!didRead) {\n        break;\n      }\n    }\n    const targetIndex = findLastIndex(buffer.presentationOrderPackets, (p) => p.pts <= searchPts && (!keyframesOnly || this.getPacketType(p.data) === \"key\"));\n    if (targetIndex !== -1) {\n      const targetPacket = buffer.presentationOrderPackets[targetIndex];\n      const lastDuration = targetIndex === 0 ? 0 : targetPacket.pts - buffer.presentationOrderPackets[targetIndex - 1].pts;\n      while (buffer.decodeOrderPackets[0] !== targetPacket) {\n        buffer.decodeOrderPackets.shift();\n      }\n      buffer.lastDuration = lastDuration;\n      const result = await buffer.readNext();\n      assert(result);\n      const packet = this.createEncodedPacket(result.packet, result.duration, options);\n      this.packetBuffers.set(packet, buffer);\n      this.packetSectionStarts.set(packet, result.packet.sectionStartPos);\n      return packet;\n    }\n    if (!keyframesOnly) {\n      return null;\n    }\n    let searchPos = currentPesPacketHeader.sectionStartPos;\n    while (true) {\n      searchPos -= demuxer.packetStride;\n      const packetHeader = await demuxer.readPacketHeader(searchPos);\n      if (!packetHeader) {\n        return null;\n      }\n      if (packetHeader.pid !== this.elementaryStream.pid || packetHeader.payloadUnitStartIndicator !== 1) {\n        continue;\n      }\n      const section2 = await demuxer.readSection(searchPos, true);\n      assert(section2);\n      const pesPacket2 = readPesPacket(section2);\n      if (!pesPacket2) {\n        throw new Error(MISSING_PES_PACKET_ERROR);\n      }\n      const context2 = new PacketReadingContext(this, pesPacket2, false);\n      await this.markNextPacket(context2);\n      if (!context2.suppliedPacket) {\n        continue;\n      }\n      if (this.getPacketType(context2.suppliedPacket.data) !== \"key\") {\n        continue;\n      }\n      context2.uncapped = true;\n      const buffer2 = new PacketBuffer(this, context2);\n      const result = await buffer2.readNext();\n      assert(result);\n      const packet = this.createEncodedPacket(result.packet, result.duration, options);\n      this.packetBuffers.set(packet, buffer2);\n      this.packetSectionStarts.set(packet, result.packet.sectionStartPos);\n      return packet;\n    }\n  }\n}\n\nclass MpegTsVideoTrackBacking extends MpegTsTrackBacking {\n  constructor(elementaryStream) {\n    super(elementaryStream);\n    this.elementaryStream = elementaryStream;\n    this.decoderConfig = {\n      codec: extractVideoCodecString({\n        width: this.elementaryStream.info.width,\n        height: this.elementaryStream.info.height,\n        codec: this.elementaryStream.info.codec,\n        codecDescription: null,\n        colorSpace: this.elementaryStream.info.colorSpace,\n        avcType: 1,\n        avcCodecInfo: this.elementaryStream.info.avcCodecInfo,\n        hevcCodecInfo: this.elementaryStream.info.hevcCodecInfo,\n        vp9CodecInfo: null,\n        av1CodecInfo: null\n      }),\n      codedWidth: this.elementaryStream.info.width,\n      codedHeight: this.elementaryStream.info.height,\n      colorSpace: this.elementaryStream.info.colorSpace\n    };\n  }\n  getCodec() {\n    return this.elementaryStream.info.codec;\n  }\n  getCodedWidth() {\n    return this.elementaryStream.info.width;\n  }\n  getCodedHeight() {\n    return this.elementaryStream.info.height;\n  }\n  getRotation() {\n    return 0;\n  }\n  async getColorSpace() {\n    return this.elementaryStream.info.colorSpace;\n  }\n  async canBeTransparent() {\n    return false;\n  }\n  async getDecoderConfig() {\n    return this.decoderConfig;\n  }\n  getPacketType(packetData) {\n    return determineVideoPacketType(this.elementaryStream.info.codec, this.decoderConfig, packetData) ?? \"key\";\n  }\n  getReorderSize() {\n    return this.elementaryStream.info.reorderSize;\n  }\n  async markNextPacket(context) {\n    assert(!context.suppliedPacket);\n    const codec = this.elementaryStream.info.codec;\n    const CHUNK_SIZE = 1024;\n    let packetStartPos = null;\n    while (true) {\n      let remaining = context.ensureBuffered(CHUNK_SIZE);\n      if (remaining instanceof Promise)\n        remaining = await remaining;\n      if (remaining === 0) {\n        break;\n      }\n      const chunkStartPos = context.currentPos;\n      const chunk = context.readBytes(remaining);\n      const length = chunk.byteLength;\n      let i = 0;\n      while (i < length) {\n        const zeroIndex = chunk.indexOf(0, i);\n        if (zeroIndex === -1 || zeroIndex >= length) {\n          break;\n        }\n        i = zeroIndex;\n        const posBeforeZero = chunkStartPos + i;\n        if (i + 4 >= length) {\n          context.seekTo(posBeforeZero);\n          break;\n        }\n        const b1 = chunk[i + 1];\n        const b2 = chunk[i + 2];\n        const b3 = chunk[i + 3];\n        let startCodeLength = 0;\n        let nalUnitTypeByte = null;\n        if (b1 === 0 && b2 === 0 && b3 === 1) {\n          startCodeLength = 4;\n          nalUnitTypeByte = chunk[i + 4];\n        } else if (b1 === 0 && b2 === 1) {\n          startCodeLength = 3;\n          nalUnitTypeByte = b3;\n        }\n        if (startCodeLength === 0) {\n          i++;\n          continue;\n        }\n        const startCodePos = posBeforeZero;\n        if (packetStartPos === null) {\n          packetStartPos = startCodePos;\n          i += startCodeLength;\n          continue;\n        }\n        if (nalUnitTypeByte !== null) {\n          const nalUnitType = codec === \"avc\" ? extractNalUnitTypeForAvc(nalUnitTypeByte) : extractNalUnitTypeForHevc(nalUnitTypeByte);\n          const isAud = codec === \"avc\" ? nalUnitType === AvcNalUnitType.AUD : nalUnitType === HevcNalUnitType.AUD_NUT;\n          if (isAud) {\n            const packetLength = startCodePos - packetStartPos;\n            context.seekTo(packetStartPos);\n            return context.supplyPacket(packetLength, 0);\n          }\n        }\n        i += startCodeLength;\n      }\n      if (remaining < CHUNK_SIZE) {\n        break;\n      }\n    }\n    if (packetStartPos !== null) {\n      const packetLength = context.endPos - packetStartPos;\n      context.seekTo(packetStartPos);\n      return context.supplyPacket(packetLength, 0);\n    }\n  }\n}\n\nclass MpegTsAudioTrackBacking extends MpegTsTrackBacking {\n  constructor(elementaryStream) {\n    super(elementaryStream);\n    this.elementaryStream = elementaryStream;\n  }\n  getCodec() {\n    return this.elementaryStream.info.codec;\n  }\n  getNumberOfChannels() {\n    return this.elementaryStream.info.numberOfChannels;\n  }\n  getSampleRate() {\n    return this.elementaryStream.info.sampleRate;\n  }\n  async getDecoderConfig() {\n    return {\n      codec: extractAudioCodecString({\n        codec: this.elementaryStream.info.codec,\n        codecDescription: null,\n        aacCodecInfo: this.elementaryStream.info.aacCodecInfo\n      }),\n      numberOfChannels: this.elementaryStream.info.numberOfChannels,\n      sampleRate: this.elementaryStream.info.sampleRate\n    };\n  }\n  getPacketType(packetData) {\n    return \"key\";\n  }\n  getReorderSize() {\n    return 1;\n  }\n  async markNextPacket(context) {\n    assert(!context.suppliedPacket);\n    const codec = this.elementaryStream.info.codec;\n    const CHUNK_SIZE = 128;\n    while (true) {\n      let remaining = context.ensureBuffered(CHUNK_SIZE);\n      if (remaining instanceof Promise)\n        remaining = await remaining;\n      const startPos = context.currentPos;\n      while (context.currentPos - startPos < remaining) {\n        const byte = context.readU8();\n        if (codec === \"aac\") {\n          if (byte !== 255) {\n            continue;\n          }\n          context.skip(-1);\n          const possibleHeaderStartPos = context.currentPos;\n          let remaining2 = context.ensureBuffered(MAX_ADTS_FRAME_HEADER_SIZE);\n          if (remaining2 instanceof Promise)\n            remaining2 = await remaining2;\n          if (remaining2 < MAX_ADTS_FRAME_HEADER_SIZE) {\n            return;\n          }\n          const headerBytes = context.readBytes(MAX_ADTS_FRAME_HEADER_SIZE);\n          const header2 = readAdtsFrameHeader(FileSlice.tempFromBytes(headerBytes));\n          if (header2) {\n            context.seekTo(possibleHeaderStartPos);\n            let remaining3 = context.ensureBuffered(header2.frameLength);\n            if (remaining3 instanceof Promise)\n              remaining3 = await remaining3;\n            return context.supplyPacket(remaining3, Math.round(SAMPLES_PER_AAC_FRAME * TIMESCALE / this.elementaryStream.info.sampleRate));\n          } else {\n            context.seekTo(possibleHeaderStartPos + 1);\n          }\n        } else if (codec === \"mp3\") {\n          if (byte !== 255) {\n            continue;\n          }\n          context.skip(-1);\n          const possibleHeaderStartPos = context.currentPos;\n          let remaining2 = context.ensureBuffered(FRAME_HEADER_SIZE);\n          if (remaining2 instanceof Promise)\n            remaining2 = await remaining2;\n          if (remaining2 < FRAME_HEADER_SIZE) {\n            return;\n          }\n          const headerBytes = context.readBytes(FRAME_HEADER_SIZE);\n          const word = toDataView(headerBytes).getUint32(0);\n          const result = readMp3FrameHeader(word, null);\n          if (result.header) {\n            context.seekTo(possibleHeaderStartPos);\n            let remaining3 = context.ensureBuffered(result.header.totalSize);\n            if (remaining3 instanceof Promise)\n              remaining3 = await remaining3;\n            const duration = result.header.audioSamplesInFrame * TIMESCALE / this.elementaryStream.info.sampleRate;\n            return context.supplyPacket(remaining3, Math.round(duration));\n          } else {\n            context.seekTo(possibleHeaderStartPos + 1);\n          }\n        } else {\n          throw new Error(\"Unreachable\");\n        }\n      }\n      if (remaining < CHUNK_SIZE) {\n        break;\n      }\n    }\n  }\n}\n\nclass PacketReadingContext {\n  constructor(backing, startingPesPacket, uncapped) {\n    this.currentPos = 0;\n    this.pesPackets = [];\n    this.currentPesPacketIndex = 0;\n    this.currentPesPacketPos = 0;\n    this.endPos = 0;\n    this.nextPts = 0;\n    this.suppliedPacket = null;\n    this.backing = backing;\n    this.pid = backing.elementaryStream.pid;\n    this.demuxer = backing.elementaryStream.demuxer;\n    this.startingPesPacket = startingPesPacket;\n    this.uncapped = uncapped;\n  }\n  clone() {\n    const clone = new PacketReadingContext(this.backing, this.startingPesPacket, true);\n    clone.currentPos = this.currentPos;\n    clone.pesPackets = [...this.pesPackets];\n    clone.currentPesPacketIndex = this.currentPesPacketIndex;\n    clone.currentPesPacketPos = this.currentPesPacketPos;\n    clone.endPos = this.endPos;\n    clone.nextPts = this.nextPts;\n    return clone;\n  }\n  ensureBuffered(length) {\n    const remaining = this.endPos - this.currentPos;\n    if (remaining >= length) {\n      return length;\n    }\n    return this.bufferData(length - remaining).then(() => Math.min(this.endPos - this.currentPos, length));\n  }\n  getCurrentPesPacket() {\n    const packet = this.pesPackets[this.currentPesPacketIndex];\n    assert(packet);\n    return packet;\n  }\n  async bufferData(length) {\n    const targetEndPos = this.endPos + length;\n    while (this.endPos < targetEndPos) {\n      let pesPacket;\n      if (this.pesPackets.length === 0) {\n        pesPacket = this.startingPesPacket;\n      } else {\n        let currentPos = last(this.pesPackets).sectionEndPos;\n        assert(currentPos !== null);\n        while (true) {\n          const packetHeader = await this.demuxer.readPacketHeader(currentPos);\n          if (!packetHeader) {\n            return;\n          }\n          if (packetHeader.pid === this.pid) {\n            break;\n          }\n          currentPos += this.demuxer.packetStride;\n        }\n        const nextSection = await this.demuxer.readSection(currentPos, true);\n        if (!nextSection) {\n          return;\n        }\n        const nextPesPacket = readPesPacket(nextSection);\n        if (!nextPesPacket) {\n          throw new Error(MISSING_PES_PACKET_ERROR);\n        }\n        pesPacket = nextPesPacket;\n      }\n      this.pesPackets.push(pesPacket);\n      this.endPos += pesPacket.data.byteLength;\n      if (this.pesPackets.length === 1) {\n        this.nextPts = pesPacket.pts;\n      }\n    }\n  }\n  readBytes(length) {\n    const currentPesPacket = this.getCurrentPesPacket();\n    const relativeStartOffset = this.currentPos - this.currentPesPacketPos;\n    const relativeEndOffset = relativeStartOffset + length;\n    this.currentPos += length;\n    if (relativeEndOffset <= currentPesPacket.data.byteLength) {\n      return currentPesPacket.data.subarray(relativeStartOffset, relativeEndOffset);\n    }\n    const result = new Uint8Array(length);\n    result.set(currentPesPacket.data.subarray(relativeStartOffset));\n    let offset = currentPesPacket.data.byteLength - relativeStartOffset;\n    while (true) {\n      this.advanceCurrentPacket();\n      const currentPesPacket2 = this.getCurrentPesPacket();\n      const relativeEndOffset2 = length - offset;\n      if (relativeEndOffset2 <= currentPesPacket2.data.byteLength) {\n        result.set(currentPesPacket2.data.subarray(0, relativeEndOffset2), offset);\n        break;\n      }\n      result.set(currentPesPacket2.data, offset);\n      offset += currentPesPacket2.data.byteLength;\n    }\n    return result;\n  }\n  readU8() {\n    let currentPesPacket = this.getCurrentPesPacket();\n    const relativeOffset = this.currentPos - this.currentPesPacketPos;\n    this.currentPos++;\n    if (relativeOffset < currentPesPacket.data.byteLength) {\n      return currentPesPacket.data[relativeOffset];\n    }\n    this.advanceCurrentPacket();\n    currentPesPacket = this.getCurrentPesPacket();\n    return currentPesPacket.data[0];\n  }\n  seekTo(pos) {\n    if (pos === this.currentPos) {\n      return;\n    }\n    if (pos < this.currentPos) {\n      while (pos < this.currentPesPacketPos) {\n        this.currentPesPacketIndex--;\n        const currentPacket = this.getCurrentPesPacket();\n        this.currentPesPacketPos -= currentPacket.data.byteLength;\n        this.nextPts = currentPacket.pts;\n      }\n    } else {\n      while (true) {\n        const currentPesPacket = this.getCurrentPesPacket();\n        const currentEndPos = this.currentPesPacketPos + currentPesPacket.data.byteLength;\n        if (pos < currentEndPos) {\n          break;\n        }\n        this.currentPesPacketPos += currentPesPacket.data.byteLength;\n        this.currentPesPacketIndex++;\n        this.nextPts = this.getCurrentPesPacket().pts;\n      }\n    }\n    this.currentPos = pos;\n  }\n  skip(n) {\n    this.seekTo(this.currentPos + n);\n  }\n  advanceCurrentPacket() {\n    this.currentPesPacketPos += this.getCurrentPesPacket().data.byteLength;\n    this.currentPesPacketIndex++;\n    this.nextPts = this.getCurrentPesPacket().pts;\n  }\n  supplyPacket(packetLength, intrinsicDuration) {\n    const currentPesPacket = this.getCurrentPesPacket();\n    if (!this.uncapped && currentPesPacket !== this.startingPesPacket) {\n      this.suppliedPacket = null;\n      return;\n    }\n    this.backing.maybeInsertReferencePacket(currentPesPacket, false, true);\n    const pts = this.nextPts;\n    this.nextPts += intrinsicDuration;\n    const sectionStartPos = currentPesPacket.sectionStartPos;\n    const sequenceNumber = sectionStartPos + (this.currentPos - this.currentPesPacketPos);\n    const data = this.readBytes(packetLength);\n    this.suppliedPacket = {\n      pts,\n      data,\n      sequenceNumber,\n      sectionStartPos\n    };\n    this.pesPackets.splice(0, this.currentPesPacketIndex);\n    this.currentPesPacketIndex = 0;\n  }\n}\n\nclass PacketBuffer {\n  constructor(backing, context) {\n    this.decodeOrderPackets = [];\n    this.reorderBuffer = [];\n    this.presentationOrderPackets = [];\n    this.reachedEnd = false;\n    this.lastDuration = 0;\n    this.backing = backing;\n    this.context = context;\n    this.reorderSize = backing.getReorderSize();\n    assert(this.reorderSize >= 0);\n  }\n  async readNext() {\n    if (this.decodeOrderPackets.length === 0) {\n      const didRead = await this.readNextDecodeOrderPacket();\n      if (!didRead) {\n        return null;\n      }\n    }\n    await this.ensureCurrentPacketHasNext();\n    const packet = this.decodeOrderPackets[0];\n    const presentationIndex = this.presentationOrderPackets.indexOf(packet);\n    assert(presentationIndex !== -1);\n    let duration;\n    if (presentationIndex === this.presentationOrderPackets.length - 1) {\n      duration = this.lastDuration;\n    } else {\n      const nextPacket = this.presentationOrderPackets[presentationIndex + 1];\n      duration = nextPacket.pts - packet.pts;\n      this.lastDuration = duration;\n    }\n    this.decodeOrderPackets.shift();\n    while (this.presentationOrderPackets.length > 0) {\n      const first = this.presentationOrderPackets[0];\n      if (this.decodeOrderPackets.includes(first)) {\n        break;\n      }\n      this.presentationOrderPackets.shift();\n    }\n    return { packet, duration };\n  }\n  async readNextDecodeOrderPacket() {\n    if (this.reachedEnd) {\n      return false;\n    }\n    let suppliedPacket;\n    if (this.context.suppliedPacket) {\n      suppliedPacket = this.context.suppliedPacket;\n    } else {\n      await this.backing.markNextPacket(this.context);\n      suppliedPacket = this.context.suppliedPacket;\n    }\n    this.context.suppliedPacket = null;\n    if (!suppliedPacket) {\n      this.reachedEnd = true;\n      this.flushReorderBuffer();\n      return false;\n    }\n    this.decodeOrderPackets.push(suppliedPacket);\n    this.processPacketThroughReorderBuffer(suppliedPacket);\n    return true;\n  }\n  async ensureCurrentPacketHasNext() {\n    const current = this.decodeOrderPackets[0];\n    assert(current);\n    while (true) {\n      const presentationIndex = this.presentationOrderPackets.indexOf(current);\n      if (presentationIndex !== -1 && presentationIndex <= this.presentationOrderPackets.length - 2) {\n        break;\n      }\n      const didRead = await this.readNextDecodeOrderPacket();\n      if (!didRead) {\n        break;\n      }\n    }\n  }\n  processPacketThroughReorderBuffer(packet) {\n    this.reorderBuffer.push(packet);\n    if (this.reorderBuffer.length >= this.reorderSize) {\n      let minIndex = 0;\n      for (let i = 1;i < this.reorderBuffer.length; i++) {\n        if (this.reorderBuffer[i].pts < this.reorderBuffer[minIndex].pts) {\n          minIndex = i;\n        }\n      }\n      const packet2 = this.reorderBuffer.splice(minIndex, 1)[0];\n      this.presentationOrderPackets.push(packet2);\n    }\n  }\n  flushReorderBuffer() {\n    this.reorderBuffer.sort((a, b) => a.pts - b.pts);\n    this.presentationOrderPackets.push(...this.reorderBuffer);\n    this.reorderBuffer.length = 0;\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/input-format.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\nclass InputFormat {\n}\n\nclass IsobmffInputFormat extends InputFormat {\n  async _getMajorBrand(input2) {\n    let slice = input2._reader.requestSlice(0, 12);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return null;\n    slice.skip(4);\n    const fourCc = readAscii(slice, 4);\n    if (fourCc !== \"ftyp\") {\n      return null;\n    }\n    return readAscii(slice, 4);\n  }\n  _createDemuxer(input2) {\n    return new IsobmffDemuxer(input2);\n  }\n}\n\nclass Mp4InputFormat extends IsobmffInputFormat {\n  async _canReadInput(input2) {\n    const majorBrand = await this._getMajorBrand(input2);\n    return !!majorBrand && majorBrand !== \"qt  \";\n  }\n  get name() {\n    return \"MP4\";\n  }\n  get mimeType() {\n    return \"video/mp4\";\n  }\n}\n\nclass QuickTimeInputFormat extends IsobmffInputFormat {\n  async _canReadInput(input2) {\n    const majorBrand = await this._getMajorBrand(input2);\n    return majorBrand === \"qt  \";\n  }\n  get name() {\n    return \"QuickTime File Format\";\n  }\n  get mimeType() {\n    return \"video/quicktime\";\n  }\n}\n\nclass MatroskaInputFormat extends InputFormat {\n  async isSupportedEBMLOfDocType(input2, desiredDocType) {\n    let headerSlice = input2._reader.requestSlice(0, MAX_HEADER_SIZE);\n    if (headerSlice instanceof Promise)\n      headerSlice = await headerSlice;\n    if (!headerSlice)\n      return false;\n    const varIntSize = readVarIntSize(headerSlice);\n    if (varIntSize === null) {\n      return false;\n    }\n    if (varIntSize < 1 || varIntSize > 8) {\n      return false;\n    }\n    const id = readUnsignedInt(headerSlice, varIntSize);\n    if (id !== EBMLId.EBML) {\n      return false;\n    }\n    const dataSize = readElementSize(headerSlice);\n    if (typeof dataSize !== \"number\") {\n      return false;\n    }\n    let dataSlice = input2._reader.requestSlice(headerSlice.filePos, dataSize);\n    if (dataSlice instanceof Promise)\n      dataSlice = await dataSlice;\n    if (!dataSlice)\n      return false;\n    const startPos = headerSlice.filePos;\n    while (dataSlice.filePos <= startPos + dataSize - MIN_HEADER_SIZE) {\n      const header2 = readElementHeader(dataSlice);\n      if (!header2)\n        break;\n      const { id: id2, size: size4 } = header2;\n      const dataStartPos = dataSlice.filePos;\n      if (size4 === undefined)\n        return false;\n      switch (id2) {\n        case EBMLId.EBMLVersion:\n          {\n            const ebmlVersion = readUnsignedInt(dataSlice, size4);\n            if (ebmlVersion !== 1) {\n              return false;\n            }\n          }\n          ;\n          break;\n        case EBMLId.EBMLReadVersion:\n          {\n            const ebmlReadVersion = readUnsignedInt(dataSlice, size4);\n            if (ebmlReadVersion !== 1) {\n              return false;\n            }\n          }\n          ;\n          break;\n        case EBMLId.DocType:\n          {\n            const docType = readAsciiString(dataSlice, size4);\n            if (docType !== desiredDocType) {\n              return false;\n            }\n          }\n          ;\n          break;\n        case EBMLId.DocTypeVersion:\n          {\n            const docTypeVersion = readUnsignedInt(dataSlice, size4);\n            if (docTypeVersion > 4) {\n              return false;\n            }\n          }\n          ;\n          break;\n      }\n      dataSlice.filePos = dataStartPos + size4;\n    }\n    return true;\n  }\n  _canReadInput(input2) {\n    return this.isSupportedEBMLOfDocType(input2, \"matroska\");\n  }\n  _createDemuxer(input2) {\n    return new MatroskaDemuxer(input2);\n  }\n  get name() {\n    return \"Matroska\";\n  }\n  get mimeType() {\n    return \"video/x-matroska\";\n  }\n}\n\nclass WebMInputFormat extends MatroskaInputFormat {\n  _canReadInput(input2) {\n    return this.isSupportedEBMLOfDocType(input2, \"webm\");\n  }\n  get name() {\n    return \"WebM\";\n  }\n  get mimeType() {\n    return \"video/webm\";\n  }\n}\n\nclass Mp3InputFormat extends InputFormat {\n  async _canReadInput(input2) {\n    let slice = input2._reader.requestSlice(0, 10);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return false;\n    let currentPos = 0;\n    let id3V2HeaderFound = false;\n    while (true) {\n      let slice2 = input2._reader.requestSlice(currentPos, ID3_V2_HEADER_SIZE);\n      if (slice2 instanceof Promise)\n        slice2 = await slice2;\n      if (!slice2)\n        break;\n      const id3V2Header = readId3V2Header(slice2);\n      if (!id3V2Header) {\n        break;\n      }\n      id3V2HeaderFound = true;\n      currentPos = slice2.filePos + id3V2Header.size;\n    }\n    const firstResult = await readNextMp3FrameHeader(input2._reader, currentPos, currentPos + 4096);\n    if (!firstResult) {\n      return false;\n    }\n    if (id3V2HeaderFound) {\n      return true;\n    }\n    currentPos = firstResult.startPos + firstResult.header.totalSize;\n    const secondResult = await readNextMp3FrameHeader(input2._reader, currentPos, currentPos + FRAME_HEADER_SIZE);\n    if (!secondResult) {\n      return false;\n    }\n    const firstHeader = firstResult.header;\n    const secondHeader = secondResult.header;\n    if (firstHeader.channel !== secondHeader.channel || firstHeader.sampleRate !== secondHeader.sampleRate) {\n      return false;\n    }\n    return true;\n  }\n  _createDemuxer(input2) {\n    return new Mp3Demuxer(input2);\n  }\n  get name() {\n    return \"MP3\";\n  }\n  get mimeType() {\n    return \"audio/mpeg\";\n  }\n}\n\nclass WaveInputFormat extends InputFormat {\n  async _canReadInput(input2) {\n    let slice = input2._reader.requestSlice(0, 12);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return false;\n    const riffType = readAscii(slice, 4);\n    if (riffType !== \"RIFF\" && riffType !== \"RIFX\" && riffType !== \"RF64\") {\n      return false;\n    }\n    slice.skip(4);\n    const format = readAscii(slice, 4);\n    return format === \"WAVE\";\n  }\n  _createDemuxer(input2) {\n    return new WaveDemuxer(input2);\n  }\n  get name() {\n    return \"WAVE\";\n  }\n  get mimeType() {\n    return \"audio/wav\";\n  }\n}\n\nclass OggInputFormat extends InputFormat {\n  async _canReadInput(input2) {\n    let slice = input2._reader.requestSlice(0, 4);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return false;\n    return readAscii(slice, 4) === \"OggS\";\n  }\n  _createDemuxer(input2) {\n    return new OggDemuxer(input2);\n  }\n  get name() {\n    return \"Ogg\";\n  }\n  get mimeType() {\n    return \"application/ogg\";\n  }\n}\n\nclass FlacInputFormat extends InputFormat {\n  async _canReadInput(input2) {\n    let slice = input2._reader.requestSlice(0, 4);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return false;\n    return readAscii(slice, 4) === \"fLaC\";\n  }\n  get name() {\n    return \"FLAC\";\n  }\n  get mimeType() {\n    return \"audio/flac\";\n  }\n  _createDemuxer(input2) {\n    return new FlacDemuxer(input2);\n  }\n}\n\nclass AdtsInputFormat extends InputFormat {\n  async _canReadInput(input2) {\n    let slice = input2._reader.requestSliceRange(0, MIN_ADTS_FRAME_HEADER_SIZE, MAX_ADTS_FRAME_HEADER_SIZE);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return false;\n    const firstHeader = readAdtsFrameHeader(slice);\n    if (!firstHeader) {\n      return false;\n    }\n    slice = input2._reader.requestSliceRange(firstHeader.frameLength, MIN_ADTS_FRAME_HEADER_SIZE, MAX_ADTS_FRAME_HEADER_SIZE);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return false;\n    const secondHeader = readAdtsFrameHeader(slice);\n    if (!secondHeader) {\n      return false;\n    }\n    return firstHeader.objectType === secondHeader.objectType && firstHeader.samplingFrequencyIndex === secondHeader.samplingFrequencyIndex && firstHeader.channelConfiguration === secondHeader.channelConfiguration;\n  }\n  _createDemuxer(input2) {\n    return new AdtsDemuxer(input2);\n  }\n  get name() {\n    return \"ADTS\";\n  }\n  get mimeType() {\n    return \"audio/aac\";\n  }\n}\n\nclass MpegTsInputFormat extends InputFormat {\n  async _canReadInput(input2) {\n    const lengthToCheck = TS_PACKET_SIZE + 16 + 1;\n    let slice = input2._reader.requestSlice(0, lengthToCheck);\n    if (slice instanceof Promise)\n      slice = await slice;\n    if (!slice)\n      return false;\n    const bytes = readBytes(slice, lengthToCheck);\n    if (bytes[0] === 71 && bytes[TS_PACKET_SIZE] === 71) {\n      return true;\n    } else if (bytes[0] === 71 && bytes[TS_PACKET_SIZE + 16] === 71) {\n      return true;\n    } else if (bytes[4] === 71 && bytes[4 + TS_PACKET_SIZE] === 71) {\n      return true;\n    }\n    return false;\n  }\n  _createDemuxer(input2) {\n    return new MpegTsDemuxer(input2);\n  }\n  get name() {\n    return \"MPEG Transport Stream\";\n  }\n  get mimeType() {\n    return \"video/MP2T\";\n  }\n}\nvar MP4 = /* @__PURE__ */ new Mp4InputFormat;\nvar QTFF = /* @__PURE__ */ new QuickTimeInputFormat;\nvar MATROSKA = /* @__PURE__ */ new MatroskaInputFormat;\nvar WEBM = /* @__PURE__ */ new WebMInputFormat;\nvar MP3 = /* @__PURE__ */ new Mp3InputFormat;\nvar WAVE = /* @__PURE__ */ new WaveInputFormat;\nvar OGG = /* @__PURE__ */ new OggInputFormat;\nvar ADTS = /* @__PURE__ */ new AdtsInputFormat;\nvar FLAC = /* @__PURE__ */ new FlacInputFormat;\nvar MPEG_TS = /* @__PURE__ */ new MpegTsInputFormat;\nvar ALL_FORMATS = [MP4, QTFF, MATROSKA, WEBM, WAVE, OGG, FLAC, MP3, ADTS, MPEG_TS];\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/source.js\nvar nodeAlias = (() => ({}));\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\nclass Source {\n  constructor() {\n    this._disposed = false;\n    this._sizePromise = null;\n    this.onread = null;\n  }\n  async getSizeOrNull() {\n    if (this._disposed) {\n      throw new InputDisposedError;\n    }\n    return this._sizePromise ??= Promise.resolve(this._retrieveSize());\n  }\n  async getSize() {\n    if (this._disposed) {\n      throw new InputDisposedError;\n    }\n    const result = await this.getSizeOrNull();\n    if (result === null) {\n      throw new Error(\"Cannot determine the size of an unsized source.\");\n    }\n    return result;\n  }\n}\nvar URL_SOURCE_MIN_LOAD_AMOUNT = 0.5 * 2 ** 20;\nvar DEFAULT_RETRY_DELAY = (previousAttempts, error, src) => {\n  const couldBeCorsError = error instanceof Error && (error.message.includes(\"Failed to fetch\") || error.message.includes(\"Load failed\") || error.message.includes(\"NetworkError when attempting to fetch resource\"));\n  if (couldBeCorsError) {\n    let originOfSrc = null;\n    try {\n      if (typeof window !== \"undefined\" && typeof window.location !== \"undefined\") {\n        originOfSrc = new URL(src instanceof Request ? src.url : src, window.location.href).origin;\n      }\n    } catch {}\n    const isOnline = typeof navigator !== \"undefined\" && typeof navigator.onLine === \"boolean\" ? navigator.onLine : true;\n    if (isOnline && originOfSrc !== null && originOfSrc !== window.location.origin) {\n      console.warn(`Request will not be retried because a CORS error was suspected due to different origins. You can` + ` modify this behavior by providing your own function for the 'getRetryDelay' option.`);\n      return null;\n    }\n  }\n  return Math.min(2 ** (previousAttempts - 2), 16);\n};\n\nclass UrlSource extends Source {\n  constructor(url, options = {}) {\n    if (typeof url !== \"string\" && !(url instanceof URL) && !(typeof Request !== \"undefined\" && url instanceof Request)) {\n      throw new TypeError(\"url must be a string, URL or Request.\");\n    }\n    if (!options || typeof options !== \"object\") {\n      throw new TypeError(\"options must be an object.\");\n    }\n    if (options.requestInit !== undefined && (!options.requestInit || typeof options.requestInit !== \"object\")) {\n      throw new TypeError(\"options.requestInit, when provided, must be an object.\");\n    }\n    if (options.getRetryDelay !== undefined && typeof options.getRetryDelay !== \"function\") {\n      throw new TypeError(\"options.getRetryDelay, when provided, must be a function.\");\n    }\n    if (options.maxCacheSize !== undefined && (!isNumber(options.maxCacheSize) || options.maxCacheSize < 0)) {\n      throw new TypeError(\"options.maxCacheSize, when provided, must be a non-negative number.\");\n    }\n    if (options.fetchFn !== undefined && typeof options.fetchFn !== \"function\") {\n      throw new TypeError(\"options.fetchFn, when provided, must be a function.\");\n    }\n    super();\n    this._existingResponses = new WeakMap;\n    this._url = url;\n    this._options = options;\n    this._getRetryDelay = options.getRetryDelay ?? DEFAULT_RETRY_DELAY;\n    this._orchestrator = new ReadOrchestrator({\n      maxCacheSize: options.maxCacheSize ?? 64 * 2 ** 20,\n      maxWorkerCount: 2,\n      runWorker: this._runWorker.bind(this),\n      prefetchProfile: PREFETCH_PROFILES.network\n    });\n  }\n  async _retrieveSize() {\n    const abortController = new AbortController;\n    const response = await retriedFetch(this._options.fetchFn ?? fetch, this._url, mergeRequestInit(this._options.requestInit ?? {}, {\n      headers: {\n        Range: \"bytes=0-\"\n      },\n      signal: abortController.signal\n    }), this._getRetryDelay, () => this._disposed);\n    if (!response.ok) {\n      throw new Error(`Error fetching ${String(this._url)}: ${response.status} ${response.statusText}`);\n    }\n    let worker;\n    let fileSize;\n    if (response.status === 206) {\n      fileSize = this._getTotalLengthFromRangeResponse(response);\n      worker = this._orchestrator.createWorker(0, Math.min(fileSize, URL_SOURCE_MIN_LOAD_AMOUNT));\n    } else {\n      const contentLength = response.headers.get(\"Content-Length\");\n      if (contentLength) {\n        fileSize = Number(contentLength);\n        worker = this._orchestrator.createWorker(0, fileSize);\n        this._orchestrator.options.maxCacheSize = Infinity;\n        console.warn(\"HTTP server did not respond with 206 Partial Content, meaning the entire remote resource now has\" + \" to be downloaded. For efficient media file streaming across a network, please make sure your\" + \" server supports range requests.\");\n      } else {\n        throw new Error(`HTTP response (status ${response.status}) must surface Content-Length header.`);\n      }\n    }\n    this._orchestrator.fileSize = fileSize;\n    this._existingResponses.set(worker, { response, abortController });\n    this._orchestrator.runWorker(worker);\n    return fileSize;\n  }\n  _read(start, end) {\n    return this._orchestrator.read(start, end);\n  }\n  async _runWorker(worker) {\n    while (true) {\n      const existing = this._existingResponses.get(worker);\n      this._existingResponses.delete(worker);\n      let abortController = existing?.abortController;\n      let response = existing?.response;\n      if (!abortController) {\n        abortController = new AbortController;\n        response = await retriedFetch(this._options.fetchFn ?? fetch, this._url, mergeRequestInit(this._options.requestInit ?? {}, {\n          headers: {\n            Range: `bytes=${worker.currentPos}-`\n          },\n          signal: abortController.signal\n        }), this._getRetryDelay, () => this._disposed);\n      }\n      assert(response);\n      if (!response.ok) {\n        throw new Error(`Error fetching ${String(this._url)}: ${response.status} ${response.statusText}`);\n      }\n      if (worker.currentPos > 0 && response.status !== 206) {\n        throw new Error(\"HTTP server did not respond with 206 Partial Content to a range request. To enable efficient media\" + \" file streaming across a network, please make sure your server supports range requests.\");\n      }\n      if (!response.body) {\n        throw new Error(\"Missing HTTP response body stream. The used fetch function must provide the response body as a\" + \" ReadableStream.\");\n      }\n      const reader = response.body.getReader();\n      while (true) {\n        if (worker.currentPos >= worker.targetPos || worker.aborted) {\n          abortController.abort();\n          worker.running = false;\n          return;\n        }\n        let readResult;\n        try {\n          readResult = await reader.read();\n        } catch (error) {\n          if (this._disposed) {\n            throw error;\n          }\n          const retryDelayInSeconds = this._getRetryDelay(1, error, this._url);\n          if (retryDelayInSeconds !== null) {\n            console.error(\"Error while reading response stream. Attempting to resume.\", error);\n            await new Promise((resolve) => setTimeout(resolve, 1000 * retryDelayInSeconds));\n            break;\n          } else {\n            throw error;\n          }\n        }\n        if (worker.aborted) {\n          continue;\n        }\n        const { done, value } = readResult;\n        if (done) {\n          if (worker.currentPos >= worker.targetPos) {\n            this._orchestrator.forgetWorker(worker);\n            worker.running = false;\n            return;\n          }\n          break;\n        }\n        this.onread?.(worker.currentPos, worker.currentPos + value.length);\n        this._orchestrator.supplyWorkerData(worker, value);\n      }\n    }\n  }\n  _getTotalLengthFromRangeResponse(response) {\n    const contentRange = response.headers.get(\"Content-Range\");\n    if (contentRange) {\n      const match = /\\/(\\d+)/.exec(contentRange);\n      if (match) {\n        return Number(match[1]);\n      }\n    }\n    const contentLength = response.headers.get(\"Content-Length\");\n    if (contentLength) {\n      return Number(contentLength);\n    } else {\n      throw new Error(\"Partial HTTP response (status 206) must surface either Content-Range or\" + \" Content-Length header.\");\n    }\n  }\n  _dispose() {\n    this._orchestrator.dispose();\n  }\n}\nvar PREFETCH_PROFILES = {\n  none: (start, end) => ({ start, end }),\n  fileSystem: (start, end) => {\n    const padding3 = 2 ** 16;\n    start = Math.floor((start - padding3) / padding3) * padding3;\n    end = Math.ceil((end + padding3) / padding3) * padding3;\n    return { start, end };\n  },\n  network: (start, end, workers) => {\n    const paddingStart = 2 ** 16;\n    start = Math.max(0, Math.floor((start - paddingStart) / paddingStart) * paddingStart);\n    for (const worker of workers) {\n      const maxExtensionAmount = 8 * 2 ** 20;\n      const thresholdPoint = Math.max((worker.startPos + worker.targetPos) / 2, worker.targetPos - maxExtensionAmount);\n      if (closedIntervalsOverlap(start, end, thresholdPoint, worker.targetPos)) {\n        const size4 = worker.targetPos - worker.startPos;\n        const a = Math.ceil((size4 + 1) / maxExtensionAmount) * maxExtensionAmount;\n        const b = 2 ** Math.ceil(Math.log2(size4 + 1));\n        const extent = Math.min(b, a);\n        end = Math.max(end, worker.startPos + extent);\n      }\n    }\n    end = Math.max(end, start + URL_SOURCE_MIN_LOAD_AMOUNT);\n    return {\n      start,\n      end\n    };\n  }\n};\n\nclass ReadOrchestrator {\n  constructor(options) {\n    this.options = options;\n    this.fileSize = null;\n    this.nextAge = 0;\n    this.workers = [];\n    this.cache = [];\n    this.currentCacheSize = 0;\n    this.disposed = false;\n  }\n  read(innerStart, innerEnd) {\n    assert(this.fileSize !== null);\n    const prefetchRange = this.options.prefetchProfile(innerStart, innerEnd, this.workers);\n    const outerStart = Math.max(prefetchRange.start, 0);\n    const outerEnd = Math.min(prefetchRange.end, this.fileSize);\n    assert(outerStart <= innerStart && innerEnd <= outerEnd);\n    let result = null;\n    const innerCacheStartIndex = binarySearchLessOrEqual(this.cache, innerStart, (x) => x.start);\n    const innerStartEntry = innerCacheStartIndex !== -1 ? this.cache[innerCacheStartIndex] : null;\n    if (innerStartEntry && innerStartEntry.start <= innerStart && innerEnd <= innerStartEntry.end) {\n      innerStartEntry.age = this.nextAge++;\n      result = {\n        bytes: innerStartEntry.bytes,\n        view: innerStartEntry.view,\n        offset: innerStartEntry.start\n      };\n    }\n    const outerCacheStartIndex = binarySearchLessOrEqual(this.cache, outerStart, (x) => x.start);\n    const bytes = result ? null : new Uint8Array(innerEnd - innerStart);\n    let contiguousBytesWriteEnd = 0;\n    let lastEnd = outerStart;\n    const outerHoles = [];\n    if (outerCacheStartIndex !== -1) {\n      for (let i = outerCacheStartIndex;i < this.cache.length; i++) {\n        const entry = this.cache[i];\n        if (entry.start >= outerEnd) {\n          break;\n        }\n        if (entry.end <= outerStart) {\n          continue;\n        }\n        const cappedOuterStart = Math.max(outerStart, entry.start);\n        const cappedOuterEnd = Math.min(outerEnd, entry.end);\n        assert(cappedOuterStart <= cappedOuterEnd);\n        if (lastEnd < cappedOuterStart) {\n          outerHoles.push({ start: lastEnd, end: cappedOuterStart });\n        }\n        lastEnd = cappedOuterEnd;\n        if (bytes) {\n          const cappedInnerStart = Math.max(innerStart, entry.start);\n          const cappedInnerEnd = Math.min(innerEnd, entry.end);\n          if (cappedInnerStart < cappedInnerEnd) {\n            const relativeOffset = cappedInnerStart - innerStart;\n            bytes.set(entry.bytes.subarray(cappedInnerStart - entry.start, cappedInnerEnd - entry.start), relativeOffset);\n            if (relativeOffset === contiguousBytesWriteEnd) {\n              contiguousBytesWriteEnd = cappedInnerEnd - innerStart;\n            }\n          }\n        }\n        entry.age = this.nextAge++;\n      }\n      if (lastEnd < outerEnd) {\n        outerHoles.push({ start: lastEnd, end: outerEnd });\n      }\n    } else {\n      outerHoles.push({ start: outerStart, end: outerEnd });\n    }\n    if (bytes && contiguousBytesWriteEnd >= bytes.length) {\n      result = {\n        bytes,\n        view: toDataView(bytes),\n        offset: innerStart\n      };\n    }\n    if (outerHoles.length === 0) {\n      assert(result);\n      return result;\n    }\n    const { promise, resolve, reject } = promiseWithResolvers();\n    const innerHoles = [];\n    for (const outerHole of outerHoles) {\n      const cappedStart = Math.max(innerStart, outerHole.start);\n      const cappedEnd = Math.min(innerEnd, outerHole.end);\n      if (cappedStart === outerHole.start && cappedEnd === outerHole.end) {\n        innerHoles.push(outerHole);\n      } else if (cappedStart < cappedEnd) {\n        innerHoles.push({ start: cappedStart, end: cappedEnd });\n      }\n    }\n    for (const outerHole of outerHoles) {\n      const pendingSlice = bytes && {\n        start: innerStart,\n        bytes,\n        holes: innerHoles,\n        resolve,\n        reject\n      };\n      let workerFound = false;\n      for (const worker of this.workers) {\n        const gapTolerance = 2 ** 17;\n        if (closedIntervalsOverlap(outerHole.start - gapTolerance, outerHole.start, worker.currentPos, worker.targetPos)) {\n          worker.targetPos = Math.max(worker.targetPos, outerHole.end);\n          workerFound = true;\n          if (pendingSlice && !worker.pendingSlices.includes(pendingSlice)) {\n            worker.pendingSlices.push(pendingSlice);\n          }\n          if (!worker.running) {\n            this.runWorker(worker);\n          }\n          break;\n        }\n      }\n      if (!workerFound) {\n        const newWorker = this.createWorker(outerHole.start, outerHole.end);\n        if (pendingSlice) {\n          newWorker.pendingSlices = [pendingSlice];\n        }\n        this.runWorker(newWorker);\n      }\n    }\n    if (!result) {\n      assert(bytes);\n      result = promise.then((bytes2) => ({\n        bytes: bytes2,\n        view: toDataView(bytes2),\n        offset: innerStart\n      }));\n    } else {}\n    return result;\n  }\n  createWorker(startPos, targetPos) {\n    const worker = {\n      startPos,\n      currentPos: startPos,\n      targetPos,\n      running: false,\n      aborted: this.disposed,\n      pendingSlices: [],\n      age: this.nextAge++\n    };\n    this.workers.push(worker);\n    while (this.workers.length > this.options.maxWorkerCount) {\n      let oldestIndex = 0;\n      let oldestWorker = this.workers[0];\n      for (let i = 1;i < this.workers.length; i++) {\n        const worker2 = this.workers[i];\n        if (worker2.age < oldestWorker.age) {\n          oldestIndex = i;\n          oldestWorker = worker2;\n        }\n      }\n      if (oldestWorker.running && oldestWorker.pendingSlices.length > 0) {\n        break;\n      }\n      oldestWorker.aborted = true;\n      this.workers.splice(oldestIndex, 1);\n    }\n    return worker;\n  }\n  runWorker(worker) {\n    assert(!worker.running);\n    assert(worker.currentPos < worker.targetPos);\n    worker.running = true;\n    worker.age = this.nextAge++;\n    this.options.runWorker(worker).catch((error) => {\n      worker.running = false;\n      if (worker.pendingSlices.length > 0) {\n        worker.pendingSlices.forEach((x) => x.reject(error));\n        worker.pendingSlices.length = 0;\n      } else {\n        throw error;\n      }\n    });\n  }\n  supplyWorkerData(worker, bytes) {\n    assert(!worker.aborted);\n    const start = worker.currentPos;\n    const end = start + bytes.length;\n    this.insertIntoCache({\n      start,\n      end,\n      bytes,\n      view: toDataView(bytes),\n      age: this.nextAge++\n    });\n    worker.currentPos += bytes.length;\n    worker.targetPos = Math.max(worker.targetPos, worker.currentPos);\n    for (let i = 0;i < worker.pendingSlices.length; i++) {\n      const pendingSlice = worker.pendingSlices[i];\n      const clampedStart = Math.max(start, pendingSlice.start);\n      const clampedEnd = Math.min(end, pendingSlice.start + pendingSlice.bytes.length);\n      if (clampedStart < clampedEnd) {\n        pendingSlice.bytes.set(bytes.subarray(clampedStart - start, clampedEnd - start), clampedStart - pendingSlice.start);\n      }\n      for (let j = 0;j < pendingSlice.holes.length; j++) {\n        const hole = pendingSlice.holes[j];\n        if (start <= hole.start && end > hole.start) {\n          hole.start = end;\n        }\n        if (hole.end <= hole.start) {\n          pendingSlice.holes.splice(j, 1);\n          j--;\n        }\n      }\n      if (pendingSlice.holes.length === 0) {\n        pendingSlice.resolve(pendingSlice.bytes);\n        worker.pendingSlices.splice(i, 1);\n        i--;\n      }\n    }\n    for (let i = 0;i < this.workers.length; i++) {\n      const otherWorker = this.workers[i];\n      if (worker === otherWorker || otherWorker.running) {\n        continue;\n      }\n      if (closedIntervalsOverlap(start, end, otherWorker.currentPos, otherWorker.targetPos)) {\n        this.workers.splice(i, 1);\n        i--;\n      }\n    }\n  }\n  forgetWorker(worker) {\n    const index = this.workers.indexOf(worker);\n    assert(index !== -1);\n    this.workers.splice(index, 1);\n  }\n  insertIntoCache(entry) {\n    if (this.options.maxCacheSize === 0) {\n      return;\n    }\n    let insertionIndex = binarySearchLessOrEqual(this.cache, entry.start, (x) => x.start) + 1;\n    if (insertionIndex > 0) {\n      const previous = this.cache[insertionIndex - 1];\n      if (previous.end >= entry.end) {\n        return;\n      }\n      if (previous.end > entry.start) {\n        const joined = new Uint8Array(entry.end - previous.start);\n        joined.set(previous.bytes, 0);\n        joined.set(entry.bytes, entry.start - previous.start);\n        this.currentCacheSize += entry.end - previous.end;\n        previous.bytes = joined;\n        previous.view = toDataView(joined);\n        previous.end = entry.end;\n        insertionIndex--;\n        entry = previous;\n      } else {\n        this.cache.splice(insertionIndex, 0, entry);\n        this.currentCacheSize += entry.bytes.length;\n      }\n    } else {\n      this.cache.splice(insertionIndex, 0, entry);\n      this.currentCacheSize += entry.bytes.length;\n    }\n    for (let i = insertionIndex + 1;i < this.cache.length; i++) {\n      const next = this.cache[i];\n      if (entry.end <= next.start) {\n        break;\n      }\n      if (entry.end >= next.end) {\n        this.cache.splice(i, 1);\n        this.currentCacheSize -= next.bytes.length;\n        i--;\n        continue;\n      }\n      const joined = new Uint8Array(next.end - entry.start);\n      joined.set(entry.bytes, 0);\n      joined.set(next.bytes, next.start - entry.start);\n      this.currentCacheSize -= entry.end - next.start;\n      entry.bytes = joined;\n      entry.view = toDataView(joined);\n      entry.end = next.end;\n      this.cache.splice(i, 1);\n      break;\n    }\n    while (this.currentCacheSize > this.options.maxCacheSize) {\n      let oldestIndex = 0;\n      let oldestEntry = this.cache[0];\n      for (let i = 1;i < this.cache.length; i++) {\n        const entry2 = this.cache[i];\n        if (entry2.age < oldestEntry.age) {\n          oldestIndex = i;\n          oldestEntry = entry2;\n        }\n      }\n      if (this.currentCacheSize - oldestEntry.bytes.length <= this.options.maxCacheSize) {\n        break;\n      }\n      this.cache.splice(oldestIndex, 1);\n      this.currentCacheSize -= oldestEntry.bytes.length;\n    }\n  }\n  dispose() {\n    for (const worker of this.workers) {\n      worker.aborted = true;\n    }\n    this.workers.length = 0;\n    this.cache.length = 0;\n    this.disposed = true;\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/input.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\npolyfillSymbolDispose();\n\nclass Input {\n  get disposed() {\n    return this._disposed;\n  }\n  constructor(options) {\n    this._demuxerPromise = null;\n    this._format = null;\n    this._disposed = false;\n    if (!options || typeof options !== \"object\") {\n      throw new TypeError(\"options must be an object.\");\n    }\n    if (!Array.isArray(options.formats) || options.formats.some((x) => !(x instanceof InputFormat))) {\n      throw new TypeError(\"options.formats must be an array of InputFormat.\");\n    }\n    if (!(options.source instanceof Source)) {\n      throw new TypeError(\"options.source must be a Source.\");\n    }\n    if (options.source._disposed) {\n      throw new Error(\"options.source must not be disposed.\");\n    }\n    this._formats = options.formats;\n    this._source = options.source;\n    this._reader = new Reader(options.source);\n  }\n  _getDemuxer() {\n    return this._demuxerPromise ??= (async () => {\n      this._reader.fileSize = await this._source.getSizeOrNull();\n      for (const format of this._formats) {\n        const canRead = await format._canReadInput(this);\n        if (canRead) {\n          this._format = format;\n          return format._createDemuxer(this);\n        }\n      }\n      throw new Error(\"Input has an unsupported or unrecognizable format.\");\n    })();\n  }\n  get source() {\n    return this._source;\n  }\n  async getFormat() {\n    await this._getDemuxer();\n    assert(this._format);\n    return this._format;\n  }\n  async computeDuration() {\n    const demuxer = await this._getDemuxer();\n    return demuxer.computeDuration();\n  }\n  async getFirstTimestamp() {\n    const tracks = await this.getTracks();\n    if (tracks.length === 0) {\n      return 0;\n    }\n    const firstTimestamps = await Promise.all(tracks.map((x) => x.getFirstTimestamp()));\n    return Math.min(...firstTimestamps);\n  }\n  async getTracks() {\n    const demuxer = await this._getDemuxer();\n    return demuxer.getTracks();\n  }\n  async getVideoTracks() {\n    const tracks = await this.getTracks();\n    return tracks.filter((x) => x.isVideoTrack());\n  }\n  async getAudioTracks() {\n    const tracks = await this.getTracks();\n    return tracks.filter((x) => x.isAudioTrack());\n  }\n  async getPrimaryVideoTrack() {\n    const tracks = await this.getTracks();\n    return tracks.find((x) => x.isVideoTrack()) ?? null;\n  }\n  async getPrimaryAudioTrack() {\n    const tracks = await this.getTracks();\n    return tracks.find((x) => x.isAudioTrack()) ?? null;\n  }\n  async getMimeType() {\n    const demuxer = await this._getDemuxer();\n    return demuxer.getMimeType();\n  }\n  async getMetadataTags() {\n    const demuxer = await this._getDemuxer();\n    return demuxer.getMetadataTags();\n  }\n  dispose() {\n    if (this._disposed) {\n      return;\n    }\n    this._disposed = true;\n    this._source._disposed = true;\n    this._source._dispose();\n  }\n  [Symbol.dispose]() {\n    this.dispose();\n  }\n}\n\nclass InputDisposedError extends Error {\n  constructor(message = \"Input has been disposed.\") {\n    super(message);\n    this.name = \"InputDisposedError\";\n  }\n}\n\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/reader.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\nclass Reader {\n  constructor(source) {\n    this.source = source;\n  }\n  requestSlice(start, length) {\n    if (this.source._disposed) {\n      throw new InputDisposedError;\n    }\n    if (start < 0) {\n      return null;\n    }\n    if (this.fileSize !== null && start + length > this.fileSize) {\n      return null;\n    }\n    const end = start + length;\n    const result = this.source._read(start, end);\n    if (result instanceof Promise) {\n      return result.then((x) => {\n        if (!x) {\n          return null;\n        }\n        return new FileSlice(x.bytes, x.view, x.offset, start, end);\n      });\n    } else {\n      if (!result) {\n        return null;\n      }\n      return new FileSlice(result.bytes, result.view, result.offset, start, end);\n    }\n  }\n  requestSliceRange(start, minLength, maxLength) {\n    if (this.source._disposed) {\n      throw new InputDisposedError;\n    }\n    if (start < 0) {\n      return null;\n    }\n    if (this.fileSize !== null) {\n      return this.requestSlice(start, clamp(this.fileSize - start, minLength, maxLength));\n    } else {\n      const promisedAttempt = this.requestSlice(start, maxLength);\n      const handleAttempt = (attempt) => {\n        if (attempt) {\n          return attempt;\n        }\n        const handleFileSize = (fileSize) => {\n          assert(fileSize !== null);\n          return this.requestSlice(start, clamp(fileSize - start, minLength, maxLength));\n        };\n        const promisedFileSize = this.source._retrieveSize();\n        if (promisedFileSize instanceof Promise) {\n          return promisedFileSize.then(handleFileSize);\n        } else {\n          return handleFileSize(promisedFileSize);\n        }\n      };\n      if (promisedAttempt instanceof Promise) {\n        return promisedAttempt.then(handleAttempt);\n      } else {\n        return handleAttempt(promisedAttempt);\n      }\n    }\n  }\n}\n\nclass FileSlice {\n  constructor(bytes, view, offset, start, end) {\n    this.bytes = bytes;\n    this.view = view;\n    this.offset = offset;\n    this.start = start;\n    this.end = end;\n    this.bufferPos = start - offset;\n  }\n  static tempFromBytes(bytes) {\n    return new FileSlice(bytes, toDataView(bytes), 0, 0, bytes.length);\n  }\n  get length() {\n    return this.end - this.start;\n  }\n  get filePos() {\n    return this.offset + this.bufferPos;\n  }\n  set filePos(value) {\n    this.bufferPos = value - this.offset;\n  }\n  get remainingLength() {\n    return Math.max(this.end - this.filePos, 0);\n  }\n  skip(byteCount) {\n    this.bufferPos += byteCount;\n  }\n  slice(filePos, length = this.end - filePos) {\n    if (filePos < this.start || filePos + length > this.end) {\n      throw new RangeError(\"Slicing outside of original slice.\");\n    }\n    return new FileSlice(this.bytes, this.view, this.offset, filePos, filePos + length);\n  }\n}\nvar checkIsInRange = (slice, bytesToRead) => {\n  if (slice.filePos < slice.start || slice.filePos + bytesToRead > slice.end) {\n    throw new RangeError(`Tried reading [${slice.filePos}, ${slice.filePos + bytesToRead}), but slice is` + ` [${slice.start}, ${slice.end}). This is likely an internal error, please report it alongside the file` + ` that caused it.`);\n  }\n};\nvar readBytes = (slice, length) => {\n  checkIsInRange(slice, length);\n  const bytes = slice.bytes.subarray(slice.bufferPos, slice.bufferPos + length);\n  slice.bufferPos += length;\n  return bytes;\n};\nvar readU8 = (slice) => {\n  checkIsInRange(slice, 1);\n  return slice.view.getUint8(slice.bufferPos++);\n};\nvar readU16 = (slice, littleEndian) => {\n  checkIsInRange(slice, 2);\n  const value = slice.view.getUint16(slice.bufferPos, littleEndian);\n  slice.bufferPos += 2;\n  return value;\n};\nvar readU16Be = (slice) => {\n  checkIsInRange(slice, 2);\n  const value = slice.view.getUint16(slice.bufferPos, false);\n  slice.bufferPos += 2;\n  return value;\n};\nvar readU24Be = (slice) => {\n  checkIsInRange(slice, 3);\n  const value = getUint24(slice.view, slice.bufferPos, false);\n  slice.bufferPos += 3;\n  return value;\n};\nvar readI16Be = (slice) => {\n  checkIsInRange(slice, 2);\n  const value = slice.view.getInt16(slice.bufferPos, false);\n  slice.bufferPos += 2;\n  return value;\n};\nvar readU32 = (slice, littleEndian) => {\n  checkIsInRange(slice, 4);\n  const value = slice.view.getUint32(slice.bufferPos, littleEndian);\n  slice.bufferPos += 4;\n  return value;\n};\nvar readU32Be = (slice) => {\n  checkIsInRange(slice, 4);\n  const value = slice.view.getUint32(slice.bufferPos, false);\n  slice.bufferPos += 4;\n  return value;\n};\nvar readU32Le = (slice) => {\n  checkIsInRange(slice, 4);\n  const value = slice.view.getUint32(slice.bufferPos, true);\n  slice.bufferPos += 4;\n  return value;\n};\nvar readI32Be = (slice) => {\n  checkIsInRange(slice, 4);\n  const value = slice.view.getInt32(slice.bufferPos, false);\n  slice.bufferPos += 4;\n  return value;\n};\nvar readI32Le = (slice) => {\n  checkIsInRange(slice, 4);\n  const value = slice.view.getInt32(slice.bufferPos, true);\n  slice.bufferPos += 4;\n  return value;\n};\nvar readU64 = (slice, littleEndian) => {\n  let low;\n  let high;\n  if (littleEndian) {\n    low = readU32(slice, true);\n    high = readU32(slice, true);\n  } else {\n    high = readU32(slice, false);\n    low = readU32(slice, false);\n  }\n  return high * 4294967296 + low;\n};\nvar readU64Be = (slice) => {\n  const high = readU32Be(slice);\n  const low = readU32Be(slice);\n  return high * 4294967296 + low;\n};\nvar readI64Be = (slice) => {\n  const high = readI32Be(slice);\n  const low = readU32Be(slice);\n  return high * 4294967296 + low;\n};\nvar readI64Le = (slice) => {\n  const low = readU32Le(slice);\n  const high = readI32Le(slice);\n  return high * 4294967296 + low;\n};\nvar readF32Be = (slice) => {\n  checkIsInRange(slice, 4);\n  const value = slice.view.getFloat32(slice.bufferPos, false);\n  slice.bufferPos += 4;\n  return value;\n};\nvar readF64Be = (slice) => {\n  checkIsInRange(slice, 8);\n  const value = slice.view.getFloat64(slice.bufferPos, false);\n  slice.bufferPos += 8;\n  return value;\n};\nvar readAscii = (slice, length) => {\n  checkIsInRange(slice, length);\n  let str = \"\";\n  for (let i = 0;i < length; i++) {\n    str += String.fromCharCode(slice.bytes[slice.bufferPos++]);\n  }\n  return str;\n};\n// ../../node_modules/.bun/mediabunny@1.29.0/node_modules/mediabunny/dist/modules/src/index.js\n/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\n// src/helpers/use-max-media-duration.ts\nimport { useEffect as useEffect69, useState as useState67 } from \"react\";\nvar cache = new Map;\nvar getSrc = (s) => {\n  if (s.type === \"video\") {\n    return s.src;\n  }\n  if (s.type === \"audio\") {\n    return s.src;\n  }\n  return null;\n};\nvar useMaxMediaDuration = (s, fps) => {\n  const src = getSrc(s);\n  const [maxMediaDuration, setMaxMediaDuration] = useState67(src ? cache.get(src) ?? null : Infinity);\n  useEffect69(() => {\n    if (!src) {\n      return;\n    }\n    const input2 = new Input({\n      formats: ALL_FORMATS,\n      source: new UrlSource(src)\n    });\n    input2.computeDuration().then((duration) => {\n      cache.set(src, Math.floor(duration * fps));\n      setMaxMediaDuration(Math.floor(duration * fps));\n    }).catch((e) => {\n      if (e instanceof InputDisposedError) {\n        return;\n      }\n      return getVideoMetadata2(src).then((metadata) => {\n        const durationOrInfinity = metadata.durationInSeconds ?? Infinity;\n        cache.set(src, Math.floor(durationOrInfinity * fps));\n        setMaxMediaDuration(Math.floor(durationOrInfinity * fps));\n      }).catch(() => {});\n    });\n    return () => {\n      input2.dispose();\n    };\n  }, [src, fps]);\n  return maxMediaDuration;\n};\n\n// src/components/AudioWaveform.tsx\nimport { getAudioData, getWaveformPortion } from \"@remotion/media-utils\";\nimport { useEffect as useEffect70, useMemo as useMemo106, useRef as useRef39, useState as useState68 } from \"react\";\nimport { Internals as Internals52 } from \"remotion\";\n\n// src/components/AudioWaveformBar.tsx\nimport { useMemo as useMemo105 } from \"react\";\nimport { jsx as jsx195 } from \"react/jsx-runtime\";\nvar WAVEFORM_BAR_LENGTH = 2;\nvar WAVEFORM_BAR_MARGIN = 1;\nvar container42 = {\n  width: WAVEFORM_BAR_LENGTH,\n  backgroundColor: \"rgba(255, 255, 255, 0.6)\",\n  marginLeft: WAVEFORM_BAR_MARGIN,\n  borderRadius: 2\n};\nvar AudioWaveformBar = ({ amplitude }) => {\n  const style11 = useMemo105(() => {\n    return {\n      ...container42,\n      height: getTimelineLayerHeight(\"other\") * amplitude * (1 / 0.6366)\n    };\n  }, [amplitude]);\n  return /* @__PURE__ */ jsx195(\"div\", {\n    style: style11\n  });\n};\n\n// src/components/AudioWaveform.tsx\nimport { jsx as jsx196, jsxs as jsxs95 } from \"react/jsx-runtime\";\nvar container43 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"flex-end\",\n  position: \"absolute\",\n  height: getTimelineLayerHeight(\"other\")\n};\nvar errorMessage = {\n  fontSize: 13,\n  paddingTop: 6,\n  paddingBottom: 6,\n  paddingLeft: 12,\n  paddingRight: 12,\n  alignSelf: \"flex-start\",\n  maxWidth: 450,\n  opacity: 0.75\n};\nvar canvasStyle = {\n  position: \"absolute\"\n};\nvar AudioWaveform = ({\n  src,\n  startFrom,\n  durationInFrames,\n  visualizationWidth,\n  volume,\n  doesVolumeChange,\n  playbackRate\n}) => {\n  const [metadata, setMetadata] = useState68(null);\n  const [error, setError] = useState68(null);\n  const mountState = useRef39({ isMounted: true });\n  const vidConf = Internals52.useUnsafeVideoConfig();\n  if (vidConf === null) {\n    throw new Error(\"Expected video config\");\n  }\n  const canvas = useRef39(null);\n  useEffect70(() => {\n    const { current } = mountState;\n    current.isMounted = true;\n    return () => {\n      current.isMounted = false;\n    };\n  }, []);\n  useEffect70(() => {\n    if (!canvas.current) {\n      return;\n    }\n    const context = canvas.current.getContext(\"2d\");\n    if (!context) {\n      return;\n    }\n    context.clearRect(0, 0, visualizationWidth, getTimelineLayerHeight(\"other\"));\n    if (!doesVolumeChange || typeof volume === \"number\") {\n      return;\n    }\n    const volumes = volume.split(\",\").map((v) => Number(v));\n    context.beginPath();\n    context.moveTo(0, getTimelineLayerHeight(\"other\"));\n    volumes.forEach((v, index) => {\n      const x = index / (volumes.length - 1) * visualizationWidth;\n      const y = (1 - v) * (getTimelineLayerHeight(\"other\") - TIMELINE_BORDER * 2) + 1;\n      if (index === 0) {\n        context.moveTo(x, y);\n      } else {\n        context.lineTo(x, y);\n      }\n    });\n    context.strokeStyle = LIGHT_TRANSPARENT;\n    context.stroke();\n  }, [visualizationWidth, metadata, startFrom, volume, doesVolumeChange]);\n  useEffect70(() => {\n    setError(null);\n    getAudioData(src).then((data) => {\n      if (mountState.current.isMounted) {\n        setMetadata(data);\n      }\n    }).catch((err) => {\n      if (mountState.current.isMounted) {\n        setError(err);\n      }\n    });\n  }, [src, vidConf.fps]);\n  const normalized = useMemo106(() => {\n    if (!metadata || metadata.numberOfChannels === 0) {\n      return [];\n    }\n    const numberOfSamples = Math.floor(visualizationWidth / (WAVEFORM_BAR_LENGTH + WAVEFORM_BAR_MARGIN));\n    return getWaveformPortion({\n      audioData: metadata,\n      startTimeInSeconds: startFrom / vidConf.fps,\n      durationInSeconds: Math.min(durationInFrames / vidConf.fps * playbackRate, metadata.durationInSeconds),\n      numberOfSamples,\n      normalize: false\n    });\n  }, [\n    durationInFrames,\n    vidConf.fps,\n    metadata,\n    playbackRate,\n    startFrom,\n    visualizationWidth\n  ]);\n  if (error) {\n    return /* @__PURE__ */ jsx196(\"div\", {\n      style: container43,\n      children: /* @__PURE__ */ jsx196(\"div\", {\n        style: errorMessage,\n        children: \"No waveform available. Audio might not support CORS.\"\n      })\n    });\n  }\n  if (!metadata) {\n    return null;\n  }\n  return /* @__PURE__ */ jsxs95(\"div\", {\n    style: container43,\n    children: [\n      normalized.map((w) => {\n        return /* @__PURE__ */ jsx196(AudioWaveformBar, {\n          amplitude: w.amplitude * (typeof volume === \"number\" ? volume : 1)\n        }, w.index);\n      }),\n      /* @__PURE__ */ jsx196(\"canvas\", {\n        ref: canvas,\n        style: canvasStyle,\n        width: visualizationWidth,\n        height: getTimelineLayerHeight(\"other\")\n      })\n    ]\n  });\n};\n\n// src/components/Timeline/LoopedTimelineIndicators.tsx\nimport React136 from \"react\";\nimport { AbsoluteFill as AbsoluteFill4 } from \"remotion\";\n\n// src/components/Timeline/LoopedIndicator.tsx\nimport { AbsoluteFill as AbsoluteFill3 } from \"remotion\";\nimport { jsx as jsx197, jsxs as jsxs96 } from \"react/jsx-runtime\";\nvar width = {\n  width: 0,\n  flexDirection: \"row\",\n  display: \"flex\",\n  position: \"relative\"\n};\nvar icon5 = {\n  height: 12\n};\nvar Icon = () => /* @__PURE__ */ jsx197(\"svg\", {\n  viewBox: \"0 0 512 512\",\n  style: icon5,\n  children: /* @__PURE__ */ jsx197(\"path\", {\n    fill: LIGHT_COLOR,\n    d: \"M512 256c0 88.224-71.775 160-160 160H170.067l34.512 32.419c9.875 9.276 10.119 24.883.539 34.464l-10.775 10.775c-9.373 9.372-24.568 9.372-33.941 0l-92.686-92.686c-9.373-9.373-9.373-24.568 0-33.941l92.686-92.686c9.373-9.373 24.568-9.373 33.941 0l10.775 10.775c9.581 9.581 9.337 25.187-.539 34.464L170.067 352H352c52.935 0 96-43.065 96-96 0-13.958-2.996-27.228-8.376-39.204-4.061-9.039-2.284-19.626 4.723-26.633l12.183-12.183c11.499-11.499 30.965-8.526 38.312 5.982C505.814 205.624 512 230.103 512 256zM72.376 295.204C66.996 283.228 64 269.958 64 256c0-52.935 43.065-96 96-96h181.933l-34.512 32.419c-9.875 9.276-10.119 24.883-.539 34.464l10.775 10.775c9.373 9.372 24.568 9.372 33.941 0l92.686-92.686c9.373-9.373 9.373-24.568 0-33.941l-92.686-92.686c-9.373-9.373-24.568-9.373-33.941 0L306.882 29.12c-9.581 9.581-9.337 25.187.539 34.464L341.933 96H160C71.775 96 0 167.776 0 256c0 25.897 6.186 50.376 17.157 72.039 7.347 14.508 26.813 17.481 38.312 5.982l12.183-12.183c7.008-7.008 8.786-17.595 4.724-26.634z\"\n  })\n});\nvar topLine = {\n  top: 0,\n  height: 2,\n  width: 1,\n  background: LIGHT_COLOR\n};\nvar bottomLine = {\n  top: 0,\n  height: 2,\n  width: 1,\n  background: LIGHT_COLOR\n};\nvar topContainer = {\n  justifyContent: \"flex-start\",\n  alignItems: \"center\"\n};\nvar centerContainer = {\n  justifyContent: \"center\",\n  alignItems: \"center\"\n};\nvar bottomContainer = {\n  justifyContent: \"flex-end\",\n  alignItems: \"center\"\n};\nvar LoopedIndicator = () => {\n  return /* @__PURE__ */ jsxs96(\"div\", {\n    style: width,\n    children: [\n      /* @__PURE__ */ jsx197(AbsoluteFill3, {\n        style: topContainer,\n        children: /* @__PURE__ */ jsx197(\"div\", {\n          style: topLine\n        })\n      }),\n      /* @__PURE__ */ jsx197(AbsoluteFill3, {\n        style: bottomContainer,\n        children: /* @__PURE__ */ jsx197(\"div\", {\n          style: bottomLine\n        })\n      }),\n      /* @__PURE__ */ jsx197(AbsoluteFill3, {\n        style: centerContainer,\n        children: /* @__PURE__ */ jsx197(Icon, {})\n      })\n    ]\n  });\n};\n\n// src/components/Timeline/LoopedTimelineIndicators.tsx\nimport { jsx as jsx198, jsxs as jsxs97 } from \"react/jsx-runtime\";\nvar row6 = {\n  flexDirection: \"row\"\n};\nvar LoopedTimelineIndicator = ({ loops }) => {\n  const leftOver = loops % 1;\n  return /* @__PURE__ */ jsxs97(AbsoluteFill4, {\n    style: row6,\n    children: [\n      new Array(Math.floor(loops)).fill(true).map((_l, i) => {\n        return /* @__PURE__ */ jsxs97(React136.Fragment, {\n          children: [\n            /* @__PURE__ */ jsx198(Flex, {}),\n            i === loops - 1 ? null : /* @__PURE__ */ jsx198(LoopedIndicator, {})\n          ]\n        }, i);\n      }),\n      leftOver > 0 ? /* @__PURE__ */ jsx198(\"div\", {\n        style: { flex: leftOver }\n      }) : null\n    ]\n  });\n};\n\n// src/components/Timeline/TimelineSequenceFrame.tsx\nimport { jsx as jsx199 } from \"react/jsx-runtime\";\nvar relativeFrameStyle = {\n  fontSize: 11,\n  fontFamily: \"Arial, Helvetica, sans-serif\",\n  color: \"white\",\n  opacity: 0.5\n};\nvar TimelineSequenceFrame = ({ roundedFrame, premounted, postmounted }) => {\n  return /* @__PURE__ */ jsx199(\"div\", {\n    style: relativeFrameStyle,\n    children: premounted ? \"0 (Premounted)\" : postmounted !== null ? `${postmounted} (Postmounted)` : roundedFrame\n  });\n};\n\n// src/components/Timeline/TimelineVideoInfo.tsx\nimport { useEffect as useEffect71, useRef as useRef40, useState as useState69 } from \"react\";\nimport { useVideoConfig as useVideoConfig5 } from \"remotion\";\n\n// src/helpers/extract-frames.ts\nasync function extractFrames({\n  src,\n  timestampsInSeconds,\n  onVideoSample,\n  signal\n}) {\n  const input2 = new Input({\n    formats: ALL_FORMATS,\n    source: new UrlSource(src)\n  });\n  const dispose = () => {\n    input2.dispose();\n  };\n  if (signal) {\n    signal.addEventListener(\"abort\", dispose, { once: true });\n  }\n  try {\n    const [durationInSeconds, format, videoTrack] = await Promise.all([\n      input2.computeDuration(),\n      input2.getFormat(),\n      input2.getPrimaryVideoTrack()\n    ]);\n    if (!videoTrack) {\n      throw new Error(\"No video track found in the input\");\n    }\n    const timestamps = typeof timestampsInSeconds === \"function\" ? await timestampsInSeconds({\n      track: {\n        width: videoTrack.displayWidth,\n        height: videoTrack.displayHeight\n      },\n      container: format.name,\n      durationInSeconds\n    }) : timestampsInSeconds;\n    if (timestamps.length === 0) {\n      return;\n    }\n    const sink = new VideoSampleSink(videoTrack);\n    for await (const videoSample of sink.samplesAtTimestamps(timestamps)) {\n      if (signal?.aborted) {\n        videoSample?.close();\n        break;\n      }\n      if (!videoSample) {\n        continue;\n      }\n      onVideoSample(videoSample);\n    }\n  } catch (error) {\n    if (error instanceof InputDisposedError) {\n      return;\n    }\n    throw error;\n  } finally {\n    dispose();\n    if (signal) {\n      signal.removeEventListener(\"abort\", dispose);\n    }\n  }\n}\n\n// src/helpers/frame-database.ts\nvar KEY_SEPARATOR = \"|\";\nvar makeFrameDatabaseKey = (src, timestamp) => `${src}${KEY_SEPARATOR}${timestamp}`;\nvar getFrameDatabaseKeyPrefix = (src) => {\n  return `${src}${KEY_SEPARATOR}`;\n};\nvar frameDatabase = new Map;\nvar aspectRatioCache = new Map;\nvar getTimestampFromFrameDatabaseKey = (key4) => {\n  const split = key4.split(KEY_SEPARATOR);\n  return Number(split[split.length - 1]);\n};\nvar getAspectRatioFromCache = (src) => {\n  const cached = aspectRatioCache.get(src);\n  if (cached) {\n    return cached;\n  }\n  return null;\n};\nvar MAX_FRAMES_IN_CACHE = 12340;\nvar clearOldFrames = () => {\n  if (frameDatabase.size <= MAX_FRAMES_IN_CACHE) {\n    return;\n  }\n  const framesToRemove = Array.from(frameDatabase.entries()).sort((a, b) => a[1].lastUsed - b[1].lastUsed);\n  for (const [key4, frame2] of framesToRemove.slice(0, framesToRemove.length - MAX_FRAMES_IN_CACHE)) {\n    frame2.frame.close();\n    frameDatabase.delete(key4);\n  }\n};\nvar clearFramesForSrc = (src) => {\n  const keysToRemove = [];\n  const prefix = getFrameDatabaseKeyPrefix(src);\n  for (const [key4, frame2] of frameDatabase.entries()) {\n    if (key4.startsWith(prefix)) {\n      frame2.frame.close();\n      keysToRemove.push(key4);\n    }\n  }\n  for (const key4 of keysToRemove) {\n    frameDatabase.delete(key4);\n  }\n};\n\n// src/helpers/resize-video-frame.ts\nvar calculateNewDimensionsFromScale = ({\n  width: width2,\n  height,\n  scale\n}) => {\n  const scaledWidth = Math.round(width2 * scale);\n  const scaledHeight = Math.round(height * scale);\n  return {\n    width: scaledWidth,\n    height: scaledHeight\n  };\n};\nvar resizeVideoFrame = ({\n  frame: frame2,\n  scale\n}) => {\n  if (scale === 1) {\n    return frame2;\n  }\n  const { width: width2, height } = calculateNewDimensionsFromScale({\n    height: frame2.displayHeight,\n    width: frame2.displayWidth,\n    scale\n  });\n  const canvas = new OffscreenCanvas(width2, height);\n  const ctx = canvas.getContext(\"2d\");\n  if (!ctx) {\n    throw new Error(\"Could not get 2d context\");\n  }\n  canvas.width = width2;\n  canvas.height = height;\n  ctx.scale(scale, scale);\n  ctx.drawImage(frame2, 0, 0);\n  return new VideoFrame(canvas, {\n    displayHeight: height,\n    displayWidth: width2,\n    duration: frame2.duration ?? undefined,\n    timestamp: frame2.timestamp\n  });\n};\n\n// src/components/Timeline/TimelineVideoInfo.tsx\nimport { jsx as jsx200 } from \"react/jsx-runtime\";\nvar HEIGHT = getTimelineLayerHeight(\"video\") - 2;\nvar containerStyle3 = {\n  height: HEIGHT,\n  width: \"100%\",\n  backgroundColor: \"rgba(0, 0, 0, 0.3)\",\n  display: \"flex\",\n  borderTopLeftRadius: 2,\n  borderBottomLeftRadius: 2,\n  fontSize: 10,\n  fontFamily: \"Arial, Helvetica\"\n};\nvar WEBCODECS_TIMESCALE = 1e6;\nvar MAX_TIME_DEVIATION = WEBCODECS_TIMESCALE * 0.05;\nvar getDurationOfOneFrame = ({\n  visualizationWidth,\n  aspectRatio,\n  segmentDuration\n}) => {\n  const framesFitInWidthUnrounded = visualizationWidth / (HEIGHT * aspectRatio);\n  return segmentDuration / framesFitInWidthUnrounded * WEBCODECS_TIMESCALE;\n};\nvar fixRounding = (value) => {\n  if (value % 1 >= 0.49999999) {\n    return Math.ceil(value);\n  }\n  return Math.floor(value);\n};\nvar calculateTimestampSlots = ({\n  visualizationWidth,\n  fromSeconds,\n  segmentDuration,\n  aspectRatio\n}) => {\n  const framesFitInWidthUnrounded = visualizationWidth / (HEIGHT * aspectRatio);\n  const framesFitInWidth = Math.ceil(framesFitInWidthUnrounded);\n  const durationOfOneFrame = getDurationOfOneFrame({\n    visualizationWidth,\n    aspectRatio,\n    segmentDuration\n  });\n  const timestampTargets = [];\n  for (let i = 0;i < framesFitInWidth + 1; i++) {\n    const target = fromSeconds * WEBCODECS_TIMESCALE + durationOfOneFrame * (i + 0.5);\n    const snappedToDuration = (Math.round(fixRounding(target / durationOfOneFrame)) - 1) * durationOfOneFrame;\n    timestampTargets.push(snappedToDuration);\n  }\n  return timestampTargets;\n};\nvar ensureSlots = ({\n  filledSlots,\n  visualizationWidth,\n  fromSeconds,\n  toSeconds,\n  aspectRatio\n}) => {\n  const segmentDuration = toSeconds - fromSeconds;\n  const timestampTargets = calculateTimestampSlots({\n    visualizationWidth,\n    fromSeconds,\n    segmentDuration,\n    aspectRatio\n  });\n  for (const timestamp of timestampTargets) {\n    if (!filledSlots.has(timestamp)) {\n      filledSlots.set(timestamp, undefined);\n    }\n  }\n};\nvar drawSlot = ({\n  frame: frame2,\n  ctx,\n  filledSlots,\n  visualizationWidth,\n  timestamp,\n  segmentDuration,\n  fromSeconds\n}) => {\n  const durationOfOneFrame = getDurationOfOneFrame({\n    visualizationWidth,\n    aspectRatio: frame2.displayWidth / frame2.displayHeight,\n    segmentDuration\n  });\n  const relativeTimestamp = timestamp - fromSeconds * WEBCODECS_TIMESCALE;\n  const frameIndex = relativeTimestamp / durationOfOneFrame;\n  const left3 = Math.floor(frameIndex * frame2.displayWidth / window.devicePixelRatio);\n  ctx.drawImage(frame2, left3, 0, frame2.displayWidth / window.devicePixelRatio, frame2.displayHeight / window.devicePixelRatio);\n  filledSlots.set(timestamp, frame2.timestamp);\n};\nvar fillWithCachedFrames = ({\n  ctx,\n  visualizationWidth,\n  filledSlots,\n  src,\n  segmentDuration,\n  fromSeconds\n}) => {\n  const prefix = getFrameDatabaseKeyPrefix(src);\n  const keys = Array.from(frameDatabase.keys()).filter((k) => k.startsWith(prefix));\n  const targets = Array.from(filledSlots.keys());\n  for (const timestamp of targets) {\n    let bestKey;\n    let bestDistance = Infinity;\n    for (const key4 of keys) {\n      const distance = Math.abs(getTimestampFromFrameDatabaseKey(key4) - timestamp);\n      if (distance < bestDistance) {\n        bestDistance = distance;\n        bestKey = key4;\n      }\n    }\n    if (!bestKey) {\n      continue;\n    }\n    const frame2 = frameDatabase.get(bestKey);\n    if (!frame2) {\n      continue;\n    }\n    const alreadyFilled = filledSlots.get(timestamp);\n    if (alreadyFilled && Math.abs(alreadyFilled - timestamp) <= Math.abs(frame2.frame.timestamp - timestamp)) {\n      continue;\n    }\n    frame2.lastUsed = Date.now();\n    drawSlot({\n      ctx,\n      frame: frame2.frame,\n      filledSlots,\n      visualizationWidth,\n      timestamp,\n      segmentDuration,\n      fromSeconds\n    });\n  }\n};\nvar fillFrameWhereItFits = ({\n  frame: frame2,\n  filledSlots,\n  ctx,\n  visualizationWidth,\n  segmentDuration,\n  fromSeconds\n}) => {\n  const slots = Array.from(filledSlots.keys());\n  for (let i = 0;i < slots.length; i++) {\n    const slot = slots[i];\n    if (Math.abs(slot - frame2.timestamp) > MAX_TIME_DEVIATION) {\n      continue;\n    }\n    const filled = filledSlots.get(slot);\n    if (filled && Math.abs(filled - slot) <= Math.abs(filled - frame2.timestamp)) {\n      continue;\n    }\n    drawSlot({\n      ctx,\n      frame: frame2,\n      filledSlots,\n      visualizationWidth,\n      timestamp: slot,\n      segmentDuration,\n      fromSeconds\n    });\n  }\n};\nvar TimelineVideoInfo = ({ src, visualizationWidth, startFrom, durationInFrames }) => {\n  const { fps } = useVideoConfig5();\n  const ref = useRef40(null);\n  const [error, setError] = useState69(null);\n  const aspectRatio = useRef40(getAspectRatioFromCache(src));\n  useEffect71(() => {\n    return () => {\n      clearFramesForSrc(src);\n    };\n  }, [src]);\n  useEffect71(() => {\n    if (error) {\n      return;\n    }\n    const { current } = ref;\n    if (!current) {\n      return;\n    }\n    const controller = new AbortController;\n    const canvas = document.createElement(\"canvas\");\n    canvas.width = visualizationWidth;\n    canvas.height = HEIGHT;\n    const ctx = canvas.getContext(\"2d\");\n    if (!ctx) {\n      return;\n    }\n    current.appendChild(canvas);\n    const filledSlots = new Map;\n    const fromSeconds = startFrom / fps;\n    const toSeconds = (startFrom + durationInFrames) / fps;\n    if (aspectRatio.current !== null) {\n      ensureSlots({\n        filledSlots,\n        visualizationWidth,\n        fromSeconds,\n        toSeconds,\n        aspectRatio: aspectRatio.current\n      });\n      fillWithCachedFrames({\n        ctx,\n        visualizationWidth,\n        filledSlots,\n        src,\n        segmentDuration: toSeconds - fromSeconds,\n        fromSeconds\n      });\n      const unfilled = Array.from(filledSlots.keys()).filter((timestamp) => !filledSlots.get(timestamp));\n      if (unfilled.length === 0) {\n        return () => {\n          current.removeChild(canvas);\n          clearOldFrames();\n        };\n      }\n    }\n    clearOldFrames();\n    extractFrames({\n      timestampsInSeconds: ({\n        track\n      }) => {\n        aspectRatio.current = track.width / track.height;\n        aspectRatioCache.set(src, aspectRatio.current);\n        ensureSlots({\n          filledSlots,\n          fromSeconds,\n          toSeconds,\n          visualizationWidth,\n          aspectRatio: aspectRatio.current\n        });\n        return Array.from(filledSlots.keys()).map((timestamp) => timestamp / WEBCODECS_TIMESCALE);\n      },\n      src,\n      onVideoSample: (sample) => {\n        const frame2 = sample.toVideoFrame();\n        const scale = HEIGHT / frame2.displayHeight * window.devicePixelRatio;\n        const transformed = resizeVideoFrame({\n          frame: frame2,\n          scale\n        });\n        if (transformed !== frame2) {\n          frame2.close();\n        }\n        const databaseKey = makeFrameDatabaseKey(src, transformed.timestamp);\n        const existingFrame = frameDatabase.get(databaseKey);\n        if (existingFrame) {\n          existingFrame.frame.close();\n        }\n        frameDatabase.set(databaseKey, {\n          frame: transformed,\n          lastUsed: Date.now()\n        });\n        if (aspectRatio.current === null) {\n          throw new Error(\"Aspect ratio is not set\");\n        }\n        ensureSlots({\n          filledSlots,\n          fromSeconds,\n          toSeconds,\n          visualizationWidth,\n          aspectRatio: aspectRatio.current\n        });\n        fillFrameWhereItFits({\n          ctx,\n          filledSlots,\n          visualizationWidth,\n          frame: transformed,\n          segmentDuration: toSeconds - fromSeconds,\n          fromSeconds\n        });\n        sample.close();\n      },\n      signal: controller.signal\n    }).then(() => {\n      fillWithCachedFrames({\n        ctx,\n        visualizationWidth,\n        filledSlots,\n        src,\n        segmentDuration: toSeconds - fromSeconds,\n        fromSeconds\n      });\n    }).catch((e) => {\n      setError(e);\n    }).finally(() => {\n      clearOldFrames();\n    });\n    return () => {\n      controller.abort();\n      current.removeChild(canvas);\n    };\n  }, [durationInFrames, error, fps, src, startFrom, visualizationWidth]);\n  return /* @__PURE__ */ jsx200(\"div\", {\n    ref,\n    style: containerStyle3\n  });\n};\n\n// src/components/Timeline/TimelineSequence.tsx\nimport { jsx as jsx201, jsxs as jsxs98 } from \"react/jsx-runtime\";\nvar AUDIO_GRADIENT = \"linear-gradient(rgb(16 171 58), rgb(43 165 63) 60%)\";\nvar VIDEO_GRADIENT = \"linear-gradient(to top, #8e44ad, #9b59b6)\";\nvar TimelineSequence = ({ s }) => {\n  const windowWidth = useContext68(TimelineWidthContext);\n  if (windowWidth === null) {\n    return null;\n  }\n  return /* @__PURE__ */ jsx201(Inner4, {\n    windowWidth,\n    s\n  });\n};\nvar Inner4 = ({ s, windowWidth }) => {\n  const video = Internals53.useVideo();\n  const maxMediaDuration = useMaxMediaDuration(s, video?.fps ?? 30);\n  if (!video) {\n    throw new TypeError(\"Expected video config\");\n  }\n  const frame2 = useCurrentFrame2();\n  const relativeFrame = frame2 - s.from;\n  const relativeFrameWithPremount = relativeFrame + (s.premountDisplay ?? 0);\n  const relativeFrameWithPostmount = relativeFrame - s.duration;\n  const roundedFrame = Math.round(relativeFrame * 100) / 100;\n  const isInRange = relativeFrame >= 0 && relativeFrame < s.duration;\n  const isPremounting = relativeFrameWithPremount >= 0 && relativeFrameWithPremount < s.duration && !isInRange;\n  const isPostmounting = relativeFrameWithPostmount >= 0 && relativeFrameWithPostmount < (s.postmountDisplay ?? 0) && !isInRange;\n  const { marginLeft, width: width2, premountWidth, postmountWidth } = useMemo107(() => {\n    return getTimelineSequenceLayout({\n      durationInFrames: s.loopDisplay ? s.loopDisplay.durationInFrames * s.loopDisplay.numberOfTimes : s.duration,\n      startFrom: s.loopDisplay ? s.from + s.loopDisplay.startOffset : s.from,\n      startFromMedia: s.type === \"sequence\" ? 0 : s.startMediaFrom,\n      maxMediaDuration,\n      video,\n      windowWidth,\n      premountDisplay: s.premountDisplay,\n      postmountDisplay: s.postmountDisplay\n    });\n  }, [maxMediaDuration, s, video, windowWidth]);\n  const style11 = useMemo107(() => {\n    return {\n      background: s.type === \"audio\" ? AUDIO_GRADIENT : s.type === \"video\" ? VIDEO_GRADIENT : BLUE,\n      border: SEQUENCE_BORDER_WIDTH + \"px solid rgba(255, 255, 255, 0.2)\",\n      borderRadius: 2,\n      position: \"absolute\",\n      height: getTimelineLayerHeight(s.type === \"video\" ? \"video\" : \"other\"),\n      marginLeft,\n      width: width2,\n      color: \"white\",\n      overflow: \"hidden\",\n      opacity: isInRange ? 1 : 0.5\n    };\n  }, [isInRange, marginLeft, s.type, width2]);\n  if (maxMediaDuration === null) {\n    return null;\n  }\n  return /* @__PURE__ */ jsxs98(\"div\", {\n    style: style11,\n    title: s.displayName,\n    children: [\n      premountWidth ? /* @__PURE__ */ jsx201(\"div\", {\n        style: {\n          width: premountWidth,\n          height: \"100%\",\n          background: `repeating-linear-gradient(\n\t\t\t\t\t\t\t-45deg,\n\t\t\t\t\t\t\ttransparent,\n\t\t\t\t\t\t\ttransparent 2px,\n\t\t\t\t\t\t\trgba(255, 255, 255, ${isPremounting ? 0.5 : 0.2}) 2px,\n\t\t\t\t\t\t\trgba(255, 255, 255, ${isPremounting ? 0.5 : 0.2}) 4px\n\t\t\t\t\t\t)`,\n          position: \"absolute\"\n        }\n      }) : null,\n      postmountWidth ? /* @__PURE__ */ jsx201(\"div\", {\n        style: {\n          width: postmountWidth,\n          height: \"100%\",\n          background: `repeating-linear-gradient(\n\t\t\t\t\t\t\t-45deg,\n\t\t\t\t\t\t\ttransparent,\n\t\t\t\t\t\t\ttransparent 2px,\n\t\t\t\t\t\t\trgba(255, 255, 255, ${isPostmounting ? 0.5 : 0.2}) 2px,\n\t\t\t\t\t\t\trgba(255, 255, 255, ${isPostmounting ? 0.5 : 0.2}) 4px\n\t\t\t\t\t\t)`,\n          position: \"absolute\",\n          right: 0\n        }\n      }) : null,\n      s.type === \"audio\" ? /* @__PURE__ */ jsx201(AudioWaveform, {\n        src: s.src,\n        doesVolumeChange: s.doesVolumeChange,\n        visualizationWidth: width2,\n        startFrom: s.startMediaFrom,\n        durationInFrames: s.duration,\n        volume: s.volume,\n        playbackRate: s.playbackRate\n      }) : null,\n      s.type === \"video\" ? /* @__PURE__ */ jsx201(TimelineVideoInfo, {\n        src: s.src,\n        visualizationWidth: width2,\n        startFrom: s.startMediaFrom,\n        durationInFrames: s.duration\n      }) : null,\n      s.loopDisplay === undefined ? null : /* @__PURE__ */ jsx201(LoopedTimelineIndicator, {\n        loops: s.loopDisplay.numberOfTimes\n      }),\n      s.type !== \"audio\" && s.type !== \"video\" && s.loopDisplay === undefined && (isInRange || isPremounting || isPostmounting) ? /* @__PURE__ */ jsx201(\"div\", {\n        style: {\n          paddingLeft: 5 + (premountWidth ?? 0),\n          height: \"100%\",\n          display: \"flex\",\n          alignItems: \"center\"\n        },\n        children: /* @__PURE__ */ jsx201(TimelineSequenceFrame, {\n          premounted: isPremounting,\n          postmounted: isPostmounting ? s.duration - 1 : null,\n          roundedFrame\n        })\n      }) : null\n    ]\n  }, s.id);\n};\n\n// src/components/Timeline/is-collapsed.ts\nvar isTrackHidden = (track) => {\n  if (!track.sequence.parent) {\n    return false;\n  }\n  return !track.sequence.showInTimeline;\n};\n\n// src/components/Timeline/TimelineTracks.tsx\nimport { jsx as jsx202, jsxs as jsxs99 } from \"react/jsx-runtime\";\nvar content = {\n  paddingLeft: TIMELINE_PADDING,\n  paddingRight: TIMELINE_PADDING,\n  paddingTop: 1\n};\nvar timelineContent = {\n  minHeight: \"100%\"\n};\nvar TimelineTracks = ({ timeline, hasBeenCut }) => {\n  const timelineStyle = useMemo108(() => {\n    return {\n      ...timelineContent,\n      width: 100 + \"%\"\n    };\n  }, []);\n  return /* @__PURE__ */ jsxs99(\"div\", {\n    style: timelineStyle,\n    children: [\n      /* @__PURE__ */ jsxs99(\"div\", {\n        style: content,\n        children: [\n          /* @__PURE__ */ jsx202(TimelineTimePadding, {}),\n          timeline.map((track) => {\n            if (isTrackHidden(track)) {\n              return null;\n            }\n            return /* @__PURE__ */ jsx202(\"div\", {\n              style: {\n                height: getTimelineLayerHeight(track.sequence.type === \"video\" ? \"video\" : \"other\"),\n                marginBottom: TIMELINE_ITEM_BORDER_BOTTOM\n              },\n              children: /* @__PURE__ */ jsx202(TimelineSequence, {\n                s: track.sequence\n              })\n            }, track.sequence.id);\n          })\n        ]\n      }),\n      hasBeenCut ? /* @__PURE__ */ jsx202(MaxTimelineTracksReached, {}) : null\n    ]\n  });\n};\n\n// src/components/Timeline/Timeline.tsx\nimport { jsx as jsx203, jsxs as jsxs100 } from \"react/jsx-runtime\";\nvar container44 = {\n  minHeight: \"100%\",\n  flex: 1,\n  display: \"flex\",\n  height: 0,\n  overflowY: \"auto\",\n  backgroundColor: BACKGROUND\n};\nvar noop3 = () => {\n  return;\n};\nvar Timeline = () => {\n  const { sequences } = useContext69(Internals54.SequenceManager);\n  const videoConfig = Internals54.useUnsafeVideoConfig();\n  const timeline = useMemo109(() => {\n    if (!videoConfig) {\n      return [];\n    }\n    return calculateTimeline({\n      sequences,\n      sequenceDuration: videoConfig.durationInFrames\n    });\n  }, [sequences, videoConfig]);\n  const durationInFrames = videoConfig?.durationInFrames ?? 0;\n  const filtered = useMemo109(() => {\n    const withoutHidden = timeline.filter((t) => !isTrackHidden(t));\n    const withoutAfter = withoutHidden.filter((t) => {\n      return t.sequence.from <= durationInFrames && t.sequence.duration > 0;\n    });\n    return withoutAfter.filter((t) => t.sequence.showInTimeline);\n  }, [durationInFrames, timeline]);\n  const shown = filtered.slice(0, MAX_TIMELINE_TRACKS);\n  const hasBeenCut = filtered.length > shown.length;\n  const inner2 = useMemo109(() => {\n    return {\n      height: shown.reduce((acc, track) => {\n        return acc + getTimelineLayerHeight(track.sequence.type === \"video\" ? \"video\" : \"other\") + Number(TIMELINE_ITEM_BORDER_BOTTOM);\n      }, 0) + TIMELINE_ITEM_BORDER_BOTTOM + (hasBeenCut ? MAX_TIMELINE_TRACKS_NOTICE_HEIGHT : 0) + TIMELINE_TIME_INDICATOR_HEIGHT,\n      display: \"flex\",\n      flex: 1,\n      minHeight: \"100%\",\n      overflowX: \"hidden\"\n    };\n  }, [hasBeenCut, shown]);\n  return /* @__PURE__ */ jsx203(\"div\", {\n    ref: timelineVerticalScroll,\n    style: container44,\n    className: \"css-reset \" + VERTICAL_SCROLLBAR_CLASSNAME,\n    children: /* @__PURE__ */ jsx203(TimelineWidthProvider, {\n      children: /* @__PURE__ */ jsx203(\"div\", {\n        style: inner2,\n        children: /* @__PURE__ */ jsxs100(SplitterContainer, {\n          orientation: \"vertical\",\n          defaultFlex: 0.2,\n          id: \"names-to-timeline\",\n          maxFlex: 0.5,\n          minFlex: 0.15,\n          children: [\n            /* @__PURE__ */ jsx203(SplitterElement, {\n              type: \"flexer\",\n              sticky: /* @__PURE__ */ jsx203(TimelineTimePlaceholders, {}),\n              children: /* @__PURE__ */ jsx203(TimelineList, {\n                timeline: shown\n              })\n            }),\n            /* @__PURE__ */ jsx203(SplitterHandle, {\n              onCollapse: noop3,\n              allowToCollapse: \"none\"\n            }),\n            /* @__PURE__ */ jsx203(SplitterElement, {\n              type: \"anti-flexer\",\n              sticky: null,\n              children: /* @__PURE__ */ jsxs100(TimelineScrollable, {\n                children: [\n                  /* @__PURE__ */ jsx203(TimelineTracks, {\n                    timeline: shown,\n                    hasBeenCut\n                  }),\n                  /* @__PURE__ */ jsx203(TimelineInOutPointer, {}),\n                  /* @__PURE__ */ jsx203(TimelinePlayCursorSyncer, {}),\n                  /* @__PURE__ */ jsx203(TimelineDragHandler, {}),\n                  /* @__PURE__ */ jsx203(TimelineTimeIndicators, {}),\n                  /* @__PURE__ */ jsx203(TimelineSlider, {})\n                ]\n              })\n            })\n          ]\n        })\n      })\n    })\n  });\n};\n\n// src/components/EditorContent.tsx\nimport { jsx as jsx204, jsxs as jsxs101, Fragment as Fragment29 } from \"react/jsx-runtime\";\nvar noop4 = () => {\n  return;\n};\nvar container45 = {\n  display: \"flex\",\n  flexDirection: \"column\",\n  flex: 1,\n  height: 0\n};\nvar EditorContent = ({ readOnlyStudio, children }) => {\n  const isStill = useIsStill();\n  const { canvasContent } = useContext70(Internals55.CompositionManager);\n  const onlyTopPanel = canvasContent === null || isStill || canvasContent.type !== \"composition\";\n  return /* @__PURE__ */ jsxs101(\"div\", {\n    style: container45,\n    children: [\n      /* @__PURE__ */ jsx204(InitialCompositionLoader, {}),\n      /* @__PURE__ */ jsx204(MenuToolbar, {\n        readOnlyStudio\n      }),\n      /* @__PURE__ */ jsxs101(SplitterContainer, {\n        orientation: \"horizontal\",\n        id: \"top-to-bottom\",\n        maxFlex: 0.9,\n        minFlex: 0.2,\n        defaultFlex: 0.75,\n        children: [\n          /* @__PURE__ */ jsx204(SplitterElement, {\n            sticky: null,\n            type: \"flexer\",\n            children\n          }),\n          onlyTopPanel ? null : /* @__PURE__ */ jsxs101(Fragment29, {\n            children: [\n              /* @__PURE__ */ jsx204(SplitterHandle, {\n                allowToCollapse: \"none\",\n                onCollapse: noop4\n              }),\n              /* @__PURE__ */ jsx204(SplitterElement, {\n                sticky: null,\n                type: \"anti-flexer\",\n                children: /* @__PURE__ */ jsx204(Timeline, {})\n              })\n            ]\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/GlobalKeybindings.tsx\nimport { useContext as useContext71, useEffect as useEffect72 } from \"react\";\nvar GlobalKeybindings = () => {\n  const keybindings = useKeybinding();\n  const { setSelectedModal } = useContext71(ModalsContext);\n  const { setCheckerboard } = useContext71(CheckerboardContext);\n  const { navigateToNextComposition, navigateToPreviousComposition } = useCompositionNavigation();\n  useEffect72(() => {\n    const nKey = keybindings.registerKeybinding({\n      event: \"keypress\",\n      key: \"n\",\n      callback: () => {\n        showNotification(`To make a new composition, right-click an existing one and select \"Duplicate\"`, 5000);\n      },\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const cmdKKey = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"k\",\n      callback: () => {\n        setSelectedModal({\n          type: \"quick-switcher\",\n          mode: \"compositions\",\n          invocationTimestamp: Date.now()\n        });\n      },\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: false,\n      commandCtrlKey: true,\n      preventDefault: true\n    });\n    const cmdIKey = process.env.ASK_AI_ENABLED ? keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"i\",\n      callback: () => {\n        askAiModalRef.current?.toggle();\n      },\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: true,\n      commandCtrlKey: true,\n      preventDefault: true\n    }) : null;\n    const cKey = keybindings.registerKeybinding({\n      event: \"keypress\",\n      key: \"t\",\n      callback: () => {\n        setCheckerboard((c) => !c);\n      },\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const questionMark = keybindings.registerKeybinding({\n      event: \"keypress\",\n      key: \"?\",\n      callback: () => {\n        setSelectedModal({\n          type: \"quick-switcher\",\n          mode: \"docs\",\n          invocationTimestamp: Date.now()\n        });\n      },\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const pageDown = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"PageDown\",\n      callback: navigateToNextComposition,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    const pageUp = keybindings.registerKeybinding({\n      event: \"keydown\",\n      key: \"PageUp\",\n      callback: navigateToPreviousComposition,\n      commandCtrlKey: false,\n      preventDefault: true,\n      triggerIfInputFieldFocused: false,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      nKey.unregister();\n      cKey.unregister();\n      questionMark.unregister();\n      cmdKKey.unregister();\n      cmdIKey?.unregister();\n      pageDown.unregister();\n      pageUp.unregister();\n    };\n  }, [\n    keybindings,\n    setCheckerboard,\n    setSelectedModal,\n    navigateToNextComposition,\n    navigateToPreviousComposition\n  ]);\n  return null;\n};\n\n// src/components/Modals.tsx\nimport { useContext as useContext85 } from \"react\";\n\n// src/components/InstallPackage.tsx\nimport { apiDocs, descriptions, installableMap } from \"@remotion/studio-shared\";\nimport React144, { useCallback as useCallback100, useContext as useContext73, useEffect as useEffect73 } from \"react\";\nimport { VERSION as VERSION2 } from \"remotion\";\n\n// src/api/install-package.ts\nimport { getRemotionEnvironment as getRemotionEnvironment4 } from \"remotion\";\nvar installPackages = (packageNames) => {\n  if (!getRemotionEnvironment4().isStudio) {\n    throw new Error(\"installPackages() is only available in the Studio\");\n  }\n  if (window.remotion_isReadOnlyStudio) {\n    throw new Error(\"installPackages() is not available in Read-Only Studio\");\n  }\n  return callApi(\"/api/install-package\", { packageNames });\n};\n\n// src/components/InstallablePackage.tsx\nimport { jsx as jsx205, jsxs as jsxs102 } from \"react/jsx-runtime\";\nvar FONT_SIZE = 13;\nvar InstallablePackageComp = ({ isInstalled, pkg, link, description }) => {\n  return /* @__PURE__ */ jsxs102(\"div\", {\n    style: {\n      fontSize: FONT_SIZE,\n      lineHeight: 1.2,\n      paddingBottom: 4,\n      paddingTop: 4\n    },\n    children: [\n      /* @__PURE__ */ jsx205(\"a\", {\n        href: link,\n        style: {\n          fontSize: FONT_SIZE,\n          color: TEXT_COLOR,\n          textDecoration: \"none\"\n        },\n        target: \"_blank\",\n        children: pkg\n      }),\n      \" \",\n      isInstalled ? /* @__PURE__ */ jsx205(\"span\", {\n        style: { opacity: 0.3, fontSize: \"inherit\" },\n        children: \"(installed)\"\n      }) : null,\n      /* @__PURE__ */ jsx205(\"br\", {}),\n      /* @__PURE__ */ jsx205(\"span\", {\n        style: { color: LIGHT_TEXT, fontSize: FONT_SIZE },\n        children: description\n      })\n    ]\n  });\n};\n\n// src/components/ModalButton.tsx\nimport { useMemo as useMemo110 } from \"react\";\nimport { jsx as jsx206 } from \"react/jsx-runtime\";\nvar buttonStyle5 = {\n  backgroundColor: BLUE,\n  color: \"white\"\n};\nvar ModalButton = (props) => {\n  const style11 = useMemo110(() => {\n    return {\n      ...buttonStyle5,\n      backgroundColor: props.disabled ? BLUE_DISABLED : BLUE\n    };\n  }, [props.disabled]);\n  return /* @__PURE__ */ jsx206(Button, {\n    ...props,\n    style: style11\n  });\n};\n\n// src/components/ModalFooter.tsx\nimport { jsx as jsx207 } from \"react/jsx-runtime\";\nvar content2 = {\n  padding: 12,\n  paddingRight: 12,\n  flex: 1,\n  fontSize: 13,\n  minWidth: 500\n};\nvar ModalFooterContainer = ({ children }) => {\n  return /* @__PURE__ */ jsx207(\"div\", {\n    style: { ...content2, borderTop: \"1px solid black\" },\n    children\n  });\n};\n\n// src/components/NewComposition/DismissableModal.tsx\nimport { useCallback as useCallback99, useContext as useContext72 } from \"react\";\nimport { jsx as jsx208 } from \"react/jsx-runtime\";\nvar DismissableModal = ({ children }) => {\n  const { setSelectedModal } = useContext72(ModalsContext);\n  const onQuit = useCallback99(() => {\n    setSelectedModal(null);\n  }, [setSelectedModal]);\n  return /* @__PURE__ */ jsx208(ModalContainer, {\n    onOutsideClick: onQuit,\n    onEscape: onQuit,\n    children\n  });\n};\n\n// src/components/InstallPackage.tsx\nimport { jsx as jsx209, jsxs as jsxs103 } from \"react/jsx-runtime\";\nvar container46 = {\n  padding: 20,\n  maxHeight: 400,\n  overflowY: \"auto\"\n};\nvar text2 = {\n  fontSize: 14\n};\nvar InstallPackageModal = ({ packageManager }) => {\n  const [state, setState] = React144.useState({ type: \"idle\" });\n  const [map, setMap] = React144.useState({});\n  const { previewServerState: ctx } = useContext73(StudioServerConnectionCtx);\n  const selectedPackages = Object.keys(map).filter((pkg) => map[pkg]);\n  const onClick = useCallback100(async () => {\n    if (state.type === \"done\") {\n      setState({ type: \"restarting\" });\n      restartStudio();\n      return;\n    }\n    setState({ type: \"installing\" });\n    try {\n      await installPackages(selectedPackages);\n      setState({ type: \"done\" });\n    } catch (err) {\n      setState({ type: \"error\", error: err });\n    }\n  }, [selectedPackages, state.type]);\n  const canSelectPackages = state.type === \"idle\" && ctx.type === \"connected\";\n  const disabled = !(canSelectPackages || state.type === \"done\") || selectedPackages.length === 0;\n  const { registerKeybinding } = useKeybinding();\n  useEffect73(() => {\n    if (disabled) {\n      return;\n    }\n    const enter = registerKeybinding({\n      callback() {\n        onClick();\n      },\n      commandCtrlKey: true,\n      key: \"Enter\",\n      event: \"keydown\",\n      preventDefault: true,\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: true\n    });\n    return () => {\n      enter.unregister();\n    };\n  }, [disabled, onClick, registerKeybinding]);\n  return /* @__PURE__ */ jsxs103(DismissableModal, {\n    children: [\n      /* @__PURE__ */ jsx209(ModalHeader, {\n        title: \"Install packages\"\n      }),\n      /* @__PURE__ */ jsx209(\"div\", {\n        style: container46,\n        className: VERTICAL_SCROLLBAR_CLASSNAME,\n        children: state.type === \"done\" ? /* @__PURE__ */ jsxs103(\"div\", {\n          style: text2,\n          children: [\n            \"Installed package\",\n            selectedPackages.length === 1 ? \"\" : \"s\",\n            \" \",\n            \"successfully. Restart the server to complete.\"\n          ]\n        }) : state.type === \"restarting\" ? /* @__PURE__ */ jsx209(\"div\", {\n          style: text2,\n          children: \"Restarting the Studio server...\"\n        }) : state.type === \"installing\" ? /* @__PURE__ */ jsxs103(\"div\", {\n          style: text2,\n          children: [\n            \"Installing package\",\n            selectedPackages.length === 1 ? \"\" : \"s\",\n            \". Check your terminal for progress.\"\n          ]\n        }) : /* @__PURE__ */ jsx209(\"div\", {\n          style: text2,\n          children: Object.entries(installableMap).filter(([, install]) => install).map(([pkgShort]) => {\n            const pkg = pkgShort === \"core\" ? \"remotion\" : `@remotion/${pkgShort}`;\n            const isInstalled = window.remotion_installedPackages?.includes(pkg) ?? false;\n            const link = apiDocs[pkgShort];\n            const description = descriptions[pkgShort];\n            if (!link) {\n              throw new Error(\"No link for \" + pkg);\n            }\n            if (!description) {\n              throw new Error(\"No description for \" + pkg);\n            }\n            return /* @__PURE__ */ jsxs103(Row, {\n              align: \"center\",\n              children: [\n                /* @__PURE__ */ jsx209(Checkbox, {\n                  checked: map[pkg],\n                  name: pkg,\n                  onChange: () => {\n                    setMap((prev) => ({ ...prev, [pkg]: !prev[pkg] }));\n                  },\n                  disabled: !canSelectPackages || isInstalled\n                }),\n                /* @__PURE__ */ jsx209(Spacing, {\n                  x: 1.5\n                }),\n                /* @__PURE__ */ jsx209(InstallablePackageComp, {\n                  description,\n                  isInstalled,\n                  link,\n                  pkg\n                })\n              ]\n            }, pkg);\n          })\n        })\n      }),\n      /* @__PURE__ */ jsx209(ModalFooterContainer, {\n        children: /* @__PURE__ */ jsxs103(Row, {\n          align: \"center\",\n          children: [\n            state.type === \"idle\" ? /* @__PURE__ */ jsxs103(\"span\", {\n              style: { color: LIGHT_TEXT, fontSize: 13, lineHeight: 1.2 },\n              children: [\n                \"This will install \",\n                selectedPackages.length,\n                \" package\",\n                selectedPackages.length === 1 ? \"\" : \"s\",\n                /* @__PURE__ */ jsx209(\"br\", {}),\n                \"using \",\n                packageManager,\n                \", Remotion v\",\n                VERSION2\n              ]\n            }) : null,\n            /* @__PURE__ */ jsx209(Flex, {}),\n            /* @__PURE__ */ jsxs103(ModalButton, {\n              onClick,\n              disabled,\n              children: [\n                state.type === \"restarting\" ? \"Restarting...\" : state.type === \"installing\" ? \"Installing...\" : state.type === \"done\" ? \"Restart Server\" : \"Install\",\n                disabled ? null : /* @__PURE__ */ jsx209(ShortcutHint, {\n                  keyToPress: \"\",\n                  cmdOrCtrl: true\n                })\n              ]\n            })\n          ]\n        })\n      })\n    ]\n  });\n};\n\n// src/components/NewComposition/DeleteComposition.tsx\nimport { useCallback as useCallback102, useContext as useContext76, useMemo as useMemo112 } from \"react\";\n\n// src/components/RenderModal/ResolveCompositionBeforeModal.tsx\nimport React145, { useContext as useContext74, useEffect as useEffect74, useMemo as useMemo111 } from \"react\";\nimport { Internals as Internals56 } from \"remotion\";\nimport { jsx as jsx210, jsxs as jsxs104 } from \"react/jsx-runtime\";\nvar loaderContainer2 = {\n  paddingTop: 40,\n  paddingBottom: 40,\n  paddingLeft: 100,\n  paddingRight: 100,\n  display: \"flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\",\n  flexDirection: \"column\"\n};\nvar loaderLabel2 = {\n  fontSize: 14,\n  color: LIGHT_TEXT,\n  fontFamily: \"sans-serif\",\n  lineHeight: 1.5\n};\nvar ResolvedCompositionContext = React145.createContext(null);\nvar ResolveCompositionBeforeModal = ({ compositionId, children }) => {\n  const resolved = Internals56.useResolvedVideoConfig(compositionId);\n  const unresolvedContext = useContext74(Internals56.CompositionManager);\n  const unresolved = unresolvedContext.compositions.find((c) => compositionId === c.id);\n  useEffect74(() => {\n    const { current } = Internals56.resolveCompositionsRef;\n    if (!current) {\n      throw new Error(\"No ref to trigger composition calc\");\n    }\n    current.setCurrentRenderModalComposition(compositionId);\n    return () => {\n      current.setCurrentRenderModalComposition(null);\n    };\n  }, [compositionId]);\n  if (!unresolved) {\n    throw new Error(\"Composition not found: \" + compositionId);\n  }\n  const value = useMemo111(() => {\n    return {\n      resolved,\n      unresolved\n    };\n  }, [resolved, unresolved]);\n  if (!resolved || resolved.type === \"loading\") {\n    return /* @__PURE__ */ jsx210(RunningCalculateMetadata, {});\n  }\n  if (resolved.type === \"error\") {\n    return /* @__PURE__ */ jsxs104(\"div\", {\n      style: loaderContainer2,\n      children: [\n        /* @__PURE__ */ jsx210(Spacing, {\n          y: 2\n        }),\n        /* @__PURE__ */ jsxs104(\"div\", {\n          style: loaderLabel2,\n          children: [\n            \"Running \",\n            /* @__PURE__ */ jsx210(\"code\", {\n              style: inlineCodeSnippet,\n              children: \"calculateMetadata()\"\n            }),\n            \" \",\n            \"yielded an error:\"\n          ]\n        }),\n        /* @__PURE__ */ jsx210(Spacing, {\n          y: 1\n        }),\n        /* @__PURE__ */ jsx210(\"div\", {\n          style: loaderLabel2,\n          children: resolved.error.message || \"Unknown error\"\n        })\n      ]\n    });\n  }\n  return /* @__PURE__ */ jsx210(ResolvedCompositionContext.Provider, {\n    value,\n    children\n  });\n};\n\n// src/components/NewComposition/CodemodFooter.tsx\nimport { useCallback as useCallback101, useContext as useContext75, useEffect as useEffect75, useState as useState70 } from \"react\";\n\n// src/components/NewComposition/DiffPreview.tsx\nimport { jsx as jsx211, jsxs as jsxs105 } from \"react/jsx-runtime\";\nvar CodemodDiffPreview = ({ status }) => {\n  if (status.type === \"loading\") {\n    return null;\n  }\n  if (status.type === \"fail\") {\n    return /* @__PURE__ */ jsx211(\"span\", {\n      style: { color: FAIL_COLOR, fontSize: 13, lineHeight: 1.2 },\n      children: status.error\n    });\n  }\n  return /* @__PURE__ */ jsxs105(\"div\", {\n    style: { lineHeight: 1.2 },\n    children: [\n      /* @__PURE__ */ jsx211(\"span\", {\n        style: { color: LIGHT_TEXT, fontSize: 13, lineHeight: 1.2 },\n        children: \"This will edit your Root file.\"\n      }),\n      /* @__PURE__ */ jsx211(\"br\", {}),\n      /* @__PURE__ */ jsxs105(\"span\", {\n        style: { color: BLUE, fontSize: 13, lineHeight: 1.2 },\n        children: [\n          status.diff.additions,\n          \" addition\",\n          status.diff.additions === 1 ? \"\" : \"s\",\n          \",\"\n        ]\n      }),\n      \" \",\n      /* @__PURE__ */ jsxs105(\"span\", {\n        style: {\n          color: SELECTED_GUIDE,\n          fontSize: 13,\n          lineHeight: 1.2\n        },\n        children: [\n          status.diff.deletions,\n          \" deletion\",\n          status.diff.deletions === 1 ? \"\" : \"s\"\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/NewComposition/CodemodFooter.tsx\nimport { jsx as jsx212, jsxs as jsxs106 } from \"react/jsx-runtime\";\nvar CodemodFooter = ({\n  codemod,\n  valid,\n  loadingNotification,\n  successNotification,\n  errorNotification,\n  genericSubmitLabel,\n  submitLabel\n}) => {\n  const [submitting, setSubmitting] = useState70(false);\n  const { setSelectedModal } = useContext75(ModalsContext);\n  const [codemodStatus, setCanApplyCodemod] = useState70({\n    type: \"loading\"\n  });\n  const [projectInfo, setProjectInfo] = useState70(null);\n  useEffect75(() => {\n    const controller = new AbortController;\n    getProjectInfo(controller.signal).then((info) => {\n      setProjectInfo(info.projectInfo);\n    }).catch((err) => {\n      showNotification(`Could not get project info: ${err.message}. Unable to duplicate composition`, 3000);\n    });\n    return () => {\n      controller.abort();\n    };\n  }, []);\n  const trigger = useCallback101(() => {\n    setSubmitting(true);\n    setSelectedModal(null);\n    const notification2 = showNotification(loadingNotification, null);\n    applyCodemod({\n      codemod,\n      dryRun: false,\n      signal: new AbortController().signal\n    }).then(() => {\n      notification2.replaceContent(successNotification, 2000);\n    }).catch((err) => {\n      notification2.replaceContent(`${errorNotification}: ${err.message}`, 2000);\n    });\n  }, [\n    codemod,\n    errorNotification,\n    loadingNotification,\n    setSelectedModal,\n    successNotification\n  ]);\n  const getCanApplyCodemod = useCallback101(async (signal) => {\n    const res = await applyCodemod({\n      codemod,\n      dryRun: true,\n      signal\n    });\n    if (res.success) {\n      setCanApplyCodemod({ type: \"success\", diff: res.diff });\n    } else {\n      setCanApplyCodemod({\n        type: \"fail\",\n        error: res.reason\n      });\n    }\n  }, [codemod]);\n  useEffect75(() => {\n    const abortController = new AbortController;\n    let aborted = false;\n    getCanApplyCodemod(abortController.signal).then(() => {\n      return;\n    }).catch((err) => {\n      if (aborted) {\n        return;\n      }\n      showNotification(`Cannot duplicate composition: ${err.message}`, 3000);\n    });\n    return () => {\n      aborted = true;\n      abortController.abort();\n    };\n  }, [codemodStatus, getCanApplyCodemod, setSelectedModal]);\n  const disabled = !valid || submitting || projectInfo === null || codemodStatus.type !== \"success\";\n  const { registerKeybinding } = useKeybinding();\n  useEffect75(() => {\n    if (disabled) {\n      return;\n    }\n    const enter = registerKeybinding({\n      callback() {\n        trigger();\n      },\n      commandCtrlKey: true,\n      key: \"Enter\",\n      event: \"keydown\",\n      preventDefault: true,\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      enter.unregister();\n    };\n  }, [disabled, registerKeybinding, trigger, valid]);\n  return /* @__PURE__ */ jsxs106(Row, {\n    align: \"center\",\n    children: [\n      /* @__PURE__ */ jsx212(CodemodDiffPreview, {\n        status: codemodStatus\n      }),\n      /* @__PURE__ */ jsx212(Flex, {}),\n      /* @__PURE__ */ jsx212(Spacing, {\n        block: true,\n        x: 2\n      }),\n      /* @__PURE__ */ jsxs106(ModalButton, {\n        onClick: trigger,\n        disabled,\n        children: [\n          projectInfo && projectInfo.relativeRootFile ? submitLabel({ relativeRootPath: projectInfo.relativeRootFile }) : genericSubmitLabel,\n          /* @__PURE__ */ jsx212(ShortcutHint, {\n            keyToPress: \"\",\n            cmdOrCtrl: true\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/NewComposition/DeleteComposition.tsx\nimport { jsx as jsx213, jsxs as jsxs107, Fragment as Fragment30 } from \"react/jsx-runtime\";\nvar content3 = {\n  padding: 16,\n  fontSize: 14,\n  flex: 1,\n  minWidth: 500\n};\nvar DeleteCompositionLoaded = ({ compositionId }) => {\n  const context = useContext76(ResolvedCompositionContext);\n  if (!context) {\n    throw new Error(\"Resolved composition context\");\n  }\n  const { unresolved } = context;\n  const codemod = useMemo112(() => {\n    return {\n      type: \"delete-composition\",\n      idToDelete: compositionId\n    };\n  }, [compositionId]);\n  const onSubmit = useCallback102((e) => {\n    e.preventDefault();\n  }, []);\n  return /* @__PURE__ */ jsxs107(Fragment30, {\n    children: [\n      /* @__PURE__ */ jsx213(ModalHeader, {\n        title: \"Delete composition\"\n      }),\n      /* @__PURE__ */ jsxs107(\"form\", {\n        onSubmit,\n        children: [\n          /* @__PURE__ */ jsxs107(\"div\", {\n            style: content3,\n            children: [\n              \"Do you want to delete the\",\n              \" \",\n              /* @__PURE__ */ jsx213(\"code\", {\n                style: inlineCodeSnippet,\n                children: unresolved.durationInFrames === 1 ? `<Still>` : \"<Composition>\"\n              }),\n              \" \",\n              \"with ID \",\n              '\"',\n              unresolved.id,\n              '\"',\n              \"?\",\n              /* @__PURE__ */ jsx213(\"br\", {}),\n              \"The associated \",\n              /* @__PURE__ */ jsx213(\"code\", {\n                style: inlineCodeSnippet,\n                children: \"component\"\n              }),\n              \" will remain in your code.\"\n            ]\n          }),\n          /* @__PURE__ */ jsx213(ModalFooterContainer, {\n            children: /* @__PURE__ */ jsx213(CodemodFooter, {\n              errorNotification: `Could not delete composition`,\n              loadingNotification: \"Deleting\",\n              successNotification: `Deleted ${unresolved.id}`,\n              genericSubmitLabel: `Delete`,\n              submitLabel: ({ relativeRootPath }) => `Delete from ${relativeRootPath}`,\n              codemod,\n              valid: true\n            })\n          })\n        ]\n      })\n    ]\n  });\n};\nvar DeleteComposition = ({ compositionId }) => {\n  return /* @__PURE__ */ jsx213(DismissableModal, {\n    children: /* @__PURE__ */ jsx213(ResolveCompositionBeforeModal, {\n      compositionId,\n      children: /* @__PURE__ */ jsx213(DeleteCompositionLoaded, {\n        compositionId\n      })\n    })\n  });\n};\n\n// src/components/NewComposition/DuplicateComposition.tsx\nimport { useCallback as useCallback104, useContext as useContext77, useMemo as useMemo113, useState as useState71 } from \"react\";\nimport { Internals as Internals58 } from \"remotion\";\n\n// src/helpers/validate-new-comp-data.ts\nimport { Internals as Internals57 } from \"remotion\";\nvar validateCompositionName = (compName, compositions) => {\n  if (!Internals57.isCompositionIdValid(compName)) {\n    return Internals57.invalidCompositionErrorMessage;\n  }\n  if (compositions.find((c) => c.id === compName)) {\n    return `A composition with that name already exists.`;\n  }\n  return null;\n};\nvar validateCompositionDimension = (dimension, value) => {\n  if (Number(value) % 2 !== 0) {\n    return `${dimension} should be divisible by 2, since H264 codec doesn't support odd dimensions.`;\n  }\n  if (Number.isNaN(Number(value))) {\n    return \"Invalid number.\";\n  }\n  if (Number(value) === 0) {\n    return dimension + \" cannot be zero.\";\n  }\n  return null;\n};\nvar validateCompositionDuration = (value) => {\n  if (value % 1 !== 0) {\n    return `Duration must be an integer.`;\n  }\n  if (Number.isNaN(value)) {\n    return \"Invalid number.\";\n  }\n  if (value === 0) {\n    return \"Duration cannot be zero.\";\n  }\n  return null;\n};\n\n// src/components/NewComposition/NewCompDuration.tsx\nimport { useCallback as useCallback103 } from \"react\";\nimport { jsx as jsx214, jsxs as jsxs108, Fragment as Fragment31 } from \"react/jsx-runtime\";\nvar NewCompDuration = ({ durationInFrames, setDurationInFrames }) => {\n  const onDurationInFramesChanged = useCallback103((newValue) => {\n    setDurationInFrames(Number(newValue));\n  }, [setDurationInFrames]);\n  const onDurationChangedDirectly = useCallback103((newVal) => {\n    setDurationInFrames(newVal);\n  }, [setDurationInFrames]);\n  const compDurationErrMessage = validateCompositionDuration(durationInFrames);\n  return /* @__PURE__ */ jsxs108(\"div\", {\n    style: optionRow,\n    children: [\n      /* @__PURE__ */ jsx214(\"div\", {\n        style: label5,\n        children: \"Duration in frames\"\n      }),\n      /* @__PURE__ */ jsxs108(\"div\", {\n        style: rightRow,\n        children: [\n          /* @__PURE__ */ jsx214(InputDragger, {\n            type: \"number\",\n            value: durationInFrames,\n            onTextChange: onDurationInFramesChanged,\n            placeholder: \"Duration (frames)\",\n            name: \"durationInFrames\",\n            min: 1,\n            step: 1,\n            required: true,\n            status: \"ok\",\n            max: 300000,\n            onValueChange: onDurationChangedDirectly,\n            rightAlign: false\n          }),\n          compDurationErrMessage ? /* @__PURE__ */ jsxs108(Fragment31, {\n            children: [\n              /* @__PURE__ */ jsx214(Spacing, {\n                y: 1,\n                block: true\n              }),\n              /* @__PURE__ */ jsx214(ValidationMessage, {\n                align: \"flex-start\",\n                message: compDurationErrMessage,\n                type: \"error\"\n              })\n            ]\n          }) : null\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/NewComposition/DuplicateComposition.tsx\nimport { jsx as jsx215, jsxs as jsxs109, Fragment as Fragment32 } from \"react/jsx-runtime\";\nvar content4 = {\n  padding: 12,\n  paddingRight: 12,\n  flex: 1,\n  fontSize: 13,\n  minWidth: 500\n};\nvar comboBoxStyle = {\n  width: 190\n};\nvar DuplicateCompositionLoaded = ({ initialType }) => {\n  const context = useContext77(ResolvedCompositionContext);\n  if (!context) {\n    throw new Error(\"Resolved composition context\");\n  }\n  const { resolved, unresolved } = context;\n  const [initialCompType] = useState71(initialType);\n  const hadDimensionsDefined = unresolved.width && unresolved.height;\n  const hadFpsDefined = unresolved.fps !== undefined;\n  const hadDurationDefined = unresolved.durationInFrames !== undefined;\n  const [selectedFrameRate, setFrameRate] = useState71(resolved.result.fps);\n  const { compositions } = useContext77(Internals58.CompositionManager);\n  const [type, setType] = useState71(initialCompType);\n  const [newId, setName] = useState71(() => {\n    const numberAtEnd = resolved.result.id.match(/([0-9]+)$/)?.[0];\n    let prefix = numberAtEnd ? Number(numberAtEnd) : 1;\n    const initialName = resolved.result.id.replace(/([0-9]+)$/, \"\");\n    let currentName = initialName;\n    while (true) {\n      currentName = initialName + prefix;\n      const err = validateCompositionName(currentName, compositions);\n      if (!err) {\n        break;\n      }\n      prefix++;\n    }\n    return currentName;\n  });\n  const [size4, setSize] = useState71(() => ({\n    width: resolved.result.width,\n    height: resolved.result.height\n  }));\n  const [durationInFrames, setDurationInFrames] = useState71(resolved.result.durationInFrames);\n  const onTypeChanged = useCallback104((newType) => {\n    setType(newType);\n  }, []);\n  const onWidthChanged = useCallback104((newValue) => {\n    setSize((s) => {\n      const { height } = s;\n      const newWidth = Number(newValue);\n      return {\n        height,\n        width: newWidth\n      };\n    });\n  }, []);\n  const onWidthDirectlyChanged = useCallback104((newWidth) => {\n    setSize((s) => {\n      const { height } = s;\n      return {\n        height,\n        width: newWidth\n      };\n    });\n  }, []);\n  const onHeightDirectlyChanged = useCallback104((newHeight) => {\n    setSize((s) => {\n      const { width: width2 } = s;\n      return {\n        width: width2,\n        height: newHeight\n      };\n    });\n  }, []);\n  const onHeightChanged = useCallback104((newValue) => {\n    setSize((s) => {\n      const { width: width2 } = s;\n      const newHeight = Number(newValue);\n      return {\n        width: width2,\n        height: newHeight\n      };\n    });\n  }, []);\n  const onNameChange = useCallback104((e) => {\n    setName(e.target.value);\n  }, []);\n  const onTextFpsChange = useCallback104((newFps) => {\n    setFrameRate(Number(newFps));\n  }, []);\n  const onFpsChange = useCallback104((newFps) => {\n    setFrameRate(newFps);\n  }, []);\n  const compNameErrMessage = validateCompositionName(newId, compositions);\n  const compWidthErrMessage = validateCompositionDimension(\"Width\", size4.width);\n  const compHeightErrMessage = validateCompositionDimension(\"Height\", size4.height);\n  const typeValues = useMemo113(() => {\n    return [\n      {\n        id: \"composition\",\n        keyHint: null,\n        label: \"<Composition />\",\n        leftItem: null,\n        onClick: () => onTypeChanged(\"composition\"),\n        subMenu: null,\n        type: \"item\",\n        value: \"composition\",\n        quickSwitcherLabel: null\n      },\n      {\n        id: \"still\",\n        keyHint: null,\n        label: \"<Still />\",\n        leftItem: null,\n        onClick: () => onTypeChanged(\"still\"),\n        subMenu: null,\n        type: \"item\",\n        value: \"still\",\n        quickSwitcherLabel: null\n      }\n    ];\n  }, [onTypeChanged]);\n  const valid = compNameErrMessage === null && compWidthErrMessage === null && compHeightErrMessage === null;\n  const codemod = useMemo113(() => {\n    return {\n      type: \"duplicate-composition\",\n      idToDuplicate: resolved.result.id,\n      newDurationInFrames: hadDurationDefined ? Number(durationInFrames) : null,\n      newFps: hadFpsDefined ? Number(selectedFrameRate) : null,\n      newHeight: hadDimensionsDefined ? Number(size4.height) : null,\n      newWidth: hadDimensionsDefined ? Number(size4.width) : null,\n      newId,\n      tag: type === \"still\" ? \"Still\" : \"Composition\"\n    };\n  }, [\n    durationInFrames,\n    hadDimensionsDefined,\n    hadDurationDefined,\n    hadFpsDefined,\n    newId,\n    resolved.result.id,\n    selectedFrameRate,\n    size4.height,\n    size4.width,\n    type\n  ]);\n  const onSubmit = useCallback104((e) => {\n    e.preventDefault();\n  }, []);\n  return /* @__PURE__ */ jsxs109(Fragment32, {\n    children: [\n      /* @__PURE__ */ jsx215(ModalHeader, {\n        title: `Duplicate ${resolved.result.id}`\n      }),\n      /* @__PURE__ */ jsxs109(\"form\", {\n        onSubmit,\n        children: [\n          /* @__PURE__ */ jsxs109(\"div\", {\n            style: content4,\n            children: [\n              initialCompType === \"composition\" ? /* @__PURE__ */ jsxs109(\"div\", {\n                style: optionRow,\n                children: [\n                  /* @__PURE__ */ jsx215(\"div\", {\n                    style: label5,\n                    children: \"Type\"\n                  }),\n                  /* @__PURE__ */ jsx215(\"div\", {\n                    style: rightRow,\n                    children: /* @__PURE__ */ jsx215(Combobox, {\n                      title: \"Type of composition\",\n                      style: comboBoxStyle,\n                      values: typeValues,\n                      selectedId: type\n                    })\n                  })\n                ]\n              }) : null,\n              /* @__PURE__ */ jsxs109(\"div\", {\n                style: optionRow,\n                children: [\n                  /* @__PURE__ */ jsx215(\"div\", {\n                    style: label5,\n                    children: \"ID\"\n                  }),\n                  /* @__PURE__ */ jsx215(\"div\", {\n                    style: rightRow,\n                    children: /* @__PURE__ */ jsxs109(\"div\", {\n                      children: [\n                        /* @__PURE__ */ jsx215(RemotionInput, {\n                          value: newId,\n                          onChange: onNameChange,\n                          type: \"text\",\n                          autoFocus: true,\n                          placeholder: \"Composition ID\",\n                          status: \"ok\",\n                          rightAlign: true\n                        }),\n                        compNameErrMessage ? /* @__PURE__ */ jsxs109(Fragment32, {\n                          children: [\n                            /* @__PURE__ */ jsx215(Spacing, {\n                              y: 1,\n                              block: true\n                            }),\n                            /* @__PURE__ */ jsx215(ValidationMessage, {\n                              align: \"flex-start\",\n                              message: compNameErrMessage,\n                              type: \"error\"\n                            })\n                          ]\n                        }) : null\n                      ]\n                    })\n                  })\n                ]\n              }),\n              hadDimensionsDefined ? /* @__PURE__ */ jsxs109(Fragment32, {\n                children: [\n                  /* @__PURE__ */ jsxs109(\"div\", {\n                    style: optionRow,\n                    children: [\n                      /* @__PURE__ */ jsx215(\"div\", {\n                        style: label5,\n                        children: \"Width\"\n                      }),\n                      /* @__PURE__ */ jsxs109(\"div\", {\n                        style: rightRow,\n                        children: [\n                          /* @__PURE__ */ jsx215(InputDragger, {\n                            type: \"number\",\n                            value: size4.width,\n                            placeholder: \"Width\",\n                            onTextChange: onWidthChanged,\n                            name: \"width\",\n                            step: 2,\n                            min: 2,\n                            required: true,\n                            status: \"ok\",\n                            formatter: (w) => `${w}px`,\n                            max: 1e8,\n                            onValueChange: onWidthDirectlyChanged,\n                            rightAlign: false\n                          }),\n                          compWidthErrMessage ? /* @__PURE__ */ jsxs109(Fragment32, {\n                            children: [\n                              /* @__PURE__ */ jsx215(Spacing, {\n                                y: 1,\n                                block: true\n                              }),\n                              /* @__PURE__ */ jsx215(ValidationMessage, {\n                                align: \"flex-start\",\n                                message: compWidthErrMessage,\n                                type: \"error\"\n                              })\n                            ]\n                          }) : null\n                        ]\n                      })\n                    ]\n                  }),\n                  /* @__PURE__ */ jsxs109(\"div\", {\n                    style: optionRow,\n                    children: [\n                      /* @__PURE__ */ jsx215(\"div\", {\n                        style: label5,\n                        children: \"Height\"\n                      }),\n                      /* @__PURE__ */ jsxs109(\"div\", {\n                        style: rightRow,\n                        children: [\n                          /* @__PURE__ */ jsx215(InputDragger, {\n                            type: \"number\",\n                            value: size4.height,\n                            onTextChange: onHeightChanged,\n                            placeholder: \"Height\",\n                            name: \"height\",\n                            step: 2,\n                            required: true,\n                            formatter: (h) => `${h}px`,\n                            min: 2,\n                            status: \"ok\",\n                            max: 1e8,\n                            onValueChange: onHeightDirectlyChanged,\n                            rightAlign: false\n                          }),\n                          compHeightErrMessage ? /* @__PURE__ */ jsxs109(Fragment32, {\n                            children: [\n                              /* @__PURE__ */ jsx215(Spacing, {\n                                y: 1,\n                                block: true\n                              }),\n                              /* @__PURE__ */ jsx215(ValidationMessage, {\n                                align: \"flex-start\",\n                                message: compHeightErrMessage,\n                                type: \"error\"\n                              })\n                            ]\n                          }) : null\n                        ]\n                      })\n                    ]\n                  })\n                ]\n              }) : null,\n              type === \"composition\" && hadDurationDefined ? /* @__PURE__ */ jsx215(NewCompDuration, {\n                durationInFrames,\n                setDurationInFrames\n              }) : null,\n              type === \"composition\" && hadFpsDefined ? /* @__PURE__ */ jsxs109(\"div\", {\n                style: optionRow,\n                children: [\n                  /* @__PURE__ */ jsx215(\"div\", {\n                    style: label5,\n                    children: \"FPS\"\n                  }),\n                  /* @__PURE__ */ jsx215(\"div\", {\n                    style: rightRow,\n                    children: /* @__PURE__ */ jsx215(InputDragger, {\n                      type: \"number\",\n                      value: selectedFrameRate,\n                      onTextChange: onTextFpsChange,\n                      placeholder: \"Frame rate (fps)\",\n                      name: \"fps\",\n                      min: 1,\n                      required: true,\n                      status: \"ok\",\n                      max: 240,\n                      step: 0.01,\n                      onValueChange: onFpsChange,\n                      rightAlign: false\n                    })\n                  })\n                ]\n              }) : null\n            ]\n          }),\n          /* @__PURE__ */ jsx215(ModalFooterContainer, {\n            children: /* @__PURE__ */ jsx215(CodemodFooter, {\n              loadingNotification: \"Duplicating...\",\n              errorNotification: \"Could not duplicate composition\",\n              successNotification: `Duplicated ${unresolved.id} as ${newId}`,\n              genericSubmitLabel: \"Duplicate\",\n              submitLabel: ({ relativeRootPath }) => `Add to ${relativeRootPath}`,\n              codemod,\n              valid\n            })\n          })\n        ]\n      })\n    ]\n  });\n};\nvar DuplicateComposition = ({ compositionId, compositionType }) => {\n  return /* @__PURE__ */ jsx215(DismissableModal, {\n    children: /* @__PURE__ */ jsx215(ResolveCompositionBeforeModal, {\n      compositionId,\n      children: /* @__PURE__ */ jsx215(DuplicateCompositionLoaded, {\n        initialType: compositionType\n      })\n    })\n  });\n};\n\n// src/components/NewComposition/RenameComposition.tsx\nimport { useCallback as useCallback105, useContext as useContext78, useMemo as useMemo114, useState as useState72 } from \"react\";\nimport { Internals as Internals59 } from \"remotion\";\nimport { jsx as jsx216, jsxs as jsxs110, Fragment as Fragment33 } from \"react/jsx-runtime\";\nvar content5 = {\n  padding: 12,\n  paddingRight: 12,\n  flex: 1,\n  fontSize: 13,\n  minWidth: 500\n};\nvar RenameCompositionLoaded = () => {\n  const context = useContext78(ResolvedCompositionContext);\n  if (!context) {\n    throw new Error(\"Resolved composition context\");\n  }\n  const { resolved } = context;\n  const { compositions } = useContext78(Internals59.CompositionManager);\n  const [newId, setName] = useState72(() => {\n    return resolved.result.id;\n  });\n  const onNameChange = useCallback105((e) => {\n    setName(e.target.value);\n  }, []);\n  const compNameErrMessage = newId === resolved.result.id ? null : validateCompositionName(newId, compositions);\n  const valid = compNameErrMessage === null && resolved.result.id !== newId;\n  const codemod = useMemo114(() => {\n    return {\n      type: \"rename-composition\",\n      idToRename: resolved.result.id,\n      newId\n    };\n  }, [newId, resolved.result.id]);\n  const onSubmit = useCallback105((e) => {\n    e.preventDefault();\n  }, []);\n  return /* @__PURE__ */ jsxs110(Fragment33, {\n    children: [\n      /* @__PURE__ */ jsx216(ModalHeader, {\n        title: `Rename ${resolved.result.id}`\n      }),\n      /* @__PURE__ */ jsxs110(\"form\", {\n        onSubmit,\n        children: [\n          /* @__PURE__ */ jsx216(\"div\", {\n            style: content5,\n            children: /* @__PURE__ */ jsxs110(\"div\", {\n              style: optionRow,\n              children: [\n                /* @__PURE__ */ jsx216(\"div\", {\n                  style: label5,\n                  children: \"ID\"\n                }),\n                /* @__PURE__ */ jsx216(\"div\", {\n                  style: rightRow,\n                  children: /* @__PURE__ */ jsxs110(\"div\", {\n                    children: [\n                      /* @__PURE__ */ jsx216(RemotionInput, {\n                        value: newId,\n                        onChange: onNameChange,\n                        type: \"text\",\n                        autoFocus: true,\n                        placeholder: \"Composition ID\",\n                        status: \"ok\",\n                        rightAlign: true\n                      }),\n                      compNameErrMessage ? /* @__PURE__ */ jsxs110(Fragment33, {\n                        children: [\n                          /* @__PURE__ */ jsx216(Spacing, {\n                            y: 1,\n                            block: true\n                          }),\n                          /* @__PURE__ */ jsx216(ValidationMessage, {\n                            align: \"flex-start\",\n                            message: compNameErrMessage,\n                            type: \"error\"\n                          })\n                        ]\n                      }) : null\n                    ]\n                  })\n                })\n              ]\n            })\n          }),\n          /* @__PURE__ */ jsx216(ModalFooterContainer, {\n            children: /* @__PURE__ */ jsx216(CodemodFooter, {\n              loadingNotification: \"Renaming...\",\n              errorNotification: \"Could not rename composition\",\n              successNotification: `Renamed to ${newId}`,\n              genericSubmitLabel: \"Rename\",\n              submitLabel: ({ relativeRootPath }) => `Modify ${relativeRootPath}`,\n              codemod,\n              valid\n            })\n          })\n        ]\n      })\n    ]\n  });\n};\nvar RenameComposition = ({ compositionId }) => {\n  return /* @__PURE__ */ jsx216(DismissableModal, {\n    children: /* @__PURE__ */ jsx216(ResolveCompositionBeforeModal, {\n      compositionId,\n      children: /* @__PURE__ */ jsx216(RenameCompositionLoaded, {})\n    })\n  });\n};\n\n// src/components/OverrideInputProps.tsx\nimport { useCallback as useCallback106, useContext as useContext79, useMemo as useMemo115, useState as useState73 } from \"react\";\nimport { Internals as Internals60 } from \"remotion\";\nimport { jsx as jsx217, jsxs as jsxs111 } from \"react/jsx-runtime\";\nvar style11 = {\n  padding: 12,\n  width: 500\n};\nvar label8 = {\n  color: LIGHT_TEXT,\n  fontSize: 14,\n  marginBottom: 10\n};\nvar textAreaStyle = {\n  fontFamily: \"monospace\",\n  minHeight: 200\n};\nvar codeSnippet2 = {\n  fontSize: 14,\n  color: BLUE,\n  fontFamily: \"monospace\"\n};\nvar row7 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  justifyContent: \"space-between\"\n};\nvar isValidJSON = (value) => {\n  try {\n    JSON.parse(value);\n    return true;\n  } catch {\n    return false;\n  }\n};\nvar Inner5 = () => {\n  const [value, setValue] = useState73(() => {\n    const override = Internals60.getInputPropsOverride();\n    if (override) {\n      return JSON.stringify(override, null, 2);\n    }\n    return null;\n  });\n  const { setSelectedModal } = useContext79(ModalsContext);\n  const valid = useMemo115(() => {\n    if (!value)\n      return true;\n    return isValidJSON(value);\n  }, [value]);\n  const onChange = useCallback106((newValue) => {\n    if (newValue.trim() === \"\") {\n      setValue(null);\n      Internals60.setInputPropsOverride(null);\n      return;\n    }\n    setValue(newValue);\n    if (!isValidJSON(newValue)) {\n      return;\n    }\n    Internals60.setInputPropsOverride(JSON.parse(newValue));\n  }, [setValue]);\n  const onReset = useCallback106(() => {\n    onChange(\"\");\n  }, [onChange]);\n  const onReloadPage = useCallback106(() => {\n    window.location.reload();\n  }, []);\n  const onDone = useCallback106(() => {\n    setSelectedModal(null);\n  }, [setSelectedModal]);\n  return /* @__PURE__ */ jsxs111(\"div\", {\n    style: style11,\n    children: [\n      /* @__PURE__ */ jsxs111(\"div\", {\n        style: label8,\n        children: [\n          \"Enter a valid JSON to override the value that\",\n          \" \",\n          /* @__PURE__ */ jsx217(\"code\", {\n            style: codeSnippet2,\n            children: \"getInputProps()\"\n          }),\n          \" returns to preview a composition with different props. The Studio must be reloaded to see the changes.\"\n        ]\n      }),\n      /* @__PURE__ */ jsx217(RemTextarea, {\n        onChange: (e) => onChange(e.target.value),\n        value: value ?? \"\",\n        status: valid ? \"ok\" : \"error\",\n        style: textAreaStyle\n      }),\n      /* @__PURE__ */ jsxs111(\"div\", {\n        style: row7,\n        children: [\n          /* @__PURE__ */ jsx217(Button, {\n            onClick: onReset,\n            children: \"Reset\"\n          }),\n          /* @__PURE__ */ jsx217(Spacing, {\n            x: 0.5\n          }),\n          /* @__PURE__ */ jsx217(Button, {\n            onClick: onReloadPage,\n            children: \"Reload page\"\n          }),\n          /* @__PURE__ */ jsx217(Flex, {}),\n          /* @__PURE__ */ jsx217(Button, {\n            onClick: onDone,\n            children: \"Done\"\n          })\n        ]\n      })\n    ]\n  });\n};\nvar OverrideInputPropsModal = () => {\n  return /* @__PURE__ */ jsx217(DismissableModal, {\n    children: /* @__PURE__ */ jsx217(Inner5, {})\n  });\n};\n\n// src/components/QuickSwitcher/QuickSwitcherContent.tsx\nimport {\n  useCallback as useCallback107,\n  useContext as useContext80,\n  useEffect as useEffect77,\n  useMemo as useMemo117,\n  useRef as useRef42,\n  useState as useState75\n} from \"react\";\nimport { Internals as Internals61 } from \"remotion\";\n\n// src/icons/keys.tsx\nimport { jsx as jsx218 } from \"react/jsx-runtime\";\nvar iconStyle5 = {\n  width: 10,\n  display: \"inline\"\n};\nvar ShiftIcon = () => {\n  return /* @__PURE__ */ jsx218(\"svg\", {\n    style: iconStyle5,\n    viewBox: \"0 0 448 512\",\n    children: /* @__PURE__ */ jsx218(\"path\", {\n      fill: \"currentColor\",\n      d: \"M48.048 304h73.798v128c0 26.51 21.49 48 48 48h108.308c26.51 0 48-21.49 48-48V304h73.789c42.638 0 64.151-51.731 33.941-81.941l-175.943-176c-18.745-18.745-49.137-18.746-67.882 0l-175.952 176C-16.042 252.208 5.325 304 48.048 304zM224 80l176 176H278.154v176H169.846V256H48L224 80z\"\n    })\n  });\n};\nvar ArrowLeft = () => {\n  return /* @__PURE__ */ jsx218(\"svg\", {\n    style: iconStyle5,\n    viewBox: \"0 0 448 512\",\n    children: /* @__PURE__ */ jsx218(\"path\", {\n      fill: \"currentColor\",\n      d: \"M257.5 445.1l-22.2 22.2c-9.4 9.4-24.6 9.4-33.9 0L7 273c-9.4-9.4-9.4-24.6 0-33.9L201.4 44.7c9.4-9.4 24.6-9.4 33.9 0l22.2 22.2c9.5 9.5 9.3 25-.4 34.3L136.6 216H424c13.3 0 24 10.7 24 24v32c0 13.3-10.7 24-24 24H136.6l120.5 114.8c9.8 9.3 10 24.8.4 34.3z\"\n    })\n  });\n};\nvar ArrowRight = () => {\n  return /* @__PURE__ */ jsx218(\"svg\", {\n    style: iconStyle5,\n    viewBox: \"0 0 448 512\",\n    children: /* @__PURE__ */ jsx218(\"path\", {\n      fill: \"currentColor\",\n      d: \"M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z\"\n    })\n  });\n};\n\n// src/components/KeyboardShortcutsExplainer.tsx\nimport { jsx as jsx219, jsxs as jsxs112, Fragment as Fragment34 } from \"react/jsx-runtime\";\nvar left3 = {\n  width: 85,\n  paddingTop: 8,\n  paddingBottom: 8\n};\nvar key4 = {\n  background: INPUT_BACKGROUND,\n  padding: \"3px 6px\",\n  color: \"white\",\n  borderRadius: 3,\n  border: \"1px solid \" + INPUT_BORDER_COLOR_UNHOVERED,\n  borderBottomWidth: 3,\n  fontSize: 14,\n  fontFamily: \"monospace\"\n};\nvar right2 = {\n  fontSize: 14,\n  color: \"#eee\"\n};\nvar container47 = {\n  paddingLeft: 20,\n  paddingRight: 40,\n  paddingTop: 10,\n  paddingBottom: 10\n};\nvar title4 = {\n  fontWeight: \"bold\",\n  color: \"white\",\n  fontSize: 14,\n  marginBottom: 10\n};\nvar keyboardShortcutsDisabled = {\n  padding: 12,\n  width: \"100%\",\n  fontSize: 14,\n  backgroundColor: \"rgba(255, 255, 255, 0.1)\"\n};\nvar ul = {\n  marginTop: 0,\n  marginBottom: 0\n};\nvar li = {\n  fontSize: 14\n};\nvar KeyboardShortcutsExplainer = () => {\n  return /* @__PURE__ */ jsxs112(\"div\", {\n    children: [\n      areKeyboardShortcutsDisabled() ? /* @__PURE__ */ jsxs112(\"div\", {\n        style: keyboardShortcutsDisabled,\n        children: [\n          \"Keyboard shortcuts disabled either due to:\",\n          /* @__PURE__ */ jsxs112(\"ul\", {\n            style: ul,\n            children: [\n              /* @__PURE__ */ jsx219(\"li\", {\n                style: li,\n                children: \"a) --disable-keyboard-shortcuts being passed\"\n              }),\n              /* @__PURE__ */ jsx219(\"li\", {\n                style: li,\n                children: \"b) Config.setKeyboardShortcutsEnabled(false) being set or\"\n              }),\n              /* @__PURE__ */ jsx219(\"li\", {\n                style: li,\n                children: \" c) a Remotion version mismatch.\"\n              })\n            ]\n          })\n        ]\n      }) : null,\n      /* @__PURE__ */ jsxs112(Row, {\n        style: container47,\n        children: [\n          /* @__PURE__ */ jsxs112(Column, {\n            children: [\n              /* @__PURE__ */ jsx219(\"div\", {\n                style: title4,\n                children: \"Playback\"\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsxs112(\"div\", {\n                    style: left3,\n                    children: [\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: /* @__PURE__ */ jsx219(ShiftIcon, {})\n                      }),\n                      /* @__PURE__ */ jsx219(Spacing, {\n                        x: 0.3\n                      }),\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: /* @__PURE__ */ jsx219(ArrowLeft, {})\n                      })\n                    ]\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"1 second back\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: /* @__PURE__ */ jsx219(ArrowLeft, {})\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Previous frame\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"Space\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Play / Pause\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: /* @__PURE__ */ jsx219(ArrowRight, {})\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Next frame\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsxs112(\"div\", {\n                    style: left3,\n                    children: [\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: /* @__PURE__ */ jsx219(ShiftIcon, {})\n                      }),\n                      /* @__PURE__ */ jsx219(Spacing, {\n                        x: 0.3\n                      }),\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: /* @__PURE__ */ jsx219(ArrowRight, {})\n                      })\n                    ]\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"1 second forward\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"A\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Jump to beginning\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"E\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Jump to end\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"J\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Reverse playback\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"K\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Pause\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"L\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Play / Speed up\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"G\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Go to frame\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"Enter\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Pause & return to playback start\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsx219(\"br\", {}),\n              /* @__PURE__ */ jsx219(\"div\", {\n                style: title4,\n                children: \"Sidebar\"\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsxs112(\"div\", {\n                    style: left3,\n                    children: [\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: cmdOrCtrlCharacter\n                      }),\n                      /* @__PURE__ */ jsx219(Spacing, {\n                        x: 0.3\n                      }),\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: \"B\"\n                      })\n                    ]\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Toggle left sidebar\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsxs112(\"div\", {\n                    style: left3,\n                    children: [\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: cmdOrCtrlCharacter\n                      }),\n                      /* @__PURE__ */ jsx219(Spacing, {\n                        x: 0.3\n                      }),\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: \"J\"\n                      })\n                    ]\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Toggle right sidebar\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsxs112(\"div\", {\n                    style: left3,\n                    children: [\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: cmdOrCtrlCharacter\n                      }),\n                      /* @__PURE__ */ jsx219(Spacing, {\n                        x: 0.3\n                      }),\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: \"G\"\n                      })\n                    ]\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Toggle both sidebars\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsx219(\"br\", {}),\n              /* @__PURE__ */ jsx219(\"div\", {\n                style: title4,\n                children: \"View\"\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"F\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Enter fullscreen\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"Esc\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Exit fullscreen\"\n                  })\n                ]\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx219(Spacing, {\n            x: 8\n          }),\n          /* @__PURE__ */ jsxs112(Column, {\n            children: [\n              /* @__PURE__ */ jsx219(\"div\", {\n                style: title4,\n                children: \"Navigation\"\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"PageUp\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Previous composition\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"PageDown\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Next composition\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"R\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Render composition\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"T\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Toggle checkerboard background\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"?\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Show keyboard shortcuts\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsxs112(\"div\", {\n                    style: left3,\n                    children: [\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: cmdOrCtrlCharacter\n                      }),\n                      /* @__PURE__ */ jsx219(Spacing, {\n                        x: 0.3\n                      }),\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: \"K\"\n                      })\n                    ]\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Quick Switcher\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsx219(\"br\", {}),\n              /* @__PURE__ */ jsx219(\"div\", {\n                style: title4,\n                children: \"Playback range\"\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"I\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Set In Point\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"O\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Set Out Point\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"X\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Clear In/Out Points\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsx219(\"br\", {}),\n              /* @__PURE__ */ jsx219(\"div\", {\n                style: title4,\n                children: \"Zoom\"\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"+\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Zoom in\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"-\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Zoom out\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: left3,\n                    children: /* @__PURE__ */ jsx219(\"kbd\", {\n                      style: key4,\n                      children: \"0\"\n                    })\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Reset zoom\"\n                  })\n                ]\n              }),\n              \" \",\n              /* @__PURE__ */ jsx219(\"br\", {}),\n              /* @__PURE__ */ jsx219(\"div\", {\n                style: title4,\n                children: \"Props Editor\"\n              }),\n              /* @__PURE__ */ jsxs112(Row, {\n                align: \"center\",\n                children: [\n                  /* @__PURE__ */ jsxs112(\"div\", {\n                    style: left3,\n                    children: [\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: cmdOrCtrlCharacter\n                      }),\n                      /* @__PURE__ */ jsx219(Spacing, {\n                        x: 0.3\n                      }),\n                      /* @__PURE__ */ jsx219(\"kbd\", {\n                        style: key4,\n                        children: \"S\"\n                      })\n                    ]\n                  }),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: right2,\n                    children: \"Save\"\n                  })\n                ]\n              }),\n              process.env.ASK_AI_ENABLED && /* @__PURE__ */ jsxs112(Fragment34, {\n                children: [\n                  /* @__PURE__ */ jsx219(\"br\", {}),\n                  /* @__PURE__ */ jsx219(\"div\", {\n                    style: title4,\n                    children: \"AI\"\n                  }),\n                  /* @__PURE__ */ jsxs112(Row, {\n                    align: \"center\",\n                    children: [\n                      /* @__PURE__ */ jsxs112(\"div\", {\n                        style: left3,\n                        children: [\n                          /* @__PURE__ */ jsx219(\"kbd\", {\n                            style: key4,\n                            children: cmdOrCtrlCharacter\n                          }),\n                          /* @__PURE__ */ jsx219(Spacing, {\n                            x: 0.3\n                          }),\n                          /* @__PURE__ */ jsx219(\"kbd\", {\n                            style: key4,\n                            children: \"I\"\n                          })\n                        ]\n                      }),\n                      /* @__PURE__ */ jsx219(\"div\", {\n                        style: right2,\n                        children: \"Ask AI\"\n                      })\n                    ]\n                  })\n                ]\n              })\n            ]\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/QuickSwitcher/AlgoliaCredit.tsx\nimport { jsx as jsx220 } from \"react/jsx-runtime\";\nvar link = {\n  display: \"inline-flex\"\n};\nvar AlgoliaCredit = () => {\n  return /* @__PURE__ */ jsx220(\"a\", {\n    style: link,\n    href: \"https://www.algolia.com/ref/docsearch/?utm_source=www.remotion.dev&utm_medium=referral&utm_content=powered_by&utm_campaign=docsearch\",\n    target: \"_blank\",\n    rel: \"noopener noreferrer\",\n    children: /* @__PURE__ */ jsx220(\"svg\", {\n      width: \"77\",\n      height: \"19\",\n      \"aria-label\": \"Algolia\",\n      role: \"img\",\n      children: /* @__PURE__ */ jsx220(\"path\", {\n        d: \"M2.5067 0h14.0245c1.384.001 2.5058 1.1205 2.5068 2.5017V16.5c-.0014 1.3808-1.1232 2.4995-2.5068 2.5H2.5067C1.1232 18.9995.0014 17.8808 0 16.5V2.4958A2.495 2.495 0 01.735.7294 2.505 2.505 0 012.5068 0zM37.95 15.0695c-3.7068.0168-3.7068-2.986-3.7068-3.4634L34.2372.3576 36.498 0v11.1794c0 .2715 0 1.9889 1.452 1.994v1.8961zm-9.1666-1.8388c.694 0 1.2086-.0397 1.5678-.1088v-2.2934a5.3639 5.3639 0 00-1.3303-.1679 4.8283 4.8283 0 00-.758.0582 2.2845 2.2845 0 00-.688.2024c-.2029.0979-.371.2362-.4919.4142-.1268.1788-.185.2826-.185.5533 0 .5297.185.8359.5205 1.0375.3355.2016.7928.3053 1.365.3053v-.0008zm-.1969-8.1817c.7463 0 1.3768.092 1.8856.2767.5088.1838.9195.4428 1.2204.7717.3068.334.5147.7777.6423 1.251.1327.4723.196.991.196 1.5603v5.798c-.5235.1036-1.05.192-1.5787.2649-.7048.1037-1.4976.156-2.3774.156-.5832 0-1.1215-.0582-1.6016-.167a3.385 3.385 0 01-1.2432-.5364 2.6034 2.6034 0 01-.8037-.9565c-.191-.3922-.29-.9447-.29-1.5208 0-.5533.11-.905.3246-1.2863a2.7351 2.7351 0 01.8849-.9329c.376-.242.8029-.415 1.2948-.5187a7.4517 7.4517 0 011.5381-.156 7.1162 7.1162 0 011.6667.2024V8.886c0-.259-.0296-.5061-.093-.7372a1.5847 1.5847 0 00-.3245-.6158 1.5079 1.5079 0 00-.6119-.4158 2.6788 2.6788 0 00-.966-.173c-.5206 0-.9948.0634-1.4283.1384a6.5481 6.5481 0 00-1.065.259l-.2712-1.849c.2831-.0986.7048-.1964 1.2491-.2943a9.2979 9.2979 0 011.752-.1501v.0008zm44.6597 8.1193c.6947 0 1.2086-.0405 1.567-.1097v-2.2942a5.3743 5.3743 0 00-1.3303-.1679c-.2485 0-.503.0177-.7573.0582a2.2853 2.2853 0 00-.688.2024 1.2333 1.2333 0 00-.4918.4142c-.1268.1788-.1843.2826-.1843.5533 0 .5297.1843.8359.5198 1.0375.3414.2066.7927.3053 1.365.3053v.0009zm-.191-8.1767c.7463 0 1.3768.0912 1.8856.2759.5087.1847.9195.4436 1.2204.7717.3.329.5147.7786.6414 1.251a5.7248 5.7248 0 01.197 1.562v5.7972c-.3466.0742-.874.1602-1.5788.2648-.7049.1038-1.4976.1552-2.3774.1552-.5832 0-1.1215-.0573-1.6016-.167a3.385 3.385 0 01-1.2432-.5356 2.6034 2.6034 0 01-.8038-.9565c-.191-.3922-.2898-.9447-.2898-1.5216 0-.5533.1098-.905.3245-1.2854a2.7373 2.7373 0 01.8849-.9338c.376-.2412.8029-.4141 1.2947-.5178a7.4545 7.4545 0 012.325-.1097c.2781.0287.5672.081.879.156v-.3686a2.7781 2.7781 0 00-.092-.738 1.5788 1.5788 0 00-.3246-.6166 1.5079 1.5079 0 00-.612-.415 2.6797 2.6797 0 00-.966-.1729c-.5205 0-.9947.0633-1.4282.1384a6.5608 6.5608 0 00-1.065.259l-.2712-1.8498c.283-.0979.7048-.1957 1.2491-.2935a9.8597 9.8597 0 011.752-.1494zm-6.79-1.072c-.7576.001-1.373-.6103-1.3759-1.3664 0-.755.6128-1.3664 1.376-1.3664.764 0 1.3775.6115 1.3775 1.3664s-.6195 1.3664-1.3776 1.3664zm1.1393 11.1507h-2.2726V5.3409l2.2734-.3568v10.0845l-.0008.0017zm-3.984 0c-3.707.0168-3.707-2.986-3.707-3.4642L59.7069.3576 61.9685 0v11.1794c0 .2715 0 1.9889 1.452 1.994V15.0703zm-7.3512-4.979c0-.975-.2138-1.7873-.6305-2.3516-.4167-.571-.9998-.852-1.747-.852-.7454 0-1.3302.281-1.7452.852-.4166.5702-.6195 1.3765-.6195 2.3516 0 .9851.208 1.6473.6254 2.2183.4158.576.9998.8587 1.7461.8587.7454 0 1.3303-.2885 1.747-.8595.4158-.5761.6237-1.2315.6237-2.2184v.0009zm2.3132-.006c0 .7609-.1099 1.3361-.3356 1.9654a4.654 4.654 0 01-.9533 1.6076A4.214 4.214 0 0155.613 14.69c-.579.2412-1.4697.3795-1.9143.3795-.4462-.005-1.3303-.1324-1.9033-.3795a4.307 4.307 0 01-1.474-1.0316c-.4115-.4445-.7293-.9801-.9609-1.6076a5.3423 5.3423 0 01-.3465-1.9653c0-.7608.104-1.493.3356-2.1155a4.683 4.683 0 01.9719-1.5958 4.3383 4.3383 0 011.479-1.0257c.5739-.242 1.2043-.3567 1.8864-.3567.6829 0 1.3125.1197 1.8906.3567a4.1245 4.1245 0 011.4816 1.0257 4.7587 4.7587 0 01.9592 1.5958c.2426.6225.3643 1.3547.3643 2.1155zm-17.0198 0c0 .9448.208 1.9932.6238 2.431.4166.4386.955.6579 1.6142.6579.3584 0 .6998-.0523 1.0176-.1502.3186-.0978.5721-.2134.775-.3517V7.0784a8.8706 8.8706 0 00-1.4926-.1906c-.8206-.0236-1.4452.312-1.8847.8468-.4335.5365-.6533 1.476-.6533 2.3516v-.0008zm6.2863 4.4485c0 1.5385-.3938 2.662-1.1866 3.3773-.791.7136-2.0005 1.0712-3.6308 1.0712-.5958 0-1.834-.1156-2.8228-.334l.3643-1.7865c.8282.173 1.9202.2193 2.4932.2193.9077 0 1.555-.1847 1.943-.5533.388-.3686.578-.916.578-1.643v-.3687a6.8289 6.8289 0 01-.8848.3349c-.3634.1096-.786.167-1.261.167-.6246 0-1.1917-.0979-1.7055-.2944a3.5554 3.5554 0 01-1.3244-.8645c-.3642-.3796-.6541-.8579-.8561-1.4289-.2028-.571-.3068-1.59-.3068-2.339 0-.7034.1099-1.5856.3245-2.1735.2198-.5871.5316-1.0949.9542-1.515.4167-.42.9255-.743 1.5213-.98a5.5923 5.5923 0 012.052-.3855c.7353 0 1.4114.092 2.0707.2024.6592.1088 1.2204.2236 1.6776.35v8.945-.0008zM11.5026 4.2418v-.6511c-.0005-.4553-.3704-.8241-.8266-.8241H8.749c-.4561 0-.826.3688-.8265.824v.669c0 .0742.0693.1264.1445.1096a6.0346 6.0346 0 011.6768-.2362 6.125 6.125 0 011.6202.2185.1116.1116 0 00.1386-.1097zm-5.2806.852l-.3296-.3282a.8266.8266 0 00-1.168 0l-.393.3922a.8199.8199 0 000 1.164l.3237.323c.0524.0515.1268.0397.1733-.0117.191-.259.3989-.507.6305-.7372.2374-.2362.48-.4437.7462-.6335.0575-.0354.0634-.1155.017-.1687zm3.5159 2.069v2.818c0 .081.0879.1392.1622.0987l2.5102-1.2964c.0574-.0287.0752-.0987.0464-.1552a3.1237 3.1237 0 00-2.603-1.574c-.0575 0-.115.0456-.115.1097l-.0008-.0009zm.0008 6.789c-2.0933.0005-3.7915-1.6912-3.7947-3.7804C5.9468 8.0821 7.6452 6.39 9.7387 6.391c2.0932-.0005 3.7911 1.6914 3.794 3.7804a3.7783 3.7783 0 01-1.1124 2.675 3.7936 3.7936 0 01-2.6824 1.1054h.0008zM9.738 4.8002c-1.9218 0-3.6975 1.0232-4.6584 2.6841a5.359 5.359 0 000 5.3683c.9609 1.661 2.7366 2.6841 4.6584 2.6841a5.3891 5.3891 0 003.8073-1.5725 5.3675 5.3675 0 001.578-3.7987 5.3574 5.3574 0 00-1.5771-3.797A5.379 5.379 0 009.7387 4.801l-.0008-.0008z\",\n        fill: \"currentColor\",\n        fillRule: \"evenodd\"\n      })\n    })\n  });\n};\n\n// src/components/QuickSwitcher/NoResults.tsx\nimport { jsxs as jsxs113 } from \"react/jsx-runtime\";\nvar container48 = {\n  padding: 80,\n  color: LIGHT_TEXT,\n  textAlign: \"center\",\n  fontSize: 14\n};\nvar MODE_TO_STRING = {\n  commands: \"commands\",\n  compositions: \"compositions\",\n  docs: \"documentation\"\n};\nvar QuickSwitcherNoResults = ({ query, mode }) => {\n  return /* @__PURE__ */ jsxs113(\"div\", {\n    style: container48,\n    children: [\n      \"No \",\n      MODE_TO_STRING[mode],\n      \" matching \",\n      '\"',\n      query,\n      '\"'\n    ]\n  });\n};\n\n// src/components/QuickSwitcher/QuickSwitcherResult.tsx\nimport { useEffect as useEffect76, useMemo as useMemo116, useRef as useRef41, useState as useState74 } from \"react\";\nimport { jsx as jsx221, jsxs as jsxs114, Fragment as Fragment35 } from \"react/jsx-runtime\";\nvar container49 = {\n  paddingLeft: 16,\n  paddingRight: 16,\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  cursor: \"pointer\"\n};\nvar label9 = {\n  whiteSpace: \"nowrap\",\n  textOverflow: \"ellipsis\"\n};\nvar searchLabel = {\n  ...label9,\n  lineHeight: 1.25\n};\nvar iconStyle6 = {\n  width: 14,\n  height: 14\n};\nvar labelContainer = {\n  overflow: \"hidden\",\n  flex: 1,\n  paddingTop: 5,\n  paddingBottom: 5\n};\nvar QuickSwitcherResult = ({ result, selected }) => {\n  const [hovered, setIsHovered] = useState74(false);\n  const ref = useRef41(null);\n  const keybindings = useKeybinding();\n  useEffect76(() => {\n    const { current } = ref;\n    if (!current) {\n      return;\n    }\n    const onMouseEnter = () => setIsHovered(true);\n    const onMouseLeave = () => setIsHovered(false);\n    current.addEventListener(\"mouseenter\", onMouseEnter);\n    current.addEventListener(\"mouseleave\", onMouseLeave);\n    return () => {\n      current.removeEventListener(\"mouseenter\", onMouseEnter);\n      current.removeEventListener(\"mouseleave\", onMouseLeave);\n    };\n  }, []);\n  useEffect76(() => {\n    if (!selected) {\n      return;\n    }\n    const binding = keybindings.registerKeybinding({\n      key: \"Enter\",\n      callback: result.onSelected,\n      commandCtrlKey: false,\n      event: \"keydown\",\n      preventDefault: true,\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      binding.unregister();\n    };\n  }, [keybindings, result.onSelected, selected]);\n  useEffect76(() => {\n    if (selected) {\n      ref.current?.scrollIntoView({\n        block: \"nearest\",\n        inline: \"center\"\n      });\n    }\n  }, [selected]);\n  const style12 = useMemo116(() => {\n    return {\n      ...container49,\n      backgroundColor: getBackgroundFromHoverState({\n        hovered,\n        selected\n      })\n    };\n  }, [hovered, selected]);\n  const labelStyle5 = useMemo116(() => {\n    return {\n      ...result.type === \"search-result\" ? searchLabel : label9,\n      color: result.type === \"search-result\" ? LIGHT_TEXT : selected || hovered ? \"white\" : LIGHT_TEXT,\n      fontSize: 15\n    };\n  }, [hovered, result.type, selected]);\n  return /* @__PURE__ */ jsxs114(\"div\", {\n    ref,\n    style: style12,\n    onClick: result.onSelected,\n    children: [\n      result.type === \"composition\" ? result.compositionType === \"still\" ? /* @__PURE__ */ jsx221(StillIcon, {\n        color: selected ? \"white\" : LIGHT_TEXT,\n        style: iconStyle6\n      }) : /* @__PURE__ */ jsx221(FilmIcon, {\n        color: selected ? \"white\" : LIGHT_TEXT,\n        style: iconStyle6\n      }) : null,\n      /* @__PURE__ */ jsx221(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsx221(\"div\", {\n        style: labelContainer,\n        children: result.type === \"search-result\" ? /* @__PURE__ */ jsxs114(Fragment35, {\n          children: [\n            /* @__PURE__ */ jsx221(\"div\", {\n              dangerouslySetInnerHTML: {\n                __html: result.titleLine\n              },\n              style: labelStyle5\n            }),\n            /* @__PURE__ */ jsx221(\"div\", {\n              dangerouslySetInnerHTML: {\n                __html: result.subtitleLine\n              },\n              style: labelStyle5\n            })\n          ]\n        }) : /* @__PURE__ */ jsx221(\"div\", {\n          style: labelStyle5,\n          children: result.title\n        })\n      })\n    ]\n  }, result.id);\n};\n\n// src/components/QuickSwitcher/algolia-search.ts\nimport { NoReactInternals as NoReactInternals15 } from \"remotion/no-react\";\nvar ALGOLIA_API_KEY = \"3e42dbd4f895fe93ff5cf40d860c4a85\";\nvar ALGOLIA_APPLICATION_ID = \"PLSDUOL1CA\";\nvar AGOLIA_SEARCH_URL = \"https://plsduol1ca-dsn.algolia.net/1/indexes/*/queries\";\nvar algoliaSearch = async (query) => {\n  const url = new URL(AGOLIA_SEARCH_URL);\n  url.searchParams.set(\"x-algolia-agen\", encodeURIComponent(\"Remotion Studio DocSearch\"));\n  url.searchParams.set(\"x-algolia-api-key\", ALGOLIA_API_KEY);\n  url.searchParams.set(\"x-algolia-application-id\", ALGOLIA_APPLICATION_ID);\n  const { results } = await fetch(url.toString(), {\n    headers: {\n      \"content-type\": \"application/x-www-form-urlencoded\"\n    },\n    body: JSON.stringify({\n      requests: [\n        {\n          query,\n          indexName: \"remotion\",\n          params: 'attributesToRetrieve=[\"hierarchy.lvl0\",\"hierarchy.lvl1\",\"hierarchy.lvl2\",\"hierarchy.lvl3\",\"hierarchy.lvl4\",\"hierarchy.lvl5\",\"hierarchy.lvl6\",\"content\",\"type\",\"url\"]&attributesToSnippet=[\"hierarchy.lvl1:10\",\"hierarchy.lvl2:10\",\"hierarchy.lvl3:10\",\"hierarchy.lvl4:10\",\"hierarchy.lvl5:10\",\"hierarchy.lvl6:10\",\"content:10\"]&hitsPerPage=20'\n        }\n      ]\n    }),\n    method: \"POST\"\n  }).then((res) => res.json());\n  const { hits } = results[0];\n  return hits.map((hit) => {\n    const entries = Object.values(hit._highlightResult.hierarchy);\n    const result = entries.find((value) => value.matchLevel === \"full\") ?? entries.find((value) => value.matchLevel === \"partial\");\n    const { subtitle: subtitle3, title: title5 } = splitMatchIntoTitleAndSubtitle(hit);\n    if (!result) {\n      return null;\n    }\n    return {\n      type: \"search-result\",\n      id: hit.objectID,\n      title: \"Should not display\",\n      titleLine: title5,\n      subtitleLine: subtitle3,\n      onSelected: () => {\n        window.open(hit.url);\n      }\n    };\n  }).filter(NoReactInternals15.truthy);\n};\nvar splitMatchIntoTitleAndSubtitle = (match) => {\n  const main = match.type === \"content\" ? match._highlightResult.content : match._highlightResult.hierarchy[match.type];\n  const title5 = main.value;\n  const subtitle3 = Object.entries(match._highlightResult.hierarchy).filter(([level]) => level !== match.type).map((value) => value[1].value).join(\"  \");\n  return { title: title5, subtitle: subtitle3 };\n};\n\n// src/components/QuickSwitcher/fuzzy-search.ts\nfunction fuzzySearch(query, dataset) {\n  const q = query ? query.trim().toLowerCase() : \"\";\n  const matchingIndices = [];\n  if (q.length === 0) {\n    for (let i = 0;i < dataset.length; i++) {\n      matchingIndices.push(i);\n    }\n    return dataset.filter((_, i) => matchingIndices.includes(i));\n  }\n  dataset.forEach((d, index) => {\n    const s = d.title.trim().toLowerCase();\n    let i = 0;\n    let n = -1;\n    let l;\n    for (;l = q[i++]; )\n      if (!~(n = s.indexOf(l, n + 1)))\n        return;\n    matchingIndices.push(index);\n  });\n  return dataset.filter((_, i) => matchingIndices.includes(i));\n}\n\n// src/components/QuickSwitcher/QuickSwitcherContent.tsx\nimport { jsx as jsx222, jsxs as jsxs115, Fragment as Fragment36 } from \"react/jsx-runtime\";\nvar input2 = {\n  width: \"100%\"\n};\nvar modeSelector = {\n  paddingLeft: 16,\n  paddingRight: 16,\n  display: \"flex\",\n  flexDirection: \"row\",\n  paddingTop: 8,\n  paddingBottom: 5\n};\nvar modeItem = {\n  appearance: \"none\",\n  border: \"none\",\n  fontFamily: \"inherit\",\n  padding: 0,\n  fontSize: 13,\n  cursor: \"pointer\"\n};\nvar modeInactive = {\n  ...modeItem,\n  color: LIGHT_TEXT\n};\nvar modeActive = {\n  ...modeItem,\n  color: \"white\",\n  fontWeight: \"bold\"\n};\nvar content6 = {\n  paddingLeft: 16,\n  paddingRight: 16,\n  paddingTop: 4,\n  paddingBottom: 10,\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar loopIndex = (index, length) => {\n  if (index < 0) {\n    index += length;\n  }\n  return index % length;\n};\nvar stripQuery = (query) => {\n  if (query.startsWith(\">\") || query.startsWith(\"?\")) {\n    return query.substring(1).trim();\n  }\n  return query.trim();\n};\nvar mapQueryToMode = (query) => {\n  return query.startsWith(\">\") ? \"commands\" : query.startsWith(\"?\") ? \"docs\" : \"compositions\";\n};\nvar mapModeToQuery = (mode) => {\n  if (mode === \"commands\") {\n    return \"> \";\n  }\n  if (mode === \"compositions\") {\n    return \"\";\n  }\n  if (mode === \"docs\") {\n    return \"? \";\n  }\n  throw new Error(\"no mode\" + mode);\n};\nvar QuickSwitcherContent = ({ initialMode, invocationTimestamp, readOnlyStudio }) => {\n  const { compositions } = useContext80(Internals61.CompositionManager);\n  const [state, setState] = useState75(() => {\n    return {\n      query: mapModeToQuery(initialMode),\n      selectedIndex: 0\n    };\n  });\n  useEffect77(() => {\n    setState({\n      query: mapModeToQuery(initialMode),\n      selectedIndex: 0\n    });\n  }, [initialMode, invocationTimestamp]);\n  const inputRef = useRef42(null);\n  const selectComposition = useSelectComposition();\n  const closeMenu = useCallback107(() => {\n    return;\n  }, []);\n  const actions = useMenuStructure(closeMenu, readOnlyStudio);\n  const [docResults, setDocResults] = useState75({ type: \"initial\" });\n  const { setSelectedModal } = useContext80(ModalsContext);\n  const keybindings = useKeybinding();\n  const mode = mapQueryToMode(state.query);\n  const actualQuery = useMemo117(() => {\n    return stripQuery(state.query);\n  }, [state.query]);\n  const menuActions = useMemo117(() => {\n    if (mode !== \"commands\") {\n      return [];\n    }\n    return makeSearchResults(actions, setSelectedModal);\n  }, [actions, mode, setSelectedModal]);\n  const resultsArray = useMemo117(() => {\n    if (mode === \"commands\") {\n      return fuzzySearch(actualQuery, menuActions);\n    }\n    if (mode === \"docs\" && docResults.type === \"results\") {\n      return docResults.results;\n    }\n    return fuzzySearch(actualQuery, compositions.map((c) => {\n      return {\n        id: \"composition-\" + c.id,\n        title: c.id,\n        type: \"composition\",\n        onSelected: () => {\n          selectComposition(c, true);\n          setSelectedModal(null);\n          const selector = `.__remotion-composition[data-compname=\"${c.id}\"]`;\n          Internals61.compositionSelectorRef.current?.expandComposition(c.id);\n          waitForElm(selector).then(() => {\n            document.querySelector(selector)?.scrollIntoView({ block: \"center\" });\n          });\n        },\n        compositionType: isCompositionStill(c) ? \"still\" : \"composition\"\n      };\n    }));\n  }, [\n    mode,\n    actualQuery,\n    compositions,\n    menuActions,\n    docResults,\n    selectComposition,\n    setSelectedModal\n  ]);\n  const onArrowDown = useCallback107(() => {\n    setState((s) => {\n      return {\n        ...s,\n        selectedIndex: s.selectedIndex + 1\n      };\n    });\n  }, []);\n  const onArrowUp = useCallback107(() => {\n    setState((s) => {\n      return {\n        ...s,\n        selectedIndex: s.selectedIndex - 1\n      };\n    });\n  }, []);\n  useEffect77(() => {\n    const binding = keybindings.registerKeybinding({\n      key: \"ArrowUp\",\n      callback: onArrowUp,\n      commandCtrlKey: false,\n      event: \"keydown\",\n      preventDefault: true,\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      binding.unregister();\n    };\n  }, [keybindings, onArrowDown, onArrowUp]);\n  useEffect77(() => {\n    if (mode !== \"docs\") {\n      return;\n    }\n    if (actualQuery.trim() === \"\") {\n      setDocResults({ type: \"initial\" });\n      return;\n    }\n    let cancelled = false;\n    setDocResults({ type: \"loading\" });\n    algoliaSearch(actualQuery).then((agoliaResults) => {\n      if (cancelled) {\n        return;\n      }\n      setDocResults({ type: \"results\", results: agoliaResults });\n    }).catch((err) => {\n      if (cancelled) {\n        return;\n      }\n      setDocResults({ type: \"error\", error: err });\n    });\n    return () => {\n      cancelled = true;\n    };\n  }, [actualQuery, mode]);\n  useEffect77(() => {\n    const binding = keybindings.registerKeybinding({\n      key: \"ArrowDown\",\n      callback: onArrowDown,\n      commandCtrlKey: false,\n      event: \"keydown\",\n      preventDefault: true,\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      binding.unregister();\n    };\n  }, [keybindings, onArrowDown]);\n  const onTextChange = useCallback107((e) => {\n    setState({ query: e.target.value, selectedIndex: 0 });\n  }, []);\n  const selectedIndexRounded = loopIndex(state.selectedIndex, resultsArray.length);\n  const onActionsSelected = useCallback107(() => {\n    setState((s) => ({\n      query: `> ${stripQuery(s.query)}`,\n      selectedIndex: 0\n    }));\n    inputRef.current?.focus();\n  }, []);\n  const onCompositionsSelected = useCallback107(() => {\n    setState((s) => ({\n      query: stripQuery(s.query),\n      selectedIndex: 0\n    }));\n    inputRef.current?.focus();\n  }, []);\n  const onDocSearchSelected = useCallback107(() => {\n    setState((s) => ({\n      query: `? ${stripQuery(s.query)}`,\n      selectedIndex: 0\n    }));\n    setDocResults({ type: \"initial\" });\n    inputRef.current?.focus();\n  }, []);\n  const showKeyboardShortcuts = mode === \"docs\" && actualQuery.trim() === \"\";\n  const showSearchLoadingState = mode === \"docs\" && docResults.type === \"loading\";\n  const container50 = useMemo117(() => {\n    return {\n      width: showKeyboardShortcuts ? 800 : 500\n    };\n  }, [showKeyboardShortcuts]);\n  const results = useMemo117(() => {\n    if (showKeyboardShortcuts) {\n      return {\n        maxHeight: 600,\n        overflowY: \"auto\"\n      };\n    }\n    return {\n      overflowY: \"auto\",\n      height: 300\n    };\n  }, [showKeyboardShortcuts]);\n  return /* @__PURE__ */ jsxs115(\"div\", {\n    style: container50,\n    children: [\n      /* @__PURE__ */ jsxs115(\"div\", {\n        style: modeSelector,\n        children: [\n          /* @__PURE__ */ jsx222(\"button\", {\n            onClick: onCompositionsSelected,\n            style: mode === \"compositions\" ? modeActive : modeInactive,\n            type: \"button\",\n            children: \"Compositions\"\n          }),\n          /* @__PURE__ */ jsx222(Spacing, {\n            x: 1\n          }),\n          /* @__PURE__ */ jsx222(\"button\", {\n            onClick: onActionsSelected,\n            style: mode === \"commands\" ? modeActive : modeInactive,\n            type: \"button\",\n            children: \"Actions\"\n          }),\n          /* @__PURE__ */ jsx222(Spacing, {\n            x: 1\n          }),\n          /* @__PURE__ */ jsx222(\"button\", {\n            onClick: onDocSearchSelected,\n            style: mode === \"docs\" ? modeActive : modeInactive,\n            type: \"button\",\n            children: \"Documentation\"\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs115(\"div\", {\n        style: content6,\n        children: [\n          /* @__PURE__ */ jsx222(RemotionInput, {\n            ref: inputRef,\n            type: \"text\",\n            style: input2,\n            autoFocus: true,\n            status: \"ok\",\n            value: state.query,\n            onChange: onTextChange,\n            placeholder: \"Search compositions...\",\n            rightAlign: false\n          }),\n          showKeyboardShortcuts ? /* @__PURE__ */ jsxs115(Fragment36, {\n            children: [\n              /* @__PURE__ */ jsx222(Spacing, {\n                x: 2\n              }),\n              \" \",\n              /* @__PURE__ */ jsx222(AlgoliaCredit, {})\n            ]\n          }) : null\n        ]\n      }),\n      /* @__PURE__ */ jsx222(\"div\", {\n        style: results,\n        className: VERTICAL_SCROLLBAR_CLASSNAME,\n        children: showKeyboardShortcuts ? /* @__PURE__ */ jsx222(KeyboardShortcutsExplainer, {}) : showSearchLoadingState ? null : resultsArray.length === 0 ? /* @__PURE__ */ jsx222(QuickSwitcherNoResults, {\n          mode,\n          query: actualQuery\n        }) : resultsArray.map((result, i) => {\n          return /* @__PURE__ */ jsx222(QuickSwitcherResult, {\n            selected: selectedIndexRounded === i,\n            result\n          }, result.id);\n        })\n      })\n    ]\n  });\n};\nfunction waitForElm(selector) {\n  return new Promise((resolve) => {\n    if (document.querySelector(selector)) {\n      resolve(document.querySelector(selector));\n      return;\n    }\n    const observer = new MutationObserver(() => {\n      if (document.querySelector(selector)) {\n        resolve(document.querySelector(selector));\n        observer.disconnect();\n      }\n    });\n    observer.observe(document.body, {\n      childList: true,\n      subtree: true\n    });\n  });\n}\n\n// src/components/QuickSwitcher/QuickSwitcher.tsx\nimport { jsx as jsx223 } from \"react/jsx-runtime\";\nvar QuickSwitcher = ({ initialMode, invocationTimestamp, readOnlyStudio }) => {\n  return /* @__PURE__ */ jsx223(DismissableModal, {\n    children: /* @__PURE__ */ jsx223(QuickSwitcherContent, {\n      readOnlyStudio,\n      invocationTimestamp,\n      initialMode\n    })\n  });\n};\nvar QuickSwitcher_default = QuickSwitcher;\n\n// src/components/RenderModal/RenderStatusModal.tsx\nimport { useCallback as useCallback109, useContext as useContext81 } from \"react\";\n\n// src/components/RenderModal/ClientRenderProgress.tsx\nimport { formatBytes as formatBytes2 } from \"@remotion/studio-shared\";\n\n// src/components/RenderQueue/SuccessIcon.tsx\nimport { jsx as jsx224 } from \"react/jsx-runtime\";\nvar iconStyle7 = {\n  height: RENDER_STATUS_INDICATOR_SIZE,\n  width: RENDER_STATUS_INDICATOR_SIZE\n};\nvar SuccessIcon = () => {\n  return /* @__PURE__ */ jsx224(\"svg\", {\n    style: iconStyle7,\n    viewBox: \"0 0 512 512\",\n    children: /* @__PURE__ */ jsx224(\"path\", {\n      fill: LIGHT_TEXT,\n      d: \"M256 512c141.4 0 256-114.6 256-256S397.4 0 256 0S0 114.6 0 256S114.6 512 256 512zM369 209L241 337l-17 17-17-17-64-64-17-17L160 222.1l17 17 47 47L335 175l17-17L385.9 192l-17 17z\"\n    })\n  });\n};\n\n// src/components/RenderModal/ClientRenderProgress.tsx\nimport { jsx as jsx225, jsxs as jsxs116 } from \"react/jsx-runtime\";\nvar progressItem = {\n  padding: 10,\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar label10 = {\n  fontSize: 14,\n  width: 400,\n  color: \"white\"\n};\nvar right3 = {\n  fontSize: 14,\n  color: LIGHT_TEXT,\n  textAlign: \"right\",\n  flex: 1\n};\nvar RenderingProgress = ({ renderedFrames, totalFrames }) => {\n  const done = renderedFrames === totalFrames;\n  const progress = totalFrames > 0 ? renderedFrames / totalFrames : 0;\n  return /* @__PURE__ */ jsxs116(\"div\", {\n    style: progressItem,\n    children: [\n      done ? /* @__PURE__ */ jsx225(SuccessIcon, {}) : /* @__PURE__ */ jsx225(CircularProgress, {\n        progress\n      }),\n      /* @__PURE__ */ jsx225(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsx225(\"div\", {\n        style: label10,\n        children: done ? `Rendered ${totalFrames} frames` : `Rendering ${renderedFrames} / ${totalFrames} frames`\n      })\n    ]\n  });\n};\nvar EncodingProgress = ({ encodedFrames, totalFrames }) => {\n  const done = encodedFrames === totalFrames;\n  const progress = totalFrames > 0 ? encodedFrames / totalFrames : 0;\n  return /* @__PURE__ */ jsxs116(\"div\", {\n    style: progressItem,\n    children: [\n      done ? /* @__PURE__ */ jsx225(SuccessIcon, {}) : /* @__PURE__ */ jsx225(CircularProgress, {\n        progress\n      }),\n      /* @__PURE__ */ jsx225(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsx225(\"div\", {\n        style: label10,\n        children: done ? `Encoded ${totalFrames} frames` : `Encoding ${encodedFrames} / ${totalFrames} frames`\n      })\n    ]\n  });\n};\nvar DoneStatus = ({ job }) => {\n  return /* @__PURE__ */ jsxs116(\"div\", {\n    style: progressItem,\n    children: [\n      /* @__PURE__ */ jsx225(SuccessIcon, {}),\n      /* @__PURE__ */ jsx225(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsx225(\"div\", {\n        style: label10,\n        children: job.outName\n      }),\n      /* @__PURE__ */ jsx225(\"div\", {\n        style: right3,\n        children: formatBytes2(job.metadata.sizeInBytes)\n      })\n    ]\n  });\n};\nvar ClientRenderProgress = ({ job }) => {\n  if (job.status === \"idle\" || job.status === \"failed\" || job.status === \"cancelled\") {\n    throw new Error(\"This component should not be rendered when the job is idle, failed, or cancelled\");\n  }\n  if (job.status === \"done\") {\n    return /* @__PURE__ */ jsxs116(\"div\", {\n      children: [\n        /* @__PURE__ */ jsx225(Spacing, {\n          y: 0.5\n        }),\n        /* @__PURE__ */ jsx225(DoneStatus, {\n          job\n        }),\n        /* @__PURE__ */ jsx225(Spacing, {\n          y: 1\n        })\n      ]\n    });\n  }\n  const { renderedFrames, encodedFrames, totalFrames } = job.progress;\n  return /* @__PURE__ */ jsxs116(\"div\", {\n    children: [\n      /* @__PURE__ */ jsx225(Spacing, {\n        y: 0.5\n      }),\n      /* @__PURE__ */ jsx225(RenderingProgress, {\n        renderedFrames,\n        totalFrames\n      }),\n      job.type === \"client-video\" && /* @__PURE__ */ jsx225(EncodingProgress, {\n        encodedFrames,\n        totalFrames\n      }),\n      /* @__PURE__ */ jsx225(Spacing, {\n        y: 1\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/GuiRenderStatus.tsx\nimport { useCallback as useCallback108, useMemo as useMemo118 } from \"react\";\nimport { jsx as jsx226, jsxs as jsxs117 } from \"react/jsx-runtime\";\nvar progressItem2 = {\n  padding: 10,\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar label11 = {\n  fontSize: 14,\n  width: 400,\n  color: \"white\"\n};\nvar right4 = {\n  fontSize: 14,\n  color: LIGHT_TEXT,\n  textAlign: \"right\",\n  flex: 1\n};\nvar BundlingProgress = ({ progress, doneIn }) => {\n  return /* @__PURE__ */ jsxs117(\"div\", {\n    style: progressItem2,\n    children: [\n      progress === 1 ? /* @__PURE__ */ jsx226(SuccessIcon, {}) : /* @__PURE__ */ jsx226(CircularProgress, {\n        progress\n      }),\n      /* @__PURE__ */ jsx226(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsx226(\"div\", {\n        style: label11,\n        children: progress === 1 ? \"Bundled\" : `Bundling ${progress * 100}%`\n      }),\n      doneIn ? /* @__PURE__ */ jsxs117(\"div\", {\n        style: right4,\n        children: [\n          doneIn,\n          \"ms\"\n        ]\n      }) : null\n    ]\n  });\n};\nvar BrowserSetupProgress = ({ progress, doneIn, startedBundling, alreadyAvailable }) => {\n  return /* @__PURE__ */ jsxs117(\"div\", {\n    style: progressItem2,\n    children: [\n      progress === 1 || alreadyAvailable ? /* @__PURE__ */ jsx226(SuccessIcon, {}) : /* @__PURE__ */ jsx226(CircularProgress, {\n        progress\n      }),\n      /* @__PURE__ */ jsx226(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsx226(\"div\", {\n        style: label11,\n        children: alreadyAvailable && startedBundling ? \"Headless browser already available\" : progress === 1 ? \"Downloaded Headless Shell\" : `Downloading Headless Shell ${Math.round(progress * 100)}%`\n      }),\n      doneIn ? /* @__PURE__ */ jsxs117(\"div\", {\n        style: right4,\n        children: [\n          doneIn,\n          \"ms\"\n        ]\n      }) : null\n    ]\n  });\n};\nvar RenderingProgress2 = ({ progress }) => {\n  return /* @__PURE__ */ jsxs117(\"div\", {\n    style: progressItem2,\n    children: [\n      progress.frames === progress.totalFrames ? /* @__PURE__ */ jsx226(SuccessIcon, {}) : /* @__PURE__ */ jsx226(CircularProgress, {\n        progress: progress.frames / progress.totalFrames\n      }),\n      /* @__PURE__ */ jsx226(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsx226(\"div\", {\n        style: label11,\n        children: progress.doneIn ? `Rendered ${progress.totalFrames} frames` : `Rendering ${progress.frames} / ${progress.totalFrames} frames`\n      }),\n      progress.doneIn ? /* @__PURE__ */ jsxs117(\"div\", {\n        style: right4,\n        children: [\n          progress.doneIn,\n          \"ms\"\n        ]\n      }) : null\n    ]\n  });\n};\nvar StitchingProgress = ({ progress }) => {\n  return /* @__PURE__ */ jsxs117(\"div\", {\n    style: progressItem2,\n    children: [\n      progress.frames === progress.totalFrames ? /* @__PURE__ */ jsx226(SuccessIcon, {}) : /* @__PURE__ */ jsx226(CircularProgress, {\n        progress: progress.frames / progress.totalFrames\n      }),\n      /* @__PURE__ */ jsx226(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsx226(\"div\", {\n        style: label11,\n        children: progress.doneIn ? `Encoded ${progress.totalFrames} frames` : `Encoding ${progress.frames} / ${progress.totalFrames} frames`\n      }),\n      progress.doneIn ? /* @__PURE__ */ jsxs117(\"div\", {\n        style: right4,\n        children: [\n          progress.doneIn,\n          \"ms\"\n        ]\n      }) : null\n    ]\n  });\n};\nvar DownloadsProgress = ({ downloads }) => {\n  const allHaveProgress = downloads.every((a) => a.totalBytes);\n  const totalBytes = allHaveProgress ? downloads.reduce((a, b) => a + b.totalBytes, 0) : null;\n  const downloaded = allHaveProgress ? downloads.reduce((a, b) => a + b.downloaded, 0) : null;\n  const progress = allHaveProgress ? downloaded / totalBytes : 0.1;\n  return /* @__PURE__ */ jsxs117(\"div\", {\n    style: progressItem2,\n    children: [\n      progress === 1 ? /* @__PURE__ */ jsx226(SuccessIcon, {}) : /* @__PURE__ */ jsx226(CircularProgress, {\n        progress\n      }),\n      /* @__PURE__ */ jsx226(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsxs117(\"div\", {\n        style: label11,\n        children: [\n          \"Downloading \",\n          downloads.length,\n          \" file\",\n          downloads.length === 1 ? \"\" : \"s\"\n        ]\n      })\n    ]\n  });\n};\nvar OpenFile = ({ job }) => {\n  const labelStyle5 = useMemo118(() => {\n    return {\n      ...label11,\n      textAlign: \"left\",\n      appearance: \"none\",\n      border: 0,\n      paddingLeft: 0,\n      cursor: job.deletedOutputLocation ? \"inherit\" : \"pointer\",\n      textDecoration: job.deletedOutputLocation ? \"line-through\" : \"none\"\n    };\n  }, [job.deletedOutputLocation]);\n  const onClick = useCallback108(() => {\n    openInFileExplorer({ directory: job.outName });\n  }, [job.outName]);\n  return /* @__PURE__ */ jsxs117(\"div\", {\n    style: progressItem2,\n    children: [\n      /* @__PURE__ */ jsx226(SuccessIcon, {}),\n      /* @__PURE__ */ jsx226(Spacing, {\n        x: 1\n      }),\n      /* @__PURE__ */ jsx226(\"button\", {\n        style: labelStyle5,\n        type: \"button\",\n        onClick,\n        children: job.outName\n      }),\n      /* @__PURE__ */ jsx226(\"div\", {\n        style: right4,\n        children: /* @__PURE__ */ jsx226(RenderQueueOpenInFinderItem, {\n          job\n        })\n      })\n    ]\n  });\n};\nvar GuiRenderStatus = ({ job }) => {\n  if (job.status === \"idle\" || job.status === \"failed\") {\n    throw new Error(\"This component should not be rendered when the job is idle\");\n  }\n  return /* @__PURE__ */ jsxs117(\"div\", {\n    children: [\n      /* @__PURE__ */ jsx226(Spacing, {\n        y: 0.5\n      }),\n      /* @__PURE__ */ jsx226(BrowserSetupProgress, {\n        ...job.progress.browser,\n        startedBundling: Boolean(job.progress.bundling)\n      }),\n      job.progress.bundling && /* @__PURE__ */ jsx226(BundlingProgress, {\n        progress: job.progress.bundling.progress,\n        doneIn: job.progress.bundling.doneIn\n      }),\n      job.progress.rendering ? /* @__PURE__ */ jsx226(RenderingProgress2, {\n        progress: job.progress.rendering\n      }) : null,\n      job.progress.stitching ? /* @__PURE__ */ jsx226(StitchingProgress, {\n        progress: job.progress.stitching\n      }) : null,\n      job.progress.downloads.length > 0 ? /* @__PURE__ */ jsx226(DownloadsProgress, {\n        downloads: job.progress.downloads\n      }) : null,\n      job.status === \"done\" ? /* @__PURE__ */ jsx226(OpenFile, {\n        job\n      }) : null,\n      /* @__PURE__ */ jsx226(Spacing, {\n        y: 1\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/RenderStatusModal.tsx\nimport { jsx as jsx227, jsxs as jsxs118, Fragment as Fragment37 } from \"react/jsx-runtime\";\nvar container50 = {\n  padding: 20,\n  maxWidth: 900,\n  paddingTop: 0\n};\nvar codeBlock = {\n  backgroundColor: \"#222\",\n  whiteSpace: \"pre\",\n  padding: 12,\n  borderRadius: 4,\n  fontFamily: \"monospace\",\n  overflow: \"auto\",\n  maxHeight: 300\n};\nvar spacer3 = {\n  height: SPACING_UNIT,\n  width: SPACING_UNIT\n};\nvar buttonRow = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  justifyContent: \"flex-end\"\n};\nvar RenderStatusModal = ({\n  jobId\n}) => {\n  const { setSelectedModal } = useContext81(ModalsContext);\n  const { jobs, removeClientJob, cancelClientJob } = useContext81(RenderQueueContext);\n  const job = jobs.find((j) => j.id === jobId);\n  if (!job) {\n    throw new Error(\"job not found\");\n  }\n  const isClientJob = isClientRenderJob(job);\n  const onQuit = useCallback109(() => {\n    setSelectedModal(null);\n  }, [setSelectedModal]);\n  const onRetry = useCallback109(() => {\n    if (isClientJob) {\n      const retryPayload = makeClientRetryPayload(job);\n      setSelectedModal(retryPayload);\n    } else {\n      const retryPayload = makeRetryPayload(job);\n      setSelectedModal(retryPayload);\n    }\n  }, [job, isClientJob, setSelectedModal]);\n  const onClickOnRemove = useCallback109(() => {\n    setSelectedModal(null);\n    if (isClientJob) {\n      removeClientJob(job.id);\n      showNotification(\"Removed render\", 2000);\n    } else {\n      removeRenderJob(job).catch((err) => {\n        showNotification(`Could not remove job: ${err.message}`, 2000);\n      });\n    }\n  }, [job, isClientJob, removeClientJob, setSelectedModal]);\n  const onClickOnCancel = useCallback109(() => {\n    if (isClientJob) {\n      cancelClientJob(job.id);\n    } else {\n      cancelRenderJob(job).catch((err) => {\n        showNotification(`Could not cancel job: ${err.message}`, 2000);\n      });\n    }\n  }, [job, isClientJob, cancelClientJob]);\n  if (job.status === \"idle\") {\n    throw new Error(\"should not have rendered this modal\");\n  }\n  return /* @__PURE__ */ jsxs118(ModalContainer, {\n    onOutsideClick: onQuit,\n    onEscape: onQuit,\n    children: [\n      /* @__PURE__ */ jsx227(ModalHeader, {\n        title: `Render ${job.compositionId}`\n      }),\n      /* @__PURE__ */ jsxs118(\"div\", {\n        style: container50,\n        children: [\n          job.status === \"failed\" ? /* @__PURE__ */ jsxs118(Fragment37, {\n            children: [\n              /* @__PURE__ */ jsx227(\"p\", {\n                children: \"The render failed because of the following error:\"\n              }),\n              /* @__PURE__ */ jsx227(\"div\", {\n                className: HORIZONTAL_SCROLLBAR_CLASSNAME,\n                style: codeBlock,\n                children: job.error.stack\n              })\n            ]\n          }) : null,\n          (job.status === \"done\" || job.status === \"running\") && (isClientJob ? /* @__PURE__ */ jsx227(ClientRenderProgress, {\n            job\n          }) : /* @__PURE__ */ jsx227(GuiRenderStatus, {\n            job\n          })),\n          /* @__PURE__ */ jsx227(\"div\", {\n            style: spacer3\n          }),\n          /* @__PURE__ */ jsxs118(\"div\", {\n            style: buttonRow,\n            children: [\n              job.status === \"running\" ? /* @__PURE__ */ jsx227(Button, {\n                onClick: onClickOnCancel,\n                children: \"Cancel render\"\n              }) : /* @__PURE__ */ jsx227(Button, {\n                onClick: onClickOnRemove,\n                children: \"Remove render\"\n              }),\n              /* @__PURE__ */ jsx227(Flex, {}),\n              job.status === \"failed\" ? /* @__PURE__ */ jsx227(Button, {\n                onClick: onRetry,\n                children: \"Retry\"\n              }) : null,\n              /* @__PURE__ */ jsx227(\"div\", {\n                style: spacer3\n              }),\n              /* @__PURE__ */ jsx227(Button, {\n                onClick: onQuit,\n                children: \"Close\"\n              })\n            ]\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/ServerRenderModal.tsx\nimport { BrowserSafeApis as BrowserSafeApis10 } from \"@remotion/renderer/client\";\nimport { getDefaultOutLocation } from \"@remotion/studio-shared\";\nimport {\n  useCallback as useCallback127,\n  useContext as useContext83,\n  useEffect as useEffect80,\n  useMemo as useMemo128,\n  useReducer as useReducer2,\n  useRef as useRef44,\n  useState as useState81\n} from \"react\";\n\n// src/helpers/convert-env-variables.ts\nvar envVariablesObjectToArray = (envVariables) => {\n  return Object.entries(envVariables).map(([key5, one]) => [\n    key5.trim().toUpperCase(),\n    one.trim()\n  ]);\n};\nvar envVariablesArrayToObject = (envVariables) => {\n  return envVariables.map(([key5, val]) => [key5.trim(), val.trim()]).filter(([key5, val]) => key5 && val).reduce((acc, [key5, value]) => {\n    acc[key5.toUpperCase()] = value;\n    return acc;\n  }, {});\n};\n\n// src/helpers/render-modal-sections.ts\nimport { useMemo as useMemo119, useState as useState76 } from \"react\";\nvar useRenderModalSections = (renderMode, codec) => {\n  const [selectedTab, setTab] = useState76(\"general\");\n  const shownTabs = useMemo119(() => {\n    if (renderMode === \"audio\") {\n      return [\"general\", \"data\", \"audio\", \"advanced\"];\n    }\n    if (renderMode === \"still\") {\n      return [\"general\", \"data\", \"picture\", \"advanced\"];\n    }\n    if (renderMode === \"sequence\") {\n      return [\"general\", \"data\", \"picture\", \"advanced\"];\n    }\n    if (renderMode === \"video\") {\n      if (codec === \"gif\") {\n        return [\"general\", \"data\", \"picture\", \"gif\", \"advanced\"];\n      }\n      return [\"general\", \"data\", \"picture\", \"audio\", \"advanced\"];\n    }\n    throw new TypeError(\"Unknown render mode\");\n  }, [codec, renderMode]);\n  const tab = useMemo119(() => {\n    if (!shownTabs.includes(selectedTab)) {\n      return shownTabs[0];\n    }\n    return selectedTab;\n  }, [selectedTab, shownTabs]);\n  return useMemo119(() => {\n    return { tab, setTab, shownTabs };\n  }, [tab, shownTabs]);\n};\n\n// src/icons/audio.tsx\nimport { jsx as jsx228 } from \"react/jsx-runtime\";\nvar AudioIcon = (props) => /* @__PURE__ */ jsx228(\"svg\", {\n  xmlns: \"http://www.w3.org/2000/svg\",\n  viewBox: \"0 0 512 512\",\n  ...props,\n  children: /* @__PURE__ */ jsx228(\"path\", {\n    fill: \"currentcolor\",\n    d: \"M243 32.32C105.5 39.15 0 157.8 0 295.5v120.4C0 451.3 28.63 480 64 480h32c17.62 0 32-14.38 32-32V288c0-17.62-14.38-32-32-32H64c-10.79 0-20.8 2.9-29.72 7.7 14.2-106.8 100.5-193.9 210.4-199.4 120.5-5.965 221.7 83.92 234 199.9-9.08-5.1-19.48-8.2-30.68-8.2h-32c-17.62 0-32 14.38-32 32v160c0 17.62 14.38 32 32 32h32c35.38 0 64-28.75 64-64.13V287.9c0-145.4-122-262.88-269-255.58zM64 288h32v160H64c-17.62 0-32-14.5-32-32.13v-95.75C32 302.5 46.38 288 64 288zm416 127.9c0 17.6-14.4 32.1-32 32.1h-32V288h32c17.62 0 32 14.5 32 32.13v95.77z\"\n  })\n});\n\n// src/icons/data.tsx\nimport { jsx as jsx229 } from \"react/jsx-runtime\";\nvar DataIcon = (props) => {\n  return /* @__PURE__ */ jsx229(\"svg\", {\n    xmlns: \"http://www.w3.org/2000/svg\",\n    viewBox: \"0 0 448 512\",\n    ...props,\n    children: /* @__PURE__ */ jsx229(\"path\", {\n      fill: \"currentcolor\",\n      d: \"M224 512C100.3 512 0 476.2 0 432V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80V432C448 476.2 347.7 512 224 512zM416 80.45C415.7 79.69 414.4 77.27 409.8 73.31C402.4 67.11 389.9 60.09 371.6 53.57C335.4 40.62 283.2 32 224 32C164.8 32 112.6 40.62 76.37 53.57C58.1 60.09 45.59 67.11 38.25 73.31C33.55 77.27 32.29 79.69 32 80.45V182.1C46.47 192.7 69.9 202.8 100.9 210.4C135.5 218.9 177.1 224 224 224C270 224 312.5 218.9 347.1 210.4C378.1 202.8 401.5 192.7 416 182.1V80.45zM416 219.5C398.8 228.4 377.9 235.8 354.8 241.5C317.3 250.7 272.2 256 224 256C175.8 256 130.7 250.7 93.22 241.5C70.11 235.8 49.18 228.4 32 219.5V310.1C46.47 320.7 69.9 330.8 100.9 338.4C135.5 346.9 177.1 352 224 352C270 352 312.5 346.9 347.1 338.4C378.1 330.8 401.5 320.7 416 310.1V219.5zM38.25 438.7C45.59 444.9 58.1 451.9 76.37 458.4C112.6 471.4 164.8 480 224 480C283.2 480 335.4 471.4 371.6 458.4C389.9 451.9 402.4 444.9 409.8 438.7C414.4 434.7 415.7 432.3 416 431.6V347.5C398.8 356.4 377.9 363.8 354.8 369.5C317.3 378.7 272.2 384 224 384C175.8 384 130.7 378.7 93.22 369.5C70.11 363.8 49.18 356.4 32 347.5V431.6C32.29 432.3 33.55 434.7 38.25 438.7zM416 431.4C416.1 431.3 416.1 431.3 416.1 431.3L416 431.4zM31.96 431.4C31.94 431.3 31.93 431.3 31.92 431.3L31.96 431.4zM31.96 80.56C31.93 80.65 31.92 80.7 31.92 80.7L31.96 80.56zM416.1 80.7C416.1 80.7 416.1 80.65 416 80.56z\"\n    })\n  });\n};\n\n// src/icons/frame.tsx\nimport { jsx as jsx230 } from \"react/jsx-runtime\";\nvar PicIcon = (props) => /* @__PURE__ */ jsx230(\"svg\", {\n  xmlns: \"http://www.w3.org/2000/svg\",\n  viewBox: \"0 0 512 512\",\n  ...props,\n  children: /* @__PURE__ */ jsx230(\"path\", {\n    fill: \"currentcolor\",\n    d: \"M324.9 157.8c-11.38-17.38-39.89-17.31-51.23-.063L200.5 268.5l-16.4-22.6c-11.4-16.8-38.2-16-49.7 0l-64.52 89.16c-6.797 9.406-7.75 21.72-2.547 32C72.53 377.5 83.05 384 94.75 384h322.5c11.41 0 21.8-6.281 27.14-16.38a30.922 30.922 0 0 0-1.516-31.56L324.9 157.8zM95.8 352l62.39-87.38 29.91 41.34c3.1 4.24 8.3 7.24 13.3 6.64 5.25-.125 10.12-2.781 13.02-7.188l83.83-129.9L415 352H95.8zM447.1 32h-384C28.65 32-.01 60.65-.01 96v320c0 35.35 28.65 64 63.1 64h384c35.35 0 64-28.65 64-64V96c.01-35.35-27.79-64-63.99-64zM480 416c0 17.64-14.36 32-32 32H64c-17.64 0-32-14.36-32-32V96c0-17.64 14.36-32 32-32h384c17.64 0 32 14.36 32 32v320zM144 192c26.5 0 48-21.5 48-48s-21.5-48-48-48-48 21.5-48 48 21.5 48 48 48zm0-64c8.822 0 15.1 7.178 15.1 16s-6.3 16-15.1 16-16-7.2-16-16 7.2-16 16-16z\"\n  })\n});\n\n// src/icons/gear.tsx\nimport { jsx as jsx231 } from \"react/jsx-runtime\";\nvar GearIcon = (props) => /* @__PURE__ */ jsx231(\"svg\", {\n  xmlns: \"http://www.w3.org/2000/svg\",\n  viewBox: \"0 0 512 512\",\n  ...props,\n  children: /* @__PURE__ */ jsx231(\"path\", {\n    fill: \"currentcolor\",\n    d: \"M168 255.1c0-47.7 39.4-88 88-88s88 40.3 88 88c0 49.5-39.4 88.9-88 88.9s-88-39.4-88-88.9zm88-56c-30.9 0-56 26-56 56 0 31.8 25.1 56 56 56s56-24.2 56-56c0-30-25.1-56-56-56zM65.67 230.6l-40.33-36.8c-11.12-10.1-13.68-26.6-6.16-39.6l30.24-52.4c7.52-13.02 23.09-19.05 37.42-14.48l51.96 16.58c13.4-10.34 28.2-18.94 44-25.47l11.7-53.27C197.7 10.47 210.7 0 225.8 0h60.4c15.1 0 28.1 10.47 31.3 25.16l11.7 53.27c14.9 6.53 30.6 15.13 44 25.47l52-16.58c14.3-4.57 29.9 1.46 37.4 14.48l30.2 52.4c7.5 13 5 29.5-6.1 39.6l-40.4 36.8c1.1 8.3 1.7 16.8 1.7 24.5 0 9.5-.6 18-1.7 26.3l40.4 36.8c11.1 10.1 13.6 26.6 6.1 39.6l-30.2 52.4c-7.5 13-23.1 19-37.4 14.5l-52-16.6c-13.4 10.3-29.1 18.9-44 25.5l-11.7 53.2c-3.2 14.7-16.2 25.2-31.3 25.2h-60.4c-15.1 0-28.1-10.5-31.3-25.2l-11.7-53.2c-15.8-6.6-30.6-15.2-44-25.5l-51.96 16.6c-14.33 4.5-29.9-1.5-37.42-14.5l-30.24-52.4c-7.52-13-4.96-29.5 6.16-39.6l40.33-36.8c-1.1-8.3-1.67-16.8-1.67-26.3 0-7.7.57-16.2 1.67-24.5zm92.73-101.4-13.3 10.3-67.97-21.7-30.24 52.4 52.69 48-2.19 16.6c-.92 6.9-1.39 14-1.39 20.3 0 8.1.47 15.2 1.39 22.1l2.19 16.6-52.69 48 30.24 52.4 67.97-21.7 13.3 10.3c11.1 8.6 23.5 15.8 36.6 20.3l15.5 7.3 15.3 69.6h60.4l15.3-69.6 14.6-7.3c14-4.5 26.4-11.7 37.5-20.3l13.3-10.3 68 21.7 30.2-52.4-52.7-48 2.2-16.6c.9-6.9 1.4-14 1.4-21.2 0-7.2-.5-14.3-1.4-21.2l-2.2-16.6 52.7-48-30.2-52.4-68 21.7-13.3-10.3c-11.1-8.6-23.5-15.8-37.5-21.2l-14.6-6.4L286.2 32h-60.4l-15.3 69.6L195 108c-13.1 5.4-25.5 12.6-36.6 21.2z\"\n  })\n});\n\n// src/icons/gif.tsx\nimport { jsx as jsx232 } from \"react/jsx-runtime\";\nvar GifIcon = (props) => /* @__PURE__ */ jsx232(\"svg\", {\n  xmlns: \"http://www.w3.org/2000/svg\",\n  viewBox: \"0 0 576 512\",\n  ...props,\n  children: /* @__PURE__ */ jsx232(\"path\", {\n    fill: \"currentcolor\",\n    d: \"M512 32H64C28.65 32 0 60.65 0 96v320c0 35.35 28.65 64 64 64h448c35.35 0 64-28.65 64-64V96c0-35.35-28.7-64-64-64zm32 384c0 17.64-14.36 32-32 32H64c-17.64 0-32-14.36-32-32V96c0-17.64 14.36-32 32-32h448c17.64 0 32 14.36 32 32v320zm-80-256h-96c-8.8 0-16 7.2-16 16v160c0 8.844 7.156 16 16 16s16-7.156 16-16v-64h56c8.844 0 16-7.156 16-16s-7.156-16-16-16h-56v-48h80c8.8 0 16-7.2 16-16s-7.2-16-16-16zm-160 0c-8.8 0-16 7.2-16 16v160c0 8.844 7.156 16 16 16s16-7.156 16-16V176c0-8.8-7.2-16-16-16zm-64 80h-64c-8.8 0-16 7.2-16 16s7.156 16 16 16h48v33.45c-24.83 19.91-69.13 18.16-91.48-4.203-24.95-24.95-24.95-65.55 0-90.5 25.03-25 64.19-25 89.22 0 6.25 6.25 16.38 6.25 22.62 0s6.25-16.38 0-22.62c-37.69-37.72-96.78-37.72-134.5 0-37.42 37.42-37.42 98.33 0 135.8C127.8 341.8 153.5 352 180.6 352c27.06 0 52.84-10.25 70.7-28.12 3-2.98 4.7-7.08 4.7-11.28V256c0-8.8-7.2-16-16-16z\"\n  })\n});\n\n// src/components/Tabs/vertical.tsx\nimport { useCallback as useCallback110, useMemo as useMemo120, useState as useState77 } from \"react\";\nimport { jsx as jsx233 } from \"react/jsx-runtime\";\nvar selectorButton2 = {\n  border: \"none\",\n  flex: 1,\n  padding: 8,\n  paddingLeft: 16,\n  display: \"flex\",\n  flexDirection: \"row\",\n  fontSize: 14,\n  color: \"inherit\",\n  alignItems: \"center\"\n};\nvar VerticalTab = ({ children, onClick, style: style12, selected }) => {\n  const [hovered, setHovered] = useState77(false);\n  const { tabIndex } = useZIndex();\n  const onPointerEnter = useCallback110(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback110(() => {\n    setHovered(false);\n  }, []);\n  const definiteStyle = useMemo120(() => {\n    return {\n      ...selectorButton2,\n      backgroundColor: selected ? SELECTED_BACKGROUND : hovered ? CLEAR_HOVER : \"transparent\",\n      color: selected ? \"white\" : LIGHT_TEXT,\n      boxShadow: selected ? \"none\" : undefined,\n      ...style12\n    };\n  }, [hovered, selected, style12]);\n  return /* @__PURE__ */ jsx233(\"button\", {\n    style: definiteStyle,\n    type: \"button\",\n    onClick,\n    tabIndex,\n    onPointerLeave,\n    onPointerEnter,\n    children\n  });\n};\n\n// src/components/RenderModal/CrfSetting.tsx\nimport { BrowserSafeApis as BrowserSafeApis2 } from \"@remotion/renderer/client\";\nimport { useState as useState79 } from \"react\";\n\n// src/components/RenderModal/NumberSetting.tsx\nimport { useCallback as useCallback112 } from \"react\";\n\n// src/components/RenderModal/OptionExplainerBubble.tsx\nimport { BrowserSafeApis } from \"@remotion/renderer/client\";\n\n// src/components/RenderModal/CliCopyButton.tsx\nimport { useCallback as useCallback111, useEffect as useEffect78, useMemo as useMemo121, useState as useState78 } from \"react\";\nimport { jsx as jsx234 } from \"react/jsx-runtime\";\nvar svgStyle2 = {\n  width: 16,\n  height: 16,\n  verticalAlign: \"sub\"\n};\nvar copiedStyle = {\n  fontSize: \"14px\",\n  minHeight: \"30px\",\n  minWidth: \"30px\",\n  display: \"flex\",\n  alignItems: \"center\",\n  justifyContent: \"center\"\n};\nvar buttonStyle6 = {\n  width: \"30px\",\n  height: \"30px\",\n  border: \"none\",\n  cursor: \"pointer\",\n  display: \"flex\",\n  alignItems: \"center\",\n  justifyContent: \"center\"\n};\nvar CliCopyButton = ({\n  valueToCopy\n}) => {\n  const [copied, setCopied] = useState78(false);\n  const [hovered, setHovered] = useState78(false);\n  const fillColor = useMemo121(() => {\n    return hovered ? \"white\" : LIGHT_TEXT;\n  }, [hovered]);\n  const clipboardIcon = /* @__PURE__ */ jsx234(ClipboardIcon, {\n    color: fillColor,\n    style: svgStyle2\n  });\n  const checkSvg = /* @__PURE__ */ jsx234(\"svg\", {\n    xmlns: \"http://www.w3.org/2000/svg\",\n    viewBox: \"0 0 448 512\",\n    style: svgStyle2,\n    children: /* @__PURE__ */ jsx234(\"path\", {\n      fill: fillColor,\n      d: \"M438.6 105.4c12.5 12.5 12.5 32.8 0 45.3l-256 256c-12.5 12.5-32.8 12.5-45.3 0l-128-128c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0L160 338.7 393.4 105.4c12.5-12.5 32.8-12.5 45.3 0z\"\n    })\n  });\n  const onPointerEnter = useCallback111(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback111(() => {\n    setHovered(false);\n  }, []);\n  useEffect78(() => {\n    if (!copied) {\n      return;\n    }\n    const handleClear = () => {\n      setCopied(false);\n      setHovered(false);\n    };\n    const to = setTimeout(() => handleClear(), 2000);\n    return () => clearTimeout(to);\n  }, [copied]);\n  return copied ? /* @__PURE__ */ jsx234(\"span\", {\n    style: copiedStyle,\n    children: checkSvg\n  }) : /* @__PURE__ */ jsx234(\"button\", {\n    type: \"button\",\n    onPointerEnter,\n    onPointerLeave,\n    style: buttonStyle6,\n    onClick: () => {\n      navigator.clipboard.writeText(valueToCopy);\n      setCopied(true);\n    },\n    children: clipboardIcon\n  });\n};\n\n// src/components/RenderModal/OptionExplainer.tsx\nimport { jsx as jsx235, jsxs as jsxs119, Fragment as Fragment38 } from \"react/jsx-runtime\";\nvar container51 = {\n  fontSize: 14,\n  paddingTop: 10,\n  paddingBottom: 10,\n  backgroundColor: INPUT_BACKGROUND\n};\nvar padding3 = {\n  paddingLeft: 20,\n  paddingRight: 20\n};\nvar title5 = {\n  fontSize: 14\n};\nvar description = {\n  fontSize: 14,\n  maxWidth: 400\n};\nvar link2 = {\n  fontSize: 14,\n  maxWidth: 200,\n  color: \"#0b84f3\",\n  wordWrap: \"break-word\",\n  textDecoration: \"none\"\n};\nvar infoRow = {\n  ...padding3,\n  fontSize: 14,\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar infoRowLabel = {\n  width: 150,\n  fontSize: 14,\n  color: \"white\"\n};\nvar flexSpacer = {\n  display: \"flex\",\n  flex: 1\n};\nvar copyWrapper = {\n  display: \"flex\",\n  justifyContent: \"flex-end\"\n};\nvar OptionExplainer = ({ option }) => {\n  return /* @__PURE__ */ jsxs119(\"div\", {\n    style: container51,\n    className: \"__remotion-info-button-container\",\n    children: [\n      /* @__PURE__ */ jsxs119(\"div\", {\n        style: padding3,\n        children: [\n          /* @__PURE__ */ jsxs119(\"div\", {\n            children: [\n              /* @__PURE__ */ jsx235(\"strong\", {\n                style: title5,\n                children: option.name\n              }),\n              option.docLink ? /* @__PURE__ */ jsxs119(Fragment38, {\n                children: [\n                  /* @__PURE__ */ jsx235(Spacing, {\n                    x: 1\n                  }),\n                  /* @__PURE__ */ jsx235(\"a\", {\n                    style: link2,\n                    href: option.docLink,\n                    target: \"_blank\",\n                    children: \"Docs\"\n                  })\n                ]\n              }) : null\n            ]\n          }),\n          /* @__PURE__ */ jsx235(\"div\", {\n            style: description,\n            children: option.description(\"ssr\")\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx235(Spacing, {\n        y: 0.5,\n        block: true\n      }),\n      /* @__PURE__ */ jsx235(MenuDivider, {}),\n      /* @__PURE__ */ jsx235(Spacing, {\n        y: 0.5,\n        block: true\n      }),\n      /* @__PURE__ */ jsxs119(\"div\", {\n        children: [\n          /* @__PURE__ */ jsxs119(\"div\", {\n            style: infoRow,\n            children: [\n              /* @__PURE__ */ jsx235(\"div\", {\n                style: infoRowLabel,\n                children: \"CLI flag\"\n              }),\n              /* @__PURE__ */ jsx235(\"div\", {\n                style: flexSpacer\n              }),\n              /* @__PURE__ */ jsxs119(\"code\", {\n                children: [\n                  \"--\",\n                  option.cliFlag\n                ]\n              }),\n              /* @__PURE__ */ jsx235(\"div\", {\n                style: copyWrapper,\n                children: /* @__PURE__ */ jsx235(CliCopyButton, {\n                  valueToCopy: option.cliFlag\n                })\n              })\n            ]\n          }),\n          option.ssrName ? /* @__PURE__ */ jsxs119(\"div\", {\n            style: infoRow,\n            children: [\n              /* @__PURE__ */ jsx235(\"div\", {\n                style: infoRowLabel,\n                children: \"Node.JS option\"\n              }),\n              /* @__PURE__ */ jsx235(\"div\", {\n                style: flexSpacer\n              }),\n              /* @__PURE__ */ jsx235(\"code\", {\n                children: option.ssrName\n              }),\n              /* @__PURE__ */ jsx235(Spacing, {\n                x: 3.75\n              })\n            ]\n          }) : null,\n          /* @__PURE__ */ jsx235(\"div\", {\n            style: infoRow\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/OptionExplainerBubble.tsx\nimport { jsx as jsx236 } from \"react/jsx-runtime\";\nvar OptionExplainerBubble = ({ id }) => {\n  const option = BrowserSafeApis.options[id];\n  return /* @__PURE__ */ jsx236(InfoBubble, {\n    title: \"Learn more about this option\",\n    children: /* @__PURE__ */ jsx236(OptionExplainer, {\n      option\n    })\n  });\n};\n\n// src/components/RenderModal/NumberSetting.tsx\nimport { jsx as jsx237, jsxs as jsxs120, Fragment as Fragment39 } from \"react/jsx-runtime\";\nvar NumberSetting = ({ name, value, step, hint, onValueChanged, max, min, formatter }) => {\n  const onTextChanged = useCallback112((e) => {\n    onValueChanged((q) => {\n      const newSetting = step < 1 ? parseFloat(e) : parseInt(e, 10);\n      if (Number.isNaN(newSetting)) {\n        return q;\n      }\n      return Math.min(max ?? Infinity, Math.max(newSetting, min));\n    });\n  }, [max, min, onValueChanged, step]);\n  const onValueChange = useCallback112((newConcurrency) => {\n    onValueChanged(newConcurrency);\n  }, [onValueChanged]);\n  return /* @__PURE__ */ jsxs120(\"div\", {\n    style: optionRow,\n    children: [\n      /* @__PURE__ */ jsxs120(\"div\", {\n        style: label5,\n        children: [\n          name,\n          hint ? /* @__PURE__ */ jsxs120(Fragment39, {\n            children: [\n              /* @__PURE__ */ jsx237(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx237(OptionExplainerBubble, {\n                id: hint\n              })\n            ]\n          }) : null\n        ]\n      }),\n      /* @__PURE__ */ jsx237(\"div\", {\n        style: rightRow,\n        children: /* @__PURE__ */ jsx237(RightAlignInput, {\n          children: /* @__PURE__ */ jsx237(InputDragger, {\n            value,\n            name: name.toLowerCase(),\n            onTextChange: onTextChanged,\n            onValueChange,\n            step,\n            placeholder: [min, max].map((f) => f !== null && f !== undefined ? f : \"\").join(\"-\"),\n            min,\n            max,\n            formatter,\n            status: \"ok\",\n            rightAlign: true\n          })\n        })\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/CrfSetting.tsx\nimport { jsx as jsx238 } from \"react/jsx-runtime\";\nvar getDefaultCrfState = () => {\n  return BrowserSafeApis2.validCodecs.map((c) => {\n    return [c, BrowserSafeApis2.getDefaultCrfForCodec(c)];\n  }).reduce((acc, [codec, crf]) => {\n    return {\n      ...acc,\n      [codec]: crf\n    };\n  }, {});\n};\nvar useCrfState = (codec) => {\n  const [state, setState] = useState79(() => getDefaultCrfState());\n  const range = BrowserSafeApis2.getValidCrfRanges(codec);\n  const setCrf = (updater) => {\n    setState((q) => {\n      const val = q[codec];\n      if (val === null) {\n        throw new TypeError(`Got unexpected codec \"${codec}\"`);\n      }\n      return {\n        ...q,\n        [codec]: typeof updater === \"number\" ? updater : updater(val)\n      };\n    });\n  };\n  return {\n    crf: state[codec],\n    setCrf,\n    minCrf: range[0],\n    maxCrf: range[1]\n  };\n};\nvar CrfSetting = ({ crf, setCrf, min, max, option }) => {\n  return /* @__PURE__ */ jsx238(NumberSetting, {\n    min,\n    max,\n    name: \"CRF\",\n    onValueChanged: setCrf,\n    value: crf,\n    step: 1,\n    hint: option\n  });\n};\n\n// src/components/RenderModal/RenderModalAdvanced.tsx\nimport { BrowserSafeApis as BrowserSafeApis3 } from \"@remotion/renderer/client\";\nimport { useCallback as useCallback116, useMemo as useMemo122 } from \"react\";\n\n// src/helpers/presets-labels.ts\nvar labelx264Preset = (profile) => {\n  if (profile === \"ultrafast\") {\n    return \"ultrafast\";\n  }\n  if (profile === \"superfast\") {\n    return \"superfast\";\n  }\n  if (profile === \"veryfast\") {\n    return \"veryfast\";\n  }\n  if (profile === \"faster\") {\n    return \"faster\";\n  }\n  if (profile === \"fast\") {\n    return \"fast\";\n  }\n  if (profile === \"medium\") {\n    return \"medium\";\n  }\n  if (profile === \"slow\") {\n    return \"slow\";\n  }\n  if (profile === \"slower\") {\n    return \"slower\";\n  }\n  if (profile === \"veryslow\") {\n    return \"veryslow\";\n  }\n  if (profile === \"placebo\") {\n    return \"placebo\";\n  }\n  throw new TypeError(`Unknown x264 preset: ${profile}`);\n};\n\n// src/components/RenderModal/RenderModalEnvironmentVariables.tsx\nimport { useCallback as useCallback115 } from \"react\";\n\n// src/components/RenderModal/EnvInput.tsx\nimport React157, { useCallback as useCallback114 } from \"react\";\n\n// src/components/RenderModal/InlineEyeIcon.tsx\nimport { useCallback as useCallback113 } from \"react\";\nimport { jsx as jsx239 } from \"react/jsx-runtime\";\nvar clearIcon2 = {\n  height: 14,\n  color: \"currentColor\"\n};\nvar InlineEyeButton = ({ onClick, enabled }) => {\n  const renderAction = useCallback113((color) => {\n    return enabled ? /* @__PURE__ */ jsx239(\"svg\", {\n      style: clearIcon2,\n      viewBox: \"0 0 640 512\",\n      children: /* @__PURE__ */ jsx239(\"path\", {\n        fill: color,\n        d: \"M25.9 3.4C19-2 8.9-.8 3.4 6.1S-.8 23.1 6.1 28.6l608 480c6.9 5.5 17 4.3 22.5-2.6s4.3-17-2.6-22.5L25.9 3.4zM605.5 268.3c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-51.2 0-96 14.8-133.9 36.8l27.3 21.5C244.6 74.2 280.2 64 320 64c70.4 0 127.7 32 170.8 72c43.1 40 71.9 88 85.2 120c-9.2 22.1-25.9 52-49.5 81.5l25.1 19.8c25.6-32 43.7-64.4 53.9-89zM88.4 154.7c-25.6 32-43.7 64.4-53.9 89c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c51.2 0 96-14.8 133.9-36.8l-27.3-21.5C395.4 437.8 359.8 448 320 448c-70.4 0-127.7-32-170.8-72C106.1 336 77.3 288 64 256c9.2-22.1 25.9-52 49.5-81.5L88.4 154.7zM320 384c16.7 0 32.7-3.2 47.4-9.1l-30.9-24.4c-5.4 .9-10.9 1.4-16.5 1.4c-51 0-92.8-39.8-95.8-90.1l-30.9-24.4c-.9 6-1.3 12.2-1.3 18.5c0 70.7 57.3 128 128 128zM448 256c0-70.7-57.3-128-128-128c-16.7 0-32.7 3.2-47.4 9.1l30.9 24.4c5.4-.9 10.9-1.4 16.5-1.4c51 0 92.8 39.8 95.8 90.1l30.9 24.4c.9-6 1.3-12.2 1.3-18.5z\"\n      })\n    }) : /* @__PURE__ */ jsx239(\"svg\", {\n      style: clearIcon2,\n      viewBox: \"0 0 576 512\",\n      children: /* @__PURE__ */ jsx239(\"path\", {\n        fill: color,\n        d: \"M117.2 136C160.3 96 217.6 64 288 64s127.7 32 170.8 72c43.1 40 71.9 88 85.2 120c-13.3 32-42.1 80-85.2 120c-43.1 40-100.4 72-170.8 72s-127.7-32-170.8-72C74.1 336 45.3 288 32 256c13.3-32 42.1-80 85.2-120zM288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM192 256a96 96 0 1 1 192 0 96 96 0 1 1 -192 0zm224 0a128 128 0 1 0 -256 0 128 128 0 1 0 256 0z\"\n      })\n    });\n  }, [enabled]);\n  return /* @__PURE__ */ jsx239(InlineAction, {\n    renderAction,\n    onClick\n  });\n};\n\n// src/components/RenderModal/EnvInput.tsx\nimport { jsx as jsx240, jsxs as jsxs121, Fragment as Fragment40 } from \"react/jsx-runtime\";\nvar input3 = {\n  flex: 1,\n  width: \"100%\"\n};\nvar validationStyle = {\n  paddingLeft: optionRow.paddingLeft,\n  paddingRight: optionRow.paddingRight\n};\nvar EnvInput = ({\n  onEnvKeyChange,\n  onEnvValChange,\n  envKey,\n  envVal,\n  onDelete,\n  index,\n  autoFocus,\n  isDuplicate\n}) => {\n  const [showInPlainText, setShowInPlainText] = React157.useState(false);\n  const [initialWarningKeyMissing, setKeyWarningEligible] = React157.useState(() => {\n    return envKey.trim() === \"\" && envVal.trim() !== \"\";\n  });\n  const [initialWarningValMissing, setValueWarningEligible] = React157.useState(() => {\n    return envKey.trim() !== \"\" && envVal.trim() === \"\";\n  });\n  const isKeyMissing = envKey.trim() === \"\" && initialWarningKeyMissing && envVal.trim() !== \"\";\n  const isValMissing = envVal.trim() === \"\" && initialWarningValMissing && envKey.trim() !== \"\";\n  const handleDelete = useCallback114(() => {\n    onDelete(index);\n  }, [index, onDelete]);\n  const togglePlainText = useCallback114(() => {\n    setShowInPlainText((prev) => !prev);\n  }, []);\n  const handleKeyChange = useCallback114((e) => {\n    onEnvKeyChange(index, e.target.value);\n  }, [index, onEnvKeyChange]);\n  const handleValueChange = useCallback114((e) => {\n    onEnvValChange(index, e.target.value);\n  }, [index, onEnvValChange]);\n  const makeKeyWarningEligible = useCallback114(() => {\n    setKeyWarningEligible(true);\n  }, []);\n  const makeValueWarningEligible = useCallback114(() => {\n    setValueWarningEligible(true);\n  }, []);\n  const isNodeEnvKey = envKey.trim() === \"NODE_ENV\";\n  return /* @__PURE__ */ jsxs121(Fragment40, {\n    children: [\n      /* @__PURE__ */ jsxs121(Row, {\n        align: \"center\",\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx240(RemotionInput, {\n            status: isNodeEnvKey || isDuplicate || isKeyMissing ? \"warning\" : \"ok\",\n            type: \"text\",\n            placeholder: \"Key\",\n            style: input3,\n            value: envKey,\n            onBlur: makeKeyWarningEligible,\n            autoFocus,\n            onChange: handleKeyChange,\n            rightAlign: false\n          }),\n          /* @__PURE__ */ jsx240(Spacing, {\n            x: 1\n          }),\n          /* @__PURE__ */ jsx240(RemotionInput, {\n            status: isValMissing ? \"warning\" : \"ok\",\n            placeholder: \"Value\",\n            type: showInPlainText ? \"text\" : \"password\",\n            style: input3,\n            value: envVal,\n            onBlur: makeValueWarningEligible,\n            onChange: handleValueChange,\n            rightAlign: false\n          }),\n          /* @__PURE__ */ jsx240(Spacing, {\n            x: 1.5\n          }),\n          /* @__PURE__ */ jsx240(InlineEyeButton, {\n            enabled: !showInPlainText,\n            onClick: togglePlainText\n          }),\n          /* @__PURE__ */ jsx240(InlineRemoveButton, {\n            onClick: handleDelete\n          })\n        ]\n      }),\n      isNodeEnvKey ? /* @__PURE__ */ jsx240(\"div\", {\n        style: validationStyle,\n        children: /* @__PURE__ */ jsx240(ValidationMessage, {\n          align: \"flex-start\",\n          type: \"warning\",\n          message: \"NODE_ENV will be overwritten by Remotion during the render process.\"\n        })\n      }) : null,\n      isDuplicate ? /* @__PURE__ */ jsx240(\"div\", {\n        style: validationStyle,\n        children: /* @__PURE__ */ jsx240(ValidationMessage, {\n          align: \"flex-start\",\n          type: \"warning\",\n          message: `${envKey.toUpperCase()} is already defined.`\n        })\n      }) : null,\n      isKeyMissing ? /* @__PURE__ */ jsx240(\"div\", {\n        style: validationStyle,\n        children: /* @__PURE__ */ jsx240(ValidationMessage, {\n          align: \"flex-start\",\n          type: \"warning\",\n          message: \"Key is missing.\"\n        })\n      }) : null,\n      isValMissing ? /* @__PURE__ */ jsx240(\"div\", {\n        style: validationStyle,\n        children: /* @__PURE__ */ jsx240(ValidationMessage, {\n          align: \"flex-start\",\n          type: \"warning\",\n          message: \"Value is missing.\"\n        })\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/RenderModalEnvironmentVariables.tsx\nimport { jsx as jsx241, jsxs as jsxs122 } from \"react/jsx-runtime\";\nvar title6 = {\n  fontSize: 14,\n  fontWeight: \"bold\",\n  color: LIGHT_TEXT,\n  marginLeft: 16\n};\nvar container52 = {\n  marginTop: 20\n};\nvar button3 = {\n  marginLeft: 16\n};\nvar RenderModalEnvironmentVariables = ({ envVariables, setEnvVariables }) => {\n  const onEnvValChange = useCallback115((index, value) => {\n    setEnvVariables((oldEnv) => {\n      const newEnv = [...oldEnv];\n      newEnv[index][1] = value;\n      return newEnv;\n    });\n  }, [setEnvVariables]);\n  const onEnvKeyChange = useCallback115((index, value) => {\n    setEnvVariables((oldEnv) => {\n      const newEnv = [...oldEnv];\n      newEnv[index][0] = value;\n      return newEnv;\n    });\n  }, [setEnvVariables]);\n  const onDelete = useCallback115((index) => {\n    setEnvVariables((oldEnv) => oldEnv.filter((_, idx) => idx !== index));\n  }, [setEnvVariables]);\n  const addField = useCallback115(() => {\n    setEnvVariables((oldEnv) => [...oldEnv, [\"\", \"\"]]);\n  }, [setEnvVariables]);\n  const usedKeys = [];\n  return /* @__PURE__ */ jsxs122(\"div\", {\n    style: container52,\n    children: [\n      /* @__PURE__ */ jsx241(\"strong\", {\n        style: title6,\n        children: \"Environment variables\"\n      }),\n      envVariables.map((env, i) => {\n        let isDuplicate = false;\n        if (usedKeys.includes(env[0].toUpperCase())) {\n          isDuplicate = true;\n        }\n        usedKeys.push(env[0].toUpperCase());\n        return /* @__PURE__ */ jsx241(EnvInput, {\n          onEnvKeyChange,\n          onEnvValChange,\n          envKey: env[0],\n          envVal: env[1],\n          onDelete,\n          index: i,\n          isDuplicate,\n          autoFocus: i === envVariables.length - 1 && env[0] === \"\"\n        }, i);\n      }),\n      /* @__PURE__ */ jsx241(Spacing, {\n        y: 1,\n        block: true\n      }),\n      /* @__PURE__ */ jsx241(Button, {\n        style: button3,\n        onClick: addField,\n        children: \"+ Add env variable\"\n      }),\n      /* @__PURE__ */ jsx241(Spacing, {\n        y: 1,\n        block: true\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/RenderModalHr.tsx\nimport { jsx as jsx242 } from \"react/jsx-runtime\";\nvar hrStyle = {\n  margin: \"0 0 0 0\",\n  padding: \"0 0 0 0\",\n  border: \"none\",\n  borderTop: \"1px solid #000\",\n  marginRight: 16,\n  marginLeft: 16,\n  marginTop: 8,\n  marginBottom: 8\n};\nvar RenderModalHr = () => {\n  return /* @__PURE__ */ jsx242(\"div\", {\n    style: hrStyle\n  });\n};\n\n// src/components/RenderModal/RenderModalAdvanced.tsx\nimport { jsx as jsx243, jsxs as jsxs123 } from \"react/jsx-runtime\";\nvar container53 = {\n  flex: 1,\n  overflowY: \"auto\"\n};\nvar RenderModalAdvanced = ({\n  renderMode,\n  maxConcurrency,\n  minConcurrency,\n  setConcurrency,\n  concurrency,\n  delayRenderTimeout,\n  setDelayRenderTimeout,\n  disallowParallelEncoding,\n  setDisallowParallelEncoding,\n  setDisableWebSecurity,\n  setIgnoreCertificateErrors,\n  setHeadless,\n  headless,\n  ignoreCertificateErrors,\n  disableWebSecurity,\n  openGlOption,\n  setOpenGlOption,\n  setEnvVariables,\n  envVariables,\n  setx264Preset,\n  x264Preset,\n  codec,\n  setMediaCacheSizeInBytes,\n  mediaCacheSizeInBytes,\n  offthreadVideoCacheSizeInBytes,\n  setOffthreadVideoCacheSizeInBytes,\n  offthreadVideoThreads,\n  setOffthreadVideoThreads,\n  enableMultiProcessOnLinux,\n  setChromiumMultiProcessOnLinux,\n  setUserAgent,\n  userAgent,\n  beep,\n  setBeep,\n  repro,\n  setRepro,\n  hardwareAcceleration,\n  chromeModeOption,\n  setChromeModeOption,\n  setHardwareAcceleration,\n  darkMode,\n  setDarkMode\n}) => {\n  const extendedOpenGlOptions = useMemo122(() => {\n    return [\n      \"angle\",\n      \"egl\",\n      \"swangle\",\n      \"swiftshader\",\n      \"vulkan\",\n      \"angle-egl\",\n      \"default\"\n    ];\n  }, []);\n  const toggleCustomMediaCacheSizeInBytes = useCallback116(() => {\n    setMediaCacheSizeInBytes((previous) => {\n      if (previous === null) {\n        return 1000 * 1000 * 1000;\n      }\n      return null;\n    });\n  }, [setMediaCacheSizeInBytes]);\n  const toggleCustomOffthreadVideoCacheSizeInBytes = useCallback116(() => {\n    setOffthreadVideoCacheSizeInBytes((previous) => {\n      if (previous === null) {\n        return 512 * 1024 * 1024;\n      }\n      return null;\n    });\n  }, [setOffthreadVideoCacheSizeInBytes]);\n  const toggleCustomOffthreadVideoThreads = useCallback116(() => {\n    setOffthreadVideoThreads((previous) => {\n      if (previous === null) {\n        return 2;\n      }\n      return null;\n    });\n  }, [setOffthreadVideoThreads]);\n  const toggleCustomUserAgent = useCallback116(() => {\n    setUserAgent((previous) => {\n      if (previous === null) {\n        return \"Mozilla/5.0 (Remotion)\";\n      }\n      return null;\n    });\n  }, [setUserAgent]);\n  const onDisallowParallelEncodingChanged = useCallback116((e) => {\n    setDisallowParallelEncoding(e.target.checked);\n  }, [setDisallowParallelEncoding]);\n  const onDisableWebSecurityChanged = useCallback116((e) => {\n    setDisableWebSecurity(e.target.checked);\n  }, [setDisableWebSecurity]);\n  const onEnableMultiProcessOnLinux = useCallback116((e) => {\n    setChromiumMultiProcessOnLinux(e.target.checked);\n  }, [setChromiumMultiProcessOnLinux]);\n  const onIgnoreCertificatErrors = useCallback116((e) => {\n    setIgnoreCertificateErrors(e.target.checked);\n  }, [setIgnoreCertificateErrors]);\n  const onHeadless = useCallback116((e) => {\n    setHeadless(e.target.checked);\n  }, [setHeadless]);\n  const onUserAgentChanged = useCallback116((e) => {\n    setUserAgent(e.target.value);\n  }, [setUserAgent]);\n  const onDarkMode = useCallback116((e) => {\n    setDarkMode(e.target.checked);\n  }, [setDarkMode]);\n  const onPlayBeepSound = useCallback116((e) => {\n    setBeep(e.target.checked);\n  }, [setBeep]);\n  const onReproToggle = useCallback116((e) => {\n    setRepro(e.target.checked);\n  }, [setRepro]);\n  const openGlOptions = useMemo122(() => {\n    return extendedOpenGlOptions.map((option) => {\n      return {\n        label: option === \"default\" ? \"Default\" : option,\n        onClick: () => setOpenGlOption(option),\n        key: option,\n        leftItem: openGlOption === option ? /* @__PURE__ */ jsx243(Checkmark, {}) : null,\n        id: option,\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: option\n      };\n    });\n  }, [extendedOpenGlOptions, openGlOption, setOpenGlOption]);\n  const chromeModeOptions = useMemo122(() => {\n    return BrowserSafeApis3.validChromeModeOptions.map((option) => {\n      return {\n        label: option,\n        onClick: () => setChromeModeOption(option),\n        key: option,\n        leftItem: chromeModeOption === option ? /* @__PURE__ */ jsx243(Checkmark, {}) : null,\n        id: option,\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: option\n      };\n    });\n  }, [chromeModeOption, setChromeModeOption]);\n  const x264PresetOptions = useMemo122(() => {\n    return BrowserSafeApis3.x264PresetOptions.map((option) => {\n      return {\n        label: labelx264Preset(option),\n        onClick: () => setx264Preset(option),\n        key: option,\n        type: \"item\",\n        id: option,\n        keyHint: null,\n        leftItem: x264Preset === option ? /* @__PURE__ */ jsx243(Checkmark, {}) : null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        value: option\n      };\n    });\n  }, [setx264Preset, x264Preset]);\n  const hardwareAccelerationValues = useMemo122(() => {\n    return BrowserSafeApis3.hardwareAccelerationOptions.map((option) => {\n      return {\n        label: option,\n        onClick: () => setHardwareAcceleration(option),\n        leftItem: hardwareAcceleration === option ? /* @__PURE__ */ jsx243(Checkmark, {}) : null,\n        subMenu: null,\n        quickSwitcherLabel: null,\n        type: \"item\",\n        id: option,\n        keyHint: null,\n        value: option\n      };\n    });\n  }, [hardwareAcceleration, setHardwareAcceleration]);\n  const changeMediaCacheSizeInBytes = useCallback116((cb) => {\n    setMediaCacheSizeInBytes((prev) => {\n      if (prev === null) {\n        throw new TypeError(\"Expected previous value\");\n      }\n      if (typeof cb === \"function\") {\n        return cb(prev);\n      }\n      return cb;\n    });\n  }, [setMediaCacheSizeInBytes]);\n  const changeOffthreadVideoCacheSizeInBytes = useCallback116((cb) => {\n    setOffthreadVideoCacheSizeInBytes((prev) => {\n      if (prev === null) {\n        throw new TypeError(\"Expected previous value\");\n      }\n      if (typeof cb === \"function\") {\n        return cb(prev);\n      }\n      return cb;\n    });\n  }, [setOffthreadVideoCacheSizeInBytes]);\n  const changeOffthreadVideoThreads = useCallback116((cb) => {\n    setOffthreadVideoThreads((prev) => {\n      if (prev === null) {\n        throw new TypeError(\"Expected previous value\");\n      }\n      if (typeof cb === \"function\") {\n        return cb(prev);\n      }\n      return cb;\n    });\n  }, [setOffthreadVideoThreads]);\n  return /* @__PURE__ */ jsxs123(\"div\", {\n    style: container53,\n    className: VERTICAL_SCROLLBAR_CLASSNAME,\n    children: [\n      renderMode === \"still\" ? null : /* @__PURE__ */ jsx243(NumberSetting, {\n        min: minConcurrency,\n        max: maxConcurrency,\n        step: 1,\n        name: \"Concurrency\",\n        formatter: (w) => `${w}x`,\n        onValueChanged: setConcurrency,\n        value: concurrency\n      }),\n      renderMode === \"video\" && codec === \"h264\" ? /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"x264 Preset\",\n              /* @__PURE__ */ jsx243(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"x264Option\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Combobox, {\n              title: x264Preset,\n              selectedId: x264Preset,\n              values: x264PresetOptions\n            })\n          })\n        ]\n      }) : null,\n      renderMode === \"video\" ? /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"Hardware acceleration\",\n              /* @__PURE__ */ jsx243(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"hardwareAccelerationOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Combobox, {\n              title: hardwareAcceleration,\n              selectedId: hardwareAcceleration,\n              values: hardwareAccelerationValues\n            })\n          })\n        ]\n      }) : null,\n      /* @__PURE__ */ jsx243(NumberSetting, {\n        min: 7000,\n        max: 900000,\n        name: \"delayRender() timeout\",\n        onValueChanged: setDelayRenderTimeout,\n        formatter: (w) => `${w}ms`,\n        step: 1000,\n        hint: \"delayRenderTimeoutInMillisecondsOption\",\n        value: delayRenderTimeout\n      }),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: label5,\n            children: \"No parallel encoding\"\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: disallowParallelEncoding,\n              onChange: onDisallowParallelEncodingChanged,\n              name: \"disallow-parallel-encoding\"\n            })\n          })\n        ]\n      }),\n      renderMode === \"audio\" ? null : /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"Custom @remotion/media cache size\",\n              /* @__PURE__ */ jsx243(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"mediaCacheSizeInBytesOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: mediaCacheSizeInBytes !== null,\n              onChange: toggleCustomMediaCacheSizeInBytes,\n              name: \"media-cache-size\"\n            })\n          })\n        ]\n      }),\n      renderMode === \"audio\" || mediaCacheSizeInBytes === null ? null : /* @__PURE__ */ jsx243(NumberSetting, {\n        min: 0,\n        max: 2000 * 1024 * 1024,\n        step: 1024,\n        name: \"@remotion/media cache size\",\n        formatter: (w) => `${w} bytes`,\n        onValueChanged: changeMediaCacheSizeInBytes,\n        value: mediaCacheSizeInBytes\n      }),\n      renderMode === \"audio\" ? null : /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"Custom OffthreadVideo cache\",\n              /* @__PURE__ */ jsx243(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"offthreadVideoCacheSizeInBytesOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: offthreadVideoCacheSizeInBytes !== null,\n              onChange: toggleCustomOffthreadVideoCacheSizeInBytes,\n              name: \"custom-audio-bitrate\"\n            })\n          })\n        ]\n      }),\n      renderMode === \"audio\" || offthreadVideoCacheSizeInBytes === null ? null : /* @__PURE__ */ jsx243(NumberSetting, {\n        min: 0,\n        max: 2000 * 1024 * 1024,\n        step: 1024,\n        name: \"OffthreadVideo cache size\",\n        formatter: (w) => `${w} bytes`,\n        onValueChanged: changeOffthreadVideoCacheSizeInBytes,\n        value: offthreadVideoCacheSizeInBytes\n      }),\n      renderMode === \"audio\" ? null : /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"OffthreadVideo threads \",\n              /* @__PURE__ */ jsx243(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"offthreadVideoThreadsOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: offthreadVideoThreads !== null,\n              onChange: toggleCustomOffthreadVideoThreads,\n              name: \"offthread-video-threads\"\n            })\n          })\n        ]\n      }),\n      renderMode === \"audio\" || offthreadVideoThreads === null ? null : /* @__PURE__ */ jsx243(NumberSetting, {\n        min: 0,\n        max: 16,\n        step: 1,\n        name: \"OffthreadVideo threads\",\n        formatter: (w) => `${w}x`,\n        onValueChanged: changeOffthreadVideoThreads,\n        value: offthreadVideoThreads\n      }),\n      /* @__PURE__ */ jsx243(RenderModalHr, {}),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: label5,\n            children: \"Disable web security\"\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: disableWebSecurity,\n              onChange: onDisableWebSecurityChanged,\n              name: \"disable-web-security\"\n            })\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: label5,\n            children: \"Ignore certificate errors\"\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: ignoreCertificateErrors,\n              onChange: onIgnoreCertificatErrors,\n              name: \"ignore-certificate-errors\"\n            })\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"Headless mode\",\n              /* @__PURE__ */ jsx243(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"headlessOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: headless,\n              onChange: onHeadless,\n              name: \"headless\"\n            })\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"Chrome Mode \",\n              /* @__PURE__ */ jsx243(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"chromeModeOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Combobox, {\n              values: chromeModeOptions,\n              selectedId: chromeModeOption,\n              title: \"Chrome mode\"\n            })\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"OpenGL render backend \",\n              /* @__PURE__ */ jsx243(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"glOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Combobox, {\n              values: openGlOptions,\n              selectedId: openGlOption,\n              title: \"OpenGl option\"\n            })\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"Multi-process Chrome on Linux\",\n              /* @__PURE__ */ jsx243(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"enableMultiprocessOnLinuxOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: enableMultiProcessOnLinux,\n              onChange: onEnableMultiProcessOnLinux,\n              name: \"enable-multi-process-on-linux\"\n            })\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"Dark Mode\",\n              /* @__PURE__ */ jsx243(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"darkModeOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: darkMode,\n              onChange: onDarkMode,\n              name: \"dark-mode\"\n            })\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: label5,\n            children: \"Custom User Agent\"\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: userAgent !== null,\n              onChange: toggleCustomUserAgent,\n              name: \"custom-user-agent\"\n            })\n          })\n        ]\n      }),\n      userAgent === null ? null : /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: label5,\n            children: \"User Agent\"\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(\"div\", {\n              children: /* @__PURE__ */ jsx243(RemotionInput, {\n                style: input,\n                value: userAgent,\n                onChange: onUserAgentChanged,\n                status: \"ok\",\n                rightAlign: true\n              })\n            })\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"Create a reproduction \",\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"reproOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: repro,\n              onChange: onReproToggle,\n              name: \"repro\"\n            })\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs123(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs123(\"div\", {\n            style: label5,\n            children: [\n              \"Beep when finished \",\n              /* @__PURE__ */ jsx243(OptionExplainerBubble, {\n                id: \"beepOnFinishOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx243(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx243(Checkbox, {\n              checked: beep,\n              onChange: onPlayBeepSound,\n              name: \"beep-when-finished\"\n            })\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx243(RenderModalHr, {}),\n      /* @__PURE__ */ jsx243(RenderModalEnvironmentVariables, {\n        envVariables,\n        setEnvVariables\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/RenderModalAudio.tsx\nimport { BrowserSafeApis as BrowserSafeApis5 } from \"@remotion/renderer/client\";\nimport { useCallback as useCallback120 } from \"react\";\n\n// src/components/RenderModal/EnforceAudioTrackSetting.tsx\nimport { useCallback as useCallback117 } from \"react\";\nimport { jsx as jsx244, jsxs as jsxs124 } from \"react/jsx-runtime\";\nvar EnforceAudioTrackSetting = ({ enforceAudioTrack, muted, setEnforceAudioTrack }) => {\n  const onEnforceAudioTrackChanged = useCallback117((e) => {\n    setEnforceAudioTrack(e.target.checked);\n  }, [setEnforceAudioTrack]);\n  return /* @__PURE__ */ jsxs124(\"div\", {\n    style: optionRow,\n    children: [\n      /* @__PURE__ */ jsxs124(\"div\", {\n        style: label5,\n        children: [\n          \"Enforce Audio Track\",\n          /* @__PURE__ */ jsx244(Spacing, {\n            x: 0.5\n          }),\n          /* @__PURE__ */ jsx244(OptionExplainerBubble, {\n            id: \"enforceAudioOption\"\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx244(\"div\", {\n        style: rightRow,\n        children: /* @__PURE__ */ jsx244(Checkbox, {\n          disabled: muted && !enforceAudioTrack,\n          checked: enforceAudioTrack,\n          onChange: onEnforceAudioTrackChanged,\n          name: \"enforce-audio-track\"\n        })\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/MutedSetting.tsx\nimport { useCallback as useCallback118 } from \"react\";\nimport { jsx as jsx245, jsxs as jsxs125 } from \"react/jsx-runtime\";\nvar MutedSetting = ({ muted, setMuted, enforceAudioTrack }) => {\n  const onMutedChanged = useCallback118((e) => {\n    setMuted(e.target.checked);\n  }, [setMuted]);\n  return /* @__PURE__ */ jsxs125(\"div\", {\n    style: optionRow,\n    children: [\n      /* @__PURE__ */ jsxs125(\"div\", {\n        style: label5,\n        children: [\n          \"Muted\",\n          /* @__PURE__ */ jsx245(Spacing, {\n            x: 0.5\n          }),\n          /* @__PURE__ */ jsx245(OptionExplainerBubble, {\n            id: \"mutedOption\"\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx245(Spacing, {\n        x: 0.25\n      }),\n      /* @__PURE__ */ jsx245(\"div\", {\n        style: rightRow,\n        children: /* @__PURE__ */ jsx245(Checkbox, {\n          checked: muted,\n          disabled: enforceAudioTrack && !muted,\n          onChange: onMutedChanged,\n          name: \"muted\"\n        })\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/SeparateAudioOption.tsx\nimport { BrowserSafeApis as BrowserSafeApis4 } from \"@remotion/renderer/client\";\nimport { useCallback as useCallback119, useMemo as useMemo123 } from \"react\";\n\n// src/helpers/use-file-existence.ts\nimport { useContext as useContext82, useEffect as useEffect79, useRef as useRef43, useState as useState80 } from \"react\";\nvar useFileExistence = (outName) => {\n  const [exists, setExists] = useState80(false);\n  const { previewServerState: state, subscribeToEvent } = useContext82(StudioServerConnectionCtx);\n  const clientId = state.type === \"connected\" ? state.clientId : undefined;\n  const currentOutName = useRef43(\"\");\n  currentOutName.current = outName;\n  useEffect79(() => {\n    if (!clientId) {\n      return;\n    }\n    subscribeToFileExistenceWatcher({\n      file: outName,\n      clientId\n    }).then((_exists) => {\n      if (currentOutName.current === outName) {\n        setExists(_exists);\n      }\n    });\n    return () => {\n      unsubscribeFromFileExistenceWatcher({ file: outName, clientId });\n    };\n  }, [clientId, outName]);\n  useEffect79(() => {\n    const listener = (event) => {\n      if (event.type !== \"watched-file-deleted\") {\n        return;\n      }\n      if (event.file !== currentOutName.current) {\n        return;\n      }\n      if (currentOutName.current === outName) {\n        setExists(false);\n      }\n    };\n    const unsub = subscribeToEvent(\"watched-file-deleted\", listener);\n    return () => {\n      unsub();\n    };\n  }, [outName, subscribeToEvent]);\n  useEffect79(() => {\n    const listener = (event) => {\n      if (event.type !== \"watched-file-undeleted\") {\n        return;\n      }\n      if (event.file !== outName) {\n        return;\n      }\n      if (currentOutName.current === outName) {\n        setExists(true);\n      }\n    };\n    const unsub = subscribeToEvent(\"watched-file-undeleted\", listener);\n    return () => {\n      unsub();\n    };\n  }, [outName, subscribeToEvent]);\n  return exists;\n};\n\n// src/components/RenderModal/RenderModalOutputName.tsx\nimport { jsx as jsx246, jsxs as jsxs126, Fragment as Fragment41 } from \"react/jsx-runtime\";\nvar RenderModalOutputName = ({\n  existence,\n  inputStyle: inputStyle2,\n  outName,\n  onValueChange,\n  validationMessage,\n  label: labelText\n}) => {\n  return /* @__PURE__ */ jsxs126(\"div\", {\n    style: optionRow,\n    children: [\n      /* @__PURE__ */ jsx246(Column, {\n        children: /* @__PURE__ */ jsx246(\"div\", {\n          style: label5,\n          children: labelText\n        })\n      }),\n      /* @__PURE__ */ jsx246(\"div\", {\n        style: rightRow,\n        children: /* @__PURE__ */ jsxs126(\"div\", {\n          children: [\n            /* @__PURE__ */ jsx246(RemotionInput, {\n              status: validationMessage ? \"error\" : existence ? \"warning\" : \"ok\",\n              style: inputStyle2,\n              type: \"text\",\n              value: outName,\n              onChange: onValueChange,\n              rightAlign: true\n            }),\n            validationMessage ? /* @__PURE__ */ jsxs126(Fragment41, {\n              children: [\n                /* @__PURE__ */ jsx246(Spacing, {\n                  y: 1,\n                  block: true\n                }),\n                /* @__PURE__ */ jsx246(ValidationMessage, {\n                  align: \"flex-end\",\n                  message: validationMessage,\n                  type: \"error\"\n                })\n              ]\n            }) : existence ? /* @__PURE__ */ jsxs126(Fragment41, {\n              children: [\n                /* @__PURE__ */ jsx246(Spacing, {\n                  y: 1,\n                  block: true\n                }),\n                /* @__PURE__ */ jsx246(ValidationMessage, {\n                  align: \"flex-end\",\n                  message: \"Will be overwritten\",\n                  type: \"warning\"\n                })\n              ]\n            }) : null\n          ]\n        })\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/get-string-before-suffix.ts\nvar getStringBeforeSuffix = (fileName) => {\n  const dotPos = fileName.lastIndexOf(\".\");\n  if (dotPos === -1) {\n    return fileName;\n  }\n  return fileName.substring(0, dotPos);\n};\n\n// src/components/RenderModal/SeparateAudioOption.tsx\nimport { jsx as jsx247, jsxs as jsxs127, Fragment as Fragment42 } from \"react/jsx-runtime\";\nvar SeparateAudioOptionInput = ({ separateAudioTo, setSeparateAudioTo, audioCodec }) => {\n  const existence = useFileExistence(separateAudioTo);\n  const onValueChange = useCallback119((e) => {\n    setSeparateAudioTo(e.target.value);\n  }, [setSeparateAudioTo]);\n  const validationMessage = useMemo123(() => {\n    const expectedExtension = BrowserSafeApis4.getExtensionFromAudioCodec(audioCodec);\n    const actualExtension = separateAudioTo.split(\".\").pop();\n    if (actualExtension !== expectedExtension) {\n      return `Expected extension: .${expectedExtension}`;\n    }\n    return null;\n  }, [audioCodec, separateAudioTo]);\n  return /* @__PURE__ */ jsx247(RenderModalOutputName, {\n    existence,\n    inputStyle: input,\n    onValueChange,\n    outName: separateAudioTo,\n    label: \"Separate audio to\",\n    validationMessage\n  });\n};\nvar SeparateAudioOption = ({ separateAudioTo, setSeparateAudioTo, audioCodec, outName }) => {\n  const onSeparateAudioChange = useCallback119((e) => {\n    if (e.target.checked) {\n      const extension = BrowserSafeApis4.getExtensionFromAudioCodec(audioCodec);\n      setSeparateAudioTo(`${getStringBeforeSuffix(outName)}.${extension}`);\n    } else {\n      setSeparateAudioTo(null);\n    }\n  }, [audioCodec, outName, setSeparateAudioTo]);\n  return /* @__PURE__ */ jsxs127(Fragment42, {\n    children: [\n      /* @__PURE__ */ jsxs127(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs127(\"div\", {\n            style: label5,\n            children: [\n              \"Separate audio\",\n              /* @__PURE__ */ jsx247(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx247(OptionExplainerBubble, {\n                id: \"separateAudioOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx247(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx247(Checkbox, {\n              disabled: false,\n              checked: Boolean(separateAudioTo),\n              onChange: onSeparateAudioChange,\n              name: \"separate-audio-to\"\n            })\n          })\n        ]\n      }),\n      separateAudioTo === null ? null : /* @__PURE__ */ jsx247(SeparateAudioOptionInput, {\n        separateAudioTo,\n        setSeparateAudioTo,\n        audioCodec\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/human-readable-audio-codecs.ts\nvar humanReadableAudioCodec = (audioCodec) => {\n  if (audioCodec === \"aac\") {\n    return \"AAC\";\n  }\n  if (audioCodec === \"mp3\") {\n    return \"MP3\";\n  }\n  if (audioCodec === \"pcm-16\") {\n    return \"Lossless\";\n  }\n  if (audioCodec === \"opus\") {\n    return \"Opus\";\n  }\n};\n\n// src/components/RenderModal/RenderModalAudio.tsx\nimport { jsx as jsx248, jsxs as jsxs128, Fragment as Fragment43 } from \"react/jsx-runtime\";\nvar container54 = {\n  flex: 1,\n  overflowY: \"auto\"\n};\nvar RenderModalAudio = ({\n  muted,\n  setMuted,\n  renderMode,\n  enforceAudioTrack,\n  setEnforceAudioTrackState,\n  setShouldHaveCustomTargetAudioBitrate,\n  shouldHaveCustomTargetAudioBitrate,\n  setCustomTargetAudioBitrateValue,\n  customTargetAudioBitrate,\n  audioCodec,\n  codec,\n  setAudioCodec,\n  forSeamlessAacConcatenation,\n  setForSeamlessAacConcatenation,\n  separateAudioTo,\n  setSeparateAudioTo,\n  outName\n}) => {\n  const onShouldHaveTargetAudioBitrateChanged = useCallback120((e) => {\n    setShouldHaveCustomTargetAudioBitrate(e.target.checked);\n  }, [setShouldHaveCustomTargetAudioBitrate]);\n  const onTargetAudioBitrateChanged = useCallback120((e) => {\n    setCustomTargetAudioBitrateValue(e.target.value);\n  }, [setCustomTargetAudioBitrateValue]);\n  const onSeamlessAacConcatenationChanges = useCallback120((e) => {\n    setForSeamlessAacConcatenation(e.target.checked);\n  }, [setForSeamlessAacConcatenation]);\n  const audioCodecOptions = useCallback120((currentCodec) => {\n    return BrowserSafeApis5.supportedAudioCodecs[currentCodec].map((audioCodecOption) => {\n      return {\n        label: humanReadableAudioCodec(audioCodecOption),\n        onClick: () => setAudioCodec(audioCodecOption),\n        key: audioCodecOption,\n        leftItem: codec === audioCodecOption ? /* @__PURE__ */ jsx248(Checkmark, {}) : null,\n        id: audioCodecOption,\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: audioCodecOption\n      };\n    });\n  }, [codec, setAudioCodec]);\n  return /* @__PURE__ */ jsxs128(\"div\", {\n    style: container54,\n    className: VERTICAL_SCROLLBAR_CLASSNAME,\n    children: [\n      renderMode === \"video\" ? /* @__PURE__ */ jsxs128(Fragment43, {\n        children: [\n          /* @__PURE__ */ jsx248(MutedSetting, {\n            enforceAudioTrack,\n            muted,\n            setMuted\n          }),\n          /* @__PURE__ */ jsx248(RenderModalHr, {})\n        ]\n      }) : null,\n      renderMode === \"video\" && audioCodecOptions(codec).length >= 2 && !muted ? /* @__PURE__ */ jsxs128(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs128(\"div\", {\n            style: label5,\n            children: [\n              \"Audio Codec \",\n              /* @__PURE__ */ jsx248(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx248(OptionExplainerBubble, {\n                id: \"audioCodecOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx248(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx248(Combobox, {\n              values: audioCodecOptions(codec),\n              selectedId: audioCodec,\n              title: \"AudioCodec\"\n            })\n          })\n        ]\n      }) : null,\n      (renderMode === \"video\" || renderMode === \"audio\") && !muted && /* @__PURE__ */ jsxs128(Fragment43, {\n        children: [\n          /* @__PURE__ */ jsx248(EnforceAudioTrackSetting, {\n            muted,\n            enforceAudioTrack,\n            setEnforceAudioTrack: setEnforceAudioTrackState\n          }),\n          /* @__PURE__ */ jsx248(RenderModalHr, {})\n        ]\n      }),\n      renderMode === \"video\" && !muted ? /* @__PURE__ */ jsx248(SeparateAudioOption, {\n        separateAudioTo,\n        setSeparateAudioTo,\n        audioCodec,\n        outName\n      }) : null,\n      audioCodec === \"aac\" && !muted ? /* @__PURE__ */ jsxs128(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs128(\"div\", {\n            style: label5,\n            children: [\n              \"For seamless AAC concatenation\",\n              /* @__PURE__ */ jsx248(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx248(OptionExplainerBubble, {\n                id: \"forSeamlessAacConcatenationOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx248(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx248(Checkbox, {\n              disabled: false,\n              checked: forSeamlessAacConcatenation,\n              onChange: onSeamlessAacConcatenationChanges,\n              name: \"enforce-audio-track\"\n            })\n          })\n        ]\n      }) : null,\n      renderMode === \"still\" || muted ? null : /* @__PURE__ */ jsxs128(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs128(\"div\", {\n            style: label5,\n            children: [\n              \"Custom audio bitrate\",\n              \" \",\n              /* @__PURE__ */ jsx248(OptionExplainerBubble, {\n                id: \"audioBitrateOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx248(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx248(Checkbox, {\n              checked: shouldHaveCustomTargetAudioBitrate,\n              onChange: onShouldHaveTargetAudioBitrateChanged,\n              name: \"custom-audio-bitrate\"\n            })\n          })\n        ]\n      }),\n      shouldHaveCustomTargetAudioBitrate && renderMode !== \"still\" && !muted ? /* @__PURE__ */ jsxs128(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx248(\"div\", {\n            style: label5,\n            children: \"Target audio bitrate\"\n          }),\n          /* @__PURE__ */ jsx248(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx248(\"div\", {\n              children: /* @__PURE__ */ jsx248(RemotionInput, {\n                style: input,\n                value: customTargetAudioBitrate,\n                onChange: onTargetAudioBitrateChanged,\n                status: \"ok\",\n                rightAlign: true\n              })\n            })\n          })\n        ]\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/RenderModalBasic.tsx\nimport { BrowserSafeApis as BrowserSafeApis6 } from \"@remotion/renderer/client\";\nimport { NoReactAPIs } from \"@remotion/renderer/pure\";\nimport { useCallback as useCallback123, useMemo as useMemo125 } from \"react\";\n\n// src/helpers/prores-labels.ts\nvar labelProResProfile = (profile) => {\n  if (profile === \"4444\") {\n    return \"4444\";\n  }\n  if (profile === \"4444-xq\") {\n    return \"4444 XQ (Best)\";\n  }\n  if (profile === \"hq\") {\n    return \"HQ\";\n  }\n  if (profile === \"proxy\") {\n    return \"Proxy (Worst)\";\n  }\n  if (profile === \"light\") {\n    return \"Light\";\n  }\n  if (profile === \"standard\") {\n    return \"Standard\";\n  }\n  throw new TypeError(`Unknown ProRes profile: ${profile}`);\n};\n\n// src/components/RenderModal/FrameRangeSetting.tsx\nimport { useCallback as useCallback122 } from \"react\";\n\n// src/components/RenderModal/MultiRangeSlider.tsx\nimport { useCallback as useCallback121, useMemo as useMemo124 } from \"react\";\nimport { jsx as jsx249, jsxs as jsxs129 } from \"react/jsx-runtime\";\nvar container55 = {\n  borderColor: \"black\",\n  borderStyle: \"solid\",\n  borderWidth: \"2px\",\n  height: 39,\n  width: 220,\n  position: \"relative\",\n  backgroundColor: INPUT_BACKGROUND,\n  marginLeft: 8,\n  marginRight: 8,\n  borderRadius: 2\n};\nvar sliderRange = {\n  position: \"absolute\",\n  top: 0,\n  backgroundColor: BLUE,\n  height: 35\n};\nvar MultiRangeSlider = ({\n  min,\n  max,\n  start,\n  end,\n  step,\n  onLeftThumbDrag,\n  onRightThumbDrag\n}) => {\n  const getPercent = useCallback121((value) => Math.round((value - min) / (max - min) * 100), [min, max]);\n  const rangeStyle = useMemo124(() => {\n    const minPercent = getPercent(start);\n    const maxPercent = getPercent(end);\n    return {\n      ...sliderRange,\n      left: `${minPercent}%`,\n      width: `${maxPercent - minPercent}%`\n    };\n  }, [end, getPercent, start]);\n  const onChangeLeft = useCallback121((event) => {\n    const value = Math.min(Number(event.target.value), end - 1);\n    onLeftThumbDrag(value);\n  }, [end, onLeftThumbDrag]);\n  const onChangeRight = useCallback121((event) => {\n    const value = Math.max(Number(event.target.value), start + 1);\n    onRightThumbDrag(value);\n  }, [onRightThumbDrag, start]);\n  return /* @__PURE__ */ jsxs129(\"div\", {\n    style: container55,\n    children: [\n      /* @__PURE__ */ jsx249(\"input\", {\n        type: \"range\",\n        min,\n        max,\n        value: start,\n        step,\n        onChange: onChangeLeft,\n        className: \"__remotion_thumb\"\n      }),\n      /* @__PURE__ */ jsx249(\"input\", {\n        type: \"range\",\n        min,\n        max,\n        value: end,\n        step,\n        onChange: onChangeRight,\n        className: \"__remotion_thumb\"\n      }),\n      /* @__PURE__ */ jsx249(\"div\", {\n        style: rangeStyle\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/FrameRangeSetting.tsx\nimport { jsx as jsx250, jsxs as jsxs130 } from \"react/jsx-runtime\";\nvar INPUT_WIDTH = 40;\nvar FrameRangeSetting = ({ startFrame, endFrame, setEndFrame, durationInFrames, setStartFrame }) => {\n  const minStartFrame = 0;\n  const maxEndFrame = durationInFrames - 1;\n  const onStartFrameChangedDirectly = useCallback122((newStartFrame) => {\n    setStartFrame(newStartFrame);\n  }, [setStartFrame]);\n  const onEndFrameChangedDirectly = useCallback122((newEndFrame) => {\n    setEndFrame(newEndFrame);\n  }, [setEndFrame]);\n  const onStartFrameChanged = useCallback122((newVal) => {\n    onStartFrameChangedDirectly(parseInt(newVal, 10));\n  }, [onStartFrameChangedDirectly]);\n  const onEndFrameChanged = useCallback122((newVal) => {\n    onEndFrameChangedDirectly(parseInt(newVal, 10));\n  }, [onEndFrameChangedDirectly]);\n  return /* @__PURE__ */ jsxs130(\"div\", {\n    style: optionRow,\n    children: [\n      /* @__PURE__ */ jsx250(\"div\", {\n        style: label5,\n        children: \"Frame range\"\n      }),\n      /* @__PURE__ */ jsxs130(\"div\", {\n        style: rightRow,\n        children: [\n          /* @__PURE__ */ jsx250(\"div\", {\n            style: { width: INPUT_WIDTH },\n            children: /* @__PURE__ */ jsx250(InputDragger, {\n              min: minStartFrame,\n              max: endFrame - 1,\n              name: \"Start frame\",\n              value: startFrame,\n              step: 1,\n              onTextChange: onStartFrameChanged,\n              onValueChange: onStartFrameChangedDirectly,\n              status: \"ok\",\n              rightAlign: true,\n              style: { width: INPUT_WIDTH }\n            })\n          }),\n          /* @__PURE__ */ jsx250(MultiRangeSlider, {\n            min: minStartFrame,\n            max: maxEndFrame,\n            start: startFrame,\n            end: endFrame,\n            step: 1,\n            onLeftThumbDrag: onStartFrameChangedDirectly,\n            onRightThumbDrag: onEndFrameChangedDirectly\n          }),\n          \" \",\n          /* @__PURE__ */ jsx250(\"div\", {\n            style: { width: INPUT_WIDTH },\n            children: /* @__PURE__ */ jsx250(InputDragger, {\n              min: startFrame + 1,\n              max: maxEndFrame,\n              name: \"End frame\",\n              value: endFrame,\n              step: 1,\n              onTextChange: onEndFrameChanged,\n              onValueChange: onEndFrameChangedDirectly,\n              status: \"ok\",\n              rightAlign: true,\n              style: { width: INPUT_WIDTH }\n            })\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/human-readable-codec.ts\nvar humanReadableCodec = (codec) => {\n  if (codec === \"aac\") {\n    return \"AAC\";\n  }\n  if (codec === \"mp3\") {\n    return \"MP3\";\n  }\n  if (codec === \"gif\") {\n    return \"GIF\";\n  }\n  if (codec === \"h264\") {\n    return \"H.264\";\n  }\n  if (codec === \"h264-mkv\") {\n    return \"H.264 (Matroska)\";\n  }\n  if (codec === \"h264-ts\") {\n    return \"H.264 (Transport Stream)\";\n  }\n  if (codec === \"h265\") {\n    return \"H.265\";\n  }\n  if (codec === \"prores\") {\n    return \"ProRes\";\n  }\n  if (codec === \"vp8\") {\n    return \"VP8\";\n  }\n  if (codec === \"vp9\") {\n    return \"VP9\";\n  }\n  if (codec === \"wav\") {\n    return \"Waveform\";\n  }\n  throw new TypeError(`Got unexpected codec \"${codec}\"`);\n};\n\n// src/components/RenderModal/human-readable-loglevel.ts\nvar humanReadableLogLevel = (logLevel) => {\n  if (logLevel === \"trace\") {\n    return \"Trace\";\n  }\n  if (logLevel === \"verbose\") {\n    return \"Verbose\";\n  }\n  if (logLevel === \"info\") {\n    return \"Info\";\n  }\n  if (logLevel === \"warn\") {\n    return \"Warn\";\n  }\n  if (logLevel === \"error\") {\n    return \"Error\";\n  }\n  throw new TypeError(`Got unexpected log level \"${logLevel}\"`);\n};\n\n// src/components/RenderModal/RenderModalBasic.tsx\nimport { jsx as jsx251, jsxs as jsxs131 } from \"react/jsx-runtime\";\nvar container56 = {\n  flex: 1\n};\nvar RenderModalBasic = ({\n  renderMode,\n  imageFormatOptions,\n  outName,\n  codec,\n  setVideoCodec: setCodec,\n  proResProfile,\n  setProResProfile,\n  frame: frame2,\n  setFrame,\n  resolvedComposition,\n  setOutName,\n  setEndFrame,\n  endFrame,\n  setStartFrame,\n  startFrame,\n  validationMessage,\n  setVerboseLogging,\n  logLevel\n}) => {\n  const existence = useFileExistence(outName);\n  const videoCodecOptions = useMemo125(() => {\n    return BrowserSafeApis6.validCodecs.filter((c) => {\n      return NoReactAPIs.isAudioCodec(c) === (renderMode === \"audio\");\n    }).map((codecOption) => {\n      return {\n        label: humanReadableCodec(codecOption),\n        onClick: () => setCodec(codecOption),\n        key: codecOption,\n        leftItem: codec === codecOption ? /* @__PURE__ */ jsx251(Checkmark, {}) : null,\n        id: codecOption,\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: codecOption\n      };\n    });\n  }, [renderMode, setCodec, codec]);\n  const proResProfileOptions = useMemo125(() => {\n    return BrowserSafeApis6.proResProfileOptions.map((option) => {\n      return {\n        label: labelProResProfile(option),\n        onClick: () => setProResProfile(option),\n        key: option,\n        selected: proResProfile === option,\n        type: \"item\",\n        id: option,\n        keyHint: null,\n        leftItem: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        value: option\n      };\n    });\n  }, [proResProfile, setProResProfile]);\n  const onFrameSetDirectly = useCallback123((newFrame) => {\n    setFrame(newFrame);\n  }, [setFrame]);\n  const onFrameChanged = useCallback123((e) => {\n    setFrame((q) => {\n      const newFrame = parseFloat(e);\n      if (Number.isNaN(newFrame)) {\n        return q;\n      }\n      return newFrame;\n    });\n  }, [setFrame]);\n  const onValueChange = useCallback123((e) => {\n    setOutName(e.target.value);\n  }, [setOutName]);\n  const logLevelOptions = useMemo125(() => {\n    return [\"trace\", \"verbose\", \"info\", \"warn\", \"error\"].map((level) => {\n      return {\n        label: humanReadableLogLevel(level),\n        onClick: () => setVerboseLogging(level),\n        leftItem: logLevel === level ? /* @__PURE__ */ jsx251(Checkmark, {}) : null,\n        id: level,\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: level\n      };\n    });\n  }, [logLevel, setVerboseLogging]);\n  return /* @__PURE__ */ jsxs131(\"div\", {\n    style: container56,\n    children: [\n      renderMode === \"still\" || renderMode === \"sequence\" ? /* @__PURE__ */ jsxs131(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx251(\"div\", {\n            style: label5,\n            children: \"Format\"\n          }),\n          /* @__PURE__ */ jsx251(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx251(SegmentedControl, {\n              items: imageFormatOptions,\n              needsWrapping: true\n            })\n          })\n        ]\n      }) : /* @__PURE__ */ jsxs131(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs131(\"div\", {\n            style: label5,\n            children: [\n              \"Codec\",\n              /* @__PURE__ */ jsx251(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx251(OptionExplainerBubble, {\n                id: \"videoCodecOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx251(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx251(Combobox, {\n              values: videoCodecOptions,\n              selectedId: codec,\n              title: \"Codec\"\n            })\n          })\n        ]\n      }),\n      renderMode === \"still\" && resolvedComposition.durationInFrames > 1 ? /* @__PURE__ */ jsxs131(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx251(\"div\", {\n            style: label5,\n            children: \"Frame\"\n          }),\n          /* @__PURE__ */ jsx251(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx251(RightAlignInput, {\n              children: /* @__PURE__ */ jsx251(InputDragger, {\n                value: frame2,\n                onTextChange: onFrameChanged,\n                placeholder: `0-${resolvedComposition.durationInFrames - 1}`,\n                onValueChange: onFrameSetDirectly,\n                name: \"frame\",\n                step: 1,\n                min: 0,\n                status: \"ok\",\n                max: resolvedComposition.durationInFrames - 1,\n                rightAlign: true\n              })\n            })\n          })\n        ]\n      }) : null,\n      renderMode === \"video\" && codec === \"prores\" ? /* @__PURE__ */ jsxs131(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx251(\"div\", {\n            style: label5,\n            children: \"ProRes profile\"\n          }),\n          /* @__PURE__ */ jsx251(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx251(Combobox, {\n              title: \"proResProfile\",\n              selectedId: proResProfile,\n              values: proResProfileOptions\n            })\n          })\n        ]\n      }) : null,\n      renderMode === \"still\" ? null : /* @__PURE__ */ jsx251(FrameRangeSetting, {\n        durationInFrames: resolvedComposition.durationInFrames,\n        endFrame,\n        setEndFrame,\n        setStartFrame,\n        startFrame\n      }),\n      /* @__PURE__ */ jsx251(RenderModalOutputName, {\n        existence,\n        inputStyle: input,\n        outName,\n        onValueChange,\n        validationMessage,\n        label: renderMode === \"sequence\" ? \"Folder name\" : \"Output name\"\n      }),\n      /* @__PURE__ */ jsxs131(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs131(\"div\", {\n            style: label5,\n            children: [\n              \"Log Level \",\n              /* @__PURE__ */ jsx251(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx251(OptionExplainerBubble, {\n                id: \"logLevelOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx251(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx251(Combobox, {\n              values: logLevelOptions,\n              selectedId: logLevel,\n              title: \"Log Level\"\n            })\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/RenderModalGif.tsx\nimport { useCallback as useCallback125 } from \"react\";\n\n// src/components/RenderModal/NumberOfLoopsSetting.tsx\nimport { useCallback as useCallback124 } from \"react\";\nimport { jsx as jsx252, jsxs as jsxs132 } from \"react/jsx-runtime\";\nvar min = 0;\nvar NumberOfLoopsSetting = ({ numberOfGifLoops, setNumberOfGifLoops }) => {\n  const onNumberOfGifLoopsChangedDirectly = useCallback124((newConcurrency) => {\n    setNumberOfGifLoops(newConcurrency);\n  }, [setNumberOfGifLoops]);\n  const onNumberOfGifLoopsChanged = useCallback124((e) => {\n    setNumberOfGifLoops((q) => {\n      const newConcurrency = parseInt(e, 10);\n      if (Number.isNaN(newConcurrency)) {\n        return q;\n      }\n      const newConcurrencyClamped = Math.max(newConcurrency, min);\n      return newConcurrencyClamped;\n    });\n  }, [setNumberOfGifLoops]);\n  return /* @__PURE__ */ jsxs132(\"div\", {\n    style: optionRow,\n    children: [\n      /* @__PURE__ */ jsx252(\"div\", {\n        style: label5,\n        children: \"Number of loops\"\n      }),\n      /* @__PURE__ */ jsx252(\"div\", {\n        style: rightRow,\n        children: /* @__PURE__ */ jsx252(RightAlignInput, {\n          children: /* @__PURE__ */ jsx252(InputDragger, {\n            value: numberOfGifLoops,\n            onTextChange: onNumberOfGifLoopsChanged,\n            placeholder: `${min}-`,\n            onValueChange: onNumberOfGifLoopsChangedDirectly,\n            name: \"number-of-gif-loops\",\n            step: 1,\n            min,\n            status: \"ok\",\n            rightAlign: true\n          })\n        })\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/RenderModalGif.tsx\nimport { jsx as jsx253, jsxs as jsxs133 } from \"react/jsx-runtime\";\nvar container57 = {\n  flex: 1\n};\nvar RenderModalGif = ({\n  everyNthFrame,\n  limitNumberOfGifLoops,\n  numberOfGifLoopsSetting,\n  setEveryNthFrameSetting,\n  setLimitNumberOfGifLoops,\n  setNumberOfGifLoopsSetting\n}) => {\n  const onShouldLimitNumberOfGifLoops = useCallback125((e) => {\n    setLimitNumberOfGifLoops(e.target.checked);\n  }, [setLimitNumberOfGifLoops]);\n  return /* @__PURE__ */ jsxs133(\"div\", {\n    style: container57,\n    children: [\n      /* @__PURE__ */ jsx253(NumberSetting, {\n        name: \"Every nth frame\",\n        min: 1,\n        onValueChanged: setEveryNthFrameSetting,\n        value: everyNthFrame,\n        step: 1\n      }),\n      /* @__PURE__ */ jsxs133(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs133(\"div\", {\n            style: label5,\n            children: [\n              \"Limit GIF loops \",\n              /* @__PURE__ */ jsx253(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx253(OptionExplainerBubble, {\n                id: \"numberOfGifLoopsOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx253(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx253(Checkbox, {\n              checked: limitNumberOfGifLoops,\n              onChange: onShouldLimitNumberOfGifLoops,\n              name: \"limitNumberOfGifLoops\"\n            })\n          })\n        ]\n      }),\n      limitNumberOfGifLoops ? /* @__PURE__ */ jsx253(NumberOfLoopsSetting, {\n        numberOfGifLoops: numberOfGifLoopsSetting,\n        setNumberOfGifLoops: setNumberOfGifLoopsSetting\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/RenderModalPicture.tsx\nimport { BrowserSafeApis as BrowserSafeApis7 } from \"@remotion/renderer/client\";\nimport { useCallback as useCallback126, useMemo as useMemo127 } from \"react\";\n\n// src/components/RenderModal/JpegQualitySetting.tsx\nimport { jsx as jsx254 } from \"react/jsx-runtime\";\nvar MIN_JPEG_QUALITY = 1;\nvar MAX_JPEG_QUALITY = 100;\nvar JpegQualitySetting = ({ jpegQuality, setJpegQuality }) => {\n  return /* @__PURE__ */ jsx254(NumberSetting, {\n    min: MIN_JPEG_QUALITY,\n    max: MAX_JPEG_QUALITY,\n    step: 1,\n    name: \"JPEG Quality\",\n    onValueChanged: setJpegQuality,\n    value: jpegQuality,\n    hint: \"jpegQualityOption\"\n  });\n};\n\n// src/components/RenderModal/ScaleSetting.tsx\nimport { useMemo as useMemo126 } from \"react\";\nimport { jsx as jsx255, jsxs as jsxs134, Fragment as Fragment44 } from \"react/jsx-runtime\";\nvar MIN_SCALE = 0.1;\nvar MAX_SCALE = 10;\nvar outputDimensionsStyle = {\n  fontSize: 13,\n  color: LIGHT_TEXT,\n  fontFamily: \"sans-serif\",\n  paddingRight: 16,\n  textAlign: \"right\",\n  marginBottom: 14,\n  marginTop: -10\n};\nvar ScaleSetting = ({ scale, setScale, compositionWidth, compositionHeight }) => {\n  const outputDimensions = useMemo126(() => {\n    const outputWidth = Math.round(compositionWidth * scale);\n    const outputHeight = Math.round(compositionHeight * scale);\n    return `${outputWidth}${outputHeight}`;\n  }, [compositionWidth, compositionHeight, scale]);\n  return /* @__PURE__ */ jsxs134(Fragment44, {\n    children: [\n      /* @__PURE__ */ jsx255(NumberSetting, {\n        min: MIN_SCALE,\n        max: MAX_SCALE,\n        step: 0.1,\n        name: \"Scale\",\n        formatter: (w) => {\n          if (typeof w === \"number\") {\n            return `${w.toFixed(1)}x`;\n          }\n          return `${w}x`;\n        },\n        onValueChanged: setScale,\n        value: scale,\n        hint: \"scaleOption\"\n      }),\n      scale !== 1 && /* @__PURE__ */ jsxs134(\"div\", {\n        style: outputDimensionsStyle,\n        children: [\n          \"Output resolution: \",\n          outputDimensions\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/RenderModalPicture.tsx\nimport { jsx as jsx256, jsxs as jsxs135, Fragment as Fragment45 } from \"react/jsx-runtime\";\nvar qualityControlModes = [\"crf\", \"bitrate\"];\nvar container58 = {\n  flex: 1,\n  overflowY: \"auto\"\n};\nvar RenderModalPicture = ({\n  renderMode,\n  scale,\n  setScale,\n  pixelFormat,\n  imageFormatOptions,\n  setQualityControl,\n  qualityControlType,\n  videoImageFormat,\n  setJpegQuality,\n  jpegQuality,\n  maxCrf,\n  minCrf,\n  setCrf,\n  shouldDisplayQualityControlPicker,\n  setCustomTargetVideoBitrateValue,\n  crf,\n  customTargetVideoBitrate,\n  stillImageFormat,\n  colorSpace,\n  setColorSpace,\n  pixelFormatOptions,\n  encodingBufferSize,\n  encodingMaxRate,\n  setEncodingBufferSize,\n  setEncodingMaxRate,\n  compositionWidth,\n  compositionHeight\n}) => {\n  const colorSpaceOptions = useMemo127(() => {\n    return BrowserSafeApis7.validColorSpaces.map((option) => {\n      return {\n        label: option,\n        onClick: () => setColorSpace(option),\n        key: option,\n        id: option,\n        keyHint: null,\n        leftItem: colorSpace === option ? /* @__PURE__ */ jsx256(Checkmark, {}) : null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: option\n      };\n    });\n  }, [colorSpace, setColorSpace]);\n  const qualityControlOptions = useMemo127(() => {\n    return qualityControlModes.map((option) => {\n      return {\n        label: option === \"crf\" ? \"CRF\" : \"Bitrate\",\n        onClick: () => setQualityControl(option),\n        key: option,\n        selected: qualityControlType === option\n      };\n    });\n  }, [qualityControlType, setQualityControl]);\n  const onTargetVideoBitrateChanged = useCallback126((e) => {\n    setCustomTargetVideoBitrateValue(e.target.value);\n  }, [setCustomTargetVideoBitrateValue]);\n  const onEncodingBufferSizeToggled = useCallback126((e) => {\n    setEncodingBufferSize(e.target.checked ? \"10000k\" : null);\n  }, [setEncodingBufferSize]);\n  const onEncodingMaxRateToggled = useCallback126((e) => {\n    setEncodingMaxRate(e.target.checked ? \"5000k\" : null);\n  }, [setEncodingMaxRate]);\n  const onEncodingBufferSizeChanged = useCallback126((e) => {\n    setEncodingBufferSize(e.target.value);\n  }, [setEncodingBufferSize]);\n  const onEncodingMaxRateChanged = useCallback126((e) => {\n    setEncodingMaxRate(e.target.value);\n  }, [setEncodingMaxRate]);\n  return /* @__PURE__ */ jsxs135(\"div\", {\n    style: container58,\n    className: VERTICAL_SCROLLBAR_CLASSNAME,\n    children: [\n      renderMode === \"video\" ? /* @__PURE__ */ jsxs135(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx256(\"div\", {\n            style: label5,\n            children: \"Image Format\"\n          }),\n          /* @__PURE__ */ jsx256(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx256(SegmentedControl, {\n              items: imageFormatOptions,\n              needsWrapping: false\n            })\n          })\n        ]\n      }) : null,\n      renderMode === \"video\" && videoImageFormat === \"jpeg\" && /* @__PURE__ */ jsx256(JpegQualitySetting, {\n        jpegQuality,\n        setJpegQuality\n      }),\n      renderMode === \"still\" && stillImageFormat === \"jpeg\" && /* @__PURE__ */ jsx256(JpegQualitySetting, {\n        jpegQuality,\n        setJpegQuality\n      }),\n      renderMode === \"video\" && qualityControlType !== null ? /* @__PURE__ */ jsx256(RenderModalHr, {}) : null,\n      shouldDisplayQualityControlPicker && renderMode === \"video\" ? /* @__PURE__ */ jsxs135(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx256(\"div\", {\n            style: label5,\n            children: \"Quality control\"\n          }),\n          /* @__PURE__ */ jsx256(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx256(SegmentedControl, {\n              items: qualityControlOptions,\n              needsWrapping: true\n            })\n          })\n        ]\n      }) : null,\n      qualityControlType === \"crf\" && renderMode !== \"still\" && renderMode !== \"sequence\" && crf !== null ? /* @__PURE__ */ jsx256(CrfSetting, {\n        crf,\n        min: minCrf,\n        max: maxCrf,\n        setCrf,\n        option: \"crfOption\"\n      }) : null,\n      qualityControlType === \"bitrate\" && renderMode === \"video\" ? /* @__PURE__ */ jsxs135(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs135(\"div\", {\n            style: label5,\n            children: [\n              \"Target video bitrate\",\n              /* @__PURE__ */ jsx256(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx256(OptionExplainerBubble, {\n                id: \"videoBitrateOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx256(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx256(\"div\", {\n              children: /* @__PURE__ */ jsx256(RemotionInput, {\n                style: input,\n                value: customTargetVideoBitrate,\n                onChange: onTargetVideoBitrateChanged,\n                status: \"ok\",\n                rightAlign: true\n              })\n            })\n          })\n        ]\n      }) : null,\n      renderMode === \"video\" ? /* @__PURE__ */ jsxs135(Fragment45, {\n        children: [\n          /* @__PURE__ */ jsxs135(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsxs135(\"div\", {\n                style: label5,\n                children: [\n                  \"Custom FFmpeg -bufsize\",\n                  /* @__PURE__ */ jsx256(Spacing, {\n                    x: 0.5\n                  }),\n                  /* @__PURE__ */ jsx256(OptionExplainerBubble, {\n                    id: \"encodingBufferSizeOption\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsx256(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx256(Checkbox, {\n                  checked: encodingBufferSize !== null,\n                  onChange: onEncodingBufferSizeToggled,\n                  name: \"encoding-buffer-size\"\n                })\n              })\n            ]\n          }),\n          encodingBufferSize === null ? null : /* @__PURE__ */ jsxs135(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsx256(\"div\", {\n                style: label5,\n                children: \"-bufsize value\"\n              }),\n              /* @__PURE__ */ jsx256(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx256(\"div\", {\n                  children: /* @__PURE__ */ jsx256(RemotionInput, {\n                    style: input,\n                    value: encodingBufferSize,\n                    onChange: onEncodingBufferSizeChanged,\n                    status: \"ok\",\n                    rightAlign: true\n                  })\n                })\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsxs135(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsxs135(\"div\", {\n                style: label5,\n                children: [\n                  \"Custom FFmpeg -maxrate\",\n                  /* @__PURE__ */ jsx256(Spacing, {\n                    x: 0.5\n                  }),\n                  /* @__PURE__ */ jsx256(OptionExplainerBubble, {\n                    id: \"encodingMaxRateOption\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsx256(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx256(Checkbox, {\n                  checked: encodingMaxRate !== null,\n                  onChange: onEncodingMaxRateToggled,\n                  name: \"encoding-max-rate\"\n                })\n              })\n            ]\n          }),\n          encodingMaxRate === null ? null : /* @__PURE__ */ jsxs135(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsx256(\"div\", {\n                style: label5,\n                children: \"-maxrate value\"\n              }),\n              /* @__PURE__ */ jsx256(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx256(\"div\", {\n                  children: /* @__PURE__ */ jsx256(RemotionInput, {\n                    style: input,\n                    value: encodingMaxRate,\n                    onChange: onEncodingMaxRateChanged,\n                    status: \"ok\",\n                    rightAlign: true\n                  })\n                })\n              })\n            ]\n          })\n        ]\n      }) : null,\n      renderMode === \"video\" ? /* @__PURE__ */ jsx256(RenderModalHr, {}) : null,\n      /* @__PURE__ */ jsx256(ScaleSetting, {\n        scale,\n        setScale,\n        compositionWidth,\n        compositionHeight\n      }),\n      renderMode === \"video\" ? /* @__PURE__ */ jsx256(RenderModalHr, {}) : null,\n      renderMode === \"video\" ? /* @__PURE__ */ jsxs135(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx256(\"div\", {\n            style: label5,\n            children: \"Pixel format\"\n          }),\n          /* @__PURE__ */ jsx256(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx256(Combobox, {\n              values: pixelFormatOptions,\n              selectedId: pixelFormat,\n              title: \"Pixel Format\"\n            })\n          })\n        ]\n      }) : null,\n      renderMode === \"video\" ? /* @__PURE__ */ jsxs135(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs135(\"div\", {\n            style: label5,\n            children: [\n              \"Color space\",\n              /* @__PURE__ */ jsx256(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx256(OptionExplainerBubble, {\n                id: \"colorSpaceOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx256(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx256(Combobox, {\n              values: colorSpaceOptions,\n              selectedId: colorSpace,\n              title: \"Color Space\"\n            })\n          })\n        ]\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/get-default-codecs.ts\nimport { BrowserSafeApis as BrowserSafeApis8 } from \"@remotion/renderer/client\";\nimport { NoReactAPIs as NoReactAPIs2 } from \"@remotion/renderer/pure\";\nvar getDefaultCodecs = ({\n  defaultConfigurationVideoCodec,\n  compositionDefaultVideoCodec,\n  renderType,\n  defaultConfigurationAudioCodec\n}) => {\n  const userPreferredVideoCodec = compositionDefaultVideoCodec ?? defaultConfigurationVideoCodec ?? \"h264\";\n  const userPreferredVideoCodecForAudioTab = userPreferredVideoCodec === \"aac\" ? \"aac\" : userPreferredVideoCodec === \"mp3\" ? \"mp3\" : userPreferredVideoCodec === \"wav\" ? \"wav\" : defaultConfigurationAudioCodec === \"pcm-16\" ? \"wav\" : defaultConfigurationAudioCodec === \"mp3\" ? \"mp3\" : \"aac\";\n  const isVideoCodecAnAudioCodec = NoReactAPIs2.isAudioCodec(userPreferredVideoCodec);\n  if (isVideoCodecAnAudioCodec) {\n    return {\n      initialAudioCodec: null,\n      initialRenderType: \"audio\",\n      initialVideoCodec: userPreferredVideoCodec,\n      initialVideoCodecForAudioTab: userPreferredVideoCodecForAudioTab,\n      initialVideoCodecForVideoTab: NoReactAPIs2.isAudioCodec(defaultConfigurationVideoCodec) ? \"h264\" : defaultConfigurationVideoCodec\n    };\n  }\n  const suitableAudioCodecForVideoCodec = BrowserSafeApis8.defaultAudioCodecs[userPreferredVideoCodec].compressed;\n  return {\n    initialAudioCodec: defaultConfigurationAudioCodec ?? suitableAudioCodecForVideoCodec,\n    initialVideoCodec: userPreferredVideoCodec,\n    initialRenderType: renderType,\n    initialVideoCodecForAudioTab: userPreferredVideoCodecForAudioTab,\n    initialVideoCodecForVideoTab: userPreferredVideoCodec\n  };\n};\n\n// src/components/RenderModal/out-name-checker.ts\nimport { BrowserSafeApis as BrowserSafeApis9 } from \"@remotion/renderer/client\";\nvar invalidCharacters = [\"?\", \"*\", \"+\", \":\", \"%\"];\nvar isValidStillExtension = (extension, stillImageFormat) => {\n  if (stillImageFormat === \"jpeg\" && extension === \"jpg\") {\n    return true;\n  }\n  return extension === stillImageFormat;\n};\nvar validateOutnameGui = ({\n  outName,\n  codec,\n  audioCodec,\n  renderMode,\n  stillImageFormat,\n  separateAudioTo\n}) => {\n  try {\n    isValidOutName({\n      audioCodec,\n      codec,\n      outName,\n      renderMode,\n      stillImageFormat,\n      separateAudioTo\n    });\n    return { valid: true };\n  } catch (err) {\n    return { valid: false, error: err };\n  }\n};\nvar isValidOutName = ({\n  outName,\n  codec,\n  audioCodec,\n  renderMode,\n  stillImageFormat,\n  separateAudioTo\n}) => {\n  const extension = outName.substring(outName.lastIndexOf(\".\") + 1);\n  const prefix = outName.substring(0, outName.lastIndexOf(\".\"));\n  const map = BrowserSafeApis9.defaultFileExtensionMap[codec];\n  if (BrowserSafeApis9.supportedAudioCodecs[codec].length > 0 && !(audioCodec in map.forAudioCodec)) {\n    throw new Error(`Audio codec ${audioCodec} is not supported for codec ${codec}`);\n  }\n  const hasDotAfterSlash = () => {\n    const substrings = prefix.split(\"/\");\n    for (const str of substrings) {\n      if (str[0] === \".\") {\n        return true;\n      }\n    }\n    return false;\n  };\n  const hasInvalidChar = () => {\n    return prefix.split(\"\").some((char) => invalidCharacters.includes(char));\n  };\n  if (renderMode === \"video\" || renderMode === \"audio\") {\n    BrowserSafeApis9.validateOutputFilename({\n      codec,\n      audioCodecSetting: audioCodec ?? null,\n      extension,\n      preferLossless: false,\n      separateAudioTo\n    });\n  }\n  if (prefix.length < 1 && renderMode !== \"sequence\") {\n    throw new Error(\"The prefix must be at least 1 character long\");\n  }\n  if (prefix[0] === \".\" || hasDotAfterSlash()) {\n    throw new Error(\"The output name must not start with a dot\");\n  }\n  if (hasInvalidChar()) {\n    throw new Error(\"Filename can't contain the following characters:  ?, *, +, %, :\");\n  }\n  if (renderMode === \"still\" && stillImageFormat && !isValidStillExtension(extension, stillImageFormat)) {\n    throw new Error(`The extension ${extension} is not supported for still image format ${stillImageFormat}`);\n  }\n  if (renderMode === \"sequence\") {\n    if (outName.includes(\".\")) {\n      throw new Error(\"Folder names must not contain a dot\");\n    }\n  }\n};\n\n// src/components/RenderModal/render-modals.ts\nvar outerModalStyle = {\n  width: getMaxModalWidth(1000),\n  height: getMaxModalHeight(640),\n  overflow: \"hidden\",\n  display: \"flex\",\n  flexDirection: \"column\"\n};\nvar container59 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  padding: \"12px 16px\",\n  borderBottom: \"1px solid black\"\n};\nvar optionsPanel = {\n  display: \"flex\",\n  width: \"100%\"\n};\nvar horizontalLayout = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  overflowY: \"auto\",\n  flex: 1\n};\nvar leftSidebar = {\n  padding: 12\n};\nvar horizontalTab = {\n  width: 250,\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  textAlign: \"left\",\n  fontSize: 16,\n  fontWeight: \"bold\",\n  paddingLeft: 15,\n  paddingTop: 12,\n  paddingBottom: 12\n};\nvar iconContainer = {\n  width: 20,\n  height: 20,\n  marginRight: 15,\n  display: \"inline-flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\"\n};\nvar icon6 = {\n  color: \"currentcolor\",\n  height: 20\n};\nvar buttonStyle7 = {\n  backgroundColor: BLUE,\n  color: \"white\"\n};\nvar flexer = {\n  flex: 1\n};\n\n// src/components/RenderModal/ServerRenderModal.tsx\nimport { jsx as jsx257, jsxs as jsxs136 } from \"react/jsx-runtime\";\nvar initialState2 = { type: \"idle\" };\nvar reducer2 = (state, action) => {\n  if (action.type === \"start\") {\n    return {\n      type: \"load\"\n    };\n  }\n  if (action.type === \"fail\") {\n    return {\n      type: \"error\"\n    };\n  }\n  if (action.type === \"succeed\") {\n    return {\n      type: \"success\"\n    };\n  }\n  return state;\n};\nvar RenderModal = ({\n  initialFrame,\n  initialVideoImageFormat,\n  initialStillImageFormat,\n  initialJpegQuality,\n  initialScale,\n  initialLogLevel,\n  initialConcurrency,\n  maxConcurrency,\n  minConcurrency,\n  initialMuted,\n  initialEnforceAudioTrack,\n  initialProResProfile,\n  initialx264Preset,\n  initialPixelFormat,\n  initialVideoBitrate,\n  initialAudioBitrate,\n  initialEveryNthFrame,\n  initialNumberOfGifLoops,\n  initialDelayRenderTimeout,\n  initialOffthreadVideoCacheSizeInBytes,\n  initialEnvVariables,\n  initialDisableWebSecurity,\n  initialGl,\n  initialHeadless,\n  initialIgnoreCertificateErrors,\n  initialEncodingBufferSize,\n  initialEncodingMaxRate,\n  initialOffthreadVideoThreads,\n  initialMediaCacheSizeInBytes,\n  initialDarkMode,\n  initialUserAgent,\n  defaultProps,\n  inFrameMark,\n  outFrameMark,\n  initialColorSpace,\n  initialMultiProcessOnLinux,\n  defaultConfigurationAudioCodec,\n  defaultConfigurationVideoCodec,\n  initialBeep,\n  initialRepro,\n  initialForSeamlessAacConcatenation,\n  renderTypeOfLastRender,\n  initialHardwareAcceleration,\n  defaultMetadata,\n  initialChromeMode,\n  renderDefaults\n}) => {\n  const { setSelectedModal } = useContext83(ModalsContext);\n  const context = useContext83(ResolvedCompositionContext);\n  if (!context) {\n    throw new Error(\"Should not be able to render without resolving comp first\");\n  }\n  const {\n    resolved: { result: resolvedComposition },\n    unresolved: unresolvedComposition\n  } = context;\n  const isMounted = useRef44(true);\n  const [isVideo] = useState81(() => {\n    return typeof resolvedComposition.durationInFrames === \"undefined\" ? true : resolvedComposition.durationInFrames > 1;\n  });\n  const [\n    {\n      initialAudioCodec,\n      initialRenderType,\n      initialVideoCodec,\n      initialVideoCodecForAudioTab,\n      initialVideoCodecForVideoTab\n    }\n  ] = useState81(() => {\n    return getDefaultCodecs({\n      defaultConfigurationVideoCodec,\n      compositionDefaultVideoCodec: resolvedComposition.defaultCodec,\n      defaultConfigurationAudioCodec,\n      renderType: renderTypeOfLastRender ?? (isVideo ? \"video\" : \"still\")\n    });\n  });\n  const [state, dispatch] = useReducer2(reducer2, initialState2);\n  const [unclampedFrame, setFrame] = useState81(() => initialFrame);\n  const [saving, setSaving] = useState81(false);\n  const [stillImageFormat, setStillImageFormat] = useState81(() => initialStillImageFormat);\n  const [videoImageFormat, setVideoImageFormat] = useState81(() => initialVideoImageFormat ?? resolvedComposition.defaultVideoImageFormat ?? renderDefaults.videoImageFormat);\n  const [sequenceImageFormat, setSequenceImageFormat] = useState81(() => initialStillImageFormat === \"jpeg\" ? \"jpeg\" : \"png\");\n  const [concurrency, setConcurrency] = useState81(() => initialConcurrency);\n  const [videoCodecForVideoTab, setVideoCodecForVideoTab] = useState81(() => initialVideoCodecForVideoTab);\n  const [userSelectedAudioCodec, setUserSelectedAudioCodec] = useState81(() => initialAudioCodec);\n  const [separateAudioTo, setSeparateAudioTo] = useState81(null);\n  const [envVariables, setEnvVariables] = useState81(() => envVariablesObjectToArray(initialEnvVariables).filter(([key5]) => key5 !== \"NODE_ENV\"));\n  const [initialOutName] = useState81(() => {\n    return getDefaultOutLocation({\n      compositionName: resolvedComposition.id,\n      defaultExtension: initialRenderType === \"still\" ? initialStillImageFormat : isVideo ? BrowserSafeApis10.getFileExtensionFromCodec(initialVideoCodec, initialAudioCodec) : initialStillImageFormat,\n      type: \"asset\",\n      compositionDefaultOutName: resolvedComposition.defaultOutName,\n      clientSideRender: false\n    });\n  });\n  const [videoCodecForAudioTab, setVideoCodecForAudioTab] = useState81(() => initialVideoCodecForAudioTab);\n  const [mutedState, setMuted] = useState81(() => initialMuted);\n  const [repro, setRepro] = useState81(() => initialRepro);\n  const [enforceAudioTrackState, setEnforceAudioTrackState] = useState81(() => initialEnforceAudioTrack);\n  const [forSeamlessAacConcatenation, setForSeamlessAacConcatenation] = useState81(() => initialForSeamlessAacConcatenation);\n  const [renderMode, setRenderModeState] = useState81(initialRenderType);\n  const [jpegQuality, setJpegQuality] = useState81(() => initialJpegQuality);\n  const [scale, setScale] = useState81(() => initialScale);\n  const [logLevel, setLogLevel] = useState81(() => initialLogLevel);\n  const [disallowParallelEncoding, setDisallowParallelEncoding] = useState81(false);\n  const [disableWebSecurity, setDisableWebSecurity] = useState81(() => initialDisableWebSecurity);\n  const [headless, setHeadless] = useState81(() => initialHeadless);\n  const [beepOnFinish, setBeepOnFinish] = useState81(() => initialBeep);\n  const [ignoreCertificateErrors, setIgnoreCertificateErrors] = useState81(() => initialIgnoreCertificateErrors);\n  const [multiProcessOnLinux, setChromiumMultiProcessOnLinux] = useState81(() => initialMultiProcessOnLinux);\n  const [darkMode, setDarkMode] = useState81(() => initialDarkMode);\n  const [openGlOption, setOpenGlOption] = useState81(() => initialGl ?? \"default\");\n  const [colorSpace, setColorSpace] = useState81(() => initialColorSpace);\n  const [userAgent, setUserAgent] = useState81(() => initialUserAgent === null ? null : initialUserAgent.trim() === \"\" ? null : initialUserAgent);\n  const chromiumOptions = useMemo128(() => {\n    return {\n      headless,\n      disableWebSecurity,\n      ignoreCertificateErrors,\n      gl: openGlOption === \"default\" ? null : openGlOption,\n      userAgent: userAgent === null ? null : userAgent.trim() === \"\" ? null : userAgent,\n      enableMultiProcessOnLinux: multiProcessOnLinux,\n      darkMode\n    };\n  }, [\n    headless,\n    disableWebSecurity,\n    ignoreCertificateErrors,\n    openGlOption,\n    userAgent,\n    multiProcessOnLinux,\n    darkMode\n  ]);\n  const [outName, setOutName] = useState81(() => initialOutName);\n  const [endFrameOrNull, setEndFrame] = useState81(() => outFrameMark ?? null);\n  const [startFrameOrNull, setStartFrame] = useState81(() => inFrameMark ?? null);\n  const [proResProfileSetting, setProResProfile] = useState81(() => initialProResProfile ?? resolvedComposition.defaultProResProfile ?? \"hq\");\n  const [x264PresetSetting, setx264Preset] = useState81(() => initialx264Preset);\n  const [hardwareAcceleration, setHardwareAcceleration] = useState81(() => initialHardwareAcceleration);\n  const [userPreferredPixelFormat, setPixelFormat] = useState81(() => initialPixelFormat ?? resolvedComposition.defaultPixelFormat ?? renderDefaults.pixelFormat);\n  const [preferredQualityControlType, setQualityControl] = useState81(() => initialVideoBitrate === null ? \"crf\" : \"bitrate\");\n  const [\n    shouldHaveCustomTargetAudioBitrate,\n    setShouldHaveCustomTargetAudioBitrate\n  ] = useState81(() => initialAudioBitrate !== null);\n  const [customTargetAudioBitrate, setCustomTargetAudioBitrateValue] = useState81(() => initialAudioBitrate ?? \"320K\");\n  const [customTargetVideoBitrate, setCustomTargetVideoBitrateValue] = useState81(() => initialVideoBitrate ?? \"1M\");\n  const [encodingMaxRate, setEncodingMaxRate] = useState81(() => initialEncodingMaxRate ?? null);\n  const [encodingBufferSize, setEncodingBufferSize] = useState81(() => initialEncodingBufferSize ?? null);\n  const [limitNumberOfGifLoops, setLimitNumberOfGifLoops] = useState81(() => initialNumberOfGifLoops !== null);\n  const [numberOfGifLoopsSetting, setNumberOfGifLoopsSetting] = useState81(() => initialNumberOfGifLoops ?? 0);\n  const [delayRenderTimeout, setDelayRenderTimeout] = useState81(() => initialDelayRenderTimeout);\n  const [chromeMode, setChromeMode] = useState81(() => initialChromeMode);\n  const [offthreadVideoCacheSizeInBytes, setOffthreadVideoCacheSizeInBytes] = useState81(initialOffthreadVideoCacheSizeInBytes);\n  const [mediaCacheSizeInBytes, setMediaCacheSizeInBytes] = useState81(initialMediaCacheSizeInBytes);\n  const [offthreadVideoThreads, setOffthreadVideoThreads] = useState81(() => initialOffthreadVideoThreads);\n  const codec = useMemo128(() => {\n    if (renderMode === \"audio\") {\n      return videoCodecForAudioTab;\n    }\n    return videoCodecForVideoTab;\n  }, [videoCodecForAudioTab, renderMode, videoCodecForVideoTab]);\n  const numberOfGifLoops = useMemo128(() => {\n    if (codec === \"gif\" && limitNumberOfGifLoops) {\n      return numberOfGifLoopsSetting;\n    }\n    return null;\n  }, [codec, limitNumberOfGifLoops, numberOfGifLoopsSetting]);\n  const audioBitrate = useMemo128(() => {\n    if (shouldHaveCustomTargetAudioBitrate) {\n      return customTargetAudioBitrate;\n    }\n    return null;\n  }, [customTargetAudioBitrate, shouldHaveCustomTargetAudioBitrate]);\n  const supportsCrf = BrowserSafeApis10.codecSupportsCrf(codec);\n  const supportsVideoBitrate = BrowserSafeApis10.codecSupportsVideoBitrate(codec);\n  const supportsBothQualityControls = useMemo128(() => {\n    return supportsCrf && supportsVideoBitrate && hardwareAcceleration !== \"if-possible\" && hardwareAcceleration !== \"required\";\n  }, [hardwareAcceleration, supportsCrf, supportsVideoBitrate]);\n  const qualityControlType = useMemo128(() => {\n    if (hardwareAcceleration === \"if-possible\" || hardwareAcceleration === \"required\") {\n      if (supportsVideoBitrate) {\n        return \"bitrate\";\n      }\n      return null;\n    }\n    if (supportsBothQualityControls) {\n      return preferredQualityControlType;\n    }\n    if (supportsCrf) {\n      return \"crf\";\n    }\n    if (supportsVideoBitrate) {\n      return \"bitrate\";\n    }\n    return null;\n  }, [\n    hardwareAcceleration,\n    preferredQualityControlType,\n    supportsBothQualityControls,\n    supportsCrf,\n    supportsVideoBitrate\n  ]);\n  const videoBitrate = useMemo128(() => {\n    if (qualityControlType === \"bitrate\") {\n      return customTargetVideoBitrate;\n    }\n    return null;\n  }, [customTargetVideoBitrate, qualityControlType]);\n  const { crf, maxCrf, minCrf, setCrf } = useCrfState(codec);\n  const dispatchIfMounted = useCallback127((payload) => {\n    if (isMounted.current === false)\n      return;\n    dispatch(payload);\n  }, []);\n  const muted = useMemo128(() => {\n    if (renderMode === \"video\") {\n      return mutedState;\n    }\n    return false;\n  }, [mutedState, renderMode]);\n  const enforceAudioTrack = useMemo128(() => {\n    if (renderMode === \"video\") {\n      return enforceAudioTrackState;\n    }\n    if (renderMode === \"audio\") {\n      return enforceAudioTrackState;\n    }\n    return false;\n  }, [enforceAudioTrackState, renderMode]);\n  const proResProfile = useMemo128(() => {\n    if (renderMode === \"video\" && codec === \"prores\") {\n      return proResProfileSetting;\n    }\n    return null;\n  }, [codec, proResProfileSetting, renderMode]);\n  const x264Preset = useMemo128(() => {\n    if (renderMode === \"video\" && codec === \"h264\") {\n      return x264PresetSetting;\n    }\n    return null;\n  }, [codec, x264PresetSetting, renderMode]);\n  const [inputProps, setInputProps] = useState81(() => defaultProps);\n  const [metadata] = useState81(() => defaultMetadata);\n  const endFrame = useMemo128(() => {\n    if (endFrameOrNull === null) {\n      return resolvedComposition.durationInFrames - 1;\n    }\n    return Math.max(0, Math.min(resolvedComposition.durationInFrames - 1, endFrameOrNull));\n  }, [resolvedComposition.durationInFrames, endFrameOrNull]);\n  const startFrame = useMemo128(() => {\n    if (startFrameOrNull === null) {\n      return 0;\n    }\n    return Math.max(0, Math.min(endFrame - 1, startFrameOrNull));\n  }, [endFrame, startFrameOrNull]);\n  const frame2 = useMemo128(() => {\n    const parsed = Math.floor(unclampedFrame);\n    return Math.max(0, Math.min(resolvedComposition.durationInFrames - 1, parsed));\n  }, [resolvedComposition.durationInFrames, unclampedFrame]);\n  const deriveFinalAudioCodec = useCallback127((passedVideoCodec, passedAudioCodec) => {\n    if (passedAudioCodec !== null && BrowserSafeApis10.supportedAudioCodecs[passedVideoCodec].includes(passedAudioCodec)) {\n      return passedAudioCodec;\n    }\n    return BrowserSafeApis10.defaultAudioCodecs[passedVideoCodec].compressed;\n  }, []);\n  const setDefaultOutName = useCallback127((options) => {\n    if (options.type === \"still\") {\n      setOutName((prev) => {\n        const newFileName = getStringBeforeSuffix(prev) + \".\" + options.imageFormat;\n        return newFileName;\n      });\n    } else if (options.type === \"sequence\") {\n      setOutName((prev) => {\n        const folderName = getStringBeforeSuffix(prev);\n        return folderName;\n      });\n    } else {\n      setOutName((prev) => {\n        const codecSuffix = BrowserSafeApis10.getFileExtensionFromCodec(options.codec, deriveFinalAudioCodec(options.codec, options.audioCodec));\n        const newFileName = getStringBeforeSuffix(prev) + \".\" + codecSuffix;\n        return newFileName;\n      });\n    }\n  }, [deriveFinalAudioCodec]);\n  const setAudioCodec = useCallback127((newAudioCodec) => {\n    setUserSelectedAudioCodec(newAudioCodec);\n    setDefaultOutName({\n      type: \"render\",\n      codec: videoCodecForVideoTab,\n      audioCodec: newAudioCodec\n    });\n    setSeparateAudioTo((prev) => {\n      if (prev === null) {\n        return null;\n      }\n      const newExtension = BrowserSafeApis10.getExtensionFromAudioCodec(newAudioCodec);\n      const newFileName = getStringBeforeSuffix(prev) + \".\" + newExtension;\n      return newFileName;\n    });\n  }, [setDefaultOutName, videoCodecForVideoTab]);\n  const setCodec = useCallback127((newCodec) => {\n    if (renderMode === \"audio\") {\n      setVideoCodecForAudioTab(newCodec);\n    } else {\n      setVideoCodecForVideoTab(newCodec);\n    }\n    setDefaultOutName({\n      type: \"render\",\n      codec: newCodec,\n      audioCodec: deriveFinalAudioCodec(newCodec, userSelectedAudioCodec)\n    });\n  }, [\n    userSelectedAudioCodec,\n    deriveFinalAudioCodec,\n    renderMode,\n    setDefaultOutName\n  ]);\n  const setStillFormat = useCallback127((format) => {\n    setStillImageFormat(format);\n    setDefaultOutName({ type: \"still\", imageFormat: format });\n  }, [setDefaultOutName]);\n  const { setSidebarCollapsedState } = useContext83(SidebarContext);\n  const onClickStill = useCallback127(() => {\n    setSidebarCollapsedState({ left: null, right: \"expanded\" });\n    persistSelectedOptionsSidebarPanel2(\"renders\");\n    optionsSidebarTabs.current?.selectRendersPanel();\n    dispatchIfMounted({ type: \"start\" });\n    addStillRenderJob({\n      compositionId: resolvedComposition.id,\n      outName,\n      imageFormat: stillImageFormat,\n      jpegQuality,\n      frame: frame2,\n      scale,\n      logLevel,\n      chromiumOptions,\n      delayRenderTimeout,\n      envVariables: envVariablesArrayToObject(envVariables),\n      inputProps,\n      offthreadVideoCacheSizeInBytes,\n      multiProcessOnLinux,\n      beepOnFinish,\n      metadata,\n      chromeMode,\n      offthreadVideoThreads,\n      mediaCacheSizeInBytes\n    }).then(() => {\n      dispatchIfMounted({ type: \"succeed\" });\n      setSelectedModal(null);\n    }).catch(() => {\n      dispatchIfMounted({ type: \"fail\" });\n    });\n  }, [\n    setSidebarCollapsedState,\n    dispatchIfMounted,\n    resolvedComposition.id,\n    outName,\n    stillImageFormat,\n    jpegQuality,\n    frame2,\n    scale,\n    logLevel,\n    chromiumOptions,\n    delayRenderTimeout,\n    envVariables,\n    inputProps,\n    offthreadVideoCacheSizeInBytes,\n    multiProcessOnLinux,\n    beepOnFinish,\n    setSelectedModal,\n    metadata,\n    chromeMode,\n    offthreadVideoThreads,\n    mediaCacheSizeInBytes\n  ]);\n  const [everyNthFrameSetting, setEveryNthFrameSetting] = useState81(() => initialEveryNthFrame);\n  const everyNthFrame = useMemo128(() => {\n    if (codec === \"gif\") {\n      return everyNthFrameSetting;\n    }\n    return 1;\n  }, [codec, everyNthFrameSetting]);\n  const audioCodec = deriveFinalAudioCodec(codec, userSelectedAudioCodec);\n  const availablePixelFormats = useMemo128(() => {\n    return BrowserSafeApis10.validPixelFormatsForCodec(codec);\n  }, [codec]);\n  const pixelFormat = useMemo128(() => {\n    if (availablePixelFormats.includes(userPreferredPixelFormat)) {\n      return userPreferredPixelFormat;\n    }\n    return availablePixelFormats[0];\n  }, [availablePixelFormats, userPreferredPixelFormat]);\n  const onClickVideo = useCallback127(() => {\n    setSidebarCollapsedState({ left: null, right: \"expanded\" });\n    persistSelectedOptionsSidebarPanel2(\"renders\");\n    optionsSidebarTabs.current?.selectRendersPanel();\n    dispatchIfMounted({ type: \"start\" });\n    addVideoRenderJob({\n      compositionId: resolvedComposition.id,\n      outName,\n      imageFormat: videoImageFormat,\n      jpegQuality: stillImageFormat === \"jpeg\" ? jpegQuality : null,\n      scale,\n      logLevel,\n      codec,\n      concurrency,\n      crf: qualityControlType === \"crf\" && hardwareAcceleration !== \"if-possible\" && hardwareAcceleration !== \"required\" ? crf : null,\n      endFrame,\n      startFrame,\n      muted,\n      enforceAudioTrack,\n      proResProfile,\n      x264Preset,\n      pixelFormat,\n      audioBitrate,\n      videoBitrate,\n      everyNthFrame,\n      numberOfGifLoops,\n      delayRenderTimeout,\n      audioCodec,\n      disallowParallelEncoding,\n      chromiumOptions,\n      envVariables: envVariablesArrayToObject(envVariables),\n      inputProps,\n      offthreadVideoCacheSizeInBytes,\n      colorSpace,\n      multiProcessOnLinux,\n      encodingBufferSize,\n      encodingMaxRate,\n      beepOnFinish,\n      repro,\n      forSeamlessAacConcatenation,\n      separateAudioTo,\n      metadata,\n      hardwareAcceleration,\n      chromeMode,\n      offthreadVideoThreads,\n      mediaCacheSizeInBytes\n    }).then(() => {\n      dispatchIfMounted({ type: \"succeed\" });\n      setSelectedModal(null);\n    }).catch(() => {\n      dispatchIfMounted({ type: \"fail\" });\n    });\n  }, [\n    setSidebarCollapsedState,\n    dispatchIfMounted,\n    resolvedComposition.id,\n    outName,\n    videoImageFormat,\n    stillImageFormat,\n    jpegQuality,\n    scale,\n    logLevel,\n    codec,\n    concurrency,\n    qualityControlType,\n    crf,\n    endFrame,\n    startFrame,\n    muted,\n    enforceAudioTrack,\n    proResProfile,\n    x264Preset,\n    pixelFormat,\n    audioBitrate,\n    videoBitrate,\n    everyNthFrame,\n    numberOfGifLoops,\n    delayRenderTimeout,\n    audioCodec,\n    disallowParallelEncoding,\n    chromiumOptions,\n    envVariables,\n    inputProps,\n    offthreadVideoCacheSizeInBytes,\n    colorSpace,\n    multiProcessOnLinux,\n    encodingBufferSize,\n    encodingMaxRate,\n    beepOnFinish,\n    repro,\n    forSeamlessAacConcatenation,\n    separateAudioTo,\n    setSelectedModal,\n    metadata,\n    hardwareAcceleration,\n    chromeMode,\n    offthreadVideoThreads,\n    mediaCacheSizeInBytes\n  ]);\n  const onClickSequence = useCallback127(() => {\n    setSidebarCollapsedState({ left: null, right: \"expanded\" });\n    persistSelectedOptionsSidebarPanel2(\"renders\");\n    optionsSidebarTabs.current?.selectRendersPanel();\n    dispatchIfMounted({ type: \"start\" });\n    addSequenceRenderJob({\n      compositionId: resolvedComposition.id,\n      outName,\n      imageFormat: sequenceImageFormat,\n      scale,\n      logLevel,\n      concurrency,\n      endFrame,\n      jpegQuality,\n      startFrame,\n      delayRenderTimeout,\n      chromiumOptions,\n      envVariables: envVariablesArrayToObject(envVariables),\n      inputProps,\n      offthreadVideoCacheSizeInBytes,\n      disallowParallelEncoding,\n      multiProcessOnLinux,\n      beepOnFinish,\n      repro,\n      metadata,\n      chromeMode,\n      offthreadVideoThreads,\n      mediaCacheSizeInBytes\n    }).then(() => {\n      dispatchIfMounted({ type: \"succeed\" });\n      setSelectedModal(null);\n    }).catch(() => {\n      dispatchIfMounted({ type: \"fail\" });\n    });\n  }, [\n    setSidebarCollapsedState,\n    dispatchIfMounted,\n    resolvedComposition.id,\n    outName,\n    sequenceImageFormat,\n    scale,\n    logLevel,\n    concurrency,\n    endFrame,\n    jpegQuality,\n    startFrame,\n    delayRenderTimeout,\n    chromiumOptions,\n    envVariables,\n    inputProps,\n    offthreadVideoCacheSizeInBytes,\n    disallowParallelEncoding,\n    multiProcessOnLinux,\n    beepOnFinish,\n    repro,\n    setSelectedModal,\n    metadata,\n    chromeMode,\n    offthreadVideoThreads,\n    mediaCacheSizeInBytes\n  ]);\n  useEffect80(() => {\n    return () => {\n      isMounted.current = false;\n    };\n  }, []);\n  const imageFormatOptions = useMemo128(() => {\n    if (renderMode === \"still\") {\n      return [\n        {\n          label: \"PNG\",\n          onClick: () => setStillFormat(\"png\"),\n          key: \"png\",\n          selected: stillImageFormat === \"png\"\n        },\n        {\n          label: \"JPEG\",\n          onClick: () => setStillFormat(\"jpeg\"),\n          key: \"jpeg\",\n          selected: stillImageFormat === \"jpeg\"\n        },\n        {\n          label: \"PDF\",\n          onClick: () => setStillFormat(\"pdf\"),\n          key: \"pdf\",\n          selected: stillImageFormat === \"pdf\"\n        },\n        {\n          label: \"WebP\",\n          onClick: () => setStillFormat(\"webp\"),\n          key: \"webp\",\n          selected: stillImageFormat === \"webp\"\n        }\n      ];\n    }\n    if (renderMode === \"sequence\") {\n      return [\n        {\n          label: \"PNG\",\n          onClick: () => setSequenceImageFormat(\"png\"),\n          key: \"png\",\n          selected: sequenceImageFormat === \"png\"\n        },\n        {\n          label: \"JPEG\",\n          onClick: () => setSequenceImageFormat(\"jpeg\"),\n          key: \"jpeg\",\n          selected: sequenceImageFormat === \"jpeg\"\n        }\n      ];\n    }\n    return [\n      {\n        label: \"PNG\",\n        onClick: () => setVideoImageFormat(\"png\"),\n        key: \"png\",\n        selected: videoImageFormat === \"png\"\n      },\n      {\n        label: \"JPEG\",\n        onClick: () => setVideoImageFormat(\"jpeg\"),\n        key: \"jpeg\",\n        selected: videoImageFormat === \"jpeg\"\n      }\n    ];\n  }, [\n    renderMode,\n    videoImageFormat,\n    stillImageFormat,\n    setStillFormat,\n    sequenceImageFormat\n  ]);\n  const setRenderMode = useCallback127((newRenderMode) => {\n    setRenderModeState(newRenderMode);\n    if (newRenderMode === \"audio\") {\n      setDefaultOutName({\n        type: \"render\",\n        codec: videoCodecForAudioTab,\n        audioCodec: deriveFinalAudioCodec(videoCodecForAudioTab, userSelectedAudioCodec)\n      });\n    }\n    if (newRenderMode === \"video\") {\n      setDefaultOutName({\n        type: \"render\",\n        codec: videoCodecForVideoTab,\n        audioCodec: deriveFinalAudioCodec(videoCodecForVideoTab, userSelectedAudioCodec)\n      });\n    }\n    if (newRenderMode === \"still\") {\n      setDefaultOutName({ type: \"still\", imageFormat: stillImageFormat });\n    }\n    if (newRenderMode === \"sequence\") {\n      setDefaultOutName({ type: \"sequence\" });\n    }\n  }, [\n    videoCodecForAudioTab,\n    userSelectedAudioCodec,\n    deriveFinalAudioCodec,\n    setDefaultOutName,\n    stillImageFormat,\n    videoCodecForVideoTab\n  ]);\n  const renderTabOptions = useMemo128(() => {\n    if (resolvedComposition?.durationInFrames < 2) {\n      return [\n        {\n          label: \"Still\",\n          onClick: () => {\n            setRenderMode(\"still\");\n          },\n          key: \"still\",\n          selected: renderMode === \"still\"\n        }\n      ];\n    }\n    return [\n      {\n        label: \"Still\",\n        onClick: () => {\n          setRenderMode(\"still\");\n        },\n        key: \"still\",\n        selected: renderMode === \"still\"\n      },\n      {\n        label: \"Video\",\n        onClick: () => {\n          setRenderMode(\"video\");\n        },\n        key: \"video\",\n        selected: renderMode === \"video\"\n      },\n      {\n        label: \"Audio\",\n        onClick: () => {\n          setRenderMode(\"audio\");\n        },\n        key: \"audio\",\n        selected: renderMode === \"audio\"\n      },\n      {\n        label: \"Image sequence\",\n        onClick: () => {\n          setRenderMode(\"sequence\");\n        },\n        key: \"sequence\",\n        selected: renderMode === \"sequence\"\n      }\n    ];\n  }, [resolvedComposition?.durationInFrames, renderMode, setRenderMode]);\n  const outnameValidation = validateOutnameGui({\n    outName,\n    codec,\n    audioCodec,\n    renderMode,\n    stillImageFormat,\n    separateAudioTo\n  });\n  const { tab, setTab, shownTabs } = useRenderModalSections(renderMode, codec);\n  const { registerKeybinding } = useKeybinding();\n  const renderDisabled = state.type === \"load\" || !outnameValidation.valid;\n  const trigger = useCallback127(() => {\n    if (renderMode === \"still\") {\n      onClickStill();\n    } else if (renderMode === \"sequence\") {\n      onClickSequence();\n    } else {\n      onClickVideo();\n    }\n  }, [renderMode, onClickStill, onClickSequence, onClickVideo]);\n  useEffect80(() => {\n    if (renderDisabled) {\n      return;\n    }\n    const enter = registerKeybinding({\n      callback() {\n        trigger();\n      },\n      commandCtrlKey: true,\n      key: \"Enter\",\n      event: \"keydown\",\n      preventDefault: true,\n      triggerIfInputFieldFocused: true,\n      keepRegisteredWhenNotHighestContext: false\n    });\n    return () => {\n      enter.unregister();\n    };\n  }, [registerKeybinding, renderDisabled, trigger]);\n  const pixelFormatOptions = useMemo128(() => {\n    return availablePixelFormats.map((option) => {\n      return {\n        label: option,\n        onClick: () => setPixelFormat(option),\n        key: option,\n        id: option,\n        keyHint: null,\n        leftItem: pixelFormat === option ? /* @__PURE__ */ jsx257(Checkmark, {}) : null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: option\n      };\n    });\n  }, [availablePixelFormats, pixelFormat]);\n  return /* @__PURE__ */ jsxs136(\"div\", {\n    style: outerModalStyle,\n    children: [\n      /* @__PURE__ */ jsx257(ModalHeader, {\n        title: `Render ${resolvedComposition.id}`\n      }),\n      /* @__PURE__ */ jsxs136(\"div\", {\n        style: container59,\n        children: [\n          /* @__PURE__ */ jsx257(SegmentedControl, {\n            items: renderTabOptions,\n            needsWrapping: false\n          }),\n          /* @__PURE__ */ jsx257(\"div\", {\n            style: flexer\n          }),\n          /* @__PURE__ */ jsxs136(Button, {\n            autoFocus: true,\n            onClick: trigger,\n            disabled: renderDisabled,\n            style: {\n              ...buttonStyle7,\n              backgroundColor: outnameValidation.valid ? BLUE : BLUE_DISABLED\n            },\n            children: [\n              state.type === \"idle\" ? `Render ${renderMode}` : \"Rendering...\",\n              /* @__PURE__ */ jsx257(ShortcutHint, {\n                keyToPress: \"\",\n                cmdOrCtrl: true\n              })\n            ]\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsxs136(\"div\", {\n        style: horizontalLayout,\n        children: [\n          /* @__PURE__ */ jsxs136(\"div\", {\n            style: leftSidebar,\n            children: [\n              shownTabs.includes(\"general\") ? /* @__PURE__ */ jsxs136(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"general\",\n                onClick: () => setTab(\"general\"),\n                children: [\n                  /* @__PURE__ */ jsx257(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx257(FileIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"General\"\n                ]\n              }) : null,\n              shownTabs.includes(\"data\") ? /* @__PURE__ */ jsxs136(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"data\",\n                onClick: () => setTab(\"data\"),\n                children: [\n                  /* @__PURE__ */ jsx257(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx257(DataIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"Input Props\"\n                ]\n              }) : null,\n              shownTabs.includes(\"picture\") ? /* @__PURE__ */ jsxs136(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"picture\",\n                onClick: () => setTab(\"picture\"),\n                children: [\n                  /* @__PURE__ */ jsx257(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx257(PicIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"Picture\"\n                ]\n              }) : null,\n              shownTabs.includes(\"audio\") ? /* @__PURE__ */ jsxs136(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"audio\",\n                onClick: () => setTab(\"audio\"),\n                children: [\n                  /* @__PURE__ */ jsx257(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx257(AudioIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"Audio\"\n                ]\n              }) : null,\n              shownTabs.includes(\"gif\") ? /* @__PURE__ */ jsxs136(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"gif\",\n                onClick: () => setTab(\"gif\"),\n                children: [\n                  /* @__PURE__ */ jsx257(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx257(GifIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"GIF\"\n                ]\n              }) : null,\n              shownTabs.includes(\"advanced\") ? /* @__PURE__ */ jsxs136(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"advanced\",\n                onClick: () => setTab(\"advanced\"),\n                children: [\n                  /* @__PURE__ */ jsx257(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx257(GearIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"Other\"\n                ]\n              }) : null\n            ]\n          }),\n          /* @__PURE__ */ jsx257(\"div\", {\n            style: optionsPanel,\n            className: VERTICAL_SCROLLBAR_CLASSNAME,\n            children: tab === \"general\" ? /* @__PURE__ */ jsx257(RenderModalBasic, {\n              codec,\n              resolvedComposition,\n              frame: frame2,\n              imageFormatOptions,\n              outName,\n              proResProfile,\n              renderMode,\n              setVideoCodec: setCodec,\n              setFrame,\n              setOutName,\n              setProResProfile,\n              endFrame,\n              setEndFrame,\n              setStartFrame,\n              setVerboseLogging: setLogLevel,\n              logLevel,\n              startFrame,\n              validationMessage: outnameValidation.valid ? null : outnameValidation.error.message\n            }) : tab === \"picture\" ? /* @__PURE__ */ jsx257(RenderModalPicture, {\n              renderMode,\n              scale,\n              setScale,\n              pixelFormat,\n              pixelFormatOptions,\n              imageFormatOptions,\n              crf,\n              setCrf,\n              customTargetVideoBitrate,\n              maxCrf,\n              minCrf,\n              jpegQuality,\n              qualityControlType,\n              setJpegQuality,\n              setColorSpace,\n              colorSpace,\n              setCustomTargetVideoBitrateValue,\n              setQualityControl,\n              videoImageFormat,\n              stillImageFormat,\n              shouldDisplayQualityControlPicker: supportsBothQualityControls,\n              encodingBufferSize,\n              setEncodingBufferSize,\n              encodingMaxRate,\n              setEncodingMaxRate,\n              compositionWidth: resolvedComposition.width,\n              compositionHeight: resolvedComposition.height\n            }) : tab === \"audio\" ? /* @__PURE__ */ jsx257(RenderModalAudio, {\n              muted,\n              renderMode,\n              setMuted,\n              codec,\n              audioCodec,\n              setAudioCodec,\n              enforceAudioTrack,\n              setEnforceAudioTrackState,\n              customTargetAudioBitrate,\n              setCustomTargetAudioBitrateValue,\n              setShouldHaveCustomTargetAudioBitrate,\n              shouldHaveCustomTargetAudioBitrate,\n              forSeamlessAacConcatenation,\n              setForSeamlessAacConcatenation,\n              separateAudioTo,\n              setSeparateAudioTo,\n              outName\n            }) : tab === \"gif\" ? /* @__PURE__ */ jsx257(RenderModalGif, {\n              everyNthFrame,\n              limitNumberOfGifLoops,\n              numberOfGifLoopsSetting,\n              setEveryNthFrameSetting,\n              setLimitNumberOfGifLoops,\n              setNumberOfGifLoopsSetting\n            }) : tab === \"data\" ? /* @__PURE__ */ jsx257(DataEditor, {\n              defaultProps: inputProps,\n              setDefaultProps: setInputProps,\n              unresolvedComposition,\n              mayShowSaveButton: false,\n              propsEditType: \"input-props\",\n              saving,\n              setSaving,\n              readOnlyStudio: false\n            }) : /* @__PURE__ */ jsx257(RenderModalAdvanced, {\n              x264Preset,\n              setx264Preset,\n              concurrency,\n              maxConcurrency,\n              minConcurrency,\n              renderMode,\n              setConcurrency,\n              delayRenderTimeout,\n              setDelayRenderTimeout,\n              disallowParallelEncoding,\n              setDisallowParallelEncoding,\n              setDisableWebSecurity,\n              setIgnoreCertificateErrors,\n              setHeadless,\n              headless,\n              ignoreCertificateErrors,\n              disableWebSecurity,\n              openGlOption,\n              setOpenGlOption,\n              setEnvVariables,\n              envVariables,\n              offthreadVideoCacheSizeInBytes,\n              setMediaCacheSizeInBytes,\n              mediaCacheSizeInBytes,\n              setOffthreadVideoCacheSizeInBytes,\n              offthreadVideoThreads,\n              setOffthreadVideoThreads,\n              enableMultiProcessOnLinux: multiProcessOnLinux,\n              setChromiumMultiProcessOnLinux,\n              codec,\n              userAgent,\n              setUserAgent,\n              setBeep: setBeepOnFinish,\n              beep: beepOnFinish,\n              repro,\n              setRepro,\n              hardwareAcceleration,\n              setHardwareAcceleration,\n              chromeModeOption: chromeMode,\n              setChromeModeOption: setChromeMode,\n              darkMode,\n              setDarkMode\n            })\n          })\n        ]\n      })\n    ]\n  });\n};\nvar RenderModalWithLoader = (props) => {\n  return /* @__PURE__ */ jsx257(DismissableModal, {\n    children: /* @__PURE__ */ jsx257(ResolveCompositionBeforeModal, {\n      compositionId: props.compositionId,\n      children: /* @__PURE__ */ jsx257(RenderModal, {\n        ...props\n      })\n    })\n  });\n};\n\n// src/components/RenderModal/WebRenderModal.tsx\nimport { getDefaultOutLocation as getDefaultOutLocation2 } from \"@remotion/studio-shared\";\nimport { getDefaultAudioCodecForContainer } from \"@remotion/web-renderer\";\nimport { useCallback as useCallback131, useContext as useContext84, useMemo as useMemo133, useState as useState85 } from \"react\";\n\n// src/icons/certificate.tsx\nimport { jsx as jsx258 } from \"react/jsx-runtime\";\nvar CertificateIcon = (props) => /* @__PURE__ */ jsx258(\"svg\", {\n  xmlns: \"http://www.w3.org/2000/svg\",\n  viewBox: \"0 0 576 512\",\n  ...props,\n  children: /* @__PURE__ */ jsx258(\"path\", {\n    fill: \"currentcolor\",\n    d: \"M192 32l128 0 0 96c0 35.3 28.7 64 64 64l96 0 0 256c0 17.7-14.3 32-32 32l-192 0 0 32 192 0c35.3 0 64-28.7 64-64l0-261.5c0-17-6.7-33.3-18.7-45.3L370.7 18.7C358.7 6.7 342.5 0 325.5 0L192 0c-35.3 0-64 28.7-64 64l0 80c10.9 0 21.6 1 32 2.9L160 64c0-17.7 14.3-32 32-32zM352 45.3L466.7 160 384 160c-17.7 0-32-14.3-32-32l0-82.7zM32 320a96 96 0 1 1 192 0 96 96 0 1 1 -192 0zM176 438.7l0 66.3-40.1-22.9c-4.9-2.8-11-2.8-15.9 0L80 505 80 438.7c14.8 6 31 9.3 48 9.3s33.2-3.3 48-9.3zm32-18.8c29.3-23.5 48-59.5 48-99.9 0-70.7-57.3-128-128-128S0 249.3 0 320c0 40.4 18.7 76.5 48 99.9l0 101.8c0 12.3 10 22.3 22.3 22.3 3.9 0 7.7-1 11.1-2.9l46.6-26.6 46.6 26.6c3.4 1.9 7.2 2.9 11.1 2.9 12.3 0 22.3-10 22.3-22.3l0-101.8zM128 344a24 24 0 1 1 0-48 24 24 0 1 1 0 48zm0-80a56 56 0 1 0 0 112 56 56 0 1 0 0-112z\"\n  })\n});\n\n// src/components/RenderModal/use-encodable-audio-codecs.ts\nimport {\n  getEncodableAudioCodecs,\n  getSupportedAudioCodecsForContainer\n} from \"@remotion/web-renderer\";\nimport { useEffect as useEffect81, useRef as useRef45, useState as useState82 } from \"react\";\nvar useEncodableAudioCodecs = (container60) => {\n  const cacheRef = useRef45({});\n  const [codecsByContainer, setCodecsByContainer] = useState82(() => {\n    return {\n      [container60]: getSupportedAudioCodecsForContainer(container60)\n    };\n  });\n  useEffect81(() => {\n    const cached = cacheRef.current[container60];\n    if (cached) {\n      return;\n    }\n    const supported = getSupportedAudioCodecsForContainer(container60);\n    cacheRef.current[container60] = {\n      codecs: supported,\n      status: \"fetching\"\n    };\n    getEncodableAudioCodecs(container60).then((encodable) => {\n      cacheRef.current[container60] = {\n        codecs: encodable,\n        status: \"done\"\n      };\n      setCodecsByContainer((prev) => ({\n        ...prev,\n        [container60]: encodable\n      }));\n    }).catch(() => {\n      cacheRef.current[container60] = {\n        codecs: supported,\n        status: \"done\"\n      };\n    });\n  }, [container60]);\n  return codecsByContainer[container60] ?? getSupportedAudioCodecsForContainer(container60);\n};\n\n// src/components/RenderModal/use-encodable-video-codecs.ts\nimport {\n  getEncodableVideoCodecs,\n  getSupportedVideoCodecsForContainer\n} from \"@remotion/web-renderer\";\nimport { useEffect as useEffect82, useRef as useRef46, useState as useState83 } from \"react\";\nvar useEncodableVideoCodecs = (container60) => {\n  const cacheRef = useRef46({});\n  const [codecsByContainer, setCodecsByContainer] = useState83(() => {\n    return {\n      [container60]: getSupportedVideoCodecsForContainer(container60)\n    };\n  });\n  useEffect82(() => {\n    const cached = cacheRef.current[container60];\n    if (cached) {\n      return;\n    }\n    const supported = getSupportedVideoCodecsForContainer(container60);\n    cacheRef.current[container60] = {\n      codecs: supported,\n      status: \"fetching\"\n    };\n    getEncodableVideoCodecs(container60).then((encodable) => {\n      cacheRef.current[container60] = {\n        codecs: encodable,\n        status: \"done\"\n      };\n      setCodecsByContainer((prev) => ({\n        ...prev,\n        [container60]: encodable\n      }));\n    }).catch(() => {\n      cacheRef.current[container60] = {\n        codecs: supported,\n        status: \"done\"\n      };\n    });\n  }, [container60]);\n  return codecsByContainer[container60] ?? getSupportedVideoCodecsForContainer(container60);\n};\n\n// src/components/RenderModal/WebRendererExperimentalBadge.tsx\nimport { jsx as jsx259, jsxs as jsxs137 } from \"react/jsx-runtime\";\nvar row8 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\",\n  justifyContent: \"center\"\n};\nvar text3 = {\n  fontSize: 14,\n  fontFamily: \"sans-serif\",\n  color: LIGHT_TEXT\n};\nvar icon7 = {\n  width: 14,\n  height: 14,\n  flexShrink: 0,\n  fill: WARNING_COLOR,\n  marginRight: 8\n};\nvar link3 = {\n  color: \"inherit\",\n  textDecoration: \"underline\",\n  fontSize: 14\n};\nvar WebRendererExperimentalBadge = () => {\n  return /* @__PURE__ */ jsxs137(\"div\", {\n    style: row8,\n    children: [\n      /* @__PURE__ */ jsx259(WarningTriangle, {\n        type: \"warning\",\n        style: icon7\n      }),\n      /* @__PURE__ */ jsxs137(\"div\", {\n        style: text3,\n        children: [\n          \"The Remotion Web Renderer is experimental.\",\n          \" \",\n          /* @__PURE__ */ jsx259(\"a\", {\n            href: \"https://github.com/remotion-dev/remotion/issues/5913\",\n            target: \"_blank\",\n            rel: \"noopener noreferrer\",\n            style: link3,\n            children: \"Track progress on GitHub\"\n          }),\n          \" \",\n          \"and discuss in the\",\n          \" \",\n          /* @__PURE__ */ jsx259(\"a\", {\n            href: \"https://remotion.dev/discord\",\n            target: \"_blank\",\n            rel: \"noopener noreferrer\",\n            style: link3,\n            children: \"#web-renderer\"\n          }),\n          \" \",\n          \"channel on Discord.\"\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/WebRenderModalAdvanced.tsx\nimport { useCallback as useCallback128, useMemo as useMemo129 } from \"react\";\nimport { jsx as jsx260, jsxs as jsxs138 } from \"react/jsx-runtime\";\nvar tabContainer = {\n  flex: 1\n};\nvar WebRenderModalAdvanced = ({\n  renderMode,\n  delayRenderTimeout,\n  setDelayRenderTimeout,\n  mediaCacheSizeInBytes,\n  setMediaCacheSizeInBytes,\n  hardwareAcceleration,\n  setHardwareAcceleration\n}) => {\n  const toggleCustomMediaCacheSizeInBytes = useCallback128(() => {\n    setMediaCacheSizeInBytes((previous) => {\n      if (previous === null) {\n        return 1000 * 1000 * 1000;\n      }\n      return null;\n    });\n  }, [setMediaCacheSizeInBytes]);\n  const changeMediaCacheSizeInBytes = useCallback128((cb) => {\n    setMediaCacheSizeInBytes((prev) => {\n      if (prev === null) {\n        throw new TypeError(\"Expected previous value\");\n      }\n      if (typeof cb === \"function\") {\n        return cb(prev);\n      }\n      return cb;\n    });\n  }, [setMediaCacheSizeInBytes]);\n  const hardwareAccelerationOptions = useMemo129(() => {\n    return [\n      {\n        label: \"No Preference\",\n        onClick: () => setHardwareAcceleration(\"no-preference\"),\n        leftItem: hardwareAcceleration === \"no-preference\" ? /* @__PURE__ */ jsx260(Checkmark, {}) : null,\n        id: \"no-preference\",\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: \"no-preference\"\n      },\n      {\n        label: \"Prefer Hardware\",\n        onClick: () => setHardwareAcceleration(\"prefer-hardware\"),\n        leftItem: hardwareAcceleration === \"prefer-hardware\" ? /* @__PURE__ */ jsx260(Checkmark, {}) : null,\n        id: \"prefer-hardware\",\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: \"prefer-hardware\"\n      },\n      {\n        label: \"Prefer Software\",\n        onClick: () => setHardwareAcceleration(\"prefer-software\"),\n        leftItem: hardwareAcceleration === \"prefer-software\" ? /* @__PURE__ */ jsx260(Checkmark, {}) : null,\n        id: \"prefer-software\",\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: \"prefer-software\"\n      }\n    ];\n  }, [hardwareAcceleration, setHardwareAcceleration]);\n  return /* @__PURE__ */ jsxs138(\"div\", {\n    style: tabContainer,\n    children: [\n      /* @__PURE__ */ jsx260(NumberSetting, {\n        name: \"Delay Render Timeout\",\n        formatter: (v) => `${v}ms`,\n        min: 0,\n        max: 1e9,\n        step: 1000,\n        value: delayRenderTimeout,\n        onValueChanged: setDelayRenderTimeout,\n        hint: \"delayRenderTimeoutInMillisecondsOption\"\n      }),\n      /* @__PURE__ */ jsxs138(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs138(\"div\", {\n            style: label5,\n            children: [\n              \"Custom @remotion/media cache size \",\n              /* @__PURE__ */ jsx260(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx260(OptionExplainerBubble, {\n                id: \"mediaCacheSizeInBytesOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx260(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx260(Checkbox, {\n              checked: mediaCacheSizeInBytes !== null,\n              onChange: toggleCustomMediaCacheSizeInBytes,\n              name: \"media-cache-size\"\n            })\n          })\n        ]\n      }),\n      mediaCacheSizeInBytes === null ? null : /* @__PURE__ */ jsx260(NumberSetting, {\n        name: \"@remotion/media cache size\",\n        formatter: (w) => `${w} bytes`,\n        min: 0,\n        max: 10000000000,\n        step: 10 * 1024 * 1024,\n        value: mediaCacheSizeInBytes,\n        onValueChanged: changeMediaCacheSizeInBytes\n      }),\n      renderMode === \"video\" ? /* @__PURE__ */ jsxs138(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsx260(\"div\", {\n            style: label5,\n            children: \"Hardware Acceleration\"\n          }),\n          /* @__PURE__ */ jsx260(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx260(Combobox, {\n              values: hardwareAccelerationOptions,\n              selectedId: hardwareAcceleration,\n              title: \"Hardware Acceleration\"\n            })\n          })\n        ]\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/WebRenderModalAudio.tsx\nimport { getSupportedAudioCodecsForContainer as getSupportedAudioCodecsForContainer2 } from \"@remotion/web-renderer\";\nimport { useMemo as useMemo130 } from \"react\";\n\n// src/components/RenderModal/quality-options.tsx\nimport { jsx as jsx261 } from \"react/jsx-runtime\";\nvar QUALITY_OPTIONS = [\n  { value: \"very-low\", label: \"Very Low\" },\n  { value: \"low\", label: \"Low\" },\n  { value: \"medium\", label: \"Medium\" },\n  { value: \"high\", label: \"High\" },\n  { value: \"very-high\", label: \"Very High\" }\n];\nvar getQualityOptions = (selectedQuality, setQuality) => {\n  return QUALITY_OPTIONS.map(({ value, label: label12 }) => ({\n    label: label12,\n    onClick: () => setQuality(value),\n    leftItem: selectedQuality === value ? /* @__PURE__ */ jsx261(Checkmark, {}) : null,\n    id: value,\n    keyHint: null,\n    quickSwitcherLabel: null,\n    subMenu: null,\n    type: \"item\",\n    value\n  }));\n};\n\n// src/components/RenderModal/WebRenderModalAudio.tsx\nimport { jsx as jsx262, jsxs as jsxs139, Fragment as Fragment46 } from \"react/jsx-runtime\";\nvar container60 = {\n  flex: 1,\n  overflowY: \"auto\"\n};\nvar fallbackNoticeStyle = {\n  backgroundColor: \"rgba(59, 130, 246, 0.15)\",\n  border: \"1px solid rgba(59, 130, 246, 0.4)\",\n  borderRadius: 4,\n  padding: \"8px 12px\",\n  marginLeft: 16,\n  marginRight: 16,\n  marginTop: 8,\n  fontSize: 13,\n  lineHeight: 1.4,\n  color: \"#60a5fa\"\n};\nvar humanReadableWebAudioCodec = (audioCodec) => {\n  switch (audioCodec) {\n    case \"aac\":\n      return \"AAC\";\n    case \"opus\":\n      return \"Opus\";\n    default:\n      return audioCodec;\n  }\n};\nvar WebRenderModalAudio = ({\n  muted,\n  setMuted,\n  audioCodec,\n  setAudioCodec,\n  audioBitrate,\n  setAudioBitrate,\n  container: videoContainer,\n  encodableCodecs,\n  effectiveAudioCodec\n}) => {\n  const containerSupported = useMemo130(() => getSupportedAudioCodecsForContainer2(videoContainer), [videoContainer]);\n  const audioCodecOptions = useMemo130(() => {\n    return containerSupported.map((codec) => {\n      const isEncodable = encodableCodecs.includes(codec);\n      return {\n        label: humanReadableWebAudioCodec(codec),\n        onClick: () => setAudioCodec(codec),\n        leftItem: audioCodec === codec ? /* @__PURE__ */ jsx262(Checkmark, {}) : null,\n        id: codec,\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: codec,\n        disabled: !isEncodable\n      };\n    });\n  }, [containerSupported, encodableCodecs, audioCodec, setAudioCodec]);\n  const audioBitrateOptions = useMemo130(() => getQualityOptions(audioBitrate, setAudioBitrate), [audioBitrate, setAudioBitrate]);\n  return /* @__PURE__ */ jsxs139(\"div\", {\n    style: container60,\n    className: VERTICAL_SCROLLBAR_CLASSNAME,\n    children: [\n      /* @__PURE__ */ jsx262(MutedSetting, {\n        enforceAudioTrack: false,\n        muted,\n        setMuted\n      }),\n      !muted ? /* @__PURE__ */ jsxs139(Fragment46, {\n        children: [\n          /* @__PURE__ */ jsx262(RenderModalHr, {}),\n          /* @__PURE__ */ jsxs139(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsxs139(\"div\", {\n                style: label5,\n                children: [\n                  \"Audio Quality\",\n                  /* @__PURE__ */ jsx262(Spacing, {\n                    x: 0.5\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsx262(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx262(Combobox, {\n                  values: audioBitrateOptions,\n                  selectedId: audioBitrate,\n                  title: \"Audio Quality\"\n                })\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsxs139(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsxs139(\"div\", {\n                style: label5,\n                children: [\n                  \"Audio Codec\",\n                  /* @__PURE__ */ jsx262(Spacing, {\n                    x: 0.5\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsx262(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx262(Combobox, {\n                  values: audioCodecOptions,\n                  selectedId: audioCodec,\n                  title: \"Audio Codec\"\n                })\n              })\n            ]\n          }),\n          effectiveAudioCodec !== audioCodec ? /* @__PURE__ */ jsxs139(\"div\", {\n            style: fallbackNoticeStyle,\n            children: [\n              humanReadableWebAudioCodec(audioCodec),\n              \" is not available in this browser. Using \",\n              humanReadableWebAudioCodec(effectiveAudioCodec),\n              \" \",\n              \"instead.\"\n            ]\n          }) : null\n        ]\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/WebRenderModalBasic.tsx\nimport { useMemo as useMemo131 } from \"react\";\nimport { jsx as jsx263, jsxs as jsxs140, Fragment as Fragment47 } from \"react/jsx-runtime\";\nvar tabContainer2 = {\n  flex: 1\n};\nvar WebRenderModalBasic = ({\n  renderMode,\n  resolvedComposition,\n  imageFormat,\n  setStillFormat,\n  frame: frame2,\n  onFrameChanged,\n  onFrameSetDirectly,\n  container: container61,\n  setContainerFormat,\n  setCodec,\n  encodableVideoCodecs,\n  effectiveVideoCodec,\n  startFrame,\n  setStartFrame,\n  endFrame,\n  setEndFrame,\n  outName,\n  onOutNameChange,\n  validationMessage,\n  logLevel,\n  setLogLevel\n}) => {\n  const imageFormatOptions = useMemo131(() => {\n    return [\n      {\n        label: \"PNG\",\n        onClick: () => setStillFormat(\"png\"),\n        key: \"png\",\n        selected: imageFormat === \"png\"\n      },\n      {\n        label: \"JPEG\",\n        onClick: () => setStillFormat(\"jpeg\"),\n        key: \"jpeg\",\n        selected: imageFormat === \"jpeg\"\n      },\n      {\n        label: \"WebP\",\n        onClick: () => setStillFormat(\"webp\"),\n        key: \"webp\",\n        selected: imageFormat === \"webp\"\n      }\n    ];\n  }, [imageFormat, setStillFormat]);\n  const logLevelOptions = useMemo131(() => {\n    return [\"trace\", \"verbose\", \"info\", \"warn\", \"error\"].map((level) => {\n      return {\n        label: humanReadableLogLevel(level),\n        onClick: () => setLogLevel(level),\n        leftItem: logLevel === level ? /* @__PURE__ */ jsx263(Checkmark, {}) : null,\n        id: level,\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: level\n      };\n    });\n  }, [logLevel, setLogLevel]);\n  const containerOptions = useMemo131(() => {\n    return [\n      {\n        label: \"MP4\",\n        onClick: () => setContainerFormat(\"mp4\"),\n        leftItem: container61 === \"mp4\" ? /* @__PURE__ */ jsx263(Checkmark, {}) : null,\n        id: \"mp4\",\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: \"mp4\"\n      },\n      {\n        label: \"WebM\",\n        onClick: () => setContainerFormat(\"webm\"),\n        leftItem: container61 === \"webm\" ? /* @__PURE__ */ jsx263(Checkmark, {}) : null,\n        id: \"webm\",\n        keyHint: null,\n        quickSwitcherLabel: null,\n        subMenu: null,\n        type: \"item\",\n        value: \"webm\"\n      }\n    ];\n  }, [container61, setContainerFormat]);\n  const codecLabels = useMemo131(() => ({\n    h264: \"H.264\",\n    h265: \"H.265\",\n    vp8: \"VP8\",\n    vp9: \"VP9\",\n    av1: \"AV1\"\n  }), []);\n  const codecOptions = useMemo131(() => {\n    return encodableVideoCodecs.map((c) => ({\n      label: codecLabels[c],\n      onClick: () => setCodec(c),\n      leftItem: effectiveVideoCodec === c ? /* @__PURE__ */ jsx263(Checkmark, {}) : null,\n      id: c,\n      keyHint: null,\n      quickSwitcherLabel: null,\n      subMenu: null,\n      type: \"item\",\n      value: c\n    }));\n  }, [encodableVideoCodecs, effectiveVideoCodec, setCodec, codecLabels]);\n  return /* @__PURE__ */ jsxs140(\"div\", {\n    style: tabContainer2,\n    children: [\n      renderMode === \"still\" ? /* @__PURE__ */ jsxs140(Fragment47, {\n        children: [\n          /* @__PURE__ */ jsxs140(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsx263(\"div\", {\n                style: label5,\n                children: \"Format\"\n              }),\n              /* @__PURE__ */ jsx263(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx263(SegmentedControl, {\n                  items: imageFormatOptions,\n                  needsWrapping: true\n                })\n              })\n            ]\n          }),\n          resolvedComposition.durationInFrames > 1 ? /* @__PURE__ */ jsxs140(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsx263(\"div\", {\n                style: label5,\n                children: \"Frame\"\n              }),\n              /* @__PURE__ */ jsx263(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx263(RightAlignInput, {\n                  children: /* @__PURE__ */ jsx263(InputDragger, {\n                    value: frame2,\n                    onTextChange: onFrameChanged,\n                    placeholder: `0-${resolvedComposition.durationInFrames - 1}`,\n                    onValueChange: onFrameSetDirectly,\n                    name: \"frame\",\n                    step: 1,\n                    min: 0,\n                    status: \"ok\",\n                    max: resolvedComposition.durationInFrames - 1,\n                    rightAlign: true\n                  })\n                })\n              })\n            ]\n          }) : null\n        ]\n      }) : /* @__PURE__ */ jsxs140(Fragment47, {\n        children: [\n          /* @__PURE__ */ jsxs140(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsx263(\"div\", {\n                style: label5,\n                children: \"Container\"\n              }),\n              /* @__PURE__ */ jsx263(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx263(Combobox, {\n                  values: containerOptions,\n                  selectedId: container61,\n                  title: \"Container\"\n                })\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsxs140(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsxs140(\"div\", {\n                style: label5,\n                children: [\n                  \"Codec\",\n                  /* @__PURE__ */ jsx263(Spacing, {\n                    x: 0.5\n                  }),\n                  /* @__PURE__ */ jsx263(OptionExplainerBubble, {\n                    id: \"videoCodecOption\"\n                  })\n                ]\n              }),\n              /* @__PURE__ */ jsx263(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx263(Combobox, {\n                  values: codecOptions,\n                  selectedId: effectiveVideoCodec,\n                  title: \"Codec\"\n                })\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx263(FrameRangeSetting, {\n            durationInFrames: resolvedComposition.durationInFrames,\n            startFrame: startFrame ?? 0,\n            endFrame: endFrame ?? resolvedComposition.durationInFrames - 1,\n            setStartFrame,\n            setEndFrame\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx263(RenderModalOutputName, {\n        existence: false,\n        inputStyle: input,\n        outName,\n        onValueChange: onOutNameChange,\n        validationMessage,\n        label: \"Download name\"\n      }),\n      /* @__PURE__ */ jsxs140(\"div\", {\n        style: optionRow,\n        children: [\n          /* @__PURE__ */ jsxs140(\"div\", {\n            style: label5,\n            children: [\n              \"Log Level \",\n              /* @__PURE__ */ jsx263(Spacing, {\n                x: 0.5\n              }),\n              /* @__PURE__ */ jsx263(OptionExplainerBubble, {\n                id: \"logLevelOption\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx263(\"div\", {\n            style: rightRow,\n            children: /* @__PURE__ */ jsx263(Combobox, {\n              values: logLevelOptions,\n              selectedId: logLevel,\n              title: \"Log Level\"\n            })\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/WebRenderModalLicense.tsx\nimport { useCallback as useCallback129, useEffect as useEffect83, useState as useState84 } from \"react\";\n\n// src/icons/check-circle-filled.tsx\nimport { jsx as jsx264 } from \"react/jsx-runtime\";\nvar CheckCircleFilled = (props) => /* @__PURE__ */ jsx264(\"svg\", {\n  xmlns: \"http://www.w3.org/2000/svg\",\n  style: { width: 14, height: 14 },\n  viewBox: \"0 0 512 512\",\n  ...props,\n  children: /* @__PURE__ */ jsx264(\"path\", {\n    d: \"M256 512a256 256 0 1 1 0-512 256 256 0 1 1 0 512zM374 145.7c-10.7-7.8-25.7-5.4-33.5 5.3L221.1 315.2 169 263.1c-9.4-9.4-24.6-9.4-33.9 0s-9.4 24.6 0 33.9l72 72c5 5 11.8 7.5 18.8 7s13.4-4.1 17.5-9.8L379.3 179.2c7.8-10.7 5.4-25.7-5.3-33.5z\"\n  })\n});\n\n// src/components/RenderModal/WebRenderModalLicenseKeyDetails.tsx\nimport { jsx as jsx265, jsxs as jsxs141 } from \"react/jsx-runtime\";\nvar textStyle2 = {\n  color: LIGHT_TEXT,\n  fontSize: 14,\n  fontFamily: \"sans-serif\",\n  lineHeight: 1.5,\n  display: \"flex\",\n  alignItems: \"center\"\n};\nvar linkStyle = {\n  fontSize: 14,\n  fontFamily: \"sans-serif\",\n  lineHeight: 1.5,\n  cursor: \"pointer\"\n};\nvar bulletStyle = {\n  display: \"flex\",\n  alignItems: \"center\",\n  gap: 6\n};\nvar icon8 = {\n  width: 14,\n  height: 14,\n  flexShrink: 0\n};\nvar PRO_HOST = \"https://remotion.pro\";\nvar fetchLicenseKeyDetails = async (licenseKey) => {\n  const response = await fetch(`${PRO_HOST}/api/validate-license-key`, {\n    method: \"POST\",\n    body: JSON.stringify({\n      licenseKey\n    }),\n    headers: {\n      \"Content-Type\": \"application/json\"\n    }\n  });\n  return response.json();\n};\nvar WebRenderModalLicenseKeyDetails = ({ details }) => {\n  return /* @__PURE__ */ jsxs141(\"div\", {\n    children: [\n      /* @__PURE__ */ jsxs141(\"div\", {\n        style: bulletStyle,\n        children: [\n          /* @__PURE__ */ jsx265(CheckCircleFilled, {\n            style: { ...icon8, fill: LIGHT_TEXT }\n          }),\n          /* @__PURE__ */ jsxs141(\"div\", {\n            style: textStyle2,\n            children: [\n              \"Belongs to\",\n              /* @__PURE__ */ jsx265(\"a\", {\n                href: `${PRO_HOST}/projects/${details.projectSlug}`,\n                target: \"_blank\",\n                style: linkStyle,\n                children: details.projectName\n              }),\n              \"-\",\n              /* @__PURE__ */ jsx265(\"a\", {\n                href: `${PRO_HOST}/projects/${details.projectSlug}/usage#client-renders-usage`,\n                target: \"_blank\",\n                style: linkStyle,\n                children: \"View usage\"\n              })\n            ]\n          })\n        ]\n      }),\n      details.hasActiveSubscription ? /* @__PURE__ */ jsxs141(\"div\", {\n        style: bulletStyle,\n        children: [\n          /* @__PURE__ */ jsx265(CheckCircleFilled, {\n            style: { ...icon8, fill: LIGHT_TEXT }\n          }),\n          /* @__PURE__ */ jsx265(\"div\", {\n            style: textStyle2,\n            children: \"Active Company License\"\n          })\n        ]\n      }) : /* @__PURE__ */ jsxs141(\"div\", {\n        style: bulletStyle,\n        children: [\n          /* @__PURE__ */ jsx265(WarningTriangle, {\n            type: \"warning\",\n            style: { ...icon8, fill: WARNING_COLOR }\n          }),\n          /* @__PURE__ */ jsx265(\"div\", {\n            style: textStyle2,\n            children: \"No active Company License\"\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/WebRenderModalLicense.tsx\nimport { jsx as jsx266, jsxs as jsxs142, Fragment as Fragment48 } from \"react/jsx-runtime\";\nvar row9 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  paddingLeft: 16,\n  paddingRight: 16\n};\nvar tabContainer3 = {\n  flex: 1\n};\nvar descriptionStyle = {\n  color: LIGHT_TEXT,\n  fontSize: 14,\n  fontFamily: \"sans-serif\",\n  paddingLeft: 16,\n  paddingRight: 16,\n  paddingTop: 16,\n  paddingBottom: 8,\n  lineHeight: 1.5\n};\nvar paddedDescriptionStyle = {\n  color: LIGHT_TEXT,\n  fontSize: 14,\n  fontFamily: \"sans-serif\",\n  padding: 9,\n  border: \"1px solid \" + INPUT_BORDER_COLOR_UNHOVERED,\n  borderRadius: 8,\n  lineHeight: 1.5,\n  marginLeft: 16,\n  marginRight: 16\n};\nvar descriptionLink = {\n  color: \"white\",\n  fontSize: 14\n};\nvar checkboxLabel = {\n  fontSize: 14,\n  lineHeight: \"40px\",\n  color: LIGHT_TEXT,\n  flex: 1,\n  fontFamily: \"sans-serif\",\n  cursor: \"pointer\",\n  userSelect: \"none\"\n};\nvar inputStyle2 = {\n  minWidth: 250\n};\nvar justifyCenter = {\n  display: \"flex\",\n  alignItems: \"center\",\n  gap: 10,\n  flex: 1\n};\nvar codeStyle = {\n  fontSize: 14,\n  fontFamily: \"monospace\",\n  color: BLUE\n};\nvar codeLine = {\n  fontSize: 14,\n  fontFamily: \"monospace\",\n  color: LIGHT_TEXT,\n  backgroundColor: INPUT_BACKGROUND,\n  padding: 6,\n  borderRadius: 3,\n  marginTop: 6,\n  overflowX: \"auto\",\n  maxWidth: \"100%\"\n};\nvar codeLineSmall = {\n  ...codeLine,\n  fontSize: 11\n};\nvar LICENSE_KEY_LENGTH = 55;\nvar LICENSE_KEY_PREFIX = \"rm_pub_\";\nvar validateLicenseKey = (key5) => {\n  if (key5.length === 0) {\n    return { valid: false, message: null, details: null };\n  }\n  if (!key5.startsWith(LICENSE_KEY_PREFIX)) {\n    return {\n      valid: false,\n      message: `License key must start with \"${LICENSE_KEY_PREFIX}\"`,\n      details: null\n    };\n  }\n  const afterPrefix = key5.slice(LICENSE_KEY_PREFIX.length);\n  if (!/^[a-zA-Z0-9]*$/.test(afterPrefix)) {\n    return {\n      valid: false,\n      message: \"License key must contain only alphanumeric characters after the prefix\",\n      details: null\n    };\n  }\n  if (key5.length !== LICENSE_KEY_LENGTH) {\n    return {\n      valid: false,\n      message: `License key must be ${LICENSE_KEY_LENGTH} characters long`,\n      details: null\n    };\n  }\n  return { valid: true, message: null, details: null };\n};\nvar WebRenderModalLicense = ({\n  licenseKey,\n  setLicenseKey,\n  initialPublicLicenseKey\n}) => {\n  const [licenseValidation, setLicenseValidation] = useState84({ valid: true, message: null, details: null });\n  const [isLoading, setIsLoading] = useState84(false);\n  useEffect83(() => {\n    if (licenseKey === null || licenseKey === \"free-license\") {\n      return setLicenseValidation({\n        valid: true,\n        message: null,\n        details: null\n      });\n    }\n    const validation = validateLicenseKey(licenseKey);\n    if (!validation.valid) {\n      return setLicenseValidation(validation);\n    }\n    setLicenseValidation({ valid: true, message: null, details: null });\n    setIsLoading(true);\n    fetchLicenseKeyDetails(licenseKey).then((details) => {\n      setIsLoading(false);\n      if (details.isValid) {\n        setLicenseValidation({ valid: true, message: null, details });\n      } else {\n        setLicenseValidation({\n          valid: false,\n          message: \"License key is invalid or has been reset\",\n          details: null\n        });\n      }\n    }).catch(() => {\n      setIsLoading(false);\n      setLicenseValidation({\n        valid: false,\n        message: \"Failed to fetch license key details\",\n        details: null\n      });\n    });\n  }, [licenseKey]);\n  const onFreeLicenseChange = useCallback129(() => {\n    setLicenseKey(\"free-license\");\n  }, [setLicenseKey]);\n  const onCompanyLicenseChange = useCallback129(() => {\n    setLicenseKey(initialPublicLicenseKey ?? \"\");\n  }, [initialPublicLicenseKey, setLicenseKey]);\n  const onLicenseKeyChange = useCallback129((e) => {\n    setLicenseKey(e.target.value);\n  }, [setLicenseKey]);\n  return /* @__PURE__ */ jsxs142(\"div\", {\n    style: tabContainer3,\n    children: [\n      /* @__PURE__ */ jsxs142(\"div\", {\n        style: descriptionStyle,\n        children: [\n          \"Remotion is free if you are an individual or company with a headcount of 3 or less. See\",\n          \" \",\n          /* @__PURE__ */ jsx266(\"a\", {\n            style: descriptionLink,\n            href: \"https://remotion.dev/license\",\n            children: \"LICENSE.md\"\n          }),\n          \".\"\n        ]\n      }),\n      /* @__PURE__ */ jsx266(\"div\", {\n        style: row9,\n        children: /* @__PURE__ */ jsxs142(\"div\", {\n          style: justifyCenter,\n          children: [\n            /* @__PURE__ */ jsx266(Checkbox, {\n              checked: licenseKey === \"free-license\",\n              onChange: onFreeLicenseChange,\n              name: \"free-license\",\n              rounded: true\n            }),\n            /* @__PURE__ */ jsxs142(\"div\", {\n              style: checkboxLabel,\n              onClick: onFreeLicenseChange,\n              children: [\n                \"I am eligible for the Free License, \",\n                \"don't\",\n                \" print a warning\"\n              ]\n            })\n          ]\n        })\n      }),\n      licenseKey === \"free-license\" ? /* @__PURE__ */ jsxs142(\"div\", {\n        style: paddedDescriptionStyle,\n        children: [\n          \"Enjoy Remotion! Add the following to\",\n          \" \",\n          /* @__PURE__ */ jsx266(\"code\", {\n            style: codeStyle,\n            children: \"remotion.config.ts\"\n          }),\n          \" to persist this setting:\",\n          /* @__PURE__ */ jsx266(\"div\", {\n            style: codeLine,\n            children: \"Config.setPublicLicenseKey('free-license');\"\n          })\n        ]\n      }) : null,\n      /* @__PURE__ */ jsx266(\"div\", {\n        style: row9,\n        children: /* @__PURE__ */ jsxs142(\"div\", {\n          style: justifyCenter,\n          children: [\n            /* @__PURE__ */ jsx266(Checkbox, {\n              checked: licenseKey !== \"free-license\" && licenseKey !== null,\n              onChange: onCompanyLicenseChange,\n              name: \"company-license\",\n              rounded: true\n            }),\n            /* @__PURE__ */ jsx266(\"div\", {\n              style: checkboxLabel,\n              onClick: onCompanyLicenseChange,\n              children: \"I have a Company License\"\n            })\n          ]\n        })\n      }),\n      licenseKey !== \"free-license\" && licenseKey !== null ? /* @__PURE__ */ jsxs142(\"div\", {\n        style: paddedDescriptionStyle,\n        children: [\n          \"Add your public license key from\",\n          \" \",\n          /* @__PURE__ */ jsx266(\"a\", {\n            href: \"https://remotion.pro/dashboard\",\n            target: \"_blank\",\n            style: descriptionLink,\n            children: \"remotion.pro\"\n          }),\n          \" \",\n          \"below.\",\n          /* @__PURE__ */ jsx266(Spacing, {\n            y: 1,\n            block: true\n          }),\n          /* @__PURE__ */ jsx266(RemotionInput, {\n            value: licenseKey,\n            onChange: onLicenseKeyChange,\n            placeholder: \"remotion.pro public license key (starts with rm_pub_)\",\n            status: licenseValidation.valid || licenseKey.length === 0 ? \"ok\" : \"error\",\n            rightAlign: false,\n            style: inputStyle2,\n            autoFocus: true\n          }),\n          licenseValidation.message ? /* @__PURE__ */ jsxs142(Fragment48, {\n            children: [\n              /* @__PURE__ */ jsx266(Spacing, {\n                y: 1,\n                block: true\n              }),\n              /* @__PURE__ */ jsx266(ValidationMessage, {\n                message: licenseValidation.message,\n                align: \"flex-start\",\n                type: \"error\"\n              })\n            ]\n          }) : null,\n          licenseValidation.valid && licenseKey.length > 0 ? /* @__PURE__ */ jsxs142(Fragment48, {\n            children: [\n              /* @__PURE__ */ jsx266(Spacing, {\n                y: 1,\n                block: true\n              }),\n              \"Add the following to\",\n              \" \",\n              /* @__PURE__ */ jsx266(\"code\", {\n                style: codeStyle,\n                children: \"remotion.config.ts\"\n              }),\n              \" to persist this setting:\",\n              /* @__PURE__ */ jsx266(\"div\", {\n                style: codeLineSmall,\n                children: \"Config.setPublicLicenseKey('\" + licenseKey + \"');\"\n              })\n            ]\n          }) : null,\n          isLoading && /* @__PURE__ */ jsxs142(Fragment48, {\n            children: [\n              /* @__PURE__ */ jsx266(Spacing, {\n                y: 1,\n                block: true\n              }),\n              \"Loading license key details...\"\n            ]\n          }),\n          licenseValidation.details && /* @__PURE__ */ jsxs142(Fragment48, {\n            children: [\n              /* @__PURE__ */ jsx266(Spacing, {\n                y: 1,\n                block: true\n              }),\n              /* @__PURE__ */ jsx266(WebRenderModalLicenseKeyDetails, {\n                details: licenseValidation.details\n              })\n            ]\n          })\n        ]\n      }) : null,\n      licenseKey === null ? /* @__PURE__ */ jsxs142(\"div\", {\n        style: descriptionStyle,\n        children: [\n          \"If you are not eligible for the free license, you need to obtain a\",\n          \" \",\n          /* @__PURE__ */ jsx266(\"a\", {\n            style: descriptionLink,\n            target: \"_blank\",\n            href: \"https://remotion.pro/license\",\n            children: \"Company License\"\n          }),\n          \".\"\n        ]\n      }) : null\n    ]\n  });\n};\n\n// src/components/RenderModal/WebRenderModalPicture.tsx\nimport { useCallback as useCallback130, useMemo as useMemo132 } from \"react\";\nimport { jsx as jsx267, jsxs as jsxs143, Fragment as Fragment49 } from \"react/jsx-runtime\";\nvar tabContainer4 = {\n  flex: 1\n};\nvar WebRenderModalPicture = ({\n  renderMode,\n  videoBitrate,\n  setVideoBitrate,\n  keyframeIntervalInSeconds,\n  setKeyframeIntervalInSeconds,\n  transparent,\n  setTransparent,\n  scale,\n  setScale,\n  compositionWidth,\n  compositionHeight\n}) => {\n  const qualityOptions = useMemo132(() => getQualityOptions(videoBitrate, setVideoBitrate), [videoBitrate, setVideoBitrate]);\n  const onTransparentChanged = useCallback130((e) => {\n    setTransparent(e.target.checked);\n  }, [setTransparent]);\n  return /* @__PURE__ */ jsxs143(\"div\", {\n    style: tabContainer4,\n    children: [\n      /* @__PURE__ */ jsx267(ScaleSetting, {\n        scale,\n        setScale,\n        compositionWidth,\n        compositionHeight\n      }),\n      renderMode !== \"video\" ? null : /* @__PURE__ */ jsxs143(Fragment49, {\n        children: [\n          /* @__PURE__ */ jsxs143(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsx267(\"div\", {\n                style: label5,\n                children: \"Quality\"\n              }),\n              /* @__PURE__ */ jsx267(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx267(Combobox, {\n                  values: qualityOptions,\n                  selectedId: videoBitrate,\n                  title: \"Quality\"\n                })\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx267(NumberSetting, {\n            name: \"Keyframe Interval\",\n            formatter: (v) => `${v}s`,\n            min: 1,\n            max: 300,\n            step: 1,\n            value: keyframeIntervalInSeconds,\n            onValueChanged: setKeyframeIntervalInSeconds\n          }),\n          /* @__PURE__ */ jsxs143(\"div\", {\n            style: optionRow,\n            children: [\n              /* @__PURE__ */ jsx267(\"div\", {\n                style: label5,\n                children: \"Transparent\"\n              }),\n              /* @__PURE__ */ jsx267(\"div\", {\n                style: rightRow,\n                children: /* @__PURE__ */ jsx267(Checkbox, {\n                  checked: transparent,\n                  onChange: onTransparentChanged,\n                  name: \"transparent\"\n                })\n              })\n            ]\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/RenderModal/WebRenderModal.tsx\nimport { jsx as jsx268, jsxs as jsxs144 } from \"react/jsx-runtime\";\nvar invalidCharacters2 = [\"?\", \"*\", \"+\", \":\", \"%\"];\nvar isValidStillExtension2 = (extension, stillImageFormat) => {\n  if (stillImageFormat === \"jpeg\" && extension === \"jpg\") {\n    return true;\n  }\n  return extension === stillImageFormat;\n};\nvar validateOutnameForStill = ({\n  outName,\n  stillImageFormat\n}) => {\n  try {\n    const extension = outName.substring(outName.lastIndexOf(\".\") + 1);\n    const prefix = outName.substring(0, outName.lastIndexOf(\".\"));\n    const hasDotAfterSlash = () => {\n      const substrings = prefix.split(\"/\");\n      for (const str of substrings) {\n        if (str[0] === \".\") {\n          return true;\n        }\n      }\n      return false;\n    };\n    const hasInvalidChar = () => {\n      return prefix.split(\"\").some((char) => invalidCharacters2.includes(char));\n    };\n    if (prefix.length < 1) {\n      throw new Error(\"The prefix must be at least 1 character long\");\n    }\n    if (prefix[0] === \".\" || hasDotAfterSlash()) {\n      throw new Error(\"The output name must not start with a dot\");\n    }\n    if (hasInvalidChar()) {\n      throw new Error(\"Filename can't contain the following characters:  ?, *, +, %, :\");\n    }\n    if (!isValidStillExtension2(extension, stillImageFormat)) {\n      throw new Error(`The extension ${extension} is not supported for still image format ${stillImageFormat}`);\n    }\n    return { valid: true };\n  } catch (err) {\n    return { valid: false, error: err };\n  }\n};\nvar WebRenderModal = ({\n  initialFrame,\n  defaultProps,\n  inFrameMark,\n  outFrameMark,\n  initialLogLevel,\n  initialLicenseKey\n}) => {\n  const context = useContext84(ResolvedCompositionContext);\n  const { setSelectedModal } = useContext84(ModalsContext);\n  const { setSidebarCollapsedState } = useContext84(SidebarContext);\n  const { addClientStillJob, addClientVideoJob } = useContext84(RenderQueueContext);\n  if (!context) {\n    throw new Error(\"Should not be able to render without resolving comp first\");\n  }\n  const {\n    resolved: { result: resolvedComposition },\n    unresolved: unresolvedComposition\n  } = context;\n  const [isVideo] = useState85(() => {\n    return typeof resolvedComposition.durationInFrames === \"undefined\" ? true : resolvedComposition.durationInFrames > 1;\n  });\n  const [renderMode, setRenderMode] = useState85(isVideo ? \"video\" : \"still\");\n  const [tab, setTab] = useState85(\"general\");\n  const [imageFormat, setImageFormat] = useState85(\"png\");\n  const [frame2, setFrame] = useState85(() => initialFrame);\n  const [logLevel, setLogLevel] = useState85(() => initialLogLevel);\n  const [inputProps, setInputProps] = useState85(() => defaultProps);\n  const [delayRenderTimeout, setDelayRenderTimeout] = useState85(30000);\n  const [mediaCacheSizeInBytes, setMediaCacheSizeInBytes] = useState85(null);\n  const [saving, setSaving] = useState85(false);\n  const [codec, setCodec] = useState85(\"h264\");\n  const [container61, setContainer] = useState85(\"mp4\");\n  const [audioCodec, setAudioCodec] = useState85(\"aac\");\n  const [audioBitrate, setAudioBitrate] = useState85(\"medium\");\n  const [videoBitrate, setVideoBitrate] = useState85(\"high\");\n  const [hardwareAcceleration, setHardwareAcceleration] = useState85(\"no-preference\");\n  const [keyframeIntervalInSeconds, setKeyframeIntervalInSeconds] = useState85(5);\n  const [startFrame, setStartFrame] = useState85(() => inFrameMark ?? null);\n  const [endFrame, setEndFrame] = useState85(() => outFrameMark ?? null);\n  const [transparent, setTransparent] = useState85(false);\n  const [muted, setMuted] = useState85(false);\n  const [scale, setScale] = useState85(1);\n  const [licenseKey, setLicenseKey] = useState85(initialLicenseKey);\n  const encodableAudioCodecs = useEncodableAudioCodecs(container61);\n  const encodableVideoCodecs = useEncodableVideoCodecs(container61);\n  const effectiveAudioCodec = useMemo133(() => {\n    if (encodableAudioCodecs.includes(audioCodec)) {\n      return audioCodec;\n    }\n    return encodableAudioCodecs[0] ?? audioCodec;\n  }, [audioCodec, encodableAudioCodecs]);\n  const effectiveVideoCodec = useMemo133(() => {\n    if (encodableVideoCodecs.includes(codec)) {\n      return codec;\n    }\n    return encodableVideoCodecs[0] ?? codec;\n  }, [codec, encodableVideoCodecs]);\n  const finalEndFrame = useMemo133(() => {\n    if (endFrame === null) {\n      return resolvedComposition.durationInFrames - 1;\n    }\n    return Math.max(0, Math.min(resolvedComposition.durationInFrames - 1, endFrame));\n  }, [endFrame, resolvedComposition.durationInFrames]);\n  const finalStartFrame = useMemo133(() => {\n    if (startFrame === null) {\n      return 0;\n    }\n    return Math.max(0, Math.min(finalEndFrame, startFrame));\n  }, [finalEndFrame, startFrame]);\n  const [initialOutName] = useState85(() => {\n    return getDefaultOutLocation2({\n      compositionName: resolvedComposition.id,\n      defaultExtension: renderMode === \"still\" ? imageFormat : isVideo ? container61 : imageFormat,\n      type: \"asset\",\n      compositionDefaultOutName: resolvedComposition.defaultOutName,\n      clientSideRender: true\n    });\n  });\n  const [outName, setOutName] = useState85(() => initialOutName);\n  const setStillFormat = useCallback131((format) => {\n    setImageFormat(format);\n    setOutName((prev) => {\n      const newFileName = getStringBeforeSuffix(prev) + \".\" + format;\n      return newFileName;\n    });\n  }, []);\n  const setContainerFormat = useCallback131((newContainer) => {\n    setContainer(newContainer);\n    setAudioCodec(getDefaultAudioCodecForContainer(newContainer));\n    setOutName((prev) => {\n      const newFileName = getStringBeforeSuffix(prev) + \".\" + newContainer;\n      return newFileName;\n    });\n  }, []);\n  const onRenderModeChange = useCallback131((newMode) => {\n    setRenderMode(newMode);\n    if (newMode === \"video\") {\n      setOutName((prev) => {\n        const newFileName = getStringBeforeSuffix(prev) + \".\" + container61;\n        return newFileName;\n      });\n    } else if (newMode === \"still\") {\n      setOutName((prev) => {\n        const newFileName = getStringBeforeSuffix(prev) + \".\" + imageFormat;\n        return newFileName;\n      });\n    }\n  }, [container61, imageFormat]);\n  const renderTabOptions = useMemo133(() => {\n    const options = [\n      {\n        label: \"Still\",\n        onClick: () => {\n          onRenderModeChange(\"still\");\n        },\n        key: \"still\",\n        selected: renderMode === \"still\"\n      }\n    ];\n    if (resolvedComposition.durationInFrames > 1) {\n      options.push({\n        label: \"Video\",\n        onClick: () => {\n          onRenderModeChange(\"video\");\n        },\n        key: \"video\",\n        selected: renderMode === \"video\"\n      });\n    }\n    return options;\n  }, [renderMode, resolvedComposition.durationInFrames, onRenderModeChange]);\n  const onFrameSetDirectly = useCallback131((newFrame) => {\n    setFrame(newFrame);\n  }, [setFrame]);\n  const onFrameChanged = useCallback131((e) => {\n    setFrame((q) => {\n      const newFrame = parseFloat(e);\n      if (Number.isNaN(newFrame)) {\n        return q;\n      }\n      return newFrame;\n    });\n  }, [setFrame]);\n  const onOutNameChange = useCallback131((e) => {\n    setOutName(e.target.value);\n  }, []);\n  const outnameValidation = useMemo133(() => {\n    if (renderMode === \"still\") {\n      return validateOutnameForStill({\n        outName,\n        stillImageFormat: imageFormat\n      });\n    }\n    try {\n      const extension = outName.substring(outName.lastIndexOf(\".\") + 1);\n      const prefix = outName.substring(0, outName.lastIndexOf(\".\"));\n      const hasDotAfterSlash = () => {\n        const substrings = prefix.split(\"/\");\n        for (const str of substrings) {\n          if (str[0] === \".\") {\n            return true;\n          }\n        }\n        return false;\n      };\n      const hasInvalidChar = () => {\n        return prefix.split(\"\").some((char) => invalidCharacters2.includes(char));\n      };\n      if (prefix.length < 1) {\n        throw new Error(\"The prefix must be at least 1 character long\");\n      }\n      if (prefix[0] === \".\" || hasDotAfterSlash()) {\n        throw new Error(\"The output name must not start with a dot\");\n      }\n      if (hasInvalidChar()) {\n        throw new Error(\"Filename can't contain the following characters:  ?, *, +, %, :\");\n      }\n      if (extension !== container61) {\n        throw new Error(`The extension ${extension} is not supported for container format ${container61}`);\n      }\n      return { valid: true };\n    } catch (err) {\n      return { valid: false, error: err };\n    }\n  }, [outName, imageFormat, renderMode, container61]);\n  const onAddToQueue = useCallback131(() => {\n    const compositionRef = {\n      component: unresolvedComposition.component,\n      calculateMetadata: unresolvedComposition.calculateMetadata ?? null,\n      width: resolvedComposition.width,\n      height: resolvedComposition.height,\n      fps: resolvedComposition.fps,\n      durationInFrames: resolvedComposition.durationInFrames,\n      defaultProps: resolvedComposition.defaultProps\n    };\n    if (renderMode === \"still\") {\n      addClientStillJob({\n        type: \"client-still\",\n        compositionId: resolvedComposition.id,\n        outName,\n        imageFormat,\n        frame: frame2,\n        inputProps,\n        delayRenderTimeout,\n        mediaCacheSizeInBytes,\n        logLevel,\n        licenseKey,\n        scale\n      }, compositionRef);\n    } else {\n      addClientVideoJob({\n        type: \"client-video\",\n        compositionId: resolvedComposition.id,\n        outName,\n        container: container61,\n        videoCodec: effectiveVideoCodec,\n        audioCodec: effectiveAudioCodec,\n        startFrame: finalStartFrame,\n        endFrame: finalEndFrame,\n        audioBitrate,\n        videoBitrate,\n        hardwareAcceleration,\n        keyframeIntervalInSeconds,\n        transparent,\n        muted,\n        inputProps,\n        delayRenderTimeout,\n        mediaCacheSizeInBytes,\n        logLevel,\n        licenseKey,\n        scale\n      }, compositionRef);\n    }\n    setSidebarCollapsedState({ left: null, right: \"expanded\" });\n    persistSelectedOptionsSidebarPanel2(\"renders\");\n    optionsSidebarTabs.current?.selectRendersPanel();\n    setSelectedModal(null);\n  }, [\n    renderMode,\n    unresolvedComposition.component,\n    unresolvedComposition.calculateMetadata,\n    resolvedComposition.width,\n    resolvedComposition.height,\n    resolvedComposition.fps,\n    resolvedComposition.durationInFrames,\n    resolvedComposition.defaultProps,\n    resolvedComposition.id,\n    setSidebarCollapsedState,\n    outName,\n    imageFormat,\n    frame2,\n    inputProps,\n    delayRenderTimeout,\n    mediaCacheSizeInBytes,\n    logLevel,\n    licenseKey,\n    container61,\n    effectiveVideoCodec,\n    effectiveAudioCodec,\n    finalStartFrame,\n    finalEndFrame,\n    audioBitrate,\n    videoBitrate,\n    hardwareAcceleration,\n    keyframeIntervalInSeconds,\n    transparent,\n    muted,\n    setSelectedModal,\n    addClientStillJob,\n    addClientVideoJob,\n    scale\n  ]);\n  return /* @__PURE__ */ jsxs144(\"div\", {\n    style: outerModalStyle,\n    children: [\n      /* @__PURE__ */ jsx268(ModalHeader, {\n        title: `Render ${resolvedComposition.id}`\n      }),\n      /* @__PURE__ */ jsxs144(\"div\", {\n        style: container59,\n        children: [\n          /* @__PURE__ */ jsx268(SegmentedControl, {\n            items: renderTabOptions,\n            needsWrapping: false\n          }),\n          /* @__PURE__ */ jsx268(\"div\", {\n            style: flexer\n          }),\n          /* @__PURE__ */ jsxs144(Button, {\n            autoFocus: true,\n            onClick: onAddToQueue,\n            style: buttonStyle7,\n            disabled: !outnameValidation.valid,\n            children: [\n              \"Render \",\n              renderMode,\n              /* @__PURE__ */ jsx268(ShortcutHint, {\n                keyToPress: \"\",\n                cmdOrCtrl: true\n              })\n            ]\n          })\n        ]\n      }),\n      /* @__PURE__ */ jsx268(\"div\", {\n        style: container59,\n        children: /* @__PURE__ */ jsx268(WebRendererExperimentalBadge, {})\n      }),\n      /* @__PURE__ */ jsxs144(\"div\", {\n        style: horizontalLayout,\n        children: [\n          /* @__PURE__ */ jsxs144(\"div\", {\n            style: leftSidebar,\n            children: [\n              /* @__PURE__ */ jsxs144(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"general\",\n                onClick: () => setTab(\"general\"),\n                children: [\n                  /* @__PURE__ */ jsx268(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx268(FileIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"General\"\n                ]\n              }),\n              /* @__PURE__ */ jsxs144(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"data\",\n                onClick: () => setTab(\"data\"),\n                children: [\n                  /* @__PURE__ */ jsx268(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx268(DataIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"Input Props\"\n                ]\n              }),\n              /* @__PURE__ */ jsxs144(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"picture\",\n                onClick: () => setTab(\"picture\"),\n                children: [\n                  /* @__PURE__ */ jsx268(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx268(PicIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"Picture\"\n                ]\n              }),\n              renderMode === \"video\" ? /* @__PURE__ */ jsxs144(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"audio\",\n                onClick: () => setTab(\"audio\"),\n                children: [\n                  /* @__PURE__ */ jsx268(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx268(AudioIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"Audio\"\n                ]\n              }) : null,\n              /* @__PURE__ */ jsxs144(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"advanced\",\n                onClick: () => setTab(\"advanced\"),\n                children: [\n                  /* @__PURE__ */ jsx268(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx268(GearIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"Other\"\n                ]\n              }),\n              /* @__PURE__ */ jsxs144(VerticalTab, {\n                style: horizontalTab,\n                selected: tab === \"license\",\n                onClick: () => setTab(\"license\"),\n                children: [\n                  /* @__PURE__ */ jsx268(\"div\", {\n                    style: iconContainer,\n                    children: /* @__PURE__ */ jsx268(CertificateIcon, {\n                      style: icon6\n                    })\n                  }),\n                  \"License\"\n                ]\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsx268(\"div\", {\n            style: optionsPanel,\n            className: VERTICAL_SCROLLBAR_CLASSNAME,\n            children: tab === \"general\" ? /* @__PURE__ */ jsx268(WebRenderModalBasic, {\n              renderMode,\n              resolvedComposition,\n              imageFormat,\n              setStillFormat,\n              frame: frame2,\n              onFrameChanged,\n              onFrameSetDirectly,\n              container: container61,\n              setContainerFormat,\n              setCodec,\n              encodableVideoCodecs,\n              effectiveVideoCodec,\n              startFrame: finalStartFrame,\n              setStartFrame,\n              endFrame: finalEndFrame,\n              setEndFrame,\n              outName,\n              onOutNameChange,\n              validationMessage: outnameValidation.valid ? null : outnameValidation.error.message,\n              logLevel,\n              setLogLevel\n            }) : tab === \"data\" ? /* @__PURE__ */ jsx268(DataEditor, {\n              defaultProps: inputProps,\n              setDefaultProps: setInputProps,\n              unresolvedComposition,\n              mayShowSaveButton: false,\n              propsEditType: \"input-props\",\n              saving,\n              setSaving,\n              readOnlyStudio: false\n            }) : tab === \"picture\" ? /* @__PURE__ */ jsx268(WebRenderModalPicture, {\n              renderMode,\n              videoBitrate,\n              setVideoBitrate,\n              keyframeIntervalInSeconds,\n              setKeyframeIntervalInSeconds,\n              transparent,\n              setTransparent,\n              scale,\n              setScale,\n              compositionWidth: resolvedComposition.width,\n              compositionHeight: resolvedComposition.height\n            }) : tab === \"audio\" ? /* @__PURE__ */ jsx268(WebRenderModalAudio, {\n              muted,\n              setMuted,\n              audioCodec,\n              setAudioCodec,\n              audioBitrate,\n              setAudioBitrate,\n              container: container61,\n              encodableCodecs: encodableAudioCodecs,\n              effectiveAudioCodec\n            }) : tab === \"advanced\" ? /* @__PURE__ */ jsx268(WebRenderModalAdvanced, {\n              renderMode,\n              delayRenderTimeout,\n              setDelayRenderTimeout,\n              mediaCacheSizeInBytes,\n              setMediaCacheSizeInBytes,\n              hardwareAcceleration,\n              setHardwareAcceleration\n            }) : /* @__PURE__ */ jsx268(WebRenderModalLicense, {\n              licenseKey,\n              setLicenseKey,\n              initialPublicLicenseKey: initialLicenseKey\n            })\n          })\n        ]\n      })\n    ]\n  });\n};\nvar WebRenderModalWithLoader = (props) => {\n  return /* @__PURE__ */ jsx268(DismissableModal, {\n    children: /* @__PURE__ */ jsx268(ResolveCompositionBeforeModal, {\n      compositionId: props.compositionId,\n      children: /* @__PURE__ */ jsx268(WebRenderModal, {\n        ...props\n      })\n    })\n  });\n};\n\n// src/components/UpdateModal/UpdateModal.tsx\nimport { useCallback as useCallback134, useMemo as useMemo135 } from \"react\";\n\n// src/components/CopyButton.tsx\nimport { useCallback as useCallback132, useEffect as useEffect84, useState as useState86 } from \"react\";\nimport { jsx as jsx269, jsxs as jsxs145 } from \"react/jsx-runtime\";\nvar iconStyle8 = {\n  width: 16,\n  height: 16,\n  color: \"white\"\n};\nvar buttonContainerStyle = {\n  display: \"flex\",\n  minWidth: \"114px\"\n};\nvar copyIcon = /* @__PURE__ */ jsx269(\"svg\", {\n  \"aria-hidden\": \"true\",\n  focusable: \"false\",\n  \"data-prefix\": \"far\",\n  \"data-icon\": \"clipboard\",\n  className: \"svg-inline--fa fa-clipboard fa-w-12\",\n  role: \"img\",\n  xmlns: \"http://www.w3.org/2000/svg\",\n  viewBox: \"0 0 384 512\",\n  style: iconStyle8,\n  children: /* @__PURE__ */ jsx269(\"path\", {\n    fill: \"currentColor\",\n    d: \"M336 64h-80c0-35.3-28.7-64-64-64s-64 28.7-64 64H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 40c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm144 418c0 3.3-2.7 6-6 6H54c-3.3 0-6-2.7-6-6V118c0-3.3 2.7-6 6-6h42v36c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12v-36h42c3.3 0 6 2.7 6 6z\"\n  })\n});\nvar labelStyle5 = {\n  fontSize: 14\n};\nvar CopyButton = ({ textToCopy, label: label12, labelWhenCopied }) => {\n  const [copied, setCopied] = useState86(false);\n  const onClick = useCallback132(() => {\n    copyText(textToCopy).then(() => {\n      setCopied(Date.now());\n    }).catch((err) => {\n      showNotification(`Could not copy: ${err.message}`, 2000);\n    });\n  }, [textToCopy]);\n  useEffect84(() => {\n    if (!copied) {\n      return;\n    }\n    const to = setTimeout(() => setCopied(false), 2000);\n    return () => clearTimeout(to);\n  }, [copied]);\n  return /* @__PURE__ */ jsxs145(Button, {\n    onClick,\n    buttonContainerStyle,\n    children: [\n      copyIcon,\n      /* @__PURE__ */ jsx269(Spacing, {\n        x: 1.5\n      }),\n      \" \",\n      /* @__PURE__ */ jsx269(\"span\", {\n        style: labelStyle5,\n        children: copied ? labelWhenCopied : label12\n      })\n    ]\n  });\n};\n\n// src/components/UpdateModal/OpenIssueButton.tsx\nimport { useCallback as useCallback133, useMemo as useMemo134, useState as useState87 } from \"react\";\nimport { jsx as jsx270 } from \"react/jsx-runtime\";\nvar svgStyle3 = {\n  width: \"11px\",\n  height: \"11px\"\n};\nvar buttonStyle8 = {\n  border: \"none\",\n  width: \"24px\",\n  height: \"24px\",\n  display: \"flex\",\n  justifyContent: \"center\",\n  alignItems: \"center\"\n};\nvar OpenIssueButton = ({ link: link4 }) => {\n  const [hovered, setHovered] = useState87(false);\n  const buttonTooltip = `Open GitHub issue in new Tab`;\n  const handleClick = useCallback133(() => {\n    window.open(link4, \"_blank\");\n  }, [link4]);\n  const svgFillColor = useMemo134(() => {\n    return hovered ? \"white\" : LIGHT_TEXT;\n  }, [hovered]);\n  const openInEditorSvg = /* @__PURE__ */ jsx270(\"svg\", {\n    viewBox: \"0 0 512 512\",\n    style: svgStyle3,\n    children: /* @__PURE__ */ jsx270(\"path\", {\n      fill: svgFillColor,\n      d: \"M320 0c-17.7 0-32 14.3-32 32s14.3 32 32 32h82.7L201.4 265.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L448 109.3V192c0 17.7 14.3 32 32 32s32-14.3 32-32V32c0-17.7-14.3-32-32-32H320zM80 32C35.8 32 0 67.8 0 112V432c0 44.2 35.8 80 80 80H400c44.2 0 80-35.8 80-80V320c0-17.7-14.3-32-32-32s-32 14.3-32 32V432c0 8.8-7.2 16-16 16H80c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16H192c17.7 0 32-14.3 32-32s-14.3-32-32-32H80z\"\n    })\n  });\n  const onPointerEnter = useCallback133(() => {\n    setHovered(true);\n  }, []);\n  const onPointerLeave = useCallback133(() => {\n    setHovered(false);\n  }, []);\n  return /* @__PURE__ */ jsx270(\"button\", {\n    title: buttonTooltip,\n    type: \"button\",\n    onPointerEnter,\n    onPointerLeave,\n    style: buttonStyle8,\n    onClick: handleClick,\n    children: openInEditorSvg\n  });\n};\n\n// src/components/KnownBugs.tsx\nimport { jsx as jsx271, jsxs as jsxs146 } from \"react/jsx-runtime\";\nvar container61 = {\n  display: \"flex\",\n  flexDirection: \"row\",\n  alignItems: \"center\"\n};\nvar text4 = {\n  fontSize: 14,\n  flex: 1\n};\nvar KnownBugs = ({ bugs }) => {\n  const bugElements = bugs.map((bug) => {\n    return /* @__PURE__ */ jsxs146(\"div\", {\n      style: container61,\n      children: [\n        /* @__PURE__ */ jsxs146(\"div\", {\n          style: text4,\n          children: [\n            \"\\uD83E\\uDEB2 \",\n            bug.title\n          ]\n        }),\n        /* @__PURE__ */ jsx271(OpenIssueButton, {\n          link: bug.link\n        })\n      ]\n    }, bug.description + bug.link);\n  });\n  return /* @__PURE__ */ jsx271(\"div\", {\n    children: bugElements\n  });\n};\n\n// src/components/UpdateModal/UpdateModal.tsx\nimport { jsx as jsx272, jsxs as jsxs147, Fragment as Fragment50 } from \"react/jsx-runtime\";\nvar container62 = {\n  padding: 20,\n  paddingTop: 0\n};\nvar text5 = {\n  fontSize: 14\n};\nvar title7 = {\n  paddingTop: 12,\n  paddingBottom: 8,\n  ...text5\n};\nvar code = {\n  background: SELECTED_BACKGROUND,\n  padding: \"12px 10px\",\n  fontSize: 14,\n  marginTop: 10,\n  marginBottom: 10\n};\nvar link4 = {\n  fontWeight: \"bold\",\n  color: BLUE,\n  textDecoration: \"none\",\n  ...text5\n};\nvar commands = {\n  npm: \"npx remotion upgrade\",\n  yarn: \"yarn remotion upgrade\",\n  pnpm: \"pnpm exec remotion upgrade\",\n  bun: \"bun remotion upgrade\",\n  unknown: \"npx remotion upgrade\"\n};\nvar UpdateModal = ({ info, knownBugs }) => {\n  const hasKnownBugs = useMemo135(() => {\n    return knownBugs && knownBugs?.length > 0;\n  }, [knownBugs]);\n  const command = commands[info.packageManager];\n  const onClick = useCallback134(() => {\n    copyText(command).catch((err) => {\n      showNotification(`Could not copy: ${err.message}`, 2000);\n    });\n  }, [command]);\n  return /* @__PURE__ */ jsxs147(DismissableModal, {\n    children: [\n      /* @__PURE__ */ jsx272(ModalHeader, {\n        title: \"Update available\"\n      }),\n      /* @__PURE__ */ jsxs147(\"div\", {\n        style: container62,\n        children: [\n          hasKnownBugs ? /* @__PURE__ */ jsxs147(Fragment50, {\n            children: [\n              /* @__PURE__ */ jsxs147(\"div\", {\n                style: title7,\n                children: [\n                  \"The currently installed version \",\n                  info.currentVersion,\n                  \" has the following known bugs:\"\n                ]\n              }),\n              /* @__PURE__ */ jsx272(KnownBugs, {\n                bugs: knownBugs\n              }),\n              /* @__PURE__ */ jsx272(\"div\", {\n                style: { height: \"20px\" }\n              }),\n              /* @__PURE__ */ jsx272(\"div\", {\n                style: text5,\n                children: \"To upgrade, run the following command:\"\n              })\n            ]\n          }) : /* @__PURE__ */ jsx272(\"div\", {\n            style: title7,\n            children: \"A new update for Remotion is available! Run the following command:\"\n          }),\n          /* @__PURE__ */ jsxs147(Row, {\n            align: \"center\",\n            children: [\n              /* @__PURE__ */ jsx272(Flex, {\n                children: /* @__PURE__ */ jsx272(\"pre\", {\n                  onClick,\n                  style: code,\n                  children: command\n                })\n              }),\n              /* @__PURE__ */ jsx272(Spacing, {\n                x: 1\n              }),\n              /* @__PURE__ */ jsx272(CopyButton, {\n                textToCopy: command,\n                label: \"Copy\",\n                labelWhenCopied: \"Copied!\"\n              })\n            ]\n          }),\n          /* @__PURE__ */ jsxs147(\"div\", {\n            style: text5,\n            children: [\n              \"This will upgrade Remotion from \",\n              info.currentVersion,\n              \" to\",\n              \" \",\n              info.latestVersion,\n              \".\"\n            ]\n          }),\n          /* @__PURE__ */ jsxs147(\"div\", {\n            style: text5,\n            children: [\n              \"Read the\",\n              \" \",\n              /* @__PURE__ */ jsx272(\"a\", {\n                style: link4,\n                target: \"_blank\",\n                href: \"https://github.com/remotion-dev/remotion/releases\",\n                children: \"Release notes\"\n              }),\n              \" \",\n              \"to know what\",\n              \"'s\",\n              \" new in Remotion.\"\n            ]\n          })\n        ]\n      })\n    ]\n  });\n};\n\n// src/components/Modals.tsx\nimport { jsx as jsx273, jsxs as jsxs148, Fragment as Fragment51 } from \"react/jsx-runtime\";\nvar Modals = ({ readOnlyStudio }) => {\n  const { selectedModal: modalContextType } = useContext85(ModalsContext);\n  const canRender = useContext85(StudioServerConnectionCtx).previewServerState.type === \"connected\";\n  return /* @__PURE__ */ jsxs148(Fragment51, {\n    children: [\n      modalContextType && modalContextType.type === \"duplicate-comp\" && /* @__PURE__ */ jsx273(DuplicateComposition, {\n        compositionType: modalContextType.compositionType,\n        compositionId: modalContextType.compositionId\n      }),\n      modalContextType && modalContextType.type === \"delete-comp\" && /* @__PURE__ */ jsx273(DeleteComposition, {\n        compositionId: modalContextType.compositionId\n      }),\n      modalContextType && modalContextType.type === \"rename-comp\" && /* @__PURE__ */ jsx273(RenameComposition, {\n        compositionId: modalContextType.compositionId\n      }),\n      modalContextType && modalContextType.type === \"input-props-override\" && /* @__PURE__ */ jsx273(OverrideInputPropsModal, {}),\n      modalContextType && modalContextType.type === \"web-render\" && /* @__PURE__ */ jsx273(WebRenderModalWithLoader, {\n        type: \"web-render\",\n        initialFrame: modalContextType.initialFrame,\n        compositionId: modalContextType.compositionId,\n        defaultProps: modalContextType.defaultProps,\n        inFrameMark: modalContextType.inFrameMark,\n        outFrameMark: modalContextType.outFrameMark,\n        initialLogLevel: modalContextType.initialLogLevel,\n        initialLicenseKey: modalContextType.initialLicenseKey\n      }),\n      modalContextType && canRender && modalContextType.type === \"server-render\" && /* @__PURE__ */ jsx273(RenderModalWithLoader, {\n        initialFrame: modalContextType.initialFrame,\n        initialDarkMode: modalContextType.initialDarkMode,\n        compositionId: modalContextType.compositionId,\n        initialVideoImageFormat: modalContextType.initialVideoImageFormat,\n        initialJpegQuality: modalContextType.initialJpegQuality,\n        initialScale: modalContextType.initialScale,\n        initialLogLevel: modalContextType.initialLogLevel,\n        initialOffthreadVideoCacheSizeInBytes: modalContextType.initialOffthreadVideoCacheSizeInBytes,\n        initialOffthreadVideoThreads: modalContextType.initialOffthreadVideoThreads,\n        initialMediaCacheSizeInBytes: modalContextType.initialMediaCacheSizeInBytes,\n        initialConcurrency: modalContextType.initialConcurrency,\n        maxConcurrency: modalContextType.maxConcurrency,\n        minConcurrency: modalContextType.minConcurrency,\n        initialStillImageFormat: modalContextType.initialStillImageFormat,\n        initialMuted: modalContextType.initialMuted,\n        initialEnforceAudioTrack: modalContextType.initialEnforceAudioTrack,\n        initialProResProfile: modalContextType.initialProResProfile,\n        initialx264Preset: modalContextType.initialx264Preset,\n        initialPixelFormat: modalContextType.initialPixelFormat,\n        initialAudioBitrate: modalContextType.initialAudioBitrate,\n        initialVideoBitrate: modalContextType.initialVideoBitrate,\n        initialEveryNthFrame: modalContextType.initialEveryNthFrame,\n        initialNumberOfGifLoops: modalContextType.initialNumberOfGifLoops,\n        initialDelayRenderTimeout: modalContextType.initialDelayRenderTimeout,\n        initialEnvVariables: modalContextType.initialEnvVariables,\n        initialDisableWebSecurity: modalContextType.initialDisableWebSecurity,\n        initialGl: modalContextType.initialOpenGlRenderer,\n        initialHeadless: modalContextType.initialHeadless,\n        initialIgnoreCertificateErrors: modalContextType.initialIgnoreCertificateErrors,\n        initialEncodingBufferSize: modalContextType.initialEncodingBufferSize,\n        initialEncodingMaxRate: modalContextType.initialEncodingMaxRate,\n        initialUserAgent: modalContextType.initialUserAgent,\n        initialColorSpace: modalContextType.initialColorSpace,\n        initialMultiProcessOnLinux: modalContextType.initialMultiProcessOnLinux,\n        initialRepro: modalContextType.initialRepro,\n        initialBeep: modalContextType.initialBeep,\n        initialForSeamlessAacConcatenation: modalContextType.initialForSeamlessAacConcatenation,\n        defaultProps: modalContextType.defaultProps,\n        inFrameMark: modalContextType.inFrameMark,\n        outFrameMark: modalContextType.outFrameMark,\n        defaultConfigurationAudioCodec: modalContextType.defaultConfigurationAudioCodec,\n        defaultConfigurationVideoCodec: modalContextType.defaultConfigurationVideoCodec,\n        renderTypeOfLastRender: modalContextType.renderTypeOfLastRender,\n        defaultMetadata: modalContextType.defaulMetadata,\n        initialHardwareAcceleration: modalContextType.initialHardwareAcceleration,\n        initialChromeMode: modalContextType.initialChromeMode,\n        renderDefaults: modalContextType.renderDefaults\n      }),\n      modalContextType && modalContextType.type === \"render-progress\" && /* @__PURE__ */ jsx273(RenderStatusModal, {\n        jobId: modalContextType.jobId\n      }),\n      modalContextType && modalContextType.type === \"update\" && /* @__PURE__ */ jsx273(UpdateModal, {\n        info: modalContextType.info,\n        knownBugs: modalContextType.knownBugs\n      }),\n      modalContextType && modalContextType.type === \"install-packages\" && /* @__PURE__ */ jsx273(InstallPackageModal, {\n        packageManager: modalContextType.packageManager\n      }),\n      modalContextType && modalContextType.type === \"quick-switcher\" && /* @__PURE__ */ jsx273(QuickSwitcher_default, {\n        readOnlyStudio,\n        invocationTimestamp: modalContextType.invocationTimestamp,\n        initialMode: modalContextType.mode\n      }),\n      process.env.ASK_AI_ENABLED && /* @__PURE__ */ jsx273(AskAiModal, {})\n    ]\n  });\n};\n\n// src/components/Editor.tsx\nimport { jsx as jsx274, jsxs as jsxs149 } from \"react/jsx-runtime\";\nvar background2 = {\n  backgroundColor: BACKGROUND,\n  display: \"flex\",\n  width: \"100%\",\n  height: \"100%\",\n  flexDirection: \"column\",\n  position: \"absolute\"\n};\nvar DEFAULT_BUFFER_STATE_DELAY_IN_MILLISECONDS = 300;\nvar BUFFER_STATE_DELAY_IN_MILLISECONDS = typeof process.env.BUFFER_STATE_DELAY_IN_MILLISECONDS === \"undefined\" || process.env.BUFFER_STATE_DELAY_IN_MILLISECONDS === null ? DEFAULT_BUFFER_STATE_DELAY_IN_MILLISECONDS : Number(process.env.BUFFER_STATE_DELAY_IN_MILLISECONDS);\nvar Editor = ({ Root, readOnlyStudio }) => {\n  const size4 = PlayerInternals19.useElementSize(drawRef, {\n    triggerOnWindowResize: false,\n    shouldApplyCssTransforms: true\n  });\n  useEffect85(() => {\n    if (readOnlyStudio) {\n      return;\n    }\n    const listenToChanges = (e) => {\n      if (window.remotion_unsavedProps) {\n        e.returnValue = \"Are you sure you want to leave?\";\n      }\n    };\n    window.addEventListener(\"beforeunload\", listenToChanges);\n    return () => {\n      window.removeEventListener(\"beforeunload\", listenToChanges);\n    };\n  }, [readOnlyStudio]);\n  const [canvasMounted, setCanvasMounted] = React177.useState(false);\n  const onMounted = useCallback135(() => {\n    setCanvasMounted(true);\n  }, []);\n  const value = useMemo136(() => {\n    if (!size4) {\n      return null;\n    }\n    return {\n      type: \"canvas-size\",\n      canvasSize: size4\n    };\n  }, [size4]);\n  const MemoRoot = useMemo136(() => {\n    return React177.memo(Root);\n  }, [Root]);\n  return /* @__PURE__ */ jsx274(HigherZIndex, {\n    onEscape: noop,\n    onOutsideClick: noop,\n    children: /* @__PURE__ */ jsxs149(TimelineZoomContext, {\n      children: [\n        /* @__PURE__ */ jsx274(Internals62.CurrentScaleContext.Provider, {\n          value,\n          children: /* @__PURE__ */ jsxs149(\"div\", {\n            style: background2,\n            children: [\n              canvasMounted ? /* @__PURE__ */ jsx274(MemoRoot, {}) : null,\n              /* @__PURE__ */ jsxs149(Internals62.CanUseRemotionHooksProvider, {\n                children: [\n                  /* @__PURE__ */ jsx274(EditorContent, {\n                    readOnlyStudio,\n                    children: /* @__PURE__ */ jsx274(TopPanel, {\n                      drawRef,\n                      bufferStateDelayInMilliseconds: BUFFER_STATE_DELAY_IN_MILLISECONDS,\n                      onMounted,\n                      readOnlyStudio\n                    })\n                  }),\n                  /* @__PURE__ */ jsx274(GlobalKeybindings, {})\n                ]\n              })\n            ]\n          })\n        }),\n        /* @__PURE__ */ jsx274(Modals, {\n          readOnlyStudio\n        }),\n        /* @__PURE__ */ jsx274(NotificationCenter, {})\n      ]\n    })\n  });\n};\n\n// src/components/EditorContexts.tsx\nimport { PlayerInternals as PlayerInternals20 } from \"@remotion/player\";\n\n// src/state/preview-size.tsx\nimport { useCallback as useCallback136, useContext as useContext86, useMemo as useMemo137, useState as useState88 } from \"react\";\nimport { Internals as Internals63 } from \"remotion\";\nimport { jsx as jsx275 } from \"react/jsx-runtime\";\nvar key5 = \"remotion.previewSize\";\nvar persistPreviewSizeOption = (option) => {\n  localStorage.setItem(key5, JSON.stringify(option));\n};\nvar loadPreviewSizeOption = () => {\n  const item2 = localStorage.getItem(key5);\n  if (item2 === null) {\n    return {\n      size: \"auto\",\n      translation: {\n        x: 0,\n        y: 0\n      }\n    };\n  }\n  return JSON.parse(item2);\n};\nvar PreviewSizeProvider = ({ children }) => {\n  const [size4, setSizeState] = useState88(() => loadPreviewSizeOption());\n  const [translation, setTranslation] = useState88(() => {\n    return {\n      x: 0,\n      y: 0\n    };\n  });\n  const { editorZoomGestures } = useContext86(EditorZoomGesturesContext);\n  const setSize = useCallback136((newValue) => {\n    setSizeState((prevState) => {\n      const newVal = newValue(prevState);\n      persistPreviewSizeOption(newVal);\n      return newVal;\n    });\n  }, []);\n  const previewSizeCtx = useMemo137(() => {\n    return {\n      size: editorZoomGestures ? size4 : {\n        size: size4.size,\n        translation: {\n          x: 0,\n          y: 0\n        }\n      },\n      setSize,\n      translation,\n      setTranslation\n    };\n  }, [editorZoomGestures, size4, setSize, translation]);\n  return /* @__PURE__ */ jsx275(Internals63.PreviewSizeContext.Provider, {\n    value: previewSizeCtx,\n    children\n  });\n};\n\n// src/components/CheckerboardProvider.tsx\nimport { useCallback as useCallback137, useMemo as useMemo138, useState as useState89 } from \"react\";\nimport { jsx as jsx276 } from \"react/jsx-runtime\";\nvar CheckerboardProvider = ({ children }) => {\n  const [checkerboard, setCheckerboardState] = useState89(() => loadCheckerboardOption());\n  const setCheckerboard = useCallback137((newValue) => {\n    setCheckerboardState((prevState) => {\n      const newVal = newValue(prevState);\n      persistCheckerboardOption(newVal);\n      return newVal;\n    });\n  }, []);\n  const checkerboardCtx = useMemo138(() => {\n    return {\n      checkerboard,\n      setCheckerboard\n    };\n  }, [checkerboard, setCheckerboard]);\n  return /* @__PURE__ */ jsx276(CheckerboardContext.Provider, {\n    value: checkerboardCtx,\n    children\n  });\n};\n\n// src/components/MediaVolumeProvider.tsx\nimport { useMemo as useMemo139, useState as useState90 } from \"react\";\nimport { Internals as Internals64 } from \"remotion\";\nimport { jsx as jsx277 } from \"react/jsx-runtime\";\nvar MediaVolumeProvider = ({ children }) => {\n  const [mediaMuted, setMediaMuted] = useState90(() => loadMuteOption());\n  const [mediaVolume, setMediaVolume] = useState90(1);\n  const mediaVolumeContextValue = useMemo139(() => {\n    return {\n      mediaMuted,\n      mediaVolume\n    };\n  }, [mediaMuted, mediaVolume]);\n  const setMediaVolumeContextValue = useMemo139(() => {\n    return {\n      setMediaMuted,\n      setMediaVolume\n    };\n  }, []);\n  return /* @__PURE__ */ jsx277(Internals64.MediaVolumeContext.Provider, {\n    value: mediaVolumeContextValue,\n    children: /* @__PURE__ */ jsx277(Internals64.SetMediaVolumeContext.Provider, {\n      value: setMediaVolumeContextValue,\n      children\n    })\n  });\n};\n\n// src/components/ModalsProvider.tsx\nimport { useMemo as useMemo140, useState as useState91 } from \"react\";\nimport { jsx as jsx278 } from \"react/jsx-runtime\";\nvar ModalsProvider = ({ children }) => {\n  const [modalContextType, setModalContextType] = useState91(null);\n  const modalsContext = useMemo140(() => {\n    return {\n      selectedModal: modalContextType,\n      setSelectedModal: setModalContextType\n    };\n  }, [modalContextType]);\n  return /* @__PURE__ */ jsx278(ModalsContext.Provider, {\n    value: modalsContext,\n    children\n  });\n};\n\n// src/components/RenderQueue/ClientRenderQueueProcessor.tsx\nimport { renderMediaOnWeb, renderStillOnWeb } from \"@remotion/web-renderer\";\nimport { useCallback as useCallback138, useContext as useContext87, useEffect as useEffect86 } from \"react\";\nvar downloadBlob = (blob, filename) => {\n  const url = URL.createObjectURL(blob);\n  const a = document.createElement(\"a\");\n  a.href = url;\n  const cleanFilename = filename.includes(\"/\") ? filename.substring(filename.lastIndexOf(\"/\") + 1) : filename;\n  a.download = cleanFilename;\n  a.click();\n  URL.revokeObjectURL(url);\n};\nvar ClientRenderQueueProcessor = () => {\n  const {\n    getAbortController: getAbortController2,\n    getCompositionForJob: getCompositionForJob2,\n    updateClientJobProgress,\n    markClientJobDone,\n    markClientJobFailed,\n    markClientJobCancelled,\n    setProcessJobCallback\n  } = useContext87(RenderQueueContext);\n  const processStillJob = useCallback138(async (job, signal) => {\n    const compositionRef = getCompositionForJob2(job.id);\n    if (!compositionRef) {\n      throw new Error(`Composition not found for job ${job.id}`);\n    }\n    const { blob } = await renderStillOnWeb({\n      composition: {\n        component: compositionRef.component,\n        width: compositionRef.width,\n        height: compositionRef.height,\n        fps: compositionRef.fps,\n        durationInFrames: compositionRef.durationInFrames,\n        defaultProps: compositionRef.defaultProps,\n        calculateMetadata: compositionRef.calculateMetadata ?? undefined,\n        id: job.compositionId\n      },\n      frame: job.frame,\n      imageFormat: job.imageFormat,\n      inputProps: job.inputProps,\n      delayRenderTimeoutInMilliseconds: job.delayRenderTimeout,\n      mediaCacheSizeInBytes: job.mediaCacheSizeInBytes,\n      logLevel: job.logLevel,\n      licenseKey: job.licenseKey ?? undefined,\n      scale: job.scale,\n      signal\n    });\n    return {\n      getBlob: () => Promise.resolve(blob),\n      width: compositionRef.width,\n      height: compositionRef.height\n    };\n  }, [getCompositionForJob2]);\n  const processVideoJob = useCallback138(async (job, signal, onProgress) => {\n    const compositionRef = getCompositionForJob2(job.id);\n    if (!compositionRef) {\n      throw new Error(`Composition not found for job ${job.id}`);\n    }\n    const totalFrames = job.endFrame - job.startFrame + 1;\n    const { getBlob } = await renderMediaOnWeb({\n      composition: {\n        component: compositionRef.component,\n        width: compositionRef.width,\n        height: compositionRef.height,\n        fps: compositionRef.fps,\n        durationInFrames: compositionRef.durationInFrames,\n        defaultProps: compositionRef.defaultProps,\n        calculateMetadata: compositionRef.calculateMetadata ?? undefined,\n        id: job.compositionId\n      },\n      inputProps: job.inputProps,\n      delayRenderTimeoutInMilliseconds: job.delayRenderTimeout,\n      mediaCacheSizeInBytes: job.mediaCacheSizeInBytes,\n      logLevel: job.logLevel,\n      videoCodec: job.videoCodec,\n      audioCodec: job.audioCodec,\n      audioBitrate: job.audioBitrate,\n      container: job.container,\n      videoBitrate: job.videoBitrate,\n      hardwareAcceleration: job.hardwareAcceleration,\n      keyframeIntervalInSeconds: job.keyframeIntervalInSeconds,\n      frameRange: [job.startFrame, job.endFrame],\n      transparent: job.transparent,\n      muted: job.muted,\n      scale: job.scale,\n      signal,\n      onProgress: (progress) => {\n        onProgress(job.id, {\n          renderedFrames: progress.renderedFrames,\n          encodedFrames: progress.encodedFrames,\n          totalFrames\n        });\n      },\n      outputTarget: \"web-fs\",\n      licenseKey: job.licenseKey ?? undefined\n    });\n    return {\n      getBlob,\n      width: compositionRef.width,\n      height: compositionRef.height\n    };\n  }, [getCompositionForJob2]);\n  const processJob = useCallback138(async (job) => {\n    const abortController = getAbortController2(job.id);\n    try {\n      let result;\n      if (job.type === \"client-still\") {\n        result = await processStillJob(job, abortController.signal);\n      } else if (job.type === \"client-video\") {\n        result = await processVideoJob(job, abortController.signal, updateClientJobProgress);\n      } else {\n        throw new Error(`Unknown job type`);\n      }\n      const blob = await result.getBlob();\n      downloadBlob(blob, job.outName);\n      const metadata = {\n        width: result.width,\n        height: result.height,\n        sizeInBytes: blob.size\n      };\n      markClientJobDone(job.id, result.getBlob, metadata);\n    } catch (err) {\n      if (abortController.signal.aborted) {\n        markClientJobCancelled(job.id);\n      } else {\n        markClientJobFailed(job.id, err);\n      }\n    }\n  }, [\n    getAbortController2,\n    processStillJob,\n    processVideoJob,\n    updateClientJobProgress,\n    markClientJobDone,\n    markClientJobFailed,\n    markClientJobCancelled\n  ]);\n  useEffect86(() => {\n    setProcessJobCallback(processJob);\n    return () => setProcessJobCallback(null);\n  }, [processJob, setProcessJobCallback]);\n  return null;\n};\n\n// src/components/SetTimelineInOutProvider.tsx\nimport { useEffect as useEffect87, useMemo as useMemo141, useState as useState92 } from \"react\";\n\n// src/state/marks.ts\nvar localStorageKey5 = () => `remotion.editor.marksv2`;\nvar persistMarks = (marks) => {\n  localStorage.setItem(localStorageKey5(), JSON.stringify(marks));\n};\nvar loadMarks = () => {\n  const item2 = localStorage.getItem(localStorageKey5());\n  if (item2 === null) {\n    return {};\n  }\n  return JSON.parse(item2);\n};\n\n// src/components/SetTimelineInOutProvider.tsx\nimport { jsx as jsx279 } from \"react/jsx-runtime\";\nvar SetTimelineInOutProvider = ({ children }) => {\n  const [inAndOutFrames, setInAndOutFrames] = useState92(() => loadMarks());\n  const setTimelineInOutContextValue = useMemo141(() => {\n    return {\n      setInAndOutFrames\n    };\n  }, []);\n  useEffect87(() => {\n    persistMarks(inAndOutFrames);\n  }, [inAndOutFrames]);\n  return /* @__PURE__ */ jsx279(TimelineInOutContext.Provider, {\n    value: inAndOutFrames,\n    children: /* @__PURE__ */ jsx279(SetTimelineInOutContext.Provider, {\n      value: setTimelineInOutContextValue,\n      children\n    })\n  });\n};\n\n// src/components/ShowGuidesProvider.tsx\nimport { useCallback as useCallback139, useMemo as useMemo142, useRef as useRef47, useState as useState93 } from \"react\";\nimport { jsx as jsx280 } from \"react/jsx-runtime\";\nvar ShowGuidesProvider = ({ children }) => {\n  const [guidesList, setGuidesList] = useState93(() => loadGuidesList());\n  const [selectedGuideId, setSelectedGuideId] = useState93(null);\n  const [hoveredGuideId, setHoveredGuideId] = useState93(null);\n  const [editorShowGuides, setEditorShowGuidesState] = useState93(() => loadEditorShowGuidesOption());\n  const shouldCreateGuideRef = useRef47(false);\n  const shouldDeleteGuideRef = useRef47(false);\n  const setEditorShowGuides = useCallback139((newValue) => {\n    setEditorShowGuidesState((prevState) => {\n      const newVal = newValue(prevState);\n      persistEditorShowGuidesOption(newVal);\n      return newVal;\n    });\n  }, []);\n  const editorShowGuidesCtx = useMemo142(() => {\n    return {\n      editorShowGuides,\n      setEditorShowGuides,\n      guidesList,\n      setGuidesList,\n      selectedGuideId,\n      setSelectedGuideId,\n      shouldCreateGuideRef,\n      shouldDeleteGuideRef,\n      hoveredGuideId,\n      setHoveredGuideId\n    };\n  }, [\n    editorShowGuides,\n    setEditorShowGuides,\n    guidesList,\n    selectedGuideId,\n    hoveredGuideId\n  ]);\n  return /* @__PURE__ */ jsx280(EditorShowGuidesContext.Provider, {\n    value: editorShowGuidesCtx,\n    children\n  });\n};\n\n// src/components/ShowRulersProvider.tsx\nimport { useCallback as useCallback140, useMemo as useMemo143, useState as useState94 } from \"react\";\nimport { jsx as jsx281 } from \"react/jsx-runtime\";\nvar ShowRulersProvider = ({ children }) => {\n  const [editorShowRulers, setEditorShowRulersState] = useState94(() => loadEditorShowRulersOption());\n  const setEditorShowRulers = useCallback140((newValue) => {\n    setEditorShowRulersState((prevState) => {\n      const newVal = newValue(prevState);\n      persistEditorShowRulersOption(newVal);\n      return newVal;\n    });\n  }, []);\n  const editorShowRulersCtx = useMemo143(() => {\n    return {\n      editorShowRulers,\n      setEditorShowRulers\n    };\n  }, [editorShowRulers, setEditorShowRulers]);\n  return /* @__PURE__ */ jsx281(EditorShowRulersContext.Provider, {\n    value: editorShowRulersCtx,\n    children\n  });\n};\n\n// src/components/ZoomGesturesProvider.tsx\nimport { useCallback as useCallback141, useMemo as useMemo144, useState as useState95 } from \"react\";\nimport { jsx as jsx282 } from \"react/jsx-runtime\";\nvar ZoomGesturesProvider = ({ children }) => {\n  const [editorZoomGestures, setEditorZoomGesturesState] = useState95(() => loadEditorZoomGesturesOption());\n  const setEditorZoomGestures = useCallback141((newValue) => {\n    setEditorZoomGesturesState((prevState) => {\n      const newVal = newValue(prevState);\n      persistEditorZoomGesturesOption(newVal);\n      return newVal;\n    });\n  }, []);\n  const editorZoomGesturesCtx = useMemo144(() => {\n    return {\n      editorZoomGestures,\n      setEditorZoomGestures\n    };\n  }, [editorZoomGestures, setEditorZoomGestures]);\n  return /* @__PURE__ */ jsx282(EditorZoomGesturesContext.Provider, {\n    value: editorZoomGesturesCtx,\n    children\n  });\n};\n\n// src/components/EditorContexts.tsx\nimport { jsx as jsx283, jsxs as jsxs150 } from \"react/jsx-runtime\";\nvar EditorContexts = ({ children, readOnlyStudio }) => {\n  return /* @__PURE__ */ jsx283(ZodProvider, {\n    children: /* @__PURE__ */ jsx283(VisualControlsProvider, {\n      children: /* @__PURE__ */ jsx283(PreviewServerConnection, {\n        readOnlyStudio,\n        children: /* @__PURE__ */ jsxs150(RenderQueueContextProvider, {\n          children: [\n            /* @__PURE__ */ jsx283(ClientRenderQueueProcessor, {}),\n            /* @__PURE__ */ jsx283(KeybindingContextProvider, {\n              children: /* @__PURE__ */ jsx283(CheckerboardProvider, {\n                children: /* @__PURE__ */ jsx283(ZoomGesturesProvider, {\n                  children: /* @__PURE__ */ jsx283(ShowRulersProvider, {\n                    children: /* @__PURE__ */ jsx283(ShowGuidesProvider, {\n                      children: /* @__PURE__ */ jsx283(PreviewSizeProvider, {\n                        children: /* @__PURE__ */ jsx283(ModalsProvider, {\n                          children: /* @__PURE__ */ jsx283(MediaVolumeProvider, {\n                            children: /* @__PURE__ */ jsx283(PlayerInternals20.PlayerEmitterProvider, {\n                              currentPlaybackRate: null,\n                              children: /* @__PURE__ */ jsx283(SidebarContextProvider, {\n                                children: /* @__PURE__ */ jsx283(FolderContextProvider, {\n                                  children: /* @__PURE__ */ jsx283(HighestZIndexProvider, {\n                                    children: /* @__PURE__ */ jsx283(SetTimelineInOutProvider, {\n                                      children\n                                    })\n                                  })\n                                })\n                              })\n                            })\n                          })\n                        })\n                      })\n                    })\n                  })\n                })\n              })\n            })\n          ]\n        })\n      })\n    })\n  });\n};\n\n// src/components/Notifications/ServerDisconnected.tsx\nimport { useContext as useContext88 } from \"react\";\nimport { jsx as jsx284, jsxs as jsxs151 } from \"react/jsx-runtime\";\nvar container63 = {\n  position: \"fixed\",\n  justifyContent: \"flex-end\",\n  alignItems: \"flex-start\",\n  display: \"flex\",\n  width: \"100%\",\n  height: \"100%\",\n  flexDirection: \"column\",\n  padding: 30,\n  pointerEvents: \"none\",\n  backgroundColor: \"transparent\",\n  fontFamily: \"SF Pro, Arial, Helvetica, sans-serif\"\n};\nvar message = {\n  backgroundColor: \"#e74c3c\",\n  color: \"white\",\n  paddingLeft: 20,\n  paddingRight: 20,\n  paddingTop: 12,\n  paddingBottom: 12,\n  borderRadius: 4,\n  boxShadow: \"0 2px 4px rgba(0, 0, 0, 0.4)\",\n  lineHeight: 1.5\n};\nvar inlineCode = {\n  fontSize: 16,\n  fontFamily: \"monospace\"\n};\nvar pageIsGoingToReload = false;\nwindow.addEventListener(\"beforeunload\", () => {\n  pageIsGoingToReload = true;\n});\nvar ServerDisconnected = () => {\n  const { previewServerState: ctx } = useContext88(StudioServerConnectionCtx);\n  const fav = document.getElementById(\"__remotion_favicon\");\n  if (ctx.type !== \"disconnected\") {\n    fav.setAttribute(\"href\", \"/favicon.ico\");\n    return null;\n  }\n  if (pageIsGoingToReload) {\n    return null;\n  }\n  const base64Favicon = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAYAAABw4pVUAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAARiSURBVHgB7d1NThRBFAfw/2tGgru5gXMD8QZ4AmVjAi6kN0TiAm8gnkBcGARNumcx4E48Ae0JaE9gewLHlQSZelaNgyHGL/RVd1X3+y10RQL58+rVx1QBKKWUUkoppZRSSimllFJKKVUjQs32stEiJcktZiwxzKL9Fvqzb6S0/44JVBKbtwa9aj29U6JjagtkJzsYzBEyBi9d5utsQIULCcxvelgo03R5jBarJZCXw/17E+bt82r4Hy4gtuEQekUbK8h7IHvDV5vMZht+VAlRfmYw3EhXKrSA10Ce2X7RIzpGDVzlgM1wPb2bI2JeA9nN99/b/waoV+XCmTAex1g13gLZyUZrdjjJ0CAbTB5bMN4C2ctHxwxaRABiCsZLIG6KmxC/R2BiCCaBBwn4NgJk10B2GOWj3Wz/IQLlpUL28oOjyy4AG1AZppuhVYt4hWRZ1o8gDGc6rL4YHjxCQMQDOcNCEI38bxnmLTc9d30PARAPZAITZP/4A1ctx3bjcw0NEw8koeQ64tRnu25qeggTb+q2/BmRcyv9K7yw3MTOsmiFuLMOtICblJzS5+Mm+opoIBOgFYHMuL5yVHcoooFQuwJxag9FNJCIG/rv1BqKaCDfzshbqbZQxAJxK3SJI9qATUPJstdef0axQGJbof+jwRc6eQ2PxAIx4DZXx3duSrybv3oCTyR7yACdYR762sIXDKQbFfId4ZGPJi8YCA3QLf05YvF+IhYIEV1Dx9hNu8XdbLQFQV6OcDuFaFNyKiwWiJ19DNBN/VN8XoMQrRABDFqCEJ32CiBisT08rRAZAwjRQAKjgcgQO+rVQARMb3gJ0UAkML+DEA1EwAQkdkNMcnOx1Zcxf8V9ol7y88GSm4tdDKRy1xsgSIes/0BM4ndN5HZ7OzZkMePperqSQ5jkkFWhO6r76WrYJ4b2N+YTumF60QeeSG6/d2DI4rHvW1eCPaT9Q9YZw/sVOMlZVoUWM8zpg/Su97dVJGdZFVrKhbFR05MdYoFcwWmF1rF9kbG8UeP7KaI3qBp628QTHrueUccwdZHw/ZDWNHY7tU1u1B2GIxqIYSO2Dd0Ud79wnq/eaOpBgR4EMVDW/oijINu87d7U6hYaJBrInA0k0iu4bvVtZ1KrBRrm4Vr06GNkF3cO7RCVhvK4pmiFOISkjOStk1lVrBQIiPh5SAyN3fWKWeMuEBjxCmEkh3bVvokAzd5idL2iQqDEA1nASXmK+XFIfeTCo5gFAudllvo8G20TUeNVElMQ58QrxLHD1jbB3GumSnhsz7qHE9BhTEGc87aOm16KJHi7rfqj8yfI53E1j/l9eK8L651stJUQeXx/iuzU1QztZLGIsRp+xvtOh3Qo3/qCedumEC6qZetpJztwz7O6UAa4FNsP7ELTfXbWbskUdjgq9M9VCJoFcwvTlfyPDd9t3XNJjA+2IZcGpmxi+7tpjW3OupurJziZhtKWPzWhlFJKKaWUUkoppZRSSiml/uwrgZ/Bfwo/wccAAAAASUVORK5CYII=\";\n  fav.setAttribute(\"href\", base64Favicon);\n  return /* @__PURE__ */ jsx284(\"div\", {\n    style: container63,\n    className: \"css-reset\",\n    children: /* @__PURE__ */ jsxs151(\"div\", {\n      style: message,\n      children: [\n        \"The studio server has disconnected. \",\n        /* @__PURE__ */ jsx284(\"br\", {}),\n        window.remotion_studioServerCommand ? /* @__PURE__ */ jsxs151(\"span\", {\n          children: [\n            \"Run\",\n            \" \",\n            /* @__PURE__ */ jsx284(\"code\", {\n              style: inlineCode,\n              children: window.remotion_studioServerCommand\n            }),\n            \" \",\n            \"to run it again.\"\n          ]\n        }) : /* @__PURE__ */ jsx284(\"span\", {\n          children: \"Fast refresh will not work.\"\n        })\n      ]\n    })\n  });\n};\n\n// src/helpers/inject-css.ts\nimport { Internals as Internals65 } from \"remotion\";\nvar makeDefaultGlobalCSS = () => {\n  const unhoveredDragAreaFactor = 2;\n  const fromMiddle = 50 / unhoveredDragAreaFactor;\n  const hoveredDragAreaFactor = 6;\n  const fromMiddleHovered = 50 / hoveredDragAreaFactor;\n  return `\n  html {\n    --remotion-cli-internals-blue: #0b84f3;\n    overscroll-behavior-y: none;\n    overscroll-behavior-x: none;\n  }\n  \n  body {\n    overscroll-behavior-y: none;\n    overscroll-behavior-x: none;\n    /* Override Chakra UI position: relative on body */\n    position: static !important;\n  }\n  \n  .remotion-splitter {\n    user-select: none;\n  }\n  \n  .remotion-splitter-horizontal {\n    transform: scaleY(${unhoveredDragAreaFactor});\n    background: linear-gradient(\n      to bottom,\n      transparent ${50 - fromMiddle}%,\n      black ${50 - fromMiddle}%,\n      black ${50 + fromMiddle}%,\n      transparent ${50 + fromMiddle}%\n    );\n  }\n  \n  .remotion-splitter-horizontal.remotion-splitter-active, .remotion-splitter-horizontal.remotion-splitter-hover {\n    background: linear-gradient(\n      to bottom,\n      transparent ${50 - fromMiddleHovered}%,\n      var(--remotion-cli-internals-blue) ${50 - fromMiddleHovered}%,\n      var(--remotion-cli-internals-blue) ${50 + fromMiddleHovered}%,\n      transparent ${50 + fromMiddleHovered}%\n    );\n    cursor: row-resize;\n    transform: scaleY(${hoveredDragAreaFactor});\n    z-index: 1000;\n  }\n  \n  .remotion-splitter-vertical {\n    transform: scaleX(${unhoveredDragAreaFactor});\n    background: linear-gradient(\n      to right,\n      transparent ${50 - fromMiddle}%,\n      black ${50 - fromMiddle}%,\n      black ${50 + fromMiddle}%,\n      transparent ${50 + fromMiddle}%\n    );\n  }\n  \n  .remotion-splitter-vertical.remotion-splitter-active, .remotion-splitter-vertical.remotion-splitter-hover {\n    background: linear-gradient(\n      to right,\n      transparent ${50 - fromMiddleHovered}%,\n      var(--remotion-cli-internals-blue) ${50 - fromMiddleHovered}%,\n      var(--remotion-cli-internals-blue) ${50 + fromMiddleHovered}%,\n      transparent ${50 + fromMiddleHovered}%\n    );\n    transform: scaleX(${hoveredDragAreaFactor});\n    cursor: col-resize;\n    z-index: 1000;\n  }\n  \n  input::-webkit-outer-spin-button,\n  input::-webkit-inner-spin-button {\n    -webkit-appearance: none;\n    margin: 0;\n  }\n  \n  input:focus,\n  textarea:focus,\n  button:focus,\n  a:focus {\n    outline: none;\n    box-shadow:\n      inset 1px 1px #555,\n      inset -1px -1px #555,\n      inset 1px -1px #555,\n      inset -1px 1px #555;\n  }\n  \n  input[type='color'].__remotion_color_picker::-webkit-color-swatch-wrapper {\n    padding: 0;\n  }\n  input[type='color'].__remotion_color_picker::-webkit-color-swatch {\n    border: none;\n  }\n  \n  .__remotion_thumb,\n  .__remotion_thumb::-webkit-slider-thumb {\n    -webkit-appearance: none;\n    -webkit-tap-highlight-color: transparent;\n  }\n  \n  .__remotion_thumb {\n    pointer-events: none;\n    position: absolute;\n    height: 0;\n    outline: none;\n    top: 15.5px;\n    width: 221px;\n    margin-left: -2px;\n    z-index: 2;\n  }\n  \n  /* For Firefox browsers */\n  .__remotion_thumb::-moz-range-thumb {\n    border: 1px solid black;\n    border-radius: 2px;\n    cursor: pointer;\n    height: 37px;\n    width: 10px;\n    pointer-events: all;\n    border-color: black;\n    background-color: white;\n    position: relative;\n  }\n  \n  /* For Chrome browsers */\n  .__remotion_thumb::-webkit-slider-thumb {\n    border: 1px solid black;\n    border-radius: 2px;\n    cursor: pointer;\n    height: 39px;\n    width: 10px;\n    pointer-events: all;\n    border-color: black;\n    background-color: white;\n    position: relative;\n  }  \n\n  .${DEFAULT_PROPS_PATH_ACTIVE_CLASSNAME} span {\n    color: var(--remotion-cli-internals-blue) !important;\n    transition: color 0.2s ease-in-out;\n  }\n  `.trim();\n};\nvar injected = false;\nvar injectCSS = () => {\n  if (injected) {\n    return;\n  }\n  Internals65.CSSUtils.injectCSS(makeDefaultGlobalCSS());\n  injected = true;\n};\n\n// src/Studio.tsx\nimport { jsx as jsx285, jsxs as jsxs152 } from \"react/jsx-runtime\";\nvar getServerDisconnectedDomElement = () => {\n  return document.getElementById(\"server-disconnected-overlay\");\n};\nvar Studio = ({ rootComponent, readOnly }) => {\n  useLayoutEffect2(() => {\n    injectCSS();\n  }, []);\n  return /* @__PURE__ */ jsx285(Internals66.CompositionManagerProvider, {\n    onlyRenderComposition: null,\n    currentCompositionMetadata: null,\n    initialCompositions: [],\n    initialCanvasContent: null,\n    children: /* @__PURE__ */ jsx285(Internals66.RemotionRootContexts, {\n      frameState: null,\n      audioEnabled: window.remotion_audioEnabled,\n      videoEnabled: window.remotion_videoEnabled,\n      logLevel: window.remotion_logLevel,\n      numberOfAudioTags: window.remotion_numberOfAudioTags,\n      audioLatencyHint: window.remotion_audioLatencyHint ?? \"interactive\",\n      children: /* @__PURE__ */ jsx285(Internals66.ResolveCompositionConfigInStudio, {\n        children: /* @__PURE__ */ jsxs152(EditorContexts, {\n          readOnlyStudio: readOnly,\n          children: [\n            /* @__PURE__ */ jsx285(Editor, {\n              readOnlyStudio: readOnly,\n              Root: rootComponent\n            }),\n            readOnly ? null : createPortal(/* @__PURE__ */ jsx285(ServerDisconnected, {}), getServerDisconnectedDomElement())\n          ]\n        })\n      })\n    })\n  });\n};\n\n// src/internals.ts\nvar StudioInternals = {\n  Studio\n};\nexport {\n  StudioInternals\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n/**\n * A data structure which is a combination of an array and a set. Adding a new\n * member is O(1), testing for membership is O(1), and finding the index of an\n * element is O(1). Removing elements from the set is not supported. Only\n * strings are supported for membership.\n */\nclass ArraySet {\n  constructor() {\n    this._array = [];\n    this._set = new Map();\n  }\n\n  /**\n   * Static method for creating ArraySet instances from an existing array.\n   */\n  static fromArray(aArray, aAllowDuplicates) {\n    const set = new ArraySet();\n    for (let i = 0, len = aArray.length; i < len; i++) {\n      set.add(aArray[i], aAllowDuplicates);\n    }\n    return set;\n  }\n\n  /**\n   * Return how many unique items are in this ArraySet. If duplicates have been\n   * added, than those do not count towards the size.\n   *\n   * @returns Number\n   */\n  size() {\n    return this._set.size;\n  }\n\n  /**\n   * Add the given string to this set.\n   *\n   * @param String aStr\n   */\n  add(aStr, aAllowDuplicates) {\n    const isDuplicate = this.has(aStr);\n    const idx = this._array.length;\n    if (!isDuplicate || aAllowDuplicates) {\n      this._array.push(aStr);\n    }\n    if (!isDuplicate) {\n      this._set.set(aStr, idx);\n    }\n  }\n\n  /**\n   * Is the given string a member of this set?\n   *\n   * @param String aStr\n   */\n  has(aStr) {\n      return this._set.has(aStr);\n  }\n\n  /**\n   * What is the index of the given string in the array?\n   *\n   * @param String aStr\n   */\n  indexOf(aStr) {\n    const idx = this._set.get(aStr);\n    if (idx >= 0) {\n        return idx;\n    }\n    throw new Error('\"' + aStr + '\" is not in the set.');\n  }\n\n  /**\n   * What is the element at the given index?\n   *\n   * @param Number aIdx\n   */\n  at(aIdx) {\n    if (aIdx >= 0 && aIdx < this._array.length) {\n      return this._array[aIdx];\n    }\n    throw new Error(\"No element indexed by \" + aIdx);\n  }\n\n  /**\n   * Returns the array representation of this set (which has the proper indices\n   * indicated by indexOf). Note that this is a copy of the internal array used\n   * for storing the members so that no one can mess with internal state.\n   */\n  toArray() {\n    return this._array.slice();\n  }\n}\nexports.ArraySet = ArraySet;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n *\n * Based on the Base 64 VLQ implementation in Closure Compiler:\n * https://code.google.com/p/closure-compiler/source/browse/trunk/src/com/google/debugging/sourcemap/Base64VLQ.java\n *\n * Copyright 2011 The Closure Compiler Authors. All rights reserved.\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are\n * met:\n *\n *  * Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above\n *    copyright notice, this list of conditions and the following\n *    disclaimer in the documentation and/or other materials provided\n *    with the distribution.\n *  * Neither the name of Google Inc. nor the names of its\n *    contributors may be used to endorse or promote products derived\n *    from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\nconst base64 = require(\"./base64\");\n\n// A single base 64 digit can contain 6 bits of data. For the base 64 variable\n// length quantities we use in the source map spec, the first bit is the sign,\n// the next four bits are the actual value, and the 6th bit is the\n// continuation bit. The continuation bit tells us whether there are more\n// digits in this value following this digit.\n//\n//   Continuation\n//   |    Sign\n//   |    |\n//   V    V\n//   101011\n\nconst VLQ_BASE_SHIFT = 5;\n\n// binary: 100000\nconst VLQ_BASE = 1 << VLQ_BASE_SHIFT;\n\n// binary: 011111\nconst VLQ_BASE_MASK = VLQ_BASE - 1;\n\n// binary: 100000\nconst VLQ_CONTINUATION_BIT = VLQ_BASE;\n\n/**\n * Converts from a two-complement value to a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   1 becomes 2 (10 binary), -1 becomes 3 (11 binary)\n *   2 becomes 4 (100 binary), -2 becomes 5 (101 binary)\n */\nfunction toVLQSigned(aValue) {\n  return aValue < 0\n    ? ((-aValue) << 1) + 1\n    : (aValue << 1) + 0;\n}\n\n/**\n * Converts to a two-complement value from a value where the sign bit is\n * placed in the least significant bit.  For example, as decimals:\n *   2 (10 binary) becomes 1, 3 (11 binary) becomes -1\n *   4 (100 binary) becomes 2, 5 (101 binary) becomes -2\n */\n// eslint-disable-next-line no-unused-vars\nfunction fromVLQSigned(aValue) {\n  const isNegative = (aValue & 1) === 1;\n  const shifted = aValue >> 1;\n  return isNegative\n    ? -shifted\n    : shifted;\n}\n\n/**\n * Returns the base 64 VLQ encoded value.\n */\nexports.encode = function base64VLQ_encode(aValue) {\n  let encoded = \"\";\n  let digit;\n\n  let vlq = toVLQSigned(aValue);\n\n  do {\n    digit = vlq & VLQ_BASE_MASK;\n    vlq >>>= VLQ_BASE_SHIFT;\n    if (vlq > 0) {\n      // There are still more digits in this value, so we must make sure the\n      // continuation bit is marked.\n      digit |= VLQ_CONTINUATION_BIT;\n    }\n    encoded += base64.encode(digit);\n  } while (vlq > 0);\n\n  return encoded;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nconst intToCharMap = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\".split(\"\");\n\n/**\n * Encode an integer in the range of 0 to 63 to a single base 64 digit.\n */\nexports.encode = function(number) {\n  if (0 <= number && number < intToCharMap.length) {\n    return intToCharMap[number];\n  }\n  throw new TypeError(\"Must be between 0 and 63: \" + number);\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nexports.GREATEST_LOWER_BOUND = 1;\nexports.LEAST_UPPER_BOUND = 2;\n\n/**\n * Recursive implementation of binary search.\n *\n * @param aLow Indices here and lower do not contain the needle.\n * @param aHigh Indices here and higher do not contain the needle.\n * @param aNeedle The element being searched for.\n * @param aHaystack The non-empty array being searched.\n * @param aCompare Function which takes two elements and returns -1, 0, or 1.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n */\nfunction recursiveSearch(aLow, aHigh, aNeedle, aHaystack, aCompare, aBias) {\n  // This function terminates when one of the following is true:\n  //\n  //   1. We find the exact element we are looking for.\n  //\n  //   2. We did not find the exact element, but we can return the index of\n  //      the next-closest element.\n  //\n  //   3. We did not find the exact element, and there is no next-closest\n  //      element than the one we are searching for, so we return -1.\n  const mid = Math.floor((aHigh - aLow) / 2) + aLow;\n  const cmp = aCompare(aNeedle, aHaystack[mid], true);\n  if (cmp === 0) {\n    // Found the element we are looking for.\n    return mid;\n  } else if (cmp > 0) {\n    // Our needle is greater than aHaystack[mid].\n    if (aHigh - mid > 1) {\n      // The element is in the upper half.\n      return recursiveSearch(mid, aHigh, aNeedle, aHaystack, aCompare, aBias);\n    }\n\n    // The exact needle element was not found in this haystack. Determine if\n    // we are in termination case (3) or (2) and return the appropriate thing.\n    if (aBias == exports.LEAST_UPPER_BOUND) {\n      return aHigh < aHaystack.length ? aHigh : -1;\n    }\n    return mid;\n  }\n\n  // Our needle is less than aHaystack[mid].\n  if (mid - aLow > 1) {\n    // The element is in the lower half.\n    return recursiveSearch(aLow, mid, aNeedle, aHaystack, aCompare, aBias);\n  }\n\n  // we are in termination case (3) or (2) and return the appropriate thing.\n  if (aBias == exports.LEAST_UPPER_BOUND) {\n    return mid;\n  }\n  return aLow < 0 ? -1 : aLow;\n}\n\n/**\n * This is an implementation of binary search which will always try and return\n * the index of the closest element if there is no exact hit. This is because\n * mappings between original and generated line/col pairs are single points,\n * and there is an implicit region between each of them, so a miss just means\n * that you aren't on the very start of a region.\n *\n * @param aNeedle The element you are looking for.\n * @param aHaystack The array that is being searched.\n * @param aCompare A function which takes the needle and an element in the\n *     array and returns -1, 0, or 1 depending on whether the needle is less\n *     than, equal to, or greater than the element, respectively.\n * @param aBias Either 'binarySearch.GREATEST_LOWER_BOUND' or\n *     'binarySearch.LEAST_UPPER_BOUND'. Specifies whether to return the\n *     closest element that is smaller than or greater than the one we are\n *     searching for, respectively, if the exact element cannot be found.\n *     Defaults to 'binarySearch.GREATEST_LOWER_BOUND'.\n */\nexports.search = function search(aNeedle, aHaystack, aCompare, aBias) {\n  if (aHaystack.length === 0) {\n    return -1;\n  }\n\n  let index = recursiveSearch(-1, aHaystack.length, aNeedle, aHaystack,\n                              aCompare, aBias || exports.GREATEST_LOWER_BOUND);\n  if (index < 0) {\n    return -1;\n  }\n\n  // We have found either the exact element, or the next-closest element than\n  // the one we are searching for. However, there may be more than one such\n  // element. Make sure we always return the smallest of these.\n  while (index - 1 >= 0) {\n    if (aCompare(aHaystack[index], aHaystack[index - 1], true) !== 0) {\n      break;\n    }\n    --index;\n  }\n\n  return index;\n};\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2014 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nconst util = require(\"./util\");\n\n/**\n * Determine whether mappingB is after mappingA with respect to generated\n * position.\n */\nfunction generatedPositionAfter(mappingA, mappingB) {\n  // Optimized for most common case\n  const lineA = mappingA.generatedLine;\n  const lineB = mappingB.generatedLine;\n  const columnA = mappingA.generatedColumn;\n  const columnB = mappingB.generatedColumn;\n  return lineB > lineA || lineB == lineA && columnB >= columnA ||\n         util.compareByGeneratedPositionsInflated(mappingA, mappingB) <= 0;\n}\n\n/**\n * A data structure to provide a sorted view of accumulated mappings in a\n * performance conscious manner. It trades a negligible overhead in general\n * case for a large speedup in case of mappings being added in order.\n */\nclass MappingList {\n  constructor() {\n    this._array = [];\n    this._sorted = true;\n    // Serves as infimum\n    this._last = {generatedLine: -1, generatedColumn: 0};\n  }\n\n  /**\n   * Iterate through internal items. This method takes the same arguments that\n   * `Array.prototype.forEach` takes.\n   *\n   * NOTE: The order of the mappings is NOT guaranteed.\n   */\n  unsortedForEach(aCallback, aThisArg) {\n    this._array.forEach(aCallback, aThisArg);\n  }\n\n  /**\n   * Add the given source mapping.\n   *\n   * @param Object aMapping\n   */\n  add(aMapping) {\n    if (generatedPositionAfter(this._last, aMapping)) {\n      this._last = aMapping;\n      this._array.push(aMapping);\n    } else {\n      this._sorted = false;\n      this._array.push(aMapping);\n    }\n  }\n\n  /**\n   * Returns the flat, sorted array of mappings. The mappings are sorted by\n   * generated position.\n   *\n   * WARNING: This method returns internal data without copying, for\n   * performance. The return value must NOT be mutated, and should be treated as\n   * an immutable borrow. If you want to take ownership, you must make your own\n   * copy.\n   */\n  toArray() {\n    if (!this._sorted) {\n      this._array.sort(util.compareByGeneratedPositionsInflated);\n      this._sorted = true;\n    }\n    return this._array;\n  }\n}\n\nexports.MappingList = MappingList;\n","if (typeof fetch === \"function\") {\n  // Web version of reading a wasm file into an array buffer.\n\n  let mappingsWasmUrl = null;\n\n  module.exports = function readWasm() {\n    if (typeof mappingsWasmUrl !== \"string\") {\n      throw new Error(\"You must provide the URL of lib/mappings.wasm by calling \" +\n                      \"SourceMapConsumer.initialize({ 'lib/mappings.wasm': ... }) \" +\n                      \"before using SourceMapConsumer\");\n    }\n\n    return fetch(mappingsWasmUrl)\n      .then(response => response.arrayBuffer());\n  };\n\n  module.exports.initialize = url => mappingsWasmUrl = url;\n} else {\n  // Node version of reading a wasm file into an array buffer.\n  const fs = require(\"fs\");\n  const path = require(\"path\");\n\n  module.exports = function readWasm() {\n    return new Promise((resolve, reject) => {\n      const wasmPath = path.join(__dirname, \"mappings.wasm\");\n      fs.readFile(wasmPath, null, (error, data) => {\n        if (error) {\n          reject(error);\n          return;\n        }\n\n        resolve(data.buffer);\n      });\n    });\n  };\n\n  module.exports.initialize = _ => {\n    console.debug(\"SourceMapConsumer.initialize is a no-op when running in node.js\");\n  };\n}\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nconst util = require(\"./util\");\nconst binarySearch = require(\"./binary-search\");\nconst ArraySet = require(\"./array-set\").ArraySet;\nconst base64VLQ = require(\"./base64-vlq\"); // eslint-disable-line no-unused-vars\nconst readWasm = require(\"../lib/read-wasm\");\nconst wasm = require(\"./wasm\");\n\nconst INTERNAL = Symbol(\"smcInternal\");\n\nclass SourceMapConsumer {\n  constructor(aSourceMap, aSourceMapURL) {\n    // If the constructor was called by super(), just return Promise<this>.\n    // Yes, this is a hack to retain the pre-existing API of the base-class\n    // constructor also being an async factory function.\n    if (aSourceMap == INTERNAL) {\n      return Promise.resolve(this);\n    }\n\n    return _factory(aSourceMap, aSourceMapURL);\n  }\n\n  static initialize(opts) {\n    readWasm.initialize(opts[\"lib/mappings.wasm\"]);\n  }\n\n  static fromSourceMap(aSourceMap, aSourceMapURL) {\n    return _factoryBSM(aSourceMap, aSourceMapURL);\n  }\n\n  /**\n   * Construct a new `SourceMapConsumer` from `rawSourceMap` and `sourceMapUrl`\n   * (see the `SourceMapConsumer` constructor for details. Then, invoke the `async\n   * function f(SourceMapConsumer) -> T` with the newly constructed consumer, wait\n   * for `f` to complete, call `destroy` on the consumer, and return `f`'s return\n   * value.\n   *\n   * You must not use the consumer after `f` completes!\n   *\n   * By using `with`, you do not have to remember to manually call `destroy` on\n   * the consumer, since it will be called automatically once `f` completes.\n   *\n   * ```js\n   * const xSquared = await SourceMapConsumer.with(\n   *   myRawSourceMap,\n   *   null,\n   *   async function (consumer) {\n   *     // Use `consumer` inside here and don't worry about remembering\n   *     // to call `destroy`.\n   *\n   *     const x = await whatever(consumer);\n   *     return x * x;\n   *   }\n   * );\n   *\n   * // You may not use that `consumer` anymore out here; it has\n   * // been destroyed. But you can use `xSquared`.\n   * console.log(xSquared);\n   * ```\n   */\n  static with(rawSourceMap, sourceMapUrl, f) {\n    // Note: The `acorn` version that `webpack` currently depends on doesn't\n    // support `async` functions, and the nodes that we support don't all have\n    // `.finally`. Therefore, this is written a bit more convolutedly than it\n    // should really be.\n\n    let consumer = null;\n    const promise = new SourceMapConsumer(rawSourceMap, sourceMapUrl);\n    return promise\n      .then(c => {\n        consumer = c;\n        return f(c);\n      })\n      .then(x => {\n        if (consumer) {\n          consumer.destroy();\n        }\n        return x;\n      }, e => {\n        if (consumer) {\n          consumer.destroy();\n        }\n        throw e;\n      });\n  }\n\n  /**\n   * Parse the mappings in a string in to a data structure which we can easily\n   * query (the ordered arrays in the `this.__generatedMappings` and\n   * `this.__originalMappings` properties).\n   */\n  _parseMappings(aStr, aSourceRoot) {\n    throw new Error(\"Subclasses must implement _parseMappings\");\n  }\n\n  /**\n   * Iterate over each mapping between an original source/line/column and a\n   * generated line/column in this source map.\n   *\n   * @param Function aCallback\n   *        The function that is called with each mapping.\n   * @param Object aContext\n   *        Optional. If specified, this object will be the value of `this` every\n   *        time that `aCallback` is called.\n   * @param aOrder\n   *        Either `SourceMapConsumer.GENERATED_ORDER` or\n   *        `SourceMapConsumer.ORIGINAL_ORDER`. Specifies whether you want to\n   *        iterate over the mappings sorted by the generated file's line/column\n   *        order or the original's source/line/column order, respectively. Defaults to\n   *        `SourceMapConsumer.GENERATED_ORDER`.\n   */\n  eachMapping(aCallback, aContext, aOrder) {\n    throw new Error(\"Subclasses must implement eachMapping\");\n  }\n\n  /**\n   * Returns all generated line and column information for the original source,\n   * line, and column provided. If no column is provided, returns all mappings\n   * corresponding to a either the line we are searching for or the next\n   * closest line that has any mappings. Otherwise, returns all mappings\n   * corresponding to the given line and either the column we are searching for\n   * or the next closest column that has any offsets.\n   *\n   * The only argument is an object with the following properties:\n   *\n   *   - source: The filename of the original source.\n   *   - line: The line number in the original source.  The line number is 1-based.\n   *   - column: Optional. the column number in the original source.\n   *    The column number is 0-based.\n   *\n   * and an array of objects is returned, each with the following properties:\n   *\n   *   - line: The line number in the generated source, or null.  The\n   *    line number is 1-based.\n   *   - column: The column number in the generated source, or null.\n   *    The column number is 0-based.\n   */\n  allGeneratedPositionsFor(aArgs) {\n    throw new Error(\"Subclasses must implement allGeneratedPositionsFor\");\n  }\n\n  destroy() {\n    throw new Error(\"Subclasses must implement destroy\");\n  }\n}\n\n/**\n * The version of the source mapping spec that we are consuming.\n */\nSourceMapConsumer.prototype._version = 3;\nSourceMapConsumer.GENERATED_ORDER = 1;\nSourceMapConsumer.ORIGINAL_ORDER = 2;\n\nSourceMapConsumer.GREATEST_LOWER_BOUND = 1;\nSourceMapConsumer.LEAST_UPPER_BOUND = 2;\n\nexports.SourceMapConsumer = SourceMapConsumer;\n\n/**\n * A BasicSourceMapConsumer instance represents a parsed source map which we can\n * query for information about the original file positions by giving it a file\n * position in the generated source.\n *\n * The first parameter is the raw source map (either as a JSON string, or\n * already parsed to an object). According to the spec, source maps have the\n * following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - sources: An array of URLs to the original source files.\n *   - names: An array of identifiers which can be referenced by individual mappings.\n *   - sourceRoot: Optional. The URL root from which all sources are relative.\n *   - sourcesContent: Optional. An array of contents of the original source files.\n *   - mappings: A string of base64 VLQs which contain the actual mappings.\n *   - file: Optional. The generated file this source map is associated with.\n *\n * Here is an example source map, taken from the source map spec[0]:\n *\n *     {\n *       version : 3,\n *       file: \"out.js\",\n *       sourceRoot : \"\",\n *       sources: [\"foo.js\", \"bar.js\"],\n *       names: [\"src\", \"maps\", \"are\", \"fun\"],\n *       mappings: \"AA,AB;;ABCDE;\"\n *     }\n *\n * The second parameter, if given, is a string whose value is the URL\n * at which the source map was found.  This URL is used to compute the\n * sources array.\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit?pli=1#\n */\nclass BasicSourceMapConsumer extends SourceMapConsumer {\n  constructor(aSourceMap, aSourceMapURL) {\n    return super(INTERNAL).then(that => {\n      let sourceMap = aSourceMap;\n      if (typeof aSourceMap === \"string\") {\n        sourceMap = util.parseSourceMapInput(aSourceMap);\n      }\n\n      const version = util.getArg(sourceMap, \"version\");\n      let sources = util.getArg(sourceMap, \"sources\");\n      // Sass 3.3 leaves out the 'names' array, so we deviate from the spec (which\n      // requires the array) to play nice here.\n      const names = util.getArg(sourceMap, \"names\", []);\n      let sourceRoot = util.getArg(sourceMap, \"sourceRoot\", null);\n      const sourcesContent = util.getArg(sourceMap, \"sourcesContent\", null);\n      const mappings = util.getArg(sourceMap, \"mappings\");\n      const file = util.getArg(sourceMap, \"file\", null);\n\n      // Once again, Sass deviates from the spec and supplies the version as a\n      // string rather than a number, so we use loose equality checking here.\n      if (version != that._version) {\n        throw new Error(\"Unsupported version: \" + version);\n      }\n\n      if (sourceRoot) {\n        sourceRoot = util.normalize(sourceRoot);\n      }\n\n      sources = sources\n        .map(String)\n        // Some source maps produce relative source paths like \"./foo.js\" instead of\n        // \"foo.js\".  Normalize these first so that future comparisons will succeed.\n        // See bugzil.la/1090768.\n        .map(util.normalize)\n        // Always ensure that absolute sources are internally stored relative to\n        // the source root, if the source root is absolute. Not doing this would\n        // be particularly problematic when the source root is a prefix of the\n        // source (valid, but why??). See github issue #199 and bugzil.la/1188982.\n        .map(function(source) {\n          return sourceRoot && util.isAbsolute(sourceRoot) && util.isAbsolute(source)\n            ? util.relative(sourceRoot, source)\n            : source;\n        });\n\n      // Pass `true` below to allow duplicate names and sources. While source maps\n      // are intended to be compressed and deduplicated, the TypeScript compiler\n      // sometimes generates source maps with duplicates in them. See Github issue\n      // #72 and bugzil.la/889492.\n      that._names = ArraySet.fromArray(names.map(String), true);\n      that._sources = ArraySet.fromArray(sources, true);\n\n      that._absoluteSources = that._sources.toArray().map(function(s) {\n        return util.computeSourceURL(sourceRoot, s, aSourceMapURL);\n      });\n\n      that.sourceRoot = sourceRoot;\n      that.sourcesContent = sourcesContent;\n      that._mappings = mappings;\n      that._sourceMapURL = aSourceMapURL;\n      that.file = file;\n\n      that._computedColumnSpans = false;\n      that._mappingsPtr = 0;\n      that._wasm = null;\n\n      return wasm().then(w => {\n        that._wasm = w;\n        return that;\n      });\n    });\n  }\n\n  /**\n   * Utility function to find the index of a source.  Returns -1 if not\n   * found.\n   */\n  _findSourceIndex(aSource) {\n    let relativeSource = aSource;\n    if (this.sourceRoot != null) {\n      relativeSource = util.relative(this.sourceRoot, relativeSource);\n    }\n\n    if (this._sources.has(relativeSource)) {\n      return this._sources.indexOf(relativeSource);\n    }\n\n    // Maybe aSource is an absolute URL as returned by |sources|.  In\n    // this case we can't simply undo the transform.\n    for (let i = 0; i < this._absoluteSources.length; ++i) {\n      if (this._absoluteSources[i] == aSource) {\n        return i;\n      }\n    }\n\n    return -1;\n  }\n\n  /**\n   * Create a BasicSourceMapConsumer from a SourceMapGenerator.\n   *\n   * @param SourceMapGenerator aSourceMap\n   *        The source map that will be consumed.\n   * @param String aSourceMapURL\n   *        The URL at which the source map can be found (optional)\n   * @returns BasicSourceMapConsumer\n   */\n  static fromSourceMap(aSourceMap, aSourceMapURL) {\n    return new BasicSourceMapConsumer(aSourceMap.toString());\n  }\n\n  get sources() {\n    return this._absoluteSources.slice();\n  }\n\n  _getMappingsPtr() {\n    if (this._mappingsPtr === 0) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this._mappingsPtr;\n  }\n\n  /**\n   * Parse the mappings in a string in to a data structure which we can easily\n   * query (the ordered arrays in the `this.__generatedMappings` and\n   * `this.__originalMappings` properties).\n   */\n  _parseMappings(aStr, aSourceRoot) {\n    const size = aStr.length;\n\n    const mappingsBufPtr = this._wasm.exports.allocate_mappings(size);\n    const mappingsBuf = new Uint8Array(this._wasm.exports.memory.buffer, mappingsBufPtr, size);\n    for (let i = 0; i < size; i++) {\n      mappingsBuf[i] = aStr.charCodeAt(i);\n    }\n\n    const mappingsPtr = this._wasm.exports.parse_mappings(mappingsBufPtr);\n\n    if (!mappingsPtr) {\n      const error = this._wasm.exports.get_last_error();\n      let msg = `Error parsing mappings (code ${error}): `;\n\n      // XXX: keep these error codes in sync with `fitzgen/source-map-mappings`.\n      switch (error) {\n        case 1:\n          msg += \"the mappings contained a negative line, column, source index, or name index\";\n          break;\n        case 2:\n          msg += \"the mappings contained a number larger than 2**32\";\n          break;\n        case 3:\n          msg += \"reached EOF while in the middle of parsing a VLQ\";\n          break;\n        case 4:\n          msg += \"invalid base 64 character while parsing a VLQ\";\n          break;\n        default:\n          msg += \"unknown error code\";\n          break;\n      }\n\n      throw new Error(msg);\n    }\n\n    this._mappingsPtr = mappingsPtr;\n  }\n\n  eachMapping(aCallback, aContext, aOrder) {\n    const context = aContext || null;\n    const order = aOrder || SourceMapConsumer.GENERATED_ORDER;\n    const sourceRoot = this.sourceRoot;\n\n    this._wasm.withMappingCallback(\n      mapping => {\n        if (mapping.source !== null) {\n          mapping.source = this._sources.at(mapping.source);\n          mapping.source = util.computeSourceURL(sourceRoot, mapping.source, this._sourceMapURL);\n\n          if (mapping.name !== null) {\n            mapping.name = this._names.at(mapping.name);\n          }\n        }\n\n        aCallback.call(context, mapping);\n      },\n      () => {\n        switch (order) {\n        case SourceMapConsumer.GENERATED_ORDER:\n          this._wasm.exports.by_generated_location(this._getMappingsPtr());\n          break;\n        case SourceMapConsumer.ORIGINAL_ORDER:\n          this._wasm.exports.by_original_location(this._getMappingsPtr());\n          break;\n        default:\n          throw new Error(\"Unknown order of iteration.\");\n        }\n      }\n    );\n  }\n\n  allGeneratedPositionsFor(aArgs) {\n    let source = util.getArg(aArgs, \"source\");\n    const originalLine = util.getArg(aArgs, \"line\");\n    const originalColumn = aArgs.column || 0;\n\n    source = this._findSourceIndex(source);\n    if (source < 0) {\n      return [];\n    }\n\n    if (originalLine < 1) {\n      throw new Error(\"Line numbers must be >= 1\");\n    }\n\n    if (originalColumn < 0) {\n      throw new Error(\"Column numbers must be >= 0\");\n    }\n\n    const mappings = [];\n\n    this._wasm.withMappingCallback(\n      m => {\n        let lastColumn = m.lastGeneratedColumn;\n        if (this._computedColumnSpans && lastColumn === null) {\n          lastColumn = Infinity;\n        }\n        mappings.push({\n          line: m.generatedLine,\n          column: m.generatedColumn,\n          lastColumn,\n        });\n      }, () => {\n        this._wasm.exports.all_generated_locations_for(\n          this._getMappingsPtr(),\n          source,\n          originalLine - 1,\n          \"column\" in aArgs,\n          originalColumn\n        );\n      }\n    );\n\n    return mappings;\n  }\n\n  destroy() {\n    if (this._mappingsPtr !== 0) {\n      this._wasm.exports.free_mappings(this._mappingsPtr);\n      this._mappingsPtr = 0;\n    }\n  }\n\n  /**\n   * Compute the last column for each generated mapping. The last column is\n   * inclusive.\n   */\n  computeColumnSpans() {\n    if (this._computedColumnSpans) {\n      return;\n    }\n\n    this._wasm.exports.compute_column_spans(this._getMappingsPtr());\n    this._computedColumnSpans = true;\n  }\n\n  /**\n   * Returns the original source, line, and column information for the generated\n   * source's line and column positions provided. The only argument is an object\n   * with the following properties:\n   *\n   *   - line: The line number in the generated source.  The line number\n   *     is 1-based.\n   *   - column: The column number in the generated source.  The column\n   *     number is 0-based.\n   *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n   *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n   *     closest element that is smaller than or greater than the one we are\n   *     searching for, respectively, if the exact element cannot be found.\n   *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n   *\n   * and an object is returned with the following properties:\n   *\n   *   - source: The original source file, or null.\n   *   - line: The line number in the original source, or null.  The\n   *     line number is 1-based.\n   *   - column: The column number in the original source, or null.  The\n   *     column number is 0-based.\n   *   - name: The original identifier, or null.\n   */\n  originalPositionFor(aArgs) {\n    const needle = {\n      generatedLine: util.getArg(aArgs, \"line\"),\n      generatedColumn: util.getArg(aArgs, \"column\")\n    };\n\n    if (needle.generatedLine < 1) {\n      throw new Error(\"Line numbers must be >= 1\");\n    }\n\n    if (needle.generatedColumn < 0) {\n      throw new Error(\"Column numbers must be >= 0\");\n    }\n\n    let bias = util.getArg(aArgs, \"bias\", SourceMapConsumer.GREATEST_LOWER_BOUND);\n    if (bias == null) {\n      bias = SourceMapConsumer.GREATEST_LOWER_BOUND;\n    }\n\n    let mapping;\n    this._wasm.withMappingCallback(m => mapping = m, () => {\n      this._wasm.exports.original_location_for(\n        this._getMappingsPtr(),\n        needle.generatedLine - 1,\n        needle.generatedColumn,\n        bias\n      );\n    });\n\n    if (mapping) {\n      if (mapping.generatedLine === needle.generatedLine) {\n        let source = util.getArg(mapping, \"source\", null);\n        if (source !== null) {\n          source = this._sources.at(source);\n          source = util.computeSourceURL(this.sourceRoot, source, this._sourceMapURL);\n        }\n\n        let name = util.getArg(mapping, \"name\", null);\n        if (name !== null) {\n          name = this._names.at(name);\n        }\n\n        return {\n          source,\n          line: util.getArg(mapping, \"originalLine\", null),\n          column: util.getArg(mapping, \"originalColumn\", null),\n          name\n        };\n      }\n    }\n\n    return {\n      source: null,\n      line: null,\n      column: null,\n      name: null\n    };\n  }\n\n  /**\n   * Return true if we have the source content for every source in the source\n   * map, false otherwise.\n   */\n  hasContentsOfAllSources() {\n    if (!this.sourcesContent) {\n      return false;\n    }\n    return this.sourcesContent.length >= this._sources.size() &&\n      !this.sourcesContent.some(function(sc) { return sc == null; });\n  }\n\n  /**\n   * Returns the original source content. The only argument is the url of the\n   * original source file. Returns null if no original source content is\n   * available.\n   */\n  sourceContentFor(aSource, nullOnMissing) {\n    if (!this.sourcesContent) {\n      return null;\n    }\n\n    const index = this._findSourceIndex(aSource);\n    if (index >= 0) {\n      return this.sourcesContent[index];\n    }\n\n    let relativeSource = aSource;\n    if (this.sourceRoot != null) {\n      relativeSource = util.relative(this.sourceRoot, relativeSource);\n    }\n\n    let url;\n    if (this.sourceRoot != null\n        && (url = util.urlParse(this.sourceRoot))) {\n      // XXX: file:// URIs and absolute paths lead to unexpected behavior for\n      // many users. We can help them out when they expect file:// URIs to\n      // behave like it would if they were running a local HTTP server. See\n      // https://bugzilla.mozilla.org/show_bug.cgi?id=885597.\n      const fileUriAbsPath = relativeSource.replace(/^file:\\/\\//, \"\");\n      if (url.scheme == \"file\"\n          && this._sources.has(fileUriAbsPath)) {\n        return this.sourcesContent[this._sources.indexOf(fileUriAbsPath)];\n      }\n\n      if ((!url.path || url.path == \"/\")\n          && this._sources.has(\"/\" + relativeSource)) {\n        return this.sourcesContent[this._sources.indexOf(\"/\" + relativeSource)];\n      }\n    }\n\n    // This function is used recursively from\n    // IndexedSourceMapConsumer.prototype.sourceContentFor. In that case, we\n    // don't want to throw if we can't find the source - we just want to\n    // return null, so we provide a flag to exit gracefully.\n    if (nullOnMissing) {\n      return null;\n    }\n\n    throw new Error('\"' + relativeSource + '\" is not in the SourceMap.');\n  }\n\n  /**\n   * Returns the generated line and column information for the original source,\n   * line, and column positions provided. The only argument is an object with\n   * the following properties:\n   *\n   *   - source: The filename of the original source.\n   *   - line: The line number in the original source.  The line number\n   *     is 1-based.\n   *   - column: The column number in the original source.  The column\n   *     number is 0-based.\n   *   - bias: Either 'SourceMapConsumer.GREATEST_LOWER_BOUND' or\n   *     'SourceMapConsumer.LEAST_UPPER_BOUND'. Specifies whether to return the\n   *     closest element that is smaller than or greater than the one we are\n   *     searching for, respectively, if the exact element cannot be found.\n   *     Defaults to 'SourceMapConsumer.GREATEST_LOWER_BOUND'.\n   *\n   * and an object is returned with the following properties:\n   *\n   *   - line: The line number in the generated source, or null.  The\n   *     line number is 1-based.\n   *   - column: The column number in the generated source, or null.\n   *     The column number is 0-based.\n   */\n  generatedPositionFor(aArgs) {\n    let source = util.getArg(aArgs, \"source\");\n    source = this._findSourceIndex(source);\n    if (source < 0) {\n      return {\n        line: null,\n        column: null,\n        lastColumn: null\n      };\n    }\n\n    const needle = {\n      source,\n      originalLine: util.getArg(aArgs, \"line\"),\n      originalColumn: util.getArg(aArgs, \"column\")\n    };\n\n    if (needle.originalLine < 1) {\n      throw new Error(\"Line numbers must be >= 1\");\n    }\n\n    if (needle.originalColumn < 0) {\n      throw new Error(\"Column numbers must be >= 0\");\n    }\n\n    let bias = util.getArg(aArgs, \"bias\", SourceMapConsumer.GREATEST_LOWER_BOUND);\n    if (bias == null) {\n      bias = SourceMapConsumer.GREATEST_LOWER_BOUND;\n    }\n\n    let mapping;\n    this._wasm.withMappingCallback(m => mapping = m, () => {\n      this._wasm.exports.generated_location_for(\n        this._getMappingsPtr(),\n        needle.source,\n        needle.originalLine - 1,\n        needle.originalColumn,\n        bias\n      );\n    });\n\n    if (mapping) {\n      if (mapping.source === needle.source) {\n        let lastColumn = mapping.lastGeneratedColumn;\n        if (this._computedColumnSpans && lastColumn === null) {\n          lastColumn = Infinity;\n        }\n        return {\n          line: util.getArg(mapping, \"generatedLine\", null),\n          column: util.getArg(mapping, \"generatedColumn\", null),\n          lastColumn,\n        };\n      }\n    }\n\n    return {\n      line: null,\n      column: null,\n      lastColumn: null\n    };\n  }\n}\n\nBasicSourceMapConsumer.prototype.consumer = SourceMapConsumer;\nexports.BasicSourceMapConsumer = BasicSourceMapConsumer;\n\n/**\n * An IndexedSourceMapConsumer instance represents a parsed source map which\n * we can query for information. It differs from BasicSourceMapConsumer in\n * that it takes \"indexed\" source maps (i.e. ones with a \"sections\" field) as\n * input.\n *\n * The first parameter is a raw source map (either as a JSON string, or already\n * parsed to an object). According to the spec for indexed source maps, they\n * have the following attributes:\n *\n *   - version: Which version of the source map spec this map is following.\n *   - file: Optional. The generated file this source map is associated with.\n *   - sections: A list of section definitions.\n *\n * Each value under the \"sections\" field has two fields:\n *   - offset: The offset into the original specified at which this section\n *       begins to apply, defined as an object with a \"line\" and \"column\"\n *       field.\n *   - map: A source map definition. This source map could also be indexed,\n *       but doesn't have to be.\n *\n * Instead of the \"map\" field, it's also possible to have a \"url\" field\n * specifying a URL to retrieve a source map from, but that's currently\n * unsupported.\n *\n * Here's an example source map, taken from the source map spec[0], but\n * modified to omit a section which uses the \"url\" field.\n *\n *  {\n *    version : 3,\n *    file: \"app.js\",\n *    sections: [{\n *      offset: {line:100, column:10},\n *      map: {\n *        version : 3,\n *        file: \"section.js\",\n *        sources: [\"foo.js\", \"bar.js\"],\n *        names: [\"src\", \"maps\", \"are\", \"fun\"],\n *        mappings: \"AAAA,E;;ABCDE;\"\n *      }\n *    }],\n *  }\n *\n * The second parameter, if given, is a string whose value is the URL\n * at which the source map was found.  This URL is used to compute the\n * sources array.\n *\n * [0]: https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit#heading=h.535es3xeprgt\n */\nclass IndexedSourceMapConsumer extends SourceMapConsumer {\n  constructor(aSourceMap, aSourceMapURL) {\n    return super(INTERNAL).then(that => {\n      let sourceMap = aSourceMap;\n      if (typeof aSourceMap === \"string\") {\n        sourceMap = util.parseSourceMapInput(aSourceMap);\n      }\n\n      const version = util.getArg(sourceMap, \"version\");\n      const sections = util.getArg(sourceMap, \"sections\");\n\n      if (version != that._version) {\n        throw new Error(\"Unsupported version: \" + version);\n      }\n\n      that._sources = new ArraySet();\n      that._names = new ArraySet();\n      that.__generatedMappings = null;\n      that.__originalMappings = null;\n      that.__generatedMappingsUnsorted = null;\n      that.__originalMappingsUnsorted = null;\n\n      let lastOffset = {\n        line: -1,\n        column: 0\n      };\n      return Promise.all(sections.map(s => {\n        if (s.url) {\n          // The url field will require support for asynchronicity.\n          // See https://github.com/mozilla/source-map/issues/16\n          throw new Error(\"Support for url field in sections not implemented.\");\n        }\n        const offset = util.getArg(s, \"offset\");\n        const offsetLine = util.getArg(offset, \"line\");\n        const offsetColumn = util.getArg(offset, \"column\");\n\n        if (offsetLine < lastOffset.line ||\n            (offsetLine === lastOffset.line && offsetColumn < lastOffset.column)) {\n          throw new Error(\"Section offsets must be ordered and non-overlapping.\");\n        }\n        lastOffset = offset;\n\n        const cons = new SourceMapConsumer(util.getArg(s, \"map\"), aSourceMapURL);\n        return cons.then(consumer => {\n          return {\n            generatedOffset: {\n              // The offset fields are 0-based, but we use 1-based indices when\n              // encoding/decoding from VLQ.\n              generatedLine: offsetLine + 1,\n              generatedColumn: offsetColumn + 1\n            },\n            consumer\n          };\n        });\n      })).then(s => {\n        that._sections = s;\n        return that;\n      });\n    });\n  }\n\n  // `__generatedMappings` and `__originalMappings` are arrays that hold the\n  // parsed mapping coordinates from the source map's \"mappings\" attribute. They\n  // are lazily instantiated, accessed via the `_generatedMappings` and\n  // `_originalMappings` getters respectively, and we only parse the mappings\n  // and create these arrays once queried for a source location. We jump through\n  // these hoops because there can be many thousands of mappings, and parsing\n  // them is expensive, so we only want to do it if we must.\n  //\n  // Each object in the arrays is of the form:\n  //\n  //     {\n  //       generatedLine: The line number in the generated code,\n  //       generatedColumn: The column number in the generated code,\n  //       source: The path to the original source file that generated this\n  //               chunk of code,\n  //       originalLine: The line number in the original source that\n  //                     corresponds to this chunk of generated code,\n  //       originalColumn: The column number in the original source that\n  //                       corresponds to this chunk of generated code,\n  //       name: The name of the original symbol which generated this chunk of\n  //             code.\n  //     }\n  //\n  // All properties except for `generatedLine` and `generatedColumn` can be\n  // `null`.\n  //\n  // `_generatedMappings` is ordered by the generated positions.\n  //\n  // `_originalMappings` is ordered by the original positions.\n  get _generatedMappings() {\n    if (!this.__generatedMappings) {\n      this._sortGeneratedMappings();\n    }\n\n    return this.__generatedMappings;\n  }\n\n  get _originalMappings() {\n    if (!this.__originalMappings) {\n      this._sortOriginalMappings();\n    }\n\n    return this.__originalMappings;\n  }\n\n  get _generatedMappingsUnsorted() {\n    if (!this.__generatedMappingsUnsorted) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__generatedMappingsUnsorted;\n  }\n\n  get _originalMappingsUnsorted() {\n    if (!this.__originalMappingsUnsorted) {\n      this._parseMappings(this._mappings, this.sourceRoot);\n    }\n\n    return this.__originalMappingsUnsorted;\n  }\n\n  _sortGeneratedMappings() {\n    const mappings = this._generatedMappingsUnsorted;\n    mappings.sort(util.compareByGeneratedPositionsDeflated);\n    this.__generatedMappings = mappings;\n  }\n\n  _sortOriginalMappings() {\n    const mappings = this._originalMappingsUnsorted;\n    mappings.sort(util.compareByOriginalPositions);\n    this.__originalMappings = mappings;\n  }\n\n  /**\n   * The list of original sources.\n   */\n  get sources() {\n    const sources = [];\n    for (let i = 0; i < this._sections.length; i++) {\n      for (let j = 0; j < this._sections[i].consumer.sources.length; j++) {\n        sources.push(this._sections[i].consumer.sources[j]);\n      }\n    }\n    return sources;\n  }\n\n  /**\n   * Returns the original source, line, and column information for the generated\n   * source's line and column positions provided. The only argument is an object\n   * with the following properties:\n   *\n   *   - line: The line number in the generated source.  The line number\n   *     is 1-based.\n   *   - column: The column number in the generated source.  The column\n   *     number is 0-based.\n   *\n   * and an object is returned with the following properties:\n   *\n   *   - source: The original source file, or null.\n   *   - line: The line number in the original source, or null.  The\n   *     line number is 1-based.\n   *   - column: The column number in the original source, or null.  The\n   *     column number is 0-based.\n   *   - name: The original identifier, or null.\n   */\n  originalPositionFor(aArgs) {\n    const needle = {\n      generatedLine: util.getArg(aArgs, \"line\"),\n      generatedColumn: util.getArg(aArgs, \"column\")\n    };\n\n    // Find the section containing the generated position we're trying to map\n    // to an original position.\n    const sectionIndex = binarySearch.search(needle, this._sections,\n      function(aNeedle, section) {\n        const cmp = aNeedle.generatedLine - section.generatedOffset.generatedLine;\n        if (cmp) {\n          return cmp;\n        }\n\n        return (aNeedle.generatedColumn -\n                section.generatedOffset.generatedColumn);\n      });\n    const section = this._sections[sectionIndex];\n\n    if (!section) {\n      return {\n        source: null,\n        line: null,\n        column: null,\n        name: null\n      };\n    }\n\n    return section.consumer.originalPositionFor({\n      line: needle.generatedLine -\n        (section.generatedOffset.generatedLine - 1),\n      column: needle.generatedColumn -\n        (section.generatedOffset.generatedLine === needle.generatedLine\n         ? section.generatedOffset.generatedColumn - 1\n         : 0),\n      bias: aArgs.bias\n    });\n  }\n\n  /**\n   * Return true if we have the source content for every source in the source\n   * map, false otherwise.\n   */\n  hasContentsOfAllSources() {\n    return this._sections.every(function(s) {\n      return s.consumer.hasContentsOfAllSources();\n    });\n  }\n\n  /**\n   * Returns the original source content. The only argument is the url of the\n   * original source file. Returns null if no original source content is\n   * available.\n   */\n  sourceContentFor(aSource, nullOnMissing) {\n    for (let i = 0; i < this._sections.length; i++) {\n      const section = this._sections[i];\n\n      const content = section.consumer.sourceContentFor(aSource, true);\n      if (content) {\n        return content;\n      }\n    }\n    if (nullOnMissing) {\n      return null;\n    }\n    throw new Error('\"' + aSource + '\" is not in the SourceMap.');\n  }\n\n  /**\n   * Returns the generated line and column information for the original source,\n   * line, and column positions provided. The only argument is an object with\n   * the following properties:\n   *\n   *   - source: The filename of the original source.\n   *   - line: The line number in the original source.  The line number\n   *     is 1-based.\n   *   - column: The column number in the original source.  The column\n   *     number is 0-based.\n   *\n   * and an object is returned with the following properties:\n   *\n   *   - line: The line number in the generated source, or null.  The\n   *     line number is 1-based.\n   *   - column: The column number in the generated source, or null.\n   *     The column number is 0-based.\n   */\n  generatedPositionFor(aArgs) {\n    for (let i = 0; i < this._sections.length; i++) {\n      const section = this._sections[i];\n\n      // Only consider this section if the requested source is in the list of\n      // sources of the consumer.\n      if (section.consumer._findSourceIndex(util.getArg(aArgs, \"source\")) === -1) {\n        continue;\n      }\n      const generatedPosition = section.consumer.generatedPositionFor(aArgs);\n      if (generatedPosition) {\n        const ret = {\n          line: generatedPosition.line +\n            (section.generatedOffset.generatedLine - 1),\n          column: generatedPosition.column +\n            (section.generatedOffset.generatedLine === generatedPosition.line\n             ? section.generatedOffset.generatedColumn - 1\n             : 0)\n        };\n        return ret;\n      }\n    }\n\n    return {\n      line: null,\n      column: null\n    };\n  }\n\n  /**\n   * Parse the mappings in a string in to a data structure which we can easily\n   * query (the ordered arrays in the `this.__generatedMappings` and\n   * `this.__originalMappings` properties).\n   */\n  _parseMappings(aStr, aSourceRoot) {\n    const generatedMappings = this.__generatedMappingsUnsorted = [];\n    const originalMappings = this.__originalMappingsUnsorted = [];\n    for (let i = 0; i < this._sections.length; i++) {\n      const section = this._sections[i];\n\n      const sectionMappings = [];\n      section.consumer.eachMapping(m => sectionMappings.push(m));\n\n      for (let j = 0; j < sectionMappings.length; j++) {\n        const mapping = sectionMappings[j];\n\n        // TODO: test if null is correct here.  The original code used\n        // `source`, which would actually have gotten used as null because\n        // var's get hoisted.\n        // See: https://github.com/mozilla/source-map/issues/333\n        let source = util.computeSourceURL(section.consumer.sourceRoot, null, this._sourceMapURL);\n        this._sources.add(source);\n        source = this._sources.indexOf(source);\n\n        let name = null;\n        if (mapping.name) {\n          this._names.add(mapping.name);\n          name = this._names.indexOf(mapping.name);\n        }\n\n        // The mappings coming from the consumer for the section have\n        // generated positions relative to the start of the section, so we\n        // need to offset them to be relative to the start of the concatenated\n        // generated file.\n        const adjustedMapping = {\n          source,\n          generatedLine: mapping.generatedLine +\n            (section.generatedOffset.generatedLine - 1),\n          generatedColumn: mapping.generatedColumn +\n            (section.generatedOffset.generatedLine === mapping.generatedLine\n            ? section.generatedOffset.generatedColumn - 1\n            : 0),\n          originalLine: mapping.originalLine,\n          originalColumn: mapping.originalColumn,\n          name\n        };\n\n        generatedMappings.push(adjustedMapping);\n        if (typeof adjustedMapping.originalLine === \"number\") {\n          originalMappings.push(adjustedMapping);\n        }\n      }\n    }\n  }\n\n  eachMapping(aCallback, aContext, aOrder) {\n    const context = aContext || null;\n    const order = aOrder || SourceMapConsumer.GENERATED_ORDER;\n\n    let mappings;\n    switch (order) {\n    case SourceMapConsumer.GENERATED_ORDER:\n      mappings = this._generatedMappings;\n      break;\n    case SourceMapConsumer.ORIGINAL_ORDER:\n      mappings = this._originalMappings;\n      break;\n    default:\n      throw new Error(\"Unknown order of iteration.\");\n    }\n\n    const sourceRoot = this.sourceRoot;\n    mappings.map(function(mapping) {\n      let source = null;\n      if (mapping.source !== null) {\n        source = this._sources.at(mapping.source);\n        source = util.computeSourceURL(sourceRoot, source, this._sourceMapURL);\n      }\n      return {\n        source,\n        generatedLine: mapping.generatedLine,\n        generatedColumn: mapping.generatedColumn,\n        originalLine: mapping.originalLine,\n        originalColumn: mapping.originalColumn,\n        name: mapping.name === null ? null : this._names.at(mapping.name)\n      };\n    }, this).forEach(aCallback, context);\n  }\n\n  /**\n   * Find the mapping that best matches the hypothetical \"needle\" mapping that\n   * we are searching for in the given \"haystack\" of mappings.\n   */\n  _findMapping(aNeedle, aMappings, aLineName,\n              aColumnName, aComparator, aBias) {\n    // To return the position we are searching for, we must first find the\n    // mapping for the given position and then return the opposite position it\n    // points to. Because the mappings are sorted, we can use binary search to\n    // find the best mapping.\n\n    if (aNeedle[aLineName] <= 0) {\n      throw new TypeError(\"Line must be greater than or equal to 1, got \"\n                          + aNeedle[aLineName]);\n    }\n    if (aNeedle[aColumnName] < 0) {\n      throw new TypeError(\"Column must be greater than or equal to 0, got \"\n                          + aNeedle[aColumnName]);\n    }\n\n    return binarySearch.search(aNeedle, aMappings, aComparator, aBias);\n  }\n\n  allGeneratedPositionsFor(aArgs) {\n    const line = util.getArg(aArgs, \"line\");\n\n    // When there is no exact match, BasicSourceMapConsumer.prototype._findMapping\n    // returns the index of the closest mapping less than the needle. By\n    // setting needle.originalColumn to 0, we thus find the last mapping for\n    // the given line, provided such a mapping exists.\n    const needle = {\n      source: util.getArg(aArgs, \"source\"),\n      originalLine: line,\n      originalColumn: util.getArg(aArgs, \"column\", 0)\n    };\n\n    needle.source = this._findSourceIndex(needle.source);\n    if (needle.source < 0) {\n      return [];\n    }\n\n    if (needle.originalLine < 1) {\n      throw new Error(\"Line numbers must be >= 1\");\n    }\n\n    if (needle.originalColumn < 0) {\n      throw new Error(\"Column numbers must be >= 0\");\n    }\n\n    const mappings = [];\n\n    let index = this._findMapping(needle,\n                                  this._originalMappings,\n                                  \"originalLine\",\n                                  \"originalColumn\",\n                                  util.compareByOriginalPositions,\n                                  binarySearch.LEAST_UPPER_BOUND);\n    if (index >= 0) {\n      let mapping = this._originalMappings[index];\n\n      if (aArgs.column === undefined) {\n        const originalLine = mapping.originalLine;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we found. Since\n        // mappings are sorted, this is guaranteed to find all mappings for\n        // the line we found.\n        while (mapping && mapping.originalLine === originalLine) {\n          let lastColumn = mapping.lastGeneratedColumn;\n          if (this._computedColumnSpans && lastColumn === null) {\n            lastColumn = Infinity;\n          }\n          mappings.push({\n            line: util.getArg(mapping, \"generatedLine\", null),\n            column: util.getArg(mapping, \"generatedColumn\", null),\n            lastColumn,\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      } else {\n        const originalColumn = mapping.originalColumn;\n\n        // Iterate until either we run out of mappings, or we run into\n        // a mapping for a different line than the one we were searching for.\n        // Since mappings are sorted, this is guaranteed to find all mappings for\n        // the line we are searching for.\n        while (mapping &&\n               mapping.originalLine === line &&\n               mapping.originalColumn == originalColumn) {\n          let lastColumn = mapping.lastGeneratedColumn;\n          if (this._computedColumnSpans && lastColumn === null) {\n            lastColumn = Infinity;\n          }\n          mappings.push({\n            line: util.getArg(mapping, \"generatedLine\", null),\n            column: util.getArg(mapping, \"generatedColumn\", null),\n            lastColumn,\n          });\n\n          mapping = this._originalMappings[++index];\n        }\n      }\n    }\n\n    return mappings;\n  }\n\n  destroy() {\n    for (let i = 0; i < this._sections.length; i++) {\n      this._sections[i].consumer.destroy();\n    }\n  }\n}\nexports.IndexedSourceMapConsumer = IndexedSourceMapConsumer;\n\n/*\n * Cheat to get around inter-twingled classes.  `factory()` can be at the end\n * where it has access to non-hoisted classes, but it gets hoisted itself.\n */\nfunction _factory(aSourceMap, aSourceMapURL) {\n  let sourceMap = aSourceMap;\n  if (typeof aSourceMap === \"string\") {\n    sourceMap = util.parseSourceMapInput(aSourceMap);\n  }\n\n  const consumer = sourceMap.sections != null\n      ? new IndexedSourceMapConsumer(sourceMap, aSourceMapURL)\n      : new BasicSourceMapConsumer(sourceMap, aSourceMapURL);\n  return Promise.resolve(consumer);\n}\n\nfunction _factoryBSM(aSourceMap, aSourceMapURL) {\n  return BasicSourceMapConsumer.fromSourceMap(aSourceMap, aSourceMapURL);\n}\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nconst base64VLQ = require(\"./base64-vlq\");\nconst util = require(\"./util\");\nconst ArraySet = require(\"./array-set\").ArraySet;\nconst MappingList = require(\"./mapping-list\").MappingList;\n\n/**\n * An instance of the SourceMapGenerator represents a source map which is\n * being built incrementally. You may pass an object with the following\n * properties:\n *\n *   - file: The filename of the generated source.\n *   - sourceRoot: A root for all relative URLs in this source map.\n */\nclass SourceMapGenerator {\n  constructor(aArgs) {\n    if (!aArgs) {\n      aArgs = {};\n    }\n    this._file = util.getArg(aArgs, \"file\", null);\n    this._sourceRoot = util.getArg(aArgs, \"sourceRoot\", null);\n    this._skipValidation = util.getArg(aArgs, \"skipValidation\", false);\n    this._sources = new ArraySet();\n    this._names = new ArraySet();\n    this._mappings = new MappingList();\n    this._sourcesContents = null;\n  }\n\n  /**\n   * Creates a new SourceMapGenerator based on a SourceMapConsumer\n   *\n   * @param aSourceMapConsumer The SourceMap.\n   */\n  static fromSourceMap(aSourceMapConsumer) {\n    const sourceRoot = aSourceMapConsumer.sourceRoot;\n    const generator = new SourceMapGenerator({\n      file: aSourceMapConsumer.file,\n      sourceRoot\n    });\n    aSourceMapConsumer.eachMapping(function(mapping) {\n      const newMapping = {\n        generated: {\n          line: mapping.generatedLine,\n          column: mapping.generatedColumn\n        }\n      };\n\n      if (mapping.source != null) {\n        newMapping.source = mapping.source;\n        if (sourceRoot != null) {\n          newMapping.source = util.relative(sourceRoot, newMapping.source);\n        }\n\n        newMapping.original = {\n          line: mapping.originalLine,\n          column: mapping.originalColumn\n        };\n\n        if (mapping.name != null) {\n          newMapping.name = mapping.name;\n        }\n      }\n\n      generator.addMapping(newMapping);\n    });\n    aSourceMapConsumer.sources.forEach(function(sourceFile) {\n      let sourceRelative = sourceFile;\n      if (sourceRoot !== null) {\n        sourceRelative = util.relative(sourceRoot, sourceFile);\n      }\n\n      if (!generator._sources.has(sourceRelative)) {\n        generator._sources.add(sourceRelative);\n      }\n\n      const content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        generator.setSourceContent(sourceFile, content);\n      }\n    });\n    return generator;\n  }\n\n  /**\n   * Add a single mapping from original source line and column to the generated\n   * source's line and column for this source map being created. The mapping\n   * object should have the following properties:\n   *\n   *   - generated: An object with the generated line and column positions.\n   *   - original: An object with the original line and column positions.\n   *   - source: The original source file (relative to the sourceRoot).\n   *   - name: An optional original token name for this mapping.\n   */\n  addMapping(aArgs) {\n    const generated = util.getArg(aArgs, \"generated\");\n    const original = util.getArg(aArgs, \"original\", null);\n    let source = util.getArg(aArgs, \"source\", null);\n    let name = util.getArg(aArgs, \"name\", null);\n\n    if (!this._skipValidation) {\n      this._validateMapping(generated, original, source, name);\n    }\n\n    if (source != null) {\n      source = String(source);\n      if (!this._sources.has(source)) {\n        this._sources.add(source);\n      }\n    }\n\n    if (name != null) {\n      name = String(name);\n      if (!this._names.has(name)) {\n        this._names.add(name);\n      }\n    }\n\n    this._mappings.add({\n      generatedLine: generated.line,\n      generatedColumn: generated.column,\n      originalLine: original != null && original.line,\n      originalColumn: original != null && original.column,\n      source,\n      name\n    });\n  }\n\n  /**\n   * Set the source content for a source file.\n   */\n  setSourceContent(aSourceFile, aSourceContent) {\n    let source = aSourceFile;\n    if (this._sourceRoot != null) {\n      source = util.relative(this._sourceRoot, source);\n    }\n\n    if (aSourceContent != null) {\n      // Add the source content to the _sourcesContents map.\n      // Create a new _sourcesContents map if the property is null.\n      if (!this._sourcesContents) {\n        this._sourcesContents = Object.create(null);\n      }\n      this._sourcesContents[util.toSetString(source)] = aSourceContent;\n    } else if (this._sourcesContents) {\n      // Remove the source file from the _sourcesContents map.\n      // If the _sourcesContents map is empty, set the property to null.\n      delete this._sourcesContents[util.toSetString(source)];\n      if (Object.keys(this._sourcesContents).length === 0) {\n        this._sourcesContents = null;\n      }\n    }\n  }\n\n  /**\n   * Applies the mappings of a sub-source-map for a specific source file to the\n   * source map being generated. Each mapping to the supplied source file is\n   * rewritten using the supplied source map. Note: The resolution for the\n   * resulting mappings is the minimium of this map and the supplied map.\n   *\n   * @param aSourceMapConsumer The source map to be applied.\n   * @param aSourceFile Optional. The filename of the source file.\n   *        If omitted, SourceMapConsumer's file property will be used.\n   * @param aSourceMapPath Optional. The dirname of the path to the source map\n   *        to be applied. If relative, it is relative to the SourceMapConsumer.\n   *        This parameter is needed when the two source maps aren't in the same\n   *        directory, and the source map to be applied contains relative source\n   *        paths. If so, those relative source paths need to be rewritten\n   *        relative to the SourceMapGenerator.\n   */\n  applySourceMap(aSourceMapConsumer, aSourceFile, aSourceMapPath) {\n    let sourceFile = aSourceFile;\n    // If aSourceFile is omitted, we will use the file property of the SourceMap\n    if (aSourceFile == null) {\n      if (aSourceMapConsumer.file == null) {\n        throw new Error(\n          \"SourceMapGenerator.prototype.applySourceMap requires either an explicit source file, \" +\n          'or the source map\\'s \"file\" property. Both were omitted.'\n        );\n      }\n      sourceFile = aSourceMapConsumer.file;\n    }\n    const sourceRoot = this._sourceRoot;\n    // Make \"sourceFile\" relative if an absolute Url is passed.\n    if (sourceRoot != null) {\n      sourceFile = util.relative(sourceRoot, sourceFile);\n    }\n    // Applying the SourceMap can add and remove items from the sources and\n    // the names array.\n    const newSources = this._mappings.toArray().length > 0\n      ? new ArraySet()\n      : this._sources;\n    const newNames = new ArraySet();\n\n    // Find mappings for the \"sourceFile\"\n    this._mappings.unsortedForEach(function(mapping) {\n      if (mapping.source === sourceFile && mapping.originalLine != null) {\n        // Check if it can be mapped by the source map, then update the mapping.\n        const original = aSourceMapConsumer.originalPositionFor({\n          line: mapping.originalLine,\n          column: mapping.originalColumn\n        });\n        if (original.source != null) {\n          // Copy mapping\n          mapping.source = original.source;\n          if (aSourceMapPath != null) {\n            mapping.source = util.join(aSourceMapPath, mapping.source);\n          }\n          if (sourceRoot != null) {\n            mapping.source = util.relative(sourceRoot, mapping.source);\n          }\n          mapping.originalLine = original.line;\n          mapping.originalColumn = original.column;\n          if (original.name != null) {\n            mapping.name = original.name;\n          }\n        }\n      }\n\n      const source = mapping.source;\n      if (source != null && !newSources.has(source)) {\n        newSources.add(source);\n      }\n\n      const name = mapping.name;\n      if (name != null && !newNames.has(name)) {\n        newNames.add(name);\n      }\n\n    }, this);\n    this._sources = newSources;\n    this._names = newNames;\n\n    // Copy sourcesContents of applied map.\n    aSourceMapConsumer.sources.forEach(function(srcFile) {\n      const content = aSourceMapConsumer.sourceContentFor(srcFile);\n      if (content != null) {\n        if (aSourceMapPath != null) {\n          srcFile = util.join(aSourceMapPath, srcFile);\n        }\n        if (sourceRoot != null) {\n          srcFile = util.relative(sourceRoot, srcFile);\n        }\n        this.setSourceContent(srcFile, content);\n      }\n    }, this);\n  }\n\n  /**\n   * A mapping can have one of the three levels of data:\n   *\n   *   1. Just the generated position.\n   *   2. The Generated position, original position, and original source.\n   *   3. Generated and original position, original source, as well as a name\n   *      token.\n   *\n   * To maintain consistency, we validate that any new mapping being added falls\n   * in to one of these categories.\n   */\n  _validateMapping(aGenerated, aOriginal, aSource, aName) {\n    // When aOriginal is truthy but has empty values for .line and .column,\n    // it is most likely a programmer error. In this case we throw a very\n    // specific error message to try to guide them the right way.\n    // For example: https://github.com/Polymer/polymer-bundler/pull/519\n    if (aOriginal && typeof aOriginal.line !== \"number\" && typeof aOriginal.column !== \"number\") {\n        throw new Error(\n            \"original.line and original.column are not numbers -- you probably meant to omit \" +\n            \"the original mapping entirely and only map the generated position. If so, pass \" +\n            \"null for the original mapping instead of an object with empty or null values.\"\n        );\n    }\n\n    if (aGenerated && \"line\" in aGenerated && \"column\" in aGenerated\n        && aGenerated.line > 0 && aGenerated.column >= 0\n        && !aOriginal && !aSource && !aName) {\n      // Case 1.\n\n    } else if (aGenerated && \"line\" in aGenerated && \"column\" in aGenerated\n             && aOriginal && \"line\" in aOriginal && \"column\" in aOriginal\n             && aGenerated.line > 0 && aGenerated.column >= 0\n             && aOriginal.line > 0 && aOriginal.column >= 0\n             && aSource) {\n      // Cases 2 and 3.\n\n    } else {\n      throw new Error(\"Invalid mapping: \" + JSON.stringify({\n        generated: aGenerated,\n        source: aSource,\n        original: aOriginal,\n        name: aName\n      }));\n    }\n  }\n\n  /**\n   * Serialize the accumulated mappings in to the stream of base 64 VLQs\n   * specified by the source map format.\n   */\n  _serializeMappings() {\n    let previousGeneratedColumn = 0;\n    let previousGeneratedLine = 1;\n    let previousOriginalColumn = 0;\n    let previousOriginalLine = 0;\n    let previousName = 0;\n    let previousSource = 0;\n    let result = \"\";\n    let next;\n    let mapping;\n    let nameIdx;\n    let sourceIdx;\n\n    const mappings = this._mappings.toArray();\n    for (let i = 0, len = mappings.length; i < len; i++) {\n      mapping = mappings[i];\n      next = \"\";\n\n      if (mapping.generatedLine !== previousGeneratedLine) {\n        previousGeneratedColumn = 0;\n        while (mapping.generatedLine !== previousGeneratedLine) {\n          next += \";\";\n          previousGeneratedLine++;\n        }\n      } else if (i > 0) {\n        if (!util.compareByGeneratedPositionsInflated(mapping, mappings[i - 1])) {\n          continue;\n        }\n        next += \",\";\n      }\n\n      next += base64VLQ.encode(mapping.generatedColumn\n                                 - previousGeneratedColumn);\n      previousGeneratedColumn = mapping.generatedColumn;\n\n      if (mapping.source != null) {\n        sourceIdx = this._sources.indexOf(mapping.source);\n        next += base64VLQ.encode(sourceIdx - previousSource);\n        previousSource = sourceIdx;\n\n        // lines are stored 0-based in SourceMap spec version 3\n        next += base64VLQ.encode(mapping.originalLine - 1\n                                   - previousOriginalLine);\n        previousOriginalLine = mapping.originalLine - 1;\n\n        next += base64VLQ.encode(mapping.originalColumn\n                                   - previousOriginalColumn);\n        previousOriginalColumn = mapping.originalColumn;\n\n        if (mapping.name != null) {\n          nameIdx = this._names.indexOf(mapping.name);\n          next += base64VLQ.encode(nameIdx - previousName);\n          previousName = nameIdx;\n        }\n      }\n\n      result += next;\n    }\n\n    return result;\n  }\n\n  _generateSourcesContent(aSources, aSourceRoot) {\n    return aSources.map(function(source) {\n      if (!this._sourcesContents) {\n        return null;\n      }\n      if (aSourceRoot != null) {\n        source = util.relative(aSourceRoot, source);\n      }\n      const key = util.toSetString(source);\n      return Object.prototype.hasOwnProperty.call(this._sourcesContents, key)\n        ? this._sourcesContents[key]\n        : null;\n    }, this);\n  }\n\n  /**\n   * Externalize the source map.\n   */\n  toJSON() {\n    const map = {\n      version: this._version,\n      sources: this._sources.toArray(),\n      names: this._names.toArray(),\n      mappings: this._serializeMappings()\n    };\n    if (this._file != null) {\n      map.file = this._file;\n    }\n    if (this._sourceRoot != null) {\n      map.sourceRoot = this._sourceRoot;\n    }\n    if (this._sourcesContents) {\n      map.sourcesContent = this._generateSourcesContent(map.sources, map.sourceRoot);\n    }\n\n    return map;\n  }\n\n  /**\n   * Render the source map being generated to a string.\n   */\n  toString() {\n    return JSON.stringify(this.toJSON());\n  }\n}\n\nSourceMapGenerator.prototype._version = 3;\nexports.SourceMapGenerator = SourceMapGenerator;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\nconst SourceMapGenerator = require(\"./source-map-generator\").SourceMapGenerator;\nconst util = require(\"./util\");\n\n// Matches a Windows-style `\\r\\n` newline or a `\\n` newline used by all other\n// operating systems these days (capturing the result).\nconst REGEX_NEWLINE = /(\\r?\\n)/;\n\n// Newline character code for charCodeAt() comparisons\nconst NEWLINE_CODE = 10;\n\n// Private symbol for identifying `SourceNode`s when multiple versions of\n// the source-map library are loaded. This MUST NOT CHANGE across\n// versions!\nconst isSourceNode = \"$$$isSourceNode$$$\";\n\n/**\n * SourceNodes provide a way to abstract over interpolating/concatenating\n * snippets of generated JavaScript source code while maintaining the line and\n * column information associated with the original source code.\n *\n * @param aLine The original line number.\n * @param aColumn The original column number.\n * @param aSource The original source's filename.\n * @param aChunks Optional. An array of strings which are snippets of\n *        generated JS, or other SourceNodes.\n * @param aName The original identifier.\n */\nclass SourceNode {\n  constructor(aLine, aColumn, aSource, aChunks, aName) {\n    this.children = [];\n    this.sourceContents = {};\n    this.line = aLine == null ? null : aLine;\n    this.column = aColumn == null ? null : aColumn;\n    this.source = aSource == null ? null : aSource;\n    this.name = aName == null ? null : aName;\n    this[isSourceNode] = true;\n    if (aChunks != null) this.add(aChunks);\n  }\n\n  /**\n   * Creates a SourceNode from generated code and a SourceMapConsumer.\n   *\n   * @param aGeneratedCode The generated code\n   * @param aSourceMapConsumer The SourceMap for the generated code\n   * @param aRelativePath Optional. The path that relative sources in the\n   *        SourceMapConsumer should be relative to.\n   */\n  static fromStringWithSourceMap(aGeneratedCode, aSourceMapConsumer, aRelativePath) {\n    // The SourceNode we want to fill with the generated code\n    // and the SourceMap\n    const node = new SourceNode();\n\n    // All even indices of this array are one line of the generated code,\n    // while all odd indices are the newlines between two adjacent lines\n    // (since `REGEX_NEWLINE` captures its match).\n    // Processed fragments are accessed by calling `shiftNextLine`.\n    const remainingLines = aGeneratedCode.split(REGEX_NEWLINE);\n    let remainingLinesIndex = 0;\n    const shiftNextLine = function() {\n      const lineContents = getNextLine();\n      // The last line of a file might not have a newline.\n      const newLine = getNextLine() || \"\";\n      return lineContents + newLine;\n\n      function getNextLine() {\n        return remainingLinesIndex < remainingLines.length ?\n            remainingLines[remainingLinesIndex++] : undefined;\n      }\n    };\n\n    // We need to remember the position of \"remainingLines\"\n    let lastGeneratedLine = 1, lastGeneratedColumn = 0;\n\n    // The generate SourceNodes we need a code range.\n    // To extract it current and last mapping is used.\n    // Here we store the last mapping.\n    let lastMapping = null;\n    let nextLine;\n\n    aSourceMapConsumer.eachMapping(function(mapping) {\n      if (lastMapping !== null) {\n        // We add the code from \"lastMapping\" to \"mapping\":\n        // First check if there is a new line in between.\n        if (lastGeneratedLine < mapping.generatedLine) {\n          // Associate first line with \"lastMapping\"\n          addMappingWithCode(lastMapping, shiftNextLine());\n          lastGeneratedLine++;\n          lastGeneratedColumn = 0;\n          // The remaining code is added without mapping\n        } else {\n          // There is no new line in between.\n          // Associate the code between \"lastGeneratedColumn\" and\n          // \"mapping.generatedColumn\" with \"lastMapping\"\n          nextLine = remainingLines[remainingLinesIndex] || \"\";\n          const code = nextLine.substr(0, mapping.generatedColumn -\n                                        lastGeneratedColumn);\n          remainingLines[remainingLinesIndex] = nextLine.substr(mapping.generatedColumn -\n                                              lastGeneratedColumn);\n          lastGeneratedColumn = mapping.generatedColumn;\n          addMappingWithCode(lastMapping, code);\n          // No more remaining code, continue\n          lastMapping = mapping;\n          return;\n        }\n      }\n      // We add the generated code until the first mapping\n      // to the SourceNode without any mapping.\n      // Each line is added as separate string.\n      while (lastGeneratedLine < mapping.generatedLine) {\n        node.add(shiftNextLine());\n        lastGeneratedLine++;\n      }\n      if (lastGeneratedColumn < mapping.generatedColumn) {\n        nextLine = remainingLines[remainingLinesIndex] || \"\";\n        node.add(nextLine.substr(0, mapping.generatedColumn));\n        remainingLines[remainingLinesIndex] = nextLine.substr(mapping.generatedColumn);\n        lastGeneratedColumn = mapping.generatedColumn;\n      }\n      lastMapping = mapping;\n    }, this);\n    // We have processed all mappings.\n    if (remainingLinesIndex < remainingLines.length) {\n      if (lastMapping) {\n        // Associate the remaining code in the current line with \"lastMapping\"\n        addMappingWithCode(lastMapping, shiftNextLine());\n      }\n      // and add the remaining lines without any mapping\n      node.add(remainingLines.splice(remainingLinesIndex).join(\"\"));\n    }\n\n    // Copy sourcesContent into SourceNode\n    aSourceMapConsumer.sources.forEach(function(sourceFile) {\n      const content = aSourceMapConsumer.sourceContentFor(sourceFile);\n      if (content != null) {\n        if (aRelativePath != null) {\n          sourceFile = util.join(aRelativePath, sourceFile);\n        }\n        node.setSourceContent(sourceFile, content);\n      }\n    });\n\n    return node;\n\n    function addMappingWithCode(mapping, code) {\n      if (mapping === null || mapping.source === undefined) {\n        node.add(code);\n      } else {\n        const source = aRelativePath\n          ? util.join(aRelativePath, mapping.source)\n          : mapping.source;\n        node.add(new SourceNode(mapping.originalLine,\n                                mapping.originalColumn,\n                                source,\n                                code,\n                                mapping.name));\n      }\n    }\n  }\n\n  /**\n   * Add a chunk of generated JS to this source node.\n   *\n   * @param aChunk A string snippet of generated JS code, another instance of\n   *        SourceNode, or an array where each member is one of those things.\n   */\n  add(aChunk) {\n    if (Array.isArray(aChunk)) {\n      aChunk.forEach(function(chunk) {\n        this.add(chunk);\n      }, this);\n    } else if (aChunk[isSourceNode] || typeof aChunk === \"string\") {\n      if (aChunk) {\n        this.children.push(aChunk);\n      }\n    } else {\n      throw new TypeError(\n        \"Expected a SourceNode, string, or an array of SourceNodes and strings. Got \" + aChunk\n      );\n    }\n    return this;\n  }\n\n  /**\n   * Add a chunk of generated JS to the beginning of this source node.\n   *\n   * @param aChunk A string snippet of generated JS code, another instance of\n   *        SourceNode, or an array where each member is one of those things.\n   */\n  prepend(aChunk) {\n    if (Array.isArray(aChunk)) {\n      for (let i = aChunk.length - 1; i >= 0; i--) {\n        this.prepend(aChunk[i]);\n      }\n    } else if (aChunk[isSourceNode] || typeof aChunk === \"string\") {\n      this.children.unshift(aChunk);\n    } else {\n      throw new TypeError(\n        \"Expected a SourceNode, string, or an array of SourceNodes and strings. Got \" + aChunk\n      );\n    }\n    return this;\n  }\n\n  /**\n   * Walk over the tree of JS snippets in this node and its children. The\n   * walking function is called once for each snippet of JS and is passed that\n   * snippet and the its original associated source's line/column location.\n   *\n   * @param aFn The traversal function.\n   */\n  walk(aFn) {\n    let chunk;\n    for (let i = 0, len = this.children.length; i < len; i++) {\n      chunk = this.children[i];\n      if (chunk[isSourceNode]) {\n        chunk.walk(aFn);\n      } else if (chunk !== \"\") {\n        aFn(chunk, { source: this.source,\n                      line: this.line,\n                      column: this.column,\n                      name: this.name });\n      }\n    }\n  }\n\n  /**\n   * Like `String.prototype.join` except for SourceNodes. Inserts `aStr` between\n   * each of `this.children`.\n   *\n   * @param aSep The separator.\n   */\n  join(aSep) {\n    let newChildren;\n    let i;\n    const len = this.children.length;\n    if (len > 0) {\n      newChildren = [];\n      for (i = 0; i < len - 1; i++) {\n        newChildren.push(this.children[i]);\n        newChildren.push(aSep);\n      }\n      newChildren.push(this.children[i]);\n      this.children = newChildren;\n    }\n    return this;\n  }\n\n  /**\n   * Call String.prototype.replace on the very right-most source snippet. Useful\n   * for trimming whitespace from the end of a source node, etc.\n   *\n   * @param aPattern The pattern to replace.\n   * @param aReplacement The thing to replace the pattern with.\n   */\n  replaceRight(aPattern, aReplacement) {\n    const lastChild = this.children[this.children.length - 1];\n    if (lastChild[isSourceNode]) {\n      lastChild.replaceRight(aPattern, aReplacement);\n    } else if (typeof lastChild === \"string\") {\n      this.children[this.children.length - 1] = lastChild.replace(aPattern, aReplacement);\n    } else {\n      this.children.push(\"\".replace(aPattern, aReplacement));\n    }\n    return this;\n  }\n\n  /**\n   * Set the source content for a source file. This will be added to the SourceMapGenerator\n   * in the sourcesContent field.\n   *\n   * @param aSourceFile The filename of the source file\n   * @param aSourceContent The content of the source file\n   */\n  setSourceContent(aSourceFile, aSourceContent) {\n    this.sourceContents[util.toSetString(aSourceFile)] = aSourceContent;\n  }\n\n  /**\n   * Walk over the tree of SourceNodes. The walking function is called for each\n   * source file content and is passed the filename and source content.\n   *\n   * @param aFn The traversal function.\n   */\n  walkSourceContents(aFn) {\n    for (let i = 0, len = this.children.length; i < len; i++) {\n      if (this.children[i][isSourceNode]) {\n        this.children[i].walkSourceContents(aFn);\n      }\n    }\n\n    const sources = Object.keys(this.sourceContents);\n    for (let i = 0, len = sources.length; i < len; i++) {\n      aFn(util.fromSetString(sources[i]), this.sourceContents[sources[i]]);\n    }\n  }\n\n  /**\n   * Return the string representation of this source node. Walks over the tree\n   * and concatenates all the various snippets together to one string.\n   */\n  toString() {\n    let str = \"\";\n    this.walk(function(chunk) {\n      str += chunk;\n    });\n    return str;\n  }\n\n  /**\n   * Returns the string representation of this source node along with a source\n   * map.\n   */\n  toStringWithSourceMap(aArgs) {\n    const generated = {\n      code: \"\",\n      line: 1,\n      column: 0\n    };\n    const map = new SourceMapGenerator(aArgs);\n    let sourceMappingActive = false;\n    let lastOriginalSource = null;\n    let lastOriginalLine = null;\n    let lastOriginalColumn = null;\n    let lastOriginalName = null;\n    this.walk(function(chunk, original) {\n      generated.code += chunk;\n      if (original.source !== null\n          && original.line !== null\n          && original.column !== null) {\n        if (lastOriginalSource !== original.source\n          || lastOriginalLine !== original.line\n          || lastOriginalColumn !== original.column\n          || lastOriginalName !== original.name) {\n          map.addMapping({\n            source: original.source,\n            original: {\n              line: original.line,\n              column: original.column\n            },\n            generated: {\n              line: generated.line,\n              column: generated.column\n            },\n            name: original.name\n          });\n        }\n        lastOriginalSource = original.source;\n        lastOriginalLine = original.line;\n        lastOriginalColumn = original.column;\n        lastOriginalName = original.name;\n        sourceMappingActive = true;\n      } else if (sourceMappingActive) {\n        map.addMapping({\n          generated: {\n            line: generated.line,\n            column: generated.column\n          }\n        });\n        lastOriginalSource = null;\n        sourceMappingActive = false;\n      }\n      for (let idx = 0, length = chunk.length; idx < length; idx++) {\n        if (chunk.charCodeAt(idx) === NEWLINE_CODE) {\n          generated.line++;\n          generated.column = 0;\n          // Mappings end at eol\n          if (idx + 1 === length) {\n            lastOriginalSource = null;\n            sourceMappingActive = false;\n          } else if (sourceMappingActive) {\n            map.addMapping({\n              source: original.source,\n              original: {\n                line: original.line,\n                column: original.column\n              },\n              generated: {\n                line: generated.line,\n                column: generated.column\n              },\n              name: original.name\n            });\n          }\n        } else {\n          generated.column++;\n        }\n      }\n    });\n    this.walkSourceContents(function(sourceFile, sourceContent) {\n      map.setSourceContent(sourceFile, sourceContent);\n    });\n\n    return { code: generated.code, map };\n  }\n}\n\nexports.SourceNode = SourceNode;\n","/* -*- Mode: js; js-indent-level: 2; -*- */\n/*\n * Copyright 2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\n\n/**\n * This is a helper function for getting values from parameter/options\n * objects.\n *\n * @param args The object we are extracting values from\n * @param name The name of the property we are getting.\n * @param defaultValue An optional value to return if the property is missing\n * from the object. If this is not specified and the property is missing, an\n * error will be thrown.\n */\nfunction getArg(aArgs, aName, aDefaultValue) {\n  if (aName in aArgs) {\n    return aArgs[aName];\n  } else if (arguments.length === 3) {\n    return aDefaultValue;\n  }\n    throw new Error('\"' + aName + '\" is a required argument.');\n\n}\nexports.getArg = getArg;\n\nconst urlRegexp = /^(?:([\\w+\\-.]+):)?\\/\\/(?:(\\w+:\\w+)@)?([\\w.-]*)(?::(\\d+))?(.*)$/;\nconst dataUrlRegexp = /^data:.+\\,.+$/;\n\nfunction urlParse(aUrl) {\n  const match = aUrl.match(urlRegexp);\n  if (!match) {\n    return null;\n  }\n  return {\n    scheme: match[1],\n    auth: match[2],\n    host: match[3],\n    port: match[4],\n    path: match[5]\n  };\n}\nexports.urlParse = urlParse;\n\nfunction urlGenerate(aParsedUrl) {\n  let url = \"\";\n  if (aParsedUrl.scheme) {\n    url += aParsedUrl.scheme + \":\";\n  }\n  url += \"//\";\n  if (aParsedUrl.auth) {\n    url += aParsedUrl.auth + \"@\";\n  }\n  if (aParsedUrl.host) {\n    url += aParsedUrl.host;\n  }\n  if (aParsedUrl.port) {\n    url += \":\" + aParsedUrl.port;\n  }\n  if (aParsedUrl.path) {\n    url += aParsedUrl.path;\n  }\n  return url;\n}\nexports.urlGenerate = urlGenerate;\n\nconst MAX_CACHED_INPUTS = 32;\n\n/**\n * Takes some function `f(input) -> result` and returns a memoized version of\n * `f`.\n *\n * We keep at most `MAX_CACHED_INPUTS` memoized results of `f` alive. The\n * memoization is a dumb-simple, linear least-recently-used cache.\n */\nfunction lruMemoize(f) {\n  const cache = [];\n\n  return function(input) {\n    for (let i = 0; i < cache.length; i++) {\n      if (cache[i].input === input) {\n        const temp = cache[0];\n        cache[0] = cache[i];\n        cache[i] = temp;\n        return cache[0].result;\n      }\n    }\n\n    const result = f(input);\n\n    cache.unshift({\n      input,\n      result,\n    });\n\n    if (cache.length > MAX_CACHED_INPUTS) {\n      cache.pop();\n    }\n\n    return result;\n  };\n}\n\n/**\n * Normalizes a path, or the path portion of a URL:\n *\n * - Replaces consecutive slashes with one slash.\n * - Removes unnecessary '.' parts.\n * - Removes unnecessary '<dir>/..' parts.\n *\n * Based on code in the Node.js 'path' core module.\n *\n * @param aPath The path or url to normalize.\n */\nconst normalize = lruMemoize(function normalize(aPath) {\n  let path = aPath;\n  const url = urlParse(aPath);\n  if (url) {\n    if (!url.path) {\n      return aPath;\n    }\n    path = url.path;\n  }\n  const isAbsolute = exports.isAbsolute(path);\n\n  // Split the path into parts between `/` characters. This is much faster than\n  // using `.split(/\\/+/g)`.\n  const parts = [];\n  let start = 0;\n  let i = 0;\n  while (true) {\n    start = i;\n    i = path.indexOf(\"/\", start);\n    if (i === -1) {\n      parts.push(path.slice(start));\n      break;\n    } else {\n      parts.push(path.slice(start, i));\n      while (i < path.length && path[i] === \"/\") {\n        i++;\n      }\n    }\n  }\n\n  let up = 0;\n  for (i = parts.length - 1; i >= 0; i--) {\n    const part = parts[i];\n    if (part === \".\") {\n      parts.splice(i, 1);\n    } else if (part === \"..\") {\n      up++;\n    } else if (up > 0) {\n      if (part === \"\") {\n        // The first part is blank if the path is absolute. Trying to go\n        // above the root is a no-op. Therefore we can remove all '..' parts\n        // directly after the root.\n        parts.splice(i + 1, up);\n        up = 0;\n      } else {\n        parts.splice(i, 2);\n        up--;\n      }\n    }\n  }\n  path = parts.join(\"/\");\n\n  if (path === \"\") {\n    path = isAbsolute ? \"/\" : \".\";\n  }\n\n  if (url) {\n    url.path = path;\n    return urlGenerate(url);\n  }\n  return path;\n});\nexports.normalize = normalize;\n\n/**\n * Joins two paths/URLs.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be joined with the root.\n *\n * - If aPath is a URL or a data URI, aPath is returned, unless aPath is a\n *   scheme-relative URL: Then the scheme of aRoot, if any, is prepended\n *   first.\n * - Otherwise aPath is a path. If aRoot is a URL, then its path portion\n *   is updated with the result and aRoot is returned. Otherwise the result\n *   is returned.\n *   - If aPath is absolute, the result is aPath.\n *   - Otherwise the two paths are joined with a slash.\n * - Joining for example 'http://' and 'www.example.com' is also supported.\n */\nfunction join(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n  if (aPath === \"\") {\n    aPath = \".\";\n  }\n  const aPathUrl = urlParse(aPath);\n  const aRootUrl = urlParse(aRoot);\n  if (aRootUrl) {\n    aRoot = aRootUrl.path || \"/\";\n  }\n\n  // `join(foo, '//www.example.org')`\n  if (aPathUrl && !aPathUrl.scheme) {\n    if (aRootUrl) {\n      aPathUrl.scheme = aRootUrl.scheme;\n    }\n    return urlGenerate(aPathUrl);\n  }\n\n  if (aPathUrl || aPath.match(dataUrlRegexp)) {\n    return aPath;\n  }\n\n  // `join('http://', 'www.example.com')`\n  if (aRootUrl && !aRootUrl.host && !aRootUrl.path) {\n    aRootUrl.host = aPath;\n    return urlGenerate(aRootUrl);\n  }\n\n  const joined = aPath.charAt(0) === \"/\"\n    ? aPath\n    : normalize(aRoot.replace(/\\/+$/, \"\") + \"/\" + aPath);\n\n  if (aRootUrl) {\n    aRootUrl.path = joined;\n    return urlGenerate(aRootUrl);\n  }\n  return joined;\n}\nexports.join = join;\n\nexports.isAbsolute = function(aPath) {\n  return aPath.charAt(0) === \"/\" || urlRegexp.test(aPath);\n};\n\n/**\n * Make a path relative to a URL or another path.\n *\n * @param aRoot The root path or URL.\n * @param aPath The path or URL to be made relative to aRoot.\n */\nfunction relative(aRoot, aPath) {\n  if (aRoot === \"\") {\n    aRoot = \".\";\n  }\n\n  aRoot = aRoot.replace(/\\/$/, \"\");\n\n  // It is possible for the path to be above the root. In this case, simply\n  // checking whether the root is a prefix of the path won't work. Instead, we\n  // need to remove components from the root one by one, until either we find\n  // a prefix that fits, or we run out of components to remove.\n  let level = 0;\n  while (aPath.indexOf(aRoot + \"/\") !== 0) {\n    const index = aRoot.lastIndexOf(\"/\");\n    if (index < 0) {\n      return aPath;\n    }\n\n    // If the only part of the root that is left is the scheme (i.e. http://,\n    // file:///, etc.), one or more slashes (/), or simply nothing at all, we\n    // have exhausted all components, so the path is not relative to the root.\n    aRoot = aRoot.slice(0, index);\n    if (aRoot.match(/^([^\\/]+:\\/)?\\/*$/)) {\n      return aPath;\n    }\n\n    ++level;\n  }\n\n  // Make sure we add a \"../\" for each component we removed from the root.\n  return Array(level + 1).join(\"../\") + aPath.substr(aRoot.length + 1);\n}\nexports.relative = relative;\n\nconst supportsNullProto = (function() {\n  const obj = Object.create(null);\n  return !(\"__proto__\" in obj);\n}());\n\nfunction identity(s) {\n  return s;\n}\n\n/**\n * Because behavior goes wacky when you set `__proto__` on objects, we\n * have to prefix all the strings in our set with an arbitrary character.\n *\n * See https://github.com/mozilla/source-map/pull/31 and\n * https://github.com/mozilla/source-map/issues/30\n *\n * @param String aStr\n */\nfunction toSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return \"$\" + aStr;\n  }\n\n  return aStr;\n}\nexports.toSetString = supportsNullProto ? identity : toSetString;\n\nfunction fromSetString(aStr) {\n  if (isProtoString(aStr)) {\n    return aStr.slice(1);\n  }\n\n  return aStr;\n}\nexports.fromSetString = supportsNullProto ? identity : fromSetString;\n\nfunction isProtoString(s) {\n  if (!s) {\n    return false;\n  }\n\n  const length = s.length;\n\n  if (length < 9 /* \"__proto__\".length */) {\n    return false;\n  }\n\n  /* eslint-disable no-multi-spaces */\n  if (s.charCodeAt(length - 1) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 2) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 3) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 4) !== 116 /* 't' */ ||\n      s.charCodeAt(length - 5) !== 111 /* 'o' */ ||\n      s.charCodeAt(length - 6) !== 114 /* 'r' */ ||\n      s.charCodeAt(length - 7) !== 112 /* 'p' */ ||\n      s.charCodeAt(length - 8) !== 95  /* '_' */ ||\n      s.charCodeAt(length - 9) !== 95  /* '_' */) {\n    return false;\n  }\n  /* eslint-enable no-multi-spaces */\n\n  for (let i = length - 10; i >= 0; i--) {\n    if (s.charCodeAt(i) !== 36 /* '$' */) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\n/**\n * Comparator between two mappings where the original positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same original source/line/column, but different generated\n * line and column the same. Useful when searching for a mapping with a\n * stubbed out mapping.\n */\nfunction compareByOriginalPositions(mappingA, mappingB, onlyCompareOriginal) {\n  let cmp = strcmp(mappingA.source, mappingB.source);\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0 || onlyCompareOriginal) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return strcmp(mappingA.name, mappingB.name);\n}\nexports.compareByOriginalPositions = compareByOriginalPositions;\n\n/**\n * Comparator between two mappings with deflated source and name indices where\n * the generated positions are compared.\n *\n * Optionally pass in `true` as `onlyCompareGenerated` to consider two\n * mappings with the same generated line and column, but different\n * source/name/original line and column the same. Useful when searching for a\n * mapping with a stubbed out mapping.\n */\nfunction compareByGeneratedPositionsDeflated(mappingA, mappingB, onlyCompareGenerated) {\n  let cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0 || onlyCompareGenerated) {\n    return cmp;\n  }\n\n  cmp = strcmp(mappingA.source, mappingB.source);\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return strcmp(mappingA.name, mappingB.name);\n}\nexports.compareByGeneratedPositionsDeflated = compareByGeneratedPositionsDeflated;\n\nfunction strcmp(aStr1, aStr2) {\n  if (aStr1 === aStr2) {\n    return 0;\n  }\n\n  if (aStr1 === null) {\n    return 1; // aStr2 !== null\n  }\n\n  if (aStr2 === null) {\n    return -1; // aStr1 !== null\n  }\n\n  if (aStr1 > aStr2) {\n    return 1;\n  }\n\n  return -1;\n}\n\n/**\n * Comparator between two mappings with inflated source and name strings where\n * the generated positions are compared.\n */\nfunction compareByGeneratedPositionsInflated(mappingA, mappingB) {\n  let cmp = mappingA.generatedLine - mappingB.generatedLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.generatedColumn - mappingB.generatedColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = strcmp(mappingA.source, mappingB.source);\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalLine - mappingB.originalLine;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  cmp = mappingA.originalColumn - mappingB.originalColumn;\n  if (cmp !== 0) {\n    return cmp;\n  }\n\n  return strcmp(mappingA.name, mappingB.name);\n}\nexports.compareByGeneratedPositionsInflated = compareByGeneratedPositionsInflated;\n\n/**\n * Strip any JSON XSSI avoidance prefix from the string (as documented\n * in the source maps specification), and then parse the string as\n * JSON.\n */\nfunction parseSourceMapInput(str) {\n  return JSON.parse(str.replace(/^\\)]}'[^\\n]*\\n/, \"\"));\n}\nexports.parseSourceMapInput = parseSourceMapInput;\n\n/**\n * Compute the URL of a source given the the source root, the source's\n * URL, and the source map's URL.\n */\nfunction computeSourceURL(sourceRoot, sourceURL, sourceMapURL) {\n  sourceURL = sourceURL || \"\";\n\n  if (sourceRoot) {\n    // This follows what Chrome does.\n    if (sourceRoot[sourceRoot.length - 1] !== \"/\" && sourceURL[0] !== \"/\") {\n      sourceRoot += \"/\";\n    }\n    // The spec says:\n    //   Line 4: An optional source root, useful for relocating source\n    //   files on a server or removing repeated values in the\n    //   sources entry.  This value is prepended to the individual\n    //   entries in the source field.\n    sourceURL = sourceRoot + sourceURL;\n  }\n\n  // Historically, SourceMapConsumer did not take the sourceMapURL as\n  // a parameter.  This mode is still somewhat supported, which is why\n  // this code block is conditional.  However, it's preferable to pass\n  // the source map URL to SourceMapConsumer, so that this function\n  // can implement the source URL resolution algorithm as outlined in\n  // the spec.  This block is basically the equivalent of:\n  //    new URL(sourceURL, sourceMapURL).toString()\n  // ... except it avoids using URL, which wasn't available in the\n  // older releases of node still supported by this library.\n  //\n  // The spec says:\n  //   If the sources are not absolute URLs after prepending of the\n  //   sourceRoot, the sources are resolved relative to the\n  //   SourceMap (like resolving script src in a html document).\n  if (sourceMapURL) {\n    const parsed = urlParse(sourceMapURL);\n    if (!parsed) {\n      throw new Error(\"sourceMapURL could not be parsed\");\n    }\n    if (parsed.path) {\n      // Strip the last path component, but keep the \"/\".\n      const index = parsed.path.lastIndexOf(\"/\");\n      if (index >= 0) {\n        parsed.path = parsed.path.substring(0, index + 1);\n      }\n    }\n    sourceURL = join(urlGenerate(parsed), sourceURL);\n  }\n\n  return normalize(sourceURL);\n}\nexports.computeSourceURL = computeSourceURL;\n","const readWasm = require(\"../lib/read-wasm\");\n\n/**\n * Provide the JIT with a nice shape / hidden class.\n */\nfunction Mapping() {\n  this.generatedLine = 0;\n  this.generatedColumn = 0;\n  this.lastGeneratedColumn = null;\n  this.source = null;\n  this.originalLine = null;\n  this.originalColumn = null;\n  this.name = null;\n}\n\nlet cachedWasm = null;\n\nmodule.exports = function wasm() {\n  if (cachedWasm) {\n    return cachedWasm;\n  }\n\n  const callbackStack = [];\n\n  cachedWasm = readWasm().then(buffer => {\n      return WebAssembly.instantiate(buffer, {\n        env: {\n          mapping_callback(\n            generatedLine,\n            generatedColumn,\n\n            hasLastGeneratedColumn,\n            lastGeneratedColumn,\n\n            hasOriginal,\n            source,\n            originalLine,\n            originalColumn,\n\n            hasName,\n            name\n          ) {\n            const mapping = new Mapping();\n            // JS uses 1-based line numbers, wasm uses 0-based.\n            mapping.generatedLine = generatedLine + 1;\n            mapping.generatedColumn = generatedColumn;\n\n            if (hasLastGeneratedColumn) {\n              // JS uses inclusive last generated column, wasm uses exclusive.\n              mapping.lastGeneratedColumn = lastGeneratedColumn - 1;\n            }\n\n            if (hasOriginal) {\n              mapping.source = source;\n              // JS uses 1-based line numbers, wasm uses 0-based.\n              mapping.originalLine = originalLine + 1;\n              mapping.originalColumn = originalColumn;\n\n              if (hasName) {\n                mapping.name = name;\n              }\n            }\n\n            callbackStack[callbackStack.length - 1](mapping);\n          },\n\n          start_all_generated_locations_for() { console.time(\"all_generated_locations_for\"); },\n          end_all_generated_locations_for() { console.timeEnd(\"all_generated_locations_for\"); },\n\n          start_compute_column_spans() { console.time(\"compute_column_spans\"); },\n          end_compute_column_spans() { console.timeEnd(\"compute_column_spans\"); },\n\n          start_generated_location_for() { console.time(\"generated_location_for\"); },\n          end_generated_location_for() { console.timeEnd(\"generated_location_for\"); },\n\n          start_original_location_for() { console.time(\"original_location_for\"); },\n          end_original_location_for() { console.timeEnd(\"original_location_for\"); },\n\n          start_parse_mappings() { console.time(\"parse_mappings\"); },\n          end_parse_mappings() { console.timeEnd(\"parse_mappings\"); },\n\n          start_sort_by_generated_location() { console.time(\"sort_by_generated_location\"); },\n          end_sort_by_generated_location() { console.timeEnd(\"sort_by_generated_location\"); },\n\n          start_sort_by_original_location() { console.time(\"sort_by_original_location\"); },\n          end_sort_by_original_location() { console.timeEnd(\"sort_by_original_location\"); },\n        }\n      });\n  }).then(Wasm => {\n    return {\n      exports: Wasm.instance.exports,\n      withMappingCallback: (mappingCallback, f) => {\n        callbackStack.push(mappingCallback);\n        try {\n          f();\n        } finally {\n          callbackStack.pop();\n        }\n      }\n    };\n  }).then(null, e => {\n    cachedWasm = null;\n    throw e;\n  });\n\n  return cachedWasm;\n};\n","/*\n * Copyright 2009-2011 Mozilla Foundation and contributors\n * Licensed under the New BSD license. See LICENSE.txt or:\n * http://opensource.org/licenses/BSD-3-Clause\n */\nexports.SourceMapGenerator = require(\"./lib/source-map-generator\").SourceMapGenerator;\nexports.SourceMapConsumer = require(\"./lib/source-map-consumer\").SourceMapConsumer;\nexports.SourceNode = require(\"./lib/source-node\").SourceNode;\n","/*!\n * Copyright (c) 2026-present, Vanilagy and contributors\n *\n * This Source Code Form is subject to the terms of the Mozilla Public\n * License, v. 2.0. If a copy of the MPL was not distributed with this\n * file, You can obtain one at https://mozilla.org/MPL/2.0/.\n */\n\"use strict\";\nvar Mediabunny = (() => {\n  var __create = Object.create;\n  var __defProp = Object.defineProperty;\n  var __getOwnPropDesc = Object.getOwnPropertyDescriptor;\n  var __getOwnPropNames = Object.getOwnPropertyNames;\n  var __getProtoOf = Object.getPrototypeOf;\n  var __hasOwnProp = Object.prototype.hasOwnProperty;\n  var __commonJS = (cb, mod) => function __require() {\n    return mod || (0, cb[__getOwnPropNames(cb)[0]])((mod = { exports: {} }).exports, mod), mod.exports;\n  };\n  var __export = (target, all) => {\n    for (var name in all)\n      __defProp(target, name, { get: all[name], enumerable: true });\n  };\n  var __copyProps = (to, from, except, desc) => {\n    if (from && typeof from === \"object\" || typeof from === \"function\") {\n      for (let key of __getOwnPropNames(from))\n        if (!__hasOwnProp.call(to, key) && key !== except)\n          __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n    }\n    return to;\n  };\n  var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(\n    // If the importer is in node compatibility mode or this is not an ESM\n    // file that has been converted to a CommonJS file using a Babel-\n    // compatible transform (i.e. \"__esModule\" has not been set), then set\n    // \"default\" to the CommonJS \"module.exports\" for node compatibility.\n    isNodeMode || !mod || !mod.__esModule ? __defProp(target, \"default\", { value: mod, enumerable: true }) : target,\n    mod\n  ));\n  var __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n  // (disabled):src/node\n  var require_node = __commonJS({\n    \"(disabled):src/node\"() {\n    }\n  });\n\n  // src/index.ts\n  var index_exports = {};\n  __export(index_exports, {\n    ADTS: () => ADTS,\n    ALL_FORMATS: () => ALL_FORMATS,\n    ALL_TRACK_TYPES: () => ALL_TRACK_TYPES,\n    AUDIO_CODECS: () => AUDIO_CODECS,\n    AdtsInputFormat: () => AdtsInputFormat,\n    AdtsOutputFormat: () => AdtsOutputFormat,\n    AttachedFile: () => AttachedFile,\n    AudioBufferSink: () => AudioBufferSink,\n    AudioBufferSource: () => AudioBufferSource,\n    AudioSample: () => AudioSample,\n    AudioSampleSink: () => AudioSampleSink,\n    AudioSampleSource: () => AudioSampleSource,\n    AudioSource: () => AudioSource,\n    BaseMediaSampleSink: () => BaseMediaSampleSink,\n    BlobSource: () => BlobSource,\n    BufferSource: () => BufferSource,\n    BufferTarget: () => BufferTarget,\n    CanvasSink: () => CanvasSink,\n    CanvasSource: () => CanvasSource,\n    Conversion: () => Conversion,\n    ConversionCanceledError: () => ConversionCanceledError,\n    CustomAudioDecoder: () => CustomAudioDecoder,\n    CustomAudioEncoder: () => CustomAudioEncoder,\n    CustomVideoDecoder: () => CustomVideoDecoder,\n    CustomVideoEncoder: () => CustomVideoEncoder,\n    EncodedAudioPacketSource: () => EncodedAudioPacketSource,\n    EncodedPacket: () => EncodedPacket,\n    EncodedPacketSink: () => EncodedPacketSink,\n    EncodedVideoPacketSource: () => EncodedVideoPacketSource,\n    FLAC: () => FLAC,\n    FilePathSource: () => FilePathSource,\n    FilePathTarget: () => FilePathTarget,\n    FlacInputFormat: () => FlacInputFormat,\n    FlacOutputFormat: () => FlacOutputFormat,\n    Input: () => Input,\n    InputAudioTrack: () => InputAudioTrack,\n    InputDisposedError: () => InputDisposedError,\n    InputFormat: () => InputFormat,\n    InputTrack: () => InputTrack,\n    InputVideoTrack: () => InputVideoTrack,\n    IsobmffInputFormat: () => IsobmffInputFormat,\n    IsobmffOutputFormat: () => IsobmffOutputFormat2,\n    MATROSKA: () => MATROSKA,\n    MP3: () => MP3,\n    MP4: () => MP4,\n    MPEG_TS: () => MPEG_TS,\n    MatroskaInputFormat: () => MatroskaInputFormat,\n    MediaSource: () => MediaSource,\n    MediaStreamAudioTrackSource: () => MediaStreamAudioTrackSource,\n    MediaStreamVideoTrackSource: () => MediaStreamVideoTrackSource,\n    MkvOutputFormat: () => MkvOutputFormat2,\n    MovOutputFormat: () => MovOutputFormat,\n    Mp3InputFormat: () => Mp3InputFormat,\n    Mp3OutputFormat: () => Mp3OutputFormat,\n    Mp4InputFormat: () => Mp4InputFormat,\n    Mp4OutputFormat: () => Mp4OutputFormat,\n    MpegTsInputFormat: () => MpegTsInputFormat,\n    MpegTsOutputFormat: () => MpegTsOutputFormat,\n    NON_PCM_AUDIO_CODECS: () => NON_PCM_AUDIO_CODECS,\n    NullTarget: () => NullTarget,\n    OGG: () => OGG,\n    OggInputFormat: () => OggInputFormat,\n    OggOutputFormat: () => OggOutputFormat,\n    Output: () => Output,\n    OutputFormat: () => OutputFormat,\n    PCM_AUDIO_CODECS: () => PCM_AUDIO_CODECS,\n    QTFF: () => QTFF,\n    QUALITY_HIGH: () => QUALITY_HIGH,\n    QUALITY_LOW: () => QUALITY_LOW,\n    QUALITY_MEDIUM: () => QUALITY_MEDIUM,\n    QUALITY_VERY_HIGH: () => QUALITY_VERY_HIGH,\n    QUALITY_VERY_LOW: () => QUALITY_VERY_LOW,\n    Quality: () => Quality,\n    QuickTimeInputFormat: () => QuickTimeInputFormat,\n    ReadableStreamSource: () => ReadableStreamSource,\n    RichImageData: () => RichImageData,\n    SUBTITLE_CODECS: () => SUBTITLE_CODECS,\n    Source: () => Source,\n    StreamSource: () => StreamSource,\n    StreamTarget: () => StreamTarget,\n    SubtitleSource: () => SubtitleSource,\n    Target: () => Target,\n    TextSubtitleSource: () => TextSubtitleSource,\n    UrlSource: () => UrlSource,\n    VIDEO_CODECS: () => VIDEO_CODECS,\n    VIDEO_SAMPLE_PIXEL_FORMATS: () => VIDEO_SAMPLE_PIXEL_FORMATS,\n    VideoSample: () => VideoSample,\n    VideoSampleColorSpace: () => VideoSampleColorSpace,\n    VideoSampleSink: () => VideoSampleSink,\n    VideoSampleSource: () => VideoSampleSource,\n    VideoSource: () => VideoSource,\n    WAVE: () => WAVE,\n    WEBM: () => WEBM,\n    WavOutputFormat: () => WavOutputFormat,\n    WaveInputFormat: () => WaveInputFormat,\n    WebMInputFormat: () => WebMInputFormat,\n    WebMOutputFormat: () => WebMOutputFormat,\n    canEncode: () => canEncode,\n    canEncodeAudio: () => canEncodeAudio,\n    canEncodeSubtitles: () => canEncodeSubtitles,\n    canEncodeVideo: () => canEncodeVideo,\n    getEncodableAudioCodecs: () => getEncodableAudioCodecs,\n    getEncodableCodecs: () => getEncodableCodecs,\n    getEncodableSubtitleCodecs: () => getEncodableSubtitleCodecs,\n    getEncodableVideoCodecs: () => getEncodableVideoCodecs,\n    getFirstEncodableAudioCodec: () => getFirstEncodableAudioCodec,\n    getFirstEncodableSubtitleCodec: () => getFirstEncodableSubtitleCodec,\n    getFirstEncodableVideoCodec: () => getFirstEncodableVideoCodec,\n    registerDecoder: () => registerDecoder,\n    registerEncoder: () => registerEncoder\n  });\n\n  // src/misc.ts\n  function assert(x) {\n    if (!x) {\n      throw new Error(\"Assertion failed.\");\n    }\n  }\n  var normalizeRotation = (rotation) => {\n    const mappedRotation = (rotation % 360 + 360) % 360;\n    if (mappedRotation === 0 || mappedRotation === 90 || mappedRotation === 180 || mappedRotation === 270) {\n      return mappedRotation;\n    } else {\n      throw new Error(`Invalid rotation ${rotation}.`);\n    }\n  };\n  var last = (arr) => {\n    return arr && arr[arr.length - 1];\n  };\n  var isU32 = (value) => {\n    return value >= 0 && value < 2 ** 32;\n  };\n  var Bitstream = class _Bitstream {\n    constructor(bytes2) {\n      this.bytes = bytes2;\n      /** Current offset in bits. */\n      this.pos = 0;\n    }\n    seekToByte(byteOffset) {\n      this.pos = 8 * byteOffset;\n    }\n    readBit() {\n      const byteIndex = Math.floor(this.pos / 8);\n      const byte = this.bytes[byteIndex] ?? 0;\n      const bitIndex = 7 - (this.pos & 7);\n      const bit = (byte & 1 << bitIndex) >> bitIndex;\n      this.pos++;\n      return bit;\n    }\n    readBits(n) {\n      if (n === 1) {\n        return this.readBit();\n      }\n      let result = 0;\n      for (let i = 0; i < n; i++) {\n        result <<= 1;\n        result |= this.readBit();\n      }\n      return result;\n    }\n    writeBits(n, value) {\n      const end = this.pos + n;\n      for (let i = this.pos; i < end; i++) {\n        const byteIndex = Math.floor(i / 8);\n        let byte = this.bytes[byteIndex];\n        const bitIndex = 7 - (i & 7);\n        byte &= ~(1 << bitIndex);\n        byte |= (value & 1 << end - i - 1) >> end - i - 1 << bitIndex;\n        this.bytes[byteIndex] = byte;\n      }\n      this.pos = end;\n    }\n    readAlignedByte() {\n      if (this.pos % 8 !== 0) {\n        throw new Error(\"Bitstream is not byte-aligned.\");\n      }\n      const byteIndex = this.pos / 8;\n      const byte = this.bytes[byteIndex] ?? 0;\n      this.pos += 8;\n      return byte;\n    }\n    skipBits(n) {\n      this.pos += n;\n    }\n    getBitsLeft() {\n      return this.bytes.length * 8 - this.pos;\n    }\n    clone() {\n      const clone = new _Bitstream(this.bytes);\n      clone.pos = this.pos;\n      return clone;\n    }\n  };\n  var readExpGolomb = (bitstream) => {\n    let leadingZeroBits = 0;\n    while (bitstream.readBits(1) === 0 && leadingZeroBits < 32) {\n      leadingZeroBits++;\n    }\n    if (leadingZeroBits >= 32) {\n      throw new Error(\"Invalid exponential-Golomb code.\");\n    }\n    const result = (1 << leadingZeroBits) - 1 + bitstream.readBits(leadingZeroBits);\n    return result;\n  };\n  var readSignedExpGolomb = (bitstream) => {\n    const codeNum = readExpGolomb(bitstream);\n    return (codeNum & 1) === 0 ? -(codeNum >> 1) : codeNum + 1 >> 1;\n  };\n  var writeBits = (bytes2, start, end, value) => {\n    for (let i = start; i < end; i++) {\n      const byteIndex = Math.floor(i / 8);\n      let byte = bytes2[byteIndex];\n      const bitIndex = 7 - (i & 7);\n      byte &= ~(1 << bitIndex);\n      byte |= (value & 1 << end - i - 1) >> end - i - 1 << bitIndex;\n      bytes2[byteIndex] = byte;\n    }\n  };\n  var toUint8Array = (source) => {\n    if (source.constructor === Uint8Array) {\n      return source;\n    } else if (ArrayBuffer.isView(source)) {\n      return new Uint8Array(source.buffer, source.byteOffset, source.byteLength);\n    } else {\n      return new Uint8Array(source);\n    }\n  };\n  var toDataView = (source) => {\n    if (source.constructor === DataView) {\n      return source;\n    } else if (ArrayBuffer.isView(source)) {\n      return new DataView(source.buffer, source.byteOffset, source.byteLength);\n    } else {\n      return new DataView(source);\n    }\n  };\n  var textDecoder = /* @__PURE__ */ new TextDecoder();\n  var textEncoder = /* @__PURE__ */ new TextEncoder();\n  var isIso88591Compatible = (text) => {\n    for (let i = 0; i < text.length; i++) {\n      const code = text.charCodeAt(i);\n      if (code > 255) {\n        return false;\n      }\n    }\n    return true;\n  };\n  var invertObject = (object) => {\n    return Object.fromEntries(Object.entries(object).map(([key, value]) => [value, key]));\n  };\n  var COLOR_PRIMARIES_MAP = {\n    bt709: 1,\n    // ITU-R BT.709\n    bt470bg: 5,\n    // ITU-R BT.470BG\n    smpte170m: 6,\n    // ITU-R BT.601 525 - SMPTE 170M\n    bt2020: 9,\n    // ITU-R BT.202\n    smpte432: 12\n    // SMPTE EG 432-1\n  };\n  var COLOR_PRIMARIES_MAP_INVERSE = /* @__PURE__ */ invertObject(COLOR_PRIMARIES_MAP);\n  var TRANSFER_CHARACTERISTICS_MAP = {\n    \"bt709\": 1,\n    // ITU-R BT.709\n    \"smpte170m\": 6,\n    // SMPTE 170M\n    \"linear\": 8,\n    // Linear transfer characteristics\n    \"iec61966-2-1\": 13,\n    // IEC 61966-2-1\n    \"pq\": 16,\n    // Rec. ITU-R BT.2100-2 perceptual quantization (PQ) system\n    \"hlg\": 18\n    // Rec. ITU-R BT.2100-2 hybrid loggamma (HLG) system\n  };\n  var TRANSFER_CHARACTERISTICS_MAP_INVERSE = /* @__PURE__ */ invertObject(TRANSFER_CHARACTERISTICS_MAP);\n  var MATRIX_COEFFICIENTS_MAP = {\n    \"rgb\": 0,\n    // Identity\n    \"bt709\": 1,\n    // ITU-R BT.709\n    \"bt470bg\": 5,\n    // ITU-R BT.470BG\n    \"smpte170m\": 6,\n    // SMPTE 170M\n    \"bt2020-ncl\": 9\n    // ITU-R BT.2020-2 (non-constant luminance)\n  };\n  var MATRIX_COEFFICIENTS_MAP_INVERSE = /* @__PURE__ */ invertObject(MATRIX_COEFFICIENTS_MAP);\n  var colorSpaceIsComplete = (colorSpace) => {\n    return !!colorSpace && !!colorSpace.primaries && !!colorSpace.transfer && !!colorSpace.matrix && colorSpace.fullRange !== void 0;\n  };\n  var isAllowSharedBufferSource = (x) => {\n    return x instanceof ArrayBuffer || typeof SharedArrayBuffer !== \"undefined\" && x instanceof SharedArrayBuffer || ArrayBuffer.isView(x);\n  };\n  var AsyncMutex = class {\n    constructor() {\n      this.currentPromise = Promise.resolve();\n      this.pending = 0;\n    }\n    async acquire() {\n      let resolver;\n      const nextPromise = new Promise((resolve) => {\n        let resolved = false;\n        resolver = () => {\n          if (resolved) {\n            return;\n          }\n          resolve();\n          this.pending--;\n          resolved = true;\n        };\n      });\n      const currentPromiseAlias = this.currentPromise;\n      this.currentPromise = nextPromise;\n      this.pending++;\n      await currentPromiseAlias;\n      return resolver;\n    }\n  };\n  var bytesToHexString = (bytes2) => {\n    return [...bytes2].map((x) => x.toString(16).padStart(2, \"0\")).join(\"\");\n  };\n  var reverseBitsU32 = (x) => {\n    x = x >> 1 & 1431655765 | (x & 1431655765) << 1;\n    x = x >> 2 & 858993459 | (x & 858993459) << 2;\n    x = x >> 4 & 252645135 | (x & 252645135) << 4;\n    x = x >> 8 & 16711935 | (x & 16711935) << 8;\n    x = x >> 16 & 65535 | (x & 65535) << 16;\n    return x >>> 0;\n  };\n  var binarySearchExact = (arr, key, valueGetter) => {\n    let low = 0;\n    let high = arr.length - 1;\n    let ans = -1;\n    while (low <= high) {\n      const mid = low + high >> 1;\n      const midVal = valueGetter(arr[mid]);\n      if (midVal === key) {\n        ans = mid;\n        high = mid - 1;\n      } else if (midVal < key) {\n        low = mid + 1;\n      } else {\n        high = mid - 1;\n      }\n    }\n    return ans;\n  };\n  var binarySearchLessOrEqual = (arr, key, valueGetter) => {\n    let low = 0;\n    let high = arr.length - 1;\n    let ans = -1;\n    while (low <= high) {\n      const mid = low + (high - low + 1) / 2 | 0;\n      const midVal = valueGetter(arr[mid]);\n      if (midVal <= key) {\n        ans = mid;\n        low = mid + 1;\n      } else {\n        high = mid - 1;\n      }\n    }\n    return ans;\n  };\n  var insertSorted = (arr, item, valueGetter) => {\n    const insertionIndex = binarySearchLessOrEqual(arr, valueGetter(item), valueGetter);\n    arr.splice(insertionIndex + 1, 0, item);\n  };\n  var promiseWithResolvers = () => {\n    let resolve;\n    let reject;\n    const promise = new Promise((res, rej) => {\n      resolve = res;\n      reject = rej;\n    });\n    return { promise, resolve, reject };\n  };\n  var findLast = (arr, predicate) => {\n    for (let i = arr.length - 1; i >= 0; i--) {\n      if (predicate(arr[i])) {\n        return arr[i];\n      }\n    }\n    return void 0;\n  };\n  var findLastIndex = (arr, predicate) => {\n    for (let i = arr.length - 1; i >= 0; i--) {\n      if (predicate(arr[i])) {\n        return i;\n      }\n    }\n    return -1;\n  };\n  var toAsyncIterator = async function* (source) {\n    if (Symbol.iterator in source) {\n      yield* source[Symbol.iterator]();\n    } else {\n      yield* source[Symbol.asyncIterator]();\n    }\n  };\n  var validateAnyIterable = (iterable) => {\n    if (!(Symbol.iterator in iterable) && !(Symbol.asyncIterator in iterable)) {\n      throw new TypeError(\"Argument must be an iterable or async iterable.\");\n    }\n  };\n  var assertNever = (x) => {\n    throw new Error(`Unexpected value: ${x}`);\n  };\n  var getUint24 = (view2, byteOffset, littleEndian) => {\n    const byte1 = view2.getUint8(byteOffset);\n    const byte2 = view2.getUint8(byteOffset + 1);\n    const byte3 = view2.getUint8(byteOffset + 2);\n    if (littleEndian) {\n      return byte1 | byte2 << 8 | byte3 << 16;\n    } else {\n      return byte1 << 16 | byte2 << 8 | byte3;\n    }\n  };\n  var getInt24 = (view2, byteOffset, littleEndian) => {\n    return getUint24(view2, byteOffset, littleEndian) << 8 >> 8;\n  };\n  var setUint24 = (view2, byteOffset, value, littleEndian) => {\n    value = value >>> 0;\n    value = value & 16777215;\n    if (littleEndian) {\n      view2.setUint8(byteOffset, value & 255);\n      view2.setUint8(byteOffset + 1, value >>> 8 & 255);\n      view2.setUint8(byteOffset + 2, value >>> 16 & 255);\n    } else {\n      view2.setUint8(byteOffset, value >>> 16 & 255);\n      view2.setUint8(byteOffset + 1, value >>> 8 & 255);\n      view2.setUint8(byteOffset + 2, value & 255);\n    }\n  };\n  var setInt24 = (view2, byteOffset, value, littleEndian) => {\n    value = clamp(value, -8388608, 8388607);\n    if (value < 0) {\n      value = value + 16777216 & 16777215;\n    }\n    setUint24(view2, byteOffset, value, littleEndian);\n  };\n  var setInt64 = (view2, byteOffset, value, littleEndian) => {\n    if (littleEndian) {\n      view2.setUint32(byteOffset + 0, value, true);\n      view2.setInt32(byteOffset + 4, Math.floor(value / 2 ** 32), true);\n    } else {\n      view2.setInt32(byteOffset + 0, Math.floor(value / 2 ** 32), true);\n      view2.setUint32(byteOffset + 4, value, true);\n    }\n  };\n  var mapAsyncGenerator = (generator, map) => {\n    return {\n      async next() {\n        const result = await generator.next();\n        if (result.done) {\n          return { value: void 0, done: true };\n        } else {\n          return { value: map(result.value), done: false };\n        }\n      },\n      return() {\n        return generator.return();\n      },\n      throw(error) {\n        return generator.throw(error);\n      },\n      [Symbol.asyncIterator]() {\n        return this;\n      }\n    };\n  };\n  var clamp = (value, min, max) => {\n    return Math.max(min, Math.min(max, value));\n  };\n  var UNDETERMINED_LANGUAGE = \"und\";\n  var roundIfAlmostInteger = (value) => {\n    const rounded = Math.round(value);\n    if (Math.abs(value / rounded - 1) < 10 * Number.EPSILON) {\n      return rounded;\n    } else {\n      return value;\n    }\n  };\n  var roundToMultiple = (value, multiple) => {\n    return Math.round(value / multiple) * multiple;\n  };\n  var ilog = (x) => {\n    let ret = 0;\n    while (x) {\n      ret++;\n      x >>= 1;\n    }\n    return ret;\n  };\n  var ISO_639_2_REGEX = /^[a-z]{3}$/;\n  var isIso639Dash2LanguageCode = (x) => {\n    return ISO_639_2_REGEX.test(x);\n  };\n  var SECOND_TO_MICROSECOND_FACTOR = 1e6 * (1 + Number.EPSILON);\n  var mergeRequestInit = (init1, init2) => {\n    const merged = { ...init1, ...init2 };\n    if (init1.headers || init2.headers) {\n      const headers1 = init1.headers ? normalizeHeaders(init1.headers) : {};\n      const headers2 = init2.headers ? normalizeHeaders(init2.headers) : {};\n      const mergedHeaders = { ...headers1 };\n      Object.entries(headers2).forEach(([key2, value2]) => {\n        const existingKey = Object.keys(mergedHeaders).find(\n          (key1) => key1.toLowerCase() === key2.toLowerCase()\n        );\n        if (existingKey) {\n          delete mergedHeaders[existingKey];\n        }\n        mergedHeaders[key2] = value2;\n      });\n      merged.headers = mergedHeaders;\n    }\n    return merged;\n  };\n  var normalizeHeaders = (headers) => {\n    if (headers instanceof Headers) {\n      const result = {};\n      headers.forEach((value, key) => {\n        result[key] = value;\n      });\n      return result;\n    }\n    if (Array.isArray(headers)) {\n      const result = {};\n      headers.forEach(([key, value]) => {\n        result[key] = value;\n      });\n      return result;\n    }\n    return headers;\n  };\n  var retriedFetch = async (fetchFn, url2, requestInit, getRetryDelay, shouldStop) => {\n    let attempts = 0;\n    while (true) {\n      try {\n        return await fetchFn(url2, requestInit);\n      } catch (error) {\n        if (shouldStop()) {\n          throw error;\n        }\n        attempts++;\n        const retryDelayInSeconds = getRetryDelay(attempts, error, url2);\n        if (retryDelayInSeconds === null) {\n          throw error;\n        }\n        console.error(\"Retrying failed fetch. Error:\", error);\n        if (!Number.isFinite(retryDelayInSeconds) || retryDelayInSeconds < 0) {\n          throw new TypeError(\"Retry delay must be a non-negative finite number.\");\n        }\n        if (retryDelayInSeconds > 0) {\n          await new Promise((resolve) => setTimeout(resolve, 1e3 * retryDelayInSeconds));\n        }\n        if (shouldStop()) {\n          throw error;\n        }\n      }\n    }\n  };\n  var computeRationalApproximation = (x, maxDenominator) => {\n    const sign = x < 0 ? -1 : 1;\n    x = Math.abs(x);\n    let prevNumerator = 0, prevDenominator = 1;\n    let currNumerator = 1, currDenominator = 0;\n    let remainder = x;\n    while (true) {\n      const integer = Math.floor(remainder);\n      const nextNumerator = integer * currNumerator + prevNumerator;\n      const nextDenominator = integer * currDenominator + prevDenominator;\n      if (nextDenominator > maxDenominator) {\n        return {\n          numerator: sign * currNumerator,\n          denominator: currDenominator\n        };\n      }\n      prevNumerator = currNumerator;\n      prevDenominator = currDenominator;\n      currNumerator = nextNumerator;\n      currDenominator = nextDenominator;\n      remainder = 1 / (remainder - integer);\n      if (!isFinite(remainder)) {\n        break;\n      }\n    }\n    return {\n      numerator: sign * currNumerator,\n      denominator: currDenominator\n    };\n  };\n  var CallSerializer = class {\n    constructor() {\n      this.currentPromise = Promise.resolve();\n    }\n    call(fn) {\n      return this.currentPromise = this.currentPromise.then(fn);\n    }\n  };\n  var isWebKitCache = null;\n  var isWebKit = () => {\n    if (isWebKitCache !== null) {\n      return isWebKitCache;\n    }\n    return isWebKitCache = !!(typeof navigator !== \"undefined\" && (navigator.vendor?.match(/apple/i) || /AppleWebKit/.test(navigator.userAgent) && !/Chrome/.test(navigator.userAgent) || /\\b(iPad|iPhone|iPod)\\b/.test(navigator.userAgent)));\n  };\n  var isFirefoxCache = null;\n  var isFirefox = () => {\n    if (isFirefoxCache !== null) {\n      return isFirefoxCache;\n    }\n    return isFirefoxCache = typeof navigator !== \"undefined\" && navigator.userAgent?.includes(\"Firefox\");\n  };\n  var isChromiumCache = null;\n  var isChromium = () => {\n    if (isChromiumCache !== null) {\n      return isChromiumCache;\n    }\n    return isChromiumCache = !!(typeof navigator !== \"undefined\" && (navigator.vendor?.includes(\"Google Inc\") || /Chrome/.test(navigator.userAgent)));\n  };\n  var chromiumVersionCache = null;\n  var getChromiumVersion = () => {\n    if (chromiumVersionCache !== null) {\n      return chromiumVersionCache;\n    }\n    if (typeof navigator === \"undefined\") {\n      return null;\n    }\n    const match = /\\bChrome\\/(\\d+)/.exec(navigator.userAgent);\n    if (!match) {\n      return null;\n    }\n    return chromiumVersionCache = Number(match[1]);\n  };\n  var coalesceIndex = (a, b) => {\n    return a !== -1 ? a : b;\n  };\n  var closedIntervalsOverlap = (startA, endA, startB, endB) => {\n    return startA <= endB && startB <= endA;\n  };\n  var keyValueIterator = function* (object) {\n    for (const key in object) {\n      const value = object[key];\n      if (value === void 0) {\n        continue;\n      }\n      yield { key, value };\n    }\n  };\n  var imageMimeTypeToExtension = (mimeType) => {\n    switch (mimeType.toLowerCase()) {\n      case \"image/jpeg\":\n      case \"image/jpg\":\n        return \".jpg\";\n      case \"image/png\":\n        return \".png\";\n      case \"image/gif\":\n        return \".gif\";\n      case \"image/webp\":\n        return \".webp\";\n      case \"image/bmp\":\n        return \".bmp\";\n      case \"image/svg+xml\":\n        return \".svg\";\n      case \"image/tiff\":\n        return \".tiff\";\n      case \"image/avif\":\n        return \".avif\";\n      case \"image/x-icon\":\n      case \"image/vnd.microsoft.icon\":\n        return \".ico\";\n      default:\n        return null;\n    }\n  };\n  var base64ToBytes = (base64) => {\n    const decoded = atob(base64);\n    const bytes2 = new Uint8Array(decoded.length);\n    for (let i = 0; i < decoded.length; i++) {\n      bytes2[i] = decoded.charCodeAt(i);\n    }\n    return bytes2;\n  };\n  var bytesToBase64 = (bytes2) => {\n    let string = \"\";\n    for (let i = 0; i < bytes2.length; i++) {\n      string += String.fromCharCode(bytes2[i]);\n    }\n    return btoa(string);\n  };\n  var uint8ArraysAreEqual = (a, b) => {\n    if (a.length !== b.length) {\n      return false;\n    }\n    for (let i = 0; i < a.length; i++) {\n      if (a[i] !== b[i]) {\n        return false;\n      }\n    }\n    return true;\n  };\n  var polyfillSymbolDispose = () => {\n    Symbol.dispose ??= Symbol(\"Symbol.dispose\");\n  };\n  var isNumber = (x) => {\n    return typeof x === \"number\" && !Number.isNaN(x);\n  };\n\n  // src/metadata.ts\n  var RichImageData = class {\n    /** Creates a new {@link RichImageData}. */\n    constructor(data, mimeType) {\n      this.data = data;\n      this.mimeType = mimeType;\n      if (!(data instanceof Uint8Array)) {\n        throw new TypeError(\"data must be a Uint8Array.\");\n      }\n      if (typeof mimeType !== \"string\") {\n        throw new TypeError(\"mimeType must be a string.\");\n      }\n    }\n  };\n  var AttachedFile = class {\n    /** Creates a new {@link AttachedFile}. */\n    constructor(data, mimeType, name, description) {\n      this.data = data;\n      this.mimeType = mimeType;\n      this.name = name;\n      this.description = description;\n      if (!(data instanceof Uint8Array)) {\n        throw new TypeError(\"data must be a Uint8Array.\");\n      }\n      if (mimeType !== void 0 && typeof mimeType !== \"string\") {\n        throw new TypeError(\"mimeType, when provided, must be a string.\");\n      }\n      if (name !== void 0 && typeof name !== \"string\") {\n        throw new TypeError(\"name, when provided, must be a string.\");\n      }\n      if (description !== void 0 && typeof description !== \"string\") {\n        throw new TypeError(\"description, when provided, must be a string.\");\n      }\n    }\n  };\n  var validateMetadataTags = (tags) => {\n    if (!tags || typeof tags !== \"object\") {\n      throw new TypeError(\"tags must be an object.\");\n    }\n    if (tags.title !== void 0 && typeof tags.title !== \"string\") {\n      throw new TypeError(\"tags.title, when provided, must be a string.\");\n    }\n    if (tags.description !== void 0 && typeof tags.description !== \"string\") {\n      throw new TypeError(\"tags.description, when provided, must be a string.\");\n    }\n    if (tags.artist !== void 0 && typeof tags.artist !== \"string\") {\n      throw new TypeError(\"tags.artist, when provided, must be a string.\");\n    }\n    if (tags.album !== void 0 && typeof tags.album !== \"string\") {\n      throw new TypeError(\"tags.album, when provided, must be a string.\");\n    }\n    if (tags.albumArtist !== void 0 && typeof tags.albumArtist !== \"string\") {\n      throw new TypeError(\"tags.albumArtist, when provided, must be a string.\");\n    }\n    if (tags.trackNumber !== void 0 && (!Number.isInteger(tags.trackNumber) || tags.trackNumber <= 0)) {\n      throw new TypeError(\"tags.trackNumber, when provided, must be a positive integer.\");\n    }\n    if (tags.tracksTotal !== void 0 && (!Number.isInteger(tags.tracksTotal) || tags.tracksTotal <= 0)) {\n      throw new TypeError(\"tags.tracksTotal, when provided, must be a positive integer.\");\n    }\n    if (tags.discNumber !== void 0 && (!Number.isInteger(tags.discNumber) || tags.discNumber <= 0)) {\n      throw new TypeError(\"tags.discNumber, when provided, must be a positive integer.\");\n    }\n    if (tags.discsTotal !== void 0 && (!Number.isInteger(tags.discsTotal) || tags.discsTotal <= 0)) {\n      throw new TypeError(\"tags.discsTotal, when provided, must be a positive integer.\");\n    }\n    if (tags.genre !== void 0 && typeof tags.genre !== \"string\") {\n      throw new TypeError(\"tags.genre, when provided, must be a string.\");\n    }\n    if (tags.date !== void 0 && (!(tags.date instanceof Date) || Number.isNaN(tags.date.getTime()))) {\n      throw new TypeError(\"tags.date, when provided, must be a valid Date.\");\n    }\n    if (tags.lyrics !== void 0 && typeof tags.lyrics !== \"string\") {\n      throw new TypeError(\"tags.lyrics, when provided, must be a string.\");\n    }\n    if (tags.images !== void 0) {\n      if (!Array.isArray(tags.images)) {\n        throw new TypeError(\"tags.images, when provided, must be an array.\");\n      }\n      for (const image of tags.images) {\n        if (!image || typeof image !== \"object\") {\n          throw new TypeError(\"Each image in tags.images must be an object.\");\n        }\n        if (!(image.data instanceof Uint8Array)) {\n          throw new TypeError(\"Each image.data must be a Uint8Array.\");\n        }\n        if (typeof image.mimeType !== \"string\") {\n          throw new TypeError(\"Each image.mimeType must be a string.\");\n        }\n        if (![\"coverFront\", \"coverBack\", \"unknown\"].includes(image.kind)) {\n          throw new TypeError(\"Each image.kind must be 'coverFront', 'coverBack', or 'unknown'.\");\n        }\n      }\n    }\n    if (tags.comment !== void 0 && typeof tags.comment !== \"string\") {\n      throw new TypeError(\"tags.comment, when provided, must be a string.\");\n    }\n    if (tags.raw !== void 0) {\n      if (!tags.raw || typeof tags.raw !== \"object\") {\n        throw new TypeError(\"tags.raw, when provided, must be an object.\");\n      }\n      for (const value of Object.values(tags.raw)) {\n        if (value !== null && typeof value !== \"string\" && !(value instanceof Uint8Array) && !(value instanceof RichImageData) && !(value instanceof AttachedFile)) {\n          throw new TypeError(\n            \"Each value in tags.raw must be a string, Uint8Array, RichImageData, AttachedFile, or null.\"\n          );\n        }\n      }\n    }\n  };\n  var metadataTagsAreEmpty = (tags) => {\n    return tags.title === void 0 && tags.description === void 0 && tags.artist === void 0 && tags.album === void 0 && tags.albumArtist === void 0 && tags.trackNumber === void 0 && tags.tracksTotal === void 0 && tags.discNumber === void 0 && tags.discsTotal === void 0 && tags.genre === void 0 && tags.date === void 0 && tags.lyrics === void 0 && (!tags.images || tags.images.length === 0) && tags.comment === void 0 && (tags.raw === void 0 || Object.keys(tags.raw).length === 0);\n  };\n  var DEFAULT_TRACK_DISPOSITION = {\n    default: true,\n    forced: false,\n    original: false,\n    commentary: false,\n    hearingImpaired: false,\n    visuallyImpaired: false\n  };\n  var validateTrackDisposition = (disposition) => {\n    if (!disposition || typeof disposition !== \"object\") {\n      throw new TypeError(\"disposition must be an object.\");\n    }\n    if (disposition.default !== void 0 && typeof disposition.default !== \"boolean\") {\n      throw new TypeError(\"disposition.default must be a boolean.\");\n    }\n    if (disposition.forced !== void 0 && typeof disposition.forced !== \"boolean\") {\n      throw new TypeError(\"disposition.forced must be a boolean.\");\n    }\n    if (disposition.original !== void 0 && typeof disposition.original !== \"boolean\") {\n      throw new TypeError(\"disposition.original must be a boolean.\");\n    }\n    if (disposition.commentary !== void 0 && typeof disposition.commentary !== \"boolean\") {\n      throw new TypeError(\"disposition.commentary must be a boolean.\");\n    }\n    if (disposition.hearingImpaired !== void 0 && typeof disposition.hearingImpaired !== \"boolean\") {\n      throw new TypeError(\"disposition.hearingImpaired must be a boolean.\");\n    }\n    if (disposition.visuallyImpaired !== void 0 && typeof disposition.visuallyImpaired !== \"boolean\") {\n      throw new TypeError(\"disposition.visuallyImpaired must be a boolean.\");\n    }\n  };\n\n  // src/codec.ts\n  var VIDEO_CODECS = [\n    \"avc\",\n    \"hevc\",\n    \"vp9\",\n    \"av1\",\n    \"vp8\"\n  ];\n  var PCM_AUDIO_CODECS = [\n    \"pcm-s16\",\n    // We don't prefix 'le' so we're compatible with the WebCodecs-registered PCM codec strings\n    \"pcm-s16be\",\n    \"pcm-s24\",\n    \"pcm-s24be\",\n    \"pcm-s32\",\n    \"pcm-s32be\",\n    \"pcm-f32\",\n    \"pcm-f32be\",\n    \"pcm-f64\",\n    \"pcm-f64be\",\n    \"pcm-u8\",\n    \"pcm-s8\",\n    \"ulaw\",\n    \"alaw\"\n  ];\n  var NON_PCM_AUDIO_CODECS = [\n    \"aac\",\n    \"opus\",\n    \"mp3\",\n    \"vorbis\",\n    \"flac\"\n  ];\n  var AUDIO_CODECS = [\n    ...NON_PCM_AUDIO_CODECS,\n    ...PCM_AUDIO_CODECS\n  ];\n  var SUBTITLE_CODECS = [\n    \"webvtt\"\n  ];\n  var AVC_LEVEL_TABLE = [\n    { maxMacroblocks: 99, maxBitrate: 64e3, maxDpbMbs: 396, level: 10 },\n    // Level 1\n    { maxMacroblocks: 396, maxBitrate: 192e3, maxDpbMbs: 900, level: 11 },\n    // Level 1.1\n    { maxMacroblocks: 396, maxBitrate: 384e3, maxDpbMbs: 2376, level: 12 },\n    // Level 1.2\n    { maxMacroblocks: 396, maxBitrate: 768e3, maxDpbMbs: 2376, level: 13 },\n    // Level 1.3\n    { maxMacroblocks: 396, maxBitrate: 2e6, maxDpbMbs: 2376, level: 20 },\n    // Level 2\n    { maxMacroblocks: 792, maxBitrate: 4e6, maxDpbMbs: 4752, level: 21 },\n    // Level 2.1\n    { maxMacroblocks: 1620, maxBitrate: 4e6, maxDpbMbs: 8100, level: 22 },\n    // Level 2.2\n    { maxMacroblocks: 1620, maxBitrate: 1e7, maxDpbMbs: 8100, level: 30 },\n    // Level 3\n    { maxMacroblocks: 3600, maxBitrate: 14e6, maxDpbMbs: 18e3, level: 31 },\n    // Level 3.1\n    { maxMacroblocks: 5120, maxBitrate: 2e7, maxDpbMbs: 20480, level: 32 },\n    // Level 3.2\n    { maxMacroblocks: 8192, maxBitrate: 2e7, maxDpbMbs: 32768, level: 40 },\n    // Level 4\n    { maxMacroblocks: 8192, maxBitrate: 5e7, maxDpbMbs: 32768, level: 41 },\n    // Level 4.1\n    { maxMacroblocks: 8704, maxBitrate: 5e7, maxDpbMbs: 34816, level: 42 },\n    // Level 4.2\n    { maxMacroblocks: 22080, maxBitrate: 135e6, maxDpbMbs: 110400, level: 50 },\n    // Level 5\n    { maxMacroblocks: 36864, maxBitrate: 24e7, maxDpbMbs: 184320, level: 51 },\n    // Level 5.1\n    { maxMacroblocks: 36864, maxBitrate: 24e7, maxDpbMbs: 184320, level: 52 },\n    // Level 5.2\n    { maxMacroblocks: 139264, maxBitrate: 24e7, maxDpbMbs: 696320, level: 60 },\n    // Level 6\n    { maxMacroblocks: 139264, maxBitrate: 48e7, maxDpbMbs: 696320, level: 61 },\n    // Level 6.1\n    { maxMacroblocks: 139264, maxBitrate: 8e8, maxDpbMbs: 696320, level: 62 }\n    // Level 6.2\n  ];\n  var HEVC_LEVEL_TABLE = [\n    { maxPictureSize: 36864, maxBitrate: 128e3, tier: \"L\", level: 30 },\n    // Level 1 (Low Tier)\n    { maxPictureSize: 122880, maxBitrate: 15e5, tier: \"L\", level: 60 },\n    // Level 2 (Low Tier)\n    { maxPictureSize: 245760, maxBitrate: 3e6, tier: \"L\", level: 63 },\n    // Level 2.1 (Low Tier)\n    { maxPictureSize: 552960, maxBitrate: 6e6, tier: \"L\", level: 90 },\n    // Level 3 (Low Tier)\n    { maxPictureSize: 983040, maxBitrate: 1e7, tier: \"L\", level: 93 },\n    // Level 3.1 (Low Tier)\n    { maxPictureSize: 2228224, maxBitrate: 12e6, tier: \"L\", level: 120 },\n    // Level 4 (Low Tier)\n    { maxPictureSize: 2228224, maxBitrate: 3e7, tier: \"H\", level: 120 },\n    // Level 4 (High Tier)\n    { maxPictureSize: 2228224, maxBitrate: 2e7, tier: \"L\", level: 123 },\n    // Level 4.1 (Low Tier)\n    { maxPictureSize: 2228224, maxBitrate: 5e7, tier: \"H\", level: 123 },\n    // Level 4.1 (High Tier)\n    { maxPictureSize: 8912896, maxBitrate: 25e6, tier: \"L\", level: 150 },\n    // Level 5 (Low Tier)\n    { maxPictureSize: 8912896, maxBitrate: 1e8, tier: \"H\", level: 150 },\n    // Level 5 (High Tier)\n    { maxPictureSize: 8912896, maxBitrate: 4e7, tier: \"L\", level: 153 },\n    // Level 5.1 (Low Tier)\n    { maxPictureSize: 8912896, maxBitrate: 16e7, tier: \"H\", level: 153 },\n    // Level 5.1 (High Tier)\n    { maxPictureSize: 8912896, maxBitrate: 6e7, tier: \"L\", level: 156 },\n    // Level 5.2 (Low Tier)\n    { maxPictureSize: 8912896, maxBitrate: 24e7, tier: \"H\", level: 156 },\n    // Level 5.2 (High Tier)\n    { maxPictureSize: 35651584, maxBitrate: 6e7, tier: \"L\", level: 180 },\n    // Level 6 (Low Tier)\n    { maxPictureSize: 35651584, maxBitrate: 24e7, tier: \"H\", level: 180 },\n    // Level 6 (High Tier)\n    { maxPictureSize: 35651584, maxBitrate: 12e7, tier: \"L\", level: 183 },\n    // Level 6.1 (Low Tier)\n    { maxPictureSize: 35651584, maxBitrate: 48e7, tier: \"H\", level: 183 },\n    // Level 6.1 (High Tier)\n    { maxPictureSize: 35651584, maxBitrate: 24e7, tier: \"L\", level: 186 },\n    // Level 6.2 (Low Tier)\n    { maxPictureSize: 35651584, maxBitrate: 8e8, tier: \"H\", level: 186 }\n    // Level 6.2 (High Tier)\n  ];\n  var VP9_LEVEL_TABLE = [\n    { maxPictureSize: 36864, maxBitrate: 2e5, level: 10 },\n    // Level 1\n    { maxPictureSize: 73728, maxBitrate: 8e5, level: 11 },\n    // Level 1.1\n    { maxPictureSize: 122880, maxBitrate: 18e5, level: 20 },\n    // Level 2\n    { maxPictureSize: 245760, maxBitrate: 36e5, level: 21 },\n    // Level 2.1\n    { maxPictureSize: 552960, maxBitrate: 72e5, level: 30 },\n    // Level 3\n    { maxPictureSize: 983040, maxBitrate: 12e6, level: 31 },\n    // Level 3.1\n    { maxPictureSize: 2228224, maxBitrate: 18e6, level: 40 },\n    // Level 4\n    { maxPictureSize: 2228224, maxBitrate: 3e7, level: 41 },\n    // Level 4.1\n    { maxPictureSize: 8912896, maxBitrate: 6e7, level: 50 },\n    // Level 5\n    { maxPictureSize: 8912896, maxBitrate: 12e7, level: 51 },\n    // Level 5.1\n    { maxPictureSize: 8912896, maxBitrate: 18e7, level: 52 },\n    // Level 5.2\n    { maxPictureSize: 35651584, maxBitrate: 18e7, level: 60 },\n    // Level 6\n    { maxPictureSize: 35651584, maxBitrate: 24e7, level: 61 },\n    // Level 6.1\n    { maxPictureSize: 35651584, maxBitrate: 48e7, level: 62 }\n    // Level 6.2\n  ];\n  var AV1_LEVEL_TABLE = [\n    { maxPictureSize: 147456, maxBitrate: 15e5, tier: \"M\", level: 0 },\n    // Level 2.0 (Main Tier)\n    { maxPictureSize: 278784, maxBitrate: 3e6, tier: \"M\", level: 1 },\n    // Level 2.1 (Main Tier)\n    { maxPictureSize: 665856, maxBitrate: 6e6, tier: \"M\", level: 4 },\n    // Level 3.0 (Main Tier)\n    { maxPictureSize: 1065024, maxBitrate: 1e7, tier: \"M\", level: 5 },\n    // Level 3.1 (Main Tier)\n    { maxPictureSize: 2359296, maxBitrate: 12e6, tier: \"M\", level: 8 },\n    // Level 4.0 (Main Tier)\n    { maxPictureSize: 2359296, maxBitrate: 3e7, tier: \"H\", level: 8 },\n    // Level 4.0 (High Tier)\n    { maxPictureSize: 2359296, maxBitrate: 2e7, tier: \"M\", level: 9 },\n    // Level 4.1 (Main Tier)\n    { maxPictureSize: 2359296, maxBitrate: 5e7, tier: \"H\", level: 9 },\n    // Level 4.1 (High Tier)\n    { maxPictureSize: 8912896, maxBitrate: 3e7, tier: \"M\", level: 12 },\n    // Level 5.0 (Main Tier)\n    { maxPictureSize: 8912896, maxBitrate: 1e8, tier: \"H\", level: 12 },\n    // Level 5.0 (High Tier)\n    { maxPictureSize: 8912896, maxBitrate: 4e7, tier: \"M\", level: 13 },\n    // Level 5.1 (Main Tier)\n    { maxPictureSize: 8912896, maxBitrate: 16e7, tier: \"H\", level: 13 },\n    // Level 5.1 (High Tier)\n    { maxPictureSize: 8912896, maxBitrate: 6e7, tier: \"M\", level: 14 },\n    // Level 5.2 (Main Tier)\n    { maxPictureSize: 8912896, maxBitrate: 24e7, tier: \"H\", level: 14 },\n    // Level 5.2 (High Tier)\n    { maxPictureSize: 35651584, maxBitrate: 6e7, tier: \"M\", level: 15 },\n    // Level 5.3 (Main Tier)\n    { maxPictureSize: 35651584, maxBitrate: 24e7, tier: \"H\", level: 15 },\n    // Level 5.3 (High Tier)\n    { maxPictureSize: 35651584, maxBitrate: 6e7, tier: \"M\", level: 16 },\n    // Level 6.0 (Main Tier)\n    { maxPictureSize: 35651584, maxBitrate: 24e7, tier: \"H\", level: 16 },\n    // Level 6.0 (High Tier)\n    { maxPictureSize: 35651584, maxBitrate: 1e8, tier: \"M\", level: 17 },\n    // Level 6.1 (Main Tier)\n    { maxPictureSize: 35651584, maxBitrate: 48e7, tier: \"H\", level: 17 },\n    // Level 6.1 (High Tier)\n    { maxPictureSize: 35651584, maxBitrate: 16e7, tier: \"M\", level: 18 },\n    // Level 6.2 (Main Tier)\n    { maxPictureSize: 35651584, maxBitrate: 8e8, tier: \"H\", level: 18 },\n    // Level 6.2 (High Tier)\n    { maxPictureSize: 35651584, maxBitrate: 16e7, tier: \"M\", level: 19 },\n    // Level 6.3 (Main Tier)\n    { maxPictureSize: 35651584, maxBitrate: 8e8, tier: \"H\", level: 19 }\n    // Level 6.3 (High Tier)\n  ];\n  var VP9_DEFAULT_SUFFIX = \".01.01.01.01.00\";\n  var AV1_DEFAULT_SUFFIX = \".0.110.01.01.01.0\";\n  var buildVideoCodecString = (codec, width, height, bitrate) => {\n    if (codec === \"avc\") {\n      const profileIndication = 100;\n      const totalMacroblocks = Math.ceil(width / 16) * Math.ceil(height / 16);\n      const levelInfo = AVC_LEVEL_TABLE.find(\n        (level) => totalMacroblocks <= level.maxMacroblocks && bitrate <= level.maxBitrate\n      ) ?? last(AVC_LEVEL_TABLE);\n      const levelIndication = levelInfo ? levelInfo.level : 0;\n      const hexProfileIndication = profileIndication.toString(16).padStart(2, \"0\");\n      const hexProfileCompatibility = \"00\";\n      const hexLevelIndication = levelIndication.toString(16).padStart(2, \"0\");\n      return `avc1.${hexProfileIndication}${hexProfileCompatibility}${hexLevelIndication}`;\n    } else if (codec === \"hevc\") {\n      const profilePrefix = \"\";\n      const profileIdc = 1;\n      const compatibilityFlags = \"6\";\n      const pictureSize = width * height;\n      const levelInfo = HEVC_LEVEL_TABLE.find(\n        (level) => pictureSize <= level.maxPictureSize && bitrate <= level.maxBitrate\n      ) ?? last(HEVC_LEVEL_TABLE);\n      const constraintFlags = \"B0\";\n      return `hev1.${profilePrefix}${profileIdc}.${compatibilityFlags}.${levelInfo.tier}${levelInfo.level}.${constraintFlags}`;\n    } else if (codec === \"vp8\") {\n      return \"vp8\";\n    } else if (codec === \"vp9\") {\n      const profile = \"00\";\n      const pictureSize = width * height;\n      const levelInfo = VP9_LEVEL_TABLE.find(\n        (level) => pictureSize <= level.maxPictureSize && bitrate <= level.maxBitrate\n      ) ?? last(VP9_LEVEL_TABLE);\n      const bitDepth = \"08\";\n      return `vp09.${profile}.${levelInfo.level.toString().padStart(2, \"0\")}.${bitDepth}`;\n    } else if (codec === \"av1\") {\n      const profile = 0;\n      const pictureSize = width * height;\n      const levelInfo = AV1_LEVEL_TABLE.find(\n        (level2) => pictureSize <= level2.maxPictureSize && bitrate <= level2.maxBitrate\n      ) ?? last(AV1_LEVEL_TABLE);\n      const level = levelInfo.level.toString().padStart(2, \"0\");\n      const bitDepth = \"08\";\n      return `av01.${profile}.${level}${levelInfo.tier}.${bitDepth}`;\n    }\n    throw new TypeError(`Unhandled codec '${codec}'.`);\n  };\n  var generateVp9CodecConfigurationFromCodecString = (codecString) => {\n    const parts = codecString.split(\".\");\n    const profile = Number(parts[1]);\n    const level = Number(parts[2]);\n    const bitDepth = Number(parts[3]);\n    const chromaSubsampling = parts[4] ? Number(parts[4]) : 1;\n    return [\n      1,\n      1,\n      profile,\n      2,\n      1,\n      level,\n      3,\n      1,\n      bitDepth,\n      4,\n      1,\n      chromaSubsampling\n    ];\n  };\n  var generateAv1CodecConfigurationFromCodecString = (codecString) => {\n    const parts = codecString.split(\".\");\n    const marker = 1;\n    const version = 1;\n    const firstByte = (marker << 7) + version;\n    const profile = Number(parts[1]);\n    const levelAndTier = parts[2];\n    const level = Number(levelAndTier.slice(0, -1));\n    const secondByte = (profile << 5) + level;\n    const tier = levelAndTier.slice(-1) === \"H\" ? 1 : 0;\n    const bitDepth = Number(parts[3]);\n    const highBitDepth = bitDepth === 8 ? 0 : 1;\n    const twelveBit = 0;\n    const monochrome = parts[4] ? Number(parts[4]) : 0;\n    const chromaSubsamplingX = parts[5] ? Number(parts[5][0]) : 1;\n    const chromaSubsamplingY = parts[5] ? Number(parts[5][1]) : 1;\n    const chromaSamplePosition = parts[5] ? Number(parts[5][2]) : 0;\n    const thirdByte = (tier << 7) + (highBitDepth << 6) + (twelveBit << 5) + (monochrome << 4) + (chromaSubsamplingX << 3) + (chromaSubsamplingY << 2) + chromaSamplePosition;\n    const initialPresentationDelayPresent = 0;\n    const fourthByte = initialPresentationDelayPresent;\n    return [firstByte, secondByte, thirdByte, fourthByte];\n  };\n  var extractVideoCodecString = (trackInfo) => {\n    const { codec, codecDescription, colorSpace, avcCodecInfo, hevcCodecInfo, vp9CodecInfo, av1CodecInfo } = trackInfo;\n    if (codec === \"avc\") {\n      assert(trackInfo.avcType !== null);\n      if (avcCodecInfo) {\n        const bytes2 = new Uint8Array([\n          avcCodecInfo.avcProfileIndication,\n          avcCodecInfo.profileCompatibility,\n          avcCodecInfo.avcLevelIndication\n        ]);\n        return `avc${trackInfo.avcType}.${bytesToHexString(bytes2)}`;\n      }\n      if (!codecDescription || codecDescription.byteLength < 4) {\n        throw new TypeError(\"AVC decoder description is not provided or is not at least 4 bytes long.\");\n      }\n      return `avc${trackInfo.avcType}.${bytesToHexString(codecDescription.subarray(1, 4))}`;\n    } else if (codec === \"hevc\") {\n      let generalProfileSpace;\n      let generalProfileIdc;\n      let compatibilityFlags;\n      let generalTierFlag;\n      let generalLevelIdc;\n      let constraintFlags;\n      if (hevcCodecInfo) {\n        generalProfileSpace = hevcCodecInfo.generalProfileSpace;\n        generalProfileIdc = hevcCodecInfo.generalProfileIdc;\n        compatibilityFlags = reverseBitsU32(hevcCodecInfo.generalProfileCompatibilityFlags);\n        generalTierFlag = hevcCodecInfo.generalTierFlag;\n        generalLevelIdc = hevcCodecInfo.generalLevelIdc;\n        constraintFlags = [...hevcCodecInfo.generalConstraintIndicatorFlags];\n      } else {\n        if (!codecDescription || codecDescription.byteLength < 23) {\n          throw new TypeError(\"HEVC decoder description is not provided or is not at least 23 bytes long.\");\n        }\n        const view2 = toDataView(codecDescription);\n        const profileByte = view2.getUint8(1);\n        generalProfileSpace = profileByte >> 6 & 3;\n        generalProfileIdc = profileByte & 31;\n        compatibilityFlags = reverseBitsU32(view2.getUint32(2));\n        generalTierFlag = profileByte >> 5 & 1;\n        generalLevelIdc = view2.getUint8(12);\n        constraintFlags = [];\n        for (let i = 0; i < 6; i++) {\n          constraintFlags.push(view2.getUint8(6 + i));\n        }\n      }\n      let codecString = \"hev1.\";\n      codecString += [\"\", \"A\", \"B\", \"C\"][generalProfileSpace] + generalProfileIdc;\n      codecString += \".\";\n      codecString += compatibilityFlags.toString(16).toUpperCase();\n      codecString += \".\";\n      codecString += generalTierFlag === 0 ? \"L\" : \"H\";\n      codecString += generalLevelIdc;\n      while (constraintFlags.length > 0 && constraintFlags[constraintFlags.length - 1] === 0) {\n        constraintFlags.pop();\n      }\n      if (constraintFlags.length > 0) {\n        codecString += \".\";\n        codecString += constraintFlags.map((x) => x.toString(16).toUpperCase()).join(\".\");\n      }\n      return codecString;\n    } else if (codec === \"vp8\") {\n      return \"vp8\";\n    } else if (codec === \"vp9\") {\n      if (!vp9CodecInfo) {\n        const pictureSize = trackInfo.width * trackInfo.height;\n        let level2 = last(VP9_LEVEL_TABLE).level;\n        for (const entry of VP9_LEVEL_TABLE) {\n          if (pictureSize <= entry.maxPictureSize) {\n            level2 = entry.level;\n            break;\n          }\n        }\n        return `vp09.00.${level2.toString().padStart(2, \"0\")}.08`;\n      }\n      const profile = vp9CodecInfo.profile.toString().padStart(2, \"0\");\n      const level = vp9CodecInfo.level.toString().padStart(2, \"0\");\n      const bitDepth = vp9CodecInfo.bitDepth.toString().padStart(2, \"0\");\n      const chromaSubsampling = vp9CodecInfo.chromaSubsampling.toString().padStart(2, \"0\");\n      const colourPrimaries = vp9CodecInfo.colourPrimaries.toString().padStart(2, \"0\");\n      const transferCharacteristics = vp9CodecInfo.transferCharacteristics.toString().padStart(2, \"0\");\n      const matrixCoefficients = vp9CodecInfo.matrixCoefficients.toString().padStart(2, \"0\");\n      const videoFullRangeFlag = vp9CodecInfo.videoFullRangeFlag.toString().padStart(2, \"0\");\n      let string = `vp09.${profile}.${level}.${bitDepth}.${chromaSubsampling}`;\n      string += `.${colourPrimaries}.${transferCharacteristics}.${matrixCoefficients}.${videoFullRangeFlag}`;\n      if (string.endsWith(VP9_DEFAULT_SUFFIX)) {\n        string = string.slice(0, -VP9_DEFAULT_SUFFIX.length);\n      }\n      return string;\n    } else if (codec === \"av1\") {\n      if (!av1CodecInfo) {\n        const pictureSize = trackInfo.width * trackInfo.height;\n        let level2 = last(VP9_LEVEL_TABLE).level;\n        for (const entry of VP9_LEVEL_TABLE) {\n          if (pictureSize <= entry.maxPictureSize) {\n            level2 = entry.level;\n            break;\n          }\n        }\n        return `av01.0.${level2.toString().padStart(2, \"0\")}M.08`;\n      }\n      const profile = av1CodecInfo.profile;\n      const level = av1CodecInfo.level.toString().padStart(2, \"0\");\n      const tier = av1CodecInfo.tier ? \"H\" : \"M\";\n      const bitDepth = av1CodecInfo.bitDepth.toString().padStart(2, \"0\");\n      const monochrome = av1CodecInfo.monochrome ? \"1\" : \"0\";\n      const chromaSubsampling = 100 * av1CodecInfo.chromaSubsamplingX + 10 * av1CodecInfo.chromaSubsamplingY + 1 * (av1CodecInfo.chromaSubsamplingX && av1CodecInfo.chromaSubsamplingY ? av1CodecInfo.chromaSamplePosition : 0);\n      const colorPrimaries = colorSpace?.primaries ? COLOR_PRIMARIES_MAP[colorSpace.primaries] : 1;\n      const transferCharacteristics = colorSpace?.transfer ? TRANSFER_CHARACTERISTICS_MAP[colorSpace.transfer] : 1;\n      const matrixCoefficients = colorSpace?.matrix ? MATRIX_COEFFICIENTS_MAP[colorSpace.matrix] : 1;\n      const videoFullRangeFlag = colorSpace?.fullRange ? 1 : 0;\n      let string = `av01.${profile}.${level}${tier}.${bitDepth}`;\n      string += `.${monochrome}.${chromaSubsampling.toString().padStart(3, \"0\")}`;\n      string += `.${colorPrimaries.toString().padStart(2, \"0\")}`;\n      string += `.${transferCharacteristics.toString().padStart(2, \"0\")}`;\n      string += `.${matrixCoefficients.toString().padStart(2, \"0\")}`;\n      string += `.${videoFullRangeFlag}`;\n      if (string.endsWith(AV1_DEFAULT_SUFFIX)) {\n        string = string.slice(0, -AV1_DEFAULT_SUFFIX.length);\n      }\n      return string;\n    }\n    throw new TypeError(`Unhandled codec '${codec}'.`);\n  };\n  var buildAudioCodecString = (codec, numberOfChannels, sampleRate) => {\n    if (codec === \"aac\") {\n      if (numberOfChannels >= 2 && sampleRate <= 24e3) {\n        return \"mp4a.40.29\";\n      }\n      if (sampleRate <= 24e3) {\n        return \"mp4a.40.5\";\n      }\n      return \"mp4a.40.2\";\n    } else if (codec === \"mp3\") {\n      return \"mp3\";\n    } else if (codec === \"opus\") {\n      return \"opus\";\n    } else if (codec === \"vorbis\") {\n      return \"vorbis\";\n    } else if (codec === \"flac\") {\n      return \"flac\";\n    } else if (PCM_AUDIO_CODECS.includes(codec)) {\n      return codec;\n    }\n    throw new TypeError(`Unhandled codec '${codec}'.`);\n  };\n  var extractAudioCodecString = (trackInfo) => {\n    const { codec, codecDescription, aacCodecInfo } = trackInfo;\n    if (codec === \"aac\") {\n      if (!aacCodecInfo) {\n        throw new TypeError(\"AAC codec info must be provided.\");\n      }\n      if (aacCodecInfo.isMpeg2) {\n        return \"mp4a.67\";\n      } else {\n        let objectType;\n        if (aacCodecInfo.objectType !== null) {\n          objectType = aacCodecInfo.objectType;\n        } else {\n          const audioSpecificConfig = parseAacAudioSpecificConfig(codecDescription);\n          objectType = audioSpecificConfig.objectType;\n        }\n        return `mp4a.40.${objectType}`;\n      }\n    } else if (codec === \"mp3\") {\n      return \"mp3\";\n    } else if (codec === \"opus\") {\n      return \"opus\";\n    } else if (codec === \"vorbis\") {\n      return \"vorbis\";\n    } else if (codec === \"flac\") {\n      return \"flac\";\n    } else if (codec && PCM_AUDIO_CODECS.includes(codec)) {\n      return codec;\n    }\n    throw new TypeError(`Unhandled codec '${codec}'.`);\n  };\n  var aacFrequencyTable = [\n    96e3,\n    88200,\n    64e3,\n    48e3,\n    44100,\n    32e3,\n    24e3,\n    22050,\n    16e3,\n    12e3,\n    11025,\n    8e3,\n    7350\n  ];\n  var aacChannelMap = [-1, 1, 2, 3, 4, 5, 6, 8];\n  var parseAacAudioSpecificConfig = (bytes2) => {\n    if (!bytes2 || bytes2.byteLength < 2) {\n      throw new TypeError(\"AAC description must be at least 2 bytes long.\");\n    }\n    const bitstream = new Bitstream(bytes2);\n    let objectType = bitstream.readBits(5);\n    if (objectType === 31) {\n      objectType = 32 + bitstream.readBits(6);\n    }\n    const frequencyIndex = bitstream.readBits(4);\n    let sampleRate = null;\n    if (frequencyIndex === 15) {\n      sampleRate = bitstream.readBits(24);\n    } else {\n      if (frequencyIndex < aacFrequencyTable.length) {\n        sampleRate = aacFrequencyTable[frequencyIndex];\n      }\n    }\n    const channelConfiguration = bitstream.readBits(4);\n    let numberOfChannels = null;\n    if (channelConfiguration >= 1 && channelConfiguration <= 7) {\n      numberOfChannels = aacChannelMap[channelConfiguration];\n    }\n    return {\n      objectType,\n      frequencyIndex,\n      sampleRate,\n      channelConfiguration,\n      numberOfChannels\n    };\n  };\n  var buildAacAudioSpecificConfig = (config) => {\n    let frequencyIndex = aacFrequencyTable.indexOf(config.sampleRate);\n    let customSampleRate = null;\n    if (frequencyIndex === -1) {\n      frequencyIndex = 15;\n      customSampleRate = config.sampleRate;\n    }\n    const channelConfiguration = aacChannelMap.indexOf(config.numberOfChannels);\n    if (channelConfiguration === -1) {\n      throw new TypeError(`Unsupported number of channels: ${config.numberOfChannels}`);\n    }\n    let bitCount = 5 + 4 + 4;\n    if (config.objectType >= 32) {\n      bitCount += 6;\n    }\n    if (frequencyIndex === 15) {\n      bitCount += 24;\n    }\n    const byteCount = Math.ceil(bitCount / 8);\n    const bytes2 = new Uint8Array(byteCount);\n    const bitstream = new Bitstream(bytes2);\n    if (config.objectType < 32) {\n      bitstream.writeBits(5, config.objectType);\n    } else {\n      bitstream.writeBits(5, 31);\n      bitstream.writeBits(6, config.objectType - 32);\n    }\n    bitstream.writeBits(4, frequencyIndex);\n    if (frequencyIndex === 15) {\n      bitstream.writeBits(24, customSampleRate);\n    }\n    bitstream.writeBits(4, channelConfiguration);\n    return bytes2;\n  };\n  var OPUS_SAMPLE_RATE = 48e3;\n  var PCM_CODEC_REGEX = /^pcm-([usf])(\\d+)+(be)?$/;\n  var parsePcmCodec = (codec) => {\n    assert(PCM_AUDIO_CODECS.includes(codec));\n    if (codec === \"ulaw\") {\n      return { dataType: \"ulaw\", sampleSize: 1, littleEndian: true, silentValue: 255 };\n    } else if (codec === \"alaw\") {\n      return { dataType: \"alaw\", sampleSize: 1, littleEndian: true, silentValue: 213 };\n    }\n    const match = PCM_CODEC_REGEX.exec(codec);\n    assert(match);\n    let dataType;\n    if (match[1] === \"u\") {\n      dataType = \"unsigned\";\n    } else if (match[1] === \"s\") {\n      dataType = \"signed\";\n    } else {\n      dataType = \"float\";\n    }\n    const sampleSize = Number(match[2]) / 8;\n    const littleEndian = match[3] !== \"be\";\n    const silentValue = codec === \"pcm-u8\" ? 2 ** 7 : 0;\n    return { dataType, sampleSize, littleEndian, silentValue };\n  };\n  var inferCodecFromCodecString = (codecString) => {\n    if (codecString.startsWith(\"avc1\") || codecString.startsWith(\"avc3\")) {\n      return \"avc\";\n    } else if (codecString.startsWith(\"hev1\") || codecString.startsWith(\"hvc1\")) {\n      return \"hevc\";\n    } else if (codecString === \"vp8\") {\n      return \"vp8\";\n    } else if (codecString.startsWith(\"vp09\")) {\n      return \"vp9\";\n    } else if (codecString.startsWith(\"av01\")) {\n      return \"av1\";\n    }\n    if (codecString.startsWith(\"mp4a.40\") || codecString === \"mp4a.67\") {\n      return \"aac\";\n    } else if (codecString === \"mp3\" || codecString === \"mp4a.69\" || codecString === \"mp4a.6B\" || codecString === \"mp4a.6b\") {\n      return \"mp3\";\n    } else if (codecString === \"opus\") {\n      return \"opus\";\n    } else if (codecString === \"vorbis\") {\n      return \"vorbis\";\n    } else if (codecString === \"flac\") {\n      return \"flac\";\n    } else if (codecString === \"ulaw\") {\n      return \"ulaw\";\n    } else if (codecString === \"alaw\") {\n      return \"alaw\";\n    } else if (PCM_CODEC_REGEX.test(codecString)) {\n      return codecString;\n    }\n    if (codecString === \"webvtt\") {\n      return \"webvtt\";\n    }\n    return null;\n  };\n  var getVideoEncoderConfigExtension = (codec) => {\n    if (codec === \"avc\") {\n      return {\n        avc: {\n          format: \"avc\"\n          // Ensure the format is not Annex B\n        }\n      };\n    } else if (codec === \"hevc\") {\n      return {\n        hevc: {\n          format: \"hevc\"\n          // Ensure the format is not Annex B\n        }\n      };\n    }\n    return {};\n  };\n  var getAudioEncoderConfigExtension = (codec) => {\n    if (codec === \"aac\") {\n      return {\n        aac: {\n          format: \"aac\"\n          // Ensure the format is not ADTS\n        }\n      };\n    } else if (codec === \"opus\") {\n      return {\n        opus: {\n          format: \"opus\"\n        }\n      };\n    }\n    return {};\n  };\n  var VALID_VIDEO_CODEC_STRING_PREFIXES = [\"avc1\", \"avc3\", \"hev1\", \"hvc1\", \"vp8\", \"vp09\", \"av01\"];\n  var AVC_CODEC_STRING_REGEX = /^(avc1|avc3)\\.[0-9a-fA-F]{6}$/;\n  var HEVC_CODEC_STRING_REGEX = /^(hev1|hvc1)\\.(?:[ABC]?\\d+)\\.[0-9a-fA-F]{1,8}\\.[LH]\\d+(?:\\.[0-9a-fA-F]{1,2}){0,6}$/;\n  var VP9_CODEC_STRING_REGEX = /^vp09(?:\\.\\d{2}){3}(?:(?:\\.\\d{2}){5})?$/;\n  var AV1_CODEC_STRING_REGEX = /^av01\\.\\d\\.\\d{2}[MH]\\.\\d{2}(?:\\.\\d\\.\\d{3}\\.\\d{2}\\.\\d{2}\\.\\d{2}\\.\\d)?$/;\n  var validateVideoChunkMetadata = (metadata) => {\n    if (!metadata) {\n      throw new TypeError(\"Video chunk metadata must be provided.\");\n    }\n    if (typeof metadata !== \"object\") {\n      throw new TypeError(\"Video chunk metadata must be an object.\");\n    }\n    if (!metadata.decoderConfig) {\n      throw new TypeError(\"Video chunk metadata must include a decoder configuration.\");\n    }\n    if (typeof metadata.decoderConfig !== \"object\") {\n      throw new TypeError(\"Video chunk metadata decoder configuration must be an object.\");\n    }\n    if (typeof metadata.decoderConfig.codec !== \"string\") {\n      throw new TypeError(\"Video chunk metadata decoder configuration must specify a codec string.\");\n    }\n    if (!VALID_VIDEO_CODEC_STRING_PREFIXES.some((prefix) => metadata.decoderConfig.codec.startsWith(prefix))) {\n      throw new TypeError(\n        \"Video chunk metadata decoder configuration codec string must be a valid video codec string as specified in the WebCodecs Codec Registry.\"\n      );\n    }\n    if (!Number.isInteger(metadata.decoderConfig.codedWidth) || metadata.decoderConfig.codedWidth <= 0) {\n      throw new TypeError(\n        \"Video chunk metadata decoder configuration must specify a valid codedWidth (positive integer).\"\n      );\n    }\n    if (!Number.isInteger(metadata.decoderConfig.codedHeight) || metadata.decoderConfig.codedHeight <= 0) {\n      throw new TypeError(\n        \"Video chunk metadata decoder configuration must specify a valid codedHeight (positive integer).\"\n      );\n    }\n    if (metadata.decoderConfig.description !== void 0) {\n      if (!isAllowSharedBufferSource(metadata.decoderConfig.description)) {\n        throw new TypeError(\n          \"Video chunk metadata decoder configuration description, when defined, must be an ArrayBuffer or an ArrayBuffer view.\"\n        );\n      }\n    }\n    if (metadata.decoderConfig.colorSpace !== void 0) {\n      const { colorSpace } = metadata.decoderConfig;\n      if (typeof colorSpace !== \"object\") {\n        throw new TypeError(\n          \"Video chunk metadata decoder configuration colorSpace, when provided, must be an object.\"\n        );\n      }\n      const primariesValues = Object.keys(COLOR_PRIMARIES_MAP);\n      if (colorSpace.primaries != null && !primariesValues.includes(colorSpace.primaries)) {\n        throw new TypeError(\n          `Video chunk metadata decoder configuration colorSpace primaries, when defined, must be one of ${primariesValues.join(\", \")}.`\n        );\n      }\n      const transferValues = Object.keys(TRANSFER_CHARACTERISTICS_MAP);\n      if (colorSpace.transfer != null && !transferValues.includes(colorSpace.transfer)) {\n        throw new TypeError(\n          `Video chunk metadata decoder configuration colorSpace transfer, when defined, must be one of ${transferValues.join(\", \")}.`\n        );\n      }\n      const matrixValues = Object.keys(MATRIX_COEFFICIENTS_MAP);\n      if (colorSpace.matrix != null && !matrixValues.includes(colorSpace.matrix)) {\n        throw new TypeError(\n          `Video chunk metadata decoder configuration colorSpace matrix, when defined, must be one of ${matrixValues.join(\", \")}.`\n        );\n      }\n      if (colorSpace.fullRange != null && typeof colorSpace.fullRange !== \"boolean\") {\n        throw new TypeError(\n          \"Video chunk metadata decoder configuration colorSpace fullRange, when defined, must be a boolean.\"\n        );\n      }\n    }\n    if (metadata.decoderConfig.codec.startsWith(\"avc1\") || metadata.decoderConfig.codec.startsWith(\"avc3\")) {\n      if (!AVC_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {\n        throw new TypeError(\n          \"Video chunk metadata decoder configuration codec string for AVC must be a valid AVC codec string as specified in Section 3.4 of RFC 6381.\"\n        );\n      }\n    } else if (metadata.decoderConfig.codec.startsWith(\"hev1\") || metadata.decoderConfig.codec.startsWith(\"hvc1\")) {\n      if (!HEVC_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {\n        throw new TypeError(\n          \"Video chunk metadata decoder configuration codec string for HEVC must be a valid HEVC codec string as specified in Section E.3 of ISO 14496-15.\"\n        );\n      }\n    } else if (metadata.decoderConfig.codec.startsWith(\"vp8\")) {\n      if (metadata.decoderConfig.codec !== \"vp8\") {\n        throw new TypeError('Video chunk metadata decoder configuration codec string for VP8 must be \"vp8\".');\n      }\n    } else if (metadata.decoderConfig.codec.startsWith(\"vp09\")) {\n      if (!VP9_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {\n        throw new TypeError(\n          'Video chunk metadata decoder configuration codec string for VP9 must be a valid VP9 codec string as specified in Section \"Codecs Parameter String\" of https://www.webmproject.org/vp9/mp4/.'\n        );\n      }\n    } else if (metadata.decoderConfig.codec.startsWith(\"av01\")) {\n      if (!AV1_CODEC_STRING_REGEX.test(metadata.decoderConfig.codec)) {\n        throw new TypeError(\n          'Video chunk metadata decoder configuration codec string for AV1 must be a valid AV1 codec string as specified in Section \"Codecs Parameter String\" of https://aomediacodec.github.io/av1-isobmff/.'\n        );\n      }\n    }\n  };\n  var VALID_AUDIO_CODEC_STRING_PREFIXES = [\"mp4a\", \"mp3\", \"opus\", \"vorbis\", \"flac\", \"ulaw\", \"alaw\", \"pcm\"];\n  var validateAudioChunkMetadata = (metadata) => {\n    if (!metadata) {\n      throw new TypeError(\"Audio chunk metadata must be provided.\");\n    }\n    if (typeof metadata !== \"object\") {\n      throw new TypeError(\"Audio chunk metadata must be an object.\");\n    }\n    if (!metadata.decoderConfig) {\n      throw new TypeError(\"Audio chunk metadata must include a decoder configuration.\");\n    }\n    if (typeof metadata.decoderConfig !== \"object\") {\n      throw new TypeError(\"Audio chunk metadata decoder configuration must be an object.\");\n    }\n    if (typeof metadata.decoderConfig.codec !== \"string\") {\n      throw new TypeError(\"Audio chunk metadata decoder configuration must specify a codec string.\");\n    }\n    if (!VALID_AUDIO_CODEC_STRING_PREFIXES.some((prefix) => metadata.decoderConfig.codec.startsWith(prefix))) {\n      throw new TypeError(\n        \"Audio chunk metadata decoder configuration codec string must be a valid audio codec string as specified in the WebCodecs Codec Registry.\"\n      );\n    }\n    if (!Number.isInteger(metadata.decoderConfig.sampleRate) || metadata.decoderConfig.sampleRate <= 0) {\n      throw new TypeError(\n        \"Audio chunk metadata decoder configuration must specify a valid sampleRate (positive integer).\"\n      );\n    }\n    if (!Number.isInteger(metadata.decoderConfig.numberOfChannels) || metadata.decoderConfig.numberOfChannels <= 0) {\n      throw new TypeError(\n        \"Audio chunk metadata decoder configuration must specify a valid numberOfChannels (positive integer).\"\n      );\n    }\n    if (metadata.decoderConfig.description !== void 0) {\n      if (!isAllowSharedBufferSource(metadata.decoderConfig.description)) {\n        throw new TypeError(\n          \"Audio chunk metadata decoder configuration description, when defined, must be an ArrayBuffer or an ArrayBuffer view.\"\n        );\n      }\n    }\n    if (metadata.decoderConfig.codec.startsWith(\"mp4a\") && metadata.decoderConfig.codec !== \"mp4a.69\" && metadata.decoderConfig.codec !== \"mp4a.6B\" && metadata.decoderConfig.codec !== \"mp4a.6b\") {\n      const validStrings = [\"mp4a.40.2\", \"mp4a.40.02\", \"mp4a.40.5\", \"mp4a.40.05\", \"mp4a.40.29\", \"mp4a.67\"];\n      if (!validStrings.includes(metadata.decoderConfig.codec)) {\n        throw new TypeError(\n          \"Audio chunk metadata decoder configuration codec string for AAC must be a valid AAC codec string as specified in https://www.w3.org/TR/webcodecs-aac-codec-registration/.\"\n        );\n      }\n    } else if (metadata.decoderConfig.codec.startsWith(\"mp3\") || metadata.decoderConfig.codec.startsWith(\"mp4a\")) {\n      if (metadata.decoderConfig.codec !== \"mp3\" && metadata.decoderConfig.codec !== \"mp4a.69\" && metadata.decoderConfig.codec !== \"mp4a.6B\" && metadata.decoderConfig.codec !== \"mp4a.6b\") {\n        throw new TypeError(\n          'Audio chunk metadata decoder configuration codec string for MP3 must be \"mp3\", \"mp4a.69\" or \"mp4a.6B\".'\n        );\n      }\n    } else if (metadata.decoderConfig.codec.startsWith(\"opus\")) {\n      if (metadata.decoderConfig.codec !== \"opus\") {\n        throw new TypeError('Audio chunk metadata decoder configuration codec string for Opus must be \"opus\".');\n      }\n      if (metadata.decoderConfig.description && metadata.decoderConfig.description.byteLength < 18) {\n        throw new TypeError(\n          \"Audio chunk metadata decoder configuration description, when specified, is expected to be an Identification Header as specified in Section 5.1 of RFC 7845.\"\n        );\n      }\n    } else if (metadata.decoderConfig.codec.startsWith(\"vorbis\")) {\n      if (metadata.decoderConfig.codec !== \"vorbis\") {\n        throw new TypeError('Audio chunk metadata decoder configuration codec string for Vorbis must be \"vorbis\".');\n      }\n      if (!metadata.decoderConfig.description) {\n        throw new TypeError(\n          \"Audio chunk metadata decoder configuration for Vorbis must include a description, which is expected to adhere to the format described in https://www.w3.org/TR/webcodecs-vorbis-codec-registration/.\"\n        );\n      }\n    } else if (metadata.decoderConfig.codec.startsWith(\"flac\")) {\n      if (metadata.decoderConfig.codec !== \"flac\") {\n        throw new TypeError('Audio chunk metadata decoder configuration codec string for FLAC must be \"flac\".');\n      }\n      const minDescriptionSize = 4 + 4 + 34;\n      if (!metadata.decoderConfig.description || metadata.decoderConfig.description.byteLength < minDescriptionSize) {\n        throw new TypeError(\n          \"Audio chunk metadata decoder configuration for FLAC must include a description, which is expected to adhere to the format described in https://www.w3.org/TR/webcodecs-flac-codec-registration/.\"\n        );\n      }\n    } else if (metadata.decoderConfig.codec.startsWith(\"pcm\") || metadata.decoderConfig.codec.startsWith(\"ulaw\") || metadata.decoderConfig.codec.startsWith(\"alaw\")) {\n      if (!PCM_AUDIO_CODECS.includes(metadata.decoderConfig.codec)) {\n        throw new TypeError(\n          `Audio chunk metadata decoder configuration codec string for PCM must be one of the supported PCM codecs (${PCM_AUDIO_CODECS.join(\", \")}).`\n        );\n      }\n    }\n  };\n  var validateSubtitleMetadata = (metadata) => {\n    if (!metadata) {\n      throw new TypeError(\"Subtitle metadata must be provided.\");\n    }\n    if (typeof metadata !== \"object\") {\n      throw new TypeError(\"Subtitle metadata must be an object.\");\n    }\n    if (!metadata.config) {\n      throw new TypeError(\"Subtitle metadata must include a config object.\");\n    }\n    if (typeof metadata.config !== \"object\") {\n      throw new TypeError(\"Subtitle metadata config must be an object.\");\n    }\n    if (typeof metadata.config.description !== \"string\") {\n      throw new TypeError(\"Subtitle metadata config description must be a string.\");\n    }\n  };\n\n  // src/muxer.ts\n  var Muxer = class {\n    constructor(output) {\n      this.mutex = new AsyncMutex();\n      /**\n       * This field is used to synchronize multiple MediaStreamTracks. They use the same time coordinate system across\n       * tracks, and to ensure correct audio-video sync, we must use the same offset for all of them. The reason an offset\n       * is needed at all is because the timestamps typically don't start at zero.\n       */\n      this.firstMediaStreamTimestamp = null;\n      this.trackTimestampInfo = /* @__PURE__ */ new WeakMap();\n      this.output = output;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    onTrackClose(track) {\n    }\n    validateAndNormalizeTimestamp(track, timestampInSeconds, isKeyPacket) {\n      timestampInSeconds += track.source._timestampOffset;\n      let timestampInfo = this.trackTimestampInfo.get(track);\n      if (!timestampInfo) {\n        if (!isKeyPacket) {\n          throw new Error(\"First packet must be a key packet.\");\n        }\n        timestampInfo = {\n          maxTimestamp: timestampInSeconds,\n          maxTimestampBeforeLastKeyPacket: timestampInSeconds\n        };\n        this.trackTimestampInfo.set(track, timestampInfo);\n      }\n      if (timestampInSeconds < 0) {\n        throw new Error(`Timestamps must be non-negative (got ${timestampInSeconds}s).`);\n      }\n      if (isKeyPacket) {\n        timestampInfo.maxTimestampBeforeLastKeyPacket = timestampInfo.maxTimestamp;\n      }\n      if (timestampInSeconds < timestampInfo.maxTimestampBeforeLastKeyPacket) {\n        throw new Error(\n          `Timestamps cannot be smaller than the largest timestamp of the previous GOP (a GOP begins with a key packet and ends right before the next key packet). Got ${timestampInSeconds}s, but largest timestamp is ${timestampInfo.maxTimestampBeforeLastKeyPacket}s.`\n        );\n      }\n      timestampInfo.maxTimestamp = Math.max(timestampInfo.maxTimestamp, timestampInSeconds);\n      return timestampInSeconds;\n    }\n  };\n\n  // src/adts/adts-misc.ts\n  var buildAdtsHeaderTemplate = (config) => {\n    const header = new Uint8Array(7);\n    const bitstream = new Bitstream(header);\n    const { objectType, frequencyIndex, channelConfiguration } = config;\n    const profile = objectType - 1;\n    bitstream.writeBits(12, 4095);\n    bitstream.writeBits(1, 0);\n    bitstream.writeBits(2, 0);\n    bitstream.writeBits(1, 1);\n    bitstream.writeBits(2, profile);\n    bitstream.writeBits(4, frequencyIndex);\n    bitstream.writeBits(1, 0);\n    bitstream.writeBits(3, channelConfiguration);\n    bitstream.writeBits(1, 0);\n    bitstream.writeBits(1, 0);\n    bitstream.writeBits(1, 0);\n    bitstream.writeBits(1, 0);\n    bitstream.skipBits(13);\n    bitstream.writeBits(11, 2047);\n    bitstream.writeBits(2, 0);\n    return { header, bitstream };\n  };\n  var writeAdtsFrameLength = (bitstream, frameLength) => {\n    bitstream.pos = 30;\n    bitstream.writeBits(13, frameLength);\n  };\n\n  // src/adts/adts-muxer.ts\n  var AdtsMuxer = class extends Muxer {\n    constructor(output, format) {\n      super(output);\n      this.header = null;\n      this.headerBitstream = null;\n      this.inputIsAdts = null;\n      this.format = format;\n      this.writer = output._writer;\n    }\n    async start() {\n    }\n    async getMimeType() {\n      return \"audio/aac\";\n    }\n    async addEncodedVideoPacket() {\n      throw new Error(\"ADTS does not support video.\");\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === \"key\");\n        if (this.inputIsAdts === null) {\n          validateAudioChunkMetadata(meta);\n          const description = meta?.decoderConfig?.description;\n          this.inputIsAdts = !description;\n          if (!this.inputIsAdts) {\n            const config = parseAacAudioSpecificConfig(toUint8Array(description));\n            const template = buildAdtsHeaderTemplate(config);\n            this.header = template.header;\n            this.headerBitstream = template.bitstream;\n          }\n        }\n        if (this.inputIsAdts) {\n          const startPos = this.writer.getPos();\n          this.writer.write(packet.data);\n          if (this.format._options.onFrame) {\n            this.format._options.onFrame(packet.data, startPos);\n          }\n        } else {\n          assert(this.header);\n          const frameLength = packet.data.byteLength + this.header.byteLength;\n          writeAdtsFrameLength(this.headerBitstream, frameLength);\n          const startPos = this.writer.getPos();\n          this.writer.write(this.header);\n          this.writer.write(packet.data);\n          if (this.format._options.onFrame) {\n            const frameBytes = new Uint8Array(frameLength);\n            frameBytes.set(this.header, 0);\n            frameBytes.set(packet.data, this.header.byteLength);\n            this.format._options.onFrame(frameBytes, startPos);\n          }\n        }\n        await this.writer.flush();\n      } finally {\n        release();\n      }\n    }\n    async addSubtitleCue() {\n      throw new Error(\"ADTS does not support subtitles.\");\n    }\n    async finalize() {\n    }\n  };\n\n  // src/codec-data.ts\n  var iterateNalUnitsInAnnexB = function* (packetData) {\n    let i = 0;\n    let nalStart = -1;\n    while (i < packetData.length - 2) {\n      const zeroIndex = packetData.indexOf(0, i);\n      if (zeroIndex === -1 || zeroIndex >= packetData.length - 2) {\n        break;\n      }\n      i = zeroIndex;\n      let startCodeLength = 0;\n      if (i + 3 < packetData.length && packetData[i + 1] === 0 && packetData[i + 2] === 0 && packetData[i + 3] === 1) {\n        startCodeLength = 4;\n      } else if (packetData[i + 1] === 0 && packetData[i + 2] === 1) {\n        startCodeLength = 3;\n      }\n      if (startCodeLength === 0) {\n        i++;\n        continue;\n      }\n      if (nalStart !== -1 && i > nalStart) {\n        yield {\n          offset: nalStart,\n          length: i - nalStart\n        };\n      }\n      nalStart = i + startCodeLength;\n      i = nalStart;\n    }\n    if (nalStart !== -1 && nalStart < packetData.length) {\n      yield {\n        offset: nalStart,\n        length: packetData.length - nalStart\n      };\n    }\n  };\n  var iterateNalUnitsInLengthPrefixed = function* (packetData, lengthSize) {\n    let offset = 0;\n    const dataView = new DataView(packetData.buffer, packetData.byteOffset, packetData.byteLength);\n    while (offset + lengthSize <= packetData.length) {\n      let nalUnitLength;\n      if (lengthSize === 1) {\n        nalUnitLength = dataView.getUint8(offset);\n      } else if (lengthSize === 2) {\n        nalUnitLength = dataView.getUint16(offset, false);\n      } else if (lengthSize === 3) {\n        nalUnitLength = getUint24(dataView, offset, false);\n      } else {\n        assert(lengthSize === 4);\n        nalUnitLength = dataView.getUint32(offset, false);\n      }\n      offset += lengthSize;\n      yield {\n        offset,\n        length: nalUnitLength\n      };\n      offset += nalUnitLength;\n    }\n  };\n  var iterateAvcNalUnits = (packetData, decoderConfig) => {\n    if (decoderConfig.description) {\n      const bytes2 = toUint8Array(decoderConfig.description);\n      const lengthSizeMinusOne = bytes2[4] & 3;\n      const lengthSize = lengthSizeMinusOne + 1;\n      return iterateNalUnitsInLengthPrefixed(packetData, lengthSize);\n    } else {\n      return iterateNalUnitsInAnnexB(packetData);\n    }\n  };\n  var iterateAvcNalUnitsAnnexB = function* (packetData) {\n    yield* iterateNalUnitsInAnnexB(packetData);\n  };\n  var extractNalUnitTypeForAvc = (byte) => {\n    return byte & 31;\n  };\n  var removeEmulationPreventionBytes = (data) => {\n    const result = [];\n    const len = data.length;\n    for (let i = 0; i < len; i++) {\n      if (i + 2 < len && data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 3) {\n        result.push(0, 0);\n        i += 2;\n      } else {\n        result.push(data[i]);\n      }\n    }\n    return new Uint8Array(result);\n  };\n  var ANNEX_B_START_CODE = new Uint8Array([0, 0, 0, 1]);\n  var concatNalUnitsInAnnexB = (nalUnits) => {\n    const totalLength = nalUnits.reduce((a, b) => a + ANNEX_B_START_CODE.byteLength + b.byteLength, 0);\n    const result = new Uint8Array(totalLength);\n    let offset = 0;\n    for (const nalUnit of nalUnits) {\n      result.set(ANNEX_B_START_CODE, offset);\n      offset += ANNEX_B_START_CODE.byteLength;\n      result.set(nalUnit, offset);\n      offset += nalUnit.byteLength;\n    }\n    return result;\n  };\n  var concatNalUnitsInLengthPrefixed = (nalUnits, lengthSize) => {\n    const totalLength = nalUnits.reduce((a, b) => a + lengthSize + b.byteLength, 0);\n    const result = new Uint8Array(totalLength);\n    let offset = 0;\n    for (const nalUnit of nalUnits) {\n      const dataView = new DataView(result.buffer, result.byteOffset, result.byteLength);\n      switch (lengthSize) {\n        case 1:\n          dataView.setUint8(offset, nalUnit.byteLength);\n          break;\n        case 2:\n          dataView.setUint16(offset, nalUnit.byteLength, false);\n          break;\n        case 3:\n          setUint24(dataView, offset, nalUnit.byteLength, false);\n          break;\n        case 4:\n          dataView.setUint32(offset, nalUnit.byteLength, false);\n          break;\n      }\n      offset += lengthSize;\n      result.set(nalUnit, offset);\n      offset += nalUnit.byteLength;\n    }\n    return result;\n  };\n  var concatAvcNalUnits = (nalUnits, decoderConfig) => {\n    if (decoderConfig.description) {\n      const bytes2 = toUint8Array(decoderConfig.description);\n      const lengthSizeMinusOne = bytes2[4] & 3;\n      const lengthSize = lengthSizeMinusOne + 1;\n      return concatNalUnitsInLengthPrefixed(nalUnits, lengthSize);\n    } else {\n      return concatNalUnitsInAnnexB(nalUnits);\n    }\n  };\n  var extractAvcDecoderConfigurationRecord = (packetData) => {\n    try {\n      const spsUnits = [];\n      const ppsUnits = [];\n      const spsExtUnits = [];\n      for (const loc of iterateAvcNalUnitsAnnexB(packetData)) {\n        const nalUnit = packetData.subarray(loc.offset, loc.offset + loc.length);\n        const type = extractNalUnitTypeForAvc(nalUnit[0]);\n        if (type === 7 /* SPS */) {\n          spsUnits.push(nalUnit);\n        } else if (type === 8 /* PPS */) {\n          ppsUnits.push(nalUnit);\n        } else if (type === 13 /* SPS_EXT */) {\n          spsExtUnits.push(nalUnit);\n        }\n      }\n      if (spsUnits.length === 0) {\n        return null;\n      }\n      if (ppsUnits.length === 0) {\n        return null;\n      }\n      const spsData = spsUnits[0];\n      const spsInfo = parseAvcSps(spsData);\n      assert(spsInfo !== null);\n      const hasExtendedData = spsInfo.profileIdc === 100 || spsInfo.profileIdc === 110 || spsInfo.profileIdc === 122 || spsInfo.profileIdc === 144;\n      return {\n        configurationVersion: 1,\n        avcProfileIndication: spsInfo.profileIdc,\n        profileCompatibility: spsInfo.constraintFlags,\n        avcLevelIndication: spsInfo.levelIdc,\n        lengthSizeMinusOne: 3,\n        // Typically 4 bytes for length field\n        sequenceParameterSets: spsUnits,\n        pictureParameterSets: ppsUnits,\n        chromaFormat: hasExtendedData ? spsInfo.chromaFormatIdc : null,\n        bitDepthLumaMinus8: hasExtendedData ? spsInfo.bitDepthLumaMinus8 : null,\n        bitDepthChromaMinus8: hasExtendedData ? spsInfo.bitDepthChromaMinus8 : null,\n        sequenceParameterSetExt: hasExtendedData ? spsExtUnits : null\n      };\n    } catch (error) {\n      console.error(\"Error building AVC Decoder Configuration Record:\", error);\n      return null;\n    }\n  };\n  var serializeAvcDecoderConfigurationRecord = (record) => {\n    const bytes2 = [];\n    bytes2.push(record.configurationVersion);\n    bytes2.push(record.avcProfileIndication);\n    bytes2.push(record.profileCompatibility);\n    bytes2.push(record.avcLevelIndication);\n    bytes2.push(252 | record.lengthSizeMinusOne & 3);\n    bytes2.push(224 | record.sequenceParameterSets.length & 31);\n    for (const sps of record.sequenceParameterSets) {\n      const length = sps.byteLength;\n      bytes2.push(length >> 8);\n      bytes2.push(length & 255);\n      for (let i = 0; i < length; i++) {\n        bytes2.push(sps[i]);\n      }\n    }\n    bytes2.push(record.pictureParameterSets.length);\n    for (const pps of record.pictureParameterSets) {\n      const length = pps.byteLength;\n      bytes2.push(length >> 8);\n      bytes2.push(length & 255);\n      for (let i = 0; i < length; i++) {\n        bytes2.push(pps[i]);\n      }\n    }\n    if (record.avcProfileIndication === 100 || record.avcProfileIndication === 110 || record.avcProfileIndication === 122 || record.avcProfileIndication === 144) {\n      assert(record.chromaFormat !== null);\n      assert(record.bitDepthLumaMinus8 !== null);\n      assert(record.bitDepthChromaMinus8 !== null);\n      assert(record.sequenceParameterSetExt !== null);\n      bytes2.push(252 | record.chromaFormat & 3);\n      bytes2.push(248 | record.bitDepthLumaMinus8 & 7);\n      bytes2.push(248 | record.bitDepthChromaMinus8 & 7);\n      bytes2.push(record.sequenceParameterSetExt.length);\n      for (const spsExt of record.sequenceParameterSetExt) {\n        const length = spsExt.byteLength;\n        bytes2.push(length >> 8);\n        bytes2.push(length & 255);\n        for (let i = 0; i < length; i++) {\n          bytes2.push(spsExt[i]);\n        }\n      }\n    }\n    return new Uint8Array(bytes2);\n  };\n  var deserializeAvcDecoderConfigurationRecord = (data) => {\n    try {\n      const view2 = toDataView(data);\n      let offset = 0;\n      const configurationVersion = view2.getUint8(offset++);\n      const avcProfileIndication = view2.getUint8(offset++);\n      const profileCompatibility = view2.getUint8(offset++);\n      const avcLevelIndication = view2.getUint8(offset++);\n      const lengthSizeMinusOne = view2.getUint8(offset++) & 3;\n      const numOfSequenceParameterSets = view2.getUint8(offset++) & 31;\n      const sequenceParameterSets = [];\n      for (let i = 0; i < numOfSequenceParameterSets; i++) {\n        const length = view2.getUint16(offset, false);\n        offset += 2;\n        sequenceParameterSets.push(data.subarray(offset, offset + length));\n        offset += length;\n      }\n      const numOfPictureParameterSets = view2.getUint8(offset++);\n      const pictureParameterSets = [];\n      for (let i = 0; i < numOfPictureParameterSets; i++) {\n        const length = view2.getUint16(offset, false);\n        offset += 2;\n        pictureParameterSets.push(data.subarray(offset, offset + length));\n        offset += length;\n      }\n      const record = {\n        configurationVersion,\n        avcProfileIndication,\n        profileCompatibility,\n        avcLevelIndication,\n        lengthSizeMinusOne,\n        sequenceParameterSets,\n        pictureParameterSets,\n        chromaFormat: null,\n        bitDepthLumaMinus8: null,\n        bitDepthChromaMinus8: null,\n        sequenceParameterSetExt: null\n      };\n      if ((avcProfileIndication === 100 || avcProfileIndication === 110 || avcProfileIndication === 122 || avcProfileIndication === 144) && offset + 4 <= data.length) {\n        const chromaFormat = view2.getUint8(offset++) & 3;\n        const bitDepthLumaMinus8 = view2.getUint8(offset++) & 7;\n        const bitDepthChromaMinus8 = view2.getUint8(offset++) & 7;\n        const numOfSequenceParameterSetExt = view2.getUint8(offset++);\n        record.chromaFormat = chromaFormat;\n        record.bitDepthLumaMinus8 = bitDepthLumaMinus8;\n        record.bitDepthChromaMinus8 = bitDepthChromaMinus8;\n        const sequenceParameterSetExt = [];\n        for (let i = 0; i < numOfSequenceParameterSetExt; i++) {\n          const length = view2.getUint16(offset, false);\n          offset += 2;\n          sequenceParameterSetExt.push(data.subarray(offset, offset + length));\n          offset += length;\n        }\n        record.sequenceParameterSetExt = sequenceParameterSetExt;\n      }\n      return record;\n    } catch (error) {\n      console.error(\"Error deserializing AVC Decoder Configuration Record:\", error);\n      return null;\n    }\n  };\n  var parseAvcSps = (sps) => {\n    try {\n      const bitstream = new Bitstream(removeEmulationPreventionBytes(sps));\n      bitstream.skipBits(1);\n      bitstream.skipBits(2);\n      const nalUnitType = bitstream.readBits(5);\n      if (nalUnitType !== 7) {\n        return null;\n      }\n      const profileIdc = bitstream.readAlignedByte();\n      const constraintFlags = bitstream.readAlignedByte();\n      const levelIdc = bitstream.readAlignedByte();\n      readExpGolomb(bitstream);\n      let chromaFormatIdc = 1;\n      let bitDepthLumaMinus8 = 0;\n      let bitDepthChromaMinus8 = 0;\n      let separateColourPlaneFlag = 0;\n      if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {\n        chromaFormatIdc = readExpGolomb(bitstream);\n        if (chromaFormatIdc === 3) {\n          separateColourPlaneFlag = bitstream.readBits(1);\n        }\n        bitDepthLumaMinus8 = readExpGolomb(bitstream);\n        bitDepthChromaMinus8 = readExpGolomb(bitstream);\n        bitstream.skipBits(1);\n        const seqScalingMatrixPresentFlag = bitstream.readBits(1);\n        if (seqScalingMatrixPresentFlag) {\n          for (let i = 0; i < (chromaFormatIdc !== 3 ? 8 : 12); i++) {\n            const seqScalingListPresentFlag = bitstream.readBits(1);\n            if (seqScalingListPresentFlag) {\n              const sizeOfScalingList = i < 6 ? 16 : 64;\n              let lastScale = 8;\n              let nextScale = 8;\n              for (let j = 0; j < sizeOfScalingList; j++) {\n                if (nextScale !== 0) {\n                  const deltaScale = readSignedExpGolomb(bitstream);\n                  nextScale = (lastScale + deltaScale + 256) % 256;\n                }\n                lastScale = nextScale === 0 ? lastScale : nextScale;\n              }\n            }\n          }\n        }\n      }\n      readExpGolomb(bitstream);\n      const picOrderCntType = readExpGolomb(bitstream);\n      if (picOrderCntType === 0) {\n        readExpGolomb(bitstream);\n      } else if (picOrderCntType === 1) {\n        bitstream.skipBits(1);\n        readSignedExpGolomb(bitstream);\n        readSignedExpGolomb(bitstream);\n        const numRefFramesInPicOrderCntCycle = readExpGolomb(bitstream);\n        for (let i = 0; i < numRefFramesInPicOrderCntCycle; i++) {\n          readSignedExpGolomb(bitstream);\n        }\n      }\n      readExpGolomb(bitstream);\n      bitstream.skipBits(1);\n      const picWidthInMbsMinus1 = readExpGolomb(bitstream);\n      const picHeightInMapUnitsMinus1 = readExpGolomb(bitstream);\n      const codedWidth = 16 * (picWidthInMbsMinus1 + 1);\n      const codedHeight = 16 * (picHeightInMapUnitsMinus1 + 1);\n      let displayWidth = codedWidth;\n      let displayHeight = codedHeight;\n      const frameMbsOnlyFlag = bitstream.readBits(1);\n      if (!frameMbsOnlyFlag) {\n        bitstream.skipBits(1);\n      }\n      bitstream.skipBits(1);\n      const frameCroppingFlag = bitstream.readBits(1);\n      if (frameCroppingFlag) {\n        const frameCropLeftOffset = readExpGolomb(bitstream);\n        const frameCropRightOffset = readExpGolomb(bitstream);\n        const frameCropTopOffset = readExpGolomb(bitstream);\n        const frameCropBottomOffset = readExpGolomb(bitstream);\n        let cropUnitX;\n        let cropUnitY;\n        const chromaArrayType = separateColourPlaneFlag === 0 ? chromaFormatIdc : 0;\n        if (chromaArrayType === 0) {\n          cropUnitX = 1;\n          cropUnitY = 2 - frameMbsOnlyFlag;\n        } else {\n          const subWidthC = chromaFormatIdc === 3 ? 1 : 2;\n          const subHeightC = chromaFormatIdc === 1 ? 2 : 1;\n          cropUnitX = subWidthC;\n          cropUnitY = subHeightC * (2 - frameMbsOnlyFlag);\n        }\n        displayWidth -= cropUnitX * (frameCropLeftOffset + frameCropRightOffset);\n        displayHeight -= cropUnitY * (frameCropTopOffset + frameCropBottomOffset);\n      }\n      let colourPrimaries = 2;\n      let transferCharacteristics = 2;\n      let matrixCoefficients = 2;\n      let fullRangeFlag = 0;\n      let numReorderFrames = null;\n      let maxDecFrameBuffering = null;\n      const vuiParametersPresentFlag = bitstream.readBits(1);\n      if (vuiParametersPresentFlag) {\n        const aspectRatioInfoPresentFlag = bitstream.readBits(1);\n        if (aspectRatioInfoPresentFlag) {\n          const aspectRatioIdc = bitstream.readBits(8);\n          if (aspectRatioIdc === 255) {\n            bitstream.skipBits(16);\n            bitstream.skipBits(16);\n          }\n        }\n        const overscanInfoPresentFlag = bitstream.readBits(1);\n        if (overscanInfoPresentFlag) {\n          bitstream.skipBits(1);\n        }\n        const videoSignalTypePresentFlag = bitstream.readBits(1);\n        if (videoSignalTypePresentFlag) {\n          bitstream.skipBits(3);\n          fullRangeFlag = bitstream.readBits(1);\n          const colourDescriptionPresentFlag = bitstream.readBits(1);\n          if (colourDescriptionPresentFlag) {\n            colourPrimaries = bitstream.readBits(8);\n            transferCharacteristics = bitstream.readBits(8);\n            matrixCoefficients = bitstream.readBits(8);\n          }\n        }\n        const chromaLocInfoPresentFlag = bitstream.readBits(1);\n        if (chromaLocInfoPresentFlag) {\n          readExpGolomb(bitstream);\n          readExpGolomb(bitstream);\n        }\n        const timingInfoPresentFlag = bitstream.readBits(1);\n        if (timingInfoPresentFlag) {\n          bitstream.skipBits(32);\n          bitstream.skipBits(32);\n          bitstream.skipBits(1);\n        }\n        const nalHrdParametersPresentFlag = bitstream.readBits(1);\n        if (nalHrdParametersPresentFlag) {\n          skipAvcHrdParameters(bitstream);\n        }\n        const vclHrdParametersPresentFlag = bitstream.readBits(1);\n        if (vclHrdParametersPresentFlag) {\n          skipAvcHrdParameters(bitstream);\n        }\n        if (nalHrdParametersPresentFlag || vclHrdParametersPresentFlag) {\n          bitstream.skipBits(1);\n        }\n        bitstream.skipBits(1);\n        const bitstreamRestrictionFlag = bitstream.readBits(1);\n        if (bitstreamRestrictionFlag) {\n          bitstream.skipBits(1);\n          readExpGolomb(bitstream);\n          readExpGolomb(bitstream);\n          readExpGolomb(bitstream);\n          readExpGolomb(bitstream);\n          numReorderFrames = readExpGolomb(bitstream);\n          maxDecFrameBuffering = readExpGolomb(bitstream);\n        }\n      }\n      if (numReorderFrames === null) {\n        assert(maxDecFrameBuffering === null);\n        const constraintSet3Flag = constraintFlags & 16;\n        if ((profileIdc === 44 || profileIdc === 86 || profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244) && constraintSet3Flag) {\n          numReorderFrames = 0;\n          maxDecFrameBuffering = 0;\n        } else {\n          const picWidthInMbs = picWidthInMbsMinus1 + 1;\n          const picHeightInMapUnits = picHeightInMapUnitsMinus1 + 1;\n          const frameHeightInMbs = (2 - frameMbsOnlyFlag) * picHeightInMapUnits;\n          const levelInfo = AVC_LEVEL_TABLE.find(\n            (x) => x.level >= levelIdc\n          ) ?? last(AVC_LEVEL_TABLE);\n          const maxDpbFrames = Math.min(\n            Math.floor(levelInfo.maxDpbMbs / (picWidthInMbs * frameHeightInMbs)),\n            16\n          );\n          numReorderFrames = maxDpbFrames;\n          maxDecFrameBuffering = maxDpbFrames;\n        }\n      }\n      assert(maxDecFrameBuffering !== null);\n      return {\n        profileIdc,\n        constraintFlags,\n        levelIdc,\n        frameMbsOnlyFlag,\n        chromaFormatIdc,\n        bitDepthLumaMinus8,\n        bitDepthChromaMinus8,\n        codedWidth,\n        codedHeight,\n        displayWidth,\n        displayHeight,\n        colourPrimaries,\n        matrixCoefficients,\n        transferCharacteristics,\n        fullRangeFlag,\n        numReorderFrames,\n        maxDecFrameBuffering\n      };\n    } catch (error) {\n      console.error(\"Error parsing AVC SPS:\", error);\n      return null;\n    }\n  };\n  var skipAvcHrdParameters = (bitstream) => {\n    const cpb_cnt_minus1 = readExpGolomb(bitstream);\n    bitstream.skipBits(4);\n    bitstream.skipBits(4);\n    for (let i = 0; i <= cpb_cnt_minus1; i++) {\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      bitstream.skipBits(1);\n    }\n    bitstream.skipBits(5);\n    bitstream.skipBits(5);\n    bitstream.skipBits(5);\n    bitstream.skipBits(5);\n  };\n  var iterateHevcNalUnits = (packetData, decoderConfig) => {\n    if (decoderConfig.description) {\n      const bytes2 = toUint8Array(decoderConfig.description);\n      const lengthSizeMinusOne = bytes2[21] & 3;\n      const lengthSize = lengthSizeMinusOne + 1;\n      return iterateNalUnitsInLengthPrefixed(packetData, lengthSize);\n    } else {\n      return iterateNalUnitsInAnnexB(packetData);\n    }\n  };\n  var iterateHevcNalUnitsAnnexB = function* (packetData) {\n    yield* iterateNalUnitsInAnnexB(packetData);\n  };\n  var extractNalUnitTypeForHevc = (byte) => {\n    return byte >> 1 & 63;\n  };\n  var parseHevcSps = (sps) => {\n    try {\n      const bitstream = new Bitstream(removeEmulationPreventionBytes(sps));\n      bitstream.skipBits(16);\n      bitstream.readBits(4);\n      const spsMaxSubLayersMinus1 = bitstream.readBits(3);\n      const spsTemporalIdNestingFlag = bitstream.readBits(1);\n      const {\n        general_profile_space,\n        general_tier_flag,\n        general_profile_idc,\n        general_profile_compatibility_flags,\n        general_constraint_indicator_flags,\n        general_level_idc\n      } = parseProfileTierLevel(bitstream, spsMaxSubLayersMinus1);\n      readExpGolomb(bitstream);\n      const chromaFormatIdc = readExpGolomb(bitstream);\n      let separateColourPlaneFlag = 0;\n      if (chromaFormatIdc === 3) {\n        separateColourPlaneFlag = bitstream.readBits(1);\n      }\n      const picWidthInLumaSamples = readExpGolomb(bitstream);\n      const picHeightInLumaSamples = readExpGolomb(bitstream);\n      let displayWidth = picWidthInLumaSamples;\n      let displayHeight = picHeightInLumaSamples;\n      if (bitstream.readBits(1)) {\n        const confWinLeftOffset = readExpGolomb(bitstream);\n        const confWinRightOffset = readExpGolomb(bitstream);\n        const confWinTopOffset = readExpGolomb(bitstream);\n        const confWinBottomOffset = readExpGolomb(bitstream);\n        let subWidthC = 1;\n        let subHeightC = 1;\n        const chromaArrayType = separateColourPlaneFlag === 0 ? chromaFormatIdc : 0;\n        if (chromaArrayType === 1) {\n          subWidthC = 2;\n          subHeightC = 2;\n        } else if (chromaArrayType === 2) {\n          subWidthC = 2;\n          subHeightC = 1;\n        }\n        displayWidth -= (confWinLeftOffset + confWinRightOffset) * subWidthC;\n        displayHeight -= (confWinTopOffset + confWinBottomOffset) * subHeightC;\n      }\n      const bitDepthLumaMinus8 = readExpGolomb(bitstream);\n      const bitDepthChromaMinus8 = readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      const spsSubLayerOrderingInfoPresentFlag = bitstream.readBits(1);\n      const startI = spsSubLayerOrderingInfoPresentFlag ? 0 : spsMaxSubLayersMinus1;\n      let spsMaxNumReorderPics = 0;\n      for (let i = startI; i <= spsMaxSubLayersMinus1; i++) {\n        readExpGolomb(bitstream);\n        spsMaxNumReorderPics = readExpGolomb(bitstream);\n        readExpGolomb(bitstream);\n      }\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      if (bitstream.readBits(1)) {\n        if (bitstream.readBits(1)) {\n          skipScalingListData(bitstream);\n        }\n      }\n      bitstream.skipBits(1);\n      bitstream.skipBits(1);\n      if (bitstream.readBits(1)) {\n        bitstream.skipBits(4);\n        bitstream.skipBits(4);\n        readExpGolomb(bitstream);\n        readExpGolomb(bitstream);\n        bitstream.skipBits(1);\n      }\n      const numShortTermRefPicSets = readExpGolomb(bitstream);\n      skipAllStRefPicSets(bitstream, numShortTermRefPicSets);\n      if (bitstream.readBits(1)) {\n        const numLongTermRefPicsSps = readExpGolomb(bitstream);\n        for (let i = 0; i < numLongTermRefPicsSps; i++) {\n          readExpGolomb(bitstream);\n          bitstream.skipBits(1);\n        }\n      }\n      bitstream.skipBits(1);\n      bitstream.skipBits(1);\n      let colourPrimaries = 2;\n      let transferCharacteristics = 2;\n      let matrixCoefficients = 2;\n      let fullRangeFlag = 0;\n      let minSpatialSegmentationIdc = 0;\n      if (bitstream.readBits(1)) {\n        const vui = parseHevcVui(bitstream, spsMaxSubLayersMinus1);\n        colourPrimaries = vui.colourPrimaries;\n        transferCharacteristics = vui.transferCharacteristics;\n        matrixCoefficients = vui.matrixCoefficients;\n        fullRangeFlag = vui.fullRangeFlag;\n        minSpatialSegmentationIdc = vui.minSpatialSegmentationIdc;\n      }\n      return {\n        displayWidth,\n        displayHeight,\n        colourPrimaries,\n        transferCharacteristics,\n        matrixCoefficients,\n        fullRangeFlag,\n        maxDecFrameBuffering: spsMaxNumReorderPics + 1,\n        spsMaxSubLayersMinus1,\n        spsTemporalIdNestingFlag,\n        generalProfileSpace: general_profile_space,\n        generalTierFlag: general_tier_flag,\n        generalProfileIdc: general_profile_idc,\n        generalProfileCompatibilityFlags: general_profile_compatibility_flags,\n        generalConstraintIndicatorFlags: general_constraint_indicator_flags,\n        generalLevelIdc: general_level_idc,\n        chromaFormatIdc,\n        bitDepthLumaMinus8,\n        bitDepthChromaMinus8,\n        minSpatialSegmentationIdc\n      };\n    } catch (error) {\n      console.error(\"Error parsing HEVC SPS:\", error);\n      return null;\n    }\n  };\n  var extractHevcDecoderConfigurationRecord = (packetData) => {\n    try {\n      const vpsUnits = [];\n      const spsUnits = [];\n      const ppsUnits = [];\n      const seiUnits = [];\n      for (const loc of iterateHevcNalUnitsAnnexB(packetData)) {\n        const nalUnit = packetData.subarray(loc.offset, loc.offset + loc.length);\n        const type = extractNalUnitTypeForHevc(nalUnit[0]);\n        if (type === 32 /* VPS_NUT */) {\n          vpsUnits.push(nalUnit);\n        } else if (type === 33 /* SPS_NUT */) {\n          spsUnits.push(nalUnit);\n        } else if (type === 34 /* PPS_NUT */) {\n          ppsUnits.push(nalUnit);\n        } else if (type === 39 /* PREFIX_SEI_NUT */ || type === 40 /* SUFFIX_SEI_NUT */) {\n          seiUnits.push(nalUnit);\n        }\n      }\n      if (spsUnits.length === 0 || ppsUnits.length === 0) return null;\n      const spsInfo = parseHevcSps(spsUnits[0]);\n      if (!spsInfo) return null;\n      let parallelismType = 0;\n      if (ppsUnits.length > 0) {\n        const pps = ppsUnits[0];\n        const ppsBitstream = new Bitstream(removeEmulationPreventionBytes(pps));\n        ppsBitstream.skipBits(16);\n        readExpGolomb(ppsBitstream);\n        readExpGolomb(ppsBitstream);\n        ppsBitstream.skipBits(1);\n        ppsBitstream.skipBits(1);\n        ppsBitstream.skipBits(3);\n        ppsBitstream.skipBits(1);\n        ppsBitstream.skipBits(1);\n        readExpGolomb(ppsBitstream);\n        readExpGolomb(ppsBitstream);\n        readSignedExpGolomb(ppsBitstream);\n        ppsBitstream.skipBits(1);\n        ppsBitstream.skipBits(1);\n        if (ppsBitstream.readBits(1)) {\n          readExpGolomb(ppsBitstream);\n        }\n        readSignedExpGolomb(ppsBitstream);\n        readSignedExpGolomb(ppsBitstream);\n        ppsBitstream.skipBits(1);\n        ppsBitstream.skipBits(1);\n        ppsBitstream.skipBits(1);\n        ppsBitstream.skipBits(1);\n        const tiles_enabled_flag = ppsBitstream.readBits(1);\n        const entropy_coding_sync_enabled_flag = ppsBitstream.readBits(1);\n        if (!tiles_enabled_flag && !entropy_coding_sync_enabled_flag) parallelismType = 0;\n        else if (tiles_enabled_flag && !entropy_coding_sync_enabled_flag) parallelismType = 2;\n        else if (!tiles_enabled_flag && entropy_coding_sync_enabled_flag) parallelismType = 3;\n        else parallelismType = 0;\n      }\n      const arrays = [\n        ...vpsUnits.length ? [\n          {\n            arrayCompleteness: 1,\n            nalUnitType: 32 /* VPS_NUT */,\n            nalUnits: vpsUnits\n          }\n        ] : [],\n        ...spsUnits.length ? [\n          {\n            arrayCompleteness: 1,\n            nalUnitType: 33 /* SPS_NUT */,\n            nalUnits: spsUnits\n          }\n        ] : [],\n        ...ppsUnits.length ? [\n          {\n            arrayCompleteness: 1,\n            nalUnitType: 34 /* PPS_NUT */,\n            nalUnits: ppsUnits\n          }\n        ] : [],\n        ...seiUnits.length ? [\n          {\n            arrayCompleteness: 1,\n            nalUnitType: extractNalUnitTypeForHevc(seiUnits[0][0]),\n            nalUnits: seiUnits\n          }\n        ] : []\n      ];\n      const record = {\n        configurationVersion: 1,\n        generalProfileSpace: spsInfo.generalProfileSpace,\n        generalTierFlag: spsInfo.generalTierFlag,\n        generalProfileIdc: spsInfo.generalProfileIdc,\n        generalProfileCompatibilityFlags: spsInfo.generalProfileCompatibilityFlags,\n        generalConstraintIndicatorFlags: spsInfo.generalConstraintIndicatorFlags,\n        generalLevelIdc: spsInfo.generalLevelIdc,\n        minSpatialSegmentationIdc: spsInfo.minSpatialSegmentationIdc,\n        parallelismType,\n        chromaFormatIdc: spsInfo.chromaFormatIdc,\n        bitDepthLumaMinus8: spsInfo.bitDepthLumaMinus8,\n        bitDepthChromaMinus8: spsInfo.bitDepthChromaMinus8,\n        avgFrameRate: 0,\n        constantFrameRate: 0,\n        numTemporalLayers: spsInfo.spsMaxSubLayersMinus1 + 1,\n        temporalIdNested: spsInfo.spsTemporalIdNestingFlag,\n        lengthSizeMinusOne: 3,\n        arrays\n      };\n      return record;\n    } catch (error) {\n      console.error(\"Error building HEVC Decoder Configuration Record:\", error);\n      return null;\n    }\n  };\n  var parseProfileTierLevel = (bitstream, maxNumSubLayersMinus1) => {\n    const general_profile_space = bitstream.readBits(2);\n    const general_tier_flag = bitstream.readBits(1);\n    const general_profile_idc = bitstream.readBits(5);\n    let general_profile_compatibility_flags = 0;\n    for (let i = 0; i < 32; i++) {\n      general_profile_compatibility_flags = general_profile_compatibility_flags << 1 | bitstream.readBits(1);\n    }\n    const general_constraint_indicator_flags = new Uint8Array(6);\n    for (let i = 0; i < 6; i++) {\n      general_constraint_indicator_flags[i] = bitstream.readBits(8);\n    }\n    const general_level_idc = bitstream.readBits(8);\n    const sub_layer_profile_present_flag = [];\n    const sub_layer_level_present_flag = [];\n    for (let i = 0; i < maxNumSubLayersMinus1; i++) {\n      sub_layer_profile_present_flag.push(bitstream.readBits(1));\n      sub_layer_level_present_flag.push(bitstream.readBits(1));\n    }\n    if (maxNumSubLayersMinus1 > 0) {\n      for (let i = maxNumSubLayersMinus1; i < 8; i++) {\n        bitstream.skipBits(2);\n      }\n    }\n    for (let i = 0; i < maxNumSubLayersMinus1; i++) {\n      if (sub_layer_profile_present_flag[i]) bitstream.skipBits(88);\n      if (sub_layer_level_present_flag[i]) bitstream.skipBits(8);\n    }\n    return {\n      general_profile_space,\n      general_tier_flag,\n      general_profile_idc,\n      general_profile_compatibility_flags,\n      general_constraint_indicator_flags,\n      general_level_idc\n    };\n  };\n  var skipScalingListData = (bitstream) => {\n    for (let sizeId = 0; sizeId < 4; sizeId++) {\n      for (let matrixId = 0; matrixId < (sizeId === 3 ? 2 : 6); matrixId++) {\n        const scaling_list_pred_mode_flag = bitstream.readBits(1);\n        if (!scaling_list_pred_mode_flag) {\n          readExpGolomb(bitstream);\n        } else {\n          const coefNum = Math.min(64, 1 << 4 + (sizeId << 1));\n          if (sizeId > 1) {\n            readSignedExpGolomb(bitstream);\n          }\n          for (let i = 0; i < coefNum; i++) {\n            readSignedExpGolomb(bitstream);\n          }\n        }\n      }\n    }\n  };\n  var skipAllStRefPicSets = (bitstream, num_short_term_ref_pic_sets) => {\n    const NumDeltaPocs = [];\n    for (let stRpsIdx = 0; stRpsIdx < num_short_term_ref_pic_sets; stRpsIdx++) {\n      NumDeltaPocs[stRpsIdx] = skipStRefPicSet(bitstream, stRpsIdx, num_short_term_ref_pic_sets, NumDeltaPocs);\n    }\n  };\n  var skipStRefPicSet = (bitstream, stRpsIdx, num_short_term_ref_pic_sets, NumDeltaPocs) => {\n    let NumDeltaPocsThis = 0;\n    let inter_ref_pic_set_prediction_flag = 0;\n    let RefRpsIdx = 0;\n    if (stRpsIdx !== 0) {\n      inter_ref_pic_set_prediction_flag = bitstream.readBits(1);\n    }\n    if (inter_ref_pic_set_prediction_flag) {\n      if (stRpsIdx === num_short_term_ref_pic_sets) {\n        const delta_idx_minus1 = readExpGolomb(bitstream);\n        RefRpsIdx = stRpsIdx - (delta_idx_minus1 + 1);\n      } else {\n        RefRpsIdx = stRpsIdx - 1;\n      }\n      bitstream.readBits(1);\n      readExpGolomb(bitstream);\n      const numDelta = NumDeltaPocs[RefRpsIdx] ?? 0;\n      for (let j = 0; j <= numDelta; j++) {\n        const used_by_curr_pic_flag = bitstream.readBits(1);\n        if (!used_by_curr_pic_flag) {\n          bitstream.readBits(1);\n        }\n      }\n      NumDeltaPocsThis = NumDeltaPocs[RefRpsIdx];\n    } else {\n      const num_negative_pics = readExpGolomb(bitstream);\n      const num_positive_pics = readExpGolomb(bitstream);\n      for (let i = 0; i < num_negative_pics; i++) {\n        readExpGolomb(bitstream);\n        bitstream.readBits(1);\n      }\n      for (let i = 0; i < num_positive_pics; i++) {\n        readExpGolomb(bitstream);\n        bitstream.readBits(1);\n      }\n      NumDeltaPocsThis = num_negative_pics + num_positive_pics;\n    }\n    return NumDeltaPocsThis;\n  };\n  var parseHevcVui = (bitstream, sps_max_sub_layers_minus1) => {\n    let colourPrimaries = 2;\n    let transferCharacteristics = 2;\n    let matrixCoefficients = 2;\n    let fullRangeFlag = 0;\n    let minSpatialSegmentationIdc = 0;\n    if (bitstream.readBits(1)) {\n      const aspect_ratio_idc = bitstream.readBits(8);\n      if (aspect_ratio_idc === 255) {\n        bitstream.readBits(16);\n        bitstream.readBits(16);\n      }\n    }\n    if (bitstream.readBits(1)) {\n      bitstream.readBits(1);\n    }\n    if (bitstream.readBits(1)) {\n      bitstream.readBits(3);\n      fullRangeFlag = bitstream.readBits(1);\n      if (bitstream.readBits(1)) {\n        colourPrimaries = bitstream.readBits(8);\n        transferCharacteristics = bitstream.readBits(8);\n        matrixCoefficients = bitstream.readBits(8);\n      }\n    }\n    if (bitstream.readBits(1)) {\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n    }\n    bitstream.readBits(1);\n    bitstream.readBits(1);\n    bitstream.readBits(1);\n    if (bitstream.readBits(1)) {\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n    }\n    if (bitstream.readBits(1)) {\n      bitstream.readBits(32);\n      bitstream.readBits(32);\n      if (bitstream.readBits(1)) {\n        readExpGolomb(bitstream);\n      }\n      if (bitstream.readBits(1)) {\n        skipHevcHrdParameters(bitstream, true, sps_max_sub_layers_minus1);\n      }\n    }\n    if (bitstream.readBits(1)) {\n      bitstream.readBits(1);\n      bitstream.readBits(1);\n      bitstream.readBits(1);\n      minSpatialSegmentationIdc = readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n    }\n    return {\n      colourPrimaries,\n      transferCharacteristics,\n      matrixCoefficients,\n      fullRangeFlag,\n      minSpatialSegmentationIdc\n    };\n  };\n  var skipHevcHrdParameters = (bitstream, commonInfPresentFlag, maxNumSubLayersMinus1) => {\n    let nal_hrd_parameters_present_flag = false;\n    let vcl_hrd_parameters_present_flag = false;\n    let sub_pic_hrd_params_present_flag = false;\n    if (commonInfPresentFlag) {\n      nal_hrd_parameters_present_flag = bitstream.readBits(1) === 1;\n      vcl_hrd_parameters_present_flag = bitstream.readBits(1) === 1;\n      if (nal_hrd_parameters_present_flag || vcl_hrd_parameters_present_flag) {\n        sub_pic_hrd_params_present_flag = bitstream.readBits(1) === 1;\n        if (sub_pic_hrd_params_present_flag) {\n          bitstream.readBits(8);\n          bitstream.readBits(5);\n          bitstream.readBits(1);\n          bitstream.readBits(5);\n        }\n        bitstream.readBits(4);\n        bitstream.readBits(4);\n        if (sub_pic_hrd_params_present_flag) {\n          bitstream.readBits(4);\n        }\n        bitstream.readBits(5);\n        bitstream.readBits(5);\n        bitstream.readBits(5);\n      }\n    }\n    for (let i = 0; i <= maxNumSubLayersMinus1; i++) {\n      const fixed_pic_rate_general_flag = bitstream.readBits(1) === 1;\n      let fixed_pic_rate_within_cvs_flag = true;\n      if (!fixed_pic_rate_general_flag) {\n        fixed_pic_rate_within_cvs_flag = bitstream.readBits(1) === 1;\n      }\n      let low_delay_hrd_flag = false;\n      if (fixed_pic_rate_within_cvs_flag) {\n        readExpGolomb(bitstream);\n      } else {\n        low_delay_hrd_flag = bitstream.readBits(1) === 1;\n      }\n      let CpbCnt = 1;\n      if (!low_delay_hrd_flag) {\n        const cpb_cnt_minus1 = readExpGolomb(bitstream);\n        CpbCnt = cpb_cnt_minus1 + 1;\n      }\n      if (nal_hrd_parameters_present_flag) {\n        skipSubLayerHrdParameters(bitstream, CpbCnt, sub_pic_hrd_params_present_flag);\n      }\n      if (vcl_hrd_parameters_present_flag) {\n        skipSubLayerHrdParameters(bitstream, CpbCnt, sub_pic_hrd_params_present_flag);\n      }\n    }\n  };\n  var skipSubLayerHrdParameters = (bitstream, CpbCnt, sub_pic_hrd_params_present_flag) => {\n    for (let i = 0; i < CpbCnt; i++) {\n      readExpGolomb(bitstream);\n      readExpGolomb(bitstream);\n      if (sub_pic_hrd_params_present_flag) {\n        readExpGolomb(bitstream);\n        readExpGolomb(bitstream);\n      }\n      bitstream.readBits(1);\n    }\n  };\n  var serializeHevcDecoderConfigurationRecord = (record) => {\n    const bytes2 = [];\n    bytes2.push(record.configurationVersion);\n    bytes2.push(\n      (record.generalProfileSpace & 3) << 6 | (record.generalTierFlag & 1) << 5 | record.generalProfileIdc & 31\n    );\n    bytes2.push(record.generalProfileCompatibilityFlags >>> 24 & 255);\n    bytes2.push(record.generalProfileCompatibilityFlags >>> 16 & 255);\n    bytes2.push(record.generalProfileCompatibilityFlags >>> 8 & 255);\n    bytes2.push(record.generalProfileCompatibilityFlags & 255);\n    bytes2.push(...record.generalConstraintIndicatorFlags);\n    bytes2.push(record.generalLevelIdc & 255);\n    bytes2.push(240 | record.minSpatialSegmentationIdc >> 8 & 15);\n    bytes2.push(record.minSpatialSegmentationIdc & 255);\n    bytes2.push(252 | record.parallelismType & 3);\n    bytes2.push(252 | record.chromaFormatIdc & 3);\n    bytes2.push(248 | record.bitDepthLumaMinus8 & 7);\n    bytes2.push(248 | record.bitDepthChromaMinus8 & 7);\n    bytes2.push(record.avgFrameRate >> 8 & 255);\n    bytes2.push(record.avgFrameRate & 255);\n    bytes2.push(\n      (record.constantFrameRate & 3) << 6 | (record.numTemporalLayers & 7) << 3 | (record.temporalIdNested & 1) << 2 | record.lengthSizeMinusOne & 3\n    );\n    bytes2.push(record.arrays.length & 255);\n    for (const arr of record.arrays) {\n      bytes2.push(\n        (arr.arrayCompleteness & 1) << 7 | 0 << 6 | arr.nalUnitType & 63\n      );\n      bytes2.push(arr.nalUnits.length >> 8 & 255);\n      bytes2.push(arr.nalUnits.length & 255);\n      for (const nal of arr.nalUnits) {\n        bytes2.push(nal.length >> 8 & 255);\n        bytes2.push(nal.length & 255);\n        for (let i = 0; i < nal.length; i++) {\n          bytes2.push(nal[i]);\n        }\n      }\n    }\n    return new Uint8Array(bytes2);\n  };\n  var deserializeHevcDecoderConfigurationRecord = (data) => {\n    try {\n      const view2 = toDataView(data);\n      let offset = 0;\n      const configurationVersion = view2.getUint8(offset++);\n      const byte1 = view2.getUint8(offset++);\n      const generalProfileSpace = byte1 >> 6 & 3;\n      const generalTierFlag = byte1 >> 5 & 1;\n      const generalProfileIdc = byte1 & 31;\n      const generalProfileCompatibilityFlags = view2.getUint32(offset, false);\n      offset += 4;\n      const generalConstraintIndicatorFlags = data.subarray(offset, offset + 6);\n      offset += 6;\n      const generalLevelIdc = view2.getUint8(offset++);\n      const minSpatialSegmentationIdc = (view2.getUint8(offset++) & 15) << 8 | view2.getUint8(offset++);\n      const parallelismType = view2.getUint8(offset++) & 3;\n      const chromaFormatIdc = view2.getUint8(offset++) & 3;\n      const bitDepthLumaMinus8 = view2.getUint8(offset++) & 7;\n      const bitDepthChromaMinus8 = view2.getUint8(offset++) & 7;\n      const avgFrameRate = view2.getUint16(offset, false);\n      offset += 2;\n      const byte21 = view2.getUint8(offset++);\n      const constantFrameRate = byte21 >> 6 & 3;\n      const numTemporalLayers = byte21 >> 3 & 7;\n      const temporalIdNested = byte21 >> 2 & 1;\n      const lengthSizeMinusOne = byte21 & 3;\n      const numOfArrays = view2.getUint8(offset++);\n      const arrays = [];\n      for (let i = 0; i < numOfArrays; i++) {\n        const arrByte = view2.getUint8(offset++);\n        const arrayCompleteness = arrByte >> 7 & 1;\n        const nalUnitType = arrByte & 63;\n        const numNalus = view2.getUint16(offset, false);\n        offset += 2;\n        const nalUnits = [];\n        for (let j = 0; j < numNalus; j++) {\n          const nalUnitLength = view2.getUint16(offset, false);\n          offset += 2;\n          nalUnits.push(data.subarray(offset, offset + nalUnitLength));\n          offset += nalUnitLength;\n        }\n        arrays.push({\n          arrayCompleteness,\n          nalUnitType,\n          nalUnits\n        });\n      }\n      return {\n        configurationVersion,\n        generalProfileSpace,\n        generalTierFlag,\n        generalProfileIdc,\n        generalProfileCompatibilityFlags,\n        generalConstraintIndicatorFlags,\n        generalLevelIdc,\n        minSpatialSegmentationIdc,\n        parallelismType,\n        chromaFormatIdc,\n        bitDepthLumaMinus8,\n        bitDepthChromaMinus8,\n        avgFrameRate,\n        constantFrameRate,\n        numTemporalLayers,\n        temporalIdNested,\n        lengthSizeMinusOne,\n        arrays\n      };\n    } catch (error) {\n      console.error(\"Error deserializing HEVC Decoder Configuration Record:\", error);\n      return null;\n    }\n  };\n  var extractVp9CodecInfoFromPacket = (packet) => {\n    const bitstream = new Bitstream(packet);\n    const frameMarker = bitstream.readBits(2);\n    if (frameMarker !== 2) {\n      return null;\n    }\n    const profileLowBit = bitstream.readBits(1);\n    const profileHighBit = bitstream.readBits(1);\n    const profile = (profileHighBit << 1) + profileLowBit;\n    if (profile === 3) {\n      bitstream.skipBits(1);\n    }\n    const showExistingFrame = bitstream.readBits(1);\n    if (showExistingFrame === 1) {\n      return null;\n    }\n    const frameType = bitstream.readBits(1);\n    if (frameType !== 0) {\n      return null;\n    }\n    bitstream.skipBits(2);\n    const syncCode = bitstream.readBits(24);\n    if (syncCode !== 4817730) {\n      return null;\n    }\n    let bitDepth = 8;\n    if (profile >= 2) {\n      const tenOrTwelveBit = bitstream.readBits(1);\n      bitDepth = tenOrTwelveBit ? 12 : 10;\n    }\n    const colorSpace = bitstream.readBits(3);\n    let chromaSubsampling = 0;\n    let videoFullRangeFlag = 0;\n    if (colorSpace !== 7) {\n      const colorRange = bitstream.readBits(1);\n      videoFullRangeFlag = colorRange;\n      if (profile === 1 || profile === 3) {\n        const subsamplingX = bitstream.readBits(1);\n        const subsamplingY = bitstream.readBits(1);\n        chromaSubsampling = !subsamplingX && !subsamplingY ? 3 : subsamplingX && !subsamplingY ? 2 : 1;\n        bitstream.skipBits(1);\n      } else {\n        chromaSubsampling = 1;\n      }\n    } else {\n      chromaSubsampling = 3;\n      videoFullRangeFlag = 1;\n    }\n    const widthMinusOne = bitstream.readBits(16);\n    const heightMinusOne = bitstream.readBits(16);\n    const width = widthMinusOne + 1;\n    const height = heightMinusOne + 1;\n    const pictureSize = width * height;\n    let level = last(VP9_LEVEL_TABLE).level;\n    for (const entry of VP9_LEVEL_TABLE) {\n      if (pictureSize <= entry.maxPictureSize) {\n        level = entry.level;\n        break;\n      }\n    }\n    const matrixCoefficients = colorSpace === 7 ? 0 : colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;\n    const colourPrimaries = colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;\n    const transferCharacteristics = colorSpace === 2 ? 1 : colorSpace === 1 ? 6 : 2;\n    return {\n      profile,\n      level,\n      bitDepth,\n      chromaSubsampling,\n      videoFullRangeFlag,\n      colourPrimaries,\n      transferCharacteristics,\n      matrixCoefficients\n    };\n  };\n  var iterateAv1PacketObus = function* (packet) {\n    const bitstream = new Bitstream(packet);\n    const readLeb128 = () => {\n      let value = 0;\n      for (let i = 0; i < 8; i++) {\n        const byte = bitstream.readAlignedByte();\n        value |= (byte & 127) << i * 7;\n        if (!(byte & 128)) {\n          break;\n        }\n        if (i === 7 && byte & 128) {\n          return null;\n        }\n      }\n      if (value >= 2 ** 32 - 1) {\n        return null;\n      }\n      return value;\n    };\n    while (bitstream.getBitsLeft() >= 8) {\n      bitstream.skipBits(1);\n      const obuType = bitstream.readBits(4);\n      const obuExtension = bitstream.readBits(1);\n      const obuHasSizeField = bitstream.readBits(1);\n      bitstream.skipBits(1);\n      if (obuExtension) {\n        bitstream.skipBits(8);\n      }\n      let obuSize;\n      if (obuHasSizeField) {\n        const obuSizeValue = readLeb128();\n        if (obuSizeValue === null) return;\n        obuSize = obuSizeValue;\n      } else {\n        obuSize = Math.floor(bitstream.getBitsLeft() / 8);\n      }\n      assert(bitstream.pos % 8 === 0);\n      yield {\n        type: obuType,\n        data: packet.subarray(bitstream.pos / 8, bitstream.pos / 8 + obuSize)\n      };\n      bitstream.skipBits(obuSize * 8);\n    }\n  };\n  var extractAv1CodecInfoFromPacket = (packet) => {\n    for (const { type, data } of iterateAv1PacketObus(packet)) {\n      if (type !== 1) {\n        continue;\n      }\n      const bitstream = new Bitstream(data);\n      const seqProfile = bitstream.readBits(3);\n      const stillPicture = bitstream.readBits(1);\n      const reducedStillPictureHeader = bitstream.readBits(1);\n      let seqLevel = 0;\n      let seqTier = 0;\n      let bufferDelayLengthMinus1 = 0;\n      if (reducedStillPictureHeader) {\n        seqLevel = bitstream.readBits(5);\n      } else {\n        const timingInfoPresentFlag = bitstream.readBits(1);\n        if (timingInfoPresentFlag) {\n          bitstream.skipBits(32);\n          bitstream.skipBits(32);\n          const equalPictureInterval = bitstream.readBits(1);\n          if (equalPictureInterval) {\n            return null;\n          }\n        }\n        const decoderModelInfoPresentFlag = bitstream.readBits(1);\n        if (decoderModelInfoPresentFlag) {\n          bufferDelayLengthMinus1 = bitstream.readBits(5);\n          bitstream.skipBits(32);\n          bitstream.skipBits(5);\n          bitstream.skipBits(5);\n        }\n        const operatingPointsCntMinus1 = bitstream.readBits(5);\n        for (let i = 0; i <= operatingPointsCntMinus1; i++) {\n          bitstream.skipBits(12);\n          const seqLevelIdx = bitstream.readBits(5);\n          if (i === 0) {\n            seqLevel = seqLevelIdx;\n          }\n          if (seqLevelIdx > 7) {\n            const seqTierTemp = bitstream.readBits(1);\n            if (i === 0) {\n              seqTier = seqTierTemp;\n            }\n          }\n          if (decoderModelInfoPresentFlag) {\n            const decoderModelPresentForThisOp = bitstream.readBits(1);\n            if (decoderModelPresentForThisOp) {\n              const n = bufferDelayLengthMinus1 + 1;\n              bitstream.skipBits(n);\n              bitstream.skipBits(n);\n              bitstream.skipBits(1);\n            }\n          }\n          const initialDisplayDelayPresentFlag = bitstream.readBits(1);\n          if (initialDisplayDelayPresentFlag) {\n            bitstream.skipBits(4);\n          }\n        }\n      }\n      const frameWidthBitsMinus1 = bitstream.readBits(4);\n      const frameHeightBitsMinus1 = bitstream.readBits(4);\n      const n1 = frameWidthBitsMinus1 + 1;\n      bitstream.skipBits(n1);\n      const n2 = frameHeightBitsMinus1 + 1;\n      bitstream.skipBits(n2);\n      let frameIdNumbersPresentFlag = 0;\n      if (reducedStillPictureHeader) {\n        frameIdNumbersPresentFlag = 0;\n      } else {\n        frameIdNumbersPresentFlag = bitstream.readBits(1);\n      }\n      if (frameIdNumbersPresentFlag) {\n        bitstream.skipBits(4);\n        bitstream.skipBits(3);\n      }\n      bitstream.skipBits(1);\n      bitstream.skipBits(1);\n      bitstream.skipBits(1);\n      if (!reducedStillPictureHeader) {\n        bitstream.skipBits(1);\n        bitstream.skipBits(1);\n        bitstream.skipBits(1);\n        bitstream.skipBits(1);\n        const enableOrderHint = bitstream.readBits(1);\n        if (enableOrderHint) {\n          bitstream.skipBits(1);\n          bitstream.skipBits(1);\n        }\n        const seqChooseScreenContentTools = bitstream.readBits(1);\n        let seqForceScreenContentTools = 0;\n        if (seqChooseScreenContentTools) {\n          seqForceScreenContentTools = 2;\n        } else {\n          seqForceScreenContentTools = bitstream.readBits(1);\n        }\n        if (seqForceScreenContentTools > 0) {\n          const seqChooseIntegerMv = bitstream.readBits(1);\n          if (!seqChooseIntegerMv) {\n            bitstream.skipBits(1);\n          }\n        }\n        if (enableOrderHint) {\n          bitstream.skipBits(3);\n        }\n      }\n      bitstream.skipBits(1);\n      bitstream.skipBits(1);\n      bitstream.skipBits(1);\n      const highBitdepth = bitstream.readBits(1);\n      let bitDepth = 8;\n      if (seqProfile === 2 && highBitdepth) {\n        const twelveBit = bitstream.readBits(1);\n        bitDepth = twelveBit ? 12 : 10;\n      } else if (seqProfile <= 2) {\n        bitDepth = highBitdepth ? 10 : 8;\n      }\n      let monochrome = 0;\n      if (seqProfile !== 1) {\n        monochrome = bitstream.readBits(1);\n      }\n      let chromaSubsamplingX = 1;\n      let chromaSubsamplingY = 1;\n      let chromaSamplePosition = 0;\n      if (!monochrome) {\n        if (seqProfile === 0) {\n          chromaSubsamplingX = 1;\n          chromaSubsamplingY = 1;\n        } else if (seqProfile === 1) {\n          chromaSubsamplingX = 0;\n          chromaSubsamplingY = 0;\n        } else {\n          if (bitDepth === 12) {\n            chromaSubsamplingX = bitstream.readBits(1);\n            if (chromaSubsamplingX) {\n              chromaSubsamplingY = bitstream.readBits(1);\n            }\n          }\n        }\n        if (chromaSubsamplingX && chromaSubsamplingY) {\n          chromaSamplePosition = bitstream.readBits(2);\n        }\n      }\n      return {\n        profile: seqProfile,\n        level: seqLevel,\n        tier: seqTier,\n        bitDepth,\n        monochrome,\n        chromaSubsamplingX,\n        chromaSubsamplingY,\n        chromaSamplePosition\n      };\n    }\n    return null;\n  };\n  var parseOpusIdentificationHeader = (bytes2) => {\n    const view2 = toDataView(bytes2);\n    const outputChannelCount = view2.getUint8(9);\n    const preSkip = view2.getUint16(10, true);\n    const inputSampleRate = view2.getUint32(12, true);\n    const outputGain = view2.getInt16(16, true);\n    const channelMappingFamily = view2.getUint8(18);\n    let channelMappingTable = null;\n    if (channelMappingFamily) {\n      channelMappingTable = bytes2.subarray(19, 19 + 2 + outputChannelCount);\n    }\n    return {\n      outputChannelCount,\n      preSkip,\n      inputSampleRate,\n      outputGain,\n      channelMappingFamily,\n      channelMappingTable\n    };\n  };\n  var OPUS_FRAME_DURATION_TABLE = [\n    480,\n    960,\n    1920,\n    2880,\n    480,\n    960,\n    1920,\n    2880,\n    480,\n    960,\n    1920,\n    2880,\n    480,\n    960,\n    480,\n    960,\n    120,\n    240,\n    480,\n    960,\n    120,\n    240,\n    480,\n    960,\n    120,\n    240,\n    480,\n    960,\n    120,\n    240,\n    480,\n    960\n  ];\n  var parseOpusTocByte = (packet) => {\n    const config = packet[0] >> 3;\n    return {\n      durationInSamples: OPUS_FRAME_DURATION_TABLE[config]\n    };\n  };\n  var parseModesFromVorbisSetupPacket = (setupHeader) => {\n    if (setupHeader.length < 7) {\n      throw new Error(\"Setup header is too short.\");\n    }\n    if (setupHeader[0] !== 5) {\n      throw new Error(\"Wrong packet type in Setup header.\");\n    }\n    const signature = String.fromCharCode(...setupHeader.slice(1, 7));\n    if (signature !== \"vorbis\") {\n      throw new Error(\"Invalid packet signature in Setup header.\");\n    }\n    const bufSize = setupHeader.length;\n    const revBuffer = new Uint8Array(bufSize);\n    for (let i = 0; i < bufSize; i++) {\n      revBuffer[i] = setupHeader[bufSize - 1 - i];\n    }\n    const bitstream = new Bitstream(revBuffer);\n    let gotFramingBit = 0;\n    while (bitstream.getBitsLeft() > 97) {\n      if (bitstream.readBits(1) === 1) {\n        gotFramingBit = bitstream.pos;\n        break;\n      }\n    }\n    if (gotFramingBit === 0) {\n      throw new Error(\"Invalid Setup header: framing bit not found.\");\n    }\n    let modeCount = 0;\n    let gotModeHeader = false;\n    let lastModeCount = 0;\n    while (bitstream.getBitsLeft() >= 97) {\n      const tempPos = bitstream.pos;\n      const a = bitstream.readBits(8);\n      const b = bitstream.readBits(16);\n      const c = bitstream.readBits(16);\n      if (a > 63 || b !== 0 || c !== 0) {\n        bitstream.pos = tempPos;\n        break;\n      }\n      bitstream.skipBits(1);\n      modeCount++;\n      if (modeCount > 64) {\n        break;\n      }\n      const bsClone = bitstream.clone();\n      const candidate = bsClone.readBits(6) + 1;\n      if (candidate === modeCount) {\n        gotModeHeader = true;\n        lastModeCount = modeCount;\n      }\n    }\n    if (!gotModeHeader) {\n      throw new Error(\"Invalid Setup header: mode header not found.\");\n    }\n    if (lastModeCount > 63) {\n      throw new Error(`Unsupported mode count: ${lastModeCount}.`);\n    }\n    const finalModeCount = lastModeCount;\n    bitstream.pos = 0;\n    bitstream.skipBits(gotFramingBit);\n    const modeBlockflags = Array(finalModeCount).fill(0);\n    for (let i = finalModeCount - 1; i >= 0; i--) {\n      bitstream.skipBits(40);\n      modeBlockflags[i] = bitstream.readBits(1);\n    }\n    return { modeBlockflags };\n  };\n  var determineVideoPacketType = (codec, decoderConfig, packetData) => {\n    switch (codec) {\n      case \"avc\":\n        {\n          for (const loc of iterateAvcNalUnits(packetData, decoderConfig)) {\n            const nalTypeByte = packetData[loc.offset];\n            const type = extractNalUnitTypeForAvc(nalTypeByte);\n            if (type >= 1 /* NON_IDR_SLICE */ && type <= 4 /* SLICE_DPC */) {\n              return \"delta\";\n            }\n            if (type === 5 /* IDR */) {\n              return \"key\";\n            }\n            if (type === 6 /* SEI */ && (!isChromium() || getChromiumVersion() >= 144)) {\n              const nalUnit = packetData.subarray(loc.offset, loc.offset + loc.length);\n              const bytes2 = removeEmulationPreventionBytes(nalUnit);\n              let pos = 1;\n              do {\n                let payloadType = 0;\n                while (true) {\n                  const nextByte = bytes2[pos++];\n                  if (nextByte === void 0) break;\n                  payloadType += nextByte;\n                  if (nextByte < 255) {\n                    break;\n                  }\n                }\n                let payloadSize = 0;\n                while (true) {\n                  const nextByte = bytes2[pos++];\n                  if (nextByte === void 0) break;\n                  payloadSize += nextByte;\n                  if (nextByte < 255) {\n                    break;\n                  }\n                }\n                const PAYLOAD_TYPE_RECOVERY_POINT = 6;\n                if (payloadType === PAYLOAD_TYPE_RECOVERY_POINT) {\n                  const bitstream = new Bitstream(bytes2);\n                  bitstream.pos = 8 * pos;\n                  const recoveryFrameCount = readExpGolomb(bitstream);\n                  const exactMatchFlag = bitstream.readBits(1);\n                  if (recoveryFrameCount === 0 && exactMatchFlag === 1) {\n                    return \"key\";\n                  }\n                }\n                pos += payloadSize;\n              } while (pos < bytes2.length - 1);\n            }\n          }\n          return \"delta\";\n        }\n        ;\n      case \"hevc\":\n        {\n          for (const loc of iterateHevcNalUnits(packetData, decoderConfig)) {\n            const type = extractNalUnitTypeForHevc(packetData[loc.offset]);\n            if (type < 16 /* BLA_W_LP */) {\n              return \"delta\";\n            }\n            if (type <= 23 /* RSV_IRAP_VCL23 */) {\n              return \"key\";\n            }\n          }\n          return \"delta\";\n        }\n        ;\n      case \"vp8\":\n        {\n          const frameType = packetData[0] & 1;\n          return frameType === 0 ? \"key\" : \"delta\";\n        }\n        ;\n      case \"vp9\":\n        {\n          const bitstream = new Bitstream(packetData);\n          if (bitstream.readBits(2) !== 2) {\n            return null;\n          }\n          ;\n          const profileLowBit = bitstream.readBits(1);\n          const profileHighBit = bitstream.readBits(1);\n          const profile = (profileHighBit << 1) + profileLowBit;\n          if (profile === 3) {\n            bitstream.skipBits(1);\n          }\n          const showExistingFrame = bitstream.readBits(1);\n          if (showExistingFrame) {\n            return null;\n          }\n          const frameType = bitstream.readBits(1);\n          return frameType === 0 ? \"key\" : \"delta\";\n        }\n        ;\n      case \"av1\":\n        {\n          let reducedStillPictureHeader = false;\n          for (const { type, data } of iterateAv1PacketObus(packetData)) {\n            if (type === 1) {\n              const bitstream = new Bitstream(data);\n              bitstream.skipBits(4);\n              reducedStillPictureHeader = !!bitstream.readBits(1);\n            } else if (type === 3 || type === 6 || type === 7) {\n              if (reducedStillPictureHeader) {\n                return \"key\";\n              }\n              const bitstream = new Bitstream(data);\n              const showExistingFrame = bitstream.readBits(1);\n              if (showExistingFrame) {\n                return null;\n              }\n              const frameType = bitstream.readBits(2);\n              return frameType === 0 ? \"key\" : \"delta\";\n            }\n          }\n          return null;\n        }\n        ;\n      default:\n        {\n          assertNever(codec);\n          assert(false);\n        }\n        ;\n    }\n  };\n  var readVorbisComments = (bytes2, metadataTags) => {\n    const commentView = toDataView(bytes2);\n    let commentPos = 0;\n    const vendorStringLength = commentView.getUint32(commentPos, true);\n    commentPos += 4;\n    const vendorString = textDecoder.decode(\n      bytes2.subarray(commentPos, commentPos + vendorStringLength)\n    );\n    commentPos += vendorStringLength;\n    if (vendorStringLength > 0) {\n      metadataTags.raw ??= {};\n      metadataTags.raw[\"vendor\"] ??= vendorString;\n    }\n    const listLength = commentView.getUint32(commentPos, true);\n    commentPos += 4;\n    for (let i = 0; i < listLength; i++) {\n      const stringLength = commentView.getUint32(commentPos, true);\n      commentPos += 4;\n      const string = textDecoder.decode(\n        bytes2.subarray(commentPos, commentPos + stringLength)\n      );\n      commentPos += stringLength;\n      const separatorIndex = string.indexOf(\"=\");\n      if (separatorIndex === -1) {\n        continue;\n      }\n      const key = string.slice(0, separatorIndex).toUpperCase();\n      const value = string.slice(separatorIndex + 1);\n      metadataTags.raw ??= {};\n      metadataTags.raw[key] ??= value;\n      switch (key) {\n        case \"TITLE\":\n          {\n            metadataTags.title ??= value;\n          }\n          ;\n          break;\n        case \"DESCRIPTION\":\n          {\n            metadataTags.description ??= value;\n          }\n          ;\n          break;\n        case \"ARTIST\":\n          {\n            metadataTags.artist ??= value;\n          }\n          ;\n          break;\n        case \"ALBUM\":\n          {\n            metadataTags.album ??= value;\n          }\n          ;\n          break;\n        case \"ALBUMARTIST\":\n          {\n            metadataTags.albumArtist ??= value;\n          }\n          ;\n          break;\n        case \"COMMENT\":\n          {\n            metadataTags.comment ??= value;\n          }\n          ;\n          break;\n        case \"LYRICS\":\n          {\n            metadataTags.lyrics ??= value;\n          }\n          ;\n          break;\n        case \"TRACKNUMBER\":\n          {\n            const parts = value.split(\"/\");\n            const trackNum = Number.parseInt(parts[0], 10);\n            const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);\n            if (Number.isInteger(trackNum) && trackNum > 0) {\n              metadataTags.trackNumber ??= trackNum;\n            }\n            if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {\n              metadataTags.tracksTotal ??= tracksTotal;\n            }\n          }\n          ;\n          break;\n        case \"TRACKTOTAL\":\n          {\n            const tracksTotal = Number.parseInt(value, 10);\n            if (Number.isInteger(tracksTotal) && tracksTotal > 0) {\n              metadataTags.tracksTotal ??= tracksTotal;\n            }\n          }\n          ;\n          break;\n        case \"DISCNUMBER\":\n          {\n            const parts = value.split(\"/\");\n            const discNum = Number.parseInt(parts[0], 10);\n            const discsTotal = parts[1] && Number.parseInt(parts[1], 10);\n            if (Number.isInteger(discNum) && discNum > 0) {\n              metadataTags.discNumber ??= discNum;\n            }\n            if (discsTotal && Number.isInteger(discsTotal) && discsTotal > 0) {\n              metadataTags.discsTotal ??= discsTotal;\n            }\n          }\n          ;\n          break;\n        case \"DISCTOTAL\":\n          {\n            const discsTotal = Number.parseInt(value, 10);\n            if (Number.isInteger(discsTotal) && discsTotal > 0) {\n              metadataTags.discsTotal ??= discsTotal;\n            }\n          }\n          ;\n          break;\n        case \"DATE\":\n          {\n            const date = new Date(value);\n            if (!Number.isNaN(date.getTime())) {\n              metadataTags.date ??= date;\n            }\n          }\n          ;\n          break;\n        case \"GENRE\":\n          {\n            metadataTags.genre ??= value;\n          }\n          ;\n          break;\n        case \"METADATA_BLOCK_PICTURE\":\n          {\n            const decoded = base64ToBytes(value);\n            const view2 = toDataView(decoded);\n            const pictureType = view2.getUint32(0, false);\n            const mediaTypeLength = view2.getUint32(4, false);\n            const mediaType = String.fromCharCode(...decoded.subarray(8, 8 + mediaTypeLength));\n            const descriptionLength = view2.getUint32(8 + mediaTypeLength, false);\n            const description = textDecoder.decode(decoded.subarray(\n              12 + mediaTypeLength,\n              12 + mediaTypeLength + descriptionLength\n            ));\n            const dataLength = view2.getUint32(mediaTypeLength + descriptionLength + 28);\n            const data = decoded.subarray(\n              mediaTypeLength + descriptionLength + 32,\n              mediaTypeLength + descriptionLength + 32 + dataLength\n            );\n            metadataTags.images ??= [];\n            metadataTags.images.push({\n              data,\n              mimeType: mediaType,\n              kind: pictureType === 3 ? \"coverFront\" : pictureType === 4 ? \"coverBack\" : \"unknown\",\n              name: void 0,\n              description: description || void 0\n            });\n          }\n          ;\n          break;\n      }\n    }\n  };\n  var createVorbisComments = (headerBytes, tags, writeImages) => {\n    const commentHeaderParts = [\n      headerBytes\n    ];\n    const vendorString = \"Mediabunny\";\n    const encodedVendorString = textEncoder.encode(vendorString);\n    let currentBuffer = new Uint8Array(4 + encodedVendorString.length);\n    let currentView = new DataView(currentBuffer.buffer);\n    currentView.setUint32(0, encodedVendorString.length, true);\n    currentBuffer.set(encodedVendorString, 4);\n    commentHeaderParts.push(currentBuffer);\n    const writtenTags = /* @__PURE__ */ new Set();\n    const addCommentTag = (key, value) => {\n      const joined = `${key}=${value}`;\n      const encoded = textEncoder.encode(joined);\n      currentBuffer = new Uint8Array(4 + encoded.length);\n      currentView = new DataView(currentBuffer.buffer);\n      currentView.setUint32(0, encoded.length, true);\n      currentBuffer.set(encoded, 4);\n      commentHeaderParts.push(currentBuffer);\n      writtenTags.add(key);\n    };\n    for (const { key, value } of keyValueIterator(tags)) {\n      switch (key) {\n        case \"title\":\n          {\n            addCommentTag(\"TITLE\", value);\n          }\n          ;\n          break;\n        case \"description\":\n          {\n            addCommentTag(\"DESCRIPTION\", value);\n          }\n          ;\n          break;\n        case \"artist\":\n          {\n            addCommentTag(\"ARTIST\", value);\n          }\n          ;\n          break;\n        case \"album\":\n          {\n            addCommentTag(\"ALBUM\", value);\n          }\n          ;\n          break;\n        case \"albumArtist\":\n          {\n            addCommentTag(\"ALBUMARTIST\", value);\n          }\n          ;\n          break;\n        case \"genre\":\n          {\n            addCommentTag(\"GENRE\", value);\n          }\n          ;\n          break;\n        case \"date\":\n          {\n            const rawVersion = tags.raw?.[\"DATE\"] ?? tags.raw?.[\"date\"];\n            if (rawVersion && typeof rawVersion === \"string\") {\n              addCommentTag(\"DATE\", rawVersion);\n            } else {\n              addCommentTag(\"DATE\", value.toISOString().slice(0, 10));\n            }\n          }\n          ;\n          break;\n        case \"comment\":\n          {\n            addCommentTag(\"COMMENT\", value);\n          }\n          ;\n          break;\n        case \"lyrics\":\n          {\n            addCommentTag(\"LYRICS\", value);\n          }\n          ;\n          break;\n        case \"trackNumber\":\n          {\n            addCommentTag(\"TRACKNUMBER\", value.toString());\n          }\n          ;\n          break;\n        case \"tracksTotal\":\n          {\n            addCommentTag(\"TRACKTOTAL\", value.toString());\n          }\n          ;\n          break;\n        case \"discNumber\":\n          {\n            addCommentTag(\"DISCNUMBER\", value.toString());\n          }\n          ;\n          break;\n        case \"discsTotal\":\n          {\n            addCommentTag(\"DISCTOTAL\", value.toString());\n          }\n          ;\n          break;\n        case \"images\":\n          {\n            if (!writeImages) {\n              break;\n            }\n            for (const image of value) {\n              const pictureType = image.kind === \"coverFront\" ? 3 : image.kind === \"coverBack\" ? 4 : 0;\n              const encodedMediaType = new Uint8Array(image.mimeType.length);\n              for (let i = 0; i < image.mimeType.length; i++) {\n                encodedMediaType[i] = image.mimeType.charCodeAt(i);\n              }\n              const encodedDescription = textEncoder.encode(image.description ?? \"\");\n              const buffer = new Uint8Array(\n                4 + 4 + encodedMediaType.length + 4 + encodedDescription.length + 16 + 4 + image.data.length\n                // Picture data\n              );\n              const view2 = toDataView(buffer);\n              view2.setUint32(0, pictureType, false);\n              view2.setUint32(4, encodedMediaType.length, false);\n              buffer.set(encodedMediaType, 8);\n              view2.setUint32(8 + encodedMediaType.length, encodedDescription.length, false);\n              buffer.set(encodedDescription, 12 + encodedMediaType.length);\n              view2.setUint32(\n                28 + encodedMediaType.length + encodedDescription.length,\n                image.data.length,\n                false\n              );\n              buffer.set(\n                image.data,\n                32 + encodedMediaType.length + encodedDescription.length\n              );\n              const encoded = bytesToBase64(buffer);\n              addCommentTag(\"METADATA_BLOCK_PICTURE\", encoded);\n            }\n          }\n          ;\n          break;\n        case \"raw\":\n          {\n          }\n          ;\n          break;\n        default:\n          assertNever(key);\n      }\n    }\n    if (tags.raw) {\n      for (const key in tags.raw) {\n        const value = tags.raw[key] ?? tags.raw[key.toLowerCase()];\n        if (key === \"vendor\" || value == null || writtenTags.has(key)) {\n          continue;\n        }\n        if (typeof value === \"string\") {\n          addCommentTag(key, value);\n        }\n      }\n    }\n    const listLengthBuffer = new Uint8Array(4);\n    toDataView(listLengthBuffer).setUint32(0, writtenTags.size, true);\n    commentHeaderParts.splice(2, 0, listLengthBuffer);\n    const commentHeaderLength = commentHeaderParts.reduce((a, b) => a + b.length, 0);\n    const commentHeader = new Uint8Array(commentHeaderLength);\n    let pos = 0;\n    for (const part of commentHeaderParts) {\n      commentHeader.set(part, pos);\n      pos += part.length;\n    }\n    return commentHeader;\n  };\n\n  // src/demuxer.ts\n  var Demuxer = class {\n    constructor(input) {\n      this.input = input;\n    }\n  };\n\n  // src/custom-coder.ts\n  var CustomVideoDecoder = class {\n    /** Returns true if and only if the decoder can decode the given codec configuration. */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    static supports(codec, config) {\n      return false;\n    }\n  };\n  var CustomAudioDecoder = class {\n    /** Returns true if and only if the decoder can decode the given codec configuration. */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    static supports(codec, config) {\n      return false;\n    }\n  };\n  var CustomVideoEncoder = class {\n    /** Returns true if and only if the encoder can encode the given codec configuration. */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    static supports(codec, config) {\n      return false;\n    }\n  };\n  var CustomAudioEncoder = class {\n    /** Returns true if and only if the encoder can encode the given codec configuration. */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    static supports(codec, config) {\n      return false;\n    }\n  };\n  var customVideoDecoders = [];\n  var customAudioDecoders = [];\n  var customVideoEncoders = [];\n  var customAudioEncoders = [];\n  var registerDecoder = (decoder) => {\n    if (decoder.prototype instanceof CustomVideoDecoder) {\n      const casted = decoder;\n      if (customVideoDecoders.includes(casted)) {\n        console.warn(\"Video decoder already registered.\");\n        return;\n      }\n      customVideoDecoders.push(casted);\n    } else if (decoder.prototype instanceof CustomAudioDecoder) {\n      const casted = decoder;\n      if (customAudioDecoders.includes(casted)) {\n        console.warn(\"Audio decoder already registered.\");\n        return;\n      }\n      customAudioDecoders.push(casted);\n    } else {\n      throw new TypeError(\"Decoder must be a CustomVideoDecoder or CustomAudioDecoder.\");\n    }\n  };\n  var registerEncoder = (encoder) => {\n    if (encoder.prototype instanceof CustomVideoEncoder) {\n      const casted = encoder;\n      if (customVideoEncoders.includes(casted)) {\n        console.warn(\"Video encoder already registered.\");\n        return;\n      }\n      customVideoEncoders.push(casted);\n    } else if (encoder.prototype instanceof CustomAudioEncoder) {\n      const casted = encoder;\n      if (customAudioEncoders.includes(casted)) {\n        console.warn(\"Audio encoder already registered.\");\n        return;\n      }\n      customAudioEncoders.push(casted);\n    } else {\n      throw new TypeError(\"Encoder must be a CustomVideoEncoder or CustomAudioEncoder.\");\n    }\n  };\n\n  // src/packet.ts\n  var PLACEHOLDER_DATA = /* @__PURE__ */ new Uint8Array(0);\n  var EncodedPacket = class _EncodedPacket {\n    /** Creates a new {@link EncodedPacket} from raw bytes and timing information. */\n    constructor(data, type, timestamp, duration, sequenceNumber = -1, byteLength, sideData) {\n      this.data = data;\n      this.type = type;\n      this.timestamp = timestamp;\n      this.duration = duration;\n      this.sequenceNumber = sequenceNumber;\n      if (data === PLACEHOLDER_DATA && byteLength === void 0) {\n        throw new Error(\n          \"Internal error: byteLength must be explicitly provided when constructing metadata-only packets.\"\n        );\n      }\n      if (byteLength === void 0) {\n        byteLength = data.byteLength;\n      }\n      if (!(data instanceof Uint8Array)) {\n        throw new TypeError(\"data must be a Uint8Array.\");\n      }\n      if (type !== \"key\" && type !== \"delta\") {\n        throw new TypeError('type must be either \"key\" or \"delta\".');\n      }\n      if (!Number.isFinite(timestamp)) {\n        throw new TypeError(\"timestamp must be a number.\");\n      }\n      if (!Number.isFinite(duration) || duration < 0) {\n        throw new TypeError(\"duration must be a non-negative number.\");\n      }\n      if (!Number.isFinite(sequenceNumber)) {\n        throw new TypeError(\"sequenceNumber must be a number.\");\n      }\n      if (!Number.isInteger(byteLength) || byteLength < 0) {\n        throw new TypeError(\"byteLength must be a non-negative integer.\");\n      }\n      if (sideData !== void 0 && (typeof sideData !== \"object\" || !sideData)) {\n        throw new TypeError(\"sideData, when provided, must be an object.\");\n      }\n      if (sideData?.alpha !== void 0 && !(sideData.alpha instanceof Uint8Array)) {\n        throw new TypeError(\"sideData.alpha, when provided, must be a Uint8Array.\");\n      }\n      if (sideData?.alphaByteLength !== void 0 && (!Number.isInteger(sideData.alphaByteLength) || sideData.alphaByteLength < 0)) {\n        throw new TypeError(\"sideData.alphaByteLength, when provided, must be a non-negative integer.\");\n      }\n      this.byteLength = byteLength;\n      this.sideData = sideData ?? {};\n      if (this.sideData.alpha && this.sideData.alphaByteLength === void 0) {\n        this.sideData.alphaByteLength = this.sideData.alpha.byteLength;\n      }\n    }\n    /**\n     * If this packet is a metadata-only packet. Metadata-only packets don't contain their packet data. They are the\n     * result of retrieving packets with {@link PacketRetrievalOptions.metadataOnly} set to `true`.\n     */\n    get isMetadataOnly() {\n      return this.data === PLACEHOLDER_DATA;\n    }\n    /** The timestamp of this packet in microseconds. */\n    get microsecondTimestamp() {\n      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.timestamp);\n    }\n    /** The duration of this packet in microseconds. */\n    get microsecondDuration() {\n      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.duration);\n    }\n    /** Converts this packet to an\n     * [`EncodedVideoChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedVideoChunk) for use with the\n     * WebCodecs API. */\n    toEncodedVideoChunk() {\n      if (this.isMetadataOnly) {\n        throw new TypeError(\"Metadata-only packets cannot be converted to a video chunk.\");\n      }\n      if (typeof EncodedVideoChunk === \"undefined\") {\n        throw new Error(\"Your browser does not support EncodedVideoChunk.\");\n      }\n      return new EncodedVideoChunk({\n        data: this.data,\n        type: this.type,\n        timestamp: this.microsecondTimestamp,\n        duration: this.microsecondDuration\n      });\n    }\n    /**\n     * Converts this packet to an\n     * [`EncodedVideoChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedVideoChunk) for use with the\n     * WebCodecs API, using the alpha side data instead of the color data. Throws if no alpha side data is defined.\n     */\n    alphaToEncodedVideoChunk(type = this.type) {\n      if (!this.sideData.alpha) {\n        throw new TypeError(\"This packet does not contain alpha side data.\");\n      }\n      if (this.isMetadataOnly) {\n        throw new TypeError(\"Metadata-only packets cannot be converted to a video chunk.\");\n      }\n      if (typeof EncodedVideoChunk === \"undefined\") {\n        throw new Error(\"Your browser does not support EncodedVideoChunk.\");\n      }\n      return new EncodedVideoChunk({\n        data: this.sideData.alpha,\n        type,\n        timestamp: this.microsecondTimestamp,\n        duration: this.microsecondDuration\n      });\n    }\n    /** Converts this packet to an\n     * [`EncodedAudioChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedAudioChunk) for use with the\n     * WebCodecs API. */\n    toEncodedAudioChunk() {\n      if (this.isMetadataOnly) {\n        throw new TypeError(\"Metadata-only packets cannot be converted to an audio chunk.\");\n      }\n      if (typeof EncodedAudioChunk === \"undefined\") {\n        throw new Error(\"Your browser does not support EncodedAudioChunk.\");\n      }\n      return new EncodedAudioChunk({\n        data: this.data,\n        type: this.type,\n        timestamp: this.microsecondTimestamp,\n        duration: this.microsecondDuration\n      });\n    }\n    /**\n     * Creates an {@link EncodedPacket} from an\n     * [`EncodedVideoChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedVideoChunk) or\n     * [`EncodedAudioChunk`](https://developer.mozilla.org/en-US/docs/Web/API/EncodedAudioChunk). This method is useful\n     * for converting chunks from the WebCodecs API to `EncodedPacket` instances.\n     */\n    static fromEncodedChunk(chunk, sideData) {\n      if (!(chunk instanceof EncodedVideoChunk || chunk instanceof EncodedAudioChunk)) {\n        throw new TypeError(\"chunk must be an EncodedVideoChunk or EncodedAudioChunk.\");\n      }\n      const data = new Uint8Array(chunk.byteLength);\n      chunk.copyTo(data);\n      return new _EncodedPacket(\n        data,\n        chunk.type,\n        chunk.timestamp / 1e6,\n        (chunk.duration ?? 0) / 1e6,\n        void 0,\n        void 0,\n        sideData\n      );\n    }\n    /** Clones this packet while optionally modifying the new packet's data. */\n    clone(options) {\n      if (options !== void 0 && (typeof options !== \"object\" || options === null)) {\n        throw new TypeError(\"options, when provided, must be an object.\");\n      }\n      if (options?.data !== void 0 && !(options.data instanceof Uint8Array)) {\n        throw new TypeError(\"options.data, when provided, must be a Uint8Array.\");\n      }\n      if (options?.type !== void 0 && options.type !== \"key\" && options.type !== \"delta\") {\n        throw new TypeError('options.type, when provided, must be either \"key\" or \"delta\".');\n      }\n      if (options?.timestamp !== void 0 && !Number.isFinite(options.timestamp)) {\n        throw new TypeError(\"options.timestamp, when provided, must be a number.\");\n      }\n      if (options?.duration !== void 0 && !Number.isFinite(options.duration)) {\n        throw new TypeError(\"options.duration, when provided, must be a number.\");\n      }\n      if (options?.sequenceNumber !== void 0 && !Number.isFinite(options.sequenceNumber)) {\n        throw new TypeError(\"options.sequenceNumber, when provided, must be a number.\");\n      }\n      if (options?.sideData !== void 0 && (typeof options.sideData !== \"object\" || options.sideData === null)) {\n        throw new TypeError(\"options.sideData, when provided, must be an object.\");\n      }\n      return new _EncodedPacket(\n        options?.data ?? this.data,\n        options?.type ?? this.type,\n        options?.timestamp ?? this.timestamp,\n        options?.duration ?? this.duration,\n        options?.sequenceNumber ?? this.sequenceNumber,\n        this.byteLength,\n        options?.sideData ?? this.sideData\n      );\n    }\n  };\n\n  // src/pcm.ts\n  var toUlaw = (s16) => {\n    const MULAW_MAX = 8191;\n    const MULAW_BIAS = 33;\n    let number = s16;\n    let mask = 4096;\n    let sign = 0;\n    let position = 12;\n    let lsb = 0;\n    if (number < 0) {\n      number = -number;\n      sign = 128;\n    }\n    number += MULAW_BIAS;\n    if (number > MULAW_MAX) {\n      number = MULAW_MAX;\n    }\n    while ((number & mask) !== mask && position >= 5) {\n      mask >>= 1;\n      position--;\n    }\n    lsb = number >> position - 4 & 15;\n    return ~(sign | position - 5 << 4 | lsb) & 255;\n  };\n  var fromUlaw = (u82) => {\n    const MULAW_BIAS = 33;\n    let sign = 0;\n    let position = 0;\n    let number = ~u82;\n    if (number & 128) {\n      number &= ~(1 << 7);\n      sign = -1;\n    }\n    position = ((number & 240) >> 4) + 5;\n    const decoded = (1 << position | (number & 15) << position - 4 | 1 << position - 5) - MULAW_BIAS;\n    return sign === 0 ? decoded : -decoded;\n  };\n  var toAlaw = (s16) => {\n    const ALAW_MAX = 4095;\n    let mask = 2048;\n    let sign = 0;\n    let position = 11;\n    let lsb = 0;\n    let number = s16;\n    if (number < 0) {\n      number = -number;\n      sign = 128;\n    }\n    if (number > ALAW_MAX) {\n      number = ALAW_MAX;\n    }\n    while ((number & mask) !== mask && position >= 5) {\n      mask >>= 1;\n      position--;\n    }\n    lsb = number >> (position === 4 ? 1 : position - 4) & 15;\n    return (sign | position - 4 << 4 | lsb) ^ 85;\n  };\n  var fromAlaw = (u82) => {\n    let sign = 0;\n    let position = 0;\n    let number = u82 ^ 85;\n    if (number & 128) {\n      number &= ~(1 << 7);\n      sign = -1;\n    }\n    position = ((number & 240) >> 4) + 4;\n    let decoded = 0;\n    if (position !== 4) {\n      decoded = 1 << position | (number & 15) << position - 4 | 1 << position - 5;\n    } else {\n      decoded = number << 1 | 1;\n    }\n    return sign === 0 ? decoded : -decoded;\n  };\n\n  // src/sample.ts\n  polyfillSymbolDispose();\n  var lastVideoGcErrorLog = -Infinity;\n  var lastAudioGcErrorLog = -Infinity;\n  var finalizationRegistry = null;\n  if (typeof FinalizationRegistry !== \"undefined\") {\n    finalizationRegistry = new FinalizationRegistry((value) => {\n      const now = Date.now();\n      if (value.type === \"video\") {\n        if (now - lastVideoGcErrorLog >= 1e3) {\n          console.error(\n            `A VideoSample was garbage collected without first being closed. For proper resource management, make sure to call close() on all your VideoSamples as soon as you're done using them.`\n          );\n          lastVideoGcErrorLog = now;\n        }\n        if (typeof VideoFrame !== \"undefined\" && value.data instanceof VideoFrame) {\n          value.data.close();\n        }\n      } else {\n        if (now - lastAudioGcErrorLog >= 1e3) {\n          console.error(\n            `An AudioSample was garbage collected without first being closed. For proper resource management, make sure to call close() on all your AudioSamples as soon as you're done using them.`\n          );\n          lastAudioGcErrorLog = now;\n        }\n        if (typeof AudioData !== \"undefined\" && value.data instanceof AudioData) {\n          value.data.close();\n        }\n      }\n    });\n  }\n  var VIDEO_SAMPLE_PIXEL_FORMATS = [\n    // 4:2:0 Y, U, V\n    \"I420\",\n    \"I420P10\",\n    \"I420P12\",\n    // 4:2:0 Y, U, V, A\n    \"I420A\",\n    \"I420AP10\",\n    \"I420AP12\",\n    // 4:2:2 Y, U, V\n    \"I422\",\n    \"I422P10\",\n    \"I422P12\",\n    // 4:2:2 Y, U, V, A\n    \"I422A\",\n    \"I422AP10\",\n    \"I422AP12\",\n    // 4:4:4 Y, U, V\n    \"I444\",\n    \"I444P10\",\n    \"I444P12\",\n    // 4:4:4 Y, U, V, A\n    \"I444A\",\n    \"I444AP10\",\n    \"I444AP12\",\n    // 4:2:0 Y, UV\n    \"NV12\",\n    // 4:4:4 RGBA\n    \"RGBA\",\n    // 4:4:4 RGBX (opaque)\n    \"RGBX\",\n    // 4:4:4 BGRA\n    \"BGRA\",\n    // 4:4:4 BGRX (opaque)\n    \"BGRX\"\n  ];\n  var VIDEO_SAMPLE_PIXEL_FORMATS_SET = new Set(VIDEO_SAMPLE_PIXEL_FORMATS);\n  var VideoSample = class _VideoSample {\n    constructor(data, init) {\n      /** @internal */\n      this._closed = false;\n      if (data instanceof ArrayBuffer || typeof SharedArrayBuffer !== \"undefined\" && data instanceof SharedArrayBuffer || ArrayBuffer.isView(data)) {\n        if (!init || typeof init !== \"object\") {\n          throw new TypeError(\"init must be an object.\");\n        }\n        if (init.format === void 0 || !VIDEO_SAMPLE_PIXEL_FORMATS_SET.has(init.format)) {\n          throw new TypeError(\"init.format must be one of: \" + VIDEO_SAMPLE_PIXEL_FORMATS.join(\", \"));\n        }\n        if (!Number.isInteger(init.codedWidth) || init.codedWidth <= 0) {\n          throw new TypeError(\"init.codedWidth must be a positive integer.\");\n        }\n        if (!Number.isInteger(init.codedHeight) || init.codedHeight <= 0) {\n          throw new TypeError(\"init.codedHeight must be a positive integer.\");\n        }\n        if (init.rotation !== void 0 && ![0, 90, 180, 270].includes(init.rotation)) {\n          throw new TypeError(\"init.rotation, when provided, must be 0, 90, 180, or 270.\");\n        }\n        if (!Number.isFinite(init.timestamp)) {\n          throw new TypeError(\"init.timestamp must be a number.\");\n        }\n        if (init.duration !== void 0 && (!Number.isFinite(init.duration) || init.duration < 0)) {\n          throw new TypeError(\"init.duration, when provided, must be a non-negative number.\");\n        }\n        this._data = toUint8Array(data).slice();\n        this._layout = init.layout ?? createDefaultPlaneLayout(init.format, init.codedWidth, init.codedHeight);\n        this.format = init.format;\n        this.codedWidth = init.codedWidth;\n        this.codedHeight = init.codedHeight;\n        this.rotation = init.rotation ?? 0;\n        this.timestamp = init.timestamp;\n        this.duration = init.duration ?? 0;\n        this.colorSpace = new VideoSampleColorSpace(init.colorSpace);\n      } else if (typeof VideoFrame !== \"undefined\" && data instanceof VideoFrame) {\n        if (init?.rotation !== void 0 && ![0, 90, 180, 270].includes(init.rotation)) {\n          throw new TypeError(\"init.rotation, when provided, must be 0, 90, 180, or 270.\");\n        }\n        if (init?.timestamp !== void 0 && !Number.isFinite(init?.timestamp)) {\n          throw new TypeError(\"init.timestamp, when provided, must be a number.\");\n        }\n        if (init?.duration !== void 0 && (!Number.isFinite(init.duration) || init.duration < 0)) {\n          throw new TypeError(\"init.duration, when provided, must be a non-negative number.\");\n        }\n        this._data = data;\n        this._layout = null;\n        this.format = data.format;\n        this.codedWidth = data.displayWidth;\n        this.codedHeight = data.displayHeight;\n        this.rotation = init?.rotation ?? 0;\n        this.timestamp = init?.timestamp ?? data.timestamp / 1e6;\n        this.duration = init?.duration ?? (data.duration ?? 0) / 1e6;\n        this.colorSpace = new VideoSampleColorSpace(data.colorSpace);\n      } else if (typeof HTMLImageElement !== \"undefined\" && data instanceof HTMLImageElement || typeof SVGImageElement !== \"undefined\" && data instanceof SVGImageElement || typeof ImageBitmap !== \"undefined\" && data instanceof ImageBitmap || typeof HTMLVideoElement !== \"undefined\" && data instanceof HTMLVideoElement || typeof HTMLCanvasElement !== \"undefined\" && data instanceof HTMLCanvasElement || typeof OffscreenCanvas !== \"undefined\" && data instanceof OffscreenCanvas) {\n        if (!init || typeof init !== \"object\") {\n          throw new TypeError(\"init must be an object.\");\n        }\n        if (init.rotation !== void 0 && ![0, 90, 180, 270].includes(init.rotation)) {\n          throw new TypeError(\"init.rotation, when provided, must be 0, 90, 180, or 270.\");\n        }\n        if (!Number.isFinite(init.timestamp)) {\n          throw new TypeError(\"init.timestamp must be a number.\");\n        }\n        if (init.duration !== void 0 && (!Number.isFinite(init.duration) || init.duration < 0)) {\n          throw new TypeError(\"init.duration, when provided, must be a non-negative number.\");\n        }\n        if (typeof VideoFrame !== \"undefined\") {\n          return new _VideoSample(\n            new VideoFrame(data, {\n              timestamp: Math.trunc(init.timestamp * SECOND_TO_MICROSECOND_FACTOR),\n              // Drag 0 to undefined\n              duration: Math.trunc((init.duration ?? 0) * SECOND_TO_MICROSECOND_FACTOR) || void 0\n            }),\n            init\n          );\n        }\n        let width = 0;\n        let height = 0;\n        if (\"naturalWidth\" in data) {\n          width = data.naturalWidth;\n          height = data.naturalHeight;\n        } else if (\"videoWidth\" in data) {\n          width = data.videoWidth;\n          height = data.videoHeight;\n        } else if (\"width\" in data) {\n          width = Number(data.width);\n          height = Number(data.height);\n        }\n        if (!width || !height) {\n          throw new TypeError(\"Could not determine dimensions.\");\n        }\n        const canvas = new OffscreenCanvas(width, height);\n        const context = canvas.getContext(\"2d\", {\n          alpha: isFirefox(),\n          // Firefox has VideoFrame glitches with opaque canvases\n          willReadFrequently: true\n        });\n        assert(context);\n        context.drawImage(data, 0, 0);\n        this._data = canvas;\n        this._layout = null;\n        this.format = \"RGBX\";\n        this.codedWidth = width;\n        this.codedHeight = height;\n        this.rotation = init.rotation ?? 0;\n        this.timestamp = init.timestamp;\n        this.duration = init.duration ?? 0;\n        this.colorSpace = new VideoSampleColorSpace({\n          matrix: \"rgb\",\n          primaries: \"bt709\",\n          transfer: \"iec61966-2-1\",\n          fullRange: true\n        });\n      } else {\n        throw new TypeError(\"Invalid data type: Must be a BufferSource or CanvasImageSource.\");\n      }\n      finalizationRegistry?.register(this, { type: \"video\", data: this._data }, this);\n    }\n    /** The width of the frame in pixels after rotation. */\n    get displayWidth() {\n      return this.rotation % 180 === 0 ? this.codedWidth : this.codedHeight;\n    }\n    /** The height of the frame in pixels after rotation. */\n    get displayHeight() {\n      return this.rotation % 180 === 0 ? this.codedHeight : this.codedWidth;\n    }\n    /** The presentation timestamp of the frame in microseconds. */\n    get microsecondTimestamp() {\n      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.timestamp);\n    }\n    /** The duration of the frame in microseconds. */\n    get microsecondDuration() {\n      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.duration);\n    }\n    /**\n     * Whether this sample uses a pixel format that can hold transparency data. Note that this doesn't necessarily mean\n     * that the sample is transparent.\n     */\n    get hasAlpha() {\n      return this.format && this.format.includes(\"A\");\n    }\n    /** Clones this video sample. */\n    clone() {\n      if (this._closed) {\n        throw new Error(\"VideoSample is closed.\");\n      }\n      assert(this._data !== null);\n      if (isVideoFrame(this._data)) {\n        return new _VideoSample(this._data.clone(), {\n          timestamp: this.timestamp,\n          duration: this.duration,\n          rotation: this.rotation\n        });\n      } else if (this._data instanceof Uint8Array) {\n        assert(this._layout);\n        return new _VideoSample(this._data, {\n          format: this.format,\n          layout: this._layout,\n          codedWidth: this.codedWidth,\n          codedHeight: this.codedHeight,\n          timestamp: this.timestamp,\n          duration: this.duration,\n          colorSpace: this.colorSpace,\n          rotation: this.rotation\n        });\n      } else {\n        return new _VideoSample(this._data, {\n          format: this.format,\n          codedWidth: this.codedWidth,\n          codedHeight: this.codedHeight,\n          timestamp: this.timestamp,\n          duration: this.duration,\n          colorSpace: this.colorSpace,\n          rotation: this.rotation\n        });\n      }\n    }\n    /**\n     * Closes this video sample, releasing held resources. Video samples should be closed as soon as they are not\n     * needed anymore.\n     */\n    close() {\n      if (this._closed) {\n        return;\n      }\n      finalizationRegistry?.unregister(this);\n      if (isVideoFrame(this._data)) {\n        this._data.close();\n      } else {\n        this._data = null;\n      }\n      this._closed = true;\n    }\n    /**\n     * Returns the number of bytes required to hold this video sample's pixel data. Throws if `format` is `null`.\n     */\n    allocationSize(options = {}) {\n      validateVideoFrameCopyToOptions(options);\n      if (this._closed) {\n        throw new Error(\"VideoSample is closed.\");\n      }\n      if (this.format === null) {\n        throw new Error(\"Cannot get allocation size when format is null. Sorry!\");\n      }\n      assert(this._data !== null);\n      if (!isVideoFrame(this._data)) {\n        if (options.colorSpace || options.format && options.format !== this.format || options.layout || options.rect) {\n          const videoFrame = this.toVideoFrame();\n          const size = videoFrame.allocationSize(options);\n          videoFrame.close();\n          return size;\n        }\n      }\n      if (isVideoFrame(this._data)) {\n        return this._data.allocationSize(options);\n      } else if (this._data instanceof Uint8Array) {\n        return this._data.byteLength;\n      } else {\n        return this.codedWidth * this.codedHeight * 4;\n      }\n    }\n    /**\n     * Copies this video sample's pixel data to an ArrayBuffer or ArrayBufferView. Throws if `format` is `null`.\n     * @returns The byte layout of the planes of the copied data.\n     */\n    async copyTo(destination, options = {}) {\n      if (!isAllowSharedBufferSource(destination)) {\n        throw new TypeError(\"destination must be an ArrayBuffer or an ArrayBuffer view.\");\n      }\n      validateVideoFrameCopyToOptions(options);\n      if (this._closed) {\n        throw new Error(\"VideoSample is closed.\");\n      }\n      if (this.format === null) {\n        throw new Error(\"Cannot copy video sample data when format is null. Sorry!\");\n      }\n      assert(this._data !== null);\n      if (!isVideoFrame(this._data)) {\n        if (options.colorSpace || options.format && options.format !== this.format || options.layout || options.rect) {\n          const videoFrame = this.toVideoFrame();\n          const layout = await videoFrame.copyTo(destination, options);\n          videoFrame.close();\n          return layout;\n        }\n      }\n      if (isVideoFrame(this._data)) {\n        return this._data.copyTo(destination, options);\n      } else if (this._data instanceof Uint8Array) {\n        assert(this._layout);\n        const dest = toUint8Array(destination);\n        dest.set(this._data);\n        return this._layout;\n      } else {\n        const canvas = this._data;\n        const context = canvas.getContext(\"2d\");\n        assert(context);\n        const imageData = context.getImageData(0, 0, this.codedWidth, this.codedHeight);\n        const dest = toUint8Array(destination);\n        dest.set(imageData.data);\n        return [{\n          offset: 0,\n          stride: 4 * this.codedWidth\n        }];\n      }\n    }\n    /**\n     * Converts this video sample to a VideoFrame for use with the WebCodecs API. The VideoFrame returned by this\n     * method *must* be closed separately from this video sample.\n     */\n    toVideoFrame() {\n      if (this._closed) {\n        throw new Error(\"VideoSample is closed.\");\n      }\n      assert(this._data !== null);\n      if (isVideoFrame(this._data)) {\n        return new VideoFrame(this._data, {\n          timestamp: this.microsecondTimestamp,\n          duration: this.microsecondDuration || void 0\n          // Drag 0 duration to undefined, glitches some codecs\n        });\n      } else if (this._data instanceof Uint8Array) {\n        return new VideoFrame(this._data, {\n          format: this.format,\n          codedWidth: this.codedWidth,\n          codedHeight: this.codedHeight,\n          timestamp: this.microsecondTimestamp,\n          duration: this.microsecondDuration || void 0,\n          colorSpace: this.colorSpace\n        });\n      } else {\n        return new VideoFrame(this._data, {\n          timestamp: this.microsecondTimestamp,\n          duration: this.microsecondDuration || void 0\n        });\n      }\n    }\n    draw(context, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8) {\n      let sx = 0;\n      let sy = 0;\n      let sWidth = this.displayWidth;\n      let sHeight = this.displayHeight;\n      let dx = 0;\n      let dy = 0;\n      let dWidth = this.displayWidth;\n      let dHeight = this.displayHeight;\n      if (arg5 !== void 0) {\n        sx = arg1;\n        sy = arg2;\n        sWidth = arg3;\n        sHeight = arg4;\n        dx = arg5;\n        dy = arg6;\n        if (arg7 !== void 0) {\n          dWidth = arg7;\n          dHeight = arg8;\n        } else {\n          dWidth = sWidth;\n          dHeight = sHeight;\n        }\n      } else {\n        dx = arg1;\n        dy = arg2;\n        if (arg3 !== void 0) {\n          dWidth = arg3;\n          dHeight = arg4;\n        }\n      }\n      if (!(typeof CanvasRenderingContext2D !== \"undefined\" && context instanceof CanvasRenderingContext2D || typeof OffscreenCanvasRenderingContext2D !== \"undefined\" && context instanceof OffscreenCanvasRenderingContext2D)) {\n        throw new TypeError(\"context must be a CanvasRenderingContext2D or OffscreenCanvasRenderingContext2D.\");\n      }\n      if (!Number.isFinite(sx)) {\n        throw new TypeError(\"sx must be a number.\");\n      }\n      if (!Number.isFinite(sy)) {\n        throw new TypeError(\"sy must be a number.\");\n      }\n      if (!Number.isFinite(sWidth) || sWidth < 0) {\n        throw new TypeError(\"sWidth must be a non-negative number.\");\n      }\n      if (!Number.isFinite(sHeight) || sHeight < 0) {\n        throw new TypeError(\"sHeight must be a non-negative number.\");\n      }\n      if (!Number.isFinite(dx)) {\n        throw new TypeError(\"dx must be a number.\");\n      }\n      if (!Number.isFinite(dy)) {\n        throw new TypeError(\"dy must be a number.\");\n      }\n      if (!Number.isFinite(dWidth) || dWidth < 0) {\n        throw new TypeError(\"dWidth must be a non-negative number.\");\n      }\n      if (!Number.isFinite(dHeight) || dHeight < 0) {\n        throw new TypeError(\"dHeight must be a non-negative number.\");\n      }\n      if (this._closed) {\n        throw new Error(\"VideoSample is closed.\");\n      }\n      ({ sx, sy, sWidth, sHeight } = this._rotateSourceRegion(sx, sy, sWidth, sHeight, this.rotation));\n      const source = this.toCanvasImageSource();\n      context.save();\n      const centerX = dx + dWidth / 2;\n      const centerY = dy + dHeight / 2;\n      context.translate(centerX, centerY);\n      context.rotate(this.rotation * Math.PI / 180);\n      const aspectRatioChange = this.rotation % 180 === 0 ? 1 : dWidth / dHeight;\n      context.scale(1 / aspectRatioChange, aspectRatioChange);\n      context.drawImage(\n        source,\n        sx,\n        sy,\n        sWidth,\n        sHeight,\n        -dWidth / 2,\n        -dHeight / 2,\n        dWidth,\n        dHeight\n      );\n      context.restore();\n    }\n    /**\n     * Draws the sample in the middle of the canvas corresponding to the context with the specified fit behavior.\n     */\n    drawWithFit(context, options) {\n      if (!(typeof CanvasRenderingContext2D !== \"undefined\" && context instanceof CanvasRenderingContext2D || typeof OffscreenCanvasRenderingContext2D !== \"undefined\" && context instanceof OffscreenCanvasRenderingContext2D)) {\n        throw new TypeError(\"context must be a CanvasRenderingContext2D or OffscreenCanvasRenderingContext2D.\");\n      }\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (![\"fill\", \"contain\", \"cover\"].includes(options.fit)) {\n        throw new TypeError(\"options.fit must be 'fill', 'contain', or 'cover'.\");\n      }\n      if (options.rotation !== void 0 && ![0, 90, 180, 270].includes(options.rotation)) {\n        throw new TypeError(\"options.rotation, when provided, must be 0, 90, 180, or 270.\");\n      }\n      if (options.crop !== void 0) {\n        validateCropRectangle(options.crop, \"options.\");\n      }\n      const canvasWidth = context.canvas.width;\n      const canvasHeight = context.canvas.height;\n      const rotation = options.rotation ?? this.rotation;\n      const [rotatedWidth, rotatedHeight] = rotation % 180 === 0 ? [this.codedWidth, this.codedHeight] : [this.codedHeight, this.codedWidth];\n      if (options.crop) {\n        clampCropRectangle(options.crop, rotatedWidth, rotatedHeight);\n      }\n      let dx;\n      let dy;\n      let newWidth;\n      let newHeight;\n      const { sx, sy, sWidth, sHeight } = this._rotateSourceRegion(\n        options.crop?.left ?? 0,\n        options.crop?.top ?? 0,\n        options.crop?.width ?? rotatedWidth,\n        options.crop?.height ?? rotatedHeight,\n        rotation\n      );\n      if (options.fit === \"fill\") {\n        dx = 0;\n        dy = 0;\n        newWidth = canvasWidth;\n        newHeight = canvasHeight;\n      } else {\n        const [sampleWidth, sampleHeight] = options.crop ? [options.crop.width, options.crop.height] : [rotatedWidth, rotatedHeight];\n        const scale = options.fit === \"contain\" ? Math.min(canvasWidth / sampleWidth, canvasHeight / sampleHeight) : Math.max(canvasWidth / sampleWidth, canvasHeight / sampleHeight);\n        newWidth = sampleWidth * scale;\n        newHeight = sampleHeight * scale;\n        dx = (canvasWidth - newWidth) / 2;\n        dy = (canvasHeight - newHeight) / 2;\n      }\n      context.save();\n      const aspectRatioChange = rotation % 180 === 0 ? 1 : newWidth / newHeight;\n      context.translate(canvasWidth / 2, canvasHeight / 2);\n      context.rotate(rotation * Math.PI / 180);\n      context.scale(1 / aspectRatioChange, aspectRatioChange);\n      context.translate(-canvasWidth / 2, -canvasHeight / 2);\n      context.drawImage(this.toCanvasImageSource(), sx, sy, sWidth, sHeight, dx, dy, newWidth, newHeight);\n      context.restore();\n    }\n    /** @internal */\n    _rotateSourceRegion(sx, sy, sWidth, sHeight, rotation) {\n      if (rotation === 90) {\n        [sx, sy, sWidth, sHeight] = [\n          sy,\n          this.codedHeight - sx - sWidth,\n          sHeight,\n          sWidth\n        ];\n      } else if (rotation === 180) {\n        [sx, sy] = [\n          this.codedWidth - sx - sWidth,\n          this.codedHeight - sy - sHeight\n        ];\n      } else if (rotation === 270) {\n        [sx, sy, sWidth, sHeight] = [\n          this.codedWidth - sy - sHeight,\n          sx,\n          sHeight,\n          sWidth\n        ];\n      }\n      return { sx, sy, sWidth, sHeight };\n    }\n    /**\n     * Converts this video sample to a\n     * [`CanvasImageSource`](https://udn.realityripple.com/docs/Web/API/CanvasImageSource) for drawing to a canvas.\n     *\n     * You must use the value returned by this method immediately, as any VideoFrame created internally will\n     * automatically be closed in the next microtask.\n     */\n    toCanvasImageSource() {\n      if (this._closed) {\n        throw new Error(\"VideoSample is closed.\");\n      }\n      assert(this._data !== null);\n      if (this._data instanceof Uint8Array) {\n        const videoFrame = this.toVideoFrame();\n        queueMicrotask(() => videoFrame.close());\n        return videoFrame;\n      } else {\n        return this._data;\n      }\n    }\n    /** Sets the rotation metadata of this video sample. */\n    setRotation(newRotation) {\n      if (![0, 90, 180, 270].includes(newRotation)) {\n        throw new TypeError(\"newRotation must be 0, 90, 180, or 270.\");\n      }\n      this.rotation = newRotation;\n    }\n    /** Sets the presentation timestamp of this video sample, in seconds. */\n    setTimestamp(newTimestamp) {\n      if (!Number.isFinite(newTimestamp)) {\n        throw new TypeError(\"newTimestamp must be a number.\");\n      }\n      this.timestamp = newTimestamp;\n    }\n    /** Sets the duration of this video sample, in seconds. */\n    setDuration(newDuration) {\n      if (!Number.isFinite(newDuration) || newDuration < 0) {\n        throw new TypeError(\"newDuration must be a non-negative number.\");\n      }\n      this.duration = newDuration;\n    }\n    /** Calls `.close()`. */\n    [Symbol.dispose]() {\n      this.close();\n    }\n  };\n  var VideoSampleColorSpace = class {\n    /** Creates a new VideoSampleColorSpace. */\n    constructor(init) {\n      this.primaries = init?.primaries ?? null;\n      this.transfer = init?.transfer ?? null;\n      this.matrix = init?.matrix ?? null;\n      this.fullRange = init?.fullRange ?? null;\n    }\n    /** Serializes the color space to a JSON object. */\n    toJSON() {\n      return {\n        primaries: this.primaries,\n        transfer: this.transfer,\n        matrix: this.matrix,\n        fullRange: this.fullRange\n      };\n    }\n  };\n  var isVideoFrame = (x) => {\n    return typeof VideoFrame !== \"undefined\" && x instanceof VideoFrame;\n  };\n  var clampCropRectangle = (crop, outerWidth, outerHeight) => {\n    crop.left = Math.min(crop.left, outerWidth);\n    crop.top = Math.min(crop.top, outerHeight);\n    crop.width = Math.min(crop.width, outerWidth - crop.left);\n    crop.height = Math.min(crop.height, outerHeight - crop.top);\n    assert(crop.width >= 0);\n    assert(crop.height >= 0);\n  };\n  var validateCropRectangle = (crop, prefix) => {\n    if (!crop || typeof crop !== \"object\") {\n      throw new TypeError(prefix + \"crop, when provided, must be an object.\");\n    }\n    if (!Number.isInteger(crop.left) || crop.left < 0) {\n      throw new TypeError(prefix + \"crop.left must be a non-negative integer.\");\n    }\n    if (!Number.isInteger(crop.top) || crop.top < 0) {\n      throw new TypeError(prefix + \"crop.top must be a non-negative integer.\");\n    }\n    if (!Number.isInteger(crop.width) || crop.width < 0) {\n      throw new TypeError(prefix + \"crop.width must be a non-negative integer.\");\n    }\n    if (!Number.isInteger(crop.height) || crop.height < 0) {\n      throw new TypeError(prefix + \"crop.height must be a non-negative integer.\");\n    }\n  };\n  var validateVideoFrameCopyToOptions = (options) => {\n    if (!options || typeof options !== \"object\") {\n      throw new TypeError(\"options must be an object.\");\n    }\n    if (options.colorSpace !== void 0 && ![\"display-p3\", \"srgb\"].includes(options.colorSpace)) {\n      throw new TypeError(\"options.colorSpace, when provided, must be 'display-p3' or 'srgb'.\");\n    }\n    if (options.format !== void 0 && typeof options.format !== \"string\") {\n      throw new TypeError(\"options.format, when provided, must be a string.\");\n    }\n    if (options.layout !== void 0) {\n      if (!Array.isArray(options.layout)) {\n        throw new TypeError(\"options.layout, when provided, must be an array.\");\n      }\n      for (const plane of options.layout) {\n        if (!plane || typeof plane !== \"object\") {\n          throw new TypeError(\"Each entry in options.layout must be an object.\");\n        }\n        if (!Number.isInteger(plane.offset) || plane.offset < 0) {\n          throw new TypeError(\"plane.offset must be a non-negative integer.\");\n        }\n        if (!Number.isInteger(plane.stride) || plane.stride < 0) {\n          throw new TypeError(\"plane.stride must be a non-negative integer.\");\n        }\n      }\n    }\n    if (options.rect !== void 0) {\n      if (!options.rect || typeof options.rect !== \"object\") {\n        throw new TypeError(\"options.rect, when provided, must be an object.\");\n      }\n      if (options.rect.x !== void 0 && (!Number.isInteger(options.rect.x) || options.rect.x < 0)) {\n        throw new TypeError(\"options.rect.x, when provided, must be a non-negative integer.\");\n      }\n      if (options.rect.y !== void 0 && (!Number.isInteger(options.rect.y) || options.rect.y < 0)) {\n        throw new TypeError(\"options.rect.y, when provided, must be a non-negative integer.\");\n      }\n      if (options.rect.width !== void 0 && (!Number.isInteger(options.rect.width) || options.rect.width < 0)) {\n        throw new TypeError(\"options.rect.width, when provided, must be a non-negative integer.\");\n      }\n      if (options.rect.height !== void 0 && (!Number.isInteger(options.rect.height) || options.rect.height < 0)) {\n        throw new TypeError(\"options.rect.height, when provided, must be a non-negative integer.\");\n      }\n    }\n  };\n  var createDefaultPlaneLayout = (format, codedWidth, codedHeight) => {\n    const planes = getPlaneConfigs(format);\n    const layouts = [];\n    let currentOffset = 0;\n    for (const plane of planes) {\n      const planeWidth = Math.ceil(codedWidth / plane.widthDivisor);\n      const planeHeight = Math.ceil(codedHeight / plane.heightDivisor);\n      const stride = planeWidth * plane.sampleBytes;\n      const planeSize = stride * planeHeight;\n      layouts.push({\n        offset: currentOffset,\n        stride\n      });\n      currentOffset += planeSize;\n    }\n    return layouts;\n  };\n  var getPlaneConfigs = (format) => {\n    const yuv = (yBytes, uvBytes, subX, subY, hasAlpha) => {\n      const configs = [\n        { sampleBytes: yBytes, widthDivisor: 1, heightDivisor: 1 },\n        { sampleBytes: uvBytes, widthDivisor: subX, heightDivisor: subY },\n        { sampleBytes: uvBytes, widthDivisor: subX, heightDivisor: subY }\n      ];\n      if (hasAlpha) {\n        configs.push({ sampleBytes: yBytes, widthDivisor: 1, heightDivisor: 1 });\n      }\n      return configs;\n    };\n    switch (format) {\n      case \"I420\":\n        return yuv(1, 1, 2, 2, false);\n      case \"I420P10\":\n      case \"I420P12\":\n        return yuv(2, 2, 2, 2, false);\n      case \"I420A\":\n        return yuv(1, 1, 2, 2, true);\n      case \"I420AP10\":\n      case \"I420AP12\":\n        return yuv(2, 2, 2, 2, true);\n      case \"I422\":\n        return yuv(1, 1, 2, 1, false);\n      case \"I422P10\":\n      case \"I422P12\":\n        return yuv(2, 2, 2, 1, false);\n      case \"I422A\":\n        return yuv(1, 1, 2, 1, true);\n      case \"I422AP10\":\n      case \"I422AP12\":\n        return yuv(2, 2, 2, 1, true);\n      case \"I444\":\n        return yuv(1, 1, 1, 1, false);\n      case \"I444P10\":\n      case \"I444P12\":\n        return yuv(2, 2, 1, 1, false);\n      case \"I444A\":\n        return yuv(1, 1, 1, 1, true);\n      case \"I444AP10\":\n      case \"I444AP12\":\n        return yuv(2, 2, 1, 1, true);\n      case \"NV12\":\n        return [\n          { sampleBytes: 1, widthDivisor: 1, heightDivisor: 1 },\n          { sampleBytes: 2, widthDivisor: 2, heightDivisor: 2 }\n          // Interleaved U and V\n        ];\n      case \"RGBA\":\n      case \"RGBX\":\n      case \"BGRA\":\n      case \"BGRX\":\n        return [\n          { sampleBytes: 4, widthDivisor: 1, heightDivisor: 1 }\n        ];\n      default:\n        assertNever(format);\n        assert(false);\n    }\n  };\n  var AUDIO_SAMPLE_FORMATS = /* @__PURE__ */ new Set(\n    [\"f32\", \"f32-planar\", \"s16\", \"s16-planar\", \"s32\", \"s32-planar\", \"u8\", \"u8-planar\"]\n  );\n  var AudioSample = class _AudioSample {\n    /**\n     * Creates a new {@link AudioSample}, either from an existing\n     * [`AudioData`](https://developer.mozilla.org/en-US/docs/Web/API/AudioData) or from raw bytes specified in\n     * {@link AudioSampleInit}.\n     */\n    constructor(init) {\n      /** @internal */\n      this._closed = false;\n      if (isAudioData(init)) {\n        if (init.format === null) {\n          throw new TypeError(\"AudioData with null format is not supported.\");\n        }\n        this._data = init;\n        this.format = init.format;\n        this.sampleRate = init.sampleRate;\n        this.numberOfFrames = init.numberOfFrames;\n        this.numberOfChannels = init.numberOfChannels;\n        this.timestamp = init.timestamp / 1e6;\n        this.duration = init.numberOfFrames / init.sampleRate;\n      } else {\n        if (!init || typeof init !== \"object\") {\n          throw new TypeError(\"Invalid AudioDataInit: must be an object.\");\n        }\n        if (!AUDIO_SAMPLE_FORMATS.has(init.format)) {\n          throw new TypeError(\"Invalid AudioDataInit: invalid format.\");\n        }\n        if (!Number.isFinite(init.sampleRate) || init.sampleRate <= 0) {\n          throw new TypeError(\"Invalid AudioDataInit: sampleRate must be > 0.\");\n        }\n        if (!Number.isInteger(init.numberOfChannels) || init.numberOfChannels === 0) {\n          throw new TypeError(\"Invalid AudioDataInit: numberOfChannels must be an integer > 0.\");\n        }\n        if (!Number.isFinite(init?.timestamp)) {\n          throw new TypeError(\"init.timestamp must be a number.\");\n        }\n        const numberOfFrames = init.data.byteLength / (getBytesPerSample(init.format) * init.numberOfChannels);\n        if (!Number.isInteger(numberOfFrames)) {\n          throw new TypeError(\"Invalid AudioDataInit: data size is not a multiple of frame size.\");\n        }\n        this.format = init.format;\n        this.sampleRate = init.sampleRate;\n        this.numberOfFrames = numberOfFrames;\n        this.numberOfChannels = init.numberOfChannels;\n        this.timestamp = init.timestamp;\n        this.duration = numberOfFrames / init.sampleRate;\n        let dataBuffer;\n        if (init.data instanceof ArrayBuffer) {\n          dataBuffer = new Uint8Array(init.data);\n        } else if (ArrayBuffer.isView(init.data)) {\n          dataBuffer = new Uint8Array(init.data.buffer, init.data.byteOffset, init.data.byteLength);\n        } else {\n          throw new TypeError(\"Invalid AudioDataInit: data is not a BufferSource.\");\n        }\n        const expectedSize = this.numberOfFrames * this.numberOfChannels * getBytesPerSample(this.format);\n        if (dataBuffer.byteLength < expectedSize) {\n          throw new TypeError(\"Invalid AudioDataInit: insufficient data size.\");\n        }\n        this._data = dataBuffer;\n      }\n      finalizationRegistry?.register(this, { type: \"audio\", data: this._data }, this);\n    }\n    /** The presentation timestamp of the sample in microseconds. */\n    get microsecondTimestamp() {\n      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.timestamp);\n    }\n    /** The duration of the sample in microseconds. */\n    get microsecondDuration() {\n      return Math.trunc(SECOND_TO_MICROSECOND_FACTOR * this.duration);\n    }\n    /** Returns the number of bytes required to hold the audio sample's data as specified by the given options. */\n    allocationSize(options) {\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (!Number.isInteger(options.planeIndex) || options.planeIndex < 0) {\n        throw new TypeError(\"planeIndex must be a non-negative integer.\");\n      }\n      if (options.format !== void 0 && !AUDIO_SAMPLE_FORMATS.has(options.format)) {\n        throw new TypeError(\"Invalid format.\");\n      }\n      if (options.frameOffset !== void 0 && (!Number.isInteger(options.frameOffset) || options.frameOffset < 0)) {\n        throw new TypeError(\"frameOffset must be a non-negative integer.\");\n      }\n      if (options.frameCount !== void 0 && (!Number.isInteger(options.frameCount) || options.frameCount < 0)) {\n        throw new TypeError(\"frameCount must be a non-negative integer.\");\n      }\n      if (this._closed) {\n        throw new Error(\"AudioSample is closed.\");\n      }\n      const destFormat = options.format ?? this.format;\n      const frameOffset = options.frameOffset ?? 0;\n      if (frameOffset >= this.numberOfFrames) {\n        throw new RangeError(\"frameOffset out of range\");\n      }\n      const copyFrameCount = options.frameCount !== void 0 ? options.frameCount : this.numberOfFrames - frameOffset;\n      if (copyFrameCount > this.numberOfFrames - frameOffset) {\n        throw new RangeError(\"frameCount out of range\");\n      }\n      const bytesPerSample = getBytesPerSample(destFormat);\n      const isPlanar = formatIsPlanar(destFormat);\n      if (isPlanar && options.planeIndex >= this.numberOfChannels) {\n        throw new RangeError(\"planeIndex out of range\");\n      }\n      if (!isPlanar && options.planeIndex !== 0) {\n        throw new RangeError(\"planeIndex out of range\");\n      }\n      const elementCount = isPlanar ? copyFrameCount : copyFrameCount * this.numberOfChannels;\n      return elementCount * bytesPerSample;\n    }\n    /** Copies the audio sample's data to an ArrayBuffer or ArrayBufferView as specified by the given options. */\n    copyTo(destination, options) {\n      if (!isAllowSharedBufferSource(destination)) {\n        throw new TypeError(\"destination must be an ArrayBuffer or an ArrayBuffer view.\");\n      }\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (!Number.isInteger(options.planeIndex) || options.planeIndex < 0) {\n        throw new TypeError(\"planeIndex must be a non-negative integer.\");\n      }\n      if (options.format !== void 0 && !AUDIO_SAMPLE_FORMATS.has(options.format)) {\n        throw new TypeError(\"Invalid format.\");\n      }\n      if (options.frameOffset !== void 0 && (!Number.isInteger(options.frameOffset) || options.frameOffset < 0)) {\n        throw new TypeError(\"frameOffset must be a non-negative integer.\");\n      }\n      if (options.frameCount !== void 0 && (!Number.isInteger(options.frameCount) || options.frameCount < 0)) {\n        throw new TypeError(\"frameCount must be a non-negative integer.\");\n      }\n      if (this._closed) {\n        throw new Error(\"AudioSample is closed.\");\n      }\n      const { planeIndex, format, frameCount: optFrameCount, frameOffset: optFrameOffset } = options;\n      const srcFormat = this.format;\n      const destFormat = format ?? this.format;\n      if (!destFormat) throw new Error(\"Destination format not determined\");\n      const numFrames = this.numberOfFrames;\n      const numChannels = this.numberOfChannels;\n      const frameOffset = optFrameOffset ?? 0;\n      if (frameOffset >= numFrames) {\n        throw new RangeError(\"frameOffset out of range\");\n      }\n      const copyFrameCount = optFrameCount !== void 0 ? optFrameCount : numFrames - frameOffset;\n      if (copyFrameCount > numFrames - frameOffset) {\n        throw new RangeError(\"frameCount out of range\");\n      }\n      const destBytesPerSample = getBytesPerSample(destFormat);\n      const destIsPlanar = formatIsPlanar(destFormat);\n      if (destIsPlanar && planeIndex >= numChannels) {\n        throw new RangeError(\"planeIndex out of range\");\n      }\n      if (!destIsPlanar && planeIndex !== 0) {\n        throw new RangeError(\"planeIndex out of range\");\n      }\n      const destElementCount = destIsPlanar ? copyFrameCount : copyFrameCount * numChannels;\n      const requiredSize = destElementCount * destBytesPerSample;\n      if (destination.byteLength < requiredSize) {\n        throw new RangeError(\"Destination buffer is too small\");\n      }\n      const destView = toDataView(destination);\n      const writeFn = getWriteFunction(destFormat);\n      if (isAudioData(this._data)) {\n        if (isWebKit() && numChannels > 2 && destFormat !== srcFormat) {\n          doAudioDataCopyToWebKitWorkaround(\n            this._data,\n            destView,\n            srcFormat,\n            destFormat,\n            numChannels,\n            planeIndex,\n            frameOffset,\n            copyFrameCount\n          );\n        } else {\n          this._data.copyTo(destination, {\n            planeIndex,\n            frameOffset,\n            frameCount: copyFrameCount,\n            format: destFormat\n          });\n        }\n      } else {\n        const uint8Data = this._data;\n        const srcView = toDataView(uint8Data);\n        const readFn = getReadFunction(srcFormat);\n        const srcBytesPerSample = getBytesPerSample(srcFormat);\n        const srcIsPlanar = formatIsPlanar(srcFormat);\n        for (let i = 0; i < copyFrameCount; i++) {\n          if (destIsPlanar) {\n            const destOffset = i * destBytesPerSample;\n            let srcOffset;\n            if (srcIsPlanar) {\n              srcOffset = (planeIndex * numFrames + (i + frameOffset)) * srcBytesPerSample;\n            } else {\n              srcOffset = ((i + frameOffset) * numChannels + planeIndex) * srcBytesPerSample;\n            }\n            const normalized = readFn(srcView, srcOffset);\n            writeFn(destView, destOffset, normalized);\n          } else {\n            for (let ch = 0; ch < numChannels; ch++) {\n              const destIndex = i * numChannels + ch;\n              const destOffset = destIndex * destBytesPerSample;\n              let srcOffset;\n              if (srcIsPlanar) {\n                srcOffset = (ch * numFrames + (i + frameOffset)) * srcBytesPerSample;\n              } else {\n                srcOffset = ((i + frameOffset) * numChannels + ch) * srcBytesPerSample;\n              }\n              const normalized = readFn(srcView, srcOffset);\n              writeFn(destView, destOffset, normalized);\n            }\n          }\n        }\n      }\n    }\n    /** Clones this audio sample. */\n    clone() {\n      if (this._closed) {\n        throw new Error(\"AudioSample is closed.\");\n      }\n      if (isAudioData(this._data)) {\n        const sample = new _AudioSample(this._data.clone());\n        sample.setTimestamp(this.timestamp);\n        return sample;\n      } else {\n        return new _AudioSample({\n          format: this.format,\n          sampleRate: this.sampleRate,\n          numberOfFrames: this.numberOfFrames,\n          numberOfChannels: this.numberOfChannels,\n          timestamp: this.timestamp,\n          data: this._data\n        });\n      }\n    }\n    /**\n     * Closes this audio sample, releasing held resources. Audio samples should be closed as soon as they are not\n     * needed anymore.\n     */\n    close() {\n      if (this._closed) {\n        return;\n      }\n      finalizationRegistry?.unregister(this);\n      if (isAudioData(this._data)) {\n        this._data.close();\n      } else {\n        this._data = new Uint8Array(0);\n      }\n      this._closed = true;\n    }\n    /**\n     * Converts this audio sample to an AudioData for use with the WebCodecs API. The AudioData returned by this\n     * method *must* be closed separately from this audio sample.\n     */\n    toAudioData() {\n      if (this._closed) {\n        throw new Error(\"AudioSample is closed.\");\n      }\n      if (isAudioData(this._data)) {\n        if (this._data.timestamp === this.microsecondTimestamp) {\n          return this._data.clone();\n        } else {\n          if (formatIsPlanar(this.format)) {\n            const size = this.allocationSize({ planeIndex: 0, format: this.format });\n            const data = new ArrayBuffer(size * this.numberOfChannels);\n            for (let i = 0; i < this.numberOfChannels; i++) {\n              this.copyTo(new Uint8Array(data, i * size, size), { planeIndex: i, format: this.format });\n            }\n            return new AudioData({\n              format: this.format,\n              sampleRate: this.sampleRate,\n              numberOfFrames: this.numberOfFrames,\n              numberOfChannels: this.numberOfChannels,\n              timestamp: this.microsecondTimestamp,\n              data\n            });\n          } else {\n            const data = new ArrayBuffer(this.allocationSize({ planeIndex: 0, format: this.format }));\n            this.copyTo(data, { planeIndex: 0, format: this.format });\n            return new AudioData({\n              format: this.format,\n              sampleRate: this.sampleRate,\n              numberOfFrames: this.numberOfFrames,\n              numberOfChannels: this.numberOfChannels,\n              timestamp: this.microsecondTimestamp,\n              data\n            });\n          }\n        }\n      } else {\n        return new AudioData({\n          format: this.format,\n          sampleRate: this.sampleRate,\n          numberOfFrames: this.numberOfFrames,\n          numberOfChannels: this.numberOfChannels,\n          timestamp: this.microsecondTimestamp,\n          data: this._data.buffer instanceof ArrayBuffer ? this._data.buffer : this._data.slice()\n          // In the case of SharedArrayBuffer, convert to ArrayBuffer\n        });\n      }\n    }\n    /** Convert this audio sample to an AudioBuffer for use with the Web Audio API. */\n    toAudioBuffer() {\n      if (this._closed) {\n        throw new Error(\"AudioSample is closed.\");\n      }\n      const audioBuffer = new AudioBuffer({\n        numberOfChannels: this.numberOfChannels,\n        length: this.numberOfFrames,\n        sampleRate: this.sampleRate\n      });\n      const dataBytes = new Float32Array(this.allocationSize({ planeIndex: 0, format: \"f32-planar\" }) / 4);\n      for (let i = 0; i < this.numberOfChannels; i++) {\n        this.copyTo(dataBytes, { planeIndex: i, format: \"f32-planar\" });\n        audioBuffer.copyToChannel(dataBytes, i);\n      }\n      return audioBuffer;\n    }\n    /** Sets the presentation timestamp of this audio sample, in seconds. */\n    setTimestamp(newTimestamp) {\n      if (!Number.isFinite(newTimestamp)) {\n        throw new TypeError(\"newTimestamp must be a number.\");\n      }\n      this.timestamp = newTimestamp;\n    }\n    /** Calls `.close()`. */\n    [Symbol.dispose]() {\n      this.close();\n    }\n    /** @internal */\n    static *_fromAudioBuffer(audioBuffer, timestamp) {\n      if (!(audioBuffer instanceof AudioBuffer)) {\n        throw new TypeError(\"audioBuffer must be an AudioBuffer.\");\n      }\n      const MAX_FLOAT_COUNT = 48e3 * 5;\n      const numberOfChannels = audioBuffer.numberOfChannels;\n      const sampleRate = audioBuffer.sampleRate;\n      const totalFrames = audioBuffer.length;\n      const maxFramesPerChunk = Math.floor(MAX_FLOAT_COUNT / numberOfChannels);\n      let currentRelativeFrame = 0;\n      let remainingFrames = totalFrames;\n      while (remainingFrames > 0) {\n        const framesToCopy = Math.min(maxFramesPerChunk, remainingFrames);\n        const chunkData = new Float32Array(numberOfChannels * framesToCopy);\n        for (let channel = 0; channel < numberOfChannels; channel++) {\n          audioBuffer.copyFromChannel(\n            chunkData.subarray(channel * framesToCopy, (channel + 1) * framesToCopy),\n            channel,\n            currentRelativeFrame\n          );\n        }\n        yield new _AudioSample({\n          format: \"f32-planar\",\n          sampleRate,\n          numberOfFrames: framesToCopy,\n          numberOfChannels,\n          timestamp: timestamp + currentRelativeFrame / sampleRate,\n          data: chunkData\n        });\n        currentRelativeFrame += framesToCopy;\n        remainingFrames -= framesToCopy;\n      }\n    }\n    /**\n     * Creates AudioSamples from an AudioBuffer, starting at the given timestamp in seconds. Typically creates exactly\n     * one sample, but may create multiple if the AudioBuffer is exceedingly large.\n     */\n    static fromAudioBuffer(audioBuffer, timestamp) {\n      if (!(audioBuffer instanceof AudioBuffer)) {\n        throw new TypeError(\"audioBuffer must be an AudioBuffer.\");\n      }\n      const MAX_FLOAT_COUNT = 48e3 * 5;\n      const numberOfChannels = audioBuffer.numberOfChannels;\n      const sampleRate = audioBuffer.sampleRate;\n      const totalFrames = audioBuffer.length;\n      const maxFramesPerChunk = Math.floor(MAX_FLOAT_COUNT / numberOfChannels);\n      let currentRelativeFrame = 0;\n      let remainingFrames = totalFrames;\n      const result = [];\n      while (remainingFrames > 0) {\n        const framesToCopy = Math.min(maxFramesPerChunk, remainingFrames);\n        const chunkData = new Float32Array(numberOfChannels * framesToCopy);\n        for (let channel = 0; channel < numberOfChannels; channel++) {\n          audioBuffer.copyFromChannel(\n            chunkData.subarray(channel * framesToCopy, (channel + 1) * framesToCopy),\n            channel,\n            currentRelativeFrame\n          );\n        }\n        const audioSample = new _AudioSample({\n          format: \"f32-planar\",\n          sampleRate,\n          numberOfFrames: framesToCopy,\n          numberOfChannels,\n          timestamp: timestamp + currentRelativeFrame / sampleRate,\n          data: chunkData\n        });\n        result.push(audioSample);\n        currentRelativeFrame += framesToCopy;\n        remainingFrames -= framesToCopy;\n      }\n      return result;\n    }\n  };\n  var getBytesPerSample = (format) => {\n    switch (format) {\n      case \"u8\":\n      case \"u8-planar\":\n        return 1;\n      case \"s16\":\n      case \"s16-planar\":\n        return 2;\n      case \"s32\":\n      case \"s32-planar\":\n        return 4;\n      case \"f32\":\n      case \"f32-planar\":\n        return 4;\n      default:\n        throw new Error(\"Unknown AudioSampleFormat\");\n    }\n  };\n  var formatIsPlanar = (format) => {\n    switch (format) {\n      case \"u8-planar\":\n      case \"s16-planar\":\n      case \"s32-planar\":\n      case \"f32-planar\":\n        return true;\n      default:\n        return false;\n    }\n  };\n  var getReadFunction = (format) => {\n    switch (format) {\n      case \"u8\":\n      case \"u8-planar\":\n        return (view2, offset) => (view2.getUint8(offset) - 128) / 128;\n      case \"s16\":\n      case \"s16-planar\":\n        return (view2, offset) => view2.getInt16(offset, true) / 32768;\n      case \"s32\":\n      case \"s32-planar\":\n        return (view2, offset) => view2.getInt32(offset, true) / 2147483648;\n      case \"f32\":\n      case \"f32-planar\":\n        return (view2, offset) => view2.getFloat32(offset, true);\n    }\n  };\n  var getWriteFunction = (format) => {\n    switch (format) {\n      case \"u8\":\n      case \"u8-planar\":\n        return (view2, offset, value) => view2.setUint8(offset, clamp((value + 1) * 127.5, 0, 255));\n      case \"s16\":\n      case \"s16-planar\":\n        return (view2, offset, value) => view2.setInt16(offset, clamp(Math.round(value * 32767), -32768, 32767), true);\n      case \"s32\":\n      case \"s32-planar\":\n        return (view2, offset, value) => view2.setInt32(offset, clamp(Math.round(value * 2147483647), -2147483648, 2147483647), true);\n      case \"f32\":\n      case \"f32-planar\":\n        return (view2, offset, value) => view2.setFloat32(offset, value, true);\n    }\n  };\n  var isAudioData = (x) => {\n    return typeof AudioData !== \"undefined\" && x instanceof AudioData;\n  };\n  var doAudioDataCopyToWebKitWorkaround = (audioData, destView, srcFormat, destFormat, numChannels, planeIndex, frameOffset, copyFrameCount) => {\n    const readFn = getReadFunction(srcFormat);\n    const writeFn = getWriteFunction(destFormat);\n    const srcBytesPerSample = getBytesPerSample(srcFormat);\n    const destBytesPerSample = getBytesPerSample(destFormat);\n    const srcIsPlanar = formatIsPlanar(srcFormat);\n    const destIsPlanar = formatIsPlanar(destFormat);\n    if (destIsPlanar) {\n      if (srcIsPlanar) {\n        const data = new ArrayBuffer(copyFrameCount * srcBytesPerSample);\n        const dataView = toDataView(data);\n        audioData.copyTo(data, {\n          planeIndex,\n          frameOffset,\n          frameCount: copyFrameCount,\n          format: srcFormat\n        });\n        for (let i = 0; i < copyFrameCount; i++) {\n          const srcOffset = i * srcBytesPerSample;\n          const destOffset = i * destBytesPerSample;\n          const sample = readFn(dataView, srcOffset);\n          writeFn(destView, destOffset, sample);\n        }\n      } else {\n        const data = new ArrayBuffer(copyFrameCount * numChannels * srcBytesPerSample);\n        const dataView = toDataView(data);\n        audioData.copyTo(data, {\n          planeIndex: 0,\n          frameOffset,\n          frameCount: copyFrameCount,\n          format: srcFormat\n        });\n        for (let i = 0; i < copyFrameCount; i++) {\n          const srcOffset = (i * numChannels + planeIndex) * srcBytesPerSample;\n          const destOffset = i * destBytesPerSample;\n          const sample = readFn(dataView, srcOffset);\n          writeFn(destView, destOffset, sample);\n        }\n      }\n    } else {\n      if (srcIsPlanar) {\n        const planeSize = copyFrameCount * srcBytesPerSample;\n        const data = new ArrayBuffer(planeSize);\n        const dataView = toDataView(data);\n        for (let ch = 0; ch < numChannels; ch++) {\n          audioData.copyTo(data, {\n            planeIndex: ch,\n            frameOffset,\n            frameCount: copyFrameCount,\n            format: srcFormat\n          });\n          for (let i = 0; i < copyFrameCount; i++) {\n            const srcOffset = i * srcBytesPerSample;\n            const destOffset = (i * numChannels + ch) * destBytesPerSample;\n            const sample = readFn(dataView, srcOffset);\n            writeFn(destView, destOffset, sample);\n          }\n        }\n      } else {\n        const data = new ArrayBuffer(copyFrameCount * numChannels * srcBytesPerSample);\n        const dataView = toDataView(data);\n        audioData.copyTo(data, {\n          planeIndex: 0,\n          frameOffset,\n          frameCount: copyFrameCount,\n          format: srcFormat\n        });\n        for (let i = 0; i < copyFrameCount; i++) {\n          for (let ch = 0; ch < numChannels; ch++) {\n            const idx = i * numChannels + ch;\n            const srcOffset = idx * srcBytesPerSample;\n            const destOffset = idx * destBytesPerSample;\n            const sample = readFn(dataView, srcOffset);\n            writeFn(destView, destOffset, sample);\n          }\n        }\n      }\n    }\n  };\n\n  // src/media-sink.ts\n  var validatePacketRetrievalOptions = (options) => {\n    if (!options || typeof options !== \"object\") {\n      throw new TypeError(\"options must be an object.\");\n    }\n    if (options.metadataOnly !== void 0 && typeof options.metadataOnly !== \"boolean\") {\n      throw new TypeError(\"options.metadataOnly, when defined, must be a boolean.\");\n    }\n    if (options.verifyKeyPackets !== void 0 && typeof options.verifyKeyPackets !== \"boolean\") {\n      throw new TypeError(\"options.verifyKeyPackets, when defined, must be a boolean.\");\n    }\n    if (options.verifyKeyPackets && options.metadataOnly) {\n      throw new TypeError(\"options.verifyKeyPackets and options.metadataOnly cannot be enabled together.\");\n    }\n  };\n  var validateTimestamp = (timestamp) => {\n    if (!isNumber(timestamp)) {\n      throw new TypeError(\"timestamp must be a number.\");\n    }\n  };\n  var maybeFixPacketType = (track, promise, options) => {\n    if (options.verifyKeyPackets) {\n      return promise.then(async (packet) => {\n        if (!packet || packet.type === \"delta\") {\n          return packet;\n        }\n        const determinedType = await track.determinePacketType(packet);\n        if (determinedType) {\n          packet.type = determinedType;\n        }\n        return packet;\n      });\n    } else {\n      return promise;\n    }\n  };\n  var EncodedPacketSink = class {\n    /** Creates a new {@link EncodedPacketSink} for the given {@link InputTrack}. */\n    constructor(track) {\n      if (!(track instanceof InputTrack)) {\n        throw new TypeError(\"track must be an InputTrack.\");\n      }\n      this._track = track;\n    }\n    /**\n     * Retrieves the track's first packet (in decode order), or null if it has no packets. The first packet is very\n     * likely to be a key packet.\n     */\n    getFirstPacket(options = {}) {\n      validatePacketRetrievalOptions(options);\n      if (this._track.input._disposed) {\n        throw new InputDisposedError();\n      }\n      return maybeFixPacketType(this._track, this._track._backing.getFirstPacket(options), options);\n    }\n    /**\n     * Retrieves the packet corresponding to the given timestamp, in seconds. More specifically, returns the last packet\n     * (in presentation order) with a start timestamp less than or equal to the given timestamp. This method can be\n     * used to retrieve a track's last packet using `getPacket(Infinity)`. The method returns null if the timestamp\n     * is before the first packet in the track.\n     *\n     * @param timestamp - The timestamp used for retrieval, in seconds.\n     */\n    getPacket(timestamp, options = {}) {\n      validateTimestamp(timestamp);\n      validatePacketRetrievalOptions(options);\n      if (this._track.input._disposed) {\n        throw new InputDisposedError();\n      }\n      return maybeFixPacketType(this._track, this._track._backing.getPacket(timestamp, options), options);\n    }\n    /**\n     * Retrieves the packet following the given packet (in decode order), or null if the given packet is the\n     * last packet.\n     */\n    getNextPacket(packet, options = {}) {\n      if (!(packet instanceof EncodedPacket)) {\n        throw new TypeError(\"packet must be an EncodedPacket.\");\n      }\n      validatePacketRetrievalOptions(options);\n      if (this._track.input._disposed) {\n        throw new InputDisposedError();\n      }\n      return maybeFixPacketType(this._track, this._track._backing.getNextPacket(packet, options), options);\n    }\n    /**\n     * Retrieves the key packet corresponding to the given timestamp, in seconds. More specifically, returns the last\n     * key packet (in presentation order) with a start timestamp less than or equal to the given timestamp. A key packet\n     * is a packet that doesn't require previous packets to be decoded. This method can be used to retrieve a track's\n     * last key packet using `getKeyPacket(Infinity)`. The method returns null if the timestamp is before the first\n     * key packet in the track.\n     *\n     * To ensure that the returned packet is guaranteed to be a real key frame, enable `options.verifyKeyPackets`.\n     *\n     * @param timestamp - The timestamp used for retrieval, in seconds.\n     */\n    async getKeyPacket(timestamp, options = {}) {\n      validateTimestamp(timestamp);\n      validatePacketRetrievalOptions(options);\n      if (this._track.input._disposed) {\n        throw new InputDisposedError();\n      }\n      if (!options.verifyKeyPackets) {\n        return this._track._backing.getKeyPacket(timestamp, options);\n      }\n      const packet = await this._track._backing.getKeyPacket(timestamp, options);\n      if (!packet) {\n        return packet;\n      }\n      assert(packet.type === \"key\");\n      const determinedType = await this._track.determinePacketType(packet);\n      if (determinedType === \"delta\") {\n        return this.getKeyPacket(packet.timestamp - 1 / this._track.timeResolution, options);\n      }\n      return packet;\n    }\n    /**\n     * Retrieves the key packet following the given packet (in decode order), or null if the given packet is the last\n     * key packet.\n     *\n     * To ensure that the returned packet is guaranteed to be a real key frame, enable `options.verifyKeyPackets`.\n     */\n    async getNextKeyPacket(packet, options = {}) {\n      if (!(packet instanceof EncodedPacket)) {\n        throw new TypeError(\"packet must be an EncodedPacket.\");\n      }\n      validatePacketRetrievalOptions(options);\n      if (this._track.input._disposed) {\n        throw new InputDisposedError();\n      }\n      if (!options.verifyKeyPackets) {\n        return this._track._backing.getNextKeyPacket(packet, options);\n      }\n      const nextPacket = await this._track._backing.getNextKeyPacket(packet, options);\n      if (!nextPacket) {\n        return nextPacket;\n      }\n      assert(nextPacket.type === \"key\");\n      const determinedType = await this._track.determinePacketType(nextPacket);\n      if (determinedType === \"delta\") {\n        return this.getNextKeyPacket(nextPacket, options);\n      }\n      return nextPacket;\n    }\n    /**\n     * Creates an async iterator that yields the packets in this track in decode order. To enable fast iteration, this\n     * method will intelligently preload packets based on the speed of the consumer.\n     *\n     * @param startPacket - (optional) The packet from which iteration should begin. This packet will also be yielded.\n     * @param endTimestamp - (optional) The timestamp at which iteration should end. This packet will _not_ be yielded.\n     */\n    packets(startPacket, endPacket, options = {}) {\n      if (startPacket !== void 0 && !(startPacket instanceof EncodedPacket)) {\n        throw new TypeError(\"startPacket must be an EncodedPacket.\");\n      }\n      if (startPacket !== void 0 && startPacket.isMetadataOnly && !options?.metadataOnly) {\n        throw new TypeError(\"startPacket can only be metadata-only if options.metadataOnly is enabled.\");\n      }\n      if (endPacket !== void 0 && !(endPacket instanceof EncodedPacket)) {\n        throw new TypeError(\"endPacket must be an EncodedPacket.\");\n      }\n      validatePacketRetrievalOptions(options);\n      if (this._track.input._disposed) {\n        throw new InputDisposedError();\n      }\n      const packetQueue = [];\n      let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers();\n      let { promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers();\n      let ended = false;\n      let terminated = false;\n      let outOfBandError = null;\n      const timestamps = [];\n      const maxQueueSize = () => Math.max(2, timestamps.length);\n      (async () => {\n        let packet = startPacket ?? await this.getFirstPacket(options);\n        while (packet && !terminated && !this._track.input._disposed) {\n          if (endPacket && packet.sequenceNumber >= endPacket?.sequenceNumber) {\n            break;\n          }\n          if (packetQueue.length > maxQueueSize()) {\n            ({ promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers());\n            await queueDequeue;\n            continue;\n          }\n          packetQueue.push(packet);\n          onQueueNotEmpty();\n          ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers());\n          packet = await this.getNextPacket(packet, options);\n        }\n        ended = true;\n        onQueueNotEmpty();\n      })().catch((error) => {\n        if (!outOfBandError) {\n          outOfBandError = error;\n          onQueueNotEmpty();\n        }\n      });\n      const track = this._track;\n      return {\n        async next() {\n          while (true) {\n            if (track.input._disposed) {\n              throw new InputDisposedError();\n            } else if (terminated) {\n              return { value: void 0, done: true };\n            } else if (outOfBandError) {\n              throw outOfBandError;\n            } else if (packetQueue.length > 0) {\n              const value = packetQueue.shift();\n              const now = performance.now();\n              timestamps.push(now);\n              while (timestamps.length > 0 && now - timestamps[0] >= 1e3) {\n                timestamps.shift();\n              }\n              onQueueDequeue();\n              return { value, done: false };\n            } else if (ended) {\n              return { value: void 0, done: true };\n            } else {\n              await queueNotEmpty;\n            }\n          }\n        },\n        async return() {\n          terminated = true;\n          onQueueDequeue();\n          onQueueNotEmpty();\n          return { value: void 0, done: true };\n        },\n        async throw(error) {\n          throw error;\n        },\n        [Symbol.asyncIterator]() {\n          return this;\n        }\n      };\n    }\n  };\n  var DecoderWrapper = class {\n    constructor(onSample, onError) {\n      this.onSample = onSample;\n      this.onError = onError;\n    }\n  };\n  var BaseMediaSampleSink = class {\n    /** @internal */\n    mediaSamplesInRange(startTimestamp = 0, endTimestamp = Infinity) {\n      validateTimestamp(startTimestamp);\n      validateTimestamp(endTimestamp);\n      const sampleQueue = [];\n      let firstSampleQueued = false;\n      let lastSample = null;\n      let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers();\n      let { promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers();\n      let decoderIsFlushed = false;\n      let ended = false;\n      let terminated = false;\n      let outOfBandError = null;\n      (async () => {\n        const decoder = await this._createDecoder((sample) => {\n          onQueueDequeue();\n          if (sample.timestamp >= endTimestamp) {\n            ended = true;\n          }\n          if (ended) {\n            sample.close();\n            return;\n          }\n          if (lastSample) {\n            if (sample.timestamp > startTimestamp) {\n              sampleQueue.push(lastSample);\n              firstSampleQueued = true;\n            } else {\n              lastSample.close();\n            }\n          }\n          if (sample.timestamp >= startTimestamp) {\n            sampleQueue.push(sample);\n            firstSampleQueued = true;\n          }\n          lastSample = firstSampleQueued ? null : sample;\n          if (sampleQueue.length > 0) {\n            onQueueNotEmpty();\n            ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers());\n          }\n        }, (error) => {\n          if (!outOfBandError) {\n            outOfBandError = error;\n            onQueueNotEmpty();\n          }\n        });\n        const packetSink = this._createPacketSink();\n        const keyPacket = await packetSink.getKeyPacket(startTimestamp, { verifyKeyPackets: true }) ?? await packetSink.getFirstPacket();\n        let currentPacket = keyPacket;\n        const endPacket = void 0;\n        const packets = packetSink.packets(keyPacket ?? void 0, endPacket);\n        await packets.next();\n        while (currentPacket && !ended && !this._track.input._disposed) {\n          const maxQueueSize = computeMaxQueueSize(sampleQueue.length);\n          if (sampleQueue.length + decoder.getDecodeQueueSize() > maxQueueSize) {\n            ({ promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers());\n            await queueDequeue;\n            continue;\n          }\n          decoder.decode(currentPacket);\n          const packetResult = await packets.next();\n          if (packetResult.done) {\n            break;\n          }\n          currentPacket = packetResult.value;\n        }\n        await packets.return();\n        if (!terminated && !this._track.input._disposed) {\n          await decoder.flush();\n        }\n        decoder.close();\n        if (!firstSampleQueued && lastSample) {\n          sampleQueue.push(lastSample);\n        }\n        decoderIsFlushed = true;\n        onQueueNotEmpty();\n      })().catch((error) => {\n        if (!outOfBandError) {\n          outOfBandError = error;\n          onQueueNotEmpty();\n        }\n      });\n      const track = this._track;\n      const closeSamples = () => {\n        lastSample?.close();\n        for (const sample of sampleQueue) {\n          sample.close();\n        }\n      };\n      return {\n        async next() {\n          while (true) {\n            if (track.input._disposed) {\n              closeSamples();\n              throw new InputDisposedError();\n            } else if (terminated) {\n              return { value: void 0, done: true };\n            } else if (outOfBandError) {\n              closeSamples();\n              throw outOfBandError;\n            } else if (sampleQueue.length > 0) {\n              const value = sampleQueue.shift();\n              onQueueDequeue();\n              return { value, done: false };\n            } else if (!decoderIsFlushed) {\n              await queueNotEmpty;\n            } else {\n              return { value: void 0, done: true };\n            }\n          }\n        },\n        async return() {\n          terminated = true;\n          ended = true;\n          onQueueDequeue();\n          onQueueNotEmpty();\n          closeSamples();\n          return { value: void 0, done: true };\n        },\n        async throw(error) {\n          throw error;\n        },\n        [Symbol.asyncIterator]() {\n          return this;\n        }\n      };\n    }\n    /** @internal */\n    mediaSamplesAtTimestamps(timestamps) {\n      validateAnyIterable(timestamps);\n      const timestampIterator = toAsyncIterator(timestamps);\n      const timestampsOfInterest = [];\n      const sampleQueue = [];\n      let { promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers();\n      let { promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers();\n      let decoderIsFlushed = false;\n      let terminated = false;\n      let outOfBandError = null;\n      const pushToQueue = (sample) => {\n        sampleQueue.push(sample);\n        onQueueNotEmpty();\n        ({ promise: queueNotEmpty, resolve: onQueueNotEmpty } = promiseWithResolvers());\n      };\n      (async () => {\n        const decoder = await this._createDecoder((sample) => {\n          onQueueDequeue();\n          if (terminated) {\n            sample.close();\n            return;\n          }\n          let sampleUses = 0;\n          while (timestampsOfInterest.length > 0 && sample.timestamp - timestampsOfInterest[0] > -1e-10) {\n            sampleUses++;\n            timestampsOfInterest.shift();\n          }\n          if (sampleUses > 0) {\n            for (let i = 0; i < sampleUses; i++) {\n              pushToQueue(i < sampleUses - 1 ? sample.clone() : sample);\n            }\n          } else {\n            sample.close();\n          }\n        }, (error) => {\n          if (!outOfBandError) {\n            outOfBandError = error;\n            onQueueNotEmpty();\n          }\n        });\n        const packetSink = this._createPacketSink();\n        let lastPacket = null;\n        let lastKeyPacket = null;\n        let maxSequenceNumber = -1;\n        const decodePackets = async () => {\n          assert(lastKeyPacket);\n          let currentPacket = lastKeyPacket;\n          decoder.decode(currentPacket);\n          while (currentPacket.sequenceNumber < maxSequenceNumber) {\n            const maxQueueSize = computeMaxQueueSize(sampleQueue.length);\n            while (sampleQueue.length + decoder.getDecodeQueueSize() > maxQueueSize && !terminated) {\n              ({ promise: queueDequeue, resolve: onQueueDequeue } = promiseWithResolvers());\n              await queueDequeue;\n            }\n            if (terminated) {\n              break;\n            }\n            const nextPacket = await packetSink.getNextPacket(currentPacket);\n            assert(nextPacket);\n            decoder.decode(nextPacket);\n            currentPacket = nextPacket;\n          }\n          maxSequenceNumber = -1;\n        };\n        const flushDecoder = async () => {\n          await decoder.flush();\n          for (let i = 0; i < timestampsOfInterest.length; i++) {\n            pushToQueue(null);\n          }\n          timestampsOfInterest.length = 0;\n        };\n        for await (const timestamp of timestampIterator) {\n          validateTimestamp(timestamp);\n          if (terminated || this._track.input._disposed) {\n            break;\n          }\n          const targetPacket = await packetSink.getPacket(timestamp);\n          const keyPacket = targetPacket && await packetSink.getKeyPacket(timestamp, { verifyKeyPackets: true });\n          if (!keyPacket) {\n            if (maxSequenceNumber !== -1) {\n              await decodePackets();\n              await flushDecoder();\n            }\n            pushToQueue(null);\n            lastPacket = null;\n            continue;\n          }\n          if (lastPacket && (keyPacket.sequenceNumber !== lastKeyPacket.sequenceNumber || targetPacket.timestamp < lastPacket.timestamp)) {\n            await decodePackets();\n            await flushDecoder();\n          }\n          timestampsOfInterest.push(targetPacket.timestamp);\n          maxSequenceNumber = Math.max(targetPacket.sequenceNumber, maxSequenceNumber);\n          lastPacket = targetPacket;\n          lastKeyPacket = keyPacket;\n        }\n        if (!terminated && !this._track.input._disposed) {\n          if (maxSequenceNumber !== -1) {\n            await decodePackets();\n          }\n          await flushDecoder();\n        }\n        decoder.close();\n        decoderIsFlushed = true;\n        onQueueNotEmpty();\n      })().catch((error) => {\n        if (!outOfBandError) {\n          outOfBandError = error;\n          onQueueNotEmpty();\n        }\n      });\n      const track = this._track;\n      const closeSamples = () => {\n        for (const sample of sampleQueue) {\n          sample?.close();\n        }\n      };\n      return {\n        async next() {\n          while (true) {\n            if (track.input._disposed) {\n              closeSamples();\n              throw new InputDisposedError();\n            } else if (terminated) {\n              return { value: void 0, done: true };\n            } else if (outOfBandError) {\n              closeSamples();\n              throw outOfBandError;\n            } else if (sampleQueue.length > 0) {\n              const value = sampleQueue.shift();\n              assert(value !== void 0);\n              onQueueDequeue();\n              return { value, done: false };\n            } else if (!decoderIsFlushed) {\n              await queueNotEmpty;\n            } else {\n              return { value: void 0, done: true };\n            }\n          }\n        },\n        async return() {\n          terminated = true;\n          onQueueDequeue();\n          onQueueNotEmpty();\n          closeSamples();\n          return { value: void 0, done: true };\n        },\n        async throw(error) {\n          throw error;\n        },\n        [Symbol.asyncIterator]() {\n          return this;\n        }\n      };\n    }\n  };\n  var computeMaxQueueSize = (decodedSampleQueueSize) => {\n    return decodedSampleQueueSize === 0 ? 40 : 8;\n  };\n  var VideoDecoderWrapper = class extends DecoderWrapper {\n    // For HEVC stuff\n    constructor(onSample, onError, codec, decoderConfig, rotation, timeResolution) {\n      super(onSample, onError);\n      this.codec = codec;\n      this.decoderConfig = decoderConfig;\n      this.rotation = rotation;\n      this.timeResolution = timeResolution;\n      this.decoder = null;\n      this.customDecoder = null;\n      this.customDecoderCallSerializer = new CallSerializer();\n      this.customDecoderQueueSize = 0;\n      this.inputTimestamps = [];\n      // Timestamps input into the decoder, sorted.\n      this.sampleQueue = [];\n      // Safari-specific thing, check usage.\n      this.currentPacketIndex = 0;\n      this.raslSkipped = false;\n      // For HEVC stuff\n      // Alpha stuff\n      this.alphaDecoder = null;\n      this.alphaHadKeyframe = false;\n      this.colorQueue = [];\n      this.alphaQueue = [];\n      this.merger = null;\n      this.mergerCreationFailed = false;\n      this.decodedAlphaChunkCount = 0;\n      this.alphaDecoderQueueSize = 0;\n      /** Each value is the number of decoded alpha chunks at which a null alpha frame should be added. */\n      this.nullAlphaFrameQueue = [];\n      this.currentAlphaPacketIndex = 0;\n      this.alphaRaslSkipped = false;\n      const MatchingCustomDecoder = customVideoDecoders.find((x) => x.supports(codec, decoderConfig));\n      if (MatchingCustomDecoder) {\n        this.customDecoder = new MatchingCustomDecoder();\n        this.customDecoder.codec = codec;\n        this.customDecoder.config = decoderConfig;\n        this.customDecoder.onSample = (sample) => {\n          if (!(sample instanceof VideoSample)) {\n            throw new TypeError(\"The argument passed to onSample must be a VideoSample.\");\n          }\n          this.finalizeAndEmitSample(sample);\n        };\n        void this.customDecoderCallSerializer.call(() => this.customDecoder.init());\n      } else {\n        const colorHandler = (frame) => {\n          if (this.alphaQueue.length > 0) {\n            const alphaFrame = this.alphaQueue.shift();\n            assert(alphaFrame !== void 0);\n            this.mergeAlpha(frame, alphaFrame);\n          } else {\n            this.colorQueue.push(frame);\n          }\n        };\n        if (codec === \"avc\" && this.decoderConfig.description && isChromium()) {\n          const record = deserializeAvcDecoderConfigurationRecord(toUint8Array(this.decoderConfig.description));\n          if (record && record.sequenceParameterSets.length > 0) {\n            const sps = parseAvcSps(record.sequenceParameterSets[0]);\n            if (sps && sps.frameMbsOnlyFlag === 0) {\n              this.decoderConfig = {\n                ...this.decoderConfig,\n                hardwareAcceleration: \"prefer-software\"\n              };\n            }\n          }\n        }\n        const stack = new Error(\"Decoding error\").stack;\n        this.decoder = new VideoDecoder({\n          output: (frame) => {\n            try {\n              colorHandler(frame);\n            } catch (error) {\n              this.onError(error);\n            }\n          },\n          error: (error) => {\n            error.stack = stack;\n            this.onError(error);\n          }\n        });\n        this.decoder.configure(this.decoderConfig);\n      }\n    }\n    getDecodeQueueSize() {\n      if (this.customDecoder) {\n        return this.customDecoderQueueSize;\n      } else {\n        assert(this.decoder);\n        return Math.max(\n          this.decoder.decodeQueueSize,\n          this.alphaDecoder?.decodeQueueSize ?? 0\n        );\n      }\n    }\n    decode(packet) {\n      if (this.codec === \"hevc\" && this.currentPacketIndex > 0 && !this.raslSkipped) {\n        if (this.hasHevcRaslPicture(packet.data)) {\n          return;\n        }\n        this.raslSkipped = true;\n      }\n      if (this.customDecoder) {\n        this.customDecoderQueueSize++;\n        void this.customDecoderCallSerializer.call(() => this.customDecoder.decode(packet)).then(() => this.customDecoderQueueSize--);\n      } else {\n        assert(this.decoder);\n        if (!isWebKit()) {\n          insertSorted(this.inputTimestamps, packet.timestamp, (x) => x);\n        }\n        if (isChromium() && this.currentPacketIndex === 0 && this.codec === \"avc\") {\n          const filteredNalUnits = [];\n          for (const loc of iterateAvcNalUnits(packet.data, this.decoderConfig)) {\n            const type = extractNalUnitTypeForAvc(packet.data[loc.offset]);\n            if (!(type >= 20 && type <= 31)) {\n              filteredNalUnits.push(packet.data.subarray(loc.offset, loc.offset + loc.length));\n            }\n          }\n          const newData = concatAvcNalUnits(filteredNalUnits, this.decoderConfig);\n          packet = new EncodedPacket(newData, packet.type, packet.timestamp, packet.duration);\n        }\n        this.decoder.decode(packet.toEncodedVideoChunk());\n        this.decodeAlphaData(packet);\n      }\n      this.currentPacketIndex++;\n    }\n    decodeAlphaData(packet) {\n      if (!packet.sideData.alpha || this.mergerCreationFailed) {\n        this.pushNullAlphaFrame();\n        return;\n      }\n      if (!this.merger) {\n        try {\n          this.merger = new ColorAlphaMerger();\n        } catch (error) {\n          console.error(\"Due to an error, only color data will be decoded.\", error);\n          this.mergerCreationFailed = true;\n          this.decodeAlphaData(packet);\n          return;\n        }\n      }\n      if (!this.alphaDecoder) {\n        const alphaHandler = (frame) => {\n          this.alphaDecoderQueueSize--;\n          if (this.colorQueue.length > 0) {\n            const colorFrame = this.colorQueue.shift();\n            assert(colorFrame !== void 0);\n            this.mergeAlpha(colorFrame, frame);\n          } else {\n            this.alphaQueue.push(frame);\n          }\n          this.decodedAlphaChunkCount++;\n          while (this.nullAlphaFrameQueue.length > 0 && this.nullAlphaFrameQueue[0] === this.decodedAlphaChunkCount) {\n            this.nullAlphaFrameQueue.shift();\n            if (this.colorQueue.length > 0) {\n              const colorFrame = this.colorQueue.shift();\n              assert(colorFrame !== void 0);\n              this.mergeAlpha(colorFrame, null);\n            } else {\n              this.alphaQueue.push(null);\n            }\n          }\n        };\n        const stack = new Error(\"Decoding error\").stack;\n        this.alphaDecoder = new VideoDecoder({\n          output: (frame) => {\n            try {\n              alphaHandler(frame);\n            } catch (error) {\n              this.onError(error);\n            }\n          },\n          error: (error) => {\n            error.stack = stack;\n            this.onError(error);\n          }\n        });\n        this.alphaDecoder.configure(this.decoderConfig);\n      }\n      const type = determineVideoPacketType(this.codec, this.decoderConfig, packet.sideData.alpha);\n      if (!this.alphaHadKeyframe) {\n        this.alphaHadKeyframe = type === \"key\";\n      }\n      if (this.alphaHadKeyframe) {\n        if (this.codec === \"hevc\" && this.currentAlphaPacketIndex > 0 && !this.alphaRaslSkipped) {\n          if (this.hasHevcRaslPicture(packet.sideData.alpha)) {\n            this.pushNullAlphaFrame();\n            return;\n          }\n          this.alphaRaslSkipped = true;\n        }\n        this.currentAlphaPacketIndex++;\n        this.alphaDecoder.decode(packet.alphaToEncodedVideoChunk(type ?? packet.type));\n        this.alphaDecoderQueueSize++;\n      } else {\n        this.pushNullAlphaFrame();\n      }\n    }\n    pushNullAlphaFrame() {\n      if (this.alphaDecoderQueueSize === 0) {\n        this.alphaQueue.push(null);\n      } else {\n        this.nullAlphaFrameQueue.push(this.decodedAlphaChunkCount + this.alphaDecoderQueueSize);\n      }\n    }\n    /**\n     * If we're using HEVC, we need to make sure to skip any RASL slices that follow a non-IDR key frame such as\n     * CRA_NUT. This is because RASL slices cannot be decoded without data before the CRA_NUT. Browsers behave\n     * differently here: Chromium drops the packets, Safari throws a decoder error. Either way, it's not good\n     * and causes bugs upstream. So, let's take the dropping into our own hands.\n     */\n    hasHevcRaslPicture(packetData) {\n      for (const loc of iterateHevcNalUnits(packetData, this.decoderConfig)) {\n        const type = extractNalUnitTypeForHevc(packetData[loc.offset]);\n        if (type === 8 /* RASL_N */ || type === 9 /* RASL_R */) {\n          return true;\n        }\n      }\n      return false;\n    }\n    /** Handler for the WebCodecs VideoDecoder for ironing out browser differences. */\n    sampleHandler(sample) {\n      if (isWebKit()) {\n        if (this.sampleQueue.length > 0 && sample.timestamp >= last(this.sampleQueue).timestamp) {\n          for (const sample2 of this.sampleQueue) {\n            this.finalizeAndEmitSample(sample2);\n          }\n          this.sampleQueue.length = 0;\n        }\n        insertSorted(this.sampleQueue, sample, (x) => x.timestamp);\n      } else {\n        const timestamp = this.inputTimestamps.shift();\n        assert(timestamp !== void 0);\n        sample.setTimestamp(timestamp);\n        this.finalizeAndEmitSample(sample);\n      }\n    }\n    finalizeAndEmitSample(sample) {\n      sample.setTimestamp(Math.round(sample.timestamp * this.timeResolution) / this.timeResolution);\n      sample.setDuration(Math.round(sample.duration * this.timeResolution) / this.timeResolution);\n      sample.setRotation(this.rotation);\n      this.onSample(sample);\n    }\n    mergeAlpha(color, alpha) {\n      if (!alpha) {\n        const finalSample2 = new VideoSample(color);\n        this.sampleHandler(finalSample2);\n        return;\n      }\n      assert(this.merger);\n      this.merger.update(color, alpha);\n      color.close();\n      alpha.close();\n      const finalFrame = new VideoFrame(this.merger.canvas, {\n        timestamp: color.timestamp,\n        duration: color.duration ?? void 0\n      });\n      const finalSample = new VideoSample(finalFrame);\n      this.sampleHandler(finalSample);\n    }\n    async flush() {\n      if (this.customDecoder) {\n        await this.customDecoderCallSerializer.call(() => this.customDecoder.flush());\n      } else {\n        assert(this.decoder);\n        await Promise.all([\n          this.decoder.flush(),\n          this.alphaDecoder?.flush()\n        ]);\n        this.colorQueue.forEach((x) => x.close());\n        this.colorQueue.length = 0;\n        this.alphaQueue.forEach((x) => x?.close());\n        this.alphaQueue.length = 0;\n        this.alphaHadKeyframe = false;\n        this.decodedAlphaChunkCount = 0;\n        this.alphaDecoderQueueSize = 0;\n        this.nullAlphaFrameQueue.length = 0;\n        this.currentAlphaPacketIndex = 0;\n        this.alphaRaslSkipped = false;\n      }\n      if (isWebKit()) {\n        for (const sample of this.sampleQueue) {\n          this.finalizeAndEmitSample(sample);\n        }\n        this.sampleQueue.length = 0;\n      }\n      this.currentPacketIndex = 0;\n      this.raslSkipped = false;\n    }\n    close() {\n      if (this.customDecoder) {\n        void this.customDecoderCallSerializer.call(() => this.customDecoder.close());\n      } else {\n        assert(this.decoder);\n        this.decoder.close();\n        this.alphaDecoder?.close();\n        this.colorQueue.forEach((x) => x.close());\n        this.colorQueue.length = 0;\n        this.alphaQueue.forEach((x) => x?.close());\n        this.alphaQueue.length = 0;\n        this.merger?.close();\n      }\n      for (const sample of this.sampleQueue) {\n        sample.close();\n      }\n      this.sampleQueue.length = 0;\n    }\n  };\n  var ColorAlphaMerger = class {\n    constructor() {\n      if (typeof OffscreenCanvas !== \"undefined\") {\n        this.canvas = new OffscreenCanvas(300, 150);\n      } else {\n        this.canvas = document.createElement(\"canvas\");\n      }\n      const gl = this.canvas.getContext(\"webgl2\", {\n        premultipliedAlpha: false\n      });\n      if (!gl) {\n        throw new Error(\"Couldn't acquire WebGL 2 context.\");\n      }\n      this.gl = gl;\n      this.program = this.createProgram();\n      this.vao = this.createVAO();\n      this.colorTexture = this.createTexture();\n      this.alphaTexture = this.createTexture();\n      this.gl.useProgram(this.program);\n      this.gl.uniform1i(this.gl.getUniformLocation(this.program, \"u_colorTexture\"), 0);\n      this.gl.uniform1i(this.gl.getUniformLocation(this.program, \"u_alphaTexture\"), 1);\n    }\n    createProgram() {\n      const vertexShader = this.createShader(this.gl.VERTEX_SHADER, `#version 300 es\n\t\t\tin vec2 a_position;\n\t\t\tin vec2 a_texCoord;\n\t\t\tout vec2 v_texCoord;\n\t\t\t\n\t\t\tvoid main() {\n\t\t\t\tgl_Position = vec4(a_position, 0.0, 1.0);\n\t\t\t\tv_texCoord = a_texCoord;\n\t\t\t}\n\t\t`);\n      const fragmentShader = this.createShader(this.gl.FRAGMENT_SHADER, `#version 300 es\n\t\t\tprecision highp float;\n\t\t\t\n\t\t\tuniform sampler2D u_colorTexture;\n\t\t\tuniform sampler2D u_alphaTexture;\n\t\t\tin vec2 v_texCoord;\n\t\t\tout vec4 fragColor;\n\t\t\t\n\t\t\tvoid main() {\n\t\t\t\tvec3 color = texture(u_colorTexture, v_texCoord).rgb;\n\t\t\t\tfloat alpha = texture(u_alphaTexture, v_texCoord).r;\n\t\t\t\tfragColor = vec4(color, alpha);\n\t\t\t}\n\t\t`);\n      const program = this.gl.createProgram();\n      this.gl.attachShader(program, vertexShader);\n      this.gl.attachShader(program, fragmentShader);\n      this.gl.linkProgram(program);\n      return program;\n    }\n    createShader(type, source) {\n      const shader = this.gl.createShader(type);\n      this.gl.shaderSource(shader, source);\n      this.gl.compileShader(shader);\n      return shader;\n    }\n    createVAO() {\n      const vao = this.gl.createVertexArray();\n      this.gl.bindVertexArray(vao);\n      const vertices = new Float32Array([\n        -1,\n        -1,\n        0,\n        1,\n        1,\n        -1,\n        1,\n        1,\n        -1,\n        1,\n        0,\n        0,\n        1,\n        1,\n        1,\n        0\n      ]);\n      const buffer = this.gl.createBuffer();\n      this.gl.bindBuffer(this.gl.ARRAY_BUFFER, buffer);\n      this.gl.bufferData(this.gl.ARRAY_BUFFER, vertices, this.gl.STATIC_DRAW);\n      const positionLocation = this.gl.getAttribLocation(this.program, \"a_position\");\n      const texCoordLocation = this.gl.getAttribLocation(this.program, \"a_texCoord\");\n      this.gl.enableVertexAttribArray(positionLocation);\n      this.gl.vertexAttribPointer(positionLocation, 2, this.gl.FLOAT, false, 16, 0);\n      this.gl.enableVertexAttribArray(texCoordLocation);\n      this.gl.vertexAttribPointer(texCoordLocation, 2, this.gl.FLOAT, false, 16, 8);\n      return vao;\n    }\n    createTexture() {\n      const texture = this.gl.createTexture();\n      this.gl.bindTexture(this.gl.TEXTURE_2D, texture);\n      this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);\n      this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);\n      this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR);\n      this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR);\n      return texture;\n    }\n    update(color, alpha) {\n      if (color.displayWidth !== this.canvas.width || color.displayHeight !== this.canvas.height) {\n        this.canvas.width = color.displayWidth;\n        this.canvas.height = color.displayHeight;\n      }\n      this.gl.activeTexture(this.gl.TEXTURE0);\n      this.gl.bindTexture(this.gl.TEXTURE_2D, this.colorTexture);\n      this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, color);\n      this.gl.activeTexture(this.gl.TEXTURE1);\n      this.gl.bindTexture(this.gl.TEXTURE_2D, this.alphaTexture);\n      this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, alpha);\n      this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);\n      this.gl.clear(this.gl.COLOR_BUFFER_BIT);\n      this.gl.bindVertexArray(this.vao);\n      this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);\n    }\n    close() {\n      this.gl.getExtension(\"WEBGL_lose_context\")?.loseContext();\n      this.gl = null;\n    }\n  };\n  var VideoSampleSink = class extends BaseMediaSampleSink {\n    /** Creates a new {@link VideoSampleSink} for the given {@link InputVideoTrack}. */\n    constructor(videoTrack) {\n      if (!(videoTrack instanceof InputVideoTrack)) {\n        throw new TypeError(\"videoTrack must be an InputVideoTrack.\");\n      }\n      super();\n      this._track = videoTrack;\n    }\n    /** @internal */\n    async _createDecoder(onSample, onError) {\n      if (!await this._track.canDecode()) {\n        throw new Error(\n          \"This video track cannot be decoded by this browser. Make sure to check decodability before using a track.\"\n        );\n      }\n      const codec = this._track.codec;\n      const rotation = this._track.rotation;\n      const decoderConfig = await this._track.getDecoderConfig();\n      const timeResolution = this._track.timeResolution;\n      assert(codec && decoderConfig);\n      return new VideoDecoderWrapper(onSample, onError, codec, decoderConfig, rotation, timeResolution);\n    }\n    /** @internal */\n    _createPacketSink() {\n      return new EncodedPacketSink(this._track);\n    }\n    /**\n     * Retrieves the video sample (frame) corresponding to the given timestamp, in seconds. More specifically, returns\n     * the last video sample (in presentation order) with a start timestamp less than or equal to the given timestamp.\n     * Returns null if the timestamp is before the track's first timestamp.\n     *\n     * @param timestamp - The timestamp used for retrieval, in seconds.\n     */\n    async getSample(timestamp) {\n      validateTimestamp(timestamp);\n      for await (const sample of this.mediaSamplesAtTimestamps([timestamp])) {\n        return sample;\n      }\n      throw new Error(\"Internal error: Iterator returned nothing.\");\n    }\n    /**\n     * Creates an async iterator that yields the video samples (frames) of this track in presentation order. This method\n     * will intelligently pre-decode a few frames ahead to enable fast iteration.\n     *\n     * @param startTimestamp - The timestamp in seconds at which to start yielding samples (inclusive).\n     * @param endTimestamp - The timestamp in seconds at which to stop yielding samples (exclusive).\n     */\n    samples(startTimestamp = 0, endTimestamp = Infinity) {\n      return this.mediaSamplesInRange(startTimestamp, endTimestamp);\n    }\n    /**\n     * Creates an async iterator that yields a video sample (frame) for each timestamp in the argument. This method\n     * uses an optimized decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most\n     * once, and is therefore more efficient than manually getting the sample for every timestamp. The iterator may\n     * yield null if no frame is available for a given timestamp.\n     *\n     * @param timestamps - An iterable or async iterable of timestamps in seconds.\n     */\n    samplesAtTimestamps(timestamps) {\n      return this.mediaSamplesAtTimestamps(timestamps);\n    }\n  };\n  var CanvasSink = class {\n    /** Creates a new {@link CanvasSink} for the given {@link InputVideoTrack}. */\n    constructor(videoTrack, options = {}) {\n      /** @internal */\n      this._nextCanvasIndex = 0;\n      if (!(videoTrack instanceof InputVideoTrack)) {\n        throw new TypeError(\"videoTrack must be an InputVideoTrack.\");\n      }\n      if (options && typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.alpha !== void 0 && typeof options.alpha !== \"boolean\") {\n        throw new TypeError(\"options.alpha, when provided, must be a boolean.\");\n      }\n      if (options.width !== void 0 && (!Number.isInteger(options.width) || options.width <= 0)) {\n        throw new TypeError(\"options.width, when defined, must be a positive integer.\");\n      }\n      if (options.height !== void 0 && (!Number.isInteger(options.height) || options.height <= 0)) {\n        throw new TypeError(\"options.height, when defined, must be a positive integer.\");\n      }\n      if (options.fit !== void 0 && ![\"fill\", \"contain\", \"cover\"].includes(options.fit)) {\n        throw new TypeError('options.fit, when provided, must be one of \"fill\", \"contain\", or \"cover\".');\n      }\n      if (options.width !== void 0 && options.height !== void 0 && options.fit === void 0) {\n        throw new TypeError(\n          \"When both options.width and options.height are provided, options.fit must also be provided.\"\n        );\n      }\n      if (options.rotation !== void 0 && ![0, 90, 180, 270].includes(options.rotation)) {\n        throw new TypeError(\"options.rotation, when provided, must be 0, 90, 180 or 270.\");\n      }\n      if (options.crop !== void 0) {\n        validateCropRectangle(options.crop, \"options.\");\n      }\n      if (options.poolSize !== void 0 && (typeof options.poolSize !== \"number\" || !Number.isInteger(options.poolSize) || options.poolSize < 0)) {\n        throw new TypeError(\"poolSize must be a non-negative integer.\");\n      }\n      const rotation = options.rotation ?? videoTrack.rotation;\n      const [rotatedWidth, rotatedHeight] = rotation % 180 === 0 ? [videoTrack.codedWidth, videoTrack.codedHeight] : [videoTrack.codedHeight, videoTrack.codedWidth];\n      const crop = options.crop;\n      if (crop) {\n        clampCropRectangle(crop, rotatedWidth, rotatedHeight);\n      }\n      let [width, height] = crop ? [crop.width, crop.height] : [rotatedWidth, rotatedHeight];\n      const originalAspectRatio = width / height;\n      if (options.width !== void 0 && options.height === void 0) {\n        width = options.width;\n        height = Math.round(width / originalAspectRatio);\n      } else if (options.width === void 0 && options.height !== void 0) {\n        height = options.height;\n        width = Math.round(height * originalAspectRatio);\n      } else if (options.width !== void 0 && options.height !== void 0) {\n        width = options.width;\n        height = options.height;\n      }\n      this._videoTrack = videoTrack;\n      this._alpha = options.alpha ?? false;\n      this._width = width;\n      this._height = height;\n      this._rotation = rotation;\n      this._crop = crop;\n      this._fit = options.fit ?? \"fill\";\n      this._videoSampleSink = new VideoSampleSink(videoTrack);\n      this._canvasPool = Array.from({ length: options.poolSize ?? 0 }, () => null);\n    }\n    /** @internal */\n    _videoSampleToWrappedCanvas(sample) {\n      let canvas = this._canvasPool[this._nextCanvasIndex];\n      let canvasIsNew = false;\n      if (!canvas) {\n        if (typeof document !== \"undefined\") {\n          canvas = document.createElement(\"canvas\");\n          canvas.width = this._width;\n          canvas.height = this._height;\n        } else {\n          canvas = new OffscreenCanvas(this._width, this._height);\n        }\n        if (this._canvasPool.length > 0) {\n          this._canvasPool[this._nextCanvasIndex] = canvas;\n        }\n        canvasIsNew = true;\n      }\n      if (this._canvasPool.length > 0) {\n        this._nextCanvasIndex = (this._nextCanvasIndex + 1) % this._canvasPool.length;\n      }\n      const context = canvas.getContext(\"2d\", {\n        alpha: this._alpha || isFirefox()\n        // Firefox has VideoFrame glitches with opaque canvases\n      });\n      assert(context);\n      context.resetTransform();\n      if (!canvasIsNew) {\n        if (!this._alpha && isFirefox()) {\n          context.fillStyle = \"black\";\n          context.fillRect(0, 0, this._width, this._height);\n        } else {\n          context.clearRect(0, 0, this._width, this._height);\n        }\n      }\n      sample.drawWithFit(context, {\n        fit: this._fit,\n        rotation: this._rotation,\n        crop: this._crop\n      });\n      const result = {\n        canvas,\n        timestamp: sample.timestamp,\n        duration: sample.duration\n      };\n      sample.close();\n      return result;\n    }\n    /**\n     * Retrieves a canvas with the video frame corresponding to the given timestamp, in seconds. More specifically,\n     * returns the last video frame (in presentation order) with a start timestamp less than or equal to the given\n     * timestamp. Returns null if the timestamp is before the track's first timestamp.\n     *\n     * @param timestamp - The timestamp used for retrieval, in seconds.\n     */\n    async getCanvas(timestamp) {\n      validateTimestamp(timestamp);\n      const sample = await this._videoSampleSink.getSample(timestamp);\n      return sample && this._videoSampleToWrappedCanvas(sample);\n    }\n    /**\n     * Creates an async iterator that yields canvases with the video frames of this track in presentation order. This\n     * method will intelligently pre-decode a few frames ahead to enable fast iteration.\n     *\n     * @param startTimestamp - The timestamp in seconds at which to start yielding canvases (inclusive).\n     * @param endTimestamp - The timestamp in seconds at which to stop yielding canvases (exclusive).\n     */\n    canvases(startTimestamp = 0, endTimestamp = Infinity) {\n      return mapAsyncGenerator(\n        this._videoSampleSink.samples(startTimestamp, endTimestamp),\n        (sample) => this._videoSampleToWrappedCanvas(sample)\n      );\n    }\n    /**\n     * Creates an async iterator that yields a canvas for each timestamp in the argument. This method uses an optimized\n     * decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most once, and is\n     * therefore more efficient than manually getting the canvas for every timestamp. The iterator may yield null if\n     * no frame is available for a given timestamp.\n     *\n     * @param timestamps - An iterable or async iterable of timestamps in seconds.\n     */\n    canvasesAtTimestamps(timestamps) {\n      return mapAsyncGenerator(\n        this._videoSampleSink.samplesAtTimestamps(timestamps),\n        (sample) => sample && this._videoSampleToWrappedCanvas(sample)\n      );\n    }\n  };\n  var AudioDecoderWrapper = class extends DecoderWrapper {\n    constructor(onSample, onError, codec, decoderConfig) {\n      super(onSample, onError);\n      this.decoder = null;\n      this.customDecoder = null;\n      this.customDecoderCallSerializer = new CallSerializer();\n      this.customDecoderQueueSize = 0;\n      // Internal state to accumulate a precise current timestamp based on audio durations, not the (potentially\n      // inaccurate) packet timestamps.\n      this.currentTimestamp = null;\n      const sampleHandler = (sample) => {\n        if (this.currentTimestamp === null || Math.abs(sample.timestamp - this.currentTimestamp) >= sample.duration) {\n          this.currentTimestamp = sample.timestamp;\n        }\n        const preciseTimestamp = this.currentTimestamp;\n        this.currentTimestamp += sample.duration;\n        if (sample.numberOfFrames === 0) {\n          sample.close();\n          return;\n        }\n        const sampleRate = decoderConfig.sampleRate;\n        sample.setTimestamp(Math.round(preciseTimestamp * sampleRate) / sampleRate);\n        onSample(sample);\n      };\n      const MatchingCustomDecoder = customAudioDecoders.find((x) => x.supports(codec, decoderConfig));\n      if (MatchingCustomDecoder) {\n        this.customDecoder = new MatchingCustomDecoder();\n        this.customDecoder.codec = codec;\n        this.customDecoder.config = decoderConfig;\n        this.customDecoder.onSample = (sample) => {\n          if (!(sample instanceof AudioSample)) {\n            throw new TypeError(\"The argument passed to onSample must be an AudioSample.\");\n          }\n          sampleHandler(sample);\n        };\n        void this.customDecoderCallSerializer.call(() => this.customDecoder.init());\n      } else {\n        const stack = new Error(\"Decoding error\").stack;\n        this.decoder = new AudioDecoder({\n          output: (data) => {\n            try {\n              sampleHandler(new AudioSample(data));\n            } catch (error) {\n              this.onError(error);\n            }\n          },\n          error: (error) => {\n            error.stack = stack;\n            this.onError(error);\n          }\n        });\n        this.decoder.configure(decoderConfig);\n      }\n    }\n    getDecodeQueueSize() {\n      if (this.customDecoder) {\n        return this.customDecoderQueueSize;\n      } else {\n        assert(this.decoder);\n        return this.decoder.decodeQueueSize;\n      }\n    }\n    decode(packet) {\n      if (this.customDecoder) {\n        this.customDecoderQueueSize++;\n        void this.customDecoderCallSerializer.call(() => this.customDecoder.decode(packet)).then(() => this.customDecoderQueueSize--);\n      } else {\n        assert(this.decoder);\n        this.decoder.decode(packet.toEncodedAudioChunk());\n      }\n    }\n    flush() {\n      if (this.customDecoder) {\n        return this.customDecoderCallSerializer.call(() => this.customDecoder.flush());\n      } else {\n        assert(this.decoder);\n        return this.decoder.flush();\n      }\n    }\n    close() {\n      if (this.customDecoder) {\n        void this.customDecoderCallSerializer.call(() => this.customDecoder.close());\n      } else {\n        assert(this.decoder);\n        this.decoder.close();\n      }\n    }\n  };\n  var PcmAudioDecoderWrapper = class extends DecoderWrapper {\n    constructor(onSample, onError, decoderConfig) {\n      super(onSample, onError);\n      this.decoderConfig = decoderConfig;\n      // Internal state to accumulate a precise current timestamp based on audio durations, not the (potentially\n      // inaccurate) packet timestamps.\n      this.currentTimestamp = null;\n      assert(PCM_AUDIO_CODECS.includes(decoderConfig.codec));\n      this.codec = decoderConfig.codec;\n      const { dataType, sampleSize, littleEndian } = parsePcmCodec(this.codec);\n      this.inputSampleSize = sampleSize;\n      switch (sampleSize) {\n        case 1:\n          {\n            if (dataType === \"unsigned\") {\n              this.readInputValue = (view2, byteOffset) => view2.getUint8(byteOffset) - 2 ** 7;\n            } else if (dataType === \"signed\") {\n              this.readInputValue = (view2, byteOffset) => view2.getInt8(byteOffset);\n            } else if (dataType === \"ulaw\") {\n              this.readInputValue = (view2, byteOffset) => fromUlaw(view2.getUint8(byteOffset));\n            } else if (dataType === \"alaw\") {\n              this.readInputValue = (view2, byteOffset) => fromAlaw(view2.getUint8(byteOffset));\n            } else {\n              assert(false);\n            }\n          }\n          ;\n          break;\n        case 2:\n          {\n            if (dataType === \"unsigned\") {\n              this.readInputValue = (view2, byteOffset) => view2.getUint16(byteOffset, littleEndian) - 2 ** 15;\n            } else if (dataType === \"signed\") {\n              this.readInputValue = (view2, byteOffset) => view2.getInt16(byteOffset, littleEndian);\n            } else {\n              assert(false);\n            }\n          }\n          ;\n          break;\n        case 3:\n          {\n            if (dataType === \"unsigned\") {\n              this.readInputValue = (view2, byteOffset) => getUint24(view2, byteOffset, littleEndian) - 2 ** 23;\n            } else if (dataType === \"signed\") {\n              this.readInputValue = (view2, byteOffset) => getInt24(view2, byteOffset, littleEndian);\n            } else {\n              assert(false);\n            }\n          }\n          ;\n          break;\n        case 4:\n          {\n            if (dataType === \"unsigned\") {\n              this.readInputValue = (view2, byteOffset) => view2.getUint32(byteOffset, littleEndian) - 2 ** 31;\n            } else if (dataType === \"signed\") {\n              this.readInputValue = (view2, byteOffset) => view2.getInt32(byteOffset, littleEndian);\n            } else if (dataType === \"float\") {\n              this.readInputValue = (view2, byteOffset) => view2.getFloat32(byteOffset, littleEndian);\n            } else {\n              assert(false);\n            }\n          }\n          ;\n          break;\n        case 8:\n          {\n            if (dataType === \"float\") {\n              this.readInputValue = (view2, byteOffset) => view2.getFloat64(byteOffset, littleEndian);\n            } else {\n              assert(false);\n            }\n          }\n          ;\n          break;\n        default:\n          {\n            assertNever(sampleSize);\n            assert(false);\n          }\n          ;\n      }\n      switch (sampleSize) {\n        case 1:\n          {\n            if (dataType === \"ulaw\" || dataType === \"alaw\") {\n              this.outputSampleSize = 2;\n              this.outputFormat = \"s16\";\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setInt16(byteOffset, value, true);\n            } else {\n              this.outputSampleSize = 1;\n              this.outputFormat = \"u8\";\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setUint8(byteOffset, value + 2 ** 7);\n            }\n          }\n          ;\n          break;\n        case 2:\n          {\n            this.outputSampleSize = 2;\n            this.outputFormat = \"s16\";\n            this.writeOutputValue = (view2, byteOffset, value) => view2.setInt16(byteOffset, value, true);\n          }\n          ;\n          break;\n        case 3:\n          {\n            this.outputSampleSize = 4;\n            this.outputFormat = \"s32\";\n            this.writeOutputValue = (view2, byteOffset, value) => view2.setInt32(byteOffset, value << 8, true);\n          }\n          ;\n          break;\n        case 4:\n          {\n            this.outputSampleSize = 4;\n            if (dataType === \"float\") {\n              this.outputFormat = \"f32\";\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setFloat32(byteOffset, value, true);\n            } else {\n              this.outputFormat = \"s32\";\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setInt32(byteOffset, value, true);\n            }\n          }\n          ;\n          break;\n        case 8:\n          {\n            this.outputSampleSize = 4;\n            this.outputFormat = \"f32\";\n            this.writeOutputValue = (view2, byteOffset, value) => view2.setFloat32(byteOffset, value, true);\n          }\n          ;\n          break;\n        default:\n          {\n            assertNever(sampleSize);\n            assert(false);\n          }\n          ;\n      }\n      ;\n    }\n    getDecodeQueueSize() {\n      return 0;\n    }\n    decode(packet) {\n      const inputView = toDataView(packet.data);\n      const numberOfFrames = packet.byteLength / this.decoderConfig.numberOfChannels / this.inputSampleSize;\n      const outputBufferSize = numberOfFrames * this.decoderConfig.numberOfChannels * this.outputSampleSize;\n      const outputBuffer = new ArrayBuffer(outputBufferSize);\n      const outputView = new DataView(outputBuffer);\n      for (let i = 0; i < numberOfFrames * this.decoderConfig.numberOfChannels; i++) {\n        const inputIndex = i * this.inputSampleSize;\n        const outputIndex = i * this.outputSampleSize;\n        const value = this.readInputValue(inputView, inputIndex);\n        this.writeOutputValue(outputView, outputIndex, value);\n      }\n      const preciseDuration = numberOfFrames / this.decoderConfig.sampleRate;\n      if (this.currentTimestamp === null || Math.abs(packet.timestamp - this.currentTimestamp) >= preciseDuration) {\n        this.currentTimestamp = packet.timestamp;\n      }\n      const preciseTimestamp = this.currentTimestamp;\n      this.currentTimestamp += preciseDuration;\n      const audioSample = new AudioSample({\n        format: this.outputFormat,\n        data: outputBuffer,\n        numberOfChannels: this.decoderConfig.numberOfChannels,\n        sampleRate: this.decoderConfig.sampleRate,\n        numberOfFrames,\n        timestamp: preciseTimestamp\n      });\n      this.onSample(audioSample);\n    }\n    async flush() {\n    }\n    close() {\n    }\n  };\n  var AudioSampleSink = class extends BaseMediaSampleSink {\n    /** Creates a new {@link AudioSampleSink} for the given {@link InputAudioTrack}. */\n    constructor(audioTrack) {\n      if (!(audioTrack instanceof InputAudioTrack)) {\n        throw new TypeError(\"audioTrack must be an InputAudioTrack.\");\n      }\n      super();\n      this._track = audioTrack;\n    }\n    /** @internal */\n    async _createDecoder(onSample, onError) {\n      if (!await this._track.canDecode()) {\n        throw new Error(\n          \"This audio track cannot be decoded by this browser. Make sure to check decodability before using a track.\"\n        );\n      }\n      const codec = this._track.codec;\n      const decoderConfig = await this._track.getDecoderConfig();\n      assert(codec && decoderConfig);\n      if (PCM_AUDIO_CODECS.includes(decoderConfig.codec)) {\n        return new PcmAudioDecoderWrapper(onSample, onError, decoderConfig);\n      } else {\n        return new AudioDecoderWrapper(onSample, onError, codec, decoderConfig);\n      }\n    }\n    /** @internal */\n    _createPacketSink() {\n      return new EncodedPacketSink(this._track);\n    }\n    /**\n     * Retrieves the audio sample corresponding to the given timestamp, in seconds. More specifically, returns\n     * the last audio sample (in presentation order) with a start timestamp less than or equal to the given timestamp.\n     * Returns null if the timestamp is before the track's first timestamp.\n     *\n     * @param timestamp - The timestamp used for retrieval, in seconds.\n     */\n    async getSample(timestamp) {\n      validateTimestamp(timestamp);\n      for await (const sample of this.mediaSamplesAtTimestamps([timestamp])) {\n        return sample;\n      }\n      throw new Error(\"Internal error: Iterator returned nothing.\");\n    }\n    /**\n     * Creates an async iterator that yields the audio samples of this track in presentation order. This method\n     * will intelligently pre-decode a few samples ahead to enable fast iteration.\n     *\n     * @param startTimestamp - The timestamp in seconds at which to start yielding samples (inclusive).\n     * @param endTimestamp - The timestamp in seconds at which to stop yielding samples (exclusive).\n     */\n    samples(startTimestamp = 0, endTimestamp = Infinity) {\n      return this.mediaSamplesInRange(startTimestamp, endTimestamp);\n    }\n    /**\n     * Creates an async iterator that yields an audio sample for each timestamp in the argument. This method\n     * uses an optimized decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most\n     * once, and is therefore more efficient than manually getting the sample for every timestamp. The iterator may\n     * yield null if no sample is available for a given timestamp.\n     *\n     * @param timestamps - An iterable or async iterable of timestamps in seconds.\n     */\n    samplesAtTimestamps(timestamps) {\n      return this.mediaSamplesAtTimestamps(timestamps);\n    }\n  };\n  var AudioBufferSink = class {\n    /** Creates a new {@link AudioBufferSink} for the given {@link InputAudioTrack}. */\n    constructor(audioTrack) {\n      if (!(audioTrack instanceof InputAudioTrack)) {\n        throw new TypeError(\"audioTrack must be an InputAudioTrack.\");\n      }\n      this._audioSampleSink = new AudioSampleSink(audioTrack);\n    }\n    /** @internal */\n    _audioSampleToWrappedArrayBuffer(sample) {\n      const result = {\n        buffer: sample.toAudioBuffer(),\n        timestamp: sample.timestamp,\n        duration: sample.duration\n      };\n      sample.close();\n      return result;\n    }\n    /**\n     * Retrieves the audio buffer corresponding to the given timestamp, in seconds. More specifically, returns\n     * the last audio buffer (in presentation order) with a start timestamp less than or equal to the given timestamp.\n     * Returns null if the timestamp is before the track's first timestamp.\n     *\n     * @param timestamp - The timestamp used for retrieval, in seconds.\n     */\n    async getBuffer(timestamp) {\n      validateTimestamp(timestamp);\n      const data = await this._audioSampleSink.getSample(timestamp);\n      return data && this._audioSampleToWrappedArrayBuffer(data);\n    }\n    /**\n     * Creates an async iterator that yields audio buffers of this track in presentation order. This method\n     * will intelligently pre-decode a few buffers ahead to enable fast iteration.\n     *\n     * @param startTimestamp - The timestamp in seconds at which to start yielding buffers (inclusive).\n     * @param endTimestamp - The timestamp in seconds at which to stop yielding buffers (exclusive).\n     */\n    buffers(startTimestamp = 0, endTimestamp = Infinity) {\n      return mapAsyncGenerator(\n        this._audioSampleSink.samples(startTimestamp, endTimestamp),\n        (data) => this._audioSampleToWrappedArrayBuffer(data)\n      );\n    }\n    /**\n     * Creates an async iterator that yields an audio buffer for each timestamp in the argument. This method\n     * uses an optimized decoding pipeline if these timestamps are monotonically sorted, decoding each packet at most\n     * once, and is therefore more efficient than manually getting the buffer for every timestamp. The iterator may\n     * yield null if no buffer is available for a given timestamp.\n     *\n     * @param timestamps - An iterable or async iterable of timestamps in seconds.\n     */\n    buffersAtTimestamps(timestamps) {\n      return mapAsyncGenerator(\n        this._audioSampleSink.samplesAtTimestamps(timestamps),\n        (data) => data && this._audioSampleToWrappedArrayBuffer(data)\n      );\n    }\n  };\n\n  // src/input-track.ts\n  var InputTrack = class {\n    /** @internal */\n    constructor(input, backing) {\n      this.input = input;\n      this._backing = backing;\n    }\n    /** Returns true if and only if this track is a video track. */\n    isVideoTrack() {\n      return this instanceof InputVideoTrack;\n    }\n    /** Returns true if and only if this track is an audio track. */\n    isAudioTrack() {\n      return this instanceof InputAudioTrack;\n    }\n    /** The unique ID of this track in the input file. */\n    get id() {\n      return this._backing.getId();\n    }\n    /**\n     * The identifier of the codec used internally by the container. It is not homogenized by Mediabunny\n     * and depends entirely on the container format.\n     *\n     * This field can be used to determine the codec of a track in case Mediabunny doesn't know that codec.\n     *\n     * - For ISOBMFF files, this field returns the name of the Sample Description Box (e.g. `'avc1'`).\n     * - For Matroska files, this field returns the value of the `CodecID` element.\n     * - For WAVE files, this field returns the value of the format tag in the `'fmt '` chunk.\n     * - For ADTS files, this field contains the `MPEG-4 Audio Object Type`.\n     * - For MPEG-TS files, this field contains the `streamType` value from the Program Map Table.\n     * - In all other cases, this field is `null`.\n     */\n    get internalCodecId() {\n      return this._backing.getInternalCodecId();\n    }\n    /**\n     * The ISO 639-2/T language code for this track. If the language is unknown, this field is `'und'` (undetermined).\n     */\n    get languageCode() {\n      return this._backing.getLanguageCode();\n    }\n    /** A user-defined name for this track. */\n    get name() {\n      return this._backing.getName();\n    }\n    /**\n     * A positive number x such that all timestamps and durations of all packets of this track are\n     * integer multiples of 1/x.\n     */\n    get timeResolution() {\n      return this._backing.getTimeResolution();\n    }\n    /** The track's disposition, i.e. information about its intended usage. */\n    get disposition() {\n      return this._backing.getDisposition();\n    }\n    /**\n     * Returns the start timestamp of the first packet of this track, in seconds. While often near zero, this value\n     * may be positive or even negative. A negative starting timestamp means the track's timing has been offset. Samples\n     * with a negative timestamp should not be presented.\n     */\n    getFirstTimestamp() {\n      return this._backing.getFirstTimestamp();\n    }\n    /** Returns the end timestamp of the last packet of this track, in seconds. */\n    computeDuration() {\n      return this._backing.computeDuration();\n    }\n    /**\n     * Computes aggregate packet statistics for this track, such as average packet rate or bitrate.\n     *\n     * @param targetPacketCount - This optional parameter sets a target for how many packets this method must have\n     * looked at before it can return early; this means, you can use it to aggregate only a subset (prefix) of all\n     * packets. This is very useful for getting a great estimate of video frame rate without having to scan through the\n     * entire file.\n     */\n    async computePacketStats(targetPacketCount = Infinity) {\n      const sink = new EncodedPacketSink(this);\n      let startTimestamp = Infinity;\n      let endTimestamp = -Infinity;\n      let packetCount = 0;\n      let totalPacketBytes = 0;\n      for await (const packet of sink.packets(void 0, void 0, { metadataOnly: true })) {\n        if (packetCount >= targetPacketCount && packet.timestamp >= endTimestamp) {\n          break;\n        }\n        startTimestamp = Math.min(startTimestamp, packet.timestamp);\n        endTimestamp = Math.max(endTimestamp, packet.timestamp + packet.duration);\n        packetCount++;\n        totalPacketBytes += packet.byteLength;\n      }\n      return {\n        packetCount,\n        averagePacketRate: packetCount ? Number((packetCount / (endTimestamp - startTimestamp)).toPrecision(16)) : 0,\n        averageBitrate: packetCount ? Number((8 * totalPacketBytes / (endTimestamp - startTimestamp)).toPrecision(16)) : 0\n      };\n    }\n  };\n  var InputVideoTrack = class extends InputTrack {\n    /** @internal */\n    constructor(input, backing) {\n      super(input, backing);\n      this._backing = backing;\n    }\n    get type() {\n      return \"video\";\n    }\n    get codec() {\n      return this._backing.getCodec();\n    }\n    /** The width in pixels of the track's coded samples, before any transformations or rotations. */\n    get codedWidth() {\n      return this._backing.getCodedWidth();\n    }\n    /** The height in pixels of the track's coded samples, before any transformations or rotations. */\n    get codedHeight() {\n      return this._backing.getCodedHeight();\n    }\n    /** The angle in degrees by which the track's frames should be rotated (clockwise). */\n    get rotation() {\n      return this._backing.getRotation();\n    }\n    /** The width in pixels of the track's frames after rotation. */\n    get displayWidth() {\n      const rotation = this._backing.getRotation();\n      return rotation % 180 === 0 ? this._backing.getCodedWidth() : this._backing.getCodedHeight();\n    }\n    /** The height in pixels of the track's frames after rotation. */\n    get displayHeight() {\n      const rotation = this._backing.getRotation();\n      return rotation % 180 === 0 ? this._backing.getCodedHeight() : this._backing.getCodedWidth();\n    }\n    /** Returns the color space of the track's samples. */\n    getColorSpace() {\n      return this._backing.getColorSpace();\n    }\n    /** If this method returns true, the track's samples use a high dynamic range (HDR). */\n    async hasHighDynamicRange() {\n      const colorSpace = await this._backing.getColorSpace();\n      return colorSpace.primaries === \"bt2020\" || colorSpace.primaries === \"smpte432\" || colorSpace.transfer === \"pg\" || colorSpace.transfer === \"hlg\" || colorSpace.matrix === \"bt2020-ncl\";\n    }\n    /** Checks if this track may contain transparent samples with alpha data. */\n    canBeTransparent() {\n      return this._backing.canBeTransparent();\n    }\n    /**\n     * Returns the [decoder configuration](https://www.w3.org/TR/webcodecs/#video-decoder-config) for decoding the\n     * track's packets using a [`VideoDecoder`](https://developer.mozilla.org/en-US/docs/Web/API/VideoDecoder). Returns\n     * null if the track's codec is unknown.\n     */\n    getDecoderConfig() {\n      return this._backing.getDecoderConfig();\n    }\n    async getCodecParameterString() {\n      const decoderConfig = await this._backing.getDecoderConfig();\n      return decoderConfig?.codec ?? null;\n    }\n    async canDecode() {\n      try {\n        const decoderConfig = await this._backing.getDecoderConfig();\n        if (!decoderConfig) {\n          return false;\n        }\n        const codec = this._backing.getCodec();\n        assert(codec !== null);\n        if (customVideoDecoders.some((x) => x.supports(codec, decoderConfig))) {\n          return true;\n        }\n        if (typeof VideoDecoder === \"undefined\") {\n          return false;\n        }\n        const support = await VideoDecoder.isConfigSupported(decoderConfig);\n        return support.supported === true;\n      } catch (error) {\n        console.error(\"Error during decodability check:\", error);\n        return false;\n      }\n    }\n    async determinePacketType(packet) {\n      if (!(packet instanceof EncodedPacket)) {\n        throw new TypeError(\"packet must be an EncodedPacket.\");\n      }\n      if (packet.isMetadataOnly) {\n        throw new TypeError(\"packet must not be metadata-only to determine its type.\");\n      }\n      if (this.codec === null) {\n        return null;\n      }\n      const decoderConfig = await this.getDecoderConfig();\n      assert(decoderConfig);\n      return determineVideoPacketType(this.codec, decoderConfig, packet.data);\n    }\n  };\n  var InputAudioTrack = class extends InputTrack {\n    /** @internal */\n    constructor(input, backing) {\n      super(input, backing);\n      this._backing = backing;\n    }\n    get type() {\n      return \"audio\";\n    }\n    get codec() {\n      return this._backing.getCodec();\n    }\n    /** The number of audio channels in the track. */\n    get numberOfChannels() {\n      return this._backing.getNumberOfChannels();\n    }\n    /** The track's audio sample rate in hertz. */\n    get sampleRate() {\n      return this._backing.getSampleRate();\n    }\n    /**\n     * Returns the [decoder configuration](https://www.w3.org/TR/webcodecs/#audio-decoder-config) for decoding the\n     * track's packets using an [`AudioDecoder`](https://developer.mozilla.org/en-US/docs/Web/API/AudioDecoder). Returns\n     * null if the track's codec is unknown.\n     */\n    getDecoderConfig() {\n      return this._backing.getDecoderConfig();\n    }\n    async getCodecParameterString() {\n      const decoderConfig = await this._backing.getDecoderConfig();\n      return decoderConfig?.codec ?? null;\n    }\n    async canDecode() {\n      try {\n        const decoderConfig = await this._backing.getDecoderConfig();\n        if (!decoderConfig) {\n          return false;\n        }\n        const codec = this._backing.getCodec();\n        assert(codec !== null);\n        if (customAudioDecoders.some((x) => x.supports(codec, decoderConfig))) {\n          return true;\n        }\n        if (decoderConfig.codec.startsWith(\"pcm-\")) {\n          return true;\n        } else {\n          if (typeof AudioDecoder === \"undefined\") {\n            return false;\n          }\n          const support = await AudioDecoder.isConfigSupported(decoderConfig);\n          return support.supported === true;\n        }\n      } catch (error) {\n        console.error(\"Error during decodability check:\", error);\n        return false;\n      }\n    }\n    async determinePacketType(packet) {\n      if (!(packet instanceof EncodedPacket)) {\n        throw new TypeError(\"packet must be an EncodedPacket.\");\n      }\n      if (this.codec === null) {\n        return null;\n      }\n      return \"key\";\n    }\n  };\n\n  // src/isobmff/isobmff-misc.ts\n  var buildIsobmffMimeType = (info) => {\n    const base = info.hasVideo ? \"video/\" : info.hasAudio ? \"audio/\" : \"application/\";\n    let string = base + (info.isQuickTime ? \"quicktime\" : \"mp4\");\n    if (info.codecStrings.length > 0) {\n      const uniqueCodecMimeTypes = [...new Set(info.codecStrings)];\n      string += `; codecs=\"${uniqueCodecMimeTypes.join(\", \")}\"`;\n    }\n    return string;\n  };\n\n  // src/isobmff/isobmff-reader.ts\n  var MIN_BOX_HEADER_SIZE = 8;\n  var MAX_BOX_HEADER_SIZE = 16;\n  var readBoxHeader = (slice) => {\n    let totalSize = readU32Be(slice);\n    const name = readAscii(slice, 4);\n    let headerSize = 8;\n    const hasLargeSize = totalSize === 1;\n    if (hasLargeSize) {\n      totalSize = readU64Be(slice);\n      headerSize = 16;\n    }\n    const contentSize = totalSize - headerSize;\n    if (contentSize < 0) {\n      return null;\n    }\n    return { name, totalSize, headerSize, contentSize };\n  };\n  var readFixed_16_16 = (slice) => {\n    return readI32Be(slice) / 65536;\n  };\n  var readFixed_2_30 = (slice) => {\n    return readI32Be(slice) / 1073741824;\n  };\n  var readIsomVariableInteger = (slice) => {\n    let result = 0;\n    for (let i = 0; i < 4; i++) {\n      result <<= 7;\n      const nextByte = readU8(slice);\n      result |= nextByte & 127;\n      if ((nextByte & 128) === 0) {\n        break;\n      }\n    }\n    return result;\n  };\n  var readMetadataStringShort = (slice) => {\n    let stringLength = readU16Be(slice);\n    slice.skip(2);\n    stringLength = Math.min(stringLength, slice.remainingLength);\n    return textDecoder.decode(readBytes(slice, stringLength));\n  };\n  var readDataBox = (slice) => {\n    const header = readBoxHeader(slice);\n    if (!header || header.name !== \"data\") {\n      return null;\n    }\n    if (slice.remainingLength < 8) {\n      return null;\n    }\n    const typeIndicator = readU32Be(slice);\n    slice.skip(4);\n    const data = readBytes(slice, header.contentSize - 8);\n    switch (typeIndicator) {\n      case 1:\n        return textDecoder.decode(data);\n      // UTF-8\n      case 2:\n        return new TextDecoder(\"utf-16be\").decode(data);\n      // UTF-16-BE\n      case 13:\n        return new RichImageData(data, \"image/jpeg\");\n      case 14:\n        return new RichImageData(data, \"image/png\");\n      case 27:\n        return new RichImageData(data, \"image/bmp\");\n      default:\n        return data;\n    }\n  };\n\n  // src/isobmff/isobmff-demuxer.ts\n  var IsobmffDemuxer = class extends Demuxer {\n    constructor(input) {\n      super(input);\n      this.moovSlice = null;\n      this.currentTrack = null;\n      this.tracks = [];\n      this.metadataPromise = null;\n      this.movieTimescale = -1;\n      this.movieDurationInTimescale = -1;\n      this.isQuickTime = false;\n      this.metadataTags = {};\n      this.currentMetadataKeys = null;\n      this.isFragmented = false;\n      this.fragmentTrackDefaults = [];\n      this.currentFragment = null;\n      /**\n       * Caches the last fragment that was read. Based on the assumption that there will be multiple reads to the\n       * same fragment in quick succession.\n       */\n      this.lastReadFragment = null;\n      this.reader = input._reader;\n    }\n    async computeDuration() {\n      const tracks = await this.getTracks();\n      const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));\n      return Math.max(0, ...trackDurations);\n    }\n    async getTracks() {\n      await this.readMetadata();\n      return this.tracks.map((track) => track.inputTrack);\n    }\n    async getMimeType() {\n      await this.readMetadata();\n      const codecStrings = await Promise.all(this.tracks.map((x) => x.inputTrack.getCodecParameterString()));\n      return buildIsobmffMimeType({\n        isQuickTime: this.isQuickTime,\n        hasVideo: this.tracks.some((x) => x.info?.type === \"video\"),\n        hasAudio: this.tracks.some((x) => x.info?.type === \"audio\"),\n        codecStrings: codecStrings.filter(Boolean)\n      });\n    }\n    async getMetadataTags() {\n      await this.readMetadata();\n      return this.metadataTags;\n    }\n    readMetadata() {\n      return this.metadataPromise ??= (async () => {\n        let currentPos = 0;\n        while (true) {\n          let slice = this.reader.requestSliceRange(currentPos, MIN_BOX_HEADER_SIZE, MAX_BOX_HEADER_SIZE);\n          if (slice instanceof Promise) slice = await slice;\n          if (!slice) break;\n          const startPos = currentPos;\n          const boxInfo = readBoxHeader(slice);\n          if (!boxInfo) {\n            break;\n          }\n          if (boxInfo.name === \"ftyp\") {\n            const majorBrand = readAscii(slice, 4);\n            this.isQuickTime = majorBrand === \"qt  \";\n          } else if (boxInfo.name === \"moov\") {\n            let moovSlice = this.reader.requestSlice(slice.filePos, boxInfo.contentSize);\n            if (moovSlice instanceof Promise) moovSlice = await moovSlice;\n            if (!moovSlice) break;\n            this.moovSlice = moovSlice;\n            this.readContiguousBoxes(this.moovSlice);\n            this.tracks.sort((a, b) => Number(b.disposition.default) - Number(a.disposition.default));\n            for (const track of this.tracks) {\n              const previousSegmentDurationsInSeconds = track.editListPreviousSegmentDurations / this.movieTimescale;\n              track.editListOffset -= Math.round(previousSegmentDurationsInSeconds * track.timescale);\n            }\n            break;\n          }\n          currentPos = startPos + boxInfo.totalSize;\n        }\n        if (this.isFragmented && this.reader.fileSize !== null) {\n          let lastWordSlice = this.reader.requestSlice(this.reader.fileSize - 4, 4);\n          if (lastWordSlice instanceof Promise) lastWordSlice = await lastWordSlice;\n          assert(lastWordSlice);\n          const lastWord = readU32Be(lastWordSlice);\n          const potentialMfraPos = this.reader.fileSize - lastWord;\n          if (potentialMfraPos >= 0 && potentialMfraPos <= this.reader.fileSize - MAX_BOX_HEADER_SIZE) {\n            let mfraHeaderSlice = this.reader.requestSliceRange(\n              potentialMfraPos,\n              MIN_BOX_HEADER_SIZE,\n              MAX_BOX_HEADER_SIZE\n            );\n            if (mfraHeaderSlice instanceof Promise) mfraHeaderSlice = await mfraHeaderSlice;\n            if (mfraHeaderSlice) {\n              const boxInfo = readBoxHeader(mfraHeaderSlice);\n              if (boxInfo && boxInfo.name === \"mfra\") {\n                let mfraSlice = this.reader.requestSlice(mfraHeaderSlice.filePos, boxInfo.contentSize);\n                if (mfraSlice instanceof Promise) mfraSlice = await mfraSlice;\n                if (mfraSlice) {\n                  this.readContiguousBoxes(mfraSlice);\n                }\n              }\n            }\n          }\n        }\n      })();\n    }\n    getSampleTableForTrack(internalTrack) {\n      if (internalTrack.sampleTable) {\n        return internalTrack.sampleTable;\n      }\n      const sampleTable = {\n        sampleTimingEntries: [],\n        sampleCompositionTimeOffsets: [],\n        sampleSizes: [],\n        keySampleIndices: null,\n        chunkOffsets: [],\n        sampleToChunk: [],\n        presentationTimestamps: null,\n        presentationTimestampIndexMap: null\n      };\n      internalTrack.sampleTable = sampleTable;\n      assert(this.moovSlice);\n      const stblContainerSlice = this.moovSlice.slice(internalTrack.sampleTableByteOffset);\n      this.currentTrack = internalTrack;\n      this.traverseBox(stblContainerSlice);\n      this.currentTrack = null;\n      const isPcmCodec = internalTrack.info?.type === \"audio\" && internalTrack.info.codec && PCM_AUDIO_CODECS.includes(internalTrack.info.codec);\n      if (isPcmCodec && sampleTable.sampleCompositionTimeOffsets.length === 0) {\n        assert(internalTrack.info?.type === \"audio\");\n        const pcmInfo = parsePcmCodec(internalTrack.info.codec);\n        const newSampleTimingEntries = [];\n        const newSampleSizes = [];\n        for (let i = 0; i < sampleTable.sampleToChunk.length; i++) {\n          const chunkEntry = sampleTable.sampleToChunk[i];\n          const nextEntry = sampleTable.sampleToChunk[i + 1];\n          const chunkCount = (nextEntry ? nextEntry.startChunkIndex : sampleTable.chunkOffsets.length) - chunkEntry.startChunkIndex;\n          for (let j = 0; j < chunkCount; j++) {\n            const startSampleIndex = chunkEntry.startSampleIndex + j * chunkEntry.samplesPerChunk;\n            const endSampleIndex = startSampleIndex + chunkEntry.samplesPerChunk;\n            const startTimingEntryIndex = binarySearchLessOrEqual(\n              sampleTable.sampleTimingEntries,\n              startSampleIndex,\n              (x) => x.startIndex\n            );\n            const startTimingEntry = sampleTable.sampleTimingEntries[startTimingEntryIndex];\n            const endTimingEntryIndex = binarySearchLessOrEqual(\n              sampleTable.sampleTimingEntries,\n              endSampleIndex,\n              (x) => x.startIndex\n            );\n            const endTimingEntry = sampleTable.sampleTimingEntries[endTimingEntryIndex];\n            const firstSampleTimestamp = startTimingEntry.startDecodeTimestamp + (startSampleIndex - startTimingEntry.startIndex) * startTimingEntry.delta;\n            const lastSampleTimestamp = endTimingEntry.startDecodeTimestamp + (endSampleIndex - endTimingEntry.startIndex) * endTimingEntry.delta;\n            const delta = lastSampleTimestamp - firstSampleTimestamp;\n            const lastSampleTimingEntry = last(newSampleTimingEntries);\n            if (lastSampleTimingEntry && lastSampleTimingEntry.delta === delta) {\n              lastSampleTimingEntry.count++;\n            } else {\n              newSampleTimingEntries.push({\n                startIndex: chunkEntry.startChunkIndex + j,\n                startDecodeTimestamp: firstSampleTimestamp,\n                count: 1,\n                delta\n              });\n            }\n            const chunkSize = chunkEntry.samplesPerChunk * pcmInfo.sampleSize * internalTrack.info.numberOfChannels;\n            newSampleSizes.push(chunkSize);\n          }\n          chunkEntry.startSampleIndex = chunkEntry.startChunkIndex;\n          chunkEntry.samplesPerChunk = 1;\n        }\n        sampleTable.sampleTimingEntries = newSampleTimingEntries;\n        sampleTable.sampleSizes = newSampleSizes;\n      }\n      if (sampleTable.sampleCompositionTimeOffsets.length > 0) {\n        sampleTable.presentationTimestamps = [];\n        for (const entry of sampleTable.sampleTimingEntries) {\n          for (let i = 0; i < entry.count; i++) {\n            sampleTable.presentationTimestamps.push({\n              presentationTimestamp: entry.startDecodeTimestamp + i * entry.delta,\n              sampleIndex: entry.startIndex + i\n            });\n          }\n        }\n        for (const entry of sampleTable.sampleCompositionTimeOffsets) {\n          for (let i = 0; i < entry.count; i++) {\n            const sampleIndex = entry.startIndex + i;\n            const sample = sampleTable.presentationTimestamps[sampleIndex];\n            if (!sample) {\n              continue;\n            }\n            sample.presentationTimestamp += entry.offset;\n          }\n        }\n        sampleTable.presentationTimestamps.sort((a, b) => a.presentationTimestamp - b.presentationTimestamp);\n        sampleTable.presentationTimestampIndexMap = Array(sampleTable.presentationTimestamps.length).fill(-1);\n        for (let i = 0; i < sampleTable.presentationTimestamps.length; i++) {\n          sampleTable.presentationTimestampIndexMap[sampleTable.presentationTimestamps[i].sampleIndex] = i;\n        }\n      } else {\n      }\n      return sampleTable;\n    }\n    async readFragment(startPos) {\n      if (this.lastReadFragment?.moofOffset === startPos) {\n        return this.lastReadFragment;\n      }\n      let headerSlice = this.reader.requestSliceRange(startPos, MIN_BOX_HEADER_SIZE, MAX_BOX_HEADER_SIZE);\n      if (headerSlice instanceof Promise) headerSlice = await headerSlice;\n      assert(headerSlice);\n      const moofBoxInfo = readBoxHeader(headerSlice);\n      assert(moofBoxInfo?.name === \"moof\");\n      let entireSlice = this.reader.requestSlice(startPos, moofBoxInfo.totalSize);\n      if (entireSlice instanceof Promise) entireSlice = await entireSlice;\n      assert(entireSlice);\n      this.traverseBox(entireSlice);\n      const fragment = this.lastReadFragment;\n      assert(fragment && fragment.moofOffset === startPos);\n      for (const [, trackData] of fragment.trackData) {\n        const track = trackData.track;\n        const { fragmentPositionCache } = track;\n        if (!trackData.startTimestampIsFinal) {\n          const lookupEntry = track.fragmentLookupTable.find((x) => x.moofOffset === fragment.moofOffset);\n          if (lookupEntry) {\n            offsetFragmentTrackDataByTimestamp(trackData, lookupEntry.timestamp);\n          } else {\n            const lastCacheIndex = binarySearchLessOrEqual(\n              fragmentPositionCache,\n              fragment.moofOffset - 1,\n              (x) => x.moofOffset\n            );\n            if (lastCacheIndex !== -1) {\n              const lastCache = fragmentPositionCache[lastCacheIndex];\n              offsetFragmentTrackDataByTimestamp(trackData, lastCache.endTimestamp);\n            } else {\n            }\n          }\n          trackData.startTimestampIsFinal = true;\n        }\n        const insertionIndex = binarySearchLessOrEqual(\n          fragmentPositionCache,\n          trackData.startTimestamp,\n          (x) => x.startTimestamp\n        );\n        if (insertionIndex === -1 || fragmentPositionCache[insertionIndex].moofOffset !== fragment.moofOffset) {\n          fragmentPositionCache.splice(insertionIndex + 1, 0, {\n            moofOffset: fragment.moofOffset,\n            startTimestamp: trackData.startTimestamp,\n            endTimestamp: trackData.endTimestamp\n          });\n        }\n      }\n      return fragment;\n    }\n    readContiguousBoxes(slice) {\n      const startIndex = slice.filePos;\n      while (slice.filePos - startIndex <= slice.length - MIN_BOX_HEADER_SIZE) {\n        const foundBox = this.traverseBox(slice);\n        if (!foundBox) {\n          break;\n        }\n      }\n    }\n    // eslint-disable-next-line @stylistic/generator-star-spacing\n    *iterateContiguousBoxes(slice) {\n      const startIndex = slice.filePos;\n      while (slice.filePos - startIndex <= slice.length - MIN_BOX_HEADER_SIZE) {\n        const startPos = slice.filePos;\n        const boxInfo = readBoxHeader(slice);\n        if (!boxInfo) {\n          break;\n        }\n        yield { boxInfo, slice };\n        slice.filePos = startPos + boxInfo.totalSize;\n      }\n    }\n    traverseBox(slice) {\n      const startPos = slice.filePos;\n      const boxInfo = readBoxHeader(slice);\n      if (!boxInfo) {\n        return false;\n      }\n      const contentStartPos = slice.filePos;\n      const boxEndPos = startPos + boxInfo.totalSize;\n      switch (boxInfo.name) {\n        case \"mdia\":\n        case \"minf\":\n        case \"dinf\":\n        case \"mfra\":\n        case \"edts\":\n          {\n            this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n          }\n          ;\n          break;\n        case \"mvhd\":\n          {\n            const version = readU8(slice);\n            slice.skip(3);\n            if (version === 1) {\n              slice.skip(8 + 8);\n              this.movieTimescale = readU32Be(slice);\n              this.movieDurationInTimescale = readU64Be(slice);\n            } else {\n              slice.skip(4 + 4);\n              this.movieTimescale = readU32Be(slice);\n              this.movieDurationInTimescale = readU32Be(slice);\n            }\n          }\n          ;\n          break;\n        case \"trak\":\n          {\n            const track = {\n              id: -1,\n              demuxer: this,\n              inputTrack: null,\n              disposition: {\n                ...DEFAULT_TRACK_DISPOSITION\n              },\n              info: null,\n              timescale: -1,\n              durationInMovieTimescale: -1,\n              durationInMediaTimescale: -1,\n              rotation: 0,\n              internalCodecId: null,\n              name: null,\n              languageCode: UNDETERMINED_LANGUAGE,\n              sampleTableByteOffset: -1,\n              sampleTable: null,\n              fragmentLookupTable: [],\n              currentFragmentState: null,\n              fragmentPositionCache: [],\n              editListPreviousSegmentDurations: 0,\n              editListOffset: 0\n            };\n            this.currentTrack = track;\n            this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n            if (track.id !== -1 && track.timescale !== -1 && track.info !== null) {\n              if (track.info.type === \"video\" && track.info.width !== -1) {\n                const videoTrack = track;\n                track.inputTrack = new InputVideoTrack(this.input, new IsobmffVideoTrackBacking(videoTrack));\n                this.tracks.push(track);\n              } else if (track.info.type === \"audio\" && track.info.numberOfChannels !== -1) {\n                const audioTrack = track;\n                track.inputTrack = new InputAudioTrack(this.input, new IsobmffAudioTrackBacking(audioTrack));\n                this.tracks.push(track);\n              }\n            }\n            this.currentTrack = null;\n          }\n          ;\n          break;\n        case \"tkhd\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            const version = readU8(slice);\n            const flags = readU24Be(slice);\n            const trackEnabled = !!(flags & 1);\n            track.disposition.default = trackEnabled;\n            if (version === 0) {\n              slice.skip(8);\n              track.id = readU32Be(slice);\n              slice.skip(4);\n              track.durationInMovieTimescale = readU32Be(slice);\n            } else if (version === 1) {\n              slice.skip(16);\n              track.id = readU32Be(slice);\n              slice.skip(4);\n              track.durationInMovieTimescale = readU64Be(slice);\n            } else {\n              throw new Error(`Incorrect track header version ${version}.`);\n            }\n            slice.skip(2 * 4 + 2 + 2 + 2 + 2);\n            const matrix = [\n              readFixed_16_16(slice),\n              readFixed_16_16(slice),\n              readFixed_2_30(slice),\n              readFixed_16_16(slice),\n              readFixed_16_16(slice),\n              readFixed_2_30(slice),\n              readFixed_16_16(slice),\n              readFixed_16_16(slice),\n              readFixed_2_30(slice)\n            ];\n            const rotation = normalizeRotation(roundToMultiple(extractRotationFromMatrix(matrix), 90));\n            assert(rotation === 0 || rotation === 90 || rotation === 180 || rotation === 270);\n            track.rotation = rotation;\n          }\n          ;\n          break;\n        case \"elst\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            const version = readU8(slice);\n            slice.skip(3);\n            let relevantEntryFound = false;\n            let previousSegmentDurations = 0;\n            const entryCount = readU32Be(slice);\n            for (let i = 0; i < entryCount; i++) {\n              const segmentDuration = version === 1 ? readU64Be(slice) : readU32Be(slice);\n              const mediaTime = version === 1 ? readI64Be(slice) : readI32Be(slice);\n              const mediaRate = readFixed_16_16(slice);\n              if (segmentDuration === 0) {\n                continue;\n              }\n              if (relevantEntryFound) {\n                console.warn(\n                  \"Unsupported edit list: multiple edits are not currently supported. Only using first edit.\"\n                );\n                break;\n              }\n              if (mediaTime === -1) {\n                previousSegmentDurations += segmentDuration;\n                continue;\n              }\n              if (mediaRate !== 1) {\n                console.warn(\"Unsupported edit list entry: media rate must be 1.\");\n                break;\n              }\n              track.editListPreviousSegmentDurations = previousSegmentDurations;\n              track.editListOffset = mediaTime;\n              relevantEntryFound = true;\n            }\n          }\n          ;\n          break;\n        case \"mdhd\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            const version = readU8(slice);\n            slice.skip(3);\n            if (version === 0) {\n              slice.skip(8);\n              track.timescale = readU32Be(slice);\n              track.durationInMediaTimescale = readU32Be(slice);\n            } else if (version === 1) {\n              slice.skip(16);\n              track.timescale = readU32Be(slice);\n              track.durationInMediaTimescale = readU64Be(slice);\n            }\n            let language = readU16Be(slice);\n            if (language > 0) {\n              track.languageCode = \"\";\n              for (let i = 0; i < 3; i++) {\n                track.languageCode = String.fromCharCode(96 + (language & 31)) + track.languageCode;\n                language >>= 5;\n              }\n              if (!isIso639Dash2LanguageCode(track.languageCode)) {\n                track.languageCode = UNDETERMINED_LANGUAGE;\n              }\n            }\n          }\n          ;\n          break;\n        case \"hdlr\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            slice.skip(8);\n            const handlerType = readAscii(slice, 4);\n            if (handlerType === \"vide\") {\n              track.info = {\n                type: \"video\",\n                width: -1,\n                height: -1,\n                codec: null,\n                codecDescription: null,\n                colorSpace: null,\n                avcType: null,\n                avcCodecInfo: null,\n                hevcCodecInfo: null,\n                vp9CodecInfo: null,\n                av1CodecInfo: null\n              };\n            } else if (handlerType === \"soun\") {\n              track.info = {\n                type: \"audio\",\n                numberOfChannels: -1,\n                sampleRate: -1,\n                codec: null,\n                codecDescription: null,\n                aacCodecInfo: null\n              };\n            }\n          }\n          ;\n          break;\n        case \"stbl\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            track.sampleTableByteOffset = startPos;\n            this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n          }\n          ;\n          break;\n        case \"stsd\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            if (track.info === null || track.sampleTable) {\n              break;\n            }\n            const stsdVersion = readU8(slice);\n            slice.skip(3);\n            const entries = readU32Be(slice);\n            for (let i = 0; i < entries; i++) {\n              const sampleBoxStartPos = slice.filePos;\n              const sampleBoxInfo = readBoxHeader(slice);\n              if (!sampleBoxInfo) {\n                break;\n              }\n              track.internalCodecId = sampleBoxInfo.name;\n              const lowercaseBoxName = sampleBoxInfo.name.toLowerCase();\n              if (track.info.type === \"video\") {\n                if (lowercaseBoxName === \"avc1\" || lowercaseBoxName === \"avc3\") {\n                  track.info.codec = \"avc\";\n                  track.info.avcType = lowercaseBoxName === \"avc1\" ? 1 : 3;\n                } else if (lowercaseBoxName === \"hvc1\" || lowercaseBoxName === \"hev1\") {\n                  track.info.codec = \"hevc\";\n                } else if (lowercaseBoxName === \"vp08\") {\n                  track.info.codec = \"vp8\";\n                } else if (lowercaseBoxName === \"vp09\") {\n                  track.info.codec = \"vp9\";\n                } else if (lowercaseBoxName === \"av01\") {\n                  track.info.codec = \"av1\";\n                } else {\n                  console.warn(`Unsupported video codec (sample entry type '${sampleBoxInfo.name}').`);\n                }\n                slice.skip(6 * 1 + 2 + 2 + 2 + 3 * 4);\n                track.info.width = readU16Be(slice);\n                track.info.height = readU16Be(slice);\n                slice.skip(4 + 4 + 4 + 2 + 32 + 2 + 2);\n                this.readContiguousBoxes(\n                  slice.slice(\n                    slice.filePos,\n                    sampleBoxStartPos + sampleBoxInfo.totalSize - slice.filePos\n                  )\n                );\n              } else {\n                if (lowercaseBoxName === \"mp4a\") {\n                } else if (lowercaseBoxName === \"opus\") {\n                  track.info.codec = \"opus\";\n                } else if (lowercaseBoxName === \"flac\") {\n                  track.info.codec = \"flac\";\n                } else if (lowercaseBoxName === \"twos\" || lowercaseBoxName === \"sowt\" || lowercaseBoxName === \"raw \" || lowercaseBoxName === \"in24\" || lowercaseBoxName === \"in32\" || lowercaseBoxName === \"fl32\" || lowercaseBoxName === \"fl64\" || lowercaseBoxName === \"lpcm\" || lowercaseBoxName === \"ipcm\" || lowercaseBoxName === \"fpcm\") {\n                } else if (lowercaseBoxName === \"ulaw\") {\n                  track.info.codec = \"ulaw\";\n                } else if (lowercaseBoxName === \"alaw\") {\n                  track.info.codec = \"alaw\";\n                } else {\n                  console.warn(`Unsupported audio codec (sample entry type '${sampleBoxInfo.name}').`);\n                }\n                slice.skip(6 * 1 + 2);\n                const version = readU16Be(slice);\n                slice.skip(3 * 2);\n                let channelCount = readU16Be(slice);\n                let sampleSize = readU16Be(slice);\n                slice.skip(2 * 2);\n                let sampleRate = readU32Be(slice) / 65536;\n                if (stsdVersion === 0 && version > 0) {\n                  if (version === 1) {\n                    slice.skip(4);\n                    sampleSize = 8 * readU32Be(slice);\n                    slice.skip(2 * 4);\n                  } else if (version === 2) {\n                    slice.skip(4);\n                    sampleRate = readF64Be(slice);\n                    channelCount = readU32Be(slice);\n                    slice.skip(4);\n                    sampleSize = readU32Be(slice);\n                    const flags = readU32Be(slice);\n                    slice.skip(2 * 4);\n                    if (lowercaseBoxName === \"lpcm\") {\n                      const bytesPerSample = sampleSize + 7 >> 3;\n                      const isFloat = Boolean(flags & 1);\n                      const isBigEndian = Boolean(flags & 2);\n                      const sFlags = flags & 4 ? -1 : 0;\n                      if (sampleSize > 0 && sampleSize <= 64) {\n                        if (isFloat) {\n                          if (sampleSize === 32) {\n                            track.info.codec = isBigEndian ? \"pcm-f32be\" : \"pcm-f32\";\n                          }\n                        } else {\n                          if (sFlags & 1 << bytesPerSample - 1) {\n                            if (bytesPerSample === 1) {\n                              track.info.codec = \"pcm-s8\";\n                            } else if (bytesPerSample === 2) {\n                              track.info.codec = isBigEndian ? \"pcm-s16be\" : \"pcm-s16\";\n                            } else if (bytesPerSample === 3) {\n                              track.info.codec = isBigEndian ? \"pcm-s24be\" : \"pcm-s24\";\n                            } else if (bytesPerSample === 4) {\n                              track.info.codec = isBigEndian ? \"pcm-s32be\" : \"pcm-s32\";\n                            }\n                          } else {\n                            if (bytesPerSample === 1) {\n                              track.info.codec = \"pcm-u8\";\n                            }\n                          }\n                        }\n                      }\n                      if (track.info.codec === null) {\n                        console.warn(\"Unsupported PCM format.\");\n                      }\n                    }\n                  }\n                }\n                if (track.info.codec === \"opus\") {\n                  sampleRate = OPUS_SAMPLE_RATE;\n                }\n                track.info.numberOfChannels = channelCount;\n                track.info.sampleRate = sampleRate;\n                if (lowercaseBoxName === \"twos\") {\n                  if (sampleSize === 8) {\n                    track.info.codec = \"pcm-s8\";\n                  } else if (sampleSize === 16) {\n                    track.info.codec = \"pcm-s16be\";\n                  } else {\n                    console.warn(`Unsupported sample size ${sampleSize} for codec 'twos'.`);\n                    track.info.codec = null;\n                  }\n                } else if (lowercaseBoxName === \"sowt\") {\n                  if (sampleSize === 8) {\n                    track.info.codec = \"pcm-s8\";\n                  } else if (sampleSize === 16) {\n                    track.info.codec = \"pcm-s16\";\n                  } else {\n                    console.warn(`Unsupported sample size ${sampleSize} for codec 'sowt'.`);\n                    track.info.codec = null;\n                  }\n                } else if (lowercaseBoxName === \"raw \") {\n                  track.info.codec = \"pcm-u8\";\n                } else if (lowercaseBoxName === \"in24\") {\n                  track.info.codec = \"pcm-s24be\";\n                } else if (lowercaseBoxName === \"in32\") {\n                  track.info.codec = \"pcm-s32be\";\n                } else if (lowercaseBoxName === \"fl32\") {\n                  track.info.codec = \"pcm-f32be\";\n                } else if (lowercaseBoxName === \"fl64\") {\n                  track.info.codec = \"pcm-f64be\";\n                } else if (lowercaseBoxName === \"ipcm\") {\n                  track.info.codec = \"pcm-s16be\";\n                } else if (lowercaseBoxName === \"fpcm\") {\n                  track.info.codec = \"pcm-f32be\";\n                }\n                this.readContiguousBoxes(\n                  slice.slice(\n                    slice.filePos,\n                    sampleBoxStartPos + sampleBoxInfo.totalSize - slice.filePos\n                  )\n                );\n              }\n            }\n          }\n          ;\n          break;\n        case \"avcC\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.info);\n            track.info.codecDescription = readBytes(slice, boxInfo.contentSize);\n          }\n          ;\n          break;\n        case \"hvcC\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.info);\n            track.info.codecDescription = readBytes(slice, boxInfo.contentSize);\n          }\n          ;\n          break;\n        case \"vpcC\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.info?.type === \"video\");\n            slice.skip(4);\n            const profile = readU8(slice);\n            const level = readU8(slice);\n            const thirdByte = readU8(slice);\n            const bitDepth = thirdByte >> 4;\n            const chromaSubsampling = thirdByte >> 1 & 7;\n            const videoFullRangeFlag = thirdByte & 1;\n            const colourPrimaries = readU8(slice);\n            const transferCharacteristics = readU8(slice);\n            const matrixCoefficients = readU8(slice);\n            track.info.vp9CodecInfo = {\n              profile,\n              level,\n              bitDepth,\n              chromaSubsampling,\n              videoFullRangeFlag,\n              colourPrimaries,\n              transferCharacteristics,\n              matrixCoefficients\n            };\n          }\n          ;\n          break;\n        case \"av1C\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.info?.type === \"video\");\n            slice.skip(1);\n            const secondByte = readU8(slice);\n            const profile = secondByte >> 5;\n            const level = secondByte & 31;\n            const thirdByte = readU8(slice);\n            const tier = thirdByte >> 7;\n            const highBitDepth = thirdByte >> 6 & 1;\n            const twelveBit = thirdByte >> 5 & 1;\n            const monochrome = thirdByte >> 4 & 1;\n            const chromaSubsamplingX = thirdByte >> 3 & 1;\n            const chromaSubsamplingY = thirdByte >> 2 & 1;\n            const chromaSamplePosition = thirdByte & 3;\n            const bitDepth = profile === 2 && highBitDepth ? twelveBit ? 12 : 10 : highBitDepth ? 10 : 8;\n            track.info.av1CodecInfo = {\n              profile,\n              level,\n              tier,\n              bitDepth,\n              monochrome,\n              chromaSubsamplingX,\n              chromaSubsamplingY,\n              chromaSamplePosition\n            };\n          }\n          ;\n          break;\n        case \"colr\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.info?.type === \"video\");\n            const colourType = readAscii(slice, 4);\n            if (colourType !== \"nclx\") {\n              break;\n            }\n            const colourPrimaries = readU16Be(slice);\n            const transferCharacteristics = readU16Be(slice);\n            const matrixCoefficients = readU16Be(slice);\n            const fullRangeFlag = Boolean(readU8(slice) & 128);\n            track.info.colorSpace = {\n              primaries: COLOR_PRIMARIES_MAP_INVERSE[colourPrimaries],\n              transfer: TRANSFER_CHARACTERISTICS_MAP_INVERSE[transferCharacteristics],\n              matrix: MATRIX_COEFFICIENTS_MAP_INVERSE[matrixCoefficients],\n              fullRange: fullRangeFlag\n            };\n          }\n          ;\n          break;\n        case \"wave\":\n          {\n            this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n          }\n          ;\n          break;\n        case \"esds\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.info?.type === \"audio\");\n            slice.skip(4);\n            const tag = readU8(slice);\n            assert(tag === 3);\n            readIsomVariableInteger(slice);\n            slice.skip(2);\n            const mixed = readU8(slice);\n            const streamDependenceFlag = (mixed & 128) !== 0;\n            const urlFlag = (mixed & 64) !== 0;\n            const ocrStreamFlag = (mixed & 32) !== 0;\n            if (streamDependenceFlag) {\n              slice.skip(2);\n            }\n            if (urlFlag) {\n              const urlLength = readU8(slice);\n              slice.skip(urlLength);\n            }\n            if (ocrStreamFlag) {\n              slice.skip(2);\n            }\n            const decoderConfigTag = readU8(slice);\n            assert(decoderConfigTag === 4);\n            const decoderConfigDescriptorLength = readIsomVariableInteger(slice);\n            const payloadStart = slice.filePos;\n            const objectTypeIndication = readU8(slice);\n            if (objectTypeIndication === 64 || objectTypeIndication === 103) {\n              track.info.codec = \"aac\";\n              track.info.aacCodecInfo = {\n                isMpeg2: objectTypeIndication === 103,\n                objectType: null\n              };\n            } else if (objectTypeIndication === 105 || objectTypeIndication === 107) {\n              track.info.codec = \"mp3\";\n            } else if (objectTypeIndication === 221) {\n              track.info.codec = \"vorbis\";\n            } else {\n              console.warn(\n                `Unsupported audio codec (objectTypeIndication ${objectTypeIndication}) - discarding track.`\n              );\n            }\n            slice.skip(1 + 3 + 4 + 4);\n            if (decoderConfigDescriptorLength > slice.filePos - payloadStart) {\n              const decoderSpecificInfoTag = readU8(slice);\n              assert(decoderSpecificInfoTag === 5);\n              const decoderSpecificInfoLength = readIsomVariableInteger(slice);\n              track.info.codecDescription = readBytes(slice, decoderSpecificInfoLength);\n              if (track.info.codec === \"aac\") {\n                const audioSpecificConfig = parseAacAudioSpecificConfig(track.info.codecDescription);\n                if (audioSpecificConfig.numberOfChannels !== null) {\n                  track.info.numberOfChannels = audioSpecificConfig.numberOfChannels;\n                }\n                if (audioSpecificConfig.sampleRate !== null) {\n                  track.info.sampleRate = audioSpecificConfig.sampleRate;\n                }\n              }\n            }\n          }\n          ;\n          break;\n        case \"enda\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.info?.type === \"audio\");\n            const littleEndian = readU16Be(slice) & 255;\n            if (littleEndian) {\n              if (track.info.codec === \"pcm-s16be\") {\n                track.info.codec = \"pcm-s16\";\n              } else if (track.info.codec === \"pcm-s24be\") {\n                track.info.codec = \"pcm-s24\";\n              } else if (track.info.codec === \"pcm-s32be\") {\n                track.info.codec = \"pcm-s32\";\n              } else if (track.info.codec === \"pcm-f32be\") {\n                track.info.codec = \"pcm-f32\";\n              } else if (track.info.codec === \"pcm-f64be\") {\n                track.info.codec = \"pcm-f64\";\n              }\n            }\n          }\n          ;\n          break;\n        case \"pcmC\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.info?.type === \"audio\");\n            slice.skip(1 + 3);\n            const formatFlags = readU8(slice);\n            const isLittleEndian = Boolean(formatFlags & 1);\n            const pcmSampleSize = readU8(slice);\n            if (track.info.codec === \"pcm-s16be\") {\n              if (isLittleEndian) {\n                if (pcmSampleSize === 16) {\n                  track.info.codec = \"pcm-s16\";\n                } else if (pcmSampleSize === 24) {\n                  track.info.codec = \"pcm-s24\";\n                } else if (pcmSampleSize === 32) {\n                  track.info.codec = \"pcm-s32\";\n                } else {\n                  console.warn(`Invalid ipcm sample size ${pcmSampleSize}.`);\n                  track.info.codec = null;\n                }\n              } else {\n                if (pcmSampleSize === 16) {\n                  track.info.codec = \"pcm-s16be\";\n                } else if (pcmSampleSize === 24) {\n                  track.info.codec = \"pcm-s24be\";\n                } else if (pcmSampleSize === 32) {\n                  track.info.codec = \"pcm-s32be\";\n                } else {\n                  console.warn(`Invalid ipcm sample size ${pcmSampleSize}.`);\n                  track.info.codec = null;\n                }\n              }\n            } else if (track.info.codec === \"pcm-f32be\") {\n              if (isLittleEndian) {\n                if (pcmSampleSize === 32) {\n                  track.info.codec = \"pcm-f32\";\n                } else if (pcmSampleSize === 64) {\n                  track.info.codec = \"pcm-f64\";\n                } else {\n                  console.warn(`Invalid fpcm sample size ${pcmSampleSize}.`);\n                  track.info.codec = null;\n                }\n              } else {\n                if (pcmSampleSize === 32) {\n                  track.info.codec = \"pcm-f32be\";\n                } else if (pcmSampleSize === 64) {\n                  track.info.codec = \"pcm-f64be\";\n                } else {\n                  console.warn(`Invalid fpcm sample size ${pcmSampleSize}.`);\n                  track.info.codec = null;\n                }\n              }\n            }\n            break;\n          }\n          ;\n        case \"dOps\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.info?.type === \"audio\");\n            slice.skip(1);\n            const outputChannelCount = readU8(slice);\n            const preSkip = readU16Be(slice);\n            const inputSampleRate = readU32Be(slice);\n            const outputGain = readI16Be(slice);\n            const channelMappingFamily = readU8(slice);\n            let channelMappingTable;\n            if (channelMappingFamily !== 0) {\n              channelMappingTable = readBytes(slice, 2 + outputChannelCount);\n            } else {\n              channelMappingTable = new Uint8Array(0);\n            }\n            const description = new Uint8Array(8 + 1 + 1 + 2 + 4 + 2 + 1 + channelMappingTable.byteLength);\n            const view2 = new DataView(description.buffer);\n            view2.setUint32(0, 1332770163, false);\n            view2.setUint32(4, 1214603620, false);\n            view2.setUint8(8, 1);\n            view2.setUint8(9, outputChannelCount);\n            view2.setUint16(10, preSkip, true);\n            view2.setUint32(12, inputSampleRate, true);\n            view2.setInt16(16, outputGain, true);\n            view2.setUint8(18, channelMappingFamily);\n            description.set(channelMappingTable, 19);\n            track.info.codecDescription = description;\n            track.info.numberOfChannels = outputChannelCount;\n          }\n          ;\n          break;\n        case \"dfLa\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.info?.type === \"audio\");\n            slice.skip(4);\n            const BLOCK_TYPE_MASK = 127;\n            const LAST_METADATA_BLOCK_FLAG_MASK = 128;\n            const startPos2 = slice.filePos;\n            while (slice.filePos < boxEndPos) {\n              const flagAndType = readU8(slice);\n              const metadataBlockLength = readU24Be(slice);\n              const type = flagAndType & BLOCK_TYPE_MASK;\n              if (type === 0 /* STREAMINFO */) {\n                slice.skip(10);\n                const word = readU32Be(slice);\n                const sampleRate = word >>> 12;\n                const numberOfChannels = (word >> 9 & 7) + 1;\n                track.info.sampleRate = sampleRate;\n                track.info.numberOfChannels = numberOfChannels;\n                slice.skip(20);\n              } else {\n                slice.skip(metadataBlockLength);\n              }\n              if (flagAndType & LAST_METADATA_BLOCK_FLAG_MASK) {\n                break;\n              }\n            }\n            const endPos = slice.filePos;\n            slice.filePos = startPos2;\n            const bytes2 = readBytes(slice, endPos - startPos2);\n            const description = new Uint8Array(4 + bytes2.byteLength);\n            const view2 = new DataView(description.buffer);\n            view2.setUint32(0, 1716281667, false);\n            description.set(bytes2, 4);\n            track.info.codecDescription = description;\n          }\n          ;\n          break;\n        case \"stts\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            if (!track.sampleTable) {\n              break;\n            }\n            slice.skip(4);\n            const entryCount = readU32Be(slice);\n            let currentIndex = 0;\n            let currentTimestamp = 0;\n            for (let i = 0; i < entryCount; i++) {\n              const sampleCount = readU32Be(slice);\n              const sampleDelta = readU32Be(slice);\n              track.sampleTable.sampleTimingEntries.push({\n                startIndex: currentIndex,\n                startDecodeTimestamp: currentTimestamp,\n                count: sampleCount,\n                delta: sampleDelta\n              });\n              currentIndex += sampleCount;\n              currentTimestamp += sampleCount * sampleDelta;\n            }\n          }\n          ;\n          break;\n        case \"ctts\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            if (!track.sampleTable) {\n              break;\n            }\n            slice.skip(1 + 3);\n            const entryCount = readU32Be(slice);\n            let sampleIndex = 0;\n            for (let i = 0; i < entryCount; i++) {\n              const sampleCount = readU32Be(slice);\n              const sampleOffset = readI32Be(slice);\n              track.sampleTable.sampleCompositionTimeOffsets.push({\n                startIndex: sampleIndex,\n                count: sampleCount,\n                offset: sampleOffset\n              });\n              sampleIndex += sampleCount;\n            }\n          }\n          ;\n          break;\n        case \"stsz\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            if (!track.sampleTable) {\n              break;\n            }\n            slice.skip(4);\n            const sampleSize = readU32Be(slice);\n            const sampleCount = readU32Be(slice);\n            if (sampleSize === 0) {\n              for (let i = 0; i < sampleCount; i++) {\n                const sampleSize2 = readU32Be(slice);\n                track.sampleTable.sampleSizes.push(sampleSize2);\n              }\n            } else {\n              track.sampleTable.sampleSizes.push(sampleSize);\n            }\n          }\n          ;\n          break;\n        case \"stz2\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            if (!track.sampleTable) {\n              break;\n            }\n            slice.skip(4);\n            slice.skip(3);\n            const fieldSize = readU8(slice);\n            const sampleCount = readU32Be(slice);\n            const bytes2 = readBytes(slice, Math.ceil(sampleCount * fieldSize / 8));\n            const bitstream = new Bitstream(bytes2);\n            for (let i = 0; i < sampleCount; i++) {\n              const sampleSize = bitstream.readBits(fieldSize);\n              track.sampleTable.sampleSizes.push(sampleSize);\n            }\n          }\n          ;\n          break;\n        case \"stss\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            if (!track.sampleTable) {\n              break;\n            }\n            slice.skip(4);\n            track.sampleTable.keySampleIndices = [];\n            const entryCount = readU32Be(slice);\n            for (let i = 0; i < entryCount; i++) {\n              const sampleIndex = readU32Be(slice) - 1;\n              track.sampleTable.keySampleIndices.push(sampleIndex);\n            }\n            if (track.sampleTable.keySampleIndices[0] !== 0) {\n              track.sampleTable.keySampleIndices.unshift(0);\n            }\n          }\n          ;\n          break;\n        case \"stsc\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            if (!track.sampleTable) {\n              break;\n            }\n            slice.skip(4);\n            const entryCount = readU32Be(slice);\n            for (let i = 0; i < entryCount; i++) {\n              const startChunkIndex = readU32Be(slice) - 1;\n              const samplesPerChunk = readU32Be(slice);\n              const sampleDescriptionIndex = readU32Be(slice);\n              track.sampleTable.sampleToChunk.push({\n                startSampleIndex: -1,\n                startChunkIndex,\n                samplesPerChunk,\n                sampleDescriptionIndex\n              });\n            }\n            let startSampleIndex = 0;\n            for (let i = 0; i < track.sampleTable.sampleToChunk.length; i++) {\n              track.sampleTable.sampleToChunk[i].startSampleIndex = startSampleIndex;\n              if (i < track.sampleTable.sampleToChunk.length - 1) {\n                const nextChunk = track.sampleTable.sampleToChunk[i + 1];\n                const chunkCount = nextChunk.startChunkIndex - track.sampleTable.sampleToChunk[i].startChunkIndex;\n                startSampleIndex += chunkCount * track.sampleTable.sampleToChunk[i].samplesPerChunk;\n              }\n            }\n          }\n          ;\n          break;\n        case \"stco\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            if (!track.sampleTable) {\n              break;\n            }\n            slice.skip(4);\n            const entryCount = readU32Be(slice);\n            for (let i = 0; i < entryCount; i++) {\n              const chunkOffset = readU32Be(slice);\n              track.sampleTable.chunkOffsets.push(chunkOffset);\n            }\n          }\n          ;\n          break;\n        case \"co64\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            if (!track.sampleTable) {\n              break;\n            }\n            slice.skip(4);\n            const entryCount = readU32Be(slice);\n            for (let i = 0; i < entryCount; i++) {\n              const chunkOffset = readU64Be(slice);\n              track.sampleTable.chunkOffsets.push(chunkOffset);\n            }\n          }\n          ;\n          break;\n        case \"mvex\":\n          {\n            this.isFragmented = true;\n            this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n          }\n          ;\n          break;\n        case \"mehd\":\n          {\n            const version = readU8(slice);\n            slice.skip(3);\n            const fragmentDuration = version === 1 ? readU64Be(slice) : readU32Be(slice);\n            this.movieDurationInTimescale = fragmentDuration;\n          }\n          ;\n          break;\n        case \"trex\":\n          {\n            slice.skip(4);\n            const trackId = readU32Be(slice);\n            const defaultSampleDescriptionIndex = readU32Be(slice);\n            const defaultSampleDuration = readU32Be(slice);\n            const defaultSampleSize = readU32Be(slice);\n            const defaultSampleFlags = readU32Be(slice);\n            this.fragmentTrackDefaults.push({\n              trackId,\n              defaultSampleDescriptionIndex,\n              defaultSampleDuration,\n              defaultSampleSize,\n              defaultSampleFlags\n            });\n          }\n          ;\n          break;\n        case \"tfra\":\n          {\n            const version = readU8(slice);\n            slice.skip(3);\n            const trackId = readU32Be(slice);\n            const track = this.tracks.find((x) => x.id === trackId);\n            if (!track) {\n              break;\n            }\n            const word = readU32Be(slice);\n            const lengthSizeOfTrafNum = (word & 48) >> 4;\n            const lengthSizeOfTrunNum = (word & 12) >> 2;\n            const lengthSizeOfSampleNum = word & 3;\n            const functions = [readU8, readU16Be, readU24Be, readU32Be];\n            const readTrafNum = functions[lengthSizeOfTrafNum];\n            const readTrunNum = functions[lengthSizeOfTrunNum];\n            const readSampleNum = functions[lengthSizeOfSampleNum];\n            const numberOfEntries = readU32Be(slice);\n            for (let i = 0; i < numberOfEntries; i++) {\n              const time = version === 1 ? readU64Be(slice) : readU32Be(slice);\n              const moofOffset = version === 1 ? readU64Be(slice) : readU32Be(slice);\n              readTrafNum(slice);\n              readTrunNum(slice);\n              readSampleNum(slice);\n              track.fragmentLookupTable.push({\n                timestamp: time,\n                moofOffset\n              });\n            }\n            track.fragmentLookupTable.sort((a, b) => a.timestamp - b.timestamp);\n            for (let i = 0; i < track.fragmentLookupTable.length - 1; i++) {\n              const entry1 = track.fragmentLookupTable[i];\n              const entry2 = track.fragmentLookupTable[i + 1];\n              if (entry1.timestamp === entry2.timestamp) {\n                track.fragmentLookupTable.splice(i + 1, 1);\n                i--;\n              }\n            }\n          }\n          ;\n          break;\n        case \"moof\":\n          {\n            this.currentFragment = {\n              moofOffset: startPos,\n              moofSize: boxInfo.totalSize,\n              implicitBaseDataOffset: startPos,\n              trackData: /* @__PURE__ */ new Map()\n            };\n            this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n            this.lastReadFragment = this.currentFragment;\n            this.currentFragment = null;\n          }\n          ;\n          break;\n        case \"traf\":\n          {\n            assert(this.currentFragment);\n            this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n            if (this.currentTrack) {\n              const trackData = this.currentFragment.trackData.get(this.currentTrack.id);\n              if (trackData) {\n                const { currentFragmentState } = this.currentTrack;\n                assert(currentFragmentState);\n                if (currentFragmentState.startTimestamp !== null) {\n                  offsetFragmentTrackDataByTimestamp(trackData, currentFragmentState.startTimestamp);\n                  trackData.startTimestampIsFinal = true;\n                }\n              }\n              this.currentTrack.currentFragmentState = null;\n              this.currentTrack = null;\n            }\n          }\n          ;\n          break;\n        case \"tfhd\":\n          {\n            assert(this.currentFragment);\n            slice.skip(1);\n            const flags = readU24Be(slice);\n            const baseDataOffsetPresent = Boolean(flags & 1);\n            const sampleDescriptionIndexPresent = Boolean(flags & 2);\n            const defaultSampleDurationPresent = Boolean(flags & 8);\n            const defaultSampleSizePresent = Boolean(flags & 16);\n            const defaultSampleFlagsPresent = Boolean(flags & 32);\n            const durationIsEmpty = Boolean(flags & 65536);\n            const defaultBaseIsMoof = Boolean(flags & 131072);\n            const trackId = readU32Be(slice);\n            const track = this.tracks.find((x) => x.id === trackId);\n            if (!track) {\n              break;\n            }\n            const defaults = this.fragmentTrackDefaults.find((x) => x.trackId === trackId);\n            this.currentTrack = track;\n            track.currentFragmentState = {\n              baseDataOffset: this.currentFragment.implicitBaseDataOffset,\n              sampleDescriptionIndex: defaults?.defaultSampleDescriptionIndex ?? null,\n              defaultSampleDuration: defaults?.defaultSampleDuration ?? null,\n              defaultSampleSize: defaults?.defaultSampleSize ?? null,\n              defaultSampleFlags: defaults?.defaultSampleFlags ?? null,\n              startTimestamp: null\n            };\n            if (baseDataOffsetPresent) {\n              track.currentFragmentState.baseDataOffset = readU64Be(slice);\n            } else if (defaultBaseIsMoof) {\n              track.currentFragmentState.baseDataOffset = this.currentFragment.moofOffset;\n            }\n            if (sampleDescriptionIndexPresent) {\n              track.currentFragmentState.sampleDescriptionIndex = readU32Be(slice);\n            }\n            if (defaultSampleDurationPresent) {\n              track.currentFragmentState.defaultSampleDuration = readU32Be(slice);\n            }\n            if (defaultSampleSizePresent) {\n              track.currentFragmentState.defaultSampleSize = readU32Be(slice);\n            }\n            if (defaultSampleFlagsPresent) {\n              track.currentFragmentState.defaultSampleFlags = readU32Be(slice);\n            }\n            if (durationIsEmpty) {\n              track.currentFragmentState.defaultSampleDuration = 0;\n            }\n          }\n          ;\n          break;\n        case \"tfdt\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(track.currentFragmentState);\n            const version = readU8(slice);\n            slice.skip(3);\n            const baseMediaDecodeTime = version === 0 ? readU32Be(slice) : readU64Be(slice);\n            track.currentFragmentState.startTimestamp = baseMediaDecodeTime;\n          }\n          ;\n          break;\n        case \"trun\":\n          {\n            const track = this.currentTrack;\n            if (!track) {\n              break;\n            }\n            assert(this.currentFragment);\n            assert(track.currentFragmentState);\n            if (this.currentFragment.trackData.has(track.id)) {\n              console.warn(\"Can't have two trun boxes for the same track in one fragment. Ignoring...\");\n              break;\n            }\n            const version = readU8(slice);\n            const flags = readU24Be(slice);\n            const dataOffsetPresent = Boolean(flags & 1);\n            const firstSampleFlagsPresent = Boolean(flags & 4);\n            const sampleDurationPresent = Boolean(flags & 256);\n            const sampleSizePresent = Boolean(flags & 512);\n            const sampleFlagsPresent = Boolean(flags & 1024);\n            const sampleCompositionTimeOffsetsPresent = Boolean(flags & 2048);\n            const sampleCount = readU32Be(slice);\n            let dataOffset = track.currentFragmentState.baseDataOffset;\n            if (dataOffsetPresent) {\n              dataOffset += readI32Be(slice);\n            }\n            let firstSampleFlags = null;\n            if (firstSampleFlagsPresent) {\n              firstSampleFlags = readU32Be(slice);\n            }\n            let currentOffset = dataOffset;\n            if (sampleCount === 0) {\n              this.currentFragment.implicitBaseDataOffset = currentOffset;\n              break;\n            }\n            let currentTimestamp = 0;\n            const trackData = {\n              track,\n              startTimestamp: 0,\n              endTimestamp: 0,\n              firstKeyFrameTimestamp: null,\n              samples: [],\n              presentationTimestamps: [],\n              startTimestampIsFinal: false\n            };\n            this.currentFragment.trackData.set(track.id, trackData);\n            for (let i = 0; i < sampleCount; i++) {\n              let sampleDuration;\n              if (sampleDurationPresent) {\n                sampleDuration = readU32Be(slice);\n              } else {\n                assert(track.currentFragmentState.defaultSampleDuration !== null);\n                sampleDuration = track.currentFragmentState.defaultSampleDuration;\n              }\n              let sampleSize;\n              if (sampleSizePresent) {\n                sampleSize = readU32Be(slice);\n              } else {\n                assert(track.currentFragmentState.defaultSampleSize !== null);\n                sampleSize = track.currentFragmentState.defaultSampleSize;\n              }\n              let sampleFlags;\n              if (sampleFlagsPresent) {\n                sampleFlags = readU32Be(slice);\n              } else {\n                assert(track.currentFragmentState.defaultSampleFlags !== null);\n                sampleFlags = track.currentFragmentState.defaultSampleFlags;\n              }\n              if (i === 0 && firstSampleFlags !== null) {\n                sampleFlags = firstSampleFlags;\n              }\n              let sampleCompositionTimeOffset = 0;\n              if (sampleCompositionTimeOffsetsPresent) {\n                if (version === 0) {\n                  sampleCompositionTimeOffset = readU32Be(slice);\n                } else {\n                  sampleCompositionTimeOffset = readI32Be(slice);\n                }\n              }\n              const isKeyFrame = !(sampleFlags & 65536);\n              trackData.samples.push({\n                presentationTimestamp: currentTimestamp + sampleCompositionTimeOffset,\n                duration: sampleDuration,\n                byteOffset: currentOffset,\n                byteSize: sampleSize,\n                isKeyFrame\n              });\n              currentOffset += sampleSize;\n              currentTimestamp += sampleDuration;\n            }\n            trackData.presentationTimestamps = trackData.samples.map((x, i) => ({ presentationTimestamp: x.presentationTimestamp, sampleIndex: i })).sort((a, b) => a.presentationTimestamp - b.presentationTimestamp);\n            for (let i = 0; i < trackData.presentationTimestamps.length; i++) {\n              const currentEntry = trackData.presentationTimestamps[i];\n              const currentSample = trackData.samples[currentEntry.sampleIndex];\n              if (trackData.firstKeyFrameTimestamp === null && currentSample.isKeyFrame) {\n                trackData.firstKeyFrameTimestamp = currentSample.presentationTimestamp;\n              }\n              if (i < trackData.presentationTimestamps.length - 1) {\n                const nextEntry = trackData.presentationTimestamps[i + 1];\n                currentSample.duration = nextEntry.presentationTimestamp - currentEntry.presentationTimestamp;\n              }\n            }\n            const firstSample = trackData.samples[trackData.presentationTimestamps[0].sampleIndex];\n            const lastSample = trackData.samples[last(trackData.presentationTimestamps).sampleIndex];\n            trackData.startTimestamp = firstSample.presentationTimestamp;\n            trackData.endTimestamp = lastSample.presentationTimestamp + lastSample.duration;\n            this.currentFragment.implicitBaseDataOffset = currentOffset;\n          }\n          ;\n          break;\n        // Metadata section\n        // https://exiftool.org/TagNames/QuickTime.html\n        // https://mp4workshop.com/about\n        case \"udta\":\n          {\n            const iterator = this.iterateContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n            for (const { boxInfo: boxInfo2, slice: slice2 } of iterator) {\n              if (boxInfo2.name !== \"meta\" && !this.currentTrack) {\n                const startPos2 = slice2.filePos;\n                this.metadataTags.raw ??= {};\n                if (boxInfo2.name[0] === \"\\xA9\") {\n                  this.metadataTags.raw[boxInfo2.name] ??= readMetadataStringShort(slice2);\n                } else {\n                  this.metadataTags.raw[boxInfo2.name] ??= readBytes(slice2, boxInfo2.contentSize);\n                }\n                slice2.filePos = startPos2;\n              }\n              switch (boxInfo2.name) {\n                case \"meta\":\n                  {\n                    slice2.skip(-boxInfo2.headerSize);\n                    this.traverseBox(slice2);\n                  }\n                  ;\n                  break;\n                case \"\\xA9nam\":\n                case \"name\":\n                  {\n                    if (this.currentTrack) {\n                      this.currentTrack.name = textDecoder.decode(readBytes(slice2, boxInfo2.contentSize));\n                    } else {\n                      this.metadataTags.title ??= readMetadataStringShort(slice2);\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9des\":\n                  {\n                    if (!this.currentTrack) {\n                      this.metadataTags.description ??= readMetadataStringShort(slice2);\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9ART\":\n                  {\n                    if (!this.currentTrack) {\n                      this.metadataTags.artist ??= readMetadataStringShort(slice2);\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9alb\":\n                  {\n                    if (!this.currentTrack) {\n                      this.metadataTags.album ??= readMetadataStringShort(slice2);\n                    }\n                  }\n                  ;\n                  break;\n                case \"albr\":\n                  {\n                    if (!this.currentTrack) {\n                      this.metadataTags.albumArtist ??= readMetadataStringShort(slice2);\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9gen\":\n                  {\n                    if (!this.currentTrack) {\n                      this.metadataTags.genre ??= readMetadataStringShort(slice2);\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9day\":\n                  {\n                    if (!this.currentTrack) {\n                      const date = new Date(readMetadataStringShort(slice2));\n                      if (!Number.isNaN(date.getTime())) {\n                        this.metadataTags.date ??= date;\n                      }\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9cmt\":\n                  {\n                    if (!this.currentTrack) {\n                      this.metadataTags.comment ??= readMetadataStringShort(slice2);\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9lyr\":\n                  {\n                    if (!this.currentTrack) {\n                      this.metadataTags.lyrics ??= readMetadataStringShort(slice2);\n                    }\n                  }\n                  ;\n                  break;\n              }\n            }\n          }\n          ;\n          break;\n        case \"meta\":\n          {\n            if (this.currentTrack) {\n              break;\n            }\n            const word = readU32Be(slice);\n            const isQuickTime = word !== 0;\n            this.currentMetadataKeys = /* @__PURE__ */ new Map();\n            if (isQuickTime) {\n              this.readContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n            } else {\n              this.readContiguousBoxes(slice.slice(contentStartPos + 4, boxInfo.contentSize - 4));\n            }\n            this.currentMetadataKeys = null;\n          }\n          ;\n          break;\n        case \"keys\":\n          {\n            if (!this.currentMetadataKeys) {\n              break;\n            }\n            slice.skip(4);\n            const entryCount = readU32Be(slice);\n            for (let i = 0; i < entryCount; i++) {\n              const keySize = readU32Be(slice);\n              slice.skip(4);\n              const keyName = textDecoder.decode(readBytes(slice, keySize - 8));\n              this.currentMetadataKeys.set(i + 1, keyName);\n            }\n          }\n          ;\n          break;\n        case \"ilst\":\n          {\n            if (!this.currentMetadataKeys) {\n              break;\n            }\n            const iterator = this.iterateContiguousBoxes(slice.slice(contentStartPos, boxInfo.contentSize));\n            for (const { boxInfo: boxInfo2, slice: slice2 } of iterator) {\n              let metadataKey = boxInfo2.name;\n              const nameAsNumber = (metadataKey.charCodeAt(0) << 24) + (metadataKey.charCodeAt(1) << 16) + (metadataKey.charCodeAt(2) << 8) + metadataKey.charCodeAt(3);\n              if (this.currentMetadataKeys.has(nameAsNumber)) {\n                metadataKey = this.currentMetadataKeys.get(nameAsNumber);\n              }\n              const data = readDataBox(slice2);\n              this.metadataTags.raw ??= {};\n              this.metadataTags.raw[metadataKey] ??= data;\n              switch (metadataKey) {\n                case \"\\xA9nam\":\n                case \"titl\":\n                case \"com.apple.quicktime.title\":\n                case \"title\":\n                  {\n                    if (typeof data === \"string\") {\n                      this.metadataTags.title ??= data;\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9des\":\n                case \"desc\":\n                case \"dscp\":\n                case \"com.apple.quicktime.description\":\n                case \"description\":\n                  {\n                    if (typeof data === \"string\") {\n                      this.metadataTags.description ??= data;\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9ART\":\n                case \"com.apple.quicktime.artist\":\n                case \"artist\":\n                  {\n                    if (typeof data === \"string\") {\n                      this.metadataTags.artist ??= data;\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9alb\":\n                case \"albm\":\n                case \"com.apple.quicktime.album\":\n                case \"album\":\n                  {\n                    if (typeof data === \"string\") {\n                      this.metadataTags.album ??= data;\n                    }\n                  }\n                  ;\n                  break;\n                case \"aART\":\n                case \"album_artist\":\n                  {\n                    if (typeof data === \"string\") {\n                      this.metadataTags.albumArtist ??= data;\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9cmt\":\n                case \"com.apple.quicktime.comment\":\n                case \"comment\":\n                  {\n                    if (typeof data === \"string\") {\n                      this.metadataTags.comment ??= data;\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9gen\":\n                case \"gnre\":\n                case \"com.apple.quicktime.genre\":\n                case \"genre\":\n                  {\n                    if (typeof data === \"string\") {\n                      this.metadataTags.genre ??= data;\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9lyr\":\n                case \"lyrics\":\n                  {\n                    if (typeof data === \"string\") {\n                      this.metadataTags.lyrics ??= data;\n                    }\n                  }\n                  ;\n                  break;\n                case \"\\xA9day\":\n                case \"rldt\":\n                case \"com.apple.quicktime.creationdate\":\n                case \"date\":\n                  {\n                    if (typeof data === \"string\") {\n                      const date = new Date(data);\n                      if (!Number.isNaN(date.getTime())) {\n                        this.metadataTags.date ??= date;\n                      }\n                    }\n                  }\n                  ;\n                  break;\n                case \"covr\":\n                case \"com.apple.quicktime.artwork\":\n                  {\n                    if (data instanceof RichImageData) {\n                      this.metadataTags.images ??= [];\n                      this.metadataTags.images.push({\n                        data: data.data,\n                        kind: \"coverFront\",\n                        mimeType: data.mimeType\n                      });\n                    } else if (data instanceof Uint8Array) {\n                      this.metadataTags.images ??= [];\n                      this.metadataTags.images.push({\n                        data,\n                        kind: \"coverFront\",\n                        mimeType: \"image/*\"\n                      });\n                    }\n                  }\n                  ;\n                  break;\n                case \"track\":\n                  {\n                    if (typeof data === \"string\") {\n                      const parts = data.split(\"/\");\n                      const trackNum = Number.parseInt(parts[0], 10);\n                      const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);\n                      if (Number.isInteger(trackNum) && trackNum > 0) {\n                        this.metadataTags.trackNumber ??= trackNum;\n                      }\n                      if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {\n                        this.metadataTags.tracksTotal ??= tracksTotal;\n                      }\n                    }\n                  }\n                  ;\n                  break;\n                case \"trkn\":\n                  {\n                    if (data instanceof Uint8Array && data.length >= 6) {\n                      const view2 = toDataView(data);\n                      const trackNumber = view2.getUint16(2, false);\n                      const tracksTotal = view2.getUint16(4, false);\n                      if (trackNumber > 0) {\n                        this.metadataTags.trackNumber ??= trackNumber;\n                      }\n                      if (tracksTotal > 0) {\n                        this.metadataTags.tracksTotal ??= tracksTotal;\n                      }\n                    }\n                  }\n                  ;\n                  break;\n                case \"disc\":\n                case \"disk\":\n                  {\n                    if (data instanceof Uint8Array && data.length >= 6) {\n                      const view2 = toDataView(data);\n                      const discNumber = view2.getUint16(2, false);\n                      const discNumberMax = view2.getUint16(4, false);\n                      if (discNumber > 0) {\n                        this.metadataTags.discNumber ??= discNumber;\n                      }\n                      if (discNumberMax > 0) {\n                        this.metadataTags.discsTotal ??= discNumberMax;\n                      }\n                    }\n                  }\n                  ;\n                  break;\n              }\n            }\n          }\n          ;\n          break;\n      }\n      slice.filePos = boxEndPos;\n      return true;\n    }\n  };\n  var IsobmffTrackBacking = class {\n    constructor(internalTrack) {\n      this.internalTrack = internalTrack;\n      this.packetToSampleIndex = /* @__PURE__ */ new WeakMap();\n      this.packetToFragmentLocation = /* @__PURE__ */ new WeakMap();\n    }\n    getId() {\n      return this.internalTrack.id;\n    }\n    getCodec() {\n      throw new Error(\"Not implemented on base class.\");\n    }\n    getInternalCodecId() {\n      return this.internalTrack.internalCodecId;\n    }\n    getName() {\n      return this.internalTrack.name;\n    }\n    getLanguageCode() {\n      return this.internalTrack.languageCode;\n    }\n    getTimeResolution() {\n      return this.internalTrack.timescale;\n    }\n    getDisposition() {\n      return this.internalTrack.disposition;\n    }\n    async computeDuration() {\n      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n    }\n    async getFirstTimestamp() {\n      const firstPacket = await this.getFirstPacket({ metadataOnly: true });\n      return firstPacket?.timestamp ?? 0;\n    }\n    async getFirstPacket(options) {\n      const regularPacket = await this.fetchPacketForSampleIndex(0, options);\n      if (regularPacket || !this.internalTrack.demuxer.isFragmented) {\n        return regularPacket;\n      }\n      return this.performFragmentedLookup(\n        null,\n        (fragment) => {\n          const trackData = fragment.trackData.get(this.internalTrack.id);\n          if (trackData) {\n            return {\n              sampleIndex: 0,\n              correctSampleFound: true\n            };\n          }\n          return {\n            sampleIndex: -1,\n            correctSampleFound: false\n          };\n        },\n        -Infinity,\n        // Use -Infinity as a search timestamp to avoid using the lookup entries\n        Infinity,\n        options\n      );\n    }\n    mapTimestampIntoTimescale(timestamp) {\n      return roundIfAlmostInteger(timestamp * this.internalTrack.timescale) + this.internalTrack.editListOffset;\n    }\n    async getPacket(timestamp, options) {\n      const timestampInTimescale = this.mapTimestampIntoTimescale(timestamp);\n      const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);\n      const sampleIndex = getSampleIndexForTimestamp(sampleTable, timestampInTimescale);\n      const regularPacket = await this.fetchPacketForSampleIndex(sampleIndex, options);\n      if (!sampleTableIsEmpty(sampleTable) || !this.internalTrack.demuxer.isFragmented) {\n        return regularPacket;\n      }\n      return this.performFragmentedLookup(\n        null,\n        (fragment) => {\n          const trackData = fragment.trackData.get(this.internalTrack.id);\n          if (!trackData) {\n            return { sampleIndex: -1, correctSampleFound: false };\n          }\n          const index = binarySearchLessOrEqual(\n            trackData.presentationTimestamps,\n            timestampInTimescale,\n            (x) => x.presentationTimestamp\n          );\n          const sampleIndex2 = index !== -1 ? trackData.presentationTimestamps[index].sampleIndex : -1;\n          const correctSampleFound = index !== -1 && timestampInTimescale < trackData.endTimestamp;\n          return { sampleIndex: sampleIndex2, correctSampleFound };\n        },\n        timestampInTimescale,\n        timestampInTimescale,\n        options\n      );\n    }\n    async getNextPacket(packet, options) {\n      const regularSampleIndex = this.packetToSampleIndex.get(packet);\n      if (regularSampleIndex !== void 0) {\n        return this.fetchPacketForSampleIndex(regularSampleIndex + 1, options);\n      }\n      const locationInFragment = this.packetToFragmentLocation.get(packet);\n      if (locationInFragment === void 0) {\n        throw new Error(\"Packet was not created from this track.\");\n      }\n      return this.performFragmentedLookup(\n        locationInFragment.fragment,\n        (fragment) => {\n          if (fragment === locationInFragment.fragment) {\n            const trackData = fragment.trackData.get(this.internalTrack.id);\n            if (locationInFragment.sampleIndex + 1 < trackData.samples.length) {\n              return {\n                sampleIndex: locationInFragment.sampleIndex + 1,\n                correctSampleFound: true\n              };\n            }\n          } else {\n            const trackData = fragment.trackData.get(this.internalTrack.id);\n            if (trackData) {\n              return {\n                sampleIndex: 0,\n                correctSampleFound: true\n              };\n            }\n          }\n          return {\n            sampleIndex: -1,\n            correctSampleFound: false\n          };\n        },\n        -Infinity,\n        // Use -Infinity as a search timestamp to avoid using the lookup entries\n        Infinity,\n        options\n      );\n    }\n    async getKeyPacket(timestamp, options) {\n      const timestampInTimescale = this.mapTimestampIntoTimescale(timestamp);\n      const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);\n      const sampleIndex = getKeyframeSampleIndexForTimestamp(sampleTable, timestampInTimescale);\n      const regularPacket = await this.fetchPacketForSampleIndex(sampleIndex, options);\n      if (!sampleTableIsEmpty(sampleTable) || !this.internalTrack.demuxer.isFragmented) {\n        return regularPacket;\n      }\n      return this.performFragmentedLookup(\n        null,\n        (fragment) => {\n          const trackData = fragment.trackData.get(this.internalTrack.id);\n          if (!trackData) {\n            return { sampleIndex: -1, correctSampleFound: false };\n          }\n          const index = findLastIndex(trackData.presentationTimestamps, (x) => {\n            const sample = trackData.samples[x.sampleIndex];\n            return sample.isKeyFrame && x.presentationTimestamp <= timestampInTimescale;\n          });\n          const sampleIndex2 = index !== -1 ? trackData.presentationTimestamps[index].sampleIndex : -1;\n          const correctSampleFound = index !== -1 && timestampInTimescale < trackData.endTimestamp;\n          return { sampleIndex: sampleIndex2, correctSampleFound };\n        },\n        timestampInTimescale,\n        timestampInTimescale,\n        options\n      );\n    }\n    async getNextKeyPacket(packet, options) {\n      const regularSampleIndex = this.packetToSampleIndex.get(packet);\n      if (regularSampleIndex !== void 0) {\n        const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);\n        const nextKeyFrameSampleIndex = getNextKeyframeIndexForSample(sampleTable, regularSampleIndex);\n        return this.fetchPacketForSampleIndex(nextKeyFrameSampleIndex, options);\n      }\n      const locationInFragment = this.packetToFragmentLocation.get(packet);\n      if (locationInFragment === void 0) {\n        throw new Error(\"Packet was not created from this track.\");\n      }\n      return this.performFragmentedLookup(\n        locationInFragment.fragment,\n        (fragment) => {\n          if (fragment === locationInFragment.fragment) {\n            const trackData = fragment.trackData.get(this.internalTrack.id);\n            const nextKeyFrameIndex = trackData.samples.findIndex(\n              (x, i) => x.isKeyFrame && i > locationInFragment.sampleIndex\n            );\n            if (nextKeyFrameIndex !== -1) {\n              return {\n                sampleIndex: nextKeyFrameIndex,\n                correctSampleFound: true\n              };\n            }\n          } else {\n            const trackData = fragment.trackData.get(this.internalTrack.id);\n            if (trackData && trackData.firstKeyFrameTimestamp !== null) {\n              const keyFrameIndex = trackData.samples.findIndex((x) => x.isKeyFrame);\n              assert(keyFrameIndex !== -1);\n              return {\n                sampleIndex: keyFrameIndex,\n                correctSampleFound: true\n              };\n            }\n          }\n          return {\n            sampleIndex: -1,\n            correctSampleFound: false\n          };\n        },\n        -Infinity,\n        // Use -Infinity as a search timestamp to avoid using the lookup entries\n        Infinity,\n        options\n      );\n    }\n    async fetchPacketForSampleIndex(sampleIndex, options) {\n      if (sampleIndex === -1) {\n        return null;\n      }\n      const sampleTable = this.internalTrack.demuxer.getSampleTableForTrack(this.internalTrack);\n      const sampleInfo = getSampleInfo(sampleTable, sampleIndex);\n      if (!sampleInfo) {\n        return null;\n      }\n      let data;\n      if (options.metadataOnly) {\n        data = PLACEHOLDER_DATA;\n      } else {\n        let slice = this.internalTrack.demuxer.reader.requestSlice(\n          sampleInfo.sampleOffset,\n          sampleInfo.sampleSize\n        );\n        if (slice instanceof Promise) slice = await slice;\n        assert(slice);\n        data = readBytes(slice, sampleInfo.sampleSize);\n      }\n      const timestamp = (sampleInfo.presentationTimestamp - this.internalTrack.editListOffset) / this.internalTrack.timescale;\n      const duration = sampleInfo.duration / this.internalTrack.timescale;\n      const packet = new EncodedPacket(\n        data,\n        sampleInfo.isKeyFrame ? \"key\" : \"delta\",\n        timestamp,\n        duration,\n        sampleIndex,\n        sampleInfo.sampleSize\n      );\n      this.packetToSampleIndex.set(packet, sampleIndex);\n      return packet;\n    }\n    async fetchPacketInFragment(fragment, sampleIndex, options) {\n      if (sampleIndex === -1) {\n        return null;\n      }\n      const trackData = fragment.trackData.get(this.internalTrack.id);\n      const fragmentSample = trackData.samples[sampleIndex];\n      assert(fragmentSample);\n      let data;\n      if (options.metadataOnly) {\n        data = PLACEHOLDER_DATA;\n      } else {\n        let slice = this.internalTrack.demuxer.reader.requestSlice(\n          fragmentSample.byteOffset,\n          fragmentSample.byteSize\n        );\n        if (slice instanceof Promise) slice = await slice;\n        assert(slice);\n        data = readBytes(slice, fragmentSample.byteSize);\n      }\n      const timestamp = (fragmentSample.presentationTimestamp - this.internalTrack.editListOffset) / this.internalTrack.timescale;\n      const duration = fragmentSample.duration / this.internalTrack.timescale;\n      const packet = new EncodedPacket(\n        data,\n        fragmentSample.isKeyFrame ? \"key\" : \"delta\",\n        timestamp,\n        duration,\n        fragment.moofOffset + sampleIndex,\n        fragmentSample.byteSize\n      );\n      this.packetToFragmentLocation.set(packet, { fragment, sampleIndex });\n      return packet;\n    }\n    /** Looks for a packet in the fragments while trying to load as few fragments as possible to retrieve it. */\n    async performFragmentedLookup(startFragment, getMatchInFragment, searchTimestamp, latestTimestamp, options) {\n      const demuxer = this.internalTrack.demuxer;\n      let currentFragment = null;\n      let bestFragment = null;\n      let bestSampleIndex = -1;\n      if (startFragment) {\n        const { sampleIndex, correctSampleFound } = getMatchInFragment(startFragment);\n        if (correctSampleFound) {\n          return this.fetchPacketInFragment(startFragment, sampleIndex, options);\n        }\n        if (sampleIndex !== -1) {\n          bestFragment = startFragment;\n          bestSampleIndex = sampleIndex;\n        }\n      }\n      const lookupEntryIndex = binarySearchLessOrEqual(\n        this.internalTrack.fragmentLookupTable,\n        searchTimestamp,\n        (x) => x.timestamp\n      );\n      const lookupEntry = lookupEntryIndex !== -1 ? this.internalTrack.fragmentLookupTable[lookupEntryIndex] : null;\n      const positionCacheIndex = binarySearchLessOrEqual(\n        this.internalTrack.fragmentPositionCache,\n        searchTimestamp,\n        (x) => x.startTimestamp\n      );\n      const positionCacheEntry = positionCacheIndex !== -1 ? this.internalTrack.fragmentPositionCache[positionCacheIndex] : null;\n      const lookupEntryPosition = Math.max(\n        lookupEntry?.moofOffset ?? 0,\n        positionCacheEntry?.moofOffset ?? 0\n      ) || null;\n      let currentPos;\n      if (!startFragment) {\n        currentPos = lookupEntryPosition ?? 0;\n      } else {\n        if (lookupEntryPosition === null || startFragment.moofOffset >= lookupEntryPosition) {\n          currentPos = startFragment.moofOffset + startFragment.moofSize;\n          currentFragment = startFragment;\n        } else {\n          currentPos = lookupEntryPosition;\n        }\n      }\n      while (true) {\n        if (currentFragment) {\n          const trackData = currentFragment.trackData.get(this.internalTrack.id);\n          if (trackData && trackData.startTimestamp > latestTimestamp) {\n            break;\n          }\n        }\n        let slice = demuxer.reader.requestSliceRange(currentPos, MIN_BOX_HEADER_SIZE, MAX_BOX_HEADER_SIZE);\n        if (slice instanceof Promise) slice = await slice;\n        if (!slice) break;\n        const boxStartPos = currentPos;\n        const boxInfo = readBoxHeader(slice);\n        if (!boxInfo) {\n          break;\n        }\n        if (boxInfo.name === \"moof\") {\n          currentFragment = await demuxer.readFragment(boxStartPos);\n          const { sampleIndex, correctSampleFound } = getMatchInFragment(currentFragment);\n          if (correctSampleFound) {\n            return this.fetchPacketInFragment(currentFragment, sampleIndex, options);\n          }\n          if (sampleIndex !== -1) {\n            bestFragment = currentFragment;\n            bestSampleIndex = sampleIndex;\n          }\n        }\n        currentPos = boxStartPos + boxInfo.totalSize;\n      }\n      if (lookupEntry && (!bestFragment || bestFragment.moofOffset < lookupEntry.moofOffset)) {\n        const previousLookupEntry = this.internalTrack.fragmentLookupTable[lookupEntryIndex - 1];\n        assert(!previousLookupEntry || previousLookupEntry.timestamp < lookupEntry.timestamp);\n        const newSearchTimestamp = previousLookupEntry?.timestamp ?? -Infinity;\n        return this.performFragmentedLookup(\n          null,\n          getMatchInFragment,\n          newSearchTimestamp,\n          latestTimestamp,\n          options\n        );\n      }\n      if (bestFragment) {\n        return this.fetchPacketInFragment(bestFragment, bestSampleIndex, options);\n      }\n      return null;\n    }\n  };\n  var IsobmffVideoTrackBacking = class extends IsobmffTrackBacking {\n    constructor(internalTrack) {\n      super(internalTrack);\n      this.decoderConfigPromise = null;\n      this.internalTrack = internalTrack;\n    }\n    getCodec() {\n      return this.internalTrack.info.codec;\n    }\n    getCodedWidth() {\n      return this.internalTrack.info.width;\n    }\n    getCodedHeight() {\n      return this.internalTrack.info.height;\n    }\n    getRotation() {\n      return this.internalTrack.rotation;\n    }\n    async getColorSpace() {\n      return {\n        primaries: this.internalTrack.info.colorSpace?.primaries,\n        transfer: this.internalTrack.info.colorSpace?.transfer,\n        matrix: this.internalTrack.info.colorSpace?.matrix,\n        fullRange: this.internalTrack.info.colorSpace?.fullRange\n      };\n    }\n    async canBeTransparent() {\n      return false;\n    }\n    async getDecoderConfig() {\n      if (!this.internalTrack.info.codec) {\n        return null;\n      }\n      return this.decoderConfigPromise ??= (async () => {\n        if (this.internalTrack.info.codec === \"vp9\" && !this.internalTrack.info.vp9CodecInfo) {\n          const firstPacket = await this.getFirstPacket({});\n          this.internalTrack.info.vp9CodecInfo = firstPacket && extractVp9CodecInfoFromPacket(firstPacket.data);\n        } else if (this.internalTrack.info.codec === \"av1\" && !this.internalTrack.info.av1CodecInfo) {\n          const firstPacket = await this.getFirstPacket({});\n          this.internalTrack.info.av1CodecInfo = firstPacket && extractAv1CodecInfoFromPacket(firstPacket.data);\n        }\n        return {\n          codec: extractVideoCodecString(this.internalTrack.info),\n          codedWidth: this.internalTrack.info.width,\n          codedHeight: this.internalTrack.info.height,\n          description: this.internalTrack.info.codecDescription ?? void 0,\n          colorSpace: this.internalTrack.info.colorSpace ?? void 0\n        };\n      })();\n    }\n  };\n  var IsobmffAudioTrackBacking = class extends IsobmffTrackBacking {\n    constructor(internalTrack) {\n      super(internalTrack);\n      this.decoderConfig = null;\n      this.internalTrack = internalTrack;\n    }\n    getCodec() {\n      return this.internalTrack.info.codec;\n    }\n    getNumberOfChannels() {\n      return this.internalTrack.info.numberOfChannels;\n    }\n    getSampleRate() {\n      return this.internalTrack.info.sampleRate;\n    }\n    async getDecoderConfig() {\n      if (!this.internalTrack.info.codec) {\n        return null;\n      }\n      return this.decoderConfig ??= {\n        codec: extractAudioCodecString(this.internalTrack.info),\n        numberOfChannels: this.internalTrack.info.numberOfChannels,\n        sampleRate: this.internalTrack.info.sampleRate,\n        description: this.internalTrack.info.codecDescription ?? void 0\n      };\n    }\n  };\n  var getSampleIndexForTimestamp = (sampleTable, timescaleUnits) => {\n    if (sampleTable.presentationTimestamps) {\n      const index = binarySearchLessOrEqual(\n        sampleTable.presentationTimestamps,\n        timescaleUnits,\n        (x) => x.presentationTimestamp\n      );\n      if (index === -1) {\n        return -1;\n      }\n      return sampleTable.presentationTimestamps[index].sampleIndex;\n    } else {\n      const index = binarySearchLessOrEqual(\n        sampleTable.sampleTimingEntries,\n        timescaleUnits,\n        (x) => x.startDecodeTimestamp\n      );\n      if (index === -1) {\n        return -1;\n      }\n      const entry = sampleTable.sampleTimingEntries[index];\n      return entry.startIndex + Math.min(\n        Math.floor((timescaleUnits - entry.startDecodeTimestamp) / entry.delta),\n        entry.count - 1\n      );\n    }\n  };\n  var getKeyframeSampleIndexForTimestamp = (sampleTable, timescaleUnits) => {\n    if (!sampleTable.keySampleIndices) {\n      return getSampleIndexForTimestamp(sampleTable, timescaleUnits);\n    }\n    if (sampleTable.presentationTimestamps) {\n      const index = binarySearchLessOrEqual(\n        sampleTable.presentationTimestamps,\n        timescaleUnits,\n        (x) => x.presentationTimestamp\n      );\n      if (index === -1) {\n        return -1;\n      }\n      for (let i = index; i >= 0; i--) {\n        const sampleIndex = sampleTable.presentationTimestamps[i].sampleIndex;\n        const isKeyFrame = binarySearchExact(sampleTable.keySampleIndices, sampleIndex, (x) => x) !== -1;\n        if (isKeyFrame) {\n          return sampleIndex;\n        }\n      }\n      return -1;\n    } else {\n      const sampleIndex = getSampleIndexForTimestamp(sampleTable, timescaleUnits);\n      const index = binarySearchLessOrEqual(sampleTable.keySampleIndices, sampleIndex, (x) => x);\n      return sampleTable.keySampleIndices[index] ?? -1;\n    }\n  };\n  var getSampleInfo = (sampleTable, sampleIndex) => {\n    const timingEntryIndex = binarySearchLessOrEqual(sampleTable.sampleTimingEntries, sampleIndex, (x) => x.startIndex);\n    const timingEntry = sampleTable.sampleTimingEntries[timingEntryIndex];\n    if (!timingEntry || timingEntry.startIndex + timingEntry.count <= sampleIndex) {\n      return null;\n    }\n    const decodeTimestamp = timingEntry.startDecodeTimestamp + (sampleIndex - timingEntry.startIndex) * timingEntry.delta;\n    let presentationTimestamp = decodeTimestamp;\n    const offsetEntryIndex = binarySearchLessOrEqual(\n      sampleTable.sampleCompositionTimeOffsets,\n      sampleIndex,\n      (x) => x.startIndex\n    );\n    const offsetEntry = sampleTable.sampleCompositionTimeOffsets[offsetEntryIndex];\n    if (offsetEntry && sampleIndex - offsetEntry.startIndex < offsetEntry.count) {\n      presentationTimestamp += offsetEntry.offset;\n    }\n    const sampleSize = sampleTable.sampleSizes[Math.min(sampleIndex, sampleTable.sampleSizes.length - 1)];\n    const chunkEntryIndex = binarySearchLessOrEqual(sampleTable.sampleToChunk, sampleIndex, (x) => x.startSampleIndex);\n    const chunkEntry = sampleTable.sampleToChunk[chunkEntryIndex];\n    assert(chunkEntry);\n    const chunkIndex = chunkEntry.startChunkIndex + Math.floor((sampleIndex - chunkEntry.startSampleIndex) / chunkEntry.samplesPerChunk);\n    const chunkOffset = sampleTable.chunkOffsets[chunkIndex];\n    const startSampleIndexOfChunk = chunkEntry.startSampleIndex + (chunkIndex - chunkEntry.startChunkIndex) * chunkEntry.samplesPerChunk;\n    let chunkSize = 0;\n    let sampleOffset = chunkOffset;\n    if (sampleTable.sampleSizes.length === 1) {\n      sampleOffset += sampleSize * (sampleIndex - startSampleIndexOfChunk);\n      chunkSize += sampleSize * chunkEntry.samplesPerChunk;\n    } else {\n      for (let i = startSampleIndexOfChunk; i < startSampleIndexOfChunk + chunkEntry.samplesPerChunk; i++) {\n        const sampleSize2 = sampleTable.sampleSizes[i];\n        if (i < sampleIndex) {\n          sampleOffset += sampleSize2;\n        }\n        chunkSize += sampleSize2;\n      }\n    }\n    let duration = timingEntry.delta;\n    if (sampleTable.presentationTimestamps) {\n      const presentationIndex = sampleTable.presentationTimestampIndexMap[sampleIndex];\n      assert(presentationIndex !== void 0);\n      if (presentationIndex < sampleTable.presentationTimestamps.length - 1) {\n        const nextEntry = sampleTable.presentationTimestamps[presentationIndex + 1];\n        const nextPresentationTimestamp = nextEntry.presentationTimestamp;\n        duration = nextPresentationTimestamp - presentationTimestamp;\n      }\n    }\n    return {\n      presentationTimestamp,\n      duration,\n      sampleOffset,\n      sampleSize,\n      chunkOffset,\n      chunkSize,\n      isKeyFrame: sampleTable.keySampleIndices ? binarySearchExact(sampleTable.keySampleIndices, sampleIndex, (x) => x) !== -1 : true\n    };\n  };\n  var getNextKeyframeIndexForSample = (sampleTable, sampleIndex) => {\n    if (!sampleTable.keySampleIndices) {\n      return sampleIndex + 1;\n    }\n    const index = binarySearchLessOrEqual(sampleTable.keySampleIndices, sampleIndex, (x) => x);\n    return sampleTable.keySampleIndices[index + 1] ?? -1;\n  };\n  var offsetFragmentTrackDataByTimestamp = (trackData, timestamp) => {\n    trackData.startTimestamp += timestamp;\n    trackData.endTimestamp += timestamp;\n    for (const sample of trackData.samples) {\n      sample.presentationTimestamp += timestamp;\n    }\n    for (const entry of trackData.presentationTimestamps) {\n      entry.presentationTimestamp += timestamp;\n    }\n  };\n  var extractRotationFromMatrix = (matrix) => {\n    const [m11, , , m21] = matrix;\n    const scaleX = Math.hypot(m11, m21);\n    const cosTheta = m11 / scaleX;\n    const sinTheta = m21 / scaleX;\n    const result = -Math.atan2(sinTheta, cosTheta) * (180 / Math.PI);\n    if (!Number.isFinite(result)) {\n      return 0;\n    }\n    return result;\n  };\n  var sampleTableIsEmpty = (sampleTable) => {\n    return sampleTable.sampleSizes.length === 0;\n  };\n\n  // src/matroska/ebml.ts\n  var EBMLFloat32 = class {\n    constructor(value) {\n      this.value = value;\n    }\n  };\n  var EBMLFloat64 = class {\n    constructor(value) {\n      this.value = value;\n    }\n  };\n  var EBMLSignedInt = class {\n    constructor(value) {\n      this.value = value;\n    }\n  };\n  var EBMLUnicodeString = class {\n    constructor(value) {\n      this.value = value;\n    }\n  };\n  var LEVEL_0_EBML_IDS = [\n    440786851 /* EBML */,\n    408125543 /* Segment */\n  ];\n  var LEVEL_1_EBML_IDS = [\n    290298740 /* SeekHead */,\n    357149030 /* Info */,\n    524531317 /* Cluster */,\n    374648427 /* Tracks */,\n    475249515 /* Cues */,\n    423732329 /* Attachments */,\n    272869232 /* Chapters */,\n    307544935 /* Tags */\n  ];\n  var LEVEL_0_AND_1_EBML_IDS = [\n    ...LEVEL_0_EBML_IDS,\n    ...LEVEL_1_EBML_IDS\n  ];\n  var measureUnsignedInt = (value) => {\n    if (value < 1 << 8) {\n      return 1;\n    } else if (value < 1 << 16) {\n      return 2;\n    } else if (value < 1 << 24) {\n      return 3;\n    } else if (value < 2 ** 32) {\n      return 4;\n    } else if (value < 2 ** 40) {\n      return 5;\n    } else {\n      return 6;\n    }\n  };\n  var measureUnsignedBigInt = (value) => {\n    if (value < 1n << 8n) {\n      return 1;\n    } else if (value < 1n << 16n) {\n      return 2;\n    } else if (value < 1n << 24n) {\n      return 3;\n    } else if (value < 1n << 32n) {\n      return 4;\n    } else if (value < 1n << 40n) {\n      return 5;\n    } else if (value < 1n << 48n) {\n      return 6;\n    } else if (value < 1n << 56n) {\n      return 7;\n    } else {\n      return 8;\n    }\n  };\n  var measureSignedInt = (value) => {\n    if (value >= -(1 << 6) && value < 1 << 6) {\n      return 1;\n    } else if (value >= -(1 << 13) && value < 1 << 13) {\n      return 2;\n    } else if (value >= -(1 << 20) && value < 1 << 20) {\n      return 3;\n    } else if (value >= -(1 << 27) && value < 1 << 27) {\n      return 4;\n    } else if (value >= -(2 ** 34) && value < 2 ** 34) {\n      return 5;\n    } else {\n      return 6;\n    }\n  };\n  var measureVarInt = (value) => {\n    if (value < (1 << 7) - 1) {\n      return 1;\n    } else if (value < (1 << 14) - 1) {\n      return 2;\n    } else if (value < (1 << 21) - 1) {\n      return 3;\n    } else if (value < (1 << 28) - 1) {\n      return 4;\n    } else if (value < 2 ** 35 - 1) {\n      return 5;\n    } else if (value < 2 ** 42 - 1) {\n      return 6;\n    } else {\n      throw new Error(\"EBML varint size not supported \" + value);\n    }\n  };\n  var EBMLWriter = class {\n    constructor(writer) {\n      this.writer = writer;\n      this.helper = new Uint8Array(8);\n      this.helperView = new DataView(this.helper.buffer);\n      /**\n       * Stores the position from the start of the file to where EBML elements have been written. This is used to\n       * rewrite/edit elements that were already added before, and to measure sizes of things.\n       */\n      this.offsets = /* @__PURE__ */ new WeakMap();\n      /** Same as offsets, but stores position where the element's data starts (after ID and size fields). */\n      this.dataOffsets = /* @__PURE__ */ new WeakMap();\n    }\n    writeByte(value) {\n      this.helperView.setUint8(0, value);\n      this.writer.write(this.helper.subarray(0, 1));\n    }\n    writeFloat32(value) {\n      this.helperView.setFloat32(0, value, false);\n      this.writer.write(this.helper.subarray(0, 4));\n    }\n    writeFloat64(value) {\n      this.helperView.setFloat64(0, value, false);\n      this.writer.write(this.helper);\n    }\n    writeUnsignedInt(value, width = measureUnsignedInt(value)) {\n      let pos = 0;\n      switch (width) {\n        case 6:\n          this.helperView.setUint8(pos++, value / 2 ** 40 | 0);\n        // eslint-disable-next-line no-fallthrough\n        case 5:\n          this.helperView.setUint8(pos++, value / 2 ** 32 | 0);\n        // eslint-disable-next-line no-fallthrough\n        case 4:\n          this.helperView.setUint8(pos++, value >> 24);\n        // eslint-disable-next-line no-fallthrough\n        case 3:\n          this.helperView.setUint8(pos++, value >> 16);\n        // eslint-disable-next-line no-fallthrough\n        case 2:\n          this.helperView.setUint8(pos++, value >> 8);\n        // eslint-disable-next-line no-fallthrough\n        case 1:\n          this.helperView.setUint8(pos++, value);\n          break;\n        default:\n          throw new Error(\"Bad unsigned int size \" + width);\n      }\n      this.writer.write(this.helper.subarray(0, pos));\n    }\n    writeUnsignedBigInt(value, width = measureUnsignedBigInt(value)) {\n      let pos = 0;\n      for (let i = width - 1; i >= 0; i--) {\n        this.helperView.setUint8(pos++, Number(value >> BigInt(i * 8) & 0xffn));\n      }\n      this.writer.write(this.helper.subarray(0, pos));\n    }\n    writeSignedInt(value, width = measureSignedInt(value)) {\n      if (value < 0) {\n        value += 2 ** (width * 8);\n      }\n      this.writeUnsignedInt(value, width);\n    }\n    writeVarInt(value, width = measureVarInt(value)) {\n      let pos = 0;\n      switch (width) {\n        case 1:\n          this.helperView.setUint8(pos++, 1 << 7 | value);\n          break;\n        case 2:\n          this.helperView.setUint8(pos++, 1 << 6 | value >> 8);\n          this.helperView.setUint8(pos++, value);\n          break;\n        case 3:\n          this.helperView.setUint8(pos++, 1 << 5 | value >> 16);\n          this.helperView.setUint8(pos++, value >> 8);\n          this.helperView.setUint8(pos++, value);\n          break;\n        case 4:\n          this.helperView.setUint8(pos++, 1 << 4 | value >> 24);\n          this.helperView.setUint8(pos++, value >> 16);\n          this.helperView.setUint8(pos++, value >> 8);\n          this.helperView.setUint8(pos++, value);\n          break;\n        case 5:\n          this.helperView.setUint8(pos++, 1 << 3 | value / 2 ** 32 & 7);\n          this.helperView.setUint8(pos++, value >> 24);\n          this.helperView.setUint8(pos++, value >> 16);\n          this.helperView.setUint8(pos++, value >> 8);\n          this.helperView.setUint8(pos++, value);\n          break;\n        case 6:\n          this.helperView.setUint8(pos++, 1 << 2 | value / 2 ** 40 & 3);\n          this.helperView.setUint8(pos++, value / 2 ** 32 | 0);\n          this.helperView.setUint8(pos++, value >> 24);\n          this.helperView.setUint8(pos++, value >> 16);\n          this.helperView.setUint8(pos++, value >> 8);\n          this.helperView.setUint8(pos++, value);\n          break;\n        default:\n          throw new Error(\"Bad EBML varint size \" + width);\n      }\n      this.writer.write(this.helper.subarray(0, pos));\n    }\n    writeAsciiString(str) {\n      this.writer.write(new Uint8Array(str.split(\"\").map((x) => x.charCodeAt(0))));\n    }\n    writeEBML(data) {\n      if (data === null) return;\n      if (data instanceof Uint8Array) {\n        this.writer.write(data);\n      } else if (Array.isArray(data)) {\n        for (const elem of data) {\n          this.writeEBML(elem);\n        }\n      } else {\n        this.offsets.set(data, this.writer.getPos());\n        this.writeUnsignedInt(data.id);\n        if (Array.isArray(data.data)) {\n          const sizePos = this.writer.getPos();\n          const sizeSize = data.size === -1 ? 1 : data.size ?? 4;\n          if (data.size === -1) {\n            this.writeByte(255);\n          } else {\n            this.writer.seek(this.writer.getPos() + sizeSize);\n          }\n          const startPos = this.writer.getPos();\n          this.dataOffsets.set(data, startPos);\n          this.writeEBML(data.data);\n          if (data.size !== -1) {\n            const size = this.writer.getPos() - startPos;\n            const endPos = this.writer.getPos();\n            this.writer.seek(sizePos);\n            this.writeVarInt(size, sizeSize);\n            this.writer.seek(endPos);\n          }\n        } else if (typeof data.data === \"number\") {\n          const size = data.size ?? measureUnsignedInt(data.data);\n          this.writeVarInt(size);\n          this.writeUnsignedInt(data.data, size);\n        } else if (typeof data.data === \"bigint\") {\n          const size = data.size ?? measureUnsignedBigInt(data.data);\n          this.writeVarInt(size);\n          this.writeUnsignedBigInt(data.data, size);\n        } else if (typeof data.data === \"string\") {\n          this.writeVarInt(data.data.length);\n          this.writeAsciiString(data.data);\n        } else if (data.data instanceof Uint8Array) {\n          this.writeVarInt(data.data.byteLength, data.size);\n          this.writer.write(data.data);\n        } else if (data.data instanceof EBMLFloat32) {\n          this.writeVarInt(4);\n          this.writeFloat32(data.data.value);\n        } else if (data.data instanceof EBMLFloat64) {\n          this.writeVarInt(8);\n          this.writeFloat64(data.data.value);\n        } else if (data.data instanceof EBMLSignedInt) {\n          const size = data.size ?? measureSignedInt(data.data.value);\n          this.writeVarInt(size);\n          this.writeSignedInt(data.data.value, size);\n        } else if (data.data instanceof EBMLUnicodeString) {\n          const bytes2 = textEncoder.encode(data.data.value);\n          this.writeVarInt(bytes2.length);\n          this.writer.write(bytes2);\n        } else {\n          assertNever(data.data);\n        }\n      }\n    }\n  };\n  var MAX_VAR_INT_SIZE = 8;\n  var MIN_HEADER_SIZE = 2;\n  var MAX_HEADER_SIZE = 2 * MAX_VAR_INT_SIZE;\n  var readVarIntSize = (slice) => {\n    if (slice.remainingLength < 1) {\n      return null;\n    }\n    const firstByte = readU8(slice);\n    slice.skip(-1);\n    if (firstByte === 0) {\n      return null;\n    }\n    let width = 1;\n    let mask = 128;\n    while ((firstByte & mask) === 0) {\n      width++;\n      mask >>= 1;\n    }\n    if (slice.remainingLength < width) {\n      return null;\n    }\n    return width;\n  };\n  var readVarInt = (slice) => {\n    if (slice.remainingLength < 1) {\n      return null;\n    }\n    const firstByte = readU8(slice);\n    if (firstByte === 0) {\n      return null;\n    }\n    let width = 1;\n    let mask = 1 << 7;\n    while ((firstByte & mask) === 0) {\n      width++;\n      mask >>= 1;\n    }\n    if (slice.remainingLength < width - 1) {\n      return null;\n    }\n    let value = firstByte & mask - 1;\n    for (let i = 1; i < width; i++) {\n      value *= 1 << 8;\n      value += readU8(slice);\n    }\n    return value;\n  };\n  var readUnsignedInt = (slice, width) => {\n    if (width < 1 || width > 8) {\n      throw new Error(\"Bad unsigned int size \" + width);\n    }\n    let value = 0;\n    for (let i = 0; i < width; i++) {\n      value *= 1 << 8;\n      value += readU8(slice);\n    }\n    return value;\n  };\n  var readUnsignedBigInt = (slice, width) => {\n    if (width < 1) {\n      throw new Error(\"Bad unsigned int size \" + width);\n    }\n    let value = 0n;\n    for (let i = 0; i < width; i++) {\n      value <<= 8n;\n      value += BigInt(readU8(slice));\n    }\n    return value;\n  };\n  var readElementId = (slice) => {\n    const size = readVarIntSize(slice);\n    if (size === null) {\n      return null;\n    }\n    if (slice.remainingLength < size) {\n      return null;\n    }\n    const id = readUnsignedInt(slice, size);\n    return id;\n  };\n  var readElementSize = (slice) => {\n    if (slice.remainingLength < 1) {\n      return null;\n    }\n    const firstByte = readU8(slice);\n    if (firstByte === 255) {\n      return void 0;\n    }\n    slice.skip(-1);\n    const size = readVarInt(slice);\n    if (size === null) {\n      return null;\n    }\n    if (size === 72057594037927940) {\n      return void 0;\n    }\n    return size;\n  };\n  var readElementHeader = (slice) => {\n    assert(slice.remainingLength >= MIN_HEADER_SIZE);\n    const id = readElementId(slice);\n    if (id === null) {\n      return null;\n    }\n    const size = readElementSize(slice);\n    if (size === null) {\n      return null;\n    }\n    return { id, size };\n  };\n  var readAsciiString = (slice, length) => {\n    const bytes2 = readBytes(slice, length);\n    let strLength = 0;\n    while (strLength < length && bytes2[strLength] !== 0) {\n      strLength += 1;\n    }\n    return String.fromCharCode(...bytes2.subarray(0, strLength));\n  };\n  var readUnicodeString = (slice, length) => {\n    const bytes2 = readBytes(slice, length);\n    let strLength = 0;\n    while (strLength < length && bytes2[strLength] !== 0) {\n      strLength += 1;\n    }\n    return textDecoder.decode(bytes2.subarray(0, strLength));\n  };\n  var readFloat = (slice, width) => {\n    if (width === 0) {\n      return 0;\n    }\n    if (width !== 4 && width !== 8) {\n      throw new Error(\"Bad float size \" + width);\n    }\n    return width === 4 ? readF32Be(slice) : readF64Be(slice);\n  };\n  var searchForNextElementId = async (reader, startPos, ids, until) => {\n    const idsSet = new Set(ids);\n    let currentPos = startPos;\n    while (until === null || currentPos < until) {\n      let slice = reader.requestSliceRange(currentPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) break;\n      const elementHeader = readElementHeader(slice);\n      if (!elementHeader) {\n        break;\n      }\n      if (idsSet.has(elementHeader.id)) {\n        return { pos: currentPos, found: true };\n      }\n      assertDefinedSize(elementHeader.size);\n      currentPos = slice.filePos + elementHeader.size;\n    }\n    return { pos: until !== null && until > currentPos ? until : currentPos, found: false };\n  };\n  var resync = async (reader, startPos, ids, until) => {\n    const CHUNK_SIZE = 2 ** 16;\n    const idsSet = new Set(ids);\n    let currentPos = startPos;\n    while (currentPos < until) {\n      let slice = reader.requestSliceRange(currentPos, 0, Math.min(CHUNK_SIZE, until - currentPos));\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) break;\n      if (slice.length < MAX_VAR_INT_SIZE) break;\n      for (let i = 0; i < slice.length - MAX_VAR_INT_SIZE; i++) {\n        slice.filePos = currentPos;\n        const elementId = readElementId(slice);\n        if (elementId !== null && idsSet.has(elementId)) {\n          return currentPos;\n        }\n        currentPos++;\n      }\n    }\n    return null;\n  };\n  var CODEC_STRING_MAP = {\n    \"avc\": \"V_MPEG4/ISO/AVC\",\n    \"hevc\": \"V_MPEGH/ISO/HEVC\",\n    \"vp8\": \"V_VP8\",\n    \"vp9\": \"V_VP9\",\n    \"av1\": \"V_AV1\",\n    \"aac\": \"A_AAC\",\n    \"mp3\": \"A_MPEG/L3\",\n    \"opus\": \"A_OPUS\",\n    \"vorbis\": \"A_VORBIS\",\n    \"flac\": \"A_FLAC\",\n    \"pcm-u8\": \"A_PCM/INT/LIT\",\n    \"pcm-s16\": \"A_PCM/INT/LIT\",\n    \"pcm-s16be\": \"A_PCM/INT/BIG\",\n    \"pcm-s24\": \"A_PCM/INT/LIT\",\n    \"pcm-s24be\": \"A_PCM/INT/BIG\",\n    \"pcm-s32\": \"A_PCM/INT/LIT\",\n    \"pcm-s32be\": \"A_PCM/INT/BIG\",\n    \"pcm-f32\": \"A_PCM/FLOAT/IEEE\",\n    \"pcm-f64\": \"A_PCM/FLOAT/IEEE\",\n    \"webvtt\": \"S_TEXT/WEBVTT\"\n  };\n  function assertDefinedSize(size) {\n    if (size === void 0) {\n      throw new Error(\"Undefined element size is used in a place where it is not supported.\");\n    }\n  }\n\n  // src/matroska/matroska-misc.ts\n  var buildMatroskaMimeType = (info) => {\n    const base = info.hasVideo ? \"video/\" : info.hasAudio ? \"audio/\" : \"application/\";\n    let string = base + (info.isWebM ? \"webm\" : \"x-matroska\");\n    if (info.codecStrings.length > 0) {\n      const uniqueCodecMimeTypes = [...new Set(info.codecStrings.filter(Boolean))];\n      string += `; codecs=\"${uniqueCodecMimeTypes.join(\", \")}\"`;\n    }\n    return string;\n  };\n\n  // src/matroska/matroska-demuxer.ts\n  var METADATA_ELEMENTS = [\n    { id: 290298740 /* SeekHead */, flag: \"seekHeadSeen\" },\n    { id: 357149030 /* Info */, flag: \"infoSeen\" },\n    { id: 374648427 /* Tracks */, flag: \"tracksSeen\" },\n    { id: 475249515 /* Cues */, flag: \"cuesSeen\" }\n  ];\n  var MAX_RESYNC_LENGTH = 10 * 2 ** 20;\n  var MatroskaDemuxer = class extends Demuxer {\n    constructor(input) {\n      super(input);\n      this.readMetadataPromise = null;\n      this.segments = [];\n      this.currentSegment = null;\n      this.currentTrack = null;\n      this.currentCluster = null;\n      this.currentBlock = null;\n      this.currentBlockAdditional = null;\n      this.currentCueTime = null;\n      this.currentDecodingInstruction = null;\n      this.currentTagTargetIsMovie = true;\n      this.currentSimpleTagName = null;\n      this.currentAttachedFile = null;\n      this.isWebM = false;\n      this.reader = input._reader;\n    }\n    async computeDuration() {\n      const tracks = await this.getTracks();\n      const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));\n      return Math.max(0, ...trackDurations);\n    }\n    async getTracks() {\n      await this.readMetadata();\n      return this.segments.flatMap((segment) => segment.tracks.map((track) => track.inputTrack));\n    }\n    async getMimeType() {\n      await this.readMetadata();\n      const tracks = await this.getTracks();\n      const codecStrings = await Promise.all(tracks.map((x) => x.getCodecParameterString()));\n      return buildMatroskaMimeType({\n        isWebM: this.isWebM,\n        hasVideo: this.segments.some((segment) => segment.tracks.some((x) => x.info?.type === \"video\")),\n        hasAudio: this.segments.some((segment) => segment.tracks.some((x) => x.info?.type === \"audio\")),\n        codecStrings: codecStrings.filter(Boolean)\n      });\n    }\n    async getMetadataTags() {\n      await this.readMetadata();\n      for (const segment of this.segments) {\n        if (!segment.metadataTagsCollected) {\n          if (this.reader.fileSize !== null) {\n            await this.loadSegmentMetadata(segment);\n          } else {\n          }\n          segment.metadataTagsCollected = true;\n        }\n      }\n      let metadataTags = {};\n      for (const segment of this.segments) {\n        metadataTags = { ...metadataTags, ...segment.metadataTags };\n      }\n      return metadataTags;\n    }\n    readMetadata() {\n      return this.readMetadataPromise ??= (async () => {\n        let currentPos = 0;\n        while (true) {\n          let slice = this.reader.requestSliceRange(currentPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n          if (slice instanceof Promise) slice = await slice;\n          if (!slice) break;\n          const header = readElementHeader(slice);\n          if (!header) {\n            break;\n          }\n          const id = header.id;\n          let size = header.size;\n          const dataStartPos = slice.filePos;\n          if (id === 440786851 /* EBML */) {\n            assertDefinedSize(size);\n            let slice2 = this.reader.requestSlice(dataStartPos, size);\n            if (slice2 instanceof Promise) slice2 = await slice2;\n            if (!slice2) break;\n            this.readContiguousElements(slice2);\n          } else if (id === 408125543 /* Segment */) {\n            await this.readSegment(dataStartPos, size);\n            if (size === void 0) {\n              break;\n            }\n            if (this.reader.fileSize === null) {\n              break;\n            }\n          } else if (id === 524531317 /* Cluster */) {\n            if (this.reader.fileSize === null) {\n              break;\n            }\n            if (size === void 0) {\n              const nextElementPos = await searchForNextElementId(\n                this.reader,\n                dataStartPos,\n                LEVEL_0_AND_1_EBML_IDS,\n                this.reader.fileSize\n              );\n              size = nextElementPos.pos - dataStartPos;\n            }\n            const lastSegment = last(this.segments);\n            if (lastSegment) {\n              lastSegment.elementEndPos = dataStartPos + size;\n            }\n          }\n          assertDefinedSize(size);\n          currentPos = dataStartPos + size;\n        }\n      })();\n    }\n    async readSegment(segmentDataStart, dataSize) {\n      this.currentSegment = {\n        seekHeadSeen: false,\n        infoSeen: false,\n        tracksSeen: false,\n        cuesSeen: false,\n        tagsSeen: false,\n        attachmentsSeen: false,\n        timestampScale: -1,\n        timestampFactor: -1,\n        duration: -1,\n        seekEntries: [],\n        tracks: [],\n        cuePoints: [],\n        dataStartPos: segmentDataStart,\n        elementEndPos: dataSize === void 0 ? null : segmentDataStart + dataSize,\n        clusterSeekStartPos: segmentDataStart,\n        lastReadCluster: null,\n        metadataTags: {},\n        metadataTagsCollected: false\n      };\n      this.segments.push(this.currentSegment);\n      let currentPos = segmentDataStart;\n      while (this.currentSegment.elementEndPos === null || currentPos < this.currentSegment.elementEndPos) {\n        let slice = this.reader.requestSliceRange(currentPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n        if (slice instanceof Promise) slice = await slice;\n        if (!slice) break;\n        const elementStartPos = currentPos;\n        const header = readElementHeader(slice);\n        if (!header || !LEVEL_1_EBML_IDS.includes(header.id) && header.id !== 236 /* Void */) {\n          const nextPos = await resync(\n            this.reader,\n            elementStartPos,\n            LEVEL_1_EBML_IDS,\n            Math.min(this.currentSegment.elementEndPos ?? Infinity, elementStartPos + MAX_RESYNC_LENGTH)\n          );\n          if (nextPos) {\n            currentPos = nextPos;\n            continue;\n          } else {\n            break;\n          }\n        }\n        const { id, size } = header;\n        const dataStartPos = slice.filePos;\n        const metadataElementIndex = METADATA_ELEMENTS.findIndex((x) => x.id === id);\n        if (metadataElementIndex !== -1) {\n          const field = METADATA_ELEMENTS[metadataElementIndex].flag;\n          this.currentSegment[field] = true;\n          assertDefinedSize(size);\n          let slice2 = this.reader.requestSlice(dataStartPos, size);\n          if (slice2 instanceof Promise) slice2 = await slice2;\n          if (slice2) {\n            this.readContiguousElements(slice2);\n          }\n        } else if (id === 307544935 /* Tags */ || id === 423732329 /* Attachments */) {\n          if (id === 307544935 /* Tags */) {\n            this.currentSegment.tagsSeen = true;\n          } else {\n            this.currentSegment.attachmentsSeen = true;\n          }\n          assertDefinedSize(size);\n          let slice2 = this.reader.requestSlice(dataStartPos, size);\n          if (slice2 instanceof Promise) slice2 = await slice2;\n          if (slice2) {\n            this.readContiguousElements(slice2);\n          }\n        } else if (id === 524531317 /* Cluster */) {\n          this.currentSegment.clusterSeekStartPos = elementStartPos;\n          break;\n        }\n        if (size === void 0) {\n          break;\n        } else {\n          currentPos = dataStartPos + size;\n        }\n      }\n      this.currentSegment.seekEntries.sort((a, b) => a.segmentPosition - b.segmentPosition);\n      if (this.reader.fileSize !== null) {\n        for (const seekEntry of this.currentSegment.seekEntries) {\n          const target = METADATA_ELEMENTS.find((x) => x.id === seekEntry.id);\n          if (!target) {\n            continue;\n          }\n          if (this.currentSegment[target.flag]) continue;\n          let slice = this.reader.requestSliceRange(\n            segmentDataStart + seekEntry.segmentPosition,\n            MIN_HEADER_SIZE,\n            MAX_HEADER_SIZE\n          );\n          if (slice instanceof Promise) slice = await slice;\n          if (!slice) continue;\n          const header = readElementHeader(slice);\n          if (!header) continue;\n          const { id, size } = header;\n          if (id !== target.id) continue;\n          assertDefinedSize(size);\n          this.currentSegment[target.flag] = true;\n          let dataSlice = this.reader.requestSlice(slice.filePos, size);\n          if (dataSlice instanceof Promise) dataSlice = await dataSlice;\n          if (!dataSlice) continue;\n          this.readContiguousElements(dataSlice);\n        }\n      }\n      if (this.currentSegment.timestampScale === -1) {\n        this.currentSegment.timestampScale = 1e6;\n        this.currentSegment.timestampFactor = 1e9 / 1e6;\n      }\n      for (const track of this.currentSegment.tracks) {\n        if (track.defaultDurationNs !== null) {\n          track.defaultDuration = this.currentSegment.timestampFactor * track.defaultDurationNs / 1e9;\n        }\n      }\n      this.currentSegment.tracks.sort((a, b) => Number(b.disposition.default) - Number(a.disposition.default));\n      const idToTrack = new Map(this.currentSegment.tracks.map((x) => [x.id, x]));\n      for (const cuePoint of this.currentSegment.cuePoints) {\n        const track = idToTrack.get(cuePoint.trackId);\n        if (track) {\n          track.cuePoints.push(cuePoint);\n        }\n      }\n      for (const track of this.currentSegment.tracks) {\n        track.cuePoints.sort((a, b) => a.time - b.time);\n        for (let i = 0; i < track.cuePoints.length - 1; i++) {\n          const cuePoint1 = track.cuePoints[i];\n          const cuePoint2 = track.cuePoints[i + 1];\n          if (cuePoint1.time === cuePoint2.time) {\n            track.cuePoints.splice(i + 1, 1);\n            i--;\n          }\n        }\n      }\n      let trackWithMostCuePoints = null;\n      let maxCuePointCount = -Infinity;\n      for (const track of this.currentSegment.tracks) {\n        if (track.cuePoints.length > maxCuePointCount) {\n          maxCuePointCount = track.cuePoints.length;\n          trackWithMostCuePoints = track;\n        }\n      }\n      for (const track of this.currentSegment.tracks) {\n        if (track.cuePoints.length === 0) {\n          track.cuePoints = trackWithMostCuePoints.cuePoints;\n        }\n      }\n      this.currentSegment = null;\n    }\n    async readCluster(startPos, segment) {\n      if (segment.lastReadCluster?.elementStartPos === startPos) {\n        return segment.lastReadCluster;\n      }\n      let headerSlice = this.reader.requestSliceRange(startPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n      if (headerSlice instanceof Promise) headerSlice = await headerSlice;\n      assert(headerSlice);\n      const elementStartPos = startPos;\n      const elementHeader = readElementHeader(headerSlice);\n      assert(elementHeader);\n      const id = elementHeader.id;\n      assert(id === 524531317 /* Cluster */);\n      let size = elementHeader.size;\n      const dataStartPos = headerSlice.filePos;\n      if (size === void 0) {\n        const nextElementPos = await searchForNextElementId(\n          this.reader,\n          dataStartPos,\n          LEVEL_0_AND_1_EBML_IDS,\n          segment.elementEndPos\n        );\n        size = nextElementPos.pos - dataStartPos;\n      }\n      let dataSlice = this.reader.requestSlice(dataStartPos, size);\n      if (dataSlice instanceof Promise) dataSlice = await dataSlice;\n      const cluster = {\n        segment,\n        elementStartPos,\n        elementEndPos: dataStartPos + size,\n        dataStartPos,\n        timestamp: -1,\n        trackData: /* @__PURE__ */ new Map()\n      };\n      this.currentCluster = cluster;\n      if (dataSlice) {\n        const endPos = this.readContiguousElements(dataSlice, LEVEL_0_AND_1_EBML_IDS);\n        cluster.elementEndPos = endPos;\n      }\n      for (const [, trackData] of cluster.trackData) {\n        const track = trackData.track;\n        assert(trackData.blocks.length > 0);\n        let hasLacedBlocks = false;\n        for (let i = 0; i < trackData.blocks.length; i++) {\n          const block = trackData.blocks[i];\n          block.timestamp += cluster.timestamp;\n          hasLacedBlocks ||= block.lacing !== 0 /* None */;\n        }\n        trackData.presentationTimestamps = trackData.blocks.map((block, i) => ({ timestamp: block.timestamp, blockIndex: i })).sort((a, b) => a.timestamp - b.timestamp);\n        for (let i = 0; i < trackData.presentationTimestamps.length; i++) {\n          const currentEntry = trackData.presentationTimestamps[i];\n          const currentBlock = trackData.blocks[currentEntry.blockIndex];\n          if (trackData.firstKeyFrameTimestamp === null && currentBlock.isKeyFrame) {\n            trackData.firstKeyFrameTimestamp = currentBlock.timestamp;\n          }\n          if (i < trackData.presentationTimestamps.length - 1) {\n            const nextEntry = trackData.presentationTimestamps[i + 1];\n            currentBlock.duration = nextEntry.timestamp - currentBlock.timestamp;\n          } else if (currentBlock.duration === 0) {\n            if (track.defaultDuration != null) {\n              if (currentBlock.lacing === 0 /* None */) {\n                currentBlock.duration = track.defaultDuration;\n              } else {\n              }\n            }\n          }\n        }\n        if (hasLacedBlocks) {\n          this.expandLacedBlocks(trackData.blocks, track);\n          trackData.presentationTimestamps = trackData.blocks.map((block, i) => ({ timestamp: block.timestamp, blockIndex: i })).sort((a, b) => a.timestamp - b.timestamp);\n        }\n        const firstBlock = trackData.blocks[trackData.presentationTimestamps[0].blockIndex];\n        const lastBlock = trackData.blocks[last(trackData.presentationTimestamps).blockIndex];\n        trackData.startTimestamp = firstBlock.timestamp;\n        trackData.endTimestamp = lastBlock.timestamp + lastBlock.duration;\n        const insertionIndex = binarySearchLessOrEqual(\n          track.clusterPositionCache,\n          trackData.startTimestamp,\n          (x) => x.startTimestamp\n        );\n        if (insertionIndex === -1 || track.clusterPositionCache[insertionIndex].elementStartPos !== elementStartPos) {\n          track.clusterPositionCache.splice(insertionIndex + 1, 0, {\n            elementStartPos: cluster.elementStartPos,\n            startTimestamp: trackData.startTimestamp\n          });\n        }\n      }\n      segment.lastReadCluster = cluster;\n      return cluster;\n    }\n    getTrackDataInCluster(cluster, trackNumber) {\n      let trackData = cluster.trackData.get(trackNumber);\n      if (!trackData) {\n        const track = cluster.segment.tracks.find((x) => x.id === trackNumber);\n        if (!track) {\n          return null;\n        }\n        trackData = {\n          track,\n          startTimestamp: 0,\n          endTimestamp: 0,\n          firstKeyFrameTimestamp: null,\n          blocks: [],\n          presentationTimestamps: []\n        };\n        cluster.trackData.set(trackNumber, trackData);\n      }\n      return trackData;\n    }\n    expandLacedBlocks(blocks, track) {\n      for (let blockIndex = 0; blockIndex < blocks.length; blockIndex++) {\n        const originalBlock = blocks[blockIndex];\n        if (originalBlock.lacing === 0 /* None */) {\n          continue;\n        }\n        if (!originalBlock.decoded) {\n          originalBlock.data = this.decodeBlockData(track, originalBlock.data);\n          originalBlock.decoded = true;\n        }\n        const slice = FileSlice4.tempFromBytes(originalBlock.data);\n        const frameSizes = [];\n        const frameCount = readU8(slice) + 1;\n        switch (originalBlock.lacing) {\n          case 1 /* Xiph */:\n            {\n              let totalUsedSize = 0;\n              for (let i = 0; i < frameCount - 1; i++) {\n                let frameSize = 0;\n                while (slice.bufferPos < slice.length) {\n                  const value = readU8(slice);\n                  frameSize += value;\n                  if (value < 255) {\n                    frameSizes.push(frameSize);\n                    totalUsedSize += frameSize;\n                    break;\n                  }\n                }\n              }\n              frameSizes.push(slice.length - (slice.bufferPos + totalUsedSize));\n            }\n            ;\n            break;\n          case 2 /* FixedSize */:\n            {\n              const totalDataSize = slice.length - 1;\n              const frameSize = Math.floor(totalDataSize / frameCount);\n              for (let i = 0; i < frameCount; i++) {\n                frameSizes.push(frameSize);\n              }\n            }\n            ;\n            break;\n          case 3 /* Ebml */:\n            {\n              const firstResult = readVarInt(slice);\n              assert(firstResult !== null);\n              let currentSize = firstResult;\n              frameSizes.push(currentSize);\n              let totalUsedSize = currentSize;\n              for (let i = 1; i < frameCount - 1; i++) {\n                const startPos = slice.bufferPos;\n                const diffResult = readVarInt(slice);\n                assert(diffResult !== null);\n                const unsignedDiff = diffResult;\n                const width = slice.bufferPos - startPos;\n                const bias = (1 << width * 7 - 1) - 1;\n                const diff = unsignedDiff - bias;\n                currentSize += diff;\n                frameSizes.push(currentSize);\n                totalUsedSize += currentSize;\n              }\n              frameSizes.push(slice.length - (slice.bufferPos + totalUsedSize));\n            }\n            ;\n            break;\n          default:\n            assert(false);\n        }\n        assert(frameSizes.length === frameCount);\n        blocks.splice(blockIndex, 1);\n        const blockDuration = originalBlock.duration || frameCount * (track.defaultDuration ?? 0);\n        for (let i = 0; i < frameCount; i++) {\n          const frameSize = frameSizes[i];\n          const frameData = readBytes(slice, frameSize);\n          const frameTimestamp = originalBlock.timestamp + blockDuration * i / frameCount;\n          const frameDuration = blockDuration / frameCount;\n          blocks.splice(blockIndex + i, 0, {\n            timestamp: frameTimestamp,\n            duration: frameDuration,\n            isKeyFrame: originalBlock.isKeyFrame,\n            data: frameData,\n            lacing: 0 /* None */,\n            decoded: true,\n            mainAdditional: originalBlock.mainAdditional\n          });\n        }\n        blockIndex += frameCount;\n        blockIndex--;\n      }\n    }\n    async loadSegmentMetadata(segment) {\n      for (const seekEntry of segment.seekEntries) {\n        if (seekEntry.id === 307544935 /* Tags */ && !segment.tagsSeen) {\n        } else if (seekEntry.id === 423732329 /* Attachments */ && !segment.attachmentsSeen) {\n        } else {\n          continue;\n        }\n        let slice = this.reader.requestSliceRange(\n          segment.dataStartPos + seekEntry.segmentPosition,\n          MIN_HEADER_SIZE,\n          MAX_HEADER_SIZE\n        );\n        if (slice instanceof Promise) slice = await slice;\n        if (!slice) continue;\n        const header = readElementHeader(slice);\n        if (!header || header.id !== seekEntry.id) continue;\n        const { size } = header;\n        assertDefinedSize(size);\n        assert(!this.currentSegment);\n        this.currentSegment = segment;\n        let dataSlice = this.reader.requestSlice(slice.filePos, size);\n        if (dataSlice instanceof Promise) dataSlice = await dataSlice;\n        if (dataSlice) {\n          this.readContiguousElements(dataSlice);\n        }\n        this.currentSegment = null;\n        if (seekEntry.id === 307544935 /* Tags */) {\n          segment.tagsSeen = true;\n        } else if (seekEntry.id === 423732329 /* Attachments */) {\n          segment.attachmentsSeen = true;\n        }\n      }\n    }\n    readContiguousElements(slice, stopIds) {\n      while (slice.remainingLength >= MIN_HEADER_SIZE) {\n        const startPos = slice.filePos;\n        const foundElement = this.traverseElement(slice, stopIds);\n        if (!foundElement) {\n          return startPos;\n        }\n      }\n      return slice.filePos;\n    }\n    traverseElement(slice, stopIds) {\n      const header = readElementHeader(slice);\n      if (!header) {\n        return false;\n      }\n      if (stopIds && stopIds.includes(header.id)) {\n        return false;\n      }\n      const { id, size } = header;\n      const dataStartPos = slice.filePos;\n      assertDefinedSize(size);\n      switch (id) {\n        case 17026 /* DocType */:\n          {\n            this.isWebM = readAsciiString(slice, size) === \"webm\";\n          }\n          ;\n          break;\n        case 19899 /* Seek */:\n          {\n            if (!this.currentSegment) break;\n            const seekEntry = { id: -1, segmentPosition: -1 };\n            this.currentSegment.seekEntries.push(seekEntry);\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n            if (seekEntry.id === -1 || seekEntry.segmentPosition === -1) {\n              this.currentSegment.seekEntries.pop();\n            }\n          }\n          ;\n          break;\n        case 21419 /* SeekID */:\n          {\n            const lastSeekEntry = this.currentSegment?.seekEntries[this.currentSegment.seekEntries.length - 1];\n            if (!lastSeekEntry) break;\n            lastSeekEntry.id = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 21420 /* SeekPosition */:\n          {\n            const lastSeekEntry = this.currentSegment?.seekEntries[this.currentSegment.seekEntries.length - 1];\n            if (!lastSeekEntry) break;\n            lastSeekEntry.segmentPosition = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 2807729 /* TimestampScale */:\n          {\n            if (!this.currentSegment) break;\n            this.currentSegment.timestampScale = readUnsignedInt(slice, size);\n            this.currentSegment.timestampFactor = 1e9 / this.currentSegment.timestampScale;\n          }\n          ;\n          break;\n        case 17545 /* Duration */:\n          {\n            if (!this.currentSegment) break;\n            this.currentSegment.duration = readFloat(slice, size);\n          }\n          ;\n          break;\n        case 174 /* TrackEntry */:\n          {\n            if (!this.currentSegment) break;\n            this.currentTrack = {\n              id: -1,\n              segment: this.currentSegment,\n              demuxer: this,\n              clusterPositionCache: [],\n              cuePoints: [],\n              disposition: {\n                ...DEFAULT_TRACK_DISPOSITION\n              },\n              inputTrack: null,\n              codecId: null,\n              codecPrivate: null,\n              defaultDuration: null,\n              defaultDurationNs: null,\n              name: null,\n              languageCode: UNDETERMINED_LANGUAGE,\n              decodingInstructions: [],\n              info: null\n            };\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n            if (!this.currentTrack) {\n              break;\n            }\n            if (this.currentTrack.decodingInstructions.some((instruction) => {\n              return instruction.data?.type !== \"decompress\" || instruction.scope !== 1 /* Block */ || instruction.data.algorithm !== 3 /* HeaderStripping */;\n            })) {\n              console.warn(`Track #${this.currentTrack.id} has an unsupported content encoding; dropping.`);\n              this.currentTrack = null;\n            }\n            if (this.currentTrack && this.currentTrack.id !== -1 && this.currentTrack.codecId && this.currentTrack.info) {\n              const slashIndex = this.currentTrack.codecId.indexOf(\"/\");\n              const codecIdWithoutSuffix = slashIndex === -1 ? this.currentTrack.codecId : this.currentTrack.codecId.slice(0, slashIndex);\n              if (this.currentTrack.info.type === \"video\" && this.currentTrack.info.width !== -1 && this.currentTrack.info.height !== -1) {\n                if (this.currentTrack.codecId === CODEC_STRING_MAP.avc) {\n                  this.currentTrack.info.codec = \"avc\";\n                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n                } else if (this.currentTrack.codecId === CODEC_STRING_MAP.hevc) {\n                  this.currentTrack.info.codec = \"hevc\";\n                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.vp8) {\n                  this.currentTrack.info.codec = \"vp8\";\n                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.vp9) {\n                  this.currentTrack.info.codec = \"vp9\";\n                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.av1) {\n                  this.currentTrack.info.codec = \"av1\";\n                }\n                const videoTrack = this.currentTrack;\n                const inputTrack = new InputVideoTrack(this.input, new MatroskaVideoTrackBacking(videoTrack));\n                this.currentTrack.inputTrack = inputTrack;\n                this.currentSegment.tracks.push(this.currentTrack);\n              } else if (this.currentTrack.info.type === \"audio\" && this.currentTrack.info.numberOfChannels !== -1 && this.currentTrack.info.sampleRate !== -1) {\n                if (codecIdWithoutSuffix === CODEC_STRING_MAP.aac) {\n                  this.currentTrack.info.codec = \"aac\";\n                  this.currentTrack.info.aacCodecInfo = {\n                    isMpeg2: this.currentTrack.codecId.includes(\"MPEG2\"),\n                    objectType: null\n                  };\n                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n                } else if (this.currentTrack.codecId === CODEC_STRING_MAP.mp3) {\n                  this.currentTrack.info.codec = \"mp3\";\n                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.opus) {\n                  this.currentTrack.info.codec = \"opus\";\n                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n                  this.currentTrack.info.sampleRate = OPUS_SAMPLE_RATE;\n                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.vorbis) {\n                  this.currentTrack.info.codec = \"vorbis\";\n                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n                } else if (codecIdWithoutSuffix === CODEC_STRING_MAP.flac) {\n                  this.currentTrack.info.codec = \"flac\";\n                  this.currentTrack.info.codecDescription = this.currentTrack.codecPrivate;\n                } else if (this.currentTrack.codecId === \"A_PCM/INT/LIT\") {\n                  if (this.currentTrack.info.bitDepth === 8) {\n                    this.currentTrack.info.codec = \"pcm-u8\";\n                  } else if (this.currentTrack.info.bitDepth === 16) {\n                    this.currentTrack.info.codec = \"pcm-s16\";\n                  } else if (this.currentTrack.info.bitDepth === 24) {\n                    this.currentTrack.info.codec = \"pcm-s24\";\n                  } else if (this.currentTrack.info.bitDepth === 32) {\n                    this.currentTrack.info.codec = \"pcm-s32\";\n                  }\n                } else if (this.currentTrack.codecId === \"A_PCM/INT/BIG\") {\n                  if (this.currentTrack.info.bitDepth === 8) {\n                    this.currentTrack.info.codec = \"pcm-u8\";\n                  } else if (this.currentTrack.info.bitDepth === 16) {\n                    this.currentTrack.info.codec = \"pcm-s16be\";\n                  } else if (this.currentTrack.info.bitDepth === 24) {\n                    this.currentTrack.info.codec = \"pcm-s24be\";\n                  } else if (this.currentTrack.info.bitDepth === 32) {\n                    this.currentTrack.info.codec = \"pcm-s32be\";\n                  }\n                } else if (this.currentTrack.codecId === \"A_PCM/FLOAT/IEEE\") {\n                  if (this.currentTrack.info.bitDepth === 32) {\n                    this.currentTrack.info.codec = \"pcm-f32\";\n                  } else if (this.currentTrack.info.bitDepth === 64) {\n                    this.currentTrack.info.codec = \"pcm-f64\";\n                  }\n                }\n                const audioTrack = this.currentTrack;\n                const inputTrack = new InputAudioTrack(this.input, new MatroskaAudioTrackBacking(audioTrack));\n                this.currentTrack.inputTrack = inputTrack;\n                this.currentSegment.tracks.push(this.currentTrack);\n              }\n            }\n            this.currentTrack = null;\n          }\n          ;\n          break;\n        case 215 /* TrackNumber */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.id = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 131 /* TrackType */:\n          {\n            if (!this.currentTrack) break;\n            const type = readUnsignedInt(slice, size);\n            if (type === 1) {\n              this.currentTrack.info = {\n                type: \"video\",\n                width: -1,\n                height: -1,\n                rotation: 0,\n                codec: null,\n                codecDescription: null,\n                colorSpace: null,\n                alphaMode: false\n              };\n            } else if (type === 2) {\n              this.currentTrack.info = {\n                type: \"audio\",\n                numberOfChannels: -1,\n                sampleRate: -1,\n                bitDepth: -1,\n                codec: null,\n                codecDescription: null,\n                aacCodecInfo: null\n              };\n            }\n          }\n          ;\n          break;\n        case 185 /* FlagEnabled */:\n          {\n            if (!this.currentTrack) break;\n            const enabled = readUnsignedInt(slice, size);\n            if (!enabled) {\n              this.currentTrack = null;\n            }\n          }\n          ;\n          break;\n        case 136 /* FlagDefault */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.disposition.default = !!readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 21930 /* FlagForced */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.disposition.forced = !!readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 21934 /* FlagOriginal */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.disposition.original = !!readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 21931 /* FlagHearingImpaired */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.disposition.hearingImpaired = !!readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 21932 /* FlagVisualImpaired */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.disposition.visuallyImpaired = !!readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 21935 /* FlagCommentary */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.disposition.commentary = !!readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 134 /* CodecID */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.codecId = readAsciiString(slice, size);\n          }\n          ;\n          break;\n        case 25506 /* CodecPrivate */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.codecPrivate = readBytes(slice, size);\n          }\n          ;\n          break;\n        case 2352003 /* DefaultDuration */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.defaultDurationNs = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 21358 /* Name */:\n          {\n            if (!this.currentTrack) break;\n            this.currentTrack.name = readUnicodeString(slice, size);\n          }\n          ;\n          break;\n        case 2274716 /* Language */:\n          {\n            if (!this.currentTrack) break;\n            if (this.currentTrack.languageCode !== UNDETERMINED_LANGUAGE) {\n              break;\n            }\n            this.currentTrack.languageCode = readAsciiString(slice, size);\n            if (!isIso639Dash2LanguageCode(this.currentTrack.languageCode)) {\n              this.currentTrack.languageCode = UNDETERMINED_LANGUAGE;\n            }\n          }\n          ;\n          break;\n        case 2274717 /* LanguageBCP47 */:\n          {\n            if (!this.currentTrack) break;\n            const bcp47 = readAsciiString(slice, size);\n            const languageSubtag = bcp47.split(\"-\")[0];\n            if (languageSubtag) {\n              this.currentTrack.languageCode = languageSubtag;\n            } else {\n              this.currentTrack.languageCode = UNDETERMINED_LANGUAGE;\n            }\n          }\n          ;\n          break;\n        case 224 /* Video */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\") break;\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n          }\n          ;\n          break;\n        case 176 /* PixelWidth */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\") break;\n            this.currentTrack.info.width = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 186 /* PixelHeight */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\") break;\n            this.currentTrack.info.height = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 21440 /* AlphaMode */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\") break;\n            this.currentTrack.info.alphaMode = readUnsignedInt(slice, size) === 1;\n          }\n          ;\n          break;\n        case 21936 /* Colour */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\") break;\n            this.currentTrack.info.colorSpace = {};\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n          }\n          ;\n          break;\n        case 21937 /* MatrixCoefficients */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\" || !this.currentTrack.info.colorSpace) break;\n            const matrixCoefficients = readUnsignedInt(slice, size);\n            const mapped = MATRIX_COEFFICIENTS_MAP_INVERSE[matrixCoefficients] ?? null;\n            this.currentTrack.info.colorSpace.matrix = mapped;\n          }\n          ;\n          break;\n        case 21945 /* Range */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\" || !this.currentTrack.info.colorSpace) break;\n            this.currentTrack.info.colorSpace.fullRange = readUnsignedInt(slice, size) === 2;\n          }\n          ;\n          break;\n        case 21946 /* TransferCharacteristics */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\" || !this.currentTrack.info.colorSpace) break;\n            const transferCharacteristics = readUnsignedInt(slice, size);\n            const mapped = TRANSFER_CHARACTERISTICS_MAP_INVERSE[transferCharacteristics] ?? null;\n            this.currentTrack.info.colorSpace.transfer = mapped;\n          }\n          ;\n          break;\n        case 21947 /* Primaries */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\" || !this.currentTrack.info.colorSpace) break;\n            const primaries = readUnsignedInt(slice, size);\n            const mapped = COLOR_PRIMARIES_MAP_INVERSE[primaries] ?? null;\n            this.currentTrack.info.colorSpace.primaries = mapped;\n          }\n          ;\n          break;\n        case 30320 /* Projection */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\") break;\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n          }\n          ;\n          break;\n        case 30325 /* ProjectionPoseRoll */:\n          {\n            if (this.currentTrack?.info?.type !== \"video\") break;\n            const rotation = readFloat(slice, size);\n            const flippedRotation = -rotation;\n            try {\n              this.currentTrack.info.rotation = normalizeRotation(flippedRotation);\n            } catch {\n            }\n          }\n          ;\n          break;\n        case 225 /* Audio */:\n          {\n            if (this.currentTrack?.info?.type !== \"audio\") break;\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n          }\n          ;\n          break;\n        case 181 /* SamplingFrequency */:\n          {\n            if (this.currentTrack?.info?.type !== \"audio\") break;\n            this.currentTrack.info.sampleRate = readFloat(slice, size);\n          }\n          ;\n          break;\n        case 159 /* Channels */:\n          {\n            if (this.currentTrack?.info?.type !== \"audio\") break;\n            this.currentTrack.info.numberOfChannels = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 25188 /* BitDepth */:\n          {\n            if (this.currentTrack?.info?.type !== \"audio\") break;\n            this.currentTrack.info.bitDepth = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 187 /* CuePoint */:\n          {\n            if (!this.currentSegment) break;\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n            this.currentCueTime = null;\n          }\n          ;\n          break;\n        case 179 /* CueTime */:\n          {\n            this.currentCueTime = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 183 /* CueTrackPositions */:\n          {\n            if (this.currentCueTime === null) break;\n            assert(this.currentSegment);\n            const cuePoint = { time: this.currentCueTime, trackId: -1, clusterPosition: -1 };\n            this.currentSegment.cuePoints.push(cuePoint);\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n            if (cuePoint.trackId === -1 || cuePoint.clusterPosition === -1) {\n              this.currentSegment.cuePoints.pop();\n            }\n          }\n          ;\n          break;\n        case 247 /* CueTrack */:\n          {\n            const lastCuePoint = this.currentSegment?.cuePoints[this.currentSegment.cuePoints.length - 1];\n            if (!lastCuePoint) break;\n            lastCuePoint.trackId = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 241 /* CueClusterPosition */:\n          {\n            const lastCuePoint = this.currentSegment?.cuePoints[this.currentSegment.cuePoints.length - 1];\n            if (!lastCuePoint) break;\n            assert(this.currentSegment);\n            lastCuePoint.clusterPosition = this.currentSegment.dataStartPos + readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 231 /* Timestamp */:\n          {\n            if (!this.currentCluster) break;\n            this.currentCluster.timestamp = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 163 /* SimpleBlock */:\n          {\n            if (!this.currentCluster) break;\n            const trackNumber = readVarInt(slice);\n            if (trackNumber === null) break;\n            const trackData = this.getTrackDataInCluster(this.currentCluster, trackNumber);\n            if (!trackData) break;\n            const relativeTimestamp = readI16Be(slice);\n            const flags = readU8(slice);\n            const lacing = flags >> 1 & 3;\n            let isKeyFrame = !!(flags & 128);\n            if (trackData.track.info?.type === \"audio\" && trackData.track.info.codec) {\n              isKeyFrame = true;\n            }\n            const blockData = readBytes(slice, size - (slice.filePos - dataStartPos));\n            const hasDecodingInstructions = trackData.track.decodingInstructions.length > 0;\n            trackData.blocks.push({\n              timestamp: relativeTimestamp,\n              // We'll add the cluster's timestamp to this later\n              duration: 0,\n              // Will set later\n              isKeyFrame,\n              data: blockData,\n              lacing,\n              decoded: !hasDecodingInstructions,\n              mainAdditional: null\n            });\n          }\n          ;\n          break;\n        case 160 /* BlockGroup */:\n          {\n            if (!this.currentCluster) break;\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n            this.currentBlock = null;\n          }\n          ;\n          break;\n        case 161 /* Block */:\n          {\n            if (!this.currentCluster) break;\n            const trackNumber = readVarInt(slice);\n            if (trackNumber === null) break;\n            const trackData = this.getTrackDataInCluster(this.currentCluster, trackNumber);\n            if (!trackData) break;\n            const relativeTimestamp = readI16Be(slice);\n            const flags = readU8(slice);\n            const lacing = flags >> 1 & 3;\n            const blockData = readBytes(slice, size - (slice.filePos - dataStartPos));\n            const hasDecodingInstructions = trackData.track.decodingInstructions.length > 0;\n            this.currentBlock = {\n              timestamp: relativeTimestamp,\n              // We'll add the cluster's timestamp to this later\n              duration: 0,\n              // Will set later\n              isKeyFrame: true,\n              data: blockData,\n              lacing,\n              decoded: !hasDecodingInstructions,\n              mainAdditional: null\n            };\n            trackData.blocks.push(this.currentBlock);\n          }\n          ;\n          break;\n        case 30113 /* BlockAdditions */:\n          {\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n          }\n          ;\n          break;\n        case 166 /* BlockMore */:\n          {\n            if (!this.currentBlock) break;\n            this.currentBlockAdditional = {\n              addId: 1,\n              data: null\n            };\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n            if (this.currentBlockAdditional.data && this.currentBlockAdditional.addId === 1) {\n              this.currentBlock.mainAdditional = this.currentBlockAdditional.data;\n            }\n            this.currentBlockAdditional = null;\n          }\n          ;\n          break;\n        case 165 /* BlockAdditional */:\n          {\n            if (!this.currentBlockAdditional) break;\n            this.currentBlockAdditional.data = readBytes(slice, size);\n          }\n          ;\n          break;\n        case 238 /* BlockAddID */:\n          {\n            if (!this.currentBlockAdditional) break;\n            this.currentBlockAdditional.addId = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 155 /* BlockDuration */:\n          {\n            if (!this.currentBlock) break;\n            this.currentBlock.duration = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 251 /* ReferenceBlock */:\n          {\n            if (!this.currentBlock) break;\n            this.currentBlock.isKeyFrame = false;\n          }\n          ;\n          break;\n        case 29555 /* Tag */:\n          {\n            this.currentTagTargetIsMovie = true;\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n          }\n          ;\n          break;\n        case 25536 /* Targets */:\n          {\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n          }\n          ;\n          break;\n        case 26826 /* TargetTypeValue */:\n          {\n            const targetTypeValue = readUnsignedInt(slice, size);\n            if (targetTypeValue !== 50) {\n              this.currentTagTargetIsMovie = false;\n            }\n          }\n          ;\n          break;\n        case 25541 /* TagTrackUID */:\n        case 25545 /* TagEditionUID */:\n        case 25540 /* TagChapterUID */:\n        case 25542 /* TagAttachmentUID */:\n          {\n            this.currentTagTargetIsMovie = false;\n          }\n          ;\n          break;\n        case 26568 /* SimpleTag */:\n          {\n            if (!this.currentTagTargetIsMovie) break;\n            this.currentSimpleTagName = null;\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n          }\n          ;\n          break;\n        case 17827 /* TagName */:\n          {\n            this.currentSimpleTagName = readUnicodeString(slice, size);\n          }\n          ;\n          break;\n        case 17543 /* TagString */:\n          {\n            if (!this.currentSimpleTagName) break;\n            const value = readUnicodeString(slice, size);\n            this.processTagValue(this.currentSimpleTagName, value);\n          }\n          ;\n          break;\n        case 17541 /* TagBinary */:\n          {\n            if (!this.currentSimpleTagName) break;\n            const value = readBytes(slice, size);\n            this.processTagValue(this.currentSimpleTagName, value);\n          }\n          ;\n          break;\n        case 24999 /* AttachedFile */:\n          {\n            if (!this.currentSegment) break;\n            this.currentAttachedFile = {\n              fileUid: null,\n              fileName: null,\n              fileMediaType: null,\n              fileData: null,\n              fileDescription: null\n            };\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n            const tags = this.currentSegment.metadataTags;\n            if (this.currentAttachedFile.fileUid && this.currentAttachedFile.fileData) {\n              tags.raw ??= {};\n              tags.raw[this.currentAttachedFile.fileUid.toString()] = new AttachedFile(\n                this.currentAttachedFile.fileData,\n                this.currentAttachedFile.fileMediaType ?? void 0,\n                this.currentAttachedFile.fileName ?? void 0,\n                this.currentAttachedFile.fileDescription ?? void 0\n              );\n            }\n            if (this.currentAttachedFile.fileMediaType?.startsWith(\"image/\") && this.currentAttachedFile.fileData) {\n              const fileName = this.currentAttachedFile.fileName;\n              let kind = \"unknown\";\n              if (fileName) {\n                const lowerName = fileName.toLowerCase();\n                if (lowerName.startsWith(\"cover.\")) {\n                  kind = \"coverFront\";\n                } else if (lowerName.startsWith(\"back.\")) {\n                  kind = \"coverBack\";\n                }\n              }\n              tags.images ??= [];\n              tags.images.push({\n                data: this.currentAttachedFile.fileData,\n                mimeType: this.currentAttachedFile.fileMediaType,\n                kind,\n                name: this.currentAttachedFile.fileName ?? void 0,\n                description: this.currentAttachedFile.fileDescription ?? void 0\n              });\n            }\n            this.currentAttachedFile = null;\n          }\n          ;\n          break;\n        case 18094 /* FileUID */:\n          {\n            if (!this.currentAttachedFile) break;\n            this.currentAttachedFile.fileUid = readUnsignedBigInt(slice, size);\n          }\n          ;\n          break;\n        case 18030 /* FileName */:\n          {\n            if (!this.currentAttachedFile) break;\n            this.currentAttachedFile.fileName = readUnicodeString(slice, size);\n          }\n          ;\n          break;\n        case 18016 /* FileMediaType */:\n          {\n            if (!this.currentAttachedFile) break;\n            this.currentAttachedFile.fileMediaType = readAsciiString(slice, size);\n          }\n          ;\n          break;\n        case 18012 /* FileData */:\n          {\n            if (!this.currentAttachedFile) break;\n            this.currentAttachedFile.fileData = readBytes(slice, size);\n          }\n          ;\n          break;\n        case 18046 /* FileDescription */:\n          {\n            if (!this.currentAttachedFile) break;\n            this.currentAttachedFile.fileDescription = readUnicodeString(slice, size);\n          }\n          ;\n          break;\n        case 28032 /* ContentEncodings */:\n          {\n            if (!this.currentTrack) break;\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n            this.currentTrack.decodingInstructions.sort((a, b) => b.order - a.order);\n          }\n          ;\n          break;\n        case 25152 /* ContentEncoding */:\n          {\n            this.currentDecodingInstruction = {\n              order: 0,\n              scope: 1 /* Block */,\n              data: null\n            };\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n            if (this.currentDecodingInstruction.data) {\n              this.currentTrack.decodingInstructions.push(this.currentDecodingInstruction);\n            }\n            this.currentDecodingInstruction = null;\n          }\n          ;\n          break;\n        case 20529 /* ContentEncodingOrder */:\n          {\n            if (!this.currentDecodingInstruction) break;\n            this.currentDecodingInstruction.order = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 20530 /* ContentEncodingScope */:\n          {\n            if (!this.currentDecodingInstruction) break;\n            this.currentDecodingInstruction.scope = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 20532 /* ContentCompression */:\n          {\n            if (!this.currentDecodingInstruction) break;\n            this.currentDecodingInstruction.data = {\n              type: \"decompress\",\n              algorithm: 0 /* Zlib */,\n              settings: null\n            };\n            this.readContiguousElements(slice.slice(dataStartPos, size));\n          }\n          ;\n          break;\n        case 16980 /* ContentCompAlgo */:\n          {\n            if (this.currentDecodingInstruction?.data?.type !== \"decompress\") break;\n            this.currentDecodingInstruction.data.algorithm = readUnsignedInt(slice, size);\n          }\n          ;\n          break;\n        case 16981 /* ContentCompSettings */:\n          {\n            if (this.currentDecodingInstruction?.data?.type !== \"decompress\") break;\n            this.currentDecodingInstruction.data.settings = readBytes(slice, size);\n          }\n          ;\n          break;\n        case 20533 /* ContentEncryption */:\n          {\n            if (!this.currentDecodingInstruction) break;\n            this.currentDecodingInstruction.data = {\n              type: \"decrypt\"\n            };\n          }\n          ;\n          break;\n      }\n      slice.filePos = dataStartPos + size;\n      return true;\n    }\n    decodeBlockData(track, rawData) {\n      assert(track.decodingInstructions.length > 0);\n      let currentData = rawData;\n      for (const instruction of track.decodingInstructions) {\n        assert(instruction.data);\n        switch (instruction.data.type) {\n          case \"decompress\":\n            {\n              switch (instruction.data.algorithm) {\n                case 3 /* HeaderStripping */:\n                  {\n                    if (instruction.data.settings && instruction.data.settings.length > 0) {\n                      const prefix = instruction.data.settings;\n                      const newData = new Uint8Array(prefix.length + currentData.length);\n                      newData.set(prefix, 0);\n                      newData.set(currentData, prefix.length);\n                      currentData = newData;\n                    }\n                  }\n                  ;\n                  break;\n                default:\n                  {\n                  }\n                  ;\n              }\n            }\n            ;\n            break;\n          default:\n            {\n            }\n            ;\n        }\n      }\n      return currentData;\n    }\n    processTagValue(name, value) {\n      if (!this.currentSegment?.metadataTags) return;\n      const metadataTags = this.currentSegment.metadataTags;\n      metadataTags.raw ??= {};\n      metadataTags.raw[name] ??= value;\n      if (typeof value === \"string\") {\n        switch (name.toLowerCase()) {\n          case \"title\":\n            {\n              metadataTags.title ??= value;\n            }\n            ;\n            break;\n          case \"description\":\n            {\n              metadataTags.description ??= value;\n            }\n            ;\n            break;\n          case \"artist\":\n            {\n              metadataTags.artist ??= value;\n            }\n            ;\n            break;\n          case \"album\":\n            {\n              metadataTags.album ??= value;\n            }\n            ;\n            break;\n          case \"album_artist\":\n            {\n              metadataTags.albumArtist ??= value;\n            }\n            ;\n            break;\n          case \"genre\":\n            {\n              metadataTags.genre ??= value;\n            }\n            ;\n            break;\n          case \"comment\":\n            {\n              metadataTags.comment ??= value;\n            }\n            ;\n            break;\n          case \"lyrics\":\n            {\n              metadataTags.lyrics ??= value;\n            }\n            ;\n            break;\n          case \"date\":\n            {\n              const date = new Date(value);\n              if (!Number.isNaN(date.getTime())) {\n                metadataTags.date ??= date;\n              }\n            }\n            ;\n            break;\n          case \"track_number\":\n          case \"part_number\":\n            {\n              const parts = value.split(\"/\");\n              const trackNum = Number.parseInt(parts[0], 10);\n              const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);\n              if (Number.isInteger(trackNum) && trackNum > 0) {\n                metadataTags.trackNumber ??= trackNum;\n              }\n              if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {\n                metadataTags.tracksTotal ??= tracksTotal;\n              }\n            }\n            ;\n            break;\n          case \"disc_number\":\n          case \"disc\":\n            {\n              const discParts = value.split(\"/\");\n              const discNum = Number.parseInt(discParts[0], 10);\n              const discsTotal = discParts[1] && Number.parseInt(discParts[1], 10);\n              if (Number.isInteger(discNum) && discNum > 0) {\n                metadataTags.discNumber ??= discNum;\n              }\n              if (discsTotal && Number.isInteger(discsTotal) && discsTotal > 0) {\n                metadataTags.discsTotal ??= discsTotal;\n              }\n            }\n            ;\n            break;\n        }\n      }\n    }\n  };\n  var MatroskaTrackBacking = class {\n    constructor(internalTrack) {\n      this.internalTrack = internalTrack;\n      this.packetToClusterLocation = /* @__PURE__ */ new WeakMap();\n    }\n    getId() {\n      return this.internalTrack.id;\n    }\n    getCodec() {\n      throw new Error(\"Not implemented on base class.\");\n    }\n    getInternalCodecId() {\n      return this.internalTrack.codecId;\n    }\n    async computeDuration() {\n      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n    }\n    getName() {\n      return this.internalTrack.name;\n    }\n    getLanguageCode() {\n      return this.internalTrack.languageCode;\n    }\n    async getFirstTimestamp() {\n      const firstPacket = await this.getFirstPacket({ metadataOnly: true });\n      return firstPacket?.timestamp ?? 0;\n    }\n    getTimeResolution() {\n      return this.internalTrack.segment.timestampFactor;\n    }\n    getDisposition() {\n      return this.internalTrack.disposition;\n    }\n    async getFirstPacket(options) {\n      return this.performClusterLookup(\n        null,\n        (cluster) => {\n          const trackData = cluster.trackData.get(this.internalTrack.id);\n          if (trackData) {\n            return {\n              blockIndex: 0,\n              correctBlockFound: true\n            };\n          }\n          return {\n            blockIndex: -1,\n            correctBlockFound: false\n          };\n        },\n        -Infinity,\n        // Use -Infinity as a search timestamp to avoid using the cues\n        Infinity,\n        options\n      );\n    }\n    intoTimescale(timestamp) {\n      return roundIfAlmostInteger(timestamp * this.internalTrack.segment.timestampFactor);\n    }\n    async getPacket(timestamp, options) {\n      const timestampInTimescale = this.intoTimescale(timestamp);\n      return this.performClusterLookup(\n        null,\n        (cluster) => {\n          const trackData = cluster.trackData.get(this.internalTrack.id);\n          if (!trackData) {\n            return { blockIndex: -1, correctBlockFound: false };\n          }\n          const index = binarySearchLessOrEqual(\n            trackData.presentationTimestamps,\n            timestampInTimescale,\n            (x) => x.timestamp\n          );\n          const blockIndex = index !== -1 ? trackData.presentationTimestamps[index].blockIndex : -1;\n          const correctBlockFound = index !== -1 && timestampInTimescale < trackData.endTimestamp;\n          return { blockIndex, correctBlockFound };\n        },\n        timestampInTimescale,\n        timestampInTimescale,\n        options\n      );\n    }\n    async getNextPacket(packet, options) {\n      const locationInCluster = this.packetToClusterLocation.get(packet);\n      if (locationInCluster === void 0) {\n        throw new Error(\"Packet was not created from this track.\");\n      }\n      return this.performClusterLookup(\n        locationInCluster.cluster,\n        (cluster) => {\n          if (cluster === locationInCluster.cluster) {\n            const trackData = cluster.trackData.get(this.internalTrack.id);\n            if (locationInCluster.blockIndex + 1 < trackData.blocks.length) {\n              return {\n                blockIndex: locationInCluster.blockIndex + 1,\n                correctBlockFound: true\n              };\n            }\n          } else {\n            const trackData = cluster.trackData.get(this.internalTrack.id);\n            if (trackData) {\n              return {\n                blockIndex: 0,\n                correctBlockFound: true\n              };\n            }\n          }\n          return {\n            blockIndex: -1,\n            correctBlockFound: false\n          };\n        },\n        -Infinity,\n        // Use -Infinity as a search timestamp to avoid using the cues\n        Infinity,\n        options\n      );\n    }\n    async getKeyPacket(timestamp, options) {\n      const timestampInTimescale = this.intoTimescale(timestamp);\n      return this.performClusterLookup(\n        null,\n        (cluster) => {\n          const trackData = cluster.trackData.get(this.internalTrack.id);\n          if (!trackData) {\n            return { blockIndex: -1, correctBlockFound: false };\n          }\n          const index = findLastIndex(trackData.presentationTimestamps, (x) => {\n            const block = trackData.blocks[x.blockIndex];\n            return block.isKeyFrame && x.timestamp <= timestampInTimescale;\n          });\n          const blockIndex = index !== -1 ? trackData.presentationTimestamps[index].blockIndex : -1;\n          const correctBlockFound = index !== -1 && timestampInTimescale < trackData.endTimestamp;\n          return { blockIndex, correctBlockFound };\n        },\n        timestampInTimescale,\n        timestampInTimescale,\n        options\n      );\n    }\n    async getNextKeyPacket(packet, options) {\n      const locationInCluster = this.packetToClusterLocation.get(packet);\n      if (locationInCluster === void 0) {\n        throw new Error(\"Packet was not created from this track.\");\n      }\n      return this.performClusterLookup(\n        locationInCluster.cluster,\n        (cluster) => {\n          if (cluster === locationInCluster.cluster) {\n            const trackData = cluster.trackData.get(this.internalTrack.id);\n            const nextKeyFrameIndex = trackData.blocks.findIndex(\n              (x, i) => x.isKeyFrame && i > locationInCluster.blockIndex\n            );\n            if (nextKeyFrameIndex !== -1) {\n              return {\n                blockIndex: nextKeyFrameIndex,\n                correctBlockFound: true\n              };\n            }\n          } else {\n            const trackData = cluster.trackData.get(this.internalTrack.id);\n            if (trackData && trackData.firstKeyFrameTimestamp !== null) {\n              const keyFrameIndex = trackData.blocks.findIndex((x) => x.isKeyFrame);\n              assert(keyFrameIndex !== -1);\n              return {\n                blockIndex: keyFrameIndex,\n                correctBlockFound: true\n              };\n            }\n          }\n          return {\n            blockIndex: -1,\n            correctBlockFound: false\n          };\n        },\n        -Infinity,\n        // Use -Infinity as a search timestamp to avoid using the cues\n        Infinity,\n        options\n      );\n    }\n    async fetchPacketInCluster(cluster, blockIndex, options) {\n      if (blockIndex === -1) {\n        return null;\n      }\n      const trackData = cluster.trackData.get(this.internalTrack.id);\n      const block = trackData.blocks[blockIndex];\n      assert(block);\n      if (!block.decoded) {\n        block.data = this.internalTrack.demuxer.decodeBlockData(this.internalTrack, block.data);\n        block.decoded = true;\n      }\n      const data = options.metadataOnly ? PLACEHOLDER_DATA : block.data;\n      const timestamp = block.timestamp / this.internalTrack.segment.timestampFactor;\n      const duration = block.duration / this.internalTrack.segment.timestampFactor;\n      const sideData = {};\n      if (block.mainAdditional && this.internalTrack.info?.type === \"video\" && this.internalTrack.info.alphaMode) {\n        sideData.alpha = options.metadataOnly ? PLACEHOLDER_DATA : block.mainAdditional;\n        sideData.alphaByteLength = block.mainAdditional.byteLength;\n      }\n      const packet = new EncodedPacket(\n        data,\n        block.isKeyFrame ? \"key\" : \"delta\",\n        timestamp,\n        duration,\n        cluster.dataStartPos + blockIndex,\n        block.data.byteLength,\n        sideData\n      );\n      this.packetToClusterLocation.set(packet, { cluster, blockIndex });\n      return packet;\n    }\n    /** Looks for a packet in the clusters while trying to load as few clusters as possible to retrieve it. */\n    async performClusterLookup(startCluster, getMatchInCluster, searchTimestamp, latestTimestamp, options) {\n      const { demuxer, segment } = this.internalTrack;\n      let currentCluster = null;\n      let bestCluster = null;\n      let bestBlockIndex = -1;\n      if (startCluster) {\n        const { blockIndex, correctBlockFound } = getMatchInCluster(startCluster);\n        if (correctBlockFound) {\n          return this.fetchPacketInCluster(startCluster, blockIndex, options);\n        }\n        if (blockIndex !== -1) {\n          bestCluster = startCluster;\n          bestBlockIndex = blockIndex;\n        }\n      }\n      const cuePointIndex = binarySearchLessOrEqual(\n        this.internalTrack.cuePoints,\n        searchTimestamp,\n        (x) => x.time\n      );\n      const cuePoint = cuePointIndex !== -1 ? this.internalTrack.cuePoints[cuePointIndex] : null;\n      const positionCacheIndex = binarySearchLessOrEqual(\n        this.internalTrack.clusterPositionCache,\n        searchTimestamp,\n        (x) => x.startTimestamp\n      );\n      const positionCacheEntry = positionCacheIndex !== -1 ? this.internalTrack.clusterPositionCache[positionCacheIndex] : null;\n      const lookupEntryPosition = Math.max(\n        cuePoint?.clusterPosition ?? 0,\n        positionCacheEntry?.elementStartPos ?? 0\n      ) || null;\n      let currentPos;\n      if (!startCluster) {\n        currentPos = lookupEntryPosition ?? segment.clusterSeekStartPos;\n      } else {\n        if (lookupEntryPosition === null || startCluster.elementStartPos >= lookupEntryPosition) {\n          currentPos = startCluster.elementEndPos;\n          currentCluster = startCluster;\n        } else {\n          currentPos = lookupEntryPosition;\n        }\n      }\n      while (segment.elementEndPos === null || currentPos <= segment.elementEndPos - MIN_HEADER_SIZE) {\n        if (currentCluster) {\n          const trackData = currentCluster.trackData.get(this.internalTrack.id);\n          if (trackData && trackData.startTimestamp > latestTimestamp) {\n            break;\n          }\n        }\n        let slice = demuxer.reader.requestSliceRange(currentPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n        if (slice instanceof Promise) slice = await slice;\n        if (!slice) break;\n        const elementStartPos = currentPos;\n        const elementHeader = readElementHeader(slice);\n        if (!elementHeader || !LEVEL_1_EBML_IDS.includes(elementHeader.id) && elementHeader.id !== 236 /* Void */) {\n          const nextPos = await resync(\n            demuxer.reader,\n            elementStartPos,\n            LEVEL_1_EBML_IDS,\n            Math.min(segment.elementEndPos ?? Infinity, elementStartPos + MAX_RESYNC_LENGTH)\n          );\n          if (nextPos) {\n            currentPos = nextPos;\n            continue;\n          } else {\n            break;\n          }\n        }\n        const id = elementHeader.id;\n        let size = elementHeader.size;\n        const dataStartPos = slice.filePos;\n        if (id === 524531317 /* Cluster */) {\n          currentCluster = await demuxer.readCluster(elementStartPos, segment);\n          size = currentCluster.elementEndPos - dataStartPos;\n          const { blockIndex, correctBlockFound } = getMatchInCluster(currentCluster);\n          if (correctBlockFound) {\n            return this.fetchPacketInCluster(currentCluster, blockIndex, options);\n          }\n          if (blockIndex !== -1) {\n            bestCluster = currentCluster;\n            bestBlockIndex = blockIndex;\n          }\n        }\n        if (size === void 0) {\n          assert(id !== 524531317 /* Cluster */);\n          const nextElementPos = await searchForNextElementId(\n            demuxer.reader,\n            dataStartPos,\n            LEVEL_0_AND_1_EBML_IDS,\n            segment.elementEndPos\n          );\n          size = nextElementPos.pos - dataStartPos;\n        }\n        const endPos = dataStartPos + size;\n        if (segment.elementEndPos === null) {\n          let slice2 = demuxer.reader.requestSliceRange(endPos, MIN_HEADER_SIZE, MAX_HEADER_SIZE);\n          if (slice2 instanceof Promise) slice2 = await slice2;\n          if (!slice2) break;\n          const elementId = readElementId(slice2);\n          if (elementId === 408125543 /* Segment */) {\n            segment.elementEndPos = endPos;\n            break;\n          }\n        }\n        currentPos = endPos;\n      }\n      if (cuePoint && (!bestCluster || bestCluster.elementStartPos < cuePoint.clusterPosition)) {\n        const previousCuePoint = this.internalTrack.cuePoints[cuePointIndex - 1];\n        assert(!previousCuePoint || previousCuePoint.time < cuePoint.time);\n        const newSearchTimestamp = previousCuePoint?.time ?? -Infinity;\n        return this.performClusterLookup(null, getMatchInCluster, newSearchTimestamp, latestTimestamp, options);\n      }\n      if (bestCluster) {\n        return this.fetchPacketInCluster(bestCluster, bestBlockIndex, options);\n      }\n      return null;\n    }\n  };\n  var MatroskaVideoTrackBacking = class extends MatroskaTrackBacking {\n    constructor(internalTrack) {\n      super(internalTrack);\n      this.decoderConfigPromise = null;\n      this.internalTrack = internalTrack;\n    }\n    getCodec() {\n      return this.internalTrack.info.codec;\n    }\n    getCodedWidth() {\n      return this.internalTrack.info.width;\n    }\n    getCodedHeight() {\n      return this.internalTrack.info.height;\n    }\n    getRotation() {\n      return this.internalTrack.info.rotation;\n    }\n    async getColorSpace() {\n      return {\n        primaries: this.internalTrack.info.colorSpace?.primaries,\n        transfer: this.internalTrack.info.colorSpace?.transfer,\n        matrix: this.internalTrack.info.colorSpace?.matrix,\n        fullRange: this.internalTrack.info.colorSpace?.fullRange\n      };\n    }\n    async canBeTransparent() {\n      return this.internalTrack.info.alphaMode;\n    }\n    async getDecoderConfig() {\n      if (!this.internalTrack.info.codec) {\n        return null;\n      }\n      return this.decoderConfigPromise ??= (async () => {\n        let firstPacket = null;\n        const needsPacketForAdditionalInfo = this.internalTrack.info.codec === \"vp9\" || this.internalTrack.info.codec === \"av1\" || this.internalTrack.info.codec === \"avc\" && !this.internalTrack.info.codecDescription || this.internalTrack.info.codec === \"hevc\" && !this.internalTrack.info.codecDescription;\n        if (needsPacketForAdditionalInfo) {\n          firstPacket = await this.getFirstPacket({});\n        }\n        return {\n          codec: extractVideoCodecString({\n            width: this.internalTrack.info.width,\n            height: this.internalTrack.info.height,\n            codec: this.internalTrack.info.codec,\n            codecDescription: this.internalTrack.info.codecDescription,\n            colorSpace: this.internalTrack.info.colorSpace,\n            avcType: 1,\n            // We don't know better (or do we?) so just assume 'avc1'\n            avcCodecInfo: this.internalTrack.info.codec === \"avc\" && firstPacket ? extractAvcDecoderConfigurationRecord(firstPacket.data) : null,\n            hevcCodecInfo: this.internalTrack.info.codec === \"hevc\" && firstPacket ? extractHevcDecoderConfigurationRecord(firstPacket.data) : null,\n            vp9CodecInfo: this.internalTrack.info.codec === \"vp9\" && firstPacket ? extractVp9CodecInfoFromPacket(firstPacket.data) : null,\n            av1CodecInfo: this.internalTrack.info.codec === \"av1\" && firstPacket ? extractAv1CodecInfoFromPacket(firstPacket.data) : null\n          }),\n          codedWidth: this.internalTrack.info.width,\n          codedHeight: this.internalTrack.info.height,\n          description: this.internalTrack.info.codecDescription ?? void 0,\n          colorSpace: this.internalTrack.info.colorSpace ?? void 0\n        };\n      })();\n    }\n  };\n  var MatroskaAudioTrackBacking = class extends MatroskaTrackBacking {\n    constructor(internalTrack) {\n      super(internalTrack);\n      this.decoderConfig = null;\n      this.internalTrack = internalTrack;\n    }\n    getCodec() {\n      return this.internalTrack.info.codec;\n    }\n    getNumberOfChannels() {\n      return this.internalTrack.info.numberOfChannels;\n    }\n    getSampleRate() {\n      return this.internalTrack.info.sampleRate;\n    }\n    async getDecoderConfig() {\n      if (!this.internalTrack.info.codec) {\n        return null;\n      }\n      return this.decoderConfig ??= {\n        codec: extractAudioCodecString({\n          codec: this.internalTrack.info.codec,\n          codecDescription: this.internalTrack.info.codecDescription,\n          aacCodecInfo: this.internalTrack.info.aacCodecInfo\n        }),\n        numberOfChannels: this.internalTrack.info.numberOfChannels,\n        sampleRate: this.internalTrack.info.sampleRate,\n        description: this.internalTrack.info.codecDescription ?? void 0\n      };\n    }\n  };\n\n  // shared/mp3-misc.ts\n  var FRAME_HEADER_SIZE = 4;\n  var SAMPLING_RATES = [44100, 48e3, 32e3];\n  var KILOBIT_RATES = [\n    // lowSamplingFrequency === 0\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    // layer = 0\n    -1,\n    32,\n    40,\n    48,\n    56,\n    64,\n    80,\n    96,\n    112,\n    128,\n    160,\n    192,\n    224,\n    256,\n    320,\n    -1,\n    // layer 1\n    -1,\n    32,\n    48,\n    56,\n    64,\n    80,\n    96,\n    112,\n    128,\n    160,\n    192,\n    224,\n    256,\n    320,\n    384,\n    -1,\n    // layer = 2\n    -1,\n    32,\n    64,\n    96,\n    128,\n    160,\n    192,\n    224,\n    256,\n    288,\n    320,\n    352,\n    384,\n    416,\n    448,\n    -1,\n    // layer = 3\n    // lowSamplingFrequency === 1\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    -1,\n    // layer = 0\n    -1,\n    8,\n    16,\n    24,\n    32,\n    40,\n    48,\n    56,\n    64,\n    80,\n    96,\n    112,\n    128,\n    144,\n    160,\n    -1,\n    // layer = 1\n    -1,\n    8,\n    16,\n    24,\n    32,\n    40,\n    48,\n    56,\n    64,\n    80,\n    96,\n    112,\n    128,\n    144,\n    160,\n    -1,\n    // layer = 2\n    -1,\n    32,\n    48,\n    56,\n    64,\n    80,\n    96,\n    112,\n    128,\n    144,\n    160,\n    176,\n    192,\n    224,\n    256,\n    -1\n    // layer = 3\n  ];\n  var XING = 1483304551;\n  var INFO = 1231971951;\n  var computeMp3FrameSize = (lowSamplingFrequency, layer, bitrate, sampleRate, padding) => {\n    if (layer === 0) {\n      return 0;\n    } else if (layer === 1) {\n      return Math.floor(144 * bitrate / (sampleRate << lowSamplingFrequency)) + padding;\n    } else if (layer === 2) {\n      return Math.floor(144 * bitrate / sampleRate) + padding;\n    } else {\n      return (Math.floor(12 * bitrate / sampleRate) + padding) * 4;\n    }\n  };\n  var getXingOffset = (mpegVersionId, channel) => {\n    return mpegVersionId === 3 ? channel === 3 ? 21 : 36 : channel === 3 ? 13 : 21;\n  };\n  var readMp3FrameHeader = (word, remainingBytes) => {\n    const firstByte = word >>> 24;\n    const secondByte = word >>> 16 & 255;\n    const thirdByte = word >>> 8 & 255;\n    const fourthByte = word & 255;\n    if (firstByte !== 255 && secondByte !== 255 && thirdByte !== 255 && fourthByte !== 255) {\n      return {\n        header: null,\n        bytesAdvanced: 4\n      };\n    }\n    if (firstByte !== 255) {\n      return { header: null, bytesAdvanced: 1 };\n    }\n    if ((secondByte & 224) !== 224) {\n      return { header: null, bytesAdvanced: 1 };\n    }\n    let lowSamplingFrequency = 0;\n    let mpeg25 = 0;\n    if (secondByte & 1 << 4) {\n      lowSamplingFrequency = secondByte & 1 << 3 ? 0 : 1;\n    } else {\n      lowSamplingFrequency = 1;\n      mpeg25 = 1;\n    }\n    const mpegVersionId = secondByte >> 3 & 3;\n    const layer = secondByte >> 1 & 3;\n    const bitrateIndex = thirdByte >> 4 & 15;\n    const frequencyIndex = (thirdByte >> 2 & 3) % 3;\n    const padding = thirdByte >> 1 & 1;\n    const channel = fourthByte >> 6 & 3;\n    const modeExtension = fourthByte >> 4 & 3;\n    const copyright = fourthByte >> 3 & 1;\n    const original = fourthByte >> 2 & 1;\n    const emphasis = fourthByte & 3;\n    const kilobitRate = KILOBIT_RATES[lowSamplingFrequency * 16 * 4 + layer * 16 + bitrateIndex];\n    if (kilobitRate === -1) {\n      return { header: null, bytesAdvanced: 1 };\n    }\n    const bitrate = kilobitRate * 1e3;\n    const sampleRate = SAMPLING_RATES[frequencyIndex] >> lowSamplingFrequency + mpeg25;\n    const frameLength = computeMp3FrameSize(lowSamplingFrequency, layer, bitrate, sampleRate, padding);\n    if (remainingBytes !== null && remainingBytes < frameLength) {\n      return { header: null, bytesAdvanced: 1 };\n    }\n    let audioSamplesInFrame;\n    if (mpegVersionId === 3) {\n      audioSamplesInFrame = layer === 3 ? 384 : 1152;\n    } else {\n      if (layer === 3) {\n        audioSamplesInFrame = 384;\n      } else if (layer === 2) {\n        audioSamplesInFrame = 1152;\n      } else {\n        audioSamplesInFrame = 576;\n      }\n    }\n    return {\n      header: {\n        totalSize: frameLength,\n        mpegVersionId,\n        layer,\n        bitrate,\n        frequencyIndex,\n        sampleRate,\n        channel,\n        modeExtension,\n        copyright,\n        original,\n        emphasis,\n        audioSamplesInFrame\n      },\n      bytesAdvanced: 1\n    };\n  };\n  var encodeSynchsafe = (unsynchsafed) => {\n    let mask = 127;\n    let synchsafed = 0;\n    let unsynchsafedRest = unsynchsafed;\n    while ((mask ^ 2147483647) !== 0) {\n      synchsafed = unsynchsafedRest & ~mask;\n      synchsafed <<= 1;\n      synchsafed |= unsynchsafedRest & mask;\n      mask = (mask + 1 << 8) - 1;\n      unsynchsafedRest = synchsafed;\n    }\n    return synchsafed;\n  };\n  var decodeSynchsafe = (synchsafed) => {\n    let mask = 2130706432;\n    let unsynchsafed = 0;\n    while (mask !== 0) {\n      unsynchsafed >>= 1;\n      unsynchsafed |= synchsafed & mask;\n      mask >>= 8;\n    }\n    return unsynchsafed;\n  };\n\n  // src/id3.ts\n  var ID3_V1_TAG_SIZE = 128;\n  var ID3_V2_HEADER_SIZE = 10;\n  var ID3_V1_GENRES = [\n    \"Blues\",\n    \"Classic rock\",\n    \"Country\",\n    \"Dance\",\n    \"Disco\",\n    \"Funk\",\n    \"Grunge\",\n    \"Hip-hop\",\n    \"Jazz\",\n    \"Metal\",\n    \"New age\",\n    \"Oldies\",\n    \"Other\",\n    \"Pop\",\n    \"Rhythm and blues\",\n    \"Rap\",\n    \"Reggae\",\n    \"Rock\",\n    \"Techno\",\n    \"Industrial\",\n    \"Alternative\",\n    \"Ska\",\n    \"Death metal\",\n    \"Pranks\",\n    \"Soundtrack\",\n    \"Euro-techno\",\n    \"Ambient\",\n    \"Trip-hop\",\n    \"Vocal\",\n    \"Jazz & funk\",\n    \"Fusion\",\n    \"Trance\",\n    \"Classical\",\n    \"Instrumental\",\n    \"Acid\",\n    \"House\",\n    \"Game\",\n    \"Sound clip\",\n    \"Gospel\",\n    \"Noise\",\n    \"Alternative rock\",\n    \"Bass\",\n    \"Soul\",\n    \"Punk\",\n    \"Space\",\n    \"Meditative\",\n    \"Instrumental pop\",\n    \"Instrumental rock\",\n    \"Ethnic\",\n    \"Gothic\",\n    \"Darkwave\",\n    \"Techno-industrial\",\n    \"Electronic\",\n    \"Pop-folk\",\n    \"Eurodance\",\n    \"Dream\",\n    \"Southern rock\",\n    \"Comedy\",\n    \"Cult\",\n    \"Gangsta\",\n    \"Top 40\",\n    \"Christian rap\",\n    \"Pop/funk\",\n    \"Jungle music\",\n    \"Native US\",\n    \"Cabaret\",\n    \"New wave\",\n    \"Psychedelic\",\n    \"Rave\",\n    \"Showtunes\",\n    \"Trailer\",\n    \"Lo-fi\",\n    \"Tribal\",\n    \"Acid punk\",\n    \"Acid jazz\",\n    \"Polka\",\n    \"Retro\",\n    \"Musical\",\n    \"Rock 'n' roll\",\n    \"Hard rock\",\n    \"Folk\",\n    \"Folk rock\",\n    \"National folk\",\n    \"Swing\",\n    \"Fast fusion\",\n    \"Bebop\",\n    \"Latin\",\n    \"Revival\",\n    \"Celtic\",\n    \"Bluegrass\",\n    \"Avantgarde\",\n    \"Gothic rock\",\n    \"Progressive rock\",\n    \"Psychedelic rock\",\n    \"Symphonic rock\",\n    \"Slow rock\",\n    \"Big band\",\n    \"Chorus\",\n    \"Easy listening\",\n    \"Acoustic\",\n    \"Humour\",\n    \"Speech\",\n    \"Chanson\",\n    \"Opera\",\n    \"Chamber music\",\n    \"Sonata\",\n    \"Symphony\",\n    \"Booty bass\",\n    \"Primus\",\n    \"Porn groove\",\n    \"Satire\",\n    \"Slow jam\",\n    \"Club\",\n    \"Tango\",\n    \"Samba\",\n    \"Folklore\",\n    \"Ballad\",\n    \"Power ballad\",\n    \"Rhythmic Soul\",\n    \"Freestyle\",\n    \"Duet\",\n    \"Punk rock\",\n    \"Drum solo\",\n    \"A cappella\",\n    \"Euro-house\",\n    \"Dance hall\",\n    \"Goa music\",\n    \"Drum & bass\",\n    \"Club-house\",\n    \"Hardcore techno\",\n    \"Terror\",\n    \"Indie\",\n    \"Britpop\",\n    \"Negerpunk\",\n    \"Polsk punk\",\n    \"Beat\",\n    \"Christian gangsta rap\",\n    \"Heavy metal\",\n    \"Black metal\",\n    \"Crossover\",\n    \"Contemporary Christian\",\n    \"Christian rock\",\n    \"Merengue\",\n    \"Salsa\",\n    \"Thrash metal\",\n    \"Anime\",\n    \"Jpop\",\n    \"Synthpop\",\n    \"Christmas\",\n    \"Art rock\",\n    \"Baroque\",\n    \"Bhangra\",\n    \"Big beat\",\n    \"Breakbeat\",\n    \"Chillout\",\n    \"Downtempo\",\n    \"Dub\",\n    \"EBM\",\n    \"Eclectic\",\n    \"Electro\",\n    \"Electroclash\",\n    \"Emo\",\n    \"Experimental\",\n    \"Garage\",\n    \"Global\",\n    \"IDM\",\n    \"Illbient\",\n    \"Industro-Goth\",\n    \"Jam Band\",\n    \"Krautrock\",\n    \"Leftfield\",\n    \"Lounge\",\n    \"Math rock\",\n    \"New romantic\",\n    \"Nu-breakz\",\n    \"Post-punk\",\n    \"Post-rock\",\n    \"Psytrance\",\n    \"Shoegaze\",\n    \"Space rock\",\n    \"Trop rock\",\n    \"World music\",\n    \"Neoclassical\",\n    \"Audiobook\",\n    \"Audio theatre\",\n    \"Neue Deutsche Welle\",\n    \"Podcast\",\n    \"Indie rock\",\n    \"G-Funk\",\n    \"Dubstep\",\n    \"Garage rock\",\n    \"Psybient\"\n  ];\n  var parseId3V1Tag = (slice, tags) => {\n    const startPos = slice.filePos;\n    tags.raw ??= {};\n    tags.raw[\"TAG\"] ??= readBytes(slice, ID3_V1_TAG_SIZE - 3);\n    slice.filePos = startPos;\n    const title = readId3V1String(slice, 30);\n    if (title) tags.title ??= title;\n    const artist = readId3V1String(slice, 30);\n    if (artist) tags.artist ??= artist;\n    const album = readId3V1String(slice, 30);\n    if (album) tags.album ??= album;\n    const yearText = readId3V1String(slice, 4);\n    const year = Number.parseInt(yearText, 10);\n    if (Number.isInteger(year) && year > 0) {\n      tags.date ??= new Date(year, 0, 1);\n    }\n    const commentBytes = readBytes(slice, 30);\n    let comment;\n    if (commentBytes[28] === 0 && commentBytes[29] !== 0) {\n      const trackNum = commentBytes[29];\n      if (trackNum > 0) {\n        tags.trackNumber ??= trackNum;\n      }\n      slice.skip(-30);\n      comment = readId3V1String(slice, 28);\n      slice.skip(2);\n    } else {\n      slice.skip(-30);\n      comment = readId3V1String(slice, 30);\n    }\n    if (comment) tags.comment ??= comment;\n    const genreIndex = readU8(slice);\n    if (genreIndex < ID3_V1_GENRES.length) {\n      tags.genre ??= ID3_V1_GENRES[genreIndex];\n    }\n  };\n  var readId3V1String = (slice, length) => {\n    const bytes2 = readBytes(slice, length);\n    const endIndex = coalesceIndex(bytes2.indexOf(0), bytes2.length);\n    const relevantBytes = bytes2.subarray(0, endIndex);\n    let str = \"\";\n    for (let i = 0; i < relevantBytes.length; i++) {\n      str += String.fromCharCode(relevantBytes[i]);\n    }\n    return str.trimEnd();\n  };\n  var readId3V2Header = (slice) => {\n    const startPos = slice.filePos;\n    const tag = readAscii(slice, 3);\n    const majorVersion = readU8(slice);\n    const revision = readU8(slice);\n    const flags = readU8(slice);\n    const sizeRaw = readU32Be(slice);\n    if (tag !== \"ID3\" || majorVersion === 255 || revision === 255 || (sizeRaw & 2155905152) !== 0) {\n      slice.filePos = startPos;\n      return null;\n    }\n    const size = decodeSynchsafe(sizeRaw);\n    return { majorVersion, revision, flags, size };\n  };\n  var parseId3V2Tag = (slice, header, tags) => {\n    if (![2, 3, 4].includes(header.majorVersion)) {\n      console.warn(`Unsupported ID3v2 major version: ${header.majorVersion}`);\n      return;\n    }\n    const bytes2 = readBytes(slice, header.size);\n    const reader = new Id3V2Reader(header, bytes2);\n    if (header.flags & 16 /* Footer */) {\n      reader.removeFooter();\n    }\n    if (header.flags & 128 /* Unsynchronisation */ && header.majorVersion === 3) {\n      reader.ununsynchronizeAll();\n    }\n    if (header.flags & 64 /* ExtendedHeader */) {\n      const extendedHeaderSize = reader.readU32();\n      if (header.majorVersion === 3) {\n        reader.pos += extendedHeaderSize;\n      } else {\n        reader.pos += extendedHeaderSize - 4;\n      }\n    }\n    while (reader.pos <= reader.bytes.length - reader.frameHeaderSize()) {\n      const frame = reader.readId3V2Frame();\n      if (!frame) {\n        break;\n      }\n      const frameStartPos = reader.pos;\n      const frameEndPos = reader.pos + frame.size;\n      let frameEncrypted = false;\n      let frameCompressed = false;\n      let frameUnsynchronized = false;\n      if (header.majorVersion === 3) {\n        frameEncrypted = !!(frame.flags & 1 << 6);\n        frameCompressed = !!(frame.flags & 1 << 7);\n      } else if (header.majorVersion === 4) {\n        frameEncrypted = !!(frame.flags & 1 << 2);\n        frameCompressed = !!(frame.flags & 1 << 3);\n        frameUnsynchronized = !!(frame.flags & 1 << 1) || !!(header.flags & 128 /* Unsynchronisation */);\n      }\n      if (frameEncrypted) {\n        console.warn(`Skipping encrypted ID3v2 frame ${frame.id}`);\n        reader.pos = frameEndPos;\n        continue;\n      }\n      if (frameCompressed) {\n        console.warn(`Skipping compressed ID3v2 frame ${frame.id}`);\n        reader.pos = frameEndPos;\n        continue;\n      }\n      if (frameUnsynchronized) {\n        reader.ununsynchronizeRegion(reader.pos, frameEndPos);\n      }\n      tags.raw ??= {};\n      if (frame.id[0] === \"T\") {\n        tags.raw[frame.id] ??= reader.readId3V2EncodingAndText(frameEndPos);\n      } else {\n        tags.raw[frame.id] ??= reader.readBytes(frame.size);\n      }\n      reader.pos = frameStartPos;\n      switch (frame.id) {\n        case \"TIT2\":\n        case \"TT2\":\n          {\n            tags.title ??= reader.readId3V2EncodingAndText(frameEndPos);\n          }\n          ;\n          break;\n        case \"TIT3\":\n        case \"TT3\":\n          {\n            tags.description ??= reader.readId3V2EncodingAndText(frameEndPos);\n          }\n          ;\n          break;\n        case \"TPE1\":\n        case \"TP1\":\n          {\n            tags.artist ??= reader.readId3V2EncodingAndText(frameEndPos);\n          }\n          ;\n          break;\n        case \"TALB\":\n        case \"TAL\":\n          {\n            tags.album ??= reader.readId3V2EncodingAndText(frameEndPos);\n          }\n          ;\n          break;\n        case \"TPE2\":\n        case \"TP2\":\n          {\n            tags.albumArtist ??= reader.readId3V2EncodingAndText(frameEndPos);\n          }\n          ;\n          break;\n        case \"TRCK\":\n        case \"TRK\":\n          {\n            const trackText = reader.readId3V2EncodingAndText(frameEndPos);\n            const parts = trackText.split(\"/\");\n            const trackNum = Number.parseInt(parts[0], 10);\n            const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);\n            if (Number.isInteger(trackNum) && trackNum > 0) {\n              tags.trackNumber ??= trackNum;\n            }\n            if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {\n              tags.tracksTotal ??= tracksTotal;\n            }\n          }\n          ;\n          break;\n        case \"TPOS\":\n        case \"TPA\":\n          {\n            const discText = reader.readId3V2EncodingAndText(frameEndPos);\n            const parts = discText.split(\"/\");\n            const discNum = Number.parseInt(parts[0], 10);\n            const discsTotal = parts[1] && Number.parseInt(parts[1], 10);\n            if (Number.isInteger(discNum) && discNum > 0) {\n              tags.discNumber ??= discNum;\n            }\n            if (discsTotal && Number.isInteger(discsTotal) && discsTotal > 0) {\n              tags.discsTotal ??= discsTotal;\n            }\n          }\n          ;\n          break;\n        case \"TCON\":\n        case \"TCO\":\n          {\n            const genreText = reader.readId3V2EncodingAndText(frameEndPos);\n            let match = /^\\((\\d+)\\)/.exec(genreText);\n            if (match) {\n              const genreNumber = Number.parseInt(match[1]);\n              if (ID3_V1_GENRES[genreNumber] !== void 0) {\n                tags.genre ??= ID3_V1_GENRES[genreNumber];\n                break;\n              }\n            }\n            match = /^\\d+$/.exec(genreText);\n            if (match) {\n              const genreNumber = Number.parseInt(match[0]);\n              if (ID3_V1_GENRES[genreNumber] !== void 0) {\n                tags.genre ??= ID3_V1_GENRES[genreNumber];\n                break;\n              }\n            }\n            tags.genre ??= genreText;\n          }\n          ;\n          break;\n        case \"TDRC\":\n        case \"TDAT\":\n          {\n            const dateText = reader.readId3V2EncodingAndText(frameEndPos);\n            const date = new Date(dateText);\n            if (!Number.isNaN(date.getTime())) {\n              tags.date ??= date;\n            }\n          }\n          ;\n          break;\n        case \"TYER\":\n        case \"TYE\":\n          {\n            const yearText = reader.readId3V2EncodingAndText(frameEndPos);\n            const year = Number.parseInt(yearText, 10);\n            if (Number.isInteger(year)) {\n              tags.date ??= new Date(year, 0, 1);\n            }\n          }\n          ;\n          break;\n        case \"USLT\":\n        case \"ULT\":\n          {\n            const encoding = reader.readU8();\n            reader.pos += 3;\n            reader.readId3V2Text(encoding, frameEndPos);\n            tags.lyrics ??= reader.readId3V2Text(encoding, frameEndPos);\n          }\n          ;\n          break;\n        case \"COMM\":\n        case \"COM\":\n          {\n            const encoding = reader.readU8();\n            reader.pos += 3;\n            reader.readId3V2Text(encoding, frameEndPos);\n            tags.comment ??= reader.readId3V2Text(encoding, frameEndPos);\n          }\n          ;\n          break;\n        case \"APIC\":\n        case \"PIC\":\n          {\n            const encoding = reader.readId3V2TextEncoding();\n            let mimeType;\n            if (header.majorVersion === 2) {\n              const imageFormat = reader.readAscii(3);\n              mimeType = imageFormat === \"PNG\" ? \"image/png\" : imageFormat === \"JPG\" ? \"image/jpeg\" : \"image/*\";\n            } else {\n              mimeType = reader.readId3V2Text(encoding, frameEndPos);\n            }\n            const pictureType = reader.readU8();\n            const description = reader.readId3V2Text(encoding, frameEndPos).trimEnd();\n            const imageDataSize = frameEndPos - reader.pos;\n            if (imageDataSize >= 0) {\n              const imageData = reader.readBytes(imageDataSize);\n              if (!tags.images) tags.images = [];\n              tags.images.push({\n                data: imageData,\n                mimeType,\n                kind: pictureType === 3 ? \"coverFront\" : pictureType === 4 ? \"coverBack\" : \"unknown\",\n                description\n              });\n            }\n          }\n          ;\n          break;\n        default:\n          {\n            reader.pos += frame.size;\n          }\n          ;\n          break;\n      }\n      reader.pos = frameEndPos;\n    }\n  };\n  var Id3V2Reader = class {\n    constructor(header, bytes2) {\n      this.header = header;\n      this.bytes = bytes2;\n      this.pos = 0;\n      this.view = new DataView(bytes2.buffer, bytes2.byteOffset, bytes2.byteLength);\n    }\n    frameHeaderSize() {\n      return this.header.majorVersion === 2 ? 6 : 10;\n    }\n    ununsynchronizeAll() {\n      const newBytes = [];\n      for (let i = 0; i < this.bytes.length; i++) {\n        const value1 = this.bytes[i];\n        newBytes.push(value1);\n        if (value1 === 255 && i !== this.bytes.length - 1) {\n          const value2 = this.bytes[i];\n          if (value2 === 0) {\n            i++;\n          }\n        }\n      }\n      this.bytes = new Uint8Array(newBytes);\n      this.view = new DataView(this.bytes.buffer);\n    }\n    ununsynchronizeRegion(start, end) {\n      const newBytes = [];\n      for (let i = start; i < end; i++) {\n        const value1 = this.bytes[i];\n        newBytes.push(value1);\n        if (value1 === 255 && i !== end - 1) {\n          const value2 = this.bytes[i + 1];\n          if (value2 === 0) {\n            i++;\n          }\n        }\n      }\n      const before = this.bytes.subarray(0, start);\n      const after = this.bytes.subarray(end);\n      this.bytes = new Uint8Array(before.length + newBytes.length + after.length);\n      this.bytes.set(before, 0);\n      this.bytes.set(newBytes, before.length);\n      this.bytes.set(after, before.length + newBytes.length);\n      this.view = new DataView(this.bytes.buffer);\n    }\n    removeFooter() {\n      this.bytes = this.bytes.subarray(0, this.bytes.length - ID3_V2_HEADER_SIZE);\n      this.view = new DataView(this.bytes.buffer);\n    }\n    readBytes(length) {\n      const slice = this.bytes.subarray(this.pos, this.pos + length);\n      this.pos += length;\n      return slice;\n    }\n    readU8() {\n      const value = this.view.getUint8(this.pos);\n      this.pos += 1;\n      return value;\n    }\n    readU16() {\n      const value = this.view.getUint16(this.pos, false);\n      this.pos += 2;\n      return value;\n    }\n    readU24() {\n      const high = this.view.getUint16(this.pos, false);\n      const low = this.view.getUint8(this.pos + 1);\n      this.pos += 3;\n      return high * 256 + low;\n    }\n    readU32() {\n      const value = this.view.getUint32(this.pos, false);\n      this.pos += 4;\n      return value;\n    }\n    readAscii(length) {\n      let str = \"\";\n      for (let i = 0; i < length; i++) {\n        str += String.fromCharCode(this.view.getUint8(this.pos + i));\n      }\n      this.pos += length;\n      return str;\n    }\n    readId3V2Frame() {\n      if (this.header.majorVersion === 2) {\n        const id = this.readAscii(3);\n        if (id === \"\\0\\0\\0\") {\n          return null;\n        }\n        const size = this.readU24();\n        return { id, size, flags: 0 };\n      } else {\n        const id = this.readAscii(4);\n        if (id === \"\\0\\0\\0\\0\") {\n          return null;\n        }\n        const sizeRaw = this.readU32();\n        let size = this.header.majorVersion === 4 ? decodeSynchsafe(sizeRaw) : sizeRaw;\n        const flags = this.readU16();\n        const headerEndPos = this.pos;\n        const isSizeValid = (size2) => {\n          const nextPos = this.pos + size2;\n          if (nextPos > this.bytes.length) {\n            return false;\n          }\n          if (nextPos <= this.bytes.length - this.frameHeaderSize()) {\n            this.pos += size2;\n            const nextId = this.readAscii(4);\n            if (nextId !== \"\\0\\0\\0\\0\" && !/[0-9A-Z]{4}/.test(nextId)) {\n              return false;\n            }\n          }\n          return true;\n        };\n        if (!isSizeValid(size)) {\n          const otherSize = this.header.majorVersion === 4 ? sizeRaw : decodeSynchsafe(sizeRaw);\n          if (isSizeValid(otherSize)) {\n            size = otherSize;\n          }\n        }\n        this.pos = headerEndPos;\n        return { id, size, flags };\n      }\n    }\n    readId3V2TextEncoding() {\n      const number = this.readU8();\n      if (number > 3) {\n        throw new Error(`Unsupported text encoding: ${number}`);\n      }\n      return number;\n    }\n    readId3V2Text(encoding, until) {\n      const startPos = this.pos;\n      const data = this.readBytes(until - this.pos);\n      switch (encoding) {\n        case 0 /* ISO_8859_1 */: {\n          let str = \"\";\n          for (let i = 0; i < data.length; i++) {\n            const value = data[i];\n            if (value === 0) {\n              this.pos = startPos + i + 1;\n              break;\n            }\n            str += String.fromCharCode(value);\n          }\n          return str;\n        }\n        case 1 /* UTF_16_WITH_BOM */: {\n          if (data[0] === 255 && data[1] === 254) {\n            const decoder = new TextDecoder(\"utf-16le\");\n            const endIndex = coalesceIndex(\n              data.findIndex((x, i) => x === 0 && data[i + 1] === 0 && i % 2 === 0),\n              data.length\n            );\n            this.pos = startPos + Math.min(endIndex + 2, data.length);\n            return decoder.decode(data.subarray(2, endIndex));\n          } else if (data[0] === 254 && data[1] === 255) {\n            const decoder = new TextDecoder(\"utf-16be\");\n            const endIndex = coalesceIndex(\n              data.findIndex((x, i) => x === 0 && data[i + 1] === 0 && i % 2 === 0),\n              data.length\n            );\n            this.pos = startPos + Math.min(endIndex + 2, data.length);\n            return decoder.decode(data.subarray(2, endIndex));\n          } else {\n            const endIndex = coalesceIndex(data.findIndex((x) => x === 0), data.length);\n            this.pos = startPos + Math.min(endIndex + 1, data.length);\n            return textDecoder.decode(data.subarray(0, endIndex));\n          }\n        }\n        case 2 /* UTF_16_BE_NO_BOM */: {\n          const decoder = new TextDecoder(\"utf-16be\");\n          const endIndex = coalesceIndex(\n            data.findIndex((x, i) => x === 0 && data[i + 1] === 0 && i % 2 === 0),\n            data.length\n          );\n          this.pos = startPos + Math.min(endIndex + 2, data.length);\n          return decoder.decode(data.subarray(0, endIndex));\n        }\n        case 3 /* UTF_8 */: {\n          const endIndex = coalesceIndex(data.findIndex((x) => x === 0), data.length);\n          this.pos = startPos + Math.min(endIndex + 1, data.length);\n          return textDecoder.decode(data.subarray(0, endIndex));\n        }\n      }\n    }\n    readId3V2EncodingAndText(until) {\n      if (this.pos >= until) {\n        return \"\";\n      }\n      const encoding = this.readId3V2TextEncoding();\n      return this.readId3V2Text(encoding, until);\n    }\n  };\n  var Id3V2Writer = class {\n    constructor(writer) {\n      this.helper = new Uint8Array(8);\n      this.helperView = toDataView(this.helper);\n      this.writer = writer;\n    }\n    writeId3V2Tag(metadata) {\n      const tagStartPos = this.writer.getPos();\n      this.writeAscii(\"ID3\");\n      this.writeU8(4);\n      this.writeU8(0);\n      this.writeU8(0);\n      this.writeSynchsafeU32(0);\n      const framesStartPos = this.writer.getPos();\n      const writtenTags = /* @__PURE__ */ new Set();\n      for (const { key, value } of keyValueIterator(metadata)) {\n        switch (key) {\n          case \"title\":\n            {\n              this.writeId3V2TextFrame(\"TIT2\", value);\n              writtenTags.add(\"TIT2\");\n            }\n            ;\n            break;\n          case \"description\":\n            {\n              this.writeId3V2TextFrame(\"TIT3\", value);\n              writtenTags.add(\"TIT3\");\n            }\n            ;\n            break;\n          case \"artist\":\n            {\n              this.writeId3V2TextFrame(\"TPE1\", value);\n              writtenTags.add(\"TPE1\");\n            }\n            ;\n            break;\n          case \"album\":\n            {\n              this.writeId3V2TextFrame(\"TALB\", value);\n              writtenTags.add(\"TALB\");\n            }\n            ;\n            break;\n          case \"albumArtist\":\n            {\n              this.writeId3V2TextFrame(\"TPE2\", value);\n              writtenTags.add(\"TPE2\");\n            }\n            ;\n            break;\n          case \"trackNumber\":\n            {\n              const string = metadata.tracksTotal !== void 0 ? `${value}/${metadata.tracksTotal}` : value.toString();\n              this.writeId3V2TextFrame(\"TRCK\", string);\n              writtenTags.add(\"TRCK\");\n            }\n            ;\n            break;\n          case \"discNumber\":\n            {\n              const string = metadata.discsTotal !== void 0 ? `${value}/${metadata.discsTotal}` : value.toString();\n              this.writeId3V2TextFrame(\"TPOS\", string);\n              writtenTags.add(\"TPOS\");\n            }\n            ;\n            break;\n          case \"genre\":\n            {\n              this.writeId3V2TextFrame(\"TCON\", value);\n              writtenTags.add(\"TCON\");\n            }\n            ;\n            break;\n          case \"date\":\n            {\n              this.writeId3V2TextFrame(\"TDRC\", value.toISOString().slice(0, 10));\n              writtenTags.add(\"TDRC\");\n            }\n            ;\n            break;\n          case \"lyrics\":\n            {\n              this.writeId3V2LyricsFrame(value);\n              writtenTags.add(\"USLT\");\n            }\n            ;\n            break;\n          case \"comment\":\n            {\n              this.writeId3V2CommentFrame(value);\n              writtenTags.add(\"COMM\");\n            }\n            ;\n            break;\n          case \"images\":\n            {\n              const pictureTypeMap = { coverFront: 3, coverBack: 4, unknown: 0 };\n              for (const image of value) {\n                const pictureType = pictureTypeMap[image.kind] ?? 0;\n                const description = image.description ?? \"\";\n                this.writeId3V2ApicFrame(image.mimeType, pictureType, description, image.data);\n              }\n            }\n            ;\n            break;\n          case \"tracksTotal\":\n          case \"discsTotal\":\n            {\n            }\n            ;\n            break;\n          case \"raw\":\n            {\n            }\n            ;\n            break;\n          default: {\n            assertNever(key);\n          }\n        }\n      }\n      if (metadata.raw) {\n        for (const key in metadata.raw) {\n          const value = metadata.raw[key];\n          if (value == null || key.length !== 4 || writtenTags.has(key)) {\n            continue;\n          }\n          let bytes2;\n          if (typeof value === \"string\") {\n            const encoded = textEncoder.encode(value);\n            bytes2 = new Uint8Array(encoded.byteLength + 2);\n            bytes2[0] = 3 /* UTF_8 */;\n            bytes2.set(encoded, 1);\n          } else if (value instanceof Uint8Array) {\n            bytes2 = value;\n          } else {\n            continue;\n          }\n          this.writeAscii(key);\n          this.writeSynchsafeU32(bytes2.byteLength);\n          this.writeU16(0);\n          this.writer.write(bytes2);\n        }\n      }\n      const framesEndPos = this.writer.getPos();\n      const framesSize = framesEndPos - framesStartPos;\n      this.writer.seek(tagStartPos + 6);\n      this.writeSynchsafeU32(framesSize);\n      this.writer.seek(framesEndPos);\n      return framesSize + 10;\n    }\n    writeU8(value) {\n      this.helper[0] = value;\n      this.writer.write(this.helper.subarray(0, 1));\n    }\n    writeU16(value) {\n      this.helperView.setUint16(0, value, false);\n      this.writer.write(this.helper.subarray(0, 2));\n    }\n    writeU32(value) {\n      this.helperView.setUint32(0, value, false);\n      this.writer.write(this.helper.subarray(0, 4));\n    }\n    writeAscii(text) {\n      for (let i = 0; i < text.length; i++) {\n        this.helper[i] = text.charCodeAt(i);\n      }\n      this.writer.write(this.helper.subarray(0, text.length));\n    }\n    writeSynchsafeU32(value) {\n      this.writeU32(encodeSynchsafe(value));\n    }\n    writeIsoString(text) {\n      const bytes2 = new Uint8Array(text.length + 1);\n      for (let i = 0; i < text.length; i++) {\n        bytes2[i] = text.charCodeAt(i);\n      }\n      bytes2[text.length] = 0;\n      this.writer.write(bytes2);\n    }\n    writeUtf8String(text) {\n      const utf8Data = textEncoder.encode(text);\n      this.writer.write(utf8Data);\n      this.writeU8(0);\n    }\n    writeId3V2TextFrame(frameId, text) {\n      const useIso88591 = isIso88591Compatible(text);\n      const textDataLength = useIso88591 ? text.length : textEncoder.encode(text).byteLength;\n      const frameSize = 1 + textDataLength + 1;\n      this.writeAscii(frameId);\n      this.writeSynchsafeU32(frameSize);\n      this.writeU16(0);\n      this.writeU8(useIso88591 ? 0 /* ISO_8859_1 */ : 3 /* UTF_8 */);\n      if (useIso88591) {\n        this.writeIsoString(text);\n      } else {\n        this.writeUtf8String(text);\n      }\n    }\n    writeId3V2LyricsFrame(lyrics) {\n      const useIso88591 = isIso88591Compatible(lyrics);\n      const shortDescription = \"\";\n      const frameSize = 1 + 3 + shortDescription.length + 1 + lyrics.length + 1;\n      this.writeAscii(\"USLT\");\n      this.writeSynchsafeU32(frameSize);\n      this.writeU16(0);\n      this.writeU8(useIso88591 ? 0 /* ISO_8859_1 */ : 3 /* UTF_8 */);\n      this.writeAscii(\"und\");\n      if (useIso88591) {\n        this.writeIsoString(shortDescription);\n        this.writeIsoString(lyrics);\n      } else {\n        this.writeUtf8String(shortDescription);\n        this.writeUtf8String(lyrics);\n      }\n    }\n    writeId3V2CommentFrame(comment) {\n      const useIso88591 = isIso88591Compatible(comment);\n      const textDataLength = useIso88591 ? comment.length : textEncoder.encode(comment).byteLength;\n      const shortDescription = \"\";\n      const frameSize = 1 + 3 + shortDescription.length + 1 + textDataLength + 1;\n      this.writeAscii(\"COMM\");\n      this.writeSynchsafeU32(frameSize);\n      this.writeU16(0);\n      this.writeU8(useIso88591 ? 0 /* ISO_8859_1 */ : 3 /* UTF_8 */);\n      this.writeU8(117);\n      this.writeU8(110);\n      this.writeU8(100);\n      if (useIso88591) {\n        this.writeIsoString(shortDescription);\n        this.writeIsoString(comment);\n      } else {\n        this.writeUtf8String(shortDescription);\n        this.writeUtf8String(comment);\n      }\n    }\n    writeId3V2ApicFrame(mimeType, pictureType, description, imageData) {\n      const useIso88591 = isIso88591Compatible(mimeType) && isIso88591Compatible(description);\n      const descriptionDataLength = useIso88591 ? description.length : textEncoder.encode(description).byteLength;\n      const frameSize = 1 + mimeType.length + 1 + 1 + descriptionDataLength + 1 + imageData.byteLength;\n      this.writeAscii(\"APIC\");\n      this.writeSynchsafeU32(frameSize);\n      this.writeU16(0);\n      this.writeU8(useIso88591 ? 0 /* ISO_8859_1 */ : 3 /* UTF_8 */);\n      if (useIso88591) {\n        this.writeIsoString(mimeType);\n      } else {\n        this.writeUtf8String(mimeType);\n      }\n      this.writeU8(pictureType);\n      if (useIso88591) {\n        this.writeIsoString(description);\n      } else {\n        this.writeUtf8String(description);\n      }\n      this.writer.write(imageData);\n    }\n  };\n\n  // src/mp3/mp3-reader.ts\n  var readNextMp3FrameHeader = async (reader, startPos, until) => {\n    let currentPos = startPos;\n    while (until === null || currentPos < until) {\n      let slice = reader.requestSlice(currentPos, FRAME_HEADER_SIZE);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) break;\n      const word = readU32Be(slice);\n      const result = readMp3FrameHeader(word, reader.fileSize !== null ? reader.fileSize - currentPos : null);\n      if (result.header) {\n        return { header: result.header, startPos: currentPos };\n      }\n      currentPos += result.bytesAdvanced;\n    }\n    return null;\n  };\n\n  // src/mp3/mp3-demuxer.ts\n  var Mp3Demuxer = class extends Demuxer {\n    constructor(input) {\n      super(input);\n      this.metadataPromise = null;\n      this.firstFrameHeader = null;\n      this.loadedSamples = [];\n      // All samples from the start of the file to lastLoadedPos\n      this.metadataTags = null;\n      this.tracks = [];\n      this.readingMutex = new AsyncMutex();\n      this.lastSampleLoaded = false;\n      this.lastLoadedPos = 0;\n      this.nextTimestampInSamples = 0;\n      this.reader = input._reader;\n    }\n    async readMetadata() {\n      return this.metadataPromise ??= (async () => {\n        while (!this.firstFrameHeader && !this.lastSampleLoaded) {\n          await this.advanceReader();\n        }\n        if (!this.firstFrameHeader) {\n          throw new Error(\"No valid MP3 frame found.\");\n        }\n        this.tracks = [new InputAudioTrack(this.input, new Mp3AudioTrackBacking(this))];\n      })();\n    }\n    async advanceReader() {\n      if (this.lastLoadedPos === 0) {\n        while (true) {\n          let slice2 = this.reader.requestSlice(this.lastLoadedPos, ID3_V2_HEADER_SIZE);\n          if (slice2 instanceof Promise) slice2 = await slice2;\n          if (!slice2) {\n            this.lastSampleLoaded = true;\n            return;\n          }\n          const id3V2Header = readId3V2Header(slice2);\n          if (!id3V2Header) {\n            break;\n          }\n          this.lastLoadedPos = slice2.filePos + id3V2Header.size;\n        }\n      }\n      const result = await readNextMp3FrameHeader(this.reader, this.lastLoadedPos, this.reader.fileSize);\n      if (!result) {\n        this.lastSampleLoaded = true;\n        return;\n      }\n      const header = result.header;\n      this.lastLoadedPos = result.startPos + header.totalSize - 1;\n      const xingOffset = getXingOffset(header.mpegVersionId, header.channel);\n      let slice = this.reader.requestSlice(result.startPos + xingOffset, 4);\n      if (slice instanceof Promise) slice = await slice;\n      if (slice) {\n        const word = readU32Be(slice);\n        const isXing = word === XING || word === INFO;\n        if (isXing) {\n          return;\n        }\n      }\n      if (!this.firstFrameHeader) {\n        this.firstFrameHeader = header;\n      }\n      if (header.sampleRate !== this.firstFrameHeader.sampleRate) {\n        console.warn(\n          `MP3 changed sample rate mid-file: ${this.firstFrameHeader.sampleRate} Hz to ${header.sampleRate} Hz. Might be a bug, so please report this file.`\n        );\n      }\n      const sampleDuration = header.audioSamplesInFrame / this.firstFrameHeader.sampleRate;\n      const sample = {\n        timestamp: this.nextTimestampInSamples / this.firstFrameHeader.sampleRate,\n        duration: sampleDuration,\n        dataStart: result.startPos,\n        dataSize: header.totalSize\n      };\n      this.loadedSamples.push(sample);\n      this.nextTimestampInSamples += header.audioSamplesInFrame;\n      return;\n    }\n    async getMimeType() {\n      return \"audio/mpeg\";\n    }\n    async getTracks() {\n      await this.readMetadata();\n      return this.tracks;\n    }\n    async computeDuration() {\n      await this.readMetadata();\n      const track = this.tracks[0];\n      assert(track);\n      return track.computeDuration();\n    }\n    async getMetadataTags() {\n      const release = await this.readingMutex.acquire();\n      try {\n        await this.readMetadata();\n        if (this.metadataTags) {\n          return this.metadataTags;\n        }\n        this.metadataTags = {};\n        let currentPos = 0;\n        let id3V2HeaderFound = false;\n        while (true) {\n          let headerSlice = this.reader.requestSlice(currentPos, ID3_V2_HEADER_SIZE);\n          if (headerSlice instanceof Promise) headerSlice = await headerSlice;\n          if (!headerSlice) break;\n          const id3V2Header = readId3V2Header(headerSlice);\n          if (!id3V2Header) {\n            break;\n          }\n          id3V2HeaderFound = true;\n          let contentSlice = this.reader.requestSlice(headerSlice.filePos, id3V2Header.size);\n          if (contentSlice instanceof Promise) contentSlice = await contentSlice;\n          if (!contentSlice) break;\n          parseId3V2Tag(contentSlice, id3V2Header, this.metadataTags);\n          currentPos = headerSlice.filePos + id3V2Header.size;\n        }\n        if (!id3V2HeaderFound && this.reader.fileSize !== null && this.reader.fileSize >= ID3_V1_TAG_SIZE) {\n          let slice = this.reader.requestSlice(this.reader.fileSize - ID3_V1_TAG_SIZE, ID3_V1_TAG_SIZE);\n          if (slice instanceof Promise) slice = await slice;\n          assert(slice);\n          const tag = readAscii(slice, 3);\n          if (tag === \"TAG\") {\n            parseId3V1Tag(slice, this.metadataTags);\n          }\n        }\n        return this.metadataTags;\n      } finally {\n        release();\n      }\n    }\n  };\n  var Mp3AudioTrackBacking = class {\n    constructor(demuxer) {\n      this.demuxer = demuxer;\n    }\n    getId() {\n      return 1;\n    }\n    async getFirstTimestamp() {\n      return 0;\n    }\n    getTimeResolution() {\n      assert(this.demuxer.firstFrameHeader);\n      return this.demuxer.firstFrameHeader.sampleRate / this.demuxer.firstFrameHeader.audioSamplesInFrame;\n    }\n    async computeDuration() {\n      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n    }\n    getName() {\n      return null;\n    }\n    getLanguageCode() {\n      return UNDETERMINED_LANGUAGE;\n    }\n    getCodec() {\n      return \"mp3\";\n    }\n    getInternalCodecId() {\n      return null;\n    }\n    getNumberOfChannels() {\n      assert(this.demuxer.firstFrameHeader);\n      return this.demuxer.firstFrameHeader.channel === 3 ? 1 : 2;\n    }\n    getSampleRate() {\n      assert(this.demuxer.firstFrameHeader);\n      return this.demuxer.firstFrameHeader.sampleRate;\n    }\n    getDisposition() {\n      return {\n        ...DEFAULT_TRACK_DISPOSITION\n      };\n    }\n    async getDecoderConfig() {\n      assert(this.demuxer.firstFrameHeader);\n      return {\n        codec: \"mp3\",\n        numberOfChannels: this.demuxer.firstFrameHeader.channel === 3 ? 1 : 2,\n        sampleRate: this.demuxer.firstFrameHeader.sampleRate\n      };\n    }\n    async getPacketAtIndex(sampleIndex, options) {\n      if (sampleIndex === -1) {\n        return null;\n      }\n      const rawSample = this.demuxer.loadedSamples[sampleIndex];\n      if (!rawSample) {\n        return null;\n      }\n      let data;\n      if (options.metadataOnly) {\n        data = PLACEHOLDER_DATA;\n      } else {\n        let slice = this.demuxer.reader.requestSlice(rawSample.dataStart, rawSample.dataSize);\n        if (slice instanceof Promise) slice = await slice;\n        if (!slice) {\n          return null;\n        }\n        data = readBytes(slice, rawSample.dataSize);\n      }\n      return new EncodedPacket(\n        data,\n        \"key\",\n        rawSample.timestamp,\n        rawSample.duration,\n        sampleIndex,\n        rawSample.dataSize\n      );\n    }\n    getFirstPacket(options) {\n      return this.getPacketAtIndex(0, options);\n    }\n    async getNextPacket(packet, options) {\n      const release = await this.demuxer.readingMutex.acquire();\n      try {\n        const sampleIndex = binarySearchExact(\n          this.demuxer.loadedSamples,\n          packet.timestamp,\n          (x) => x.timestamp\n        );\n        if (sampleIndex === -1) {\n          throw new Error(\"Packet was not created from this track.\");\n        }\n        const nextIndex = sampleIndex + 1;\n        while (nextIndex >= this.demuxer.loadedSamples.length && !this.demuxer.lastSampleLoaded) {\n          await this.demuxer.advanceReader();\n        }\n        return this.getPacketAtIndex(nextIndex, options);\n      } finally {\n        release();\n      }\n    }\n    async getPacket(timestamp, options) {\n      const release = await this.demuxer.readingMutex.acquire();\n      try {\n        while (true) {\n          const index = binarySearchLessOrEqual(\n            this.demuxer.loadedSamples,\n            timestamp,\n            (x) => x.timestamp\n          );\n          if (index === -1 && this.demuxer.loadedSamples.length > 0) {\n            return null;\n          }\n          if (this.demuxer.lastSampleLoaded) {\n            return this.getPacketAtIndex(index, options);\n          }\n          if (index >= 0 && index + 1 < this.demuxer.loadedSamples.length) {\n            return this.getPacketAtIndex(index, options);\n          }\n          await this.demuxer.advanceReader();\n        }\n      } finally {\n        release();\n      }\n    }\n    getKeyPacket(timestamp, options) {\n      return this.getPacket(timestamp, options);\n    }\n    getNextKeyPacket(packet, options) {\n      return this.getNextPacket(packet, options);\n    }\n  };\n\n  // src/ogg/ogg-misc.ts\n  var OGGS = 1399285583;\n  var OGG_CRC_POLYNOMIAL = 79764919;\n  var OGG_CRC_TABLE = new Uint32Array(256);\n  for (let n = 0; n < 256; n++) {\n    let crc = n << 24;\n    for (let k = 0; k < 8; k++) {\n      crc = crc & 2147483648 ? crc << 1 ^ OGG_CRC_POLYNOMIAL : crc << 1;\n    }\n    OGG_CRC_TABLE[n] = crc >>> 0 & 4294967295;\n  }\n  var computeOggPageCrc = (bytes2) => {\n    const view2 = toDataView(bytes2);\n    const originalChecksum = view2.getUint32(22, true);\n    view2.setUint32(22, 0, true);\n    let crc = 0;\n    for (let i = 0; i < bytes2.length; i++) {\n      const byte = bytes2[i];\n      crc = (crc << 8 ^ OGG_CRC_TABLE[crc >>> 24 ^ byte]) >>> 0;\n    }\n    view2.setUint32(22, originalChecksum, true);\n    return crc;\n  };\n  var extractSampleMetadata = (data, codecInfo, vorbisLastBlocksize) => {\n    let durationInSamples = 0;\n    let currentBlocksize = null;\n    if (data.length > 0) {\n      if (codecInfo.codec === \"vorbis\") {\n        assert(codecInfo.vorbisInfo);\n        const vorbisModeCount = codecInfo.vorbisInfo.modeBlockflags.length;\n        const bitCount = ilog(vorbisModeCount - 1);\n        const modeMask = (1 << bitCount) - 1 << 1;\n        const modeNumber = (data[0] & modeMask) >> 1;\n        if (modeNumber >= codecInfo.vorbisInfo.modeBlockflags.length) {\n          throw new Error(\"Invalid mode number.\");\n        }\n        let prevBlocksize = vorbisLastBlocksize;\n        const blockflag = codecInfo.vorbisInfo.modeBlockflags[modeNumber];\n        currentBlocksize = codecInfo.vorbisInfo.blocksizes[blockflag];\n        if (blockflag === 1) {\n          const prevMask = (modeMask | 1) + 1;\n          const flag = data[0] & prevMask ? 1 : 0;\n          prevBlocksize = codecInfo.vorbisInfo.blocksizes[flag];\n        }\n        durationInSamples = prevBlocksize !== null ? prevBlocksize + currentBlocksize >> 2 : 0;\n      } else if (codecInfo.codec === \"opus\") {\n        const toc = parseOpusTocByte(data);\n        durationInSamples = toc.durationInSamples;\n      }\n    }\n    return {\n      durationInSamples,\n      vorbisBlockSize: currentBlocksize\n    };\n  };\n  var buildOggMimeType = (info) => {\n    let string = \"audio/ogg\";\n    if (info.codecStrings) {\n      const uniqueCodecMimeTypes = [...new Set(info.codecStrings)];\n      string += `; codecs=\"${uniqueCodecMimeTypes.join(\", \")}\"`;\n    }\n    return string;\n  };\n\n  // src/ogg/ogg-reader.ts\n  var MIN_PAGE_HEADER_SIZE = 27;\n  var MAX_PAGE_HEADER_SIZE = 27 + 255;\n  var MAX_PAGE_SIZE = MAX_PAGE_HEADER_SIZE + 255 * 255;\n  var readPageHeader = (slice) => {\n    const startPos = slice.filePos;\n    const capturePattern = readU32Le(slice);\n    if (capturePattern !== OGGS) {\n      return null;\n    }\n    slice.skip(1);\n    const headerType = readU8(slice);\n    const granulePosition = readI64Le(slice);\n    const serialNumber = readU32Le(slice);\n    const sequenceNumber = readU32Le(slice);\n    const checksum = readU32Le(slice);\n    const numberPageSegments = readU8(slice);\n    const lacingValues = new Uint8Array(numberPageSegments);\n    for (let i = 0; i < numberPageSegments; i++) {\n      lacingValues[i] = readU8(slice);\n    }\n    const headerSize = 27 + numberPageSegments;\n    const dataSize = lacingValues.reduce((a, b) => a + b, 0);\n    const totalSize = headerSize + dataSize;\n    return {\n      headerStartPos: startPos,\n      totalSize,\n      dataStartPos: startPos + headerSize,\n      dataSize,\n      headerType,\n      granulePosition,\n      serialNumber,\n      sequenceNumber,\n      checksum,\n      lacingValues\n    };\n  };\n  var findNextPageHeader = (slice, until) => {\n    while (slice.filePos < until - (4 - 1)) {\n      const word = readU32Le(slice);\n      const firstByte = word & 255;\n      const secondByte = word >>> 8 & 255;\n      const thirdByte = word >>> 16 & 255;\n      const fourthByte = word >>> 24 & 255;\n      const O = 79;\n      if (firstByte !== O && secondByte !== O && thirdByte !== O && fourthByte !== O) {\n        continue;\n      }\n      slice.skip(-4);\n      if (word === OGGS) {\n        return true;\n      }\n      slice.skip(1);\n    }\n    return false;\n  };\n\n  // src/ogg/ogg-demuxer.ts\n  var OggDemuxer = class extends Demuxer {\n    constructor(input) {\n      super(input);\n      this.metadataPromise = null;\n      this.bitstreams = [];\n      this.tracks = [];\n      this.metadataTags = {};\n      this.reader = input._reader;\n    }\n    async readMetadata() {\n      return this.metadataPromise ??= (async () => {\n        let currentPos = 0;\n        while (true) {\n          let slice = this.reader.requestSliceRange(currentPos, MIN_PAGE_HEADER_SIZE, MAX_PAGE_HEADER_SIZE);\n          if (slice instanceof Promise) slice = await slice;\n          if (!slice) break;\n          const page = readPageHeader(slice);\n          if (!page) {\n            break;\n          }\n          const isBos = !!(page.headerType & 2);\n          if (!isBos) {\n            break;\n          }\n          this.bitstreams.push({\n            serialNumber: page.serialNumber,\n            bosPage: page,\n            description: null,\n            numberOfChannels: -1,\n            sampleRate: -1,\n            codecInfo: {\n              codec: null,\n              vorbisInfo: null,\n              opusInfo: null\n            },\n            lastMetadataPacket: null\n          });\n          currentPos = page.headerStartPos + page.totalSize;\n        }\n        for (const bitstream of this.bitstreams) {\n          const firstPacket = await this.readPacket(bitstream.bosPage, 0);\n          if (!firstPacket) {\n            continue;\n          }\n          if (\n            // Check for Vorbis\n            firstPacket.data.byteLength >= 7 && firstPacket.data[0] === 1 && firstPacket.data[1] === 118 && firstPacket.data[2] === 111 && firstPacket.data[3] === 114 && firstPacket.data[4] === 98 && firstPacket.data[5] === 105 && firstPacket.data[6] === 115\n          ) {\n            await this.readVorbisMetadata(firstPacket, bitstream);\n          } else if (\n            // Check for Opus\n            firstPacket.data.byteLength >= 8 && firstPacket.data[0] === 79 && firstPacket.data[1] === 112 && firstPacket.data[2] === 117 && firstPacket.data[3] === 115 && firstPacket.data[4] === 72 && firstPacket.data[5] === 101 && firstPacket.data[6] === 97 && firstPacket.data[7] === 100\n          ) {\n            await this.readOpusMetadata(firstPacket, bitstream);\n          }\n          if (bitstream.codecInfo.codec !== null) {\n            this.tracks.push(new InputAudioTrack(this.input, new OggAudioTrackBacking(bitstream, this)));\n          }\n        }\n      })();\n    }\n    async readVorbisMetadata(firstPacket, bitstream) {\n      let nextPacketPosition = await this.findNextPacketStart(firstPacket);\n      if (!nextPacketPosition) {\n        return;\n      }\n      const secondPacket = await this.readPacket(nextPacketPosition.startPage, nextPacketPosition.startSegmentIndex);\n      if (!secondPacket) {\n        return;\n      }\n      nextPacketPosition = await this.findNextPacketStart(secondPacket);\n      if (!nextPacketPosition) {\n        return;\n      }\n      const thirdPacket = await this.readPacket(nextPacketPosition.startPage, nextPacketPosition.startSegmentIndex);\n      if (!thirdPacket) {\n        return;\n      }\n      if (secondPacket.data[0] !== 3 || thirdPacket.data[0] !== 5) {\n        return;\n      }\n      const lacingValues = [];\n      const addBytesToSegmentTable = (bytes2) => {\n        while (true) {\n          lacingValues.push(Math.min(255, bytes2));\n          if (bytes2 < 255) {\n            break;\n          }\n          bytes2 -= 255;\n        }\n      };\n      addBytesToSegmentTable(firstPacket.data.length);\n      addBytesToSegmentTable(secondPacket.data.length);\n      const description = new Uint8Array(\n        1 + lacingValues.length + firstPacket.data.length + secondPacket.data.length + thirdPacket.data.length\n      );\n      description[0] = 2;\n      description.set(\n        lacingValues,\n        1\n      );\n      description.set(\n        firstPacket.data,\n        1 + lacingValues.length\n      );\n      description.set(\n        secondPacket.data,\n        1 + lacingValues.length + firstPacket.data.length\n      );\n      description.set(\n        thirdPacket.data,\n        1 + lacingValues.length + firstPacket.data.length + secondPacket.data.length\n      );\n      bitstream.codecInfo.codec = \"vorbis\";\n      bitstream.description = description;\n      bitstream.lastMetadataPacket = thirdPacket;\n      const view2 = toDataView(firstPacket.data);\n      bitstream.numberOfChannels = view2.getUint8(11);\n      bitstream.sampleRate = view2.getUint32(12, true);\n      const blockSizeByte = view2.getUint8(28);\n      bitstream.codecInfo.vorbisInfo = {\n        blocksizes: [\n          1 << (blockSizeByte & 15),\n          1 << (blockSizeByte >> 4)\n        ],\n        modeBlockflags: parseModesFromVorbisSetupPacket(thirdPacket.data).modeBlockflags\n      };\n      readVorbisComments(secondPacket.data.subarray(7), this.metadataTags);\n    }\n    async readOpusMetadata(firstPacket, bitstream) {\n      const nextPacketPosition = await this.findNextPacketStart(firstPacket);\n      if (!nextPacketPosition) {\n        return;\n      }\n      const secondPacket = await this.readPacket(\n        nextPacketPosition.startPage,\n        nextPacketPosition.startSegmentIndex\n      );\n      if (!secondPacket) {\n        return;\n      }\n      bitstream.codecInfo.codec = \"opus\";\n      bitstream.description = firstPacket.data;\n      bitstream.lastMetadataPacket = secondPacket;\n      const header = parseOpusIdentificationHeader(firstPacket.data);\n      bitstream.numberOfChannels = header.outputChannelCount;\n      bitstream.sampleRate = OPUS_SAMPLE_RATE;\n      bitstream.codecInfo.opusInfo = {\n        preSkip: header.preSkip\n      };\n      readVorbisComments(secondPacket.data.subarray(8), this.metadataTags);\n    }\n    async readPacket(startPage, startSegmentIndex) {\n      assert(startSegmentIndex < startPage.lacingValues.length);\n      let startDataOffset = 0;\n      for (let i = 0; i < startSegmentIndex; i++) {\n        startDataOffset += startPage.lacingValues[i];\n      }\n      let currentPage = startPage;\n      let currentDataOffset = startDataOffset;\n      let currentSegmentIndex = startSegmentIndex;\n      const chunks = [];\n      outer:\n        while (true) {\n          let pageSlice = this.reader.requestSlice(currentPage.dataStartPos, currentPage.dataSize);\n          if (pageSlice instanceof Promise) pageSlice = await pageSlice;\n          assert(pageSlice);\n          const pageData = readBytes(pageSlice, currentPage.dataSize);\n          while (true) {\n            if (currentSegmentIndex === currentPage.lacingValues.length) {\n              chunks.push(pageData.subarray(startDataOffset, currentDataOffset));\n              break;\n            }\n            const lacingValue = currentPage.lacingValues[currentSegmentIndex];\n            currentDataOffset += lacingValue;\n            if (lacingValue < 255) {\n              chunks.push(pageData.subarray(startDataOffset, currentDataOffset));\n              break outer;\n            }\n            currentSegmentIndex++;\n          }\n          let currentPos = currentPage.headerStartPos + currentPage.totalSize;\n          while (true) {\n            let headerSlice = this.reader.requestSliceRange(currentPos, MIN_PAGE_HEADER_SIZE, MAX_PAGE_HEADER_SIZE);\n            if (headerSlice instanceof Promise) headerSlice = await headerSlice;\n            if (!headerSlice) {\n              return null;\n            }\n            const nextPage = readPageHeader(headerSlice);\n            if (!nextPage) {\n              return null;\n            }\n            currentPage = nextPage;\n            if (currentPage.serialNumber === startPage.serialNumber) {\n              break;\n            }\n            currentPos = currentPage.headerStartPos + currentPage.totalSize;\n          }\n          startDataOffset = 0;\n          currentDataOffset = 0;\n          currentSegmentIndex = 0;\n        }\n      const totalPacketSize = chunks.reduce((sum, chunk) => sum + chunk.length, 0);\n      if (totalPacketSize === 0) {\n        return null;\n      }\n      const packetData = new Uint8Array(totalPacketSize);\n      let offset = 0;\n      for (let i = 0; i < chunks.length; i++) {\n        const chunk = chunks[i];\n        packetData.set(chunk, offset);\n        offset += chunk.length;\n      }\n      return {\n        data: packetData,\n        endPage: currentPage,\n        endSegmentIndex: currentSegmentIndex\n      };\n    }\n    async findNextPacketStart(lastPacket) {\n      if (lastPacket.endSegmentIndex < lastPacket.endPage.lacingValues.length - 1) {\n        return { startPage: lastPacket.endPage, startSegmentIndex: lastPacket.endSegmentIndex + 1 };\n      }\n      const isEos = !!(lastPacket.endPage.headerType & 4);\n      if (isEos) {\n        return null;\n      }\n      let currentPos = lastPacket.endPage.headerStartPos + lastPacket.endPage.totalSize;\n      while (true) {\n        let slice = this.reader.requestSliceRange(currentPos, MIN_PAGE_HEADER_SIZE, MAX_PAGE_HEADER_SIZE);\n        if (slice instanceof Promise) slice = await slice;\n        if (!slice) {\n          return null;\n        }\n        const nextPage = readPageHeader(slice);\n        if (!nextPage) {\n          return null;\n        }\n        if (nextPage.serialNumber === lastPacket.endPage.serialNumber) {\n          return { startPage: nextPage, startSegmentIndex: 0 };\n        }\n        currentPos = nextPage.headerStartPos + nextPage.totalSize;\n      }\n    }\n    async getMimeType() {\n      await this.readMetadata();\n      const codecStrings = await Promise.all(this.tracks.map((x) => x.getCodecParameterString()));\n      return buildOggMimeType({\n        codecStrings: codecStrings.filter(Boolean)\n      });\n    }\n    async getTracks() {\n      await this.readMetadata();\n      return this.tracks;\n    }\n    async computeDuration() {\n      const tracks = await this.getTracks();\n      const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));\n      return Math.max(0, ...trackDurations);\n    }\n    async getMetadataTags() {\n      await this.readMetadata();\n      return this.metadataTags;\n    }\n  };\n  var OggAudioTrackBacking = class {\n    constructor(bitstream, demuxer) {\n      this.bitstream = bitstream;\n      this.demuxer = demuxer;\n      this.encodedPacketToMetadata = /* @__PURE__ */ new WeakMap();\n      this.sequentialScanCache = [];\n      this.sequentialScanMutex = new AsyncMutex();\n      this.internalSampleRate = bitstream.codecInfo.codec === \"opus\" ? OPUS_SAMPLE_RATE : bitstream.sampleRate;\n    }\n    getId() {\n      return this.bitstream.serialNumber;\n    }\n    getNumberOfChannels() {\n      return this.bitstream.numberOfChannels;\n    }\n    getSampleRate() {\n      return this.bitstream.sampleRate;\n    }\n    getTimeResolution() {\n      return this.bitstream.sampleRate;\n    }\n    getCodec() {\n      return this.bitstream.codecInfo.codec;\n    }\n    getInternalCodecId() {\n      return null;\n    }\n    async getDecoderConfig() {\n      assert(this.bitstream.codecInfo.codec);\n      return {\n        codec: this.bitstream.codecInfo.codec,\n        numberOfChannels: this.bitstream.numberOfChannels,\n        sampleRate: this.bitstream.sampleRate,\n        description: this.bitstream.description ?? void 0\n      };\n    }\n    getName() {\n      return null;\n    }\n    getLanguageCode() {\n      return UNDETERMINED_LANGUAGE;\n    }\n    getDisposition() {\n      return {\n        ...DEFAULT_TRACK_DISPOSITION\n      };\n    }\n    async getFirstTimestamp() {\n      return 0;\n    }\n    async computeDuration() {\n      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n    }\n    granulePositionToTimestampInSamples(granulePosition) {\n      if (this.bitstream.codecInfo.codec === \"opus\") {\n        assert(this.bitstream.codecInfo.opusInfo);\n        return granulePosition - this.bitstream.codecInfo.opusInfo.preSkip;\n      }\n      return granulePosition;\n    }\n    createEncodedPacketFromOggPacket(packet, additional, options) {\n      if (!packet) {\n        return null;\n      }\n      const { durationInSamples, vorbisBlockSize } = extractSampleMetadata(\n        packet.data,\n        this.bitstream.codecInfo,\n        additional.vorbisLastBlocksize\n      );\n      const encodedPacket = new EncodedPacket(\n        options.metadataOnly ? PLACEHOLDER_DATA : packet.data,\n        \"key\",\n        Math.max(0, additional.timestampInSamples) / this.internalSampleRate,\n        durationInSamples / this.internalSampleRate,\n        packet.endPage.headerStartPos + packet.endSegmentIndex,\n        packet.data.byteLength\n      );\n      this.encodedPacketToMetadata.set(encodedPacket, {\n        packet,\n        timestampInSamples: additional.timestampInSamples,\n        durationInSamples,\n        vorbisLastBlockSize: additional.vorbisLastBlocksize,\n        vorbisBlockSize\n      });\n      return encodedPacket;\n    }\n    async getFirstPacket(options) {\n      assert(this.bitstream.lastMetadataPacket);\n      const packetPosition = await this.demuxer.findNextPacketStart(this.bitstream.lastMetadataPacket);\n      if (!packetPosition) {\n        return null;\n      }\n      let timestampInSamples = 0;\n      if (this.bitstream.codecInfo.codec === \"opus\") {\n        assert(this.bitstream.codecInfo.opusInfo);\n        timestampInSamples -= this.bitstream.codecInfo.opusInfo.preSkip;\n      }\n      const packet = await this.demuxer.readPacket(packetPosition.startPage, packetPosition.startSegmentIndex);\n      return this.createEncodedPacketFromOggPacket(\n        packet,\n        {\n          timestampInSamples,\n          vorbisLastBlocksize: null\n        },\n        options\n      );\n    }\n    async getNextPacket(prevPacket, options) {\n      const prevMetadata = this.encodedPacketToMetadata.get(prevPacket);\n      if (!prevMetadata) {\n        throw new Error(\"Packet was not created from this track.\");\n      }\n      const packetPosition = await this.demuxer.findNextPacketStart(prevMetadata.packet);\n      if (!packetPosition) {\n        return null;\n      }\n      const timestampInSamples = prevMetadata.timestampInSamples + prevMetadata.durationInSamples;\n      const packet = await this.demuxer.readPacket(\n        packetPosition.startPage,\n        packetPosition.startSegmentIndex\n      );\n      return this.createEncodedPacketFromOggPacket(\n        packet,\n        {\n          timestampInSamples,\n          vorbisLastBlocksize: prevMetadata.vorbisBlockSize\n        },\n        options\n      );\n    }\n    async getPacket(timestamp, options) {\n      if (this.demuxer.reader.fileSize === null) {\n        return this.getPacketSequential(timestamp, options);\n      }\n      const timestampInSamples = roundIfAlmostInteger(timestamp * this.internalSampleRate);\n      if (timestampInSamples === 0) {\n        return this.getFirstPacket(options);\n      }\n      if (timestampInSamples < 0) {\n        return null;\n      }\n      assert(this.bitstream.lastMetadataPacket);\n      const startPosition = await this.demuxer.findNextPacketStart(this.bitstream.lastMetadataPacket);\n      if (!startPosition) {\n        return null;\n      }\n      let lowPage = startPosition.startPage;\n      let high = this.demuxer.reader.fileSize;\n      const lowPages = [lowPage];\n      outer:\n        while (lowPage.headerStartPos + lowPage.totalSize < high) {\n          const low = lowPage.headerStartPos;\n          const mid = Math.floor((low + high) / 2);\n          let searchStartPos = mid;\n          while (true) {\n            const until = Math.min(\n              searchStartPos + MAX_PAGE_SIZE,\n              high - MIN_PAGE_HEADER_SIZE\n            );\n            let searchSlice = this.demuxer.reader.requestSlice(searchStartPos, until - searchStartPos);\n            if (searchSlice instanceof Promise) searchSlice = await searchSlice;\n            assert(searchSlice);\n            const found = findNextPageHeader(searchSlice, until);\n            if (!found) {\n              high = mid + MIN_PAGE_HEADER_SIZE;\n              continue outer;\n            }\n            let headerSlice = this.demuxer.reader.requestSliceRange(\n              searchSlice.filePos,\n              MIN_PAGE_HEADER_SIZE,\n              MAX_PAGE_HEADER_SIZE\n            );\n            if (headerSlice instanceof Promise) headerSlice = await headerSlice;\n            assert(headerSlice);\n            const page = readPageHeader(headerSlice);\n            assert(page);\n            let pageValid = false;\n            if (page.serialNumber === this.bitstream.serialNumber) {\n              pageValid = true;\n            } else {\n              let pageSlice = this.demuxer.reader.requestSlice(page.headerStartPos, page.totalSize);\n              if (pageSlice instanceof Promise) pageSlice = await pageSlice;\n              assert(pageSlice);\n              const bytes2 = readBytes(pageSlice, page.totalSize);\n              const crc = computeOggPageCrc(bytes2);\n              pageValid = crc === page.checksum;\n            }\n            if (!pageValid) {\n              searchStartPos = page.headerStartPos + 4;\n              continue;\n            }\n            if (pageValid && page.serialNumber !== this.bitstream.serialNumber) {\n              searchStartPos = page.headerStartPos + page.totalSize;\n              continue;\n            }\n            const isContinuationPage = page.granulePosition === -1;\n            if (isContinuationPage) {\n              searchStartPos = page.headerStartPos + page.totalSize;\n              continue;\n            }\n            if (this.granulePositionToTimestampInSamples(page.granulePosition) > timestampInSamples) {\n              high = page.headerStartPos;\n            } else {\n              lowPage = page;\n              lowPages.push(page);\n            }\n            continue outer;\n          }\n        }\n      let lowerPage = startPosition.startPage;\n      for (const otherLowPage of lowPages) {\n        if (otherLowPage.granulePosition === lowPage.granulePosition) {\n          break;\n        }\n        if (!lowerPage || otherLowPage.headerStartPos > lowerPage.headerStartPos) {\n          lowerPage = otherLowPage;\n        }\n      }\n      let currentPage = lowerPage;\n      const previousPages = [currentPage];\n      while (true) {\n        if (currentPage.serialNumber === this.bitstream.serialNumber && currentPage.granulePosition === lowPage.granulePosition) {\n          break;\n        }\n        const nextPos = currentPage.headerStartPos + currentPage.totalSize;\n        let slice = this.demuxer.reader.requestSliceRange(nextPos, MIN_PAGE_HEADER_SIZE, MAX_PAGE_HEADER_SIZE);\n        if (slice instanceof Promise) slice = await slice;\n        assert(slice);\n        const nextPage = readPageHeader(slice);\n        assert(nextPage);\n        currentPage = nextPage;\n        if (currentPage.serialNumber === this.bitstream.serialNumber) {\n          previousPages.push(currentPage);\n        }\n      }\n      assert(currentPage.granulePosition !== -1);\n      let currentSegmentIndex = null;\n      let currentTimestampInSamples;\n      let currentTimestampIsCorrect;\n      let endPage = currentPage;\n      let endSegmentIndex = 0;\n      if (currentPage.headerStartPos === startPosition.startPage.headerStartPos) {\n        currentTimestampInSamples = this.granulePositionToTimestampInSamples(0);\n        currentTimestampIsCorrect = true;\n        currentSegmentIndex = 0;\n      } else {\n        currentTimestampInSamples = 0;\n        currentTimestampIsCorrect = false;\n        for (let i = currentPage.lacingValues.length - 1; i >= 0; i--) {\n          const value = currentPage.lacingValues[i];\n          if (value < 255) {\n            currentSegmentIndex = i + 1;\n            break;\n          }\n        }\n        if (currentSegmentIndex === null) {\n          throw new Error(\"Invalid page with granule position: no packets end on this page.\");\n        }\n        endSegmentIndex = currentSegmentIndex - 1;\n        const pseudopacket = {\n          data: PLACEHOLDER_DATA,\n          endPage,\n          endSegmentIndex\n        };\n        const nextPosition = await this.demuxer.findNextPacketStart(pseudopacket);\n        if (nextPosition) {\n          const endPosition = findPreviousPacketEndPosition(previousPages, currentPage, currentSegmentIndex);\n          assert(endPosition);\n          const startPosition2 = findPacketStartPosition(\n            previousPages,\n            endPosition.page,\n            endPosition.segmentIndex\n          );\n          if (startPosition2) {\n            currentPage = startPosition2.page;\n            currentSegmentIndex = startPosition2.segmentIndex;\n          }\n        } else {\n          while (true) {\n            const endPosition = findPreviousPacketEndPosition(\n              previousPages,\n              currentPage,\n              currentSegmentIndex\n            );\n            if (!endPosition) {\n              break;\n            }\n            const startPosition2 = findPacketStartPosition(\n              previousPages,\n              endPosition.page,\n              endPosition.segmentIndex\n            );\n            if (!startPosition2) {\n              break;\n            }\n            currentPage = startPosition2.page;\n            currentSegmentIndex = startPosition2.segmentIndex;\n            if (endPosition.page.headerStartPos !== endPage.headerStartPos) {\n              endPage = endPosition.page;\n              endSegmentIndex = endPosition.segmentIndex;\n              break;\n            }\n          }\n        }\n      }\n      let lastEncodedPacket = null;\n      let lastEncodedPacketMetadata = null;\n      while (currentPage !== null) {\n        assert(currentSegmentIndex !== null);\n        const packet = await this.demuxer.readPacket(currentPage, currentSegmentIndex);\n        if (!packet) {\n          break;\n        }\n        const skipPacket = currentPage.headerStartPos === startPosition.startPage.headerStartPos && currentSegmentIndex < startPosition.startSegmentIndex;\n        if (!skipPacket) {\n          let encodedPacket = this.createEncodedPacketFromOggPacket(\n            packet,\n            {\n              timestampInSamples: currentTimestampInSamples,\n              vorbisLastBlocksize: lastEncodedPacketMetadata?.vorbisBlockSize ?? null\n            },\n            options\n          );\n          assert(encodedPacket);\n          let encodedPacketMetadata = this.encodedPacketToMetadata.get(encodedPacket);\n          assert(encodedPacketMetadata);\n          if (!currentTimestampIsCorrect && packet.endPage.headerStartPos === endPage.headerStartPos && packet.endSegmentIndex === endSegmentIndex) {\n            currentTimestampInSamples = this.granulePositionToTimestampInSamples(\n              currentPage.granulePosition\n            );\n            currentTimestampIsCorrect = true;\n            encodedPacket = this.createEncodedPacketFromOggPacket(\n              packet,\n              {\n                timestampInSamples: currentTimestampInSamples - encodedPacketMetadata.durationInSamples,\n                vorbisLastBlocksize: lastEncodedPacketMetadata?.vorbisBlockSize ?? null\n              },\n              options\n            );\n            assert(encodedPacket);\n            encodedPacketMetadata = this.encodedPacketToMetadata.get(encodedPacket);\n            assert(encodedPacketMetadata);\n          } else {\n            currentTimestampInSamples += encodedPacketMetadata.durationInSamples;\n          }\n          lastEncodedPacket = encodedPacket;\n          lastEncodedPacketMetadata = encodedPacketMetadata;\n          if (currentTimestampIsCorrect && // Next timestamp will be too late\n          (Math.max(currentTimestampInSamples, 0) > timestampInSamples || Math.max(encodedPacketMetadata.timestampInSamples, 0) === timestampInSamples)) {\n            break;\n          }\n        }\n        const nextPosition = await this.demuxer.findNextPacketStart(packet);\n        if (!nextPosition) {\n          break;\n        }\n        currentPage = nextPosition.startPage;\n        currentSegmentIndex = nextPosition.startSegmentIndex;\n      }\n      return lastEncodedPacket;\n    }\n    // A slower but simpler and sequential algorithm for finding a packet in a file\n    async getPacketSequential(timestamp, options) {\n      const release = await this.sequentialScanMutex.acquire();\n      try {\n        const timestampInSamples = roundIfAlmostInteger(timestamp * this.internalSampleRate);\n        timestamp = timestampInSamples / this.internalSampleRate;\n        const index = binarySearchLessOrEqual(\n          this.sequentialScanCache,\n          timestampInSamples,\n          (x) => x.timestampInSamples\n        );\n        let currentPacket;\n        if (index !== -1) {\n          const cacheEntry = this.sequentialScanCache[index];\n          currentPacket = this.createEncodedPacketFromOggPacket(\n            cacheEntry.packet,\n            {\n              timestampInSamples: cacheEntry.timestampInSamples,\n              vorbisLastBlocksize: cacheEntry.vorbisLastBlockSize\n            },\n            options\n          );\n        } else {\n          currentPacket = await this.getFirstPacket(options);\n        }\n        let i = 0;\n        while (currentPacket && currentPacket.timestamp < timestamp) {\n          const nextPacket = await this.getNextPacket(currentPacket, options);\n          if (!nextPacket || nextPacket.timestamp > timestamp) {\n            break;\n          }\n          currentPacket = nextPacket;\n          i++;\n          if (i === 100) {\n            i = 0;\n            const metadata = this.encodedPacketToMetadata.get(currentPacket);\n            assert(metadata);\n            if (this.sequentialScanCache.length > 0) {\n              assert(last(this.sequentialScanCache).timestampInSamples <= metadata.timestampInSamples);\n            }\n            this.sequentialScanCache.push(metadata);\n          }\n        }\n        return currentPacket;\n      } finally {\n        release();\n      }\n    }\n    getKeyPacket(timestamp, options) {\n      return this.getPacket(timestamp, options);\n    }\n    getNextKeyPacket(packet, options) {\n      return this.getNextPacket(packet, options);\n    }\n  };\n  var findPacketStartPosition = (pageList, endPage, endSegmentIndex) => {\n    let page = endPage;\n    let segmentIndex = endSegmentIndex;\n    outer:\n      while (true) {\n        segmentIndex--;\n        for (segmentIndex; segmentIndex >= 0; segmentIndex--) {\n          const lacingValue = page.lacingValues[segmentIndex];\n          if (lacingValue < 255) {\n            segmentIndex++;\n            break outer;\n          }\n        }\n        assert(segmentIndex === -1);\n        const pageStartsWithFreshPacket = !(page.headerType & 1);\n        if (pageStartsWithFreshPacket) {\n          segmentIndex = 0;\n          break;\n        }\n        const previousPage = findLast(\n          pageList,\n          (x) => x.headerStartPos < page.headerStartPos\n        );\n        if (!previousPage) {\n          return null;\n        }\n        page = previousPage;\n        segmentIndex = page.lacingValues.length;\n      }\n    assert(segmentIndex !== -1);\n    if (segmentIndex === page.lacingValues.length) {\n      const nextPage = pageList[pageList.indexOf(page) + 1];\n      assert(nextPage);\n      page = nextPage;\n      segmentIndex = 0;\n    }\n    return { page, segmentIndex };\n  };\n  var findPreviousPacketEndPosition = (pageList, startPage, startSegmentIndex) => {\n    if (startSegmentIndex > 0) {\n      return { page: startPage, segmentIndex: startSegmentIndex - 1 };\n    }\n    const previousPage = findLast(\n      pageList,\n      (x) => x.headerStartPos < startPage.headerStartPos\n    );\n    if (!previousPage) {\n      return null;\n    }\n    return { page: previousPage, segmentIndex: previousPage.lacingValues.length - 1 };\n  };\n\n  // src/wave/wave-demuxer.ts\n  var WaveDemuxer = class extends Demuxer {\n    constructor(input) {\n      super(input);\n      this.metadataPromise = null;\n      this.dataStart = -1;\n      this.dataSize = -1;\n      this.audioInfo = null;\n      this.tracks = [];\n      this.lastKnownPacketIndex = 0;\n      this.metadataTags = {};\n      this.reader = input._reader;\n    }\n    async readMetadata() {\n      return this.metadataPromise ??= (async () => {\n        let slice = this.reader.requestSlice(0, 12);\n        if (slice instanceof Promise) slice = await slice;\n        assert(slice);\n        const riffType = readAscii(slice, 4);\n        const littleEndian = riffType !== \"RIFX\";\n        const isRf64 = riffType === \"RF64\";\n        const outerChunkSize = readU32(slice, littleEndian);\n        let totalFileSize = isRf64 ? this.reader.fileSize : Math.min(outerChunkSize + 8, this.reader.fileSize ?? Infinity);\n        const format = readAscii(slice, 4);\n        if (format !== \"WAVE\") {\n          throw new Error(\"Invalid WAVE file - wrong format\");\n        }\n        let chunksRead = 0;\n        let dataChunkSize = null;\n        let currentPos = slice.filePos;\n        while (totalFileSize === null || currentPos < totalFileSize) {\n          let slice2 = this.reader.requestSlice(currentPos, 8);\n          if (slice2 instanceof Promise) slice2 = await slice2;\n          if (!slice2) break;\n          const chunkId = readAscii(slice2, 4);\n          const chunkSize = readU32(slice2, littleEndian);\n          const startPos = slice2.filePos;\n          if (isRf64 && chunksRead === 0 && chunkId !== \"ds64\") {\n            throw new Error('Invalid RF64 file: First chunk must be \"ds64\".');\n          }\n          if (chunkId === \"fmt \") {\n            await this.parseFmtChunk(startPos, chunkSize, littleEndian);\n          } else if (chunkId === \"data\") {\n            dataChunkSize ??= chunkSize;\n            this.dataStart = slice2.filePos;\n            this.dataSize = Math.min(dataChunkSize, (totalFileSize ?? Infinity) - this.dataStart);\n            if (this.reader.fileSize === null) {\n              break;\n            }\n          } else if (chunkId === \"ds64\") {\n            let ds64Slice = this.reader.requestSlice(startPos, chunkSize);\n            if (ds64Slice instanceof Promise) ds64Slice = await ds64Slice;\n            if (!ds64Slice) break;\n            const riffChunkSize = readU64(ds64Slice, littleEndian);\n            dataChunkSize = readU64(ds64Slice, littleEndian);\n            totalFileSize = Math.min(riffChunkSize + 8, this.reader.fileSize ?? Infinity);\n          } else if (chunkId === \"LIST\") {\n            await this.parseListChunk(startPos, chunkSize, littleEndian);\n          } else if (chunkId === \"ID3 \" || chunkId === \"id3 \") {\n            await this.parseId3Chunk(startPos, chunkSize);\n          }\n          currentPos = startPos + chunkSize + (chunkSize & 1);\n          chunksRead++;\n        }\n        if (!this.audioInfo) {\n          throw new Error('Invalid WAVE file - missing \"fmt \" chunk');\n        }\n        if (this.dataStart === -1) {\n          throw new Error('Invalid WAVE file - missing \"data\" chunk');\n        }\n        const blockSize = this.audioInfo.blockSizeInBytes;\n        this.dataSize = Math.floor(this.dataSize / blockSize) * blockSize;\n        this.tracks.push(new InputAudioTrack(this.input, new WaveAudioTrackBacking(this)));\n      })();\n    }\n    async parseFmtChunk(startPos, size, littleEndian) {\n      let slice = this.reader.requestSlice(startPos, size);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return;\n      let formatTag = readU16(slice, littleEndian);\n      const numChannels = readU16(slice, littleEndian);\n      const sampleRate = readU32(slice, littleEndian);\n      slice.skip(4);\n      const blockAlign = readU16(slice, littleEndian);\n      let bitsPerSample;\n      if (size === 14) {\n        bitsPerSample = 8;\n      } else {\n        bitsPerSample = readU16(slice, littleEndian);\n      }\n      if (size >= 18 && formatTag !== 357) {\n        const cbSize = readU16(slice, littleEndian);\n        const remainingSize = size - 18;\n        const extensionSize = Math.min(remainingSize, cbSize);\n        if (extensionSize >= 22 && formatTag === 65534 /* EXTENSIBLE */) {\n          slice.skip(2 + 4);\n          const subFormat = readBytes(slice, 16);\n          formatTag = subFormat[0] | subFormat[1] << 8;\n        }\n      }\n      if (formatTag === 7 /* MULAW */ || formatTag === 6 /* ALAW */) {\n        bitsPerSample = 8;\n      }\n      this.audioInfo = {\n        format: formatTag,\n        numberOfChannels: numChannels,\n        sampleRate,\n        sampleSizeInBytes: Math.ceil(bitsPerSample / 8),\n        blockSizeInBytes: blockAlign\n      };\n    }\n    async parseListChunk(startPos, size, littleEndian) {\n      let slice = this.reader.requestSlice(startPos, size);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return;\n      const infoType = readAscii(slice, 4);\n      if (infoType !== \"INFO\" && infoType !== \"INF0\") {\n        return;\n      }\n      let currentPos = slice.filePos;\n      while (currentPos <= startPos + size - 8) {\n        slice.filePos = currentPos;\n        const chunkName = readAscii(slice, 4);\n        const chunkSize = readU32(slice, littleEndian);\n        const bytes2 = readBytes(slice, chunkSize);\n        let stringLength = 0;\n        for (let i = 0; i < bytes2.length; i++) {\n          if (bytes2[i] === 0) {\n            break;\n          }\n          stringLength++;\n        }\n        const value = String.fromCharCode(...bytes2.subarray(0, stringLength));\n        this.metadataTags.raw ??= {};\n        this.metadataTags.raw[chunkName] = value;\n        switch (chunkName) {\n          case \"INAM\":\n          case \"TITL\":\n            {\n              this.metadataTags.title ??= value;\n            }\n            ;\n            break;\n          case \"TIT3\":\n            {\n              this.metadataTags.description ??= value;\n            }\n            ;\n            break;\n          case \"IART\":\n            {\n              this.metadataTags.artist ??= value;\n            }\n            ;\n            break;\n          case \"IPRD\":\n            {\n              this.metadataTags.album ??= value;\n            }\n            ;\n            break;\n          case \"IPRT\":\n          case \"ITRK\":\n          case \"TRCK\":\n            {\n              const parts = value.split(\"/\");\n              const trackNum = Number.parseInt(parts[0], 10);\n              const tracksTotal = parts[1] && Number.parseInt(parts[1], 10);\n              if (Number.isInteger(trackNum) && trackNum > 0) {\n                this.metadataTags.trackNumber ??= trackNum;\n              }\n              if (tracksTotal && Number.isInteger(tracksTotal) && tracksTotal > 0) {\n                this.metadataTags.tracksTotal ??= tracksTotal;\n              }\n            }\n            ;\n            break;\n          case \"ICRD\":\n          case \"IDIT\":\n            {\n              const date = new Date(value);\n              if (!Number.isNaN(date.getTime())) {\n                this.metadataTags.date ??= date;\n              }\n            }\n            ;\n            break;\n          case \"YEAR\":\n            {\n              const year = Number.parseInt(value, 10);\n              if (Number.isInteger(year) && year > 0) {\n                this.metadataTags.date ??= new Date(year, 0, 1);\n              }\n            }\n            ;\n            break;\n          case \"IGNR\":\n          case \"GENR\":\n            {\n              this.metadataTags.genre ??= value;\n            }\n            ;\n            break;\n          case \"ICMT\":\n          case \"CMNT\":\n          case \"COMM\":\n            {\n              this.metadataTags.comment ??= value;\n            }\n            ;\n            break;\n        }\n        currentPos += 8 + chunkSize + (chunkSize & 1);\n      }\n    }\n    async parseId3Chunk(startPos, size) {\n      let slice = this.reader.requestSlice(startPos, size);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return;\n      const id3V2Header = readId3V2Header(slice);\n      if (id3V2Header) {\n        const contentSlice = slice.slice(startPos + 10, id3V2Header.size);\n        parseId3V2Tag(contentSlice, id3V2Header, this.metadataTags);\n      }\n    }\n    getCodec() {\n      assert(this.audioInfo);\n      if (this.audioInfo.format === 7 /* MULAW */) {\n        return \"ulaw\";\n      }\n      if (this.audioInfo.format === 6 /* ALAW */) {\n        return \"alaw\";\n      }\n      if (this.audioInfo.format === 1 /* PCM */) {\n        if (this.audioInfo.sampleSizeInBytes === 1) {\n          return \"pcm-u8\";\n        } else if (this.audioInfo.sampleSizeInBytes === 2) {\n          return \"pcm-s16\";\n        } else if (this.audioInfo.sampleSizeInBytes === 3) {\n          return \"pcm-s24\";\n        } else if (this.audioInfo.sampleSizeInBytes === 4) {\n          return \"pcm-s32\";\n        }\n      }\n      if (this.audioInfo.format === 3 /* IEEE_FLOAT */) {\n        if (this.audioInfo.sampleSizeInBytes === 4) {\n          return \"pcm-f32\";\n        }\n      }\n      return null;\n    }\n    async getMimeType() {\n      return \"audio/wav\";\n    }\n    async computeDuration() {\n      await this.readMetadata();\n      const track = this.tracks[0];\n      assert(track);\n      return track.computeDuration();\n    }\n    async getTracks() {\n      await this.readMetadata();\n      return this.tracks;\n    }\n    async getMetadataTags() {\n      await this.readMetadata();\n      return this.metadataTags;\n    }\n  };\n  var PACKET_SIZE_IN_FRAMES = 2048;\n  var WaveAudioTrackBacking = class {\n    constructor(demuxer) {\n      this.demuxer = demuxer;\n    }\n    getId() {\n      return 1;\n    }\n    getCodec() {\n      return this.demuxer.getCodec();\n    }\n    getInternalCodecId() {\n      assert(this.demuxer.audioInfo);\n      return this.demuxer.audioInfo.format;\n    }\n    async getDecoderConfig() {\n      const codec = this.demuxer.getCodec();\n      if (!codec) {\n        return null;\n      }\n      assert(this.demuxer.audioInfo);\n      return {\n        codec,\n        numberOfChannels: this.demuxer.audioInfo.numberOfChannels,\n        sampleRate: this.demuxer.audioInfo.sampleRate\n      };\n    }\n    async computeDuration() {\n      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n    }\n    getNumberOfChannels() {\n      assert(this.demuxer.audioInfo);\n      return this.demuxer.audioInfo.numberOfChannels;\n    }\n    getSampleRate() {\n      assert(this.demuxer.audioInfo);\n      return this.demuxer.audioInfo.sampleRate;\n    }\n    getTimeResolution() {\n      assert(this.demuxer.audioInfo);\n      return this.demuxer.audioInfo.sampleRate;\n    }\n    getName() {\n      return null;\n    }\n    getLanguageCode() {\n      return UNDETERMINED_LANGUAGE;\n    }\n    getDisposition() {\n      return {\n        ...DEFAULT_TRACK_DISPOSITION\n      };\n    }\n    async getFirstTimestamp() {\n      return 0;\n    }\n    async getPacketAtIndex(packetIndex, options) {\n      assert(this.demuxer.audioInfo);\n      const startOffset = packetIndex * PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes;\n      if (startOffset >= this.demuxer.dataSize) {\n        return null;\n      }\n      const sizeInBytes = Math.min(\n        PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes,\n        this.demuxer.dataSize - startOffset\n      );\n      if (this.demuxer.reader.fileSize === null) {\n        let slice = this.demuxer.reader.requestSlice(this.demuxer.dataStart + startOffset, sizeInBytes);\n        if (slice instanceof Promise) slice = await slice;\n        if (!slice) {\n          return null;\n        }\n      }\n      let data;\n      if (options.metadataOnly) {\n        data = PLACEHOLDER_DATA;\n      } else {\n        let slice = this.demuxer.reader.requestSlice(this.demuxer.dataStart + startOffset, sizeInBytes);\n        if (slice instanceof Promise) slice = await slice;\n        assert(slice);\n        data = readBytes(slice, sizeInBytes);\n      }\n      const timestamp = packetIndex * PACKET_SIZE_IN_FRAMES / this.demuxer.audioInfo.sampleRate;\n      const duration = sizeInBytes / this.demuxer.audioInfo.blockSizeInBytes / this.demuxer.audioInfo.sampleRate;\n      this.demuxer.lastKnownPacketIndex = Math.max(\n        packetIndex,\n        timestamp\n      );\n      return new EncodedPacket(\n        data,\n        \"key\",\n        timestamp,\n        duration,\n        packetIndex,\n        sizeInBytes\n      );\n    }\n    getFirstPacket(options) {\n      return this.getPacketAtIndex(0, options);\n    }\n    async getPacket(timestamp, options) {\n      assert(this.demuxer.audioInfo);\n      const packetIndex = Math.floor(Math.min(\n        timestamp * this.demuxer.audioInfo.sampleRate / PACKET_SIZE_IN_FRAMES,\n        (this.demuxer.dataSize - 1) / (PACKET_SIZE_IN_FRAMES * this.demuxer.audioInfo.blockSizeInBytes)\n      ));\n      const packet = await this.getPacketAtIndex(packetIndex, options);\n      if (packet) {\n        return packet;\n      }\n      if (packetIndex === 0) {\n        return null;\n      }\n      assert(this.demuxer.reader.fileSize === null);\n      let currentPacket = await this.getPacketAtIndex(this.demuxer.lastKnownPacketIndex, options);\n      while (currentPacket) {\n        const nextPacket = await this.getNextPacket(currentPacket, options);\n        if (!nextPacket) {\n          break;\n        }\n        currentPacket = nextPacket;\n      }\n      return currentPacket;\n    }\n    getNextPacket(packet, options) {\n      assert(this.demuxer.audioInfo);\n      const packetIndex = Math.round(packet.timestamp * this.demuxer.audioInfo.sampleRate / PACKET_SIZE_IN_FRAMES);\n      return this.getPacketAtIndex(packetIndex + 1, options);\n    }\n    getKeyPacket(timestamp, options) {\n      return this.getPacket(timestamp, options);\n    }\n    getNextKeyPacket(packet, options) {\n      return this.getNextPacket(packet, options);\n    }\n  };\n\n  // src/adts/adts-reader.ts\n  var MIN_ADTS_FRAME_HEADER_SIZE = 7;\n  var MAX_ADTS_FRAME_HEADER_SIZE = 9;\n  var readAdtsFrameHeader = (slice) => {\n    const startPos = slice.filePos;\n    const bytes2 = readBytes(slice, 9);\n    const bitstream = new Bitstream(bytes2);\n    const syncword = bitstream.readBits(12);\n    if (syncword !== 4095) {\n      return null;\n    }\n    bitstream.skipBits(1);\n    const layer = bitstream.readBits(2);\n    if (layer !== 0) {\n      return null;\n    }\n    const protectionAbsence = bitstream.readBits(1);\n    const objectType = bitstream.readBits(2) + 1;\n    const samplingFrequencyIndex = bitstream.readBits(4);\n    if (samplingFrequencyIndex === 15) {\n      return null;\n    }\n    bitstream.skipBits(1);\n    const channelConfiguration = bitstream.readBits(3);\n    if (channelConfiguration === 0) {\n      throw new Error(\"ADTS frames with channel configuration 0 are not supported.\");\n    }\n    bitstream.skipBits(1);\n    bitstream.skipBits(1);\n    bitstream.skipBits(1);\n    bitstream.skipBits(1);\n    const frameLength = bitstream.readBits(13);\n    bitstream.skipBits(11);\n    const numberOfAacFrames = bitstream.readBits(2) + 1;\n    if (numberOfAacFrames !== 1) {\n      throw new Error(\"ADTS frames with more than one AAC frame are not supported.\");\n    }\n    let crcCheck = null;\n    if (protectionAbsence === 1) {\n      slice.filePos -= 2;\n    } else {\n      crcCheck = bitstream.readBits(16);\n    }\n    return {\n      objectType,\n      samplingFrequencyIndex,\n      channelConfiguration,\n      frameLength,\n      numberOfAacFrames,\n      crcCheck,\n      startPos\n    };\n  };\n\n  // src/adts/adts-demuxer.ts\n  var SAMPLES_PER_AAC_FRAME = 1024;\n  var AdtsDemuxer = class extends Demuxer {\n    constructor(input) {\n      super(input);\n      this.metadataPromise = null;\n      this.firstFrameHeader = null;\n      this.loadedSamples = [];\n      this.tracks = [];\n      this.readingMutex = new AsyncMutex();\n      this.lastSampleLoaded = false;\n      this.lastLoadedPos = 0;\n      this.nextTimestampInSamples = 0;\n      this.reader = input._reader;\n    }\n    async readMetadata() {\n      return this.metadataPromise ??= (async () => {\n        while (!this.firstFrameHeader && !this.lastSampleLoaded) {\n          await this.advanceReader();\n        }\n        assert(this.firstFrameHeader);\n        this.tracks = [new InputAudioTrack(this.input, new AdtsAudioTrackBacking(this))];\n      })();\n    }\n    async advanceReader() {\n      let slice = this.reader.requestSliceRange(\n        this.lastLoadedPos,\n        MIN_ADTS_FRAME_HEADER_SIZE,\n        MAX_ADTS_FRAME_HEADER_SIZE\n      );\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) {\n        this.lastSampleLoaded = true;\n        return;\n      }\n      const header = readAdtsFrameHeader(slice);\n      if (!header) {\n        this.lastSampleLoaded = true;\n        return;\n      }\n      if (this.reader.fileSize !== null && header.startPos + header.frameLength > this.reader.fileSize) {\n        this.lastSampleLoaded = true;\n        return;\n      }\n      if (!this.firstFrameHeader) {\n        this.firstFrameHeader = header;\n      }\n      const sampleRate = aacFrequencyTable[header.samplingFrequencyIndex];\n      assert(sampleRate !== void 0);\n      const sampleDuration = SAMPLES_PER_AAC_FRAME / sampleRate;\n      const sample = {\n        timestamp: this.nextTimestampInSamples / sampleRate,\n        duration: sampleDuration,\n        dataStart: header.startPos,\n        dataSize: header.frameLength\n      };\n      this.loadedSamples.push(sample);\n      this.nextTimestampInSamples += SAMPLES_PER_AAC_FRAME;\n      this.lastLoadedPos = header.startPos + header.frameLength;\n    }\n    async getMimeType() {\n      return \"audio/aac\";\n    }\n    async getTracks() {\n      await this.readMetadata();\n      return this.tracks;\n    }\n    async computeDuration() {\n      await this.readMetadata();\n      const track = this.tracks[0];\n      assert(track);\n      return track.computeDuration();\n    }\n    async getMetadataTags() {\n      return {};\n    }\n  };\n  var AdtsAudioTrackBacking = class {\n    constructor(demuxer) {\n      this.demuxer = demuxer;\n    }\n    getId() {\n      return 1;\n    }\n    async getFirstTimestamp() {\n      return 0;\n    }\n    getTimeResolution() {\n      const sampleRate = this.getSampleRate();\n      return sampleRate / SAMPLES_PER_AAC_FRAME;\n    }\n    async computeDuration() {\n      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n    }\n    getName() {\n      return null;\n    }\n    getLanguageCode() {\n      return UNDETERMINED_LANGUAGE;\n    }\n    getCodec() {\n      return \"aac\";\n    }\n    getInternalCodecId() {\n      assert(this.demuxer.firstFrameHeader);\n      return this.demuxer.firstFrameHeader.objectType;\n    }\n    getNumberOfChannels() {\n      assert(this.demuxer.firstFrameHeader);\n      const numberOfChannels = aacChannelMap[this.demuxer.firstFrameHeader.channelConfiguration];\n      assert(numberOfChannels !== void 0);\n      return numberOfChannels;\n    }\n    getSampleRate() {\n      assert(this.demuxer.firstFrameHeader);\n      const sampleRate = aacFrequencyTable[this.demuxer.firstFrameHeader.samplingFrequencyIndex];\n      assert(sampleRate !== void 0);\n      return sampleRate;\n    }\n    getDisposition() {\n      return {\n        ...DEFAULT_TRACK_DISPOSITION\n      };\n    }\n    async getDecoderConfig() {\n      assert(this.demuxer.firstFrameHeader);\n      return {\n        codec: `mp4a.40.${this.demuxer.firstFrameHeader.objectType}`,\n        numberOfChannels: this.getNumberOfChannels(),\n        sampleRate: this.getSampleRate()\n      };\n    }\n    async getPacketAtIndex(sampleIndex, options) {\n      if (sampleIndex === -1) {\n        return null;\n      }\n      const rawSample = this.demuxer.loadedSamples[sampleIndex];\n      if (!rawSample) {\n        return null;\n      }\n      let data;\n      if (options.metadataOnly) {\n        data = PLACEHOLDER_DATA;\n      } else {\n        let slice = this.demuxer.reader.requestSlice(rawSample.dataStart, rawSample.dataSize);\n        if (slice instanceof Promise) slice = await slice;\n        if (!slice) {\n          return null;\n        }\n        data = readBytes(slice, rawSample.dataSize);\n      }\n      return new EncodedPacket(\n        data,\n        \"key\",\n        rawSample.timestamp,\n        rawSample.duration,\n        sampleIndex,\n        rawSample.dataSize\n      );\n    }\n    getFirstPacket(options) {\n      return this.getPacketAtIndex(0, options);\n    }\n    async getNextPacket(packet, options) {\n      const release = await this.demuxer.readingMutex.acquire();\n      try {\n        const sampleIndex = binarySearchExact(\n          this.demuxer.loadedSamples,\n          packet.timestamp,\n          (x) => x.timestamp\n        );\n        if (sampleIndex === -1) {\n          throw new Error(\"Packet was not created from this track.\");\n        }\n        const nextIndex = sampleIndex + 1;\n        while (nextIndex >= this.demuxer.loadedSamples.length && !this.demuxer.lastSampleLoaded) {\n          await this.demuxer.advanceReader();\n        }\n        return this.getPacketAtIndex(nextIndex, options);\n      } finally {\n        release();\n      }\n    }\n    async getPacket(timestamp, options) {\n      const release = await this.demuxer.readingMutex.acquire();\n      try {\n        while (true) {\n          const index = binarySearchLessOrEqual(\n            this.demuxer.loadedSamples,\n            timestamp,\n            (x) => x.timestamp\n          );\n          if (index === -1 && this.demuxer.loadedSamples.length > 0) {\n            return null;\n          }\n          if (this.demuxer.lastSampleLoaded) {\n            return this.getPacketAtIndex(index, options);\n          }\n          if (index >= 0 && index + 1 < this.demuxer.loadedSamples.length) {\n            return this.getPacketAtIndex(index, options);\n          }\n          await this.demuxer.advanceReader();\n        }\n      } finally {\n        release();\n      }\n    }\n    getKeyPacket(timestamp, options) {\n      return this.getPacket(timestamp, options);\n    }\n    getNextKeyPacket(packet, options) {\n      return this.getNextPacket(packet, options);\n    }\n  };\n\n  // src/flac/flac-misc.ts\n  var getBlockSizeOrUncommon = (bits) => {\n    if (bits === 0) {\n      return null;\n    } else if (bits === 1) {\n      return 192;\n    } else if (bits >= 2 && bits <= 5) {\n      return 144 * 2 ** bits;\n    } else if (bits === 6) {\n      return \"uncommon-u8\";\n    } else if (bits === 7) {\n      return \"uncommon-u16\";\n    } else if (bits >= 8 && bits <= 15) {\n      return 2 ** bits;\n    } else {\n      return null;\n    }\n  };\n  var getSampleRateOrUncommon = (sampleRateBits, streamInfoSampleRate) => {\n    switch (sampleRateBits) {\n      case 0:\n        return streamInfoSampleRate;\n      case 1:\n        return 88200;\n      case 2:\n        return 176400;\n      case 3:\n        return 192e3;\n      case 4:\n        return 8e3;\n      case 5:\n        return 16e3;\n      case 6:\n        return 22050;\n      case 7:\n        return 24e3;\n      case 8:\n        return 32e3;\n      case 9:\n        return 44100;\n      case 10:\n        return 48e3;\n      case 11:\n        return 96e3;\n      case 12:\n        return \"uncommon-u8\";\n      case 13:\n        return \"uncommon-u16\";\n      case 14:\n        return \"uncommon-u16-10\";\n      default:\n        return null;\n    }\n  };\n  var readCodedNumber = (fileSlice) => {\n    let ones = 0;\n    const bitstream1 = new Bitstream(readBytes(fileSlice, 1));\n    while (bitstream1.readBits(1) === 1) {\n      ones++;\n    }\n    if (ones === 0) {\n      return bitstream1.readBits(7);\n    }\n    const bitArray = [];\n    const extraBytes = ones - 1;\n    const bitstream2 = new Bitstream(readBytes(fileSlice, extraBytes));\n    const firstByteBits = 8 - ones - 1;\n    for (let i = 0; i < firstByteBits; i++) {\n      bitArray.unshift(bitstream1.readBits(1));\n    }\n    for (let i = 0; i < extraBytes; i++) {\n      for (let j = 0; j < 8; j++) {\n        const val = bitstream2.readBits(1);\n        if (j < 2) {\n          continue;\n        }\n        bitArray.unshift(val);\n      }\n    }\n    const encoded = bitArray.reduce((acc, bit, index) => {\n      return acc | bit << index;\n    }, 0);\n    return encoded;\n  };\n  var readBlockSize = (slice, blockSizeBits) => {\n    if (blockSizeBits === \"uncommon-u16\") {\n      return readU16Be(slice) + 1;\n    } else if (blockSizeBits === \"uncommon-u8\") {\n      return readU8(slice) + 1;\n    } else if (typeof blockSizeBits === \"number\") {\n      return blockSizeBits;\n    } else {\n      assertNever(blockSizeBits);\n      assert(false);\n    }\n  };\n  var readSampleRate = (slice, sampleRateOrUncommon) => {\n    if (sampleRateOrUncommon === \"uncommon-u16\") {\n      return readU16Be(slice);\n    }\n    if (sampleRateOrUncommon === \"uncommon-u16-10\") {\n      return readU16Be(slice) * 10;\n    }\n    if (sampleRateOrUncommon === \"uncommon-u8\") {\n      return readU8(slice);\n    }\n    if (typeof sampleRateOrUncommon === \"number\") {\n      return sampleRateOrUncommon;\n    }\n    return null;\n  };\n  var calculateCrc8 = (data) => {\n    const polynomial = 7;\n    let crc = 0;\n    for (const byte of data) {\n      crc ^= byte;\n      for (let i = 0; i < 8; i++) {\n        if ((crc & 128) !== 0) {\n          crc = crc << 1 ^ polynomial;\n        } else {\n          crc <<= 1;\n        }\n        crc &= 255;\n      }\n    }\n    return crc;\n  };\n\n  // src/flac/flac-demuxer.ts\n  var FlacDemuxer = class extends Demuxer {\n    constructor(input) {\n      super(input);\n      this.loadedSamples = [];\n      // All samples from the start of the file to lastLoadedPos\n      this.metadataPromise = null;\n      this.track = null;\n      this.metadataTags = {};\n      this.audioInfo = null;\n      this.lastLoadedPos = null;\n      this.blockingBit = null;\n      this.readingMutex = new AsyncMutex();\n      this.lastSampleLoaded = false;\n      this.reader = input._reader;\n    }\n    async computeDuration() {\n      await this.readMetadata();\n      assert(this.track);\n      return this.track.computeDuration();\n    }\n    async getMetadataTags() {\n      await this.readMetadata();\n      return this.metadataTags;\n    }\n    async getTracks() {\n      await this.readMetadata();\n      assert(this.track);\n      return [this.track];\n    }\n    async getMimeType() {\n      return \"audio/flac\";\n    }\n    async readMetadata() {\n      let currentPos = 4;\n      return this.metadataPromise ??= (async () => {\n        while (this.reader.fileSize === null || currentPos < this.reader.fileSize) {\n          let sizeSlice = this.reader.requestSlice(currentPos, 4);\n          if (sizeSlice instanceof Promise) sizeSlice = await sizeSlice;\n          currentPos += 4;\n          if (sizeSlice === null) {\n            throw new Error(\n              `Metadata block at position ${currentPos} is too small! Corrupted file.`\n            );\n          }\n          assert(sizeSlice);\n          const byte = readU8(sizeSlice);\n          const size = readU24Be(sizeSlice);\n          const isLastMetadata = (byte & 128) !== 0;\n          const metaBlockType = byte & 127;\n          switch (metaBlockType) {\n            case 0 /* STREAMINFO */: {\n              let streamInfoBlock = this.reader.requestSlice(\n                currentPos,\n                size\n              );\n              if (streamInfoBlock instanceof Promise) streamInfoBlock = await streamInfoBlock;\n              assert(streamInfoBlock);\n              if (streamInfoBlock === null) {\n                throw new Error(\n                  `StreamInfo block at position ${currentPos} is too small! Corrupted file.`\n                );\n              }\n              const streamInfoBytes = readBytes(streamInfoBlock, 34);\n              const bitstream = new Bitstream(streamInfoBytes);\n              const minimumBlockSize = bitstream.readBits(16);\n              const maximumBlockSize = bitstream.readBits(16);\n              const minimumFrameSize = bitstream.readBits(24);\n              const maximumFrameSize = bitstream.readBits(24);\n              const sampleRate = bitstream.readBits(20);\n              const numberOfChannels = bitstream.readBits(3) + 1;\n              bitstream.readBits(5);\n              const totalSamples = bitstream.readBits(36);\n              bitstream.skipBits(16 * 8);\n              const description = new Uint8Array(42);\n              description.set(new Uint8Array([102, 76, 97, 67]), 0);\n              description.set(new Uint8Array([128, 0, 0, 34]), 4);\n              description.set(streamInfoBytes, 8);\n              this.audioInfo = {\n                numberOfChannels,\n                sampleRate,\n                totalSamples,\n                minimumBlockSize,\n                maximumBlockSize,\n                minimumFrameSize,\n                maximumFrameSize,\n                description\n              };\n              this.track = new InputAudioTrack(this.input, new FlacAudioTrackBacking(this));\n              break;\n            }\n            case 4 /* VORBIS_COMMENT */: {\n              let vorbisCommentBlock = this.reader.requestSlice(\n                currentPos,\n                size\n              );\n              if (vorbisCommentBlock instanceof Promise) vorbisCommentBlock = await vorbisCommentBlock;\n              assert(vorbisCommentBlock);\n              readVorbisComments(\n                readBytes(vorbisCommentBlock, size),\n                this.metadataTags\n              );\n              break;\n            }\n            case 6 /* PICTURE */: {\n              let pictureBlock = this.reader.requestSlice(\n                currentPos,\n                size\n              );\n              if (pictureBlock instanceof Promise) pictureBlock = await pictureBlock;\n              assert(pictureBlock);\n              const pictureType = readU32Be(pictureBlock);\n              const mediaTypeLength = readU32Be(pictureBlock);\n              const mediaType = textDecoder.decode(\n                readBytes(pictureBlock, mediaTypeLength)\n              );\n              const descriptionLength = readU32Be(pictureBlock);\n              const description = textDecoder.decode(\n                readBytes(pictureBlock, descriptionLength)\n              );\n              pictureBlock.skip(4 + 4 + 4 + 4);\n              const dataLength = readU32Be(pictureBlock);\n              const data = readBytes(pictureBlock, dataLength);\n              this.metadataTags.images ??= [];\n              this.metadataTags.images.push({\n                data,\n                mimeType: mediaType,\n                // https://www.rfc-editor.org/rfc/rfc9639.html#table13\n                kind: pictureType === 3 ? \"coverFront\" : pictureType === 4 ? \"coverBack\" : \"unknown\",\n                description\n              });\n              break;\n            }\n            default:\n              break;\n          }\n          currentPos += size;\n          if (isLastMetadata) {\n            this.lastLoadedPos = currentPos;\n            break;\n          }\n        }\n      })();\n    }\n    async readNextFlacFrame({\n      startPos,\n      isFirstPacket\n    }) {\n      assert(this.audioInfo);\n      const minimumHeaderLength = 6;\n      const maximumHeaderSize = 16;\n      const maximumSliceLength = this.audioInfo.maximumFrameSize + maximumHeaderSize;\n      const slice = await this.reader.requestSliceRange(\n        startPos,\n        this.audioInfo.minimumFrameSize,\n        maximumSliceLength\n      );\n      if (!slice) {\n        return null;\n      }\n      const frameHeader = this.readFlacFrameHeader({\n        slice,\n        isFirstPacket\n      });\n      if (!frameHeader) {\n        return null;\n      }\n      slice.filePos = startPos + this.audioInfo.minimumFrameSize;\n      while (true) {\n        if (slice.filePos > slice.end - minimumHeaderLength) {\n          return {\n            num: frameHeader.num,\n            blockSize: frameHeader.blockSize,\n            sampleRate: frameHeader.sampleRate,\n            size: slice.end - startPos,\n            isLastFrame: true\n          };\n        }\n        const nextByte = readU8(slice);\n        if (nextByte === 255) {\n          const positionBeforeReading = slice.filePos;\n          const byteAfterNextByte = readU8(slice);\n          const expected = this.blockingBit === 1 ? 249 : 248;\n          if (byteAfterNextByte !== expected) {\n            slice.filePos = positionBeforeReading;\n            continue;\n          }\n          slice.skip(-2);\n          const lengthIfNextFlacFrameHeaderIsLegit = slice.filePos - startPos;\n          const nextFrameHeader = this.readFlacFrameHeader({\n            slice,\n            isFirstPacket: false\n          });\n          if (!nextFrameHeader) {\n            slice.filePos = positionBeforeReading;\n            continue;\n          }\n          if (this.blockingBit === 0) {\n            if (nextFrameHeader.num - frameHeader.num !== 1) {\n              slice.filePos = positionBeforeReading;\n              continue;\n            }\n          } else {\n            if (nextFrameHeader.num - frameHeader.num !== frameHeader.blockSize) {\n              slice.filePos = positionBeforeReading;\n              continue;\n            }\n          }\n          return {\n            num: frameHeader.num,\n            blockSize: frameHeader.blockSize,\n            sampleRate: frameHeader.sampleRate,\n            size: lengthIfNextFlacFrameHeaderIsLegit,\n            isLastFrame: false\n          };\n        }\n      }\n    }\n    readFlacFrameHeader({\n      slice,\n      isFirstPacket\n    }) {\n      const startOffset = slice.filePos;\n      const bytes2 = readBytes(slice, 4);\n      const bitstream = new Bitstream(bytes2);\n      const bits = bitstream.readBits(15);\n      if (bits !== 32764) {\n        return null;\n      }\n      if (this.blockingBit === null) {\n        assert(isFirstPacket);\n        const newBlockingBit = bitstream.readBits(1);\n        this.blockingBit = newBlockingBit;\n      } else if (this.blockingBit === 1) {\n        assert(!isFirstPacket);\n        const newBlockingBit = bitstream.readBits(1);\n        if (newBlockingBit !== 1) {\n          return null;\n        }\n      } else if (this.blockingBit === 0) {\n        assert(!isFirstPacket);\n        const newBlockingBit = bitstream.readBits(1);\n        if (newBlockingBit !== 0) {\n          return null;\n        }\n      } else {\n        throw new Error(\"Invalid blocking bit\");\n      }\n      const blockSizeOrUncommon = getBlockSizeOrUncommon(bitstream.readBits(4));\n      if (!blockSizeOrUncommon) {\n        return null;\n      }\n      assert(this.audioInfo);\n      const sampleRateOrUncommon = getSampleRateOrUncommon(\n        bitstream.readBits(4),\n        this.audioInfo.sampleRate\n      );\n      if (!sampleRateOrUncommon) {\n        return null;\n      }\n      bitstream.readBits(4);\n      bitstream.readBits(3);\n      const reservedZero = bitstream.readBits(1);\n      if (reservedZero !== 0) {\n        return null;\n      }\n      const num = readCodedNumber(slice);\n      const blockSize = readBlockSize(slice, blockSizeOrUncommon);\n      const sampleRate = readSampleRate(slice, sampleRateOrUncommon);\n      if (sampleRate === null) {\n        return null;\n      }\n      if (sampleRate !== this.audioInfo.sampleRate) {\n        return null;\n      }\n      const size = slice.filePos - startOffset;\n      const crc = readU8(slice);\n      slice.skip(-size);\n      slice.skip(-1);\n      const crcCalculated = calculateCrc8(readBytes(slice, size));\n      if (crc !== crcCalculated) {\n        return null;\n      }\n      return { num, blockSize, sampleRate };\n    }\n    async advanceReader() {\n      await this.readMetadata();\n      assert(this.lastLoadedPos !== null);\n      assert(this.audioInfo);\n      const startPos = this.lastLoadedPos;\n      const frame = await this.readNextFlacFrame({\n        startPos,\n        isFirstPacket: this.loadedSamples.length === 0\n      });\n      if (!frame) {\n        this.lastSampleLoaded = true;\n        return;\n      }\n      const lastSample = this.loadedSamples[this.loadedSamples.length - 1];\n      const blockOffset = lastSample ? lastSample.blockOffset + lastSample.blockSize : 0;\n      const sample = {\n        blockOffset,\n        blockSize: frame.blockSize,\n        byteOffset: startPos,\n        byteSize: frame.size\n      };\n      this.lastLoadedPos = this.lastLoadedPos + frame.size;\n      this.loadedSamples.push(sample);\n      if (frame.isLastFrame) {\n        this.lastSampleLoaded = true;\n        return;\n      }\n    }\n  };\n  var FlacAudioTrackBacking = class {\n    constructor(demuxer) {\n      this.demuxer = demuxer;\n    }\n    getId() {\n      return 1;\n    }\n    getCodec() {\n      return \"flac\";\n    }\n    getInternalCodecId() {\n      return null;\n    }\n    getNumberOfChannels() {\n      assert(this.demuxer.audioInfo);\n      return this.demuxer.audioInfo.numberOfChannels;\n    }\n    async computeDuration() {\n      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n    }\n    getSampleRate() {\n      assert(this.demuxer.audioInfo);\n      return this.demuxer.audioInfo.sampleRate;\n    }\n    getName() {\n      return null;\n    }\n    getLanguageCode() {\n      return UNDETERMINED_LANGUAGE;\n    }\n    getTimeResolution() {\n      assert(this.demuxer.audioInfo);\n      return this.demuxer.audioInfo.sampleRate;\n    }\n    getDisposition() {\n      return {\n        ...DEFAULT_TRACK_DISPOSITION\n      };\n    }\n    async getFirstTimestamp() {\n      return 0;\n    }\n    async getDecoderConfig() {\n      assert(this.demuxer.audioInfo);\n      return {\n        codec: \"flac\",\n        numberOfChannels: this.demuxer.audioInfo.numberOfChannels,\n        sampleRate: this.demuxer.audioInfo.sampleRate,\n        description: this.demuxer.audioInfo.description\n      };\n    }\n    async getPacket(timestamp, options) {\n      assert(this.demuxer.audioInfo);\n      if (timestamp < 0) {\n        throw new Error(\"Timestamp cannot be negative\");\n      }\n      const release = await this.demuxer.readingMutex.acquire();\n      try {\n        while (true) {\n          const packetIndex = binarySearchLessOrEqual(\n            this.demuxer.loadedSamples,\n            timestamp,\n            (x) => x.blockOffset / this.demuxer.audioInfo.sampleRate\n          );\n          if (packetIndex === -1) {\n            await this.demuxer.advanceReader();\n            continue;\n          }\n          const packet = this.demuxer.loadedSamples[packetIndex];\n          const sampleTimestamp = packet.blockOffset / this.demuxer.audioInfo.sampleRate;\n          const sampleDuration = packet.blockSize / this.demuxer.audioInfo.sampleRate;\n          if (sampleTimestamp + sampleDuration <= timestamp) {\n            if (this.demuxer.lastSampleLoaded) {\n              return this.getPacketAtIndex(\n                this.demuxer.loadedSamples.length - 1,\n                options\n              );\n            }\n            await this.demuxer.advanceReader();\n            continue;\n          }\n          return this.getPacketAtIndex(packetIndex, options);\n        }\n      } finally {\n        release();\n      }\n    }\n    async getNextPacket(packet, options) {\n      const release = await this.demuxer.readingMutex.acquire();\n      try {\n        const nextIndex = packet.sequenceNumber + 1;\n        if (this.demuxer.lastSampleLoaded && nextIndex >= this.demuxer.loadedSamples.length) {\n          return null;\n        }\n        while (nextIndex >= this.demuxer.loadedSamples.length && !this.demuxer.lastSampleLoaded) {\n          await this.demuxer.advanceReader();\n        }\n        return this.getPacketAtIndex(nextIndex, options);\n      } finally {\n        release();\n      }\n    }\n    getKeyPacket(timestamp, options) {\n      return this.getPacket(timestamp, options);\n    }\n    getNextKeyPacket(packet, options) {\n      return this.getNextPacket(packet, options);\n    }\n    async getPacketAtIndex(sampleIndex, options) {\n      const rawSample = this.demuxer.loadedSamples[sampleIndex];\n      if (!rawSample) {\n        return null;\n      }\n      let data;\n      if (options.metadataOnly) {\n        data = PLACEHOLDER_DATA;\n      } else {\n        let slice = this.demuxer.reader.requestSlice(\n          rawSample.byteOffset,\n          rawSample.byteSize\n        );\n        if (slice instanceof Promise) slice = await slice;\n        if (!slice) {\n          return null;\n        }\n        data = readBytes(slice, rawSample.byteSize);\n      }\n      assert(this.demuxer.audioInfo);\n      const timestamp = rawSample.blockOffset / this.demuxer.audioInfo.sampleRate;\n      const duration = rawSample.blockSize / this.demuxer.audioInfo.sampleRate;\n      return new EncodedPacket(\n        data,\n        \"key\",\n        timestamp,\n        duration,\n        sampleIndex,\n        rawSample.byteSize\n      );\n    }\n    async getFirstPacket(options) {\n      while (this.demuxer.loadedSamples.length === 0 && !this.demuxer.lastSampleLoaded) {\n        await this.demuxer.advanceReader();\n      }\n      return this.getPacketAtIndex(0, options);\n    }\n  };\n\n  // src/mpeg-ts/mpeg-ts-misc.ts\n  var TIMESCALE = 9e4;\n  var TS_PACKET_SIZE = 188;\n  var buildMpegTsMimeType = (codecStrings) => {\n    let string = \"video/MP2T\";\n    const uniqueCodecStrings = [...new Set(codecStrings.filter(Boolean))];\n    if (uniqueCodecStrings.length > 0) {\n      string += `; codecs=\"${uniqueCodecStrings.join(\", \")}\"`;\n    }\n    return string;\n  };\n\n  // src/mpeg-ts/mpeg-ts-demuxer.ts\n  var MISSING_PES_PACKET_ERROR = \"No PES packet found where one was expected.\";\n  var MpegTsDemuxer = class extends Demuxer {\n    constructor(input) {\n      super(input);\n      this.metadataPromise = null;\n      this.elementaryStreams = [];\n      this.tracks = [];\n      this.packetOffset = 0;\n      this.packetStride = -1;\n      this.reader = input._reader;\n    }\n    async readMetadata() {\n      return this.metadataPromise ??= (async () => {\n        const lengthToCheck = TS_PACKET_SIZE + 16 + 1;\n        let startingSlice = this.reader.requestSlice(0, lengthToCheck);\n        if (startingSlice instanceof Promise) startingSlice = await startingSlice;\n        assert(startingSlice);\n        const startingBytes = readBytes(startingSlice, lengthToCheck);\n        if (startingBytes[0] === 71 && startingBytes[TS_PACKET_SIZE] === 71) {\n          this.packetOffset = 0;\n          this.packetStride = TS_PACKET_SIZE;\n        } else if (startingBytes[0] === 71 && startingBytes[TS_PACKET_SIZE + 16] === 71) {\n          this.packetOffset = 0;\n          this.packetStride = TS_PACKET_SIZE + 16;\n        } else if (startingBytes[4] === 71 && startingBytes[4 + TS_PACKET_SIZE] === 71) {\n          this.packetOffset = 4;\n          this.packetStride = TS_PACKET_SIZE;\n        } else {\n          throw new Error(\"Unreachable.\");\n        }\n        let currentPos = this.packetOffset;\n        let programMapPid = null;\n        let hasProgramAssociationTable = false;\n        let hasProgramMap = false;\n        while (true) {\n          const section = await this.readSection(currentPos, true);\n          if (!section) {\n            break;\n          }\n          const BYTES_BEFORE_SECTION_LENGTH = 3;\n          const BITS_IN_CRC_32 = 32;\n          if (section.pid === 0 && !hasProgramAssociationTable) {\n            const bitstream = new Bitstream(section.payload);\n            const pointerField = bitstream.readAlignedByte();\n            bitstream.skipBits(8 * pointerField);\n            bitstream.skipBits(14);\n            const sectionLength = bitstream.readBits(10);\n            bitstream.skipBits(40);\n            while (8 * (sectionLength + BYTES_BEFORE_SECTION_LENGTH) - bitstream.pos > BITS_IN_CRC_32) {\n              const programNumber = bitstream.readBits(16);\n              bitstream.skipBits(3);\n              if (programNumber !== 0) {\n                if (programMapPid !== null) {\n                  throw new Error(\"Only files with a single program are supported.\");\n                } else {\n                  programMapPid = bitstream.readBits(13);\n                }\n              }\n            }\n            if (programMapPid === null) {\n              throw new Error(\"Program Association Table must link to a Program Map Table.\");\n            }\n            hasProgramAssociationTable = true;\n          } else if (section.pid === programMapPid && !hasProgramMap) {\n            const bitstream = new Bitstream(section.payload);\n            const pointerField = bitstream.readAlignedByte();\n            bitstream.skipBits(8 * pointerField);\n            bitstream.skipBits(12);\n            const sectionLength = bitstream.readBits(12);\n            bitstream.skipBits(43);\n            const pcrPid = bitstream.readBits(13);\n            bitstream.skipBits(6);\n            const programInfoLength = bitstream.readBits(10);\n            bitstream.skipBits(8 * programInfoLength);\n            while (8 * (sectionLength + BYTES_BEFORE_SECTION_LENGTH) - bitstream.pos > BITS_IN_CRC_32) {\n              const streamType = bitstream.readBits(8);\n              bitstream.skipBits(3);\n              const elementaryPid = bitstream.readBits(13);\n              bitstream.skipBits(6);\n              const esInfoLength = bitstream.readBits(10);\n              bitstream.skipBits(8 * esInfoLength);\n              let info = null;\n              switch (streamType) {\n                case 3 /* MP3_MPEG1 */:\n                case 4 /* MP3_MPEG2 */:\n                case 15 /* AAC */:\n                  {\n                    const codec = streamType === 15 /* AAC */ ? \"aac\" : \"mp3\";\n                    info = {\n                      type: \"audio\",\n                      codec,\n                      aacCodecInfo: null,\n                      numberOfChannels: -1,\n                      sampleRate: -1\n                    };\n                  }\n                  ;\n                  break;\n                case 27 /* AVC */:\n                case 36 /* HEVC */:\n                  {\n                    const codec = streamType === 27 /* AVC */ ? \"avc\" : \"hevc\";\n                    info = {\n                      type: \"video\",\n                      codec,\n                      avcCodecInfo: null,\n                      hevcCodecInfo: null,\n                      colorSpace: {\n                        primaries: null,\n                        transfer: null,\n                        matrix: null,\n                        fullRange: null\n                      },\n                      width: -1,\n                      height: -1,\n                      reorderSize: -1\n                    };\n                  }\n                  ;\n                  break;\n                default: {\n                }\n              }\n              if (info) {\n                this.elementaryStreams.push({\n                  demuxer: this,\n                  pid: elementaryPid,\n                  streamType,\n                  initialized: false,\n                  firstSection: null,\n                  info\n                });\n              }\n            }\n            hasProgramMap = true;\n          } else {\n            const elementaryStream = this.elementaryStreams.find((x) => x.pid === section.pid);\n            if (elementaryStream && !elementaryStream.initialized) {\n              const pesPacket = readPesPacket(section);\n              if (!pesPacket) {\n                throw new Error(\n                  `Couldn't read first PES packet for Elementary Stream with PID ${elementaryStream.pid}`\n                );\n              }\n              elementaryStream.firstSection = section;\n              if (elementaryStream.info.type === \"video\") {\n                if (elementaryStream.info.codec === \"avc\") {\n                  elementaryStream.info.avcCodecInfo = extractAvcDecoderConfigurationRecord(pesPacket.data);\n                  if (!elementaryStream.info.avcCodecInfo) {\n                    throw new Error(\n                      \"Invalid AVC video stream; could not extract AVCDecoderConfigurationRecord from first packet.\"\n                    );\n                  }\n                  const spsUnit = elementaryStream.info.avcCodecInfo.sequenceParameterSets[0];\n                  assert(spsUnit);\n                  const spsInfo = parseAvcSps(spsUnit);\n                  elementaryStream.info.width = spsInfo.displayWidth;\n                  elementaryStream.info.height = spsInfo.displayHeight;\n                  elementaryStream.info.colorSpace = {\n                    primaries: COLOR_PRIMARIES_MAP_INVERSE[spsInfo.colourPrimaries],\n                    transfer: TRANSFER_CHARACTERISTICS_MAP_INVERSE[spsInfo.transferCharacteristics],\n                    matrix: MATRIX_COEFFICIENTS_MAP_INVERSE[spsInfo.matrixCoefficients],\n                    fullRange: !!spsInfo.fullRangeFlag\n                  };\n                  elementaryStream.info.reorderSize = spsInfo.maxDecFrameBuffering;\n                  elementaryStream.initialized = true;\n                } else if (elementaryStream.info.codec === \"hevc\") {\n                  elementaryStream.info.hevcCodecInfo = extractHevcDecoderConfigurationRecord(pesPacket.data);\n                  if (!elementaryStream.info.hevcCodecInfo) {\n                    throw new Error(\n                      \"Invalid HEVC video stream; could not extract HVCDecoderConfigurationRecord from first packet.\"\n                    );\n                  }\n                  const spsArray = elementaryStream.info.hevcCodecInfo.arrays.find(\n                    (a) => a.nalUnitType === 33 /* SPS_NUT */\n                  );\n                  const spsUnit = spsArray.nalUnits[0];\n                  assert(spsUnit);\n                  const spsInfo = parseHevcSps(spsUnit);\n                  elementaryStream.info.width = spsInfo.displayWidth;\n                  elementaryStream.info.height = spsInfo.displayHeight;\n                  elementaryStream.info.colorSpace = {\n                    primaries: COLOR_PRIMARIES_MAP_INVERSE[spsInfo.colourPrimaries],\n                    transfer: TRANSFER_CHARACTERISTICS_MAP_INVERSE[spsInfo.transferCharacteristics],\n                    matrix: MATRIX_COEFFICIENTS_MAP_INVERSE[spsInfo.matrixCoefficients],\n                    fullRange: !!spsInfo.fullRangeFlag\n                  };\n                  elementaryStream.info.reorderSize = spsInfo.maxDecFrameBuffering;\n                  elementaryStream.initialized = true;\n                } else {\n                  throw new Error(\"Unhandled.\");\n                }\n              } else {\n                if (elementaryStream.info.codec === \"aac\") {\n                  const slice = FileSlice4.tempFromBytes(pesPacket.data);\n                  const header = readAdtsFrameHeader(slice);\n                  if (!header) {\n                    throw new Error(\n                      \"Invalid AAC audio stream; could not read ADTS frame header from first packet.\"\n                    );\n                  }\n                  elementaryStream.info.aacCodecInfo = {\n                    isMpeg2: false,\n                    objectType: header.objectType\n                  };\n                  elementaryStream.info.numberOfChannels = aacChannelMap[header.channelConfiguration];\n                  elementaryStream.info.sampleRate = aacFrequencyTable[header.samplingFrequencyIndex];\n                  elementaryStream.initialized = true;\n                } else if (elementaryStream.info.codec === \"mp3\") {\n                  const word = readU32Be(FileSlice4.tempFromBytes(pesPacket.data));\n                  const result = readMp3FrameHeader(word, pesPacket.data.byteLength);\n                  if (!result.header) {\n                    throw new Error(\n                      \"Invalid MP3 audio stream; could not read frame header from first packet.\"\n                    );\n                  }\n                  elementaryStream.info.numberOfChannels = result.header.channel === 3 ? 1 : 2;\n                  elementaryStream.info.sampleRate = result.header.sampleRate;\n                  elementaryStream.initialized = true;\n                } else {\n                  throw new Error(\"Unhandled.\");\n                }\n              }\n            }\n          }\n          const isDone = hasProgramMap && this.elementaryStreams.every((x) => x.initialized);\n          if (isDone) {\n            break;\n          }\n          assert(section.endPos !== null);\n          currentPos = section.endPos;\n        }\n        for (const stream of this.elementaryStreams) {\n          if (stream.info.type === \"video\") {\n            this.tracks.push(\n              new InputVideoTrack(\n                this.input,\n                new MpegTsVideoTrackBacking(stream)\n              )\n            );\n          } else {\n            this.tracks.push(\n              new InputAudioTrack(\n                this.input,\n                new MpegTsAudioTrackBacking(stream)\n              )\n            );\n          }\n        }\n      })();\n    }\n    async getTracks() {\n      await this.readMetadata();\n      return this.tracks;\n    }\n    async getMetadataTags() {\n      return {};\n    }\n    async computeDuration() {\n      const tracks = await this.getTracks();\n      const trackDurations = await Promise.all(tracks.map((x) => x.computeDuration()));\n      return Math.max(0, ...trackDurations);\n    }\n    async getMimeType() {\n      await this.readMetadata();\n      const tracks = await this.getTracks();\n      const codecStrings = await Promise.all(tracks.map((x) => x.getCodecParameterString()));\n      return buildMpegTsMimeType(codecStrings);\n    }\n    async readSection(startPos, full) {\n      let endPos = startPos;\n      let currentPos = startPos;\n      const chunks = [];\n      let chunksByteLength = 0;\n      let firstPacket = null;\n      while (true) {\n        const packet = await this.readPacket(currentPos);\n        currentPos += this.packetStride;\n        if (!packet) {\n          break;\n        }\n        if (!firstPacket) {\n          if (packet.payloadUnitStartIndicator === 0) {\n            break;\n          }\n          firstPacket = packet;\n        } else {\n          if (packet.pid !== firstPacket.pid) {\n            continue;\n          }\n          if (packet.payloadUnitStartIndicator === 1) {\n            break;\n          }\n        }\n        const hasAdaptationField = !!(packet.adaptationFieldControl & 2);\n        const hasPayload = !!(packet.adaptationFieldControl & 1);\n        let adaptationFieldLength = 0;\n        if (hasAdaptationField) {\n          adaptationFieldLength = 1 + packet.body[0];\n        }\n        if (hasPayload) {\n          if (adaptationFieldLength === 0) {\n            chunks.push(packet.body);\n            chunksByteLength += packet.body.byteLength;\n          } else {\n            chunks.push(packet.body.subarray(adaptationFieldLength));\n            chunksByteLength += packet.body.byteLength - adaptationFieldLength;\n          }\n        }\n        endPos = currentPos;\n        if (!full && chunksByteLength >= 64) {\n          break;\n        }\n      }\n      if (!firstPacket) {\n        return null;\n      }\n      let merged;\n      if (chunks.length === 1) {\n        merged = chunks[0];\n      } else {\n        const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);\n        merged = new Uint8Array(totalLength);\n        let offset = 0;\n        for (const chunk of chunks) {\n          merged.set(chunk, offset);\n          offset += chunk.length;\n        }\n      }\n      return {\n        startPos,\n        endPos: full ? endPos : null,\n        pid: firstPacket.pid,\n        payload: merged\n      };\n    }\n    async readPacketHeader(pos) {\n      let slice = this.reader.requestSlice(pos, 4);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) {\n        return null;\n      }\n      const syncByte = readU8(slice);\n      if (syncByte !== 71) {\n        throw new Error(\"Invalid TS packet sync byte. Likely an internal bug, please report this file.\");\n      }\n      const nextTwoBytes = readU16Be(slice);\n      const transportErrorIndicator = nextTwoBytes >> 15;\n      const payloadUnitStartIndicator = nextTwoBytes >> 14 & 1;\n      const transportPriority = nextTwoBytes >> 13 & 1;\n      const pid = nextTwoBytes & 8191;\n      const nextByte = readU8(slice);\n      const transportScramblingControl = nextByte >> 6;\n      const adaptationFieldControl = nextByte >> 4 & 3;\n      const continuityCounter = nextByte & 15;\n      return {\n        payloadUnitStartIndicator,\n        pid,\n        adaptationFieldControl\n      };\n    }\n    async readPacket(pos) {\n      let slice = this.reader.requestSlice(pos, TS_PACKET_SIZE);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) {\n        return null;\n      }\n      const bytes2 = readBytes(slice, TS_PACKET_SIZE);\n      const syncByte = bytes2[0];\n      if (syncByte !== 71) {\n        throw new Error(\"Invalid TS packet sync byte. Likely an internal bug, please report this file.\");\n      }\n      const nextTwoBytes = (bytes2[1] << 8) + bytes2[2];\n      const transportErrorIndicator = nextTwoBytes >> 15;\n      const payloadUnitStartIndicator = nextTwoBytes >> 14 & 1;\n      const transportPriority = nextTwoBytes >> 13 & 1;\n      const pid = nextTwoBytes & 8191;\n      const nextByte = bytes2[3];\n      const transportScramblingControl = nextByte >> 6;\n      const adaptationFieldControl = nextByte >> 4 & 3;\n      const continuityCounter = nextByte & 15;\n      return {\n        payloadUnitStartIndicator,\n        pid,\n        adaptationFieldControl,\n        body: bytes2.subarray(4)\n      };\n    }\n  };\n  var readPesPacketHeader = (section) => {\n    const bitstream = new Bitstream(section.payload);\n    const startCodePrefix = bitstream.readBits(24);\n    if (startCodePrefix !== 1) {\n      return null;\n    }\n    const streamId = bitstream.readBits(8);\n    bitstream.skipBits(16);\n    if (streamId === 188 || streamId === 190 || streamId === 191 || streamId === 240 || streamId === 241 || streamId === 255 || streamId === 242 || streamId === 248) {\n      return null;\n    }\n    bitstream.skipBits(8);\n    const ptsDtsFlags = bitstream.readBits(2);\n    bitstream.skipBits(14);\n    let pts = 0;\n    if (ptsDtsFlags === 2 || ptsDtsFlags === 3) {\n      bitstream.skipBits(4);\n      pts += bitstream.readBits(3) * (1 << 30);\n      bitstream.skipBits(1);\n      pts += bitstream.readBits(15) * (1 << 15);\n      bitstream.skipBits(1);\n      pts += bitstream.readBits(15);\n    } else {\n      throw new Error(\n        \"PES packets without PTS are not currently supported. If you think this file should be supported, please report it.\"\n      );\n    }\n    return {\n      sectionStartPos: section.startPos,\n      sectionEndPos: section.endPos,\n      pts\n    };\n  };\n  var readPesPacket = (section) => {\n    assert(section.endPos !== null);\n    const header = readPesPacketHeader(section);\n    if (!header) {\n      return null;\n    }\n    const bitstream = new Bitstream(section.payload);\n    bitstream.skipBits(32);\n    const pesPacketLength = bitstream.readBits(16);\n    const BYTES_UNTIL_END_OF_PES_PACKET_LENGTH = 6;\n    bitstream.skipBits(16);\n    const pesHeaderDataLength = bitstream.readBits(8);\n    const pesHeaderEndPos = bitstream.pos + 8 * pesHeaderDataLength;\n    bitstream.pos = pesHeaderEndPos;\n    const bytePos = pesHeaderEndPos / 8;\n    assert(Number.isInteger(bytePos));\n    const data = section.payload.subarray(\n      bytePos,\n      // \"A value of 0 indicates that the PES packet length is neither specified nor bounded and is allowed only in\n      // PES packets whose payload consists of bytes from a video elementary stream contained in\n      // transport stream packets.\"\n      pesPacketLength > 0 ? BYTES_UNTIL_END_OF_PES_PACKET_LENGTH + pesPacketLength : section.payload.byteLength\n    );\n    return {\n      ...header,\n      data\n    };\n  };\n  var MpegTsTrackBacking = class {\n    constructor(elementaryStream) {\n      this.elementaryStream = elementaryStream;\n      /**\n       * Reference PES packets, spread throughout the file, to be used to speed up random access and perform\n       * binary search for packets.\n       */\n      this.referencePesPackets = [];\n      this.endReferencePesPacketAdded = false;\n      this.packetBuffers = /* @__PURE__ */ new WeakMap();\n      /** Used for recreating PacketBuffers if necessary. */\n      this.packetSectionStarts = /* @__PURE__ */ new WeakMap();\n      this.mutex = new AsyncMutex();\n    }\n    getId() {\n      return this.elementaryStream.pid;\n    }\n    getCodec() {\n      throw new Error(\"Not implemented on base class.\");\n    }\n    getInternalCodecId() {\n      return this.elementaryStream.streamType;\n    }\n    getName() {\n      return null;\n    }\n    getLanguageCode() {\n      return UNDETERMINED_LANGUAGE;\n    }\n    getDisposition() {\n      return DEFAULT_TRACK_DISPOSITION;\n    }\n    getTimeResolution() {\n      return TIMESCALE;\n    }\n    async computeDuration() {\n      const lastPacket = await this.getPacket(Infinity, { metadataOnly: true });\n      return (lastPacket?.timestamp ?? 0) + (lastPacket?.duration ?? 0);\n    }\n    async getFirstTimestamp() {\n      const firstPacket = await this.getFirstPacket({ metadataOnly: true });\n      return firstPacket?.timestamp ?? 0;\n    }\n    createEncodedPacket(suppliedPacket, duration, options) {\n      return new EncodedPacket(\n        options.metadataOnly ? PLACEHOLDER_DATA : suppliedPacket.data,\n        this.getPacketType(suppliedPacket.data),\n        suppliedPacket.pts / TIMESCALE,\n        Math.max(duration / TIMESCALE, 0),\n        suppliedPacket.sequenceNumber,\n        suppliedPacket.data.byteLength\n      );\n    }\n    maybeInsertReferencePacket(pesPacketHeader, force, dropIfMutexLocked) {\n      if (dropIfMutexLocked && this.mutex.pending > 0) {\n        return;\n      }\n      const index = binarySearchLessOrEqual(this.referencePesPackets, pesPacketHeader.pts, (x) => x.pts);\n      if (index >= 0) {\n        const entry = this.referencePesPackets[index];\n        if (pesPacketHeader.sectionStartPos <= entry.sectionStartPos) {\n          return false;\n        }\n        if (!force && pesPacketHeader.pts - entry.pts < TIMESCALE / 2) {\n          return false;\n        }\n        if (index < this.referencePesPackets.length - 1) {\n          const nextEntry = this.referencePesPackets[index + 1];\n          if (nextEntry.sectionStartPos < pesPacketHeader.sectionStartPos) {\n            return false;\n          }\n          if (!force && nextEntry.pts - pesPacketHeader.pts < TIMESCALE / 2) {\n            return false;\n          }\n        }\n      }\n      this.referencePesPackets.splice(index + 1, 0, pesPacketHeader);\n      return true;\n    }\n    async getFirstPacket(options) {\n      const section = this.elementaryStream.firstSection;\n      assert(section);\n      const pesPacket = readPesPacket(section);\n      assert(pesPacket);\n      const context = new PacketReadingContext(this, pesPacket, true);\n      const buffer = new PacketBuffer(this, context);\n      const result = await buffer.readNext();\n      if (!result) {\n        return null;\n      }\n      const packet = this.createEncodedPacket(result.packet, result.duration, options);\n      this.packetBuffers.set(packet, buffer);\n      this.packetSectionStarts.set(packet, result.packet.sectionStartPos);\n      return packet;\n    }\n    async getNextPacket(packet, options) {\n      let buffer = this.packetBuffers.get(packet);\n      if (buffer) {\n        const result = await buffer.readNext();\n        if (!result) {\n          return null;\n        }\n        this.packetBuffers.delete(packet);\n        const newPacket = this.createEncodedPacket(result.packet, result.duration, options);\n        this.packetBuffers.set(newPacket, buffer);\n        this.packetSectionStarts.set(newPacket, result.packet.sectionStartPos);\n        return newPacket;\n      }\n      const sectionStartPos = this.packetSectionStarts.get(packet);\n      if (sectionStartPos === void 0) {\n        throw new Error(\"Packet was not created from this track.\");\n      }\n      const demuxer = this.elementaryStream.demuxer;\n      const section = await demuxer.readSection(sectionStartPos, true);\n      assert(section);\n      const pesPacket = readPesPacket(section);\n      assert(pesPacket);\n      const context = new PacketReadingContext(this, pesPacket, true);\n      buffer = new PacketBuffer(this, context);\n      const targetSequenceNumber = packet.sequenceNumber;\n      while (true) {\n        const result = await buffer.readNext();\n        if (!result) {\n          return null;\n        }\n        if (result.packet.sequenceNumber > targetSequenceNumber) {\n          const newPacket = this.createEncodedPacket(result.packet, result.duration, options);\n          this.packetBuffers.set(newPacket, buffer);\n          this.packetSectionStarts.set(newPacket, result.packet.sectionStartPos);\n          return newPacket;\n        }\n      }\n    }\n    async getNextKeyPacket(packet, options) {\n      let currentPacket = packet;\n      while (true) {\n        currentPacket = await this.getNextPacket(currentPacket, options);\n        if (!currentPacket) {\n          return null;\n        }\n        if (currentPacket.type === \"key\") {\n          return currentPacket;\n        }\n      }\n    }\n    getPacket(timestamp, options) {\n      return this.doPacketLookup(timestamp, false, options);\n    }\n    getKeyPacket(timestamp, options) {\n      return this.doPacketLookup(timestamp, true, options);\n    }\n    /**\n     * Searches for the packet with the largest timestamp not larger than `timestamp` in the file, using a combination\n     * of binary search and linear refinement.\n     */\n    async doPacketLookup(timestamp, keyframesOnly, options) {\n      const searchPts = roundIfAlmostInteger(timestamp * TIMESCALE);\n      const demuxer = this.elementaryStream.demuxer;\n      const reader = demuxer.reader;\n      const release = await this.mutex.acquire();\n      let currentPesPacketHeader;\n      try {\n        if (this.referencePesPackets.length === 0) {\n          const section2 = this.elementaryStream.firstSection;\n          assert(section2);\n          const pesPacketHeader = readPesPacketHeader(section2);\n          assert(pesPacketHeader);\n          this.maybeInsertReferencePacket(pesPacketHeader, false, false);\n          assert(this.referencePesPackets.length === 1);\n        }\n        let currentIndex = binarySearchLessOrEqual(this.referencePesPackets, searchPts, (x) => x.pts);\n        if (currentIndex === -1) {\n          return null;\n        }\n        const needsToLookForLastPacket = reader.fileSize !== null && currentIndex === this.referencePesPackets.length - 1 && !this.endReferencePesPacketAdded;\n        if (needsToLookForLastPacket) {\n          let currentPos = reader.fileSize - demuxer.packetStride + demuxer.packetOffset;\n          let packetHeader = await demuxer.readPacketHeader(currentPos);\n          if (!packetHeader) {\n            return null;\n          }\n          while (packetHeader.pid !== this.elementaryStream.pid || packetHeader.payloadUnitStartIndicator === 0) {\n            currentPos -= demuxer.packetStride;\n            const previousPacketHeader = await demuxer.readPacketHeader(currentPos);\n            if (!previousPacketHeader) {\n              return null;\n            }\n            packetHeader = previousPacketHeader;\n          }\n          const section2 = await demuxer.readSection(currentPos, false);\n          assert(section2);\n          const pesPacketHeader = readPesPacketHeader(section2);\n          if (!pesPacketHeader) {\n            throw new Error(MISSING_PES_PACKET_ERROR);\n          }\n          this.maybeInsertReferencePacket(pesPacketHeader, true, false);\n          this.endReferencePesPacketAdded = true;\n        }\n        currentIndex = binarySearchLessOrEqual(this.referencePesPackets, searchPts, (x) => x.pts);\n        assert(currentIndex !== -1);\n        while (reader.fileSize !== null) {\n          const currentEntry = this.referencePesPackets[currentIndex];\n          const nextEntry = this.referencePesPackets[currentIndex + 1];\n          if (searchPts - currentEntry.pts < TIMESCALE || !nextEntry) {\n            break;\n          }\n          const midpoint = roundToMultiple(\n            (currentEntry.sectionStartPos + nextEntry.sectionStartPos) / 2,\n            demuxer.packetStride\n          ) + demuxer.packetOffset;\n          let currentPos = midpoint;\n          let packetHeader = await demuxer.readPacketHeader(currentPos);\n          assert(packetHeader);\n          while (currentPos < nextEntry.sectionStartPos && (packetHeader.pid !== this.elementaryStream.pid || packetHeader.payloadUnitStartIndicator === 0)) {\n            currentPos += demuxer.packetStride;\n            const previousPacketHeader = await demuxer.readPacketHeader(currentPos);\n            if (!previousPacketHeader) {\n              return null;\n            }\n            packetHeader = previousPacketHeader;\n          }\n          if (currentPos >= nextEntry.sectionStartPos) {\n            break;\n          }\n          const section2 = await demuxer.readSection(currentPos, false);\n          assert(section2);\n          const pesPacketHeader = readPesPacketHeader(section2);\n          if (!pesPacketHeader) {\n            throw new Error(MISSING_PES_PACKET_ERROR);\n          }\n          const addedPoint = this.maybeInsertReferencePacket(pesPacketHeader, false, false);\n          if (!addedPoint) {\n            break;\n          }\n          if (pesPacketHeader.pts <= searchPts) {\n            currentIndex++;\n          }\n        }\n        currentPesPacketHeader = this.referencePesPackets[currentIndex];\n        assert(currentPesPacketHeader.pts <= searchPts);\n      } finally {\n        release();\n      }\n      release();\n      outer:\n        while (true) {\n          let currentPos = currentPesPacketHeader.sectionStartPos + demuxer.packetStride;\n          while (true) {\n            const packetHeader = await demuxer.readPacketHeader(currentPos);\n            if (!packetHeader) {\n              break outer;\n            }\n            if (packetHeader.pid === this.elementaryStream.pid && packetHeader.payloadUnitStartIndicator === 1) {\n              break;\n            }\n            currentPos += demuxer.packetStride;\n          }\n          const nextSection = await demuxer.readSection(currentPos, false);\n          if (!nextSection) {\n            break;\n          }\n          const nextPesPacketHeader = readPesPacketHeader(nextSection);\n          if (!nextPesPacketHeader) {\n            throw new Error(MISSING_PES_PACKET_ERROR);\n          }\n          if (nextPesPacketHeader.pts > searchPts) {\n            break;\n          }\n          currentPesPacketHeader = nextPesPacketHeader;\n          if (reader.fileSize === null) {\n            this.maybeInsertReferencePacket(nextPesPacketHeader, false, true);\n          }\n        }\n      const reorderSize = this.getReorderSize();\n      for (let i = 0; i < reorderSize; i++) {\n        let pos = currentPesPacketHeader.sectionStartPos - demuxer.packetStride;\n        while (true) {\n          const packetHeader = await demuxer.readPacketHeader(pos);\n          if (!packetHeader) {\n            break;\n          }\n          if (packetHeader.pid === this.elementaryStream.pid && packetHeader.payloadUnitStartIndicator === 1) {\n            const headerSection = await demuxer.readSection(pos, false);\n            assert(headerSection);\n            const header = readPesPacketHeader(headerSection);\n            if (!header) {\n              throw new Error(MISSING_PES_PACKET_ERROR);\n            }\n            currentPesPacketHeader = header;\n            break;\n          }\n          pos -= demuxer.packetStride;\n        }\n      }\n      const section = await demuxer.readSection(currentPesPacketHeader.sectionStartPos, true);\n      assert(section);\n      const pesPacket = readPesPacket(section);\n      assert(pesPacket);\n      const context = new PacketReadingContext(this, pesPacket, true);\n      const buffer = new PacketBuffer(this, context);\n      while (true) {\n        const topPts = last(buffer.presentationOrderPackets)?.pts ?? -Infinity;\n        if (topPts >= searchPts) {\n          break;\n        }\n        const didRead = await buffer.readNextDecodeOrderPacket();\n        if (!didRead) {\n          break;\n        }\n      }\n      const targetIndex = findLastIndex(\n        buffer.presentationOrderPackets,\n        (p) => p.pts <= searchPts && (!keyframesOnly || this.getPacketType(p.data) === \"key\")\n      );\n      if (targetIndex !== -1) {\n        const targetPacket = buffer.presentationOrderPackets[targetIndex];\n        const lastDuration = targetIndex === 0 ? 0 : targetPacket.pts - buffer.presentationOrderPackets[targetIndex - 1].pts;\n        while (buffer.decodeOrderPackets[0] !== targetPacket) {\n          buffer.decodeOrderPackets.shift();\n        }\n        buffer.lastDuration = lastDuration;\n        const result = await buffer.readNext();\n        assert(result);\n        const packet = this.createEncodedPacket(result.packet, result.duration, options);\n        this.packetBuffers.set(packet, buffer);\n        this.packetSectionStarts.set(packet, result.packet.sectionStartPos);\n        return packet;\n      }\n      if (!keyframesOnly) {\n        return null;\n      }\n      let searchPos = currentPesPacketHeader.sectionStartPos;\n      while (true) {\n        searchPos -= demuxer.packetStride;\n        const packetHeader = await demuxer.readPacketHeader(searchPos);\n        if (!packetHeader) {\n          return null;\n        }\n        if (packetHeader.pid !== this.elementaryStream.pid || packetHeader.payloadUnitStartIndicator !== 1) {\n          continue;\n        }\n        const section2 = await demuxer.readSection(searchPos, true);\n        assert(section2);\n        const pesPacket2 = readPesPacket(section2);\n        if (!pesPacket2) {\n          throw new Error(MISSING_PES_PACKET_ERROR);\n        }\n        const context2 = new PacketReadingContext(this, pesPacket2, false);\n        await this.markNextPacket(context2);\n        if (!context2.suppliedPacket) {\n          continue;\n        }\n        if (this.getPacketType(context2.suppliedPacket.data) !== \"key\") {\n          continue;\n        }\n        context2.uncapped = true;\n        const buffer2 = new PacketBuffer(this, context2);\n        const result = await buffer2.readNext();\n        assert(result);\n        const packet = this.createEncodedPacket(result.packet, result.duration, options);\n        this.packetBuffers.set(packet, buffer2);\n        this.packetSectionStarts.set(packet, result.packet.sectionStartPos);\n        return packet;\n      }\n    }\n  };\n  var MpegTsVideoTrackBacking = class extends MpegTsTrackBacking {\n    constructor(elementaryStream) {\n      super(elementaryStream);\n      this.elementaryStream = elementaryStream;\n      this.decoderConfig = {\n        codec: extractVideoCodecString({\n          width: this.elementaryStream.info.width,\n          height: this.elementaryStream.info.height,\n          codec: this.elementaryStream.info.codec,\n          codecDescription: null,\n          colorSpace: this.elementaryStream.info.colorSpace,\n          avcType: 1,\n          avcCodecInfo: this.elementaryStream.info.avcCodecInfo,\n          hevcCodecInfo: this.elementaryStream.info.hevcCodecInfo,\n          vp9CodecInfo: null,\n          av1CodecInfo: null\n        }),\n        codedWidth: this.elementaryStream.info.width,\n        codedHeight: this.elementaryStream.info.height,\n        colorSpace: this.elementaryStream.info.colorSpace\n      };\n    }\n    getCodec() {\n      return this.elementaryStream.info.codec;\n    }\n    getCodedWidth() {\n      return this.elementaryStream.info.width;\n    }\n    getCodedHeight() {\n      return this.elementaryStream.info.height;\n    }\n    getRotation() {\n      return 0;\n    }\n    async getColorSpace() {\n      return this.elementaryStream.info.colorSpace;\n    }\n    async canBeTransparent() {\n      return false;\n    }\n    async getDecoderConfig() {\n      return this.decoderConfig;\n    }\n    getPacketType(packetData) {\n      return determineVideoPacketType(this.elementaryStream.info.codec, this.decoderConfig, packetData) ?? \"key\";\n    }\n    getReorderSize() {\n      return this.elementaryStream.info.reorderSize;\n    }\n    async markNextPacket(context) {\n      assert(!context.suppliedPacket);\n      const codec = this.elementaryStream.info.codec;\n      const CHUNK_SIZE = 1024;\n      let packetStartPos = null;\n      while (true) {\n        let remaining = context.ensureBuffered(CHUNK_SIZE);\n        if (remaining instanceof Promise) remaining = await remaining;\n        if (remaining === 0) {\n          break;\n        }\n        const chunkStartPos = context.currentPos;\n        const chunk = context.readBytes(remaining);\n        const length = chunk.byteLength;\n        let i = 0;\n        while (i < length) {\n          const zeroIndex = chunk.indexOf(0, i);\n          if (zeroIndex === -1 || zeroIndex >= length) {\n            break;\n          }\n          i = zeroIndex;\n          const posBeforeZero = chunkStartPos + i;\n          if (i + 4 >= length) {\n            context.seekTo(posBeforeZero);\n            break;\n          }\n          const b1 = chunk[i + 1];\n          const b2 = chunk[i + 2];\n          const b3 = chunk[i + 3];\n          let startCodeLength = 0;\n          let nalUnitTypeByte = null;\n          if (b1 === 0 && b2 === 0 && b3 === 1) {\n            startCodeLength = 4;\n            nalUnitTypeByte = chunk[i + 4];\n          } else if (b1 === 0 && b2 === 1) {\n            startCodeLength = 3;\n            nalUnitTypeByte = b3;\n          }\n          if (startCodeLength === 0) {\n            i++;\n            continue;\n          }\n          const startCodePos = posBeforeZero;\n          if (packetStartPos === null) {\n            packetStartPos = startCodePos;\n            i += startCodeLength;\n            continue;\n          }\n          if (nalUnitTypeByte !== null) {\n            const nalUnitType = codec === \"avc\" ? extractNalUnitTypeForAvc(nalUnitTypeByte) : extractNalUnitTypeForHevc(nalUnitTypeByte);\n            const isAud = codec === \"avc\" ? nalUnitType === 9 /* AUD */ : nalUnitType === 35 /* AUD_NUT */;\n            if (isAud) {\n              const packetLength = startCodePos - packetStartPos;\n              context.seekTo(packetStartPos);\n              return context.supplyPacket(packetLength, 0);\n            }\n          }\n          i += startCodeLength;\n        }\n        if (remaining < CHUNK_SIZE) {\n          break;\n        }\n      }\n      if (packetStartPos !== null) {\n        const packetLength = context.endPos - packetStartPos;\n        context.seekTo(packetStartPos);\n        return context.supplyPacket(packetLength, 0);\n      }\n    }\n  };\n  var MpegTsAudioTrackBacking = class extends MpegTsTrackBacking {\n    constructor(elementaryStream) {\n      super(elementaryStream);\n      this.elementaryStream = elementaryStream;\n    }\n    getCodec() {\n      return this.elementaryStream.info.codec;\n    }\n    getNumberOfChannels() {\n      return this.elementaryStream.info.numberOfChannels;\n    }\n    getSampleRate() {\n      return this.elementaryStream.info.sampleRate;\n    }\n    async getDecoderConfig() {\n      return {\n        codec: extractAudioCodecString({\n          codec: this.elementaryStream.info.codec,\n          codecDescription: null,\n          aacCodecInfo: this.elementaryStream.info.aacCodecInfo\n        }),\n        numberOfChannels: this.elementaryStream.info.numberOfChannels,\n        sampleRate: this.elementaryStream.info.sampleRate\n      };\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    getPacketType(packetData) {\n      return \"key\";\n    }\n    getReorderSize() {\n      return 1;\n    }\n    async markNextPacket(context) {\n      assert(!context.suppliedPacket);\n      const codec = this.elementaryStream.info.codec;\n      const CHUNK_SIZE = 128;\n      while (true) {\n        let remaining = context.ensureBuffered(CHUNK_SIZE);\n        if (remaining instanceof Promise) remaining = await remaining;\n        const startPos = context.currentPos;\n        while (context.currentPos - startPos < remaining) {\n          const byte = context.readU8();\n          if (codec === \"aac\") {\n            if (byte !== 255) {\n              continue;\n            }\n            context.skip(-1);\n            const possibleHeaderStartPos = context.currentPos;\n            let remaining2 = context.ensureBuffered(MAX_ADTS_FRAME_HEADER_SIZE);\n            if (remaining2 instanceof Promise) remaining2 = await remaining2;\n            if (remaining2 < MAX_ADTS_FRAME_HEADER_SIZE) {\n              return;\n            }\n            const headerBytes = context.readBytes(MAX_ADTS_FRAME_HEADER_SIZE);\n            const header = readAdtsFrameHeader(FileSlice4.tempFromBytes(headerBytes));\n            if (header) {\n              context.seekTo(possibleHeaderStartPos);\n              let remaining3 = context.ensureBuffered(header.frameLength);\n              if (remaining3 instanceof Promise) remaining3 = await remaining3;\n              return context.supplyPacket(\n                remaining3,\n                Math.round(SAMPLES_PER_AAC_FRAME * TIMESCALE / this.elementaryStream.info.sampleRate)\n              );\n            } else {\n              context.seekTo(possibleHeaderStartPos + 1);\n            }\n          } else if (codec === \"mp3\") {\n            if (byte !== 255) {\n              continue;\n            }\n            context.skip(-1);\n            const possibleHeaderStartPos = context.currentPos;\n            let remaining2 = context.ensureBuffered(FRAME_HEADER_SIZE);\n            if (remaining2 instanceof Promise) remaining2 = await remaining2;\n            if (remaining2 < FRAME_HEADER_SIZE) {\n              return;\n            }\n            const headerBytes = context.readBytes(FRAME_HEADER_SIZE);\n            const word = toDataView(headerBytes).getUint32(0);\n            const result = readMp3FrameHeader(word, null);\n            if (result.header) {\n              context.seekTo(possibleHeaderStartPos);\n              let remaining3 = context.ensureBuffered(result.header.totalSize);\n              if (remaining3 instanceof Promise) remaining3 = await remaining3;\n              const duration = result.header.audioSamplesInFrame * TIMESCALE / this.elementaryStream.info.sampleRate;\n              return context.supplyPacket(remaining3, Math.round(duration));\n            } else {\n              context.seekTo(possibleHeaderStartPos + 1);\n            }\n          } else {\n            throw new Error(\"Unreachable\");\n          }\n        }\n        if (remaining < CHUNK_SIZE) {\n          break;\n        }\n      }\n    }\n  };\n  var PacketReadingContext = class _PacketReadingContext {\n    constructor(backing, startingPesPacket, uncapped) {\n      this.currentPos = 0;\n      // Relative to the data in startingPesPacket\n      this.pesPackets = [];\n      this.currentPesPacketIndex = 0;\n      this.currentPesPacketPos = 0;\n      this.endPos = 0;\n      this.nextPts = 0;\n      this.suppliedPacket = null;\n      this.backing = backing;\n      this.pid = backing.elementaryStream.pid;\n      this.demuxer = backing.elementaryStream.demuxer;\n      this.startingPesPacket = startingPesPacket;\n      this.uncapped = uncapped;\n    }\n    clone() {\n      const clone = new _PacketReadingContext(this.backing, this.startingPesPacket, true);\n      clone.currentPos = this.currentPos;\n      clone.pesPackets = [...this.pesPackets];\n      clone.currentPesPacketIndex = this.currentPesPacketIndex;\n      clone.currentPesPacketPos = this.currentPesPacketPos;\n      clone.endPos = this.endPos;\n      clone.nextPts = this.nextPts;\n      return clone;\n    }\n    ensureBuffered(length) {\n      const remaining = this.endPos - this.currentPos;\n      if (remaining >= length) {\n        return length;\n      }\n      return this.bufferData(length - remaining).then(() => Math.min(this.endPos - this.currentPos, length));\n    }\n    getCurrentPesPacket() {\n      const packet = this.pesPackets[this.currentPesPacketIndex];\n      assert(packet);\n      return packet;\n    }\n    async bufferData(length) {\n      const targetEndPos = this.endPos + length;\n      while (this.endPos < targetEndPos) {\n        let pesPacket;\n        if (this.pesPackets.length === 0) {\n          pesPacket = this.startingPesPacket;\n        } else {\n          let currentPos = last(this.pesPackets).sectionEndPos;\n          assert(currentPos !== null);\n          while (true) {\n            const packetHeader = await this.demuxer.readPacketHeader(currentPos);\n            if (!packetHeader) {\n              return;\n            }\n            if (packetHeader.pid === this.pid) {\n              break;\n            }\n            currentPos += this.demuxer.packetStride;\n          }\n          const nextSection = await this.demuxer.readSection(currentPos, true);\n          if (!nextSection) {\n            return;\n          }\n          const nextPesPacket = readPesPacket(nextSection);\n          if (!nextPesPacket) {\n            throw new Error(MISSING_PES_PACKET_ERROR);\n          }\n          pesPacket = nextPesPacket;\n        }\n        this.pesPackets.push(pesPacket);\n        this.endPos += pesPacket.data.byteLength;\n        if (this.pesPackets.length === 1) {\n          this.nextPts = pesPacket.pts;\n        }\n      }\n    }\n    readBytes(length) {\n      const currentPesPacket = this.getCurrentPesPacket();\n      const relativeStartOffset = this.currentPos - this.currentPesPacketPos;\n      const relativeEndOffset = relativeStartOffset + length;\n      this.currentPos += length;\n      if (relativeEndOffset <= currentPesPacket.data.byteLength) {\n        return currentPesPacket.data.subarray(relativeStartOffset, relativeEndOffset);\n      }\n      const result = new Uint8Array(length);\n      result.set(currentPesPacket.data.subarray(relativeStartOffset));\n      let offset = currentPesPacket.data.byteLength - relativeStartOffset;\n      while (true) {\n        this.advanceCurrentPacket();\n        const currentPesPacket2 = this.getCurrentPesPacket();\n        const relativeEndOffset2 = length - offset;\n        if (relativeEndOffset2 <= currentPesPacket2.data.byteLength) {\n          result.set(currentPesPacket2.data.subarray(0, relativeEndOffset2), offset);\n          break;\n        }\n        result.set(currentPesPacket2.data, offset);\n        offset += currentPesPacket2.data.byteLength;\n      }\n      return result;\n    }\n    readU8() {\n      let currentPesPacket = this.getCurrentPesPacket();\n      const relativeOffset = this.currentPos - this.currentPesPacketPos;\n      this.currentPos++;\n      if (relativeOffset < currentPesPacket.data.byteLength) {\n        return currentPesPacket.data[relativeOffset];\n      }\n      this.advanceCurrentPacket();\n      currentPesPacket = this.getCurrentPesPacket();\n      return currentPesPacket.data[0];\n    }\n    seekTo(pos) {\n      if (pos === this.currentPos) {\n        return;\n      }\n      if (pos < this.currentPos) {\n        while (pos < this.currentPesPacketPos) {\n          this.currentPesPacketIndex--;\n          const currentPacket = this.getCurrentPesPacket();\n          this.currentPesPacketPos -= currentPacket.data.byteLength;\n          this.nextPts = currentPacket.pts;\n        }\n      } else {\n        while (true) {\n          const currentPesPacket = this.getCurrentPesPacket();\n          const currentEndPos = this.currentPesPacketPos + currentPesPacket.data.byteLength;\n          if (pos < currentEndPos) {\n            break;\n          }\n          this.currentPesPacketPos += currentPesPacket.data.byteLength;\n          this.currentPesPacketIndex++;\n          this.nextPts = this.getCurrentPesPacket().pts;\n        }\n      }\n      this.currentPos = pos;\n    }\n    skip(n) {\n      this.seekTo(this.currentPos + n);\n    }\n    advanceCurrentPacket() {\n      this.currentPesPacketPos += this.getCurrentPesPacket().data.byteLength;\n      this.currentPesPacketIndex++;\n      this.nextPts = this.getCurrentPesPacket().pts;\n    }\n    /** Supplies the context with a new encoded packet, beginning at the current position. */\n    supplyPacket(packetLength, intrinsicDuration) {\n      const currentPesPacket = this.getCurrentPesPacket();\n      if (!this.uncapped && currentPesPacket !== this.startingPesPacket) {\n        this.suppliedPacket = null;\n        return;\n      }\n      this.backing.maybeInsertReferencePacket(currentPesPacket, false, true);\n      const pts = this.nextPts;\n      this.nextPts += intrinsicDuration;\n      const sectionStartPos = currentPesPacket.sectionStartPos;\n      const sequenceNumber = sectionStartPos + (this.currentPos - this.currentPesPacketPos);\n      const data = this.readBytes(packetLength);\n      this.suppliedPacket = {\n        pts,\n        data,\n        sequenceNumber,\n        sectionStartPos\n      };\n      this.pesPackets.splice(0, this.currentPesPacketIndex);\n      this.currentPesPacketIndex = 0;\n    }\n  };\n  var PacketBuffer = class {\n    constructor(backing, context) {\n      this.decodeOrderPackets = [];\n      this.reorderBuffer = [];\n      this.presentationOrderPackets = [];\n      this.reachedEnd = false;\n      this.lastDuration = 0;\n      this.backing = backing;\n      this.context = context;\n      this.reorderSize = backing.getReorderSize();\n      assert(this.reorderSize >= 0);\n    }\n    async readNext() {\n      if (this.decodeOrderPackets.length === 0) {\n        const didRead = await this.readNextDecodeOrderPacket();\n        if (!didRead) {\n          return null;\n        }\n      }\n      await this.ensureCurrentPacketHasNext();\n      const packet = this.decodeOrderPackets[0];\n      const presentationIndex = this.presentationOrderPackets.indexOf(packet);\n      assert(presentationIndex !== -1);\n      let duration;\n      if (presentationIndex === this.presentationOrderPackets.length - 1) {\n        duration = this.lastDuration;\n      } else {\n        const nextPacket = this.presentationOrderPackets[presentationIndex + 1];\n        duration = nextPacket.pts - packet.pts;\n        this.lastDuration = duration;\n      }\n      this.decodeOrderPackets.shift();\n      while (this.presentationOrderPackets.length > 0) {\n        const first = this.presentationOrderPackets[0];\n        if (this.decodeOrderPackets.includes(first)) {\n          break;\n        }\n        this.presentationOrderPackets.shift();\n      }\n      return { packet, duration };\n    }\n    async readNextDecodeOrderPacket() {\n      if (this.reachedEnd) {\n        return false;\n      }\n      let suppliedPacket;\n      if (this.context.suppliedPacket) {\n        suppliedPacket = this.context.suppliedPacket;\n      } else {\n        await this.backing.markNextPacket(this.context);\n        suppliedPacket = this.context.suppliedPacket;\n      }\n      this.context.suppliedPacket = null;\n      if (!suppliedPacket) {\n        this.reachedEnd = true;\n        this.flushReorderBuffer();\n        return false;\n      }\n      this.decodeOrderPackets.push(suppliedPacket);\n      this.processPacketThroughReorderBuffer(suppliedPacket);\n      return true;\n    }\n    async ensureCurrentPacketHasNext() {\n      const current = this.decodeOrderPackets[0];\n      assert(current);\n      while (true) {\n        const presentationIndex = this.presentationOrderPackets.indexOf(current);\n        if (presentationIndex !== -1 && presentationIndex <= this.presentationOrderPackets.length - 2) {\n          break;\n        }\n        const didRead = await this.readNextDecodeOrderPacket();\n        if (!didRead) {\n          break;\n        }\n      }\n    }\n    processPacketThroughReorderBuffer(packet) {\n      this.reorderBuffer.push(packet);\n      if (this.reorderBuffer.length >= this.reorderSize) {\n        let minIndex = 0;\n        for (let i = 1; i < this.reorderBuffer.length; i++) {\n          if (this.reorderBuffer[i].pts < this.reorderBuffer[minIndex].pts) {\n            minIndex = i;\n          }\n        }\n        const packet2 = this.reorderBuffer.splice(minIndex, 1)[0];\n        this.presentationOrderPackets.push(packet2);\n      }\n    }\n    flushReorderBuffer() {\n      this.reorderBuffer.sort((a, b) => a.pts - b.pts);\n      this.presentationOrderPackets.push(...this.reorderBuffer);\n      this.reorderBuffer.length = 0;\n    }\n  };\n\n  // src/input-format.ts\n  var InputFormat = class {\n  };\n  var IsobmffInputFormat = class extends InputFormat {\n    /** @internal */\n    async _getMajorBrand(input) {\n      let slice = input._reader.requestSlice(0, 12);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return null;\n      slice.skip(4);\n      const fourCc = readAscii(slice, 4);\n      if (fourCc !== \"ftyp\") {\n        return null;\n      }\n      return readAscii(slice, 4);\n    }\n    /** @internal */\n    _createDemuxer(input) {\n      return new IsobmffDemuxer(input);\n    }\n  };\n  var Mp4InputFormat = class extends IsobmffInputFormat {\n    /** @internal */\n    async _canReadInput(input) {\n      const majorBrand = await this._getMajorBrand(input);\n      return !!majorBrand && majorBrand !== \"qt  \";\n    }\n    get name() {\n      return \"MP4\";\n    }\n    get mimeType() {\n      return \"video/mp4\";\n    }\n  };\n  var QuickTimeInputFormat = class extends IsobmffInputFormat {\n    /** @internal */\n    async _canReadInput(input) {\n      const majorBrand = await this._getMajorBrand(input);\n      return majorBrand === \"qt  \";\n    }\n    get name() {\n      return \"QuickTime File Format\";\n    }\n    get mimeType() {\n      return \"video/quicktime\";\n    }\n  };\n  var MatroskaInputFormat = class extends InputFormat {\n    /** @internal */\n    async isSupportedEBMLOfDocType(input, desiredDocType) {\n      let headerSlice = input._reader.requestSlice(0, MAX_HEADER_SIZE);\n      if (headerSlice instanceof Promise) headerSlice = await headerSlice;\n      if (!headerSlice) return false;\n      const varIntSize = readVarIntSize(headerSlice);\n      if (varIntSize === null) {\n        return false;\n      }\n      if (varIntSize < 1 || varIntSize > 8) {\n        return false;\n      }\n      const id = readUnsignedInt(headerSlice, varIntSize);\n      if (id !== 440786851 /* EBML */) {\n        return false;\n      }\n      const dataSize = readElementSize(headerSlice);\n      if (typeof dataSize !== \"number\") {\n        return false;\n      }\n      let dataSlice = input._reader.requestSlice(headerSlice.filePos, dataSize);\n      if (dataSlice instanceof Promise) dataSlice = await dataSlice;\n      if (!dataSlice) return false;\n      const startPos = headerSlice.filePos;\n      while (dataSlice.filePos <= startPos + dataSize - MIN_HEADER_SIZE) {\n        const header = readElementHeader(dataSlice);\n        if (!header) break;\n        const { id: id2, size } = header;\n        const dataStartPos = dataSlice.filePos;\n        if (size === void 0) return false;\n        switch (id2) {\n          case 17030 /* EBMLVersion */:\n            {\n              const ebmlVersion = readUnsignedInt(dataSlice, size);\n              if (ebmlVersion !== 1) {\n                return false;\n              }\n            }\n            ;\n            break;\n          case 17143 /* EBMLReadVersion */:\n            {\n              const ebmlReadVersion = readUnsignedInt(dataSlice, size);\n              if (ebmlReadVersion !== 1) {\n                return false;\n              }\n            }\n            ;\n            break;\n          case 17026 /* DocType */:\n            {\n              const docType = readAsciiString(dataSlice, size);\n              if (docType !== desiredDocType) {\n                return false;\n              }\n            }\n            ;\n            break;\n          case 17031 /* DocTypeVersion */:\n            {\n              const docTypeVersion = readUnsignedInt(dataSlice, size);\n              if (docTypeVersion > 4) {\n                return false;\n              }\n            }\n            ;\n            break;\n        }\n        dataSlice.filePos = dataStartPos + size;\n      }\n      return true;\n    }\n    /** @internal */\n    _canReadInput(input) {\n      return this.isSupportedEBMLOfDocType(input, \"matroska\");\n    }\n    /** @internal */\n    _createDemuxer(input) {\n      return new MatroskaDemuxer(input);\n    }\n    get name() {\n      return \"Matroska\";\n    }\n    get mimeType() {\n      return \"video/x-matroska\";\n    }\n  };\n  var WebMInputFormat = class extends MatroskaInputFormat {\n    /** @internal */\n    _canReadInput(input) {\n      return this.isSupportedEBMLOfDocType(input, \"webm\");\n    }\n    get name() {\n      return \"WebM\";\n    }\n    get mimeType() {\n      return \"video/webm\";\n    }\n  };\n  var Mp3InputFormat = class extends InputFormat {\n    /** @internal */\n    async _canReadInput(input) {\n      let slice = input._reader.requestSlice(0, 10);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return false;\n      let currentPos = 0;\n      let id3V2HeaderFound = false;\n      while (true) {\n        let slice2 = input._reader.requestSlice(currentPos, ID3_V2_HEADER_SIZE);\n        if (slice2 instanceof Promise) slice2 = await slice2;\n        if (!slice2) break;\n        const id3V2Header = readId3V2Header(slice2);\n        if (!id3V2Header) {\n          break;\n        }\n        id3V2HeaderFound = true;\n        currentPos = slice2.filePos + id3V2Header.size;\n      }\n      const firstResult = await readNextMp3FrameHeader(input._reader, currentPos, currentPos + 4096);\n      if (!firstResult) {\n        return false;\n      }\n      if (id3V2HeaderFound) {\n        return true;\n      }\n      currentPos = firstResult.startPos + firstResult.header.totalSize;\n      const secondResult = await readNextMp3FrameHeader(input._reader, currentPos, currentPos + FRAME_HEADER_SIZE);\n      if (!secondResult) {\n        return false;\n      }\n      const firstHeader = firstResult.header;\n      const secondHeader = secondResult.header;\n      if (firstHeader.channel !== secondHeader.channel || firstHeader.sampleRate !== secondHeader.sampleRate) {\n        return false;\n      }\n      return true;\n    }\n    /** @internal */\n    _createDemuxer(input) {\n      return new Mp3Demuxer(input);\n    }\n    get name() {\n      return \"MP3\";\n    }\n    get mimeType() {\n      return \"audio/mpeg\";\n    }\n  };\n  var WaveInputFormat = class extends InputFormat {\n    /** @internal */\n    async _canReadInput(input) {\n      let slice = input._reader.requestSlice(0, 12);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return false;\n      const riffType = readAscii(slice, 4);\n      if (riffType !== \"RIFF\" && riffType !== \"RIFX\" && riffType !== \"RF64\") {\n        return false;\n      }\n      slice.skip(4);\n      const format = readAscii(slice, 4);\n      return format === \"WAVE\";\n    }\n    /** @internal */\n    _createDemuxer(input) {\n      return new WaveDemuxer(input);\n    }\n    get name() {\n      return \"WAVE\";\n    }\n    get mimeType() {\n      return \"audio/wav\";\n    }\n  };\n  var OggInputFormat = class extends InputFormat {\n    /** @internal */\n    async _canReadInput(input) {\n      let slice = input._reader.requestSlice(0, 4);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return false;\n      return readAscii(slice, 4) === \"OggS\";\n    }\n    /** @internal */\n    _createDemuxer(input) {\n      return new OggDemuxer(input);\n    }\n    get name() {\n      return \"Ogg\";\n    }\n    get mimeType() {\n      return \"application/ogg\";\n    }\n  };\n  var FlacInputFormat = class extends InputFormat {\n    /** @internal */\n    async _canReadInput(input) {\n      let slice = input._reader.requestSlice(0, 4);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return false;\n      return readAscii(slice, 4) === \"fLaC\";\n    }\n    get name() {\n      return \"FLAC\";\n    }\n    get mimeType() {\n      return \"audio/flac\";\n    }\n    /** @internal */\n    _createDemuxer(input) {\n      return new FlacDemuxer(input);\n    }\n  };\n  var AdtsInputFormat = class extends InputFormat {\n    /** @internal */\n    async _canReadInput(input) {\n      let slice = input._reader.requestSliceRange(\n        0,\n        MIN_ADTS_FRAME_HEADER_SIZE,\n        MAX_ADTS_FRAME_HEADER_SIZE\n      );\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return false;\n      const firstHeader = readAdtsFrameHeader(slice);\n      if (!firstHeader) {\n        return false;\n      }\n      slice = input._reader.requestSliceRange(\n        firstHeader.frameLength,\n        MIN_ADTS_FRAME_HEADER_SIZE,\n        MAX_ADTS_FRAME_HEADER_SIZE\n      );\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return false;\n      const secondHeader = readAdtsFrameHeader(slice);\n      if (!secondHeader) {\n        return false;\n      }\n      return firstHeader.objectType === secondHeader.objectType && firstHeader.samplingFrequencyIndex === secondHeader.samplingFrequencyIndex && firstHeader.channelConfiguration === secondHeader.channelConfiguration;\n    }\n    /** @internal */\n    _createDemuxer(input) {\n      return new AdtsDemuxer(input);\n    }\n    get name() {\n      return \"ADTS\";\n    }\n    get mimeType() {\n      return \"audio/aac\";\n    }\n  };\n  var MpegTsInputFormat = class extends InputFormat {\n    /** @internal */\n    async _canReadInput(input) {\n      const lengthToCheck = TS_PACKET_SIZE + 16 + 1;\n      let slice = input._reader.requestSlice(0, lengthToCheck);\n      if (slice instanceof Promise) slice = await slice;\n      if (!slice) return false;\n      const bytes2 = readBytes(slice, lengthToCheck);\n      if (bytes2[0] === 71 && bytes2[TS_PACKET_SIZE] === 71) {\n        return true;\n      } else if (bytes2[0] === 71 && bytes2[TS_PACKET_SIZE + 16] === 71) {\n        return true;\n      } else if (bytes2[4] === 71 && bytes2[4 + TS_PACKET_SIZE] === 71) {\n        return true;\n      }\n      return false;\n    }\n    /** @internal */\n    _createDemuxer(input) {\n      return new MpegTsDemuxer(input);\n    }\n    get name() {\n      return \"MPEG Transport Stream\";\n    }\n    get mimeType() {\n      return \"video/MP2T\";\n    }\n  };\n  var MP4 = /* @__PURE__ */ new Mp4InputFormat();\n  var QTFF = /* @__PURE__ */ new QuickTimeInputFormat();\n  var MATROSKA = /* @__PURE__ */ new MatroskaInputFormat();\n  var WEBM = /* @__PURE__ */ new WebMInputFormat();\n  var MP3 = /* @__PURE__ */ new Mp3InputFormat();\n  var WAVE = /* @__PURE__ */ new WaveInputFormat();\n  var OGG = /* @__PURE__ */ new OggInputFormat();\n  var ADTS = /* @__PURE__ */ new AdtsInputFormat();\n  var FLAC = /* @__PURE__ */ new FlacInputFormat();\n  var MPEG_TS = /* @__PURE__ */ new MpegTsInputFormat();\n  var ALL_FORMATS = [MP4, QTFF, MATROSKA, WEBM, WAVE, OGG, FLAC, MP3, ADTS, MPEG_TS];\n\n  // src/source.ts\n  var nodeAlias = __toESM(require_node(), 1);\n  var node = typeof nodeAlias !== \"undefined\" ? nodeAlias : void 0;\n  var Source = class {\n    constructor() {\n      /** @internal */\n      this._disposed = false;\n      /** @internal */\n      this._sizePromise = null;\n      /** Called each time data is retrieved from the source. Will be called with the retrieved range (end exclusive). */\n      this.onread = null;\n    }\n    /**\n     * Resolves with the total size of the file in bytes. This function is memoized, meaning only the first call\n     * will retrieve the size.\n     *\n     * Returns null if the source is unsized.\n     */\n    async getSizeOrNull() {\n      if (this._disposed) {\n        throw new InputDisposedError();\n      }\n      return this._sizePromise ??= Promise.resolve(this._retrieveSize());\n    }\n    /**\n     * Resolves with the total size of the file in bytes. This function is memoized, meaning only the first call\n     * will retrieve the size.\n     *\n     * Throws an error if the source is unsized.\n     */\n    async getSize() {\n      if (this._disposed) {\n        throw new InputDisposedError();\n      }\n      const result = await this.getSizeOrNull();\n      if (result === null) {\n        throw new Error(\"Cannot determine the size of an unsized source.\");\n      }\n      return result;\n    }\n  };\n  var BufferSource = class extends Source {\n    /**\n     * Creates a new {@link BufferSource} backed by the specified `ArrayBuffer`, `SharedArrayBuffer`,\n     * or `ArrayBufferView`.\n     */\n    constructor(buffer) {\n      if (!(buffer instanceof ArrayBuffer) && !(typeof SharedArrayBuffer !== \"undefined\" && buffer instanceof SharedArrayBuffer) && !ArrayBuffer.isView(buffer)) {\n        throw new TypeError(\"buffer must be an ArrayBuffer, SharedArrayBuffer, or ArrayBufferView.\");\n      }\n      super();\n      /** @internal */\n      this._onreadCalled = false;\n      this._bytes = toUint8Array(buffer);\n      this._view = toDataView(buffer);\n    }\n    /** @internal */\n    _retrieveSize() {\n      return this._bytes.byteLength;\n    }\n    /** @internal */\n    _read() {\n      if (!this._onreadCalled) {\n        this.onread?.(0, this._bytes.byteLength);\n        this._onreadCalled = true;\n      }\n      return {\n        bytes: this._bytes,\n        view: this._view,\n        offset: 0\n      };\n    }\n    /** @internal */\n    _dispose() {\n    }\n  };\n  var BlobSource = class extends Source {\n    /**\n     * Creates a new {@link BlobSource} backed by the specified\n     * [`Blob`](https://developer.mozilla.org/en-US/docs/Web/API/Blob).\n     */\n    constructor(blob, options = {}) {\n      if (!(blob instanceof Blob)) {\n        throw new TypeError(\"blob must be a Blob.\");\n      }\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.maxCacheSize !== void 0 && (!isNumber(options.maxCacheSize) || options.maxCacheSize < 0)) {\n        throw new TypeError(\"options.maxCacheSize, when provided, must be a non-negative number.\");\n      }\n      super();\n      /** @internal */\n      this._readers = /* @__PURE__ */ new WeakMap();\n      this._blob = blob;\n      this._orchestrator = new ReadOrchestrator({\n        maxCacheSize: options.maxCacheSize ?? 8 * 2 ** 20,\n        maxWorkerCount: 4,\n        runWorker: this._runWorker.bind(this),\n        prefetchProfile: PREFETCH_PROFILES.fileSystem\n      });\n    }\n    /** @internal */\n    _retrieveSize() {\n      const size = this._blob.size;\n      this._orchestrator.fileSize = size;\n      return size;\n    }\n    /** @internal */\n    _read(start, end) {\n      return this._orchestrator.read(start, end);\n    }\n    /** @internal */\n    async _runWorker(worker) {\n      let reader = this._readers.get(worker);\n      if (reader === void 0) {\n        if (\"stream\" in this._blob && !isWebKit()) {\n          const slice = this._blob.slice(worker.currentPos);\n          reader = slice.stream().getReader();\n        } else {\n          reader = null;\n        }\n        this._readers.set(worker, reader);\n      }\n      while (worker.currentPos < worker.targetPos && !worker.aborted) {\n        if (reader) {\n          const { done, value } = await reader.read();\n          if (done) {\n            this._orchestrator.forgetWorker(worker);\n            throw new Error(\"Blob reader stopped unexpectedly before all requested data was read.\");\n          }\n          if (worker.aborted) {\n            break;\n          }\n          this.onread?.(worker.currentPos, worker.currentPos + value.length);\n          this._orchestrator.supplyWorkerData(worker, value);\n        } else {\n          const data = await this._blob.slice(worker.currentPos, worker.targetPos).arrayBuffer();\n          if (worker.aborted) {\n            break;\n          }\n          this.onread?.(worker.currentPos, worker.currentPos + data.byteLength);\n          this._orchestrator.supplyWorkerData(worker, new Uint8Array(data));\n        }\n      }\n      worker.running = false;\n      if (worker.aborted) {\n        await reader?.cancel();\n      }\n    }\n    /** @internal */\n    _dispose() {\n      this._orchestrator.dispose();\n    }\n  };\n  var URL_SOURCE_MIN_LOAD_AMOUNT = 0.5 * 2 ** 20;\n  var DEFAULT_RETRY_DELAY = (previousAttempts, error, src) => {\n    const couldBeCorsError = error instanceof Error && (error.message.includes(\"Failed to fetch\") || error.message.includes(\"Load failed\") || error.message.includes(\"NetworkError when attempting to fetch resource\"));\n    if (couldBeCorsError) {\n      let originOfSrc = null;\n      try {\n        if (typeof window !== \"undefined\" && typeof window.location !== \"undefined\") {\n          originOfSrc = new URL(src instanceof Request ? src.url : src, window.location.href).origin;\n        }\n      } catch {\n      }\n      const isOnline = typeof navigator !== \"undefined\" && typeof navigator.onLine === \"boolean\" ? navigator.onLine : true;\n      if (isOnline && originOfSrc !== null && originOfSrc !== window.location.origin) {\n        console.warn(\n          `Request will not be retried because a CORS error was suspected due to different origins. You can modify this behavior by providing your own function for the 'getRetryDelay' option.`\n        );\n        return null;\n      }\n    }\n    return Math.min(2 ** (previousAttempts - 2), 16);\n  };\n  var UrlSource = class extends Source {\n    /** Creates a new {@link UrlSource} backed by the resource at the specified URL. */\n    constructor(url2, options = {}) {\n      if (typeof url2 !== \"string\" && !(url2 instanceof URL) && !(typeof Request !== \"undefined\" && url2 instanceof Request)) {\n        throw new TypeError(\"url must be a string, URL or Request.\");\n      }\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.requestInit !== void 0 && (!options.requestInit || typeof options.requestInit !== \"object\")) {\n        throw new TypeError(\"options.requestInit, when provided, must be an object.\");\n      }\n      if (options.getRetryDelay !== void 0 && typeof options.getRetryDelay !== \"function\") {\n        throw new TypeError(\"options.getRetryDelay, when provided, must be a function.\");\n      }\n      if (options.maxCacheSize !== void 0 && (!isNumber(options.maxCacheSize) || options.maxCacheSize < 0)) {\n        throw new TypeError(\"options.maxCacheSize, when provided, must be a non-negative number.\");\n      }\n      if (options.fetchFn !== void 0 && typeof options.fetchFn !== \"function\") {\n        throw new TypeError(\"options.fetchFn, when provided, must be a function.\");\n      }\n      super();\n      /** @internal */\n      this._existingResponses = /* @__PURE__ */ new WeakMap();\n      this._url = url2;\n      this._options = options;\n      this._getRetryDelay = options.getRetryDelay ?? DEFAULT_RETRY_DELAY;\n      this._orchestrator = new ReadOrchestrator({\n        maxCacheSize: options.maxCacheSize ?? 64 * 2 ** 20,\n        // Most files in the real-world have a single sequential access pattern, but having two in parallel can\n        // also happen\n        maxWorkerCount: 2,\n        runWorker: this._runWorker.bind(this),\n        prefetchProfile: PREFETCH_PROFILES.network\n      });\n    }\n    /** @internal */\n    async _retrieveSize() {\n      const abortController = new AbortController();\n      const response = await retriedFetch(\n        this._options.fetchFn ?? fetch,\n        this._url,\n        mergeRequestInit(this._options.requestInit ?? {}, {\n          headers: {\n            // We could also send a non-range request to request the same bytes (all of them), but doing it like\n            // this is an easy way to check if the server supports range requests in the first place\n            Range: \"bytes=0-\"\n          },\n          signal: abortController.signal\n        }),\n        this._getRetryDelay,\n        () => this._disposed\n      );\n      if (!response.ok) {\n        throw new Error(`Error fetching ${String(this._url)}: ${response.status} ${response.statusText}`);\n      }\n      let worker;\n      let fileSize;\n      if (response.status === 206) {\n        fileSize = this._getTotalLengthFromRangeResponse(response);\n        worker = this._orchestrator.createWorker(0, Math.min(fileSize, URL_SOURCE_MIN_LOAD_AMOUNT));\n      } else {\n        const contentLength = response.headers.get(\"Content-Length\");\n        if (contentLength) {\n          fileSize = Number(contentLength);\n          worker = this._orchestrator.createWorker(0, fileSize);\n          this._orchestrator.options.maxCacheSize = Infinity;\n          console.warn(\n            \"HTTP server did not respond with 206 Partial Content, meaning the entire remote resource now has to be downloaded. For efficient media file streaming across a network, please make sure your server supports range requests.\"\n          );\n        } else {\n          throw new Error(`HTTP response (status ${response.status}) must surface Content-Length header.`);\n        }\n      }\n      this._orchestrator.fileSize = fileSize;\n      this._existingResponses.set(worker, { response, abortController });\n      this._orchestrator.runWorker(worker);\n      return fileSize;\n    }\n    /** @internal */\n    _read(start, end) {\n      return this._orchestrator.read(start, end);\n    }\n    /** @internal */\n    async _runWorker(worker) {\n      while (true) {\n        const existing = this._existingResponses.get(worker);\n        this._existingResponses.delete(worker);\n        let abortController = existing?.abortController;\n        let response = existing?.response;\n        if (!abortController) {\n          abortController = new AbortController();\n          response = await retriedFetch(\n            this._options.fetchFn ?? fetch,\n            this._url,\n            mergeRequestInit(this._options.requestInit ?? {}, {\n              headers: {\n                Range: `bytes=${worker.currentPos}-`\n              },\n              signal: abortController.signal\n            }),\n            this._getRetryDelay,\n            () => this._disposed\n          );\n        }\n        assert(response);\n        if (!response.ok) {\n          throw new Error(`Error fetching ${String(this._url)}: ${response.status} ${response.statusText}`);\n        }\n        if (worker.currentPos > 0 && response.status !== 206) {\n          throw new Error(\n            \"HTTP server did not respond with 206 Partial Content to a range request. To enable efficient media file streaming across a network, please make sure your server supports range requests.\"\n          );\n        }\n        if (!response.body) {\n          throw new Error(\n            \"Missing HTTP response body stream. The used fetch function must provide the response body as a ReadableStream.\"\n          );\n        }\n        const reader = response.body.getReader();\n        while (true) {\n          if (worker.currentPos >= worker.targetPos || worker.aborted) {\n            abortController.abort();\n            worker.running = false;\n            return;\n          }\n          let readResult;\n          try {\n            readResult = await reader.read();\n          } catch (error) {\n            if (this._disposed) {\n              throw error;\n            }\n            const retryDelayInSeconds = this._getRetryDelay(1, error, this._url);\n            if (retryDelayInSeconds !== null) {\n              console.error(\"Error while reading response stream. Attempting to resume.\", error);\n              await new Promise((resolve) => setTimeout(resolve, 1e3 * retryDelayInSeconds));\n              break;\n            } else {\n              throw error;\n            }\n          }\n          if (worker.aborted) {\n            continue;\n          }\n          const { done, value } = readResult;\n          if (done) {\n            if (worker.currentPos >= worker.targetPos) {\n              this._orchestrator.forgetWorker(worker);\n              worker.running = false;\n              return;\n            }\n            break;\n          }\n          this.onread?.(worker.currentPos, worker.currentPos + value.length);\n          this._orchestrator.supplyWorkerData(worker, value);\n        }\n      }\n    }\n    /** @internal */\n    _getTotalLengthFromRangeResponse(response) {\n      const contentRange = response.headers.get(\"Content-Range\");\n      if (contentRange) {\n        const match = /\\/(\\d+)/.exec(contentRange);\n        if (match) {\n          return Number(match[1]);\n        }\n      }\n      const contentLength = response.headers.get(\"Content-Length\");\n      if (contentLength) {\n        return Number(contentLength);\n      } else {\n        throw new Error(\n          \"Partial HTTP response (status 206) must surface either Content-Range or Content-Length header.\"\n        );\n      }\n    }\n    /** @internal */\n    _dispose() {\n      this._orchestrator.dispose();\n    }\n  };\n  var FilePathSource = class extends Source {\n    /** Creates a new {@link FilePathSource} backed by the file at the specified file path. */\n    constructor(filePath, options = {}) {\n      if (typeof filePath !== \"string\") {\n        throw new TypeError(\"filePath must be a string.\");\n      }\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.maxCacheSize !== void 0 && (!isNumber(options.maxCacheSize) || options.maxCacheSize < 0)) {\n        throw new TypeError(\"options.maxCacheSize, when provided, must be a non-negative number.\");\n      }\n      super();\n      /** @internal */\n      this._fileHandle = null;\n      this._streamSource = new StreamSource({\n        getSize: async () => {\n          this._fileHandle = await node.fs.open(filePath, \"r\");\n          const stats = await this._fileHandle.stat();\n          return stats.size;\n        },\n        read: async (start, end) => {\n          assert(this._fileHandle);\n          const buffer = new Uint8Array(end - start);\n          await this._fileHandle.read(buffer, 0, end - start, start);\n          return buffer;\n        },\n        maxCacheSize: options.maxCacheSize,\n        prefetchProfile: \"fileSystem\"\n      });\n    }\n    /** @internal */\n    _read(start, end) {\n      return this._streamSource._read(start, end);\n    }\n    /** @internal */\n    _retrieveSize() {\n      return this._streamSource._retrieveSize();\n    }\n    /** @internal */\n    _dispose() {\n      this._streamSource._dispose();\n      void this._fileHandle?.close();\n      this._fileHandle = null;\n    }\n  };\n  var StreamSource = class extends Source {\n    /** Creates a new {@link StreamSource} whose behavior is specified by `options`.  */\n    constructor(options) {\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (typeof options.getSize !== \"function\") {\n        throw new TypeError(\"options.getSize must be a function.\");\n      }\n      if (typeof options.read !== \"function\") {\n        throw new TypeError(\"options.read must be a function.\");\n      }\n      if (options.dispose !== void 0 && typeof options.dispose !== \"function\") {\n        throw new TypeError(\"options.dispose, when provided, must be a function.\");\n      }\n      if (options.maxCacheSize !== void 0 && (!isNumber(options.maxCacheSize) || options.maxCacheSize < 0)) {\n        throw new TypeError(\"options.maxCacheSize, when provided, must be a non-negative number.\");\n      }\n      if (options.prefetchProfile && ![\"none\", \"fileSystem\", \"network\"].includes(options.prefetchProfile)) {\n        throw new TypeError(\n          \"options.prefetchProfile, when provided, must be one of 'none', 'fileSystem' or 'network'.\"\n        );\n      }\n      super();\n      this._options = options;\n      this._orchestrator = new ReadOrchestrator({\n        maxCacheSize: options.maxCacheSize ?? 8 * 2 ** 20,\n        maxWorkerCount: 2,\n        // Fixed for now, *should* be fine\n        prefetchProfile: PREFETCH_PROFILES[options.prefetchProfile ?? \"none\"],\n        runWorker: this._runWorker.bind(this)\n      });\n    }\n    /** @internal */\n    _retrieveSize() {\n      const result = this._options.getSize();\n      if (result instanceof Promise) {\n        return result.then((size) => {\n          if (!Number.isInteger(size) || size < 0) {\n            throw new TypeError(\"options.getSize must return or resolve to a non-negative integer.\");\n          }\n          this._orchestrator.fileSize = size;\n          return size;\n        });\n      } else {\n        if (!Number.isInteger(result) || result < 0) {\n          throw new TypeError(\"options.getSize must return or resolve to a non-negative integer.\");\n        }\n        this._orchestrator.fileSize = result;\n        return result;\n      }\n    }\n    /** @internal */\n    _read(start, end) {\n      return this._orchestrator.read(start, end);\n    }\n    /** @internal */\n    async _runWorker(worker) {\n      while (worker.currentPos < worker.targetPos && !worker.aborted) {\n        const originalCurrentPos = worker.currentPos;\n        const originalTargetPos = worker.targetPos;\n        let data = this._options.read(worker.currentPos, originalTargetPos);\n        if (data instanceof Promise) data = await data;\n        if (worker.aborted) {\n          break;\n        }\n        if (data instanceof Uint8Array) {\n          data = toUint8Array(data);\n          if (data.length !== originalTargetPos - worker.currentPos) {\n            throw new Error(\n              `options.read returned a Uint8Array with unexpected length: Requested ${originalTargetPos - worker.currentPos} bytes, but got ${data.length}.`\n            );\n          }\n          this.onread?.(worker.currentPos, worker.currentPos + data.length);\n          this._orchestrator.supplyWorkerData(worker, data);\n        } else if (data instanceof ReadableStream) {\n          const reader = data.getReader();\n          while (worker.currentPos < originalTargetPos && !worker.aborted) {\n            const { done, value } = await reader.read();\n            if (done) {\n              if (worker.currentPos < originalTargetPos) {\n                throw new Error(\n                  `ReadableStream returned by options.read ended before supplying enough data. Requested ${originalTargetPos - originalCurrentPos} bytes, but got ${worker.currentPos - originalCurrentPos}`\n                );\n              }\n              break;\n            }\n            if (!(value instanceof Uint8Array)) {\n              throw new TypeError(\"ReadableStream returned by options.read must yield Uint8Array chunks.\");\n            }\n            if (worker.aborted) {\n              break;\n            }\n            const data2 = toUint8Array(value);\n            this.onread?.(worker.currentPos, worker.currentPos + data2.length);\n            this._orchestrator.supplyWorkerData(worker, data2);\n          }\n        } else {\n          throw new TypeError(\"options.read must return or resolve to a Uint8Array or a ReadableStream.\");\n        }\n      }\n      worker.running = false;\n    }\n    /** @internal */\n    _dispose() {\n      this._orchestrator.dispose();\n      this._options.dispose?.();\n    }\n  };\n  var ReadableStreamSource = class extends Source {\n    /** Creates a new {@link ReadableStreamSource} backed by the specified `ReadableStream<Uint8Array>`. */\n    constructor(stream, options = {}) {\n      if (!(stream instanceof ReadableStream)) {\n        throw new TypeError(\"stream must be a ReadableStream.\");\n      }\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.maxCacheSize !== void 0 && (!isNumber(options.maxCacheSize) || options.maxCacheSize < 0)) {\n        throw new TypeError(\"options.maxCacheSize, when provided, must be a non-negative number.\");\n      }\n      super();\n      /** @internal */\n      this._reader = null;\n      /** @internal */\n      this._cache = [];\n      /** @internal */\n      this._pendingSlices = [];\n      /** @internal */\n      this._currentIndex = 0;\n      /** @internal */\n      this._targetIndex = 0;\n      /** @internal */\n      this._maxRequestedIndex = 0;\n      /** @internal */\n      this._endIndex = null;\n      /** @internal */\n      this._pulling = false;\n      this._stream = stream;\n      this._maxCacheSize = options.maxCacheSize ?? 16 * 2 ** 20;\n    }\n    /** @internal */\n    _retrieveSize() {\n      return this._endIndex;\n    }\n    /** @internal */\n    _read(start, end) {\n      if (this._endIndex !== null && end > this._endIndex) {\n        return null;\n      }\n      this._maxRequestedIndex = Math.max(this._maxRequestedIndex, end);\n      const cacheStartIndex = binarySearchLessOrEqual(this._cache, start, (x) => x.start);\n      const cacheStartEntry = cacheStartIndex !== -1 ? this._cache[cacheStartIndex] : null;\n      if (cacheStartEntry && cacheStartEntry.start <= start && end <= cacheStartEntry.end) {\n        return {\n          bytes: cacheStartEntry.bytes,\n          view: cacheStartEntry.view,\n          offset: cacheStartEntry.start\n        };\n      }\n      let lastEnd = start;\n      const bytes2 = new Uint8Array(end - start);\n      if (cacheStartIndex !== -1) {\n        for (let i = cacheStartIndex; i < this._cache.length; i++) {\n          const cacheEntry = this._cache[i];\n          if (cacheEntry.start >= end) {\n            break;\n          }\n          const cappedStart = Math.max(start, cacheEntry.start);\n          if (cappedStart > lastEnd) {\n            this._throwDueToCacheMiss();\n          }\n          const cappedEnd = Math.min(end, cacheEntry.end);\n          if (cappedStart < cappedEnd) {\n            bytes2.set(\n              cacheEntry.bytes.subarray(cappedStart - cacheEntry.start, cappedEnd - cacheEntry.start),\n              cappedStart - start\n            );\n            lastEnd = cappedEnd;\n          }\n        }\n      }\n      if (lastEnd === end) {\n        return {\n          bytes: bytes2,\n          view: toDataView(bytes2),\n          offset: start\n        };\n      }\n      if (this._currentIndex > lastEnd) {\n        this._throwDueToCacheMiss();\n      }\n      const { promise, resolve, reject } = promiseWithResolvers();\n      this._pendingSlices.push({\n        start,\n        end,\n        bytes: bytes2,\n        resolve,\n        reject\n      });\n      this._targetIndex = Math.max(this._targetIndex, end);\n      if (!this._pulling) {\n        this._pulling = true;\n        void this._pull().catch((error) => {\n          this._pulling = false;\n          if (this._pendingSlices.length > 0) {\n            this._pendingSlices.forEach((x) => x.reject(error));\n            this._pendingSlices.length = 0;\n          } else {\n            throw error;\n          }\n        });\n      }\n      return promise;\n    }\n    /** @internal */\n    _throwDueToCacheMiss() {\n      throw new Error(\n        \"Read is before the cached region. With ReadableStreamSource, you must access the data more sequentially or increase the size of its cache.\"\n      );\n    }\n    /** @internal */\n    async _pull() {\n      this._reader ??= this._stream.getReader();\n      while (this._currentIndex < this._targetIndex && !this._disposed) {\n        const { done, value } = await this._reader.read();\n        if (done) {\n          for (const pendingSlice of this._pendingSlices) {\n            pendingSlice.resolve(null);\n          }\n          this._pendingSlices.length = 0;\n          this._endIndex = this._currentIndex;\n          break;\n        }\n        const startIndex = this._currentIndex;\n        const endIndex = this._currentIndex + value.byteLength;\n        for (let i = 0; i < this._pendingSlices.length; i++) {\n          const pendingSlice = this._pendingSlices[i];\n          const cappedStart = Math.max(startIndex, pendingSlice.start);\n          const cappedEnd = Math.min(endIndex, pendingSlice.end);\n          if (cappedStart < cappedEnd) {\n            pendingSlice.bytes.set(\n              value.subarray(cappedStart - startIndex, cappedEnd - startIndex),\n              cappedStart - pendingSlice.start\n            );\n            if (cappedEnd === pendingSlice.end) {\n              pendingSlice.resolve({\n                bytes: pendingSlice.bytes,\n                view: toDataView(pendingSlice.bytes),\n                offset: pendingSlice.start\n              });\n              this._pendingSlices.splice(i, 1);\n              i--;\n            }\n          }\n        }\n        this._cache.push({\n          start: startIndex,\n          end: endIndex,\n          bytes: value,\n          view: toDataView(value),\n          age: 0\n          // Unused\n        });\n        while (this._cache.length > 0) {\n          const firstEntry = this._cache[0];\n          const distance = this._maxRequestedIndex - firstEntry.end;\n          if (distance <= this._maxCacheSize) {\n            break;\n          }\n          this._cache.shift();\n        }\n        this._currentIndex += value.byteLength;\n      }\n      this._pulling = false;\n    }\n    /** @internal */\n    _dispose() {\n      this._pendingSlices.length = 0;\n      this._cache.length = 0;\n    }\n  };\n  var PREFETCH_PROFILES = {\n    none: (start, end) => ({ start, end }),\n    fileSystem: (start, end) => {\n      const padding = 2 ** 16;\n      start = Math.floor((start - padding) / padding) * padding;\n      end = Math.ceil((end + padding) / padding) * padding;\n      return { start, end };\n    },\n    network: (start, end, workers) => {\n      const paddingStart = 2 ** 16;\n      start = Math.max(0, Math.floor((start - paddingStart) / paddingStart) * paddingStart);\n      for (const worker of workers) {\n        const maxExtensionAmount = 8 * 2 ** 20;\n        const thresholdPoint = Math.max(\n          (worker.startPos + worker.targetPos) / 2,\n          worker.targetPos - maxExtensionAmount\n        );\n        if (closedIntervalsOverlap(\n          start,\n          end,\n          thresholdPoint,\n          worker.targetPos\n        )) {\n          const size = worker.targetPos - worker.startPos;\n          const a = Math.ceil((size + 1) / maxExtensionAmount) * maxExtensionAmount;\n          const b = 2 ** Math.ceil(Math.log2(size + 1));\n          const extent = Math.min(b, a);\n          end = Math.max(end, worker.startPos + extent);\n        }\n      }\n      end = Math.max(end, start + URL_SOURCE_MIN_LOAD_AMOUNT);\n      return {\n        start,\n        end\n      };\n    }\n  };\n  var ReadOrchestrator = class {\n    constructor(options) {\n      this.options = options;\n      this.fileSize = null;\n      this.nextAge = 0;\n      // Used for LRU eviction of both cache entries and workers\n      this.workers = [];\n      this.cache = [];\n      this.currentCacheSize = 0;\n      this.disposed = false;\n    }\n    read(innerStart, innerEnd) {\n      assert(this.fileSize !== null);\n      const prefetchRange = this.options.prefetchProfile(innerStart, innerEnd, this.workers);\n      const outerStart = Math.max(prefetchRange.start, 0);\n      const outerEnd = Math.min(prefetchRange.end, this.fileSize);\n      assert(outerStart <= innerStart && innerEnd <= outerEnd);\n      let result = null;\n      const innerCacheStartIndex = binarySearchLessOrEqual(this.cache, innerStart, (x) => x.start);\n      const innerStartEntry = innerCacheStartIndex !== -1 ? this.cache[innerCacheStartIndex] : null;\n      if (innerStartEntry && innerStartEntry.start <= innerStart && innerEnd <= innerStartEntry.end) {\n        innerStartEntry.age = this.nextAge++;\n        result = {\n          bytes: innerStartEntry.bytes,\n          view: innerStartEntry.view,\n          offset: innerStartEntry.start\n        };\n      }\n      const outerCacheStartIndex = binarySearchLessOrEqual(this.cache, outerStart, (x) => x.start);\n      const bytes2 = result ? null : new Uint8Array(innerEnd - innerStart);\n      let contiguousBytesWriteEnd = 0;\n      let lastEnd = outerStart;\n      const outerHoles = [];\n      if (outerCacheStartIndex !== -1) {\n        for (let i = outerCacheStartIndex; i < this.cache.length; i++) {\n          const entry = this.cache[i];\n          if (entry.start >= outerEnd) {\n            break;\n          }\n          if (entry.end <= outerStart) {\n            continue;\n          }\n          const cappedOuterStart = Math.max(outerStart, entry.start);\n          const cappedOuterEnd = Math.min(outerEnd, entry.end);\n          assert(cappedOuterStart <= cappedOuterEnd);\n          if (lastEnd < cappedOuterStart) {\n            outerHoles.push({ start: lastEnd, end: cappedOuterStart });\n          }\n          lastEnd = cappedOuterEnd;\n          if (bytes2) {\n            const cappedInnerStart = Math.max(innerStart, entry.start);\n            const cappedInnerEnd = Math.min(innerEnd, entry.end);\n            if (cappedInnerStart < cappedInnerEnd) {\n              const relativeOffset = cappedInnerStart - innerStart;\n              bytes2.set(\n                entry.bytes.subarray(cappedInnerStart - entry.start, cappedInnerEnd - entry.start),\n                relativeOffset\n              );\n              if (relativeOffset === contiguousBytesWriteEnd) {\n                contiguousBytesWriteEnd = cappedInnerEnd - innerStart;\n              }\n            }\n          }\n          entry.age = this.nextAge++;\n        }\n        if (lastEnd < outerEnd) {\n          outerHoles.push({ start: lastEnd, end: outerEnd });\n        }\n      } else {\n        outerHoles.push({ start: outerStart, end: outerEnd });\n      }\n      if (bytes2 && contiguousBytesWriteEnd >= bytes2.length) {\n        result = {\n          bytes: bytes2,\n          view: toDataView(bytes2),\n          offset: innerStart\n        };\n      }\n      if (outerHoles.length === 0) {\n        assert(result);\n        return result;\n      }\n      const { promise, resolve, reject } = promiseWithResolvers();\n      const innerHoles = [];\n      for (const outerHole of outerHoles) {\n        const cappedStart = Math.max(innerStart, outerHole.start);\n        const cappedEnd = Math.min(innerEnd, outerHole.end);\n        if (cappedStart === outerHole.start && cappedEnd === outerHole.end) {\n          innerHoles.push(outerHole);\n        } else if (cappedStart < cappedEnd) {\n          innerHoles.push({ start: cappedStart, end: cappedEnd });\n        }\n      }\n      for (const outerHole of outerHoles) {\n        const pendingSlice = bytes2 && {\n          start: innerStart,\n          bytes: bytes2,\n          holes: innerHoles,\n          resolve,\n          reject\n        };\n        let workerFound = false;\n        for (const worker of this.workers) {\n          const gapTolerance = 2 ** 17;\n          if (closedIntervalsOverlap(\n            outerHole.start - gapTolerance,\n            outerHole.start,\n            worker.currentPos,\n            worker.targetPos\n          )) {\n            worker.targetPos = Math.max(worker.targetPos, outerHole.end);\n            workerFound = true;\n            if (pendingSlice && !worker.pendingSlices.includes(pendingSlice)) {\n              worker.pendingSlices.push(pendingSlice);\n            }\n            if (!worker.running) {\n              this.runWorker(worker);\n            }\n            break;\n          }\n        }\n        if (!workerFound) {\n          const newWorker = this.createWorker(outerHole.start, outerHole.end);\n          if (pendingSlice) {\n            newWorker.pendingSlices = [pendingSlice];\n          }\n          this.runWorker(newWorker);\n        }\n      }\n      if (!result) {\n        assert(bytes2);\n        result = promise.then((bytes3) => ({\n          bytes: bytes3,\n          view: toDataView(bytes3),\n          offset: innerStart\n        }));\n      } else {\n      }\n      return result;\n    }\n    createWorker(startPos, targetPos) {\n      const worker = {\n        startPos,\n        currentPos: startPos,\n        targetPos,\n        running: false,\n        // Due to async shenanigans, it can happen that workers are started after disposal. In this case, instead of\n        // simply not creating the worker, we allow it to run but immediately label it as aborted, so it can then\n        // shut itself down.\n        aborted: this.disposed,\n        pendingSlices: [],\n        age: this.nextAge++\n      };\n      this.workers.push(worker);\n      while (this.workers.length > this.options.maxWorkerCount) {\n        let oldestIndex = 0;\n        let oldestWorker = this.workers[0];\n        for (let i = 1; i < this.workers.length; i++) {\n          const worker2 = this.workers[i];\n          if (worker2.age < oldestWorker.age) {\n            oldestIndex = i;\n            oldestWorker = worker2;\n          }\n        }\n        if (oldestWorker.running && oldestWorker.pendingSlices.length > 0) {\n          break;\n        }\n        oldestWorker.aborted = true;\n        this.workers.splice(oldestIndex, 1);\n      }\n      return worker;\n    }\n    runWorker(worker) {\n      assert(!worker.running);\n      assert(worker.currentPos < worker.targetPos);\n      worker.running = true;\n      worker.age = this.nextAge++;\n      void this.options.runWorker(worker).catch((error) => {\n        worker.running = false;\n        if (worker.pendingSlices.length > 0) {\n          worker.pendingSlices.forEach((x) => x.reject(error));\n          worker.pendingSlices.length = 0;\n        } else {\n          throw error;\n        }\n      });\n    }\n    /** Called by a worker when it has read some data. */\n    supplyWorkerData(worker, bytes2) {\n      assert(!worker.aborted);\n      const start = worker.currentPos;\n      const end = start + bytes2.length;\n      this.insertIntoCache({\n        start,\n        end,\n        bytes: bytes2,\n        view: toDataView(bytes2),\n        age: this.nextAge++\n      });\n      worker.currentPos += bytes2.length;\n      worker.targetPos = Math.max(worker.targetPos, worker.currentPos);\n      for (let i = 0; i < worker.pendingSlices.length; i++) {\n        const pendingSlice = worker.pendingSlices[i];\n        const clampedStart = Math.max(start, pendingSlice.start);\n        const clampedEnd = Math.min(end, pendingSlice.start + pendingSlice.bytes.length);\n        if (clampedStart < clampedEnd) {\n          pendingSlice.bytes.set(\n            bytes2.subarray(clampedStart - start, clampedEnd - start),\n            clampedStart - pendingSlice.start\n          );\n        }\n        for (let j = 0; j < pendingSlice.holes.length; j++) {\n          const hole = pendingSlice.holes[j];\n          if (start <= hole.start && end > hole.start) {\n            hole.start = end;\n          }\n          if (hole.end <= hole.start) {\n            pendingSlice.holes.splice(j, 1);\n            j--;\n          }\n        }\n        if (pendingSlice.holes.length === 0) {\n          pendingSlice.resolve(pendingSlice.bytes);\n          worker.pendingSlices.splice(i, 1);\n          i--;\n        }\n      }\n      for (let i = 0; i < this.workers.length; i++) {\n        const otherWorker = this.workers[i];\n        if (worker === otherWorker || otherWorker.running) {\n          continue;\n        }\n        if (closedIntervalsOverlap(\n          start,\n          end,\n          otherWorker.currentPos,\n          otherWorker.targetPos\n          // These should typically be equal when the worker's idle\n        )) {\n          this.workers.splice(i, 1);\n          i--;\n        }\n      }\n    }\n    forgetWorker(worker) {\n      const index = this.workers.indexOf(worker);\n      assert(index !== -1);\n      this.workers.splice(index, 1);\n    }\n    insertIntoCache(entry) {\n      if (this.options.maxCacheSize === 0) {\n        return;\n      }\n      let insertionIndex = binarySearchLessOrEqual(this.cache, entry.start, (x) => x.start) + 1;\n      if (insertionIndex > 0) {\n        const previous = this.cache[insertionIndex - 1];\n        if (previous.end >= entry.end) {\n          return;\n        }\n        if (previous.end > entry.start) {\n          const joined = new Uint8Array(entry.end - previous.start);\n          joined.set(previous.bytes, 0);\n          joined.set(entry.bytes, entry.start - previous.start);\n          this.currentCacheSize += entry.end - previous.end;\n          previous.bytes = joined;\n          previous.view = toDataView(joined);\n          previous.end = entry.end;\n          insertionIndex--;\n          entry = previous;\n        } else {\n          this.cache.splice(insertionIndex, 0, entry);\n          this.currentCacheSize += entry.bytes.length;\n        }\n      } else {\n        this.cache.splice(insertionIndex, 0, entry);\n        this.currentCacheSize += entry.bytes.length;\n      }\n      for (let i = insertionIndex + 1; i < this.cache.length; i++) {\n        const next = this.cache[i];\n        if (entry.end <= next.start) {\n          break;\n        }\n        if (entry.end >= next.end) {\n          this.cache.splice(i, 1);\n          this.currentCacheSize -= next.bytes.length;\n          i--;\n          continue;\n        }\n        const joined = new Uint8Array(next.end - entry.start);\n        joined.set(entry.bytes, 0);\n        joined.set(next.bytes, next.start - entry.start);\n        this.currentCacheSize -= entry.end - next.start;\n        entry.bytes = joined;\n        entry.view = toDataView(joined);\n        entry.end = next.end;\n        this.cache.splice(i, 1);\n        break;\n      }\n      while (this.currentCacheSize > this.options.maxCacheSize) {\n        let oldestIndex = 0;\n        let oldestEntry = this.cache[0];\n        for (let i = 1; i < this.cache.length; i++) {\n          const entry2 = this.cache[i];\n          if (entry2.age < oldestEntry.age) {\n            oldestIndex = i;\n            oldestEntry = entry2;\n          }\n        }\n        if (this.currentCacheSize - oldestEntry.bytes.length <= this.options.maxCacheSize) {\n          break;\n        }\n        this.cache.splice(oldestIndex, 1);\n        this.currentCacheSize -= oldestEntry.bytes.length;\n      }\n    }\n    dispose() {\n      for (const worker of this.workers) {\n        worker.aborted = true;\n      }\n      this.workers.length = 0;\n      this.cache.length = 0;\n      this.disposed = true;\n    }\n  };\n\n  // src/input.ts\n  polyfillSymbolDispose();\n  var Input = class {\n    /**\n     * Creates a new input file from the specified options. No reading operations will be performed until methods are\n     * called on this instance.\n     */\n    constructor(options) {\n      /** @internal */\n      this._demuxerPromise = null;\n      /** @internal */\n      this._format = null;\n      /** @internal */\n      this._disposed = false;\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (!Array.isArray(options.formats) || options.formats.some((x) => !(x instanceof InputFormat))) {\n        throw new TypeError(\"options.formats must be an array of InputFormat.\");\n      }\n      if (!(options.source instanceof Source)) {\n        throw new TypeError(\"options.source must be a Source.\");\n      }\n      if (options.source._disposed) {\n        throw new Error(\"options.source must not be disposed.\");\n      }\n      this._formats = options.formats;\n      this._source = options.source;\n      this._reader = new Reader11(options.source);\n    }\n    /** True if the input has been disposed. */\n    get disposed() {\n      return this._disposed;\n    }\n    /** @internal */\n    _getDemuxer() {\n      return this._demuxerPromise ??= (async () => {\n        this._reader.fileSize = await this._source.getSizeOrNull();\n        for (const format of this._formats) {\n          const canRead = await format._canReadInput(this);\n          if (canRead) {\n            this._format = format;\n            return format._createDemuxer(this);\n          }\n        }\n        throw new Error(\"Input has an unsupported or unrecognizable format.\");\n      })();\n    }\n    /**\n     * Returns the source from which this input file reads its data. This is the same source that was passed to the\n     * constructor.\n     */\n    get source() {\n      return this._source;\n    }\n    /**\n     * Returns the format of the input file. You can compare this result directly to the {@link InputFormat} singletons\n     * or use `instanceof` checks for subset-aware logic (for example, `format instanceof MatroskaInputFormat` is true\n     * for both MKV and WebM).\n     */\n    async getFormat() {\n      await this._getDemuxer();\n      assert(this._format);\n      return this._format;\n    }\n    /**\n     * Computes the duration of the input file, in seconds. More precisely, returns the largest end timestamp among\n     * all tracks.\n     */\n    async computeDuration() {\n      const demuxer = await this._getDemuxer();\n      return demuxer.computeDuration();\n    }\n    /**\n     * Returns the timestamp at which the input file starts. More precisely, returns the smallest starting timestamp\n     * among all tracks.\n     */\n    async getFirstTimestamp() {\n      const tracks = await this.getTracks();\n      if (tracks.length === 0) {\n        return 0;\n      }\n      const firstTimestamps = await Promise.all(tracks.map((x) => x.getFirstTimestamp()));\n      return Math.min(...firstTimestamps);\n    }\n    /** Returns the list of all tracks of this input file. */\n    async getTracks() {\n      const demuxer = await this._getDemuxer();\n      return demuxer.getTracks();\n    }\n    /** Returns the list of all video tracks of this input file. */\n    async getVideoTracks() {\n      const tracks = await this.getTracks();\n      return tracks.filter((x) => x.isVideoTrack());\n    }\n    /** Returns the list of all audio tracks of this input file. */\n    async getAudioTracks() {\n      const tracks = await this.getTracks();\n      return tracks.filter((x) => x.isAudioTrack());\n    }\n    /** Returns the primary video track of this input file, or null if there are no video tracks. */\n    async getPrimaryVideoTrack() {\n      const tracks = await this.getTracks();\n      return tracks.find((x) => x.isVideoTrack()) ?? null;\n    }\n    /** Returns the primary audio track of this input file, or null if there are no audio tracks. */\n    async getPrimaryAudioTrack() {\n      const tracks = await this.getTracks();\n      return tracks.find((x) => x.isAudioTrack()) ?? null;\n    }\n    /** Returns the full MIME type of this input file, including track codecs. */\n    async getMimeType() {\n      const demuxer = await this._getDemuxer();\n      return demuxer.getMimeType();\n    }\n    /**\n     * Returns descriptive metadata tags about the media file, such as title, author, date, cover art, or other\n     * attached files.\n     */\n    async getMetadataTags() {\n      const demuxer = await this._getDemuxer();\n      return demuxer.getMetadataTags();\n    }\n    /**\n     * Disposes this input and frees connected resources. When an input is disposed, ongoing read operations will be\n     * canceled, all future read operations will fail, any open decoders will be closed, and all ongoing media sink\n     * operations will be canceled. Disallowed and canceled operations will throw an {@link InputDisposedError}.\n     *\n     * You are expected not to use an input after disposing it. While some operations may still work, it is not\n     * specified and may change in any future update.\n     */\n    dispose() {\n      if (this._disposed) {\n        return;\n      }\n      this._disposed = true;\n      this._source._disposed = true;\n      this._source._dispose();\n    }\n    /**\n     * Calls `.dispose()` on the input, implementing the `Disposable` interface for use with\n     * JavaScript Explicit Resource Management features.\n     */\n    [Symbol.dispose]() {\n      this.dispose();\n    }\n  };\n  var InputDisposedError = class extends Error {\n    /** Creates a new {@link InputDisposedError}. */\n    constructor(message = \"Input has been disposed.\") {\n      super(message);\n      this.name = \"InputDisposedError\";\n    }\n  };\n\n  // src/reader.ts\n  var Reader11 = class {\n    constructor(source) {\n      this.source = source;\n    }\n    requestSlice(start, length) {\n      if (this.source._disposed) {\n        throw new InputDisposedError();\n      }\n      if (start < 0) {\n        return null;\n      }\n      if (this.fileSize !== null && start + length > this.fileSize) {\n        return null;\n      }\n      const end = start + length;\n      const result = this.source._read(start, end);\n      if (result instanceof Promise) {\n        return result.then((x) => {\n          if (!x) {\n            return null;\n          }\n          return new FileSlice4(x.bytes, x.view, x.offset, start, end);\n        });\n      } else {\n        if (!result) {\n          return null;\n        }\n        return new FileSlice4(result.bytes, result.view, result.offset, start, end);\n      }\n    }\n    requestSliceRange(start, minLength, maxLength) {\n      if (this.source._disposed) {\n        throw new InputDisposedError();\n      }\n      if (start < 0) {\n        return null;\n      }\n      if (this.fileSize !== null) {\n        return this.requestSlice(\n          start,\n          clamp(this.fileSize - start, minLength, maxLength)\n        );\n      } else {\n        const promisedAttempt = this.requestSlice(start, maxLength);\n        const handleAttempt = (attempt) => {\n          if (attempt) {\n            return attempt;\n          }\n          const handleFileSize = (fileSize) => {\n            assert(fileSize !== null);\n            return this.requestSlice(\n              start,\n              clamp(fileSize - start, minLength, maxLength)\n            );\n          };\n          const promisedFileSize = this.source._retrieveSize();\n          if (promisedFileSize instanceof Promise) {\n            return promisedFileSize.then(handleFileSize);\n          } else {\n            return handleFileSize(promisedFileSize);\n          }\n        };\n        if (promisedAttempt instanceof Promise) {\n          return promisedAttempt.then(handleAttempt);\n        } else {\n          return handleAttempt(promisedAttempt);\n        }\n      }\n    }\n  };\n  var FileSlice4 = class _FileSlice {\n    constructor(bytes2, view2, offset, start, end) {\n      this.bytes = bytes2;\n      this.view = view2;\n      this.offset = offset;\n      this.start = start;\n      this.end = end;\n      this.bufferPos = start - offset;\n    }\n    static tempFromBytes(bytes2) {\n      return new _FileSlice(\n        bytes2,\n        toDataView(bytes2),\n        0,\n        0,\n        bytes2.length\n      );\n    }\n    get length() {\n      return this.end - this.start;\n    }\n    get filePos() {\n      return this.offset + this.bufferPos;\n    }\n    set filePos(value) {\n      this.bufferPos = value - this.offset;\n    }\n    /** The number of bytes left from the current pos to the end of the slice. */\n    get remainingLength() {\n      return Math.max(this.end - this.filePos, 0);\n    }\n    skip(byteCount) {\n      this.bufferPos += byteCount;\n    }\n    /** Creates a new subslice of this slice whose byte range must be contained within this slice. */\n    slice(filePos, length = this.end - filePos) {\n      if (filePos < this.start || filePos + length > this.end) {\n        throw new RangeError(\"Slicing outside of original slice.\");\n      }\n      return new _FileSlice(\n        this.bytes,\n        this.view,\n        this.offset,\n        filePos,\n        filePos + length\n      );\n    }\n  };\n  var checkIsInRange = (slice, bytesToRead) => {\n    if (slice.filePos < slice.start || slice.filePos + bytesToRead > slice.end) {\n      throw new RangeError(\n        `Tried reading [${slice.filePos}, ${slice.filePos + bytesToRead}), but slice is [${slice.start}, ${slice.end}). This is likely an internal error, please report it alongside the file that caused it.`\n      );\n    }\n  };\n  var readBytes = (slice, length) => {\n    checkIsInRange(slice, length);\n    const bytes2 = slice.bytes.subarray(slice.bufferPos, slice.bufferPos + length);\n    slice.bufferPos += length;\n    return bytes2;\n  };\n  var readU8 = (slice) => {\n    checkIsInRange(slice, 1);\n    return slice.view.getUint8(slice.bufferPos++);\n  };\n  var readU16 = (slice, littleEndian) => {\n    checkIsInRange(slice, 2);\n    const value = slice.view.getUint16(slice.bufferPos, littleEndian);\n    slice.bufferPos += 2;\n    return value;\n  };\n  var readU16Be = (slice) => {\n    checkIsInRange(slice, 2);\n    const value = slice.view.getUint16(slice.bufferPos, false);\n    slice.bufferPos += 2;\n    return value;\n  };\n  var readU24Be = (slice) => {\n    checkIsInRange(slice, 3);\n    const value = getUint24(slice.view, slice.bufferPos, false);\n    slice.bufferPos += 3;\n    return value;\n  };\n  var readI16Be = (slice) => {\n    checkIsInRange(slice, 2);\n    const value = slice.view.getInt16(slice.bufferPos, false);\n    slice.bufferPos += 2;\n    return value;\n  };\n  var readU32 = (slice, littleEndian) => {\n    checkIsInRange(slice, 4);\n    const value = slice.view.getUint32(slice.bufferPos, littleEndian);\n    slice.bufferPos += 4;\n    return value;\n  };\n  var readU32Be = (slice) => {\n    checkIsInRange(slice, 4);\n    const value = slice.view.getUint32(slice.bufferPos, false);\n    slice.bufferPos += 4;\n    return value;\n  };\n  var readU32Le = (slice) => {\n    checkIsInRange(slice, 4);\n    const value = slice.view.getUint32(slice.bufferPos, true);\n    slice.bufferPos += 4;\n    return value;\n  };\n  var readI32Be = (slice) => {\n    checkIsInRange(slice, 4);\n    const value = slice.view.getInt32(slice.bufferPos, false);\n    slice.bufferPos += 4;\n    return value;\n  };\n  var readI32Le = (slice) => {\n    checkIsInRange(slice, 4);\n    const value = slice.view.getInt32(slice.bufferPos, true);\n    slice.bufferPos += 4;\n    return value;\n  };\n  var readU64 = (slice, littleEndian) => {\n    let low;\n    let high;\n    if (littleEndian) {\n      low = readU32(slice, true);\n      high = readU32(slice, true);\n    } else {\n      high = readU32(slice, false);\n      low = readU32(slice, false);\n    }\n    return high * 4294967296 + low;\n  };\n  var readU64Be = (slice) => {\n    const high = readU32Be(slice);\n    const low = readU32Be(slice);\n    return high * 4294967296 + low;\n  };\n  var readI64Be = (slice) => {\n    const high = readI32Be(slice);\n    const low = readU32Be(slice);\n    return high * 4294967296 + low;\n  };\n  var readI64Le = (slice) => {\n    const low = readU32Le(slice);\n    const high = readI32Le(slice);\n    return high * 4294967296 + low;\n  };\n  var readF32Be = (slice) => {\n    checkIsInRange(slice, 4);\n    const value = slice.view.getFloat32(slice.bufferPos, false);\n    slice.bufferPos += 4;\n    return value;\n  };\n  var readF64Be = (slice) => {\n    checkIsInRange(slice, 8);\n    const value = slice.view.getFloat64(slice.bufferPos, false);\n    slice.bufferPos += 8;\n    return value;\n  };\n  var readAscii = (slice, length) => {\n    checkIsInRange(slice, length);\n    let str = \"\";\n    for (let i = 0; i < length; i++) {\n      str += String.fromCharCode(slice.bytes[slice.bufferPos++]);\n    }\n    return str;\n  };\n\n  // src/flac/flac-muxer.ts\n  var FLAC_HEADER = /* @__PURE__ */ new Uint8Array([102, 76, 97, 67]);\n  var STREAMINFO_SIZE = 38;\n  var STREAMINFO_BLOCK_SIZE = 34;\n  var FlacMuxer = class extends Muxer {\n    constructor(output, format) {\n      super(output);\n      this.metadataWritten = false;\n      this.blockSizes = [];\n      this.frameSizes = [];\n      this.sampleRate = null;\n      this.channels = null;\n      this.bitsPerSample = null;\n      this.writer = output._writer;\n      this.format = format;\n    }\n    async start() {\n      this.writer.write(FLAC_HEADER);\n    }\n    writeHeader({\n      bitsPerSample,\n      minimumBlockSize,\n      maximumBlockSize,\n      minimumFrameSize,\n      maximumFrameSize,\n      sampleRate,\n      channels,\n      totalSamples\n    }) {\n      assert(this.writer.getPos() === 4);\n      const hasMetadata = !metadataTagsAreEmpty(this.output._metadataTags);\n      const headerBitstream = new Bitstream(new Uint8Array(4));\n      headerBitstream.writeBits(1, Number(!hasMetadata));\n      headerBitstream.writeBits(7, 0 /* STREAMINFO */);\n      headerBitstream.writeBits(24, STREAMINFO_BLOCK_SIZE);\n      this.writer.write(headerBitstream.bytes);\n      const contentBitstream = new Bitstream(new Uint8Array(18));\n      contentBitstream.writeBits(16, minimumBlockSize);\n      contentBitstream.writeBits(16, maximumBlockSize);\n      contentBitstream.writeBits(24, minimumFrameSize);\n      contentBitstream.writeBits(24, maximumFrameSize);\n      contentBitstream.writeBits(20, sampleRate);\n      contentBitstream.writeBits(3, channels - 1);\n      contentBitstream.writeBits(5, bitsPerSample - 1);\n      if (totalSamples >= 2 ** 32) {\n        throw new Error(\"This muxer only supports writing up to 2 ** 32 samples\");\n      }\n      contentBitstream.writeBits(4, 0);\n      contentBitstream.writeBits(32, totalSamples);\n      this.writer.write(contentBitstream.bytes);\n      this.writer.write(new Uint8Array(16));\n    }\n    writePictureBlock(picture) {\n      const headerSize = 32 + picture.mimeType.length + (picture.description?.length ?? 0) + picture.data.length;\n      const header = new Uint8Array(headerSize);\n      let offset = 0;\n      const dataView = toDataView(header);\n      dataView.setUint32(\n        offset,\n        picture.kind === \"coverFront\" ? 3 : picture.kind === \"coverBack\" ? 4 : 0\n      );\n      offset += 4;\n      dataView.setUint32(offset, picture.mimeType.length);\n      offset += 4;\n      header.set(textEncoder.encode(picture.mimeType), 8);\n      offset += picture.mimeType.length;\n      dataView.setUint32(offset, picture.description?.length ?? 0);\n      offset += 4;\n      header.set(textEncoder.encode(picture.description ?? \"\"), offset);\n      offset += picture.description?.length ?? 0;\n      offset += 4 + 4 + 4 + 4;\n      dataView.setUint32(offset, picture.data.length);\n      offset += 4;\n      header.set(picture.data, offset);\n      offset += picture.data.length;\n      assert(offset === headerSize);\n      const headerBitstream = new Bitstream(new Uint8Array(4));\n      headerBitstream.writeBits(1, 0);\n      headerBitstream.writeBits(7, 6 /* PICTURE */);\n      headerBitstream.writeBits(24, headerSize);\n      this.writer.write(headerBitstream.bytes);\n      this.writer.write(header);\n    }\n    writeVorbisCommentAndPictureBlock() {\n      this.writer.seek(STREAMINFO_SIZE + FLAC_HEADER.byteLength);\n      if (metadataTagsAreEmpty(this.output._metadataTags)) {\n        this.metadataWritten = true;\n        return;\n      }\n      const pictures = this.output._metadataTags.images ?? [];\n      for (const picture of pictures) {\n        this.writePictureBlock(picture);\n      }\n      const vorbisComment = createVorbisComments(\n        new Uint8Array(0),\n        this.output._metadataTags,\n        false\n      );\n      const headerBitstream = new Bitstream(new Uint8Array(4));\n      headerBitstream.writeBits(1, 1);\n      headerBitstream.writeBits(7, 4 /* VORBIS_COMMENT */);\n      headerBitstream.writeBits(24, vorbisComment.length);\n      this.writer.write(headerBitstream.bytes);\n      this.writer.write(vorbisComment);\n      this.metadataWritten = true;\n    }\n    async getMimeType() {\n      return \"audio/flac\";\n    }\n    async addEncodedVideoPacket() {\n      throw new Error(\"FLAC does not support video.\");\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n      const release = await this.mutex.acquire();\n      validateAudioChunkMetadata(meta);\n      assert(meta);\n      assert(meta.decoderConfig);\n      assert(meta.decoderConfig.description);\n      try {\n        this.validateAndNormalizeTimestamp(\n          track,\n          packet.timestamp,\n          packet.type === \"key\"\n        );\n        if (this.sampleRate === null) {\n          this.sampleRate = meta.decoderConfig.sampleRate;\n        }\n        if (this.channels === null) {\n          this.channels = meta.decoderConfig.numberOfChannels;\n        }\n        if (this.bitsPerSample === null) {\n          const descriptionBitstream = new Bitstream(\n            toUint8Array(meta.decoderConfig.description)\n          );\n          descriptionBitstream.skipBits(103 + 64);\n          const bitsPerSample = descriptionBitstream.readBits(5) + 1;\n          this.bitsPerSample = bitsPerSample;\n        }\n        if (!this.metadataWritten) {\n          this.writeVorbisCommentAndPictureBlock();\n        }\n        const slice = FileSlice4.tempFromBytes(packet.data);\n        readBytes(slice, 2);\n        const bytes2 = readBytes(slice, 2);\n        const bitstream = new Bitstream(bytes2);\n        const blockSizeOrUncommon = getBlockSizeOrUncommon(bitstream.readBits(4));\n        if (blockSizeOrUncommon === null) {\n          throw new Error(\"Invalid FLAC frame: Invalid block size.\");\n        }\n        readCodedNumber(slice);\n        const blockSize = readBlockSize(slice, blockSizeOrUncommon);\n        this.blockSizes.push(blockSize);\n        this.frameSizes.push(packet.data.length);\n        const startPos = this.writer.getPos();\n        this.writer.write(packet.data);\n        if (this.format._options.onFrame) {\n          this.format._options.onFrame(packet.data, startPos);\n        }\n        await this.writer.flush();\n      } finally {\n        release();\n      }\n    }\n    addSubtitleCue() {\n      throw new Error(\"FLAC does not support subtitles.\");\n    }\n    async finalize() {\n      const release = await this.mutex.acquire();\n      let minimumBlockSize = Infinity;\n      let maximumBlockSize = 0;\n      let minimumFrameSize = Infinity;\n      let maximumFrameSize = 0;\n      let totalSamples = 0;\n      for (let i = 0; i < this.blockSizes.length; i++) {\n        minimumFrameSize = Math.min(minimumFrameSize, this.frameSizes[i]);\n        maximumFrameSize = Math.max(maximumFrameSize, this.frameSizes[i]);\n        maximumBlockSize = Math.max(maximumBlockSize, this.blockSizes[i]);\n        totalSamples += this.blockSizes[i];\n        const isLastFrame = i === this.blockSizes.length - 1;\n        if (isLastFrame) {\n          continue;\n        }\n        minimumBlockSize = Math.min(minimumBlockSize, this.blockSizes[i]);\n      }\n      assert(this.sampleRate !== null);\n      assert(this.channels !== null);\n      assert(this.bitsPerSample !== null);\n      this.writer.seek(4);\n      this.writeHeader({\n        minimumBlockSize,\n        maximumBlockSize,\n        minimumFrameSize,\n        maximumFrameSize,\n        sampleRate: this.sampleRate,\n        channels: this.channels,\n        bitsPerSample: this.bitsPerSample,\n        totalSamples\n      });\n      release();\n    }\n  };\n\n  // src/subtitles.ts\n  var cueBlockHeaderRegex = /(?:(.+?)\\n)?((?:\\d{2}:)?\\d{2}:\\d{2}.\\d{3})\\s+-->\\s+((?:\\d{2}:)?\\d{2}:\\d{2}.\\d{3})/g;\n  var preambleStartRegex = /^WEBVTT(.|\\n)*?\\n{2}/;\n  var inlineTimestampRegex = /<(?:(\\d{2}):)?(\\d{2}):(\\d{2}).(\\d{3})>/g;\n  var SubtitleParser = class {\n    constructor(options) {\n      this.preambleText = null;\n      this.preambleEmitted = false;\n      this.options = options;\n    }\n    parse(text) {\n      text = text.replaceAll(\"\\r\\n\", \"\\n\").replaceAll(\"\\r\", \"\\n\");\n      cueBlockHeaderRegex.lastIndex = 0;\n      let match;\n      if (!this.preambleText) {\n        if (!preambleStartRegex.test(text)) {\n          throw new Error(\"WebVTT preamble incorrect.\");\n        }\n        match = cueBlockHeaderRegex.exec(text);\n        const preamble = text.slice(0, match?.index ?? text.length).trimEnd();\n        if (!preamble) {\n          throw new Error(\"No WebVTT preamble provided.\");\n        }\n        this.preambleText = preamble;\n        if (match) {\n          text = text.slice(match.index);\n          cueBlockHeaderRegex.lastIndex = 0;\n        }\n      }\n      while (match = cueBlockHeaderRegex.exec(text)) {\n        const notes = text.slice(0, match.index);\n        const cueIdentifier = match[1];\n        const matchEnd = match.index + match[0].length;\n        const bodyStart = text.indexOf(\"\\n\", matchEnd) + 1;\n        const cueSettings = text.slice(matchEnd, bodyStart).trim();\n        let bodyEnd = text.indexOf(\"\\n\\n\", matchEnd);\n        if (bodyEnd === -1) bodyEnd = text.length;\n        const startTime = parseSubtitleTimestamp(match[2]);\n        const endTime = parseSubtitleTimestamp(match[3]);\n        const duration = endTime - startTime;\n        const body = text.slice(bodyStart, bodyEnd).trim();\n        text = text.slice(bodyEnd).trimStart();\n        cueBlockHeaderRegex.lastIndex = 0;\n        const cue = {\n          timestamp: startTime / 1e3,\n          duration: duration / 1e3,\n          text: body,\n          identifier: cueIdentifier,\n          settings: cueSettings,\n          notes\n        };\n        const meta = {};\n        if (!this.preambleEmitted) {\n          meta.config = {\n            description: this.preambleText\n          };\n          this.preambleEmitted = true;\n        }\n        this.options.output(cue, meta);\n      }\n    }\n  };\n  var timestampRegex = /(?:(\\d{2}):)?(\\d{2}):(\\d{2}).(\\d{3})/;\n  var parseSubtitleTimestamp = (string) => {\n    const match = timestampRegex.exec(string);\n    if (!match) throw new Error(\"Expected match.\");\n    return 60 * 60 * 1e3 * Number(match[1] || \"0\") + 60 * 1e3 * Number(match[2]) + 1e3 * Number(match[3]) + Number(match[4]);\n  };\n  var formatSubtitleTimestamp = (timestamp) => {\n    const hours = Math.floor(timestamp / (60 * 60 * 1e3));\n    const minutes = Math.floor(timestamp % (60 * 60 * 1e3) / (60 * 1e3));\n    const seconds = Math.floor(timestamp % (60 * 1e3) / 1e3);\n    const milliseconds = timestamp % 1e3;\n    return hours.toString().padStart(2, \"0\") + \":\" + minutes.toString().padStart(2, \"0\") + \":\" + seconds.toString().padStart(2, \"0\") + \".\" + milliseconds.toString().padStart(3, \"0\");\n  };\n\n  // src/isobmff/isobmff-boxes.ts\n  var IsobmffBoxWriter = class {\n    constructor(writer) {\n      this.writer = writer;\n      this.helper = new Uint8Array(8);\n      this.helperView = new DataView(this.helper.buffer);\n      /**\n       * Stores the position from the start of the file to where boxes elements have been written. This is used to\n       * rewrite/edit elements that were already added before, and to measure sizes of things.\n       */\n      this.offsets = /* @__PURE__ */ new WeakMap();\n    }\n    writeU32(value) {\n      this.helperView.setUint32(0, value, false);\n      this.writer.write(this.helper.subarray(0, 4));\n    }\n    writeU64(value) {\n      this.helperView.setUint32(0, Math.floor(value / 2 ** 32), false);\n      this.helperView.setUint32(4, value, false);\n      this.writer.write(this.helper.subarray(0, 8));\n    }\n    writeAscii(text) {\n      for (let i = 0; i < text.length; i++) {\n        this.helperView.setUint8(i % 8, text.charCodeAt(i));\n        if (i % 8 === 7) this.writer.write(this.helper);\n      }\n      if (text.length % 8 !== 0) {\n        this.writer.write(this.helper.subarray(0, text.length % 8));\n      }\n    }\n    writeBox(box2) {\n      this.offsets.set(box2, this.writer.getPos());\n      if (box2.contents && !box2.children) {\n        this.writeBoxHeader(box2, box2.size ?? box2.contents.byteLength + 8);\n        this.writer.write(box2.contents);\n      } else {\n        const startPos = this.writer.getPos();\n        this.writeBoxHeader(box2, 0);\n        if (box2.contents) this.writer.write(box2.contents);\n        if (box2.children) {\n          for (const child of box2.children) if (child) this.writeBox(child);\n        }\n        const endPos = this.writer.getPos();\n        const size = box2.size ?? endPos - startPos;\n        this.writer.seek(startPos);\n        this.writeBoxHeader(box2, size);\n        this.writer.seek(endPos);\n      }\n    }\n    writeBoxHeader(box2, size) {\n      this.writeU32(box2.largeSize ? 1 : size);\n      this.writeAscii(box2.type);\n      if (box2.largeSize) this.writeU64(size);\n    }\n    measureBoxHeader(box2) {\n      return 8 + (box2.largeSize ? 8 : 0);\n    }\n    patchBox(box2) {\n      const boxOffset = this.offsets.get(box2);\n      assert(boxOffset !== void 0);\n      const endPos = this.writer.getPos();\n      this.writer.seek(boxOffset);\n      this.writeBox(box2);\n      this.writer.seek(endPos);\n    }\n    measureBox(box2) {\n      if (box2.contents && !box2.children) {\n        const headerSize = this.measureBoxHeader(box2);\n        return headerSize + box2.contents.byteLength;\n      } else {\n        let result = this.measureBoxHeader(box2);\n        if (box2.contents) result += box2.contents.byteLength;\n        if (box2.children) {\n          for (const child of box2.children) if (child) result += this.measureBox(child);\n        }\n        return result;\n      }\n    }\n  };\n  var bytes = /* @__PURE__ */ new Uint8Array(8);\n  var view = /* @__PURE__ */ new DataView(bytes.buffer);\n  var u8 = (value) => {\n    return [(value % 256 + 256) % 256];\n  };\n  var u16 = (value) => {\n    view.setUint16(0, value, false);\n    return [bytes[0], bytes[1]];\n  };\n  var i16 = (value) => {\n    view.setInt16(0, value, false);\n    return [bytes[0], bytes[1]];\n  };\n  var u24 = (value) => {\n    view.setUint32(0, value, false);\n    return [bytes[1], bytes[2], bytes[3]];\n  };\n  var u32 = (value) => {\n    view.setUint32(0, value, false);\n    return [bytes[0], bytes[1], bytes[2], bytes[3]];\n  };\n  var i32 = (value) => {\n    view.setInt32(0, value, false);\n    return [bytes[0], bytes[1], bytes[2], bytes[3]];\n  };\n  var u64 = (value) => {\n    view.setUint32(0, Math.floor(value / 2 ** 32), false);\n    view.setUint32(4, value, false);\n    return [bytes[0], bytes[1], bytes[2], bytes[3], bytes[4], bytes[5], bytes[6], bytes[7]];\n  };\n  var fixed_8_8 = (value) => {\n    view.setInt16(0, 2 ** 8 * value, false);\n    return [bytes[0], bytes[1]];\n  };\n  var fixed_16_16 = (value) => {\n    view.setInt32(0, 2 ** 16 * value, false);\n    return [bytes[0], bytes[1], bytes[2], bytes[3]];\n  };\n  var fixed_2_30 = (value) => {\n    view.setInt32(0, 2 ** 30 * value, false);\n    return [bytes[0], bytes[1], bytes[2], bytes[3]];\n  };\n  var variableUnsignedInt = (value, byteLength) => {\n    const bytes2 = [];\n    let remaining = value;\n    do {\n      let byte = remaining & 127;\n      remaining >>= 7;\n      if (bytes2.length > 0) {\n        byte |= 128;\n      }\n      bytes2.push(byte);\n      if (byteLength !== void 0) {\n        byteLength--;\n      }\n    } while (remaining > 0 || byteLength);\n    return bytes2.reverse();\n  };\n  var ascii = (text, nullTerminated = false) => {\n    const bytes2 = Array(text.length).fill(null).map((_, i) => text.charCodeAt(i));\n    if (nullTerminated) bytes2.push(0);\n    return bytes2;\n  };\n  var lastPresentedSample = (samples) => {\n    let result = null;\n    for (const sample of samples) {\n      if (!result || sample.timestamp > result.timestamp) {\n        result = sample;\n      }\n    }\n    return result;\n  };\n  var rotationMatrix = (rotationInDegrees) => {\n    const theta = rotationInDegrees * (Math.PI / 180);\n    const cosTheta = Math.round(Math.cos(theta));\n    const sinTheta = Math.round(Math.sin(theta));\n    return [\n      cosTheta,\n      sinTheta,\n      0,\n      -sinTheta,\n      cosTheta,\n      0,\n      0,\n      0,\n      1\n    ];\n  };\n  var IDENTITY_MATRIX = /* @__PURE__ */ rotationMatrix(0);\n  var matrixToBytes = (matrix) => {\n    return [\n      fixed_16_16(matrix[0]),\n      fixed_16_16(matrix[1]),\n      fixed_2_30(matrix[2]),\n      fixed_16_16(matrix[3]),\n      fixed_16_16(matrix[4]),\n      fixed_2_30(matrix[5]),\n      fixed_16_16(matrix[6]),\n      fixed_16_16(matrix[7]),\n      fixed_2_30(matrix[8])\n    ];\n  };\n  var box = (type, contents, children) => ({\n    type,\n    contents: contents && new Uint8Array(contents.flat(10)),\n    children\n  });\n  var fullBox = (type, version, flags, contents, children) => box(\n    type,\n    [u8(version), u24(flags), contents ?? []],\n    children\n  );\n  var ftyp = (details) => {\n    const minorVersion = 512;\n    if (details.isQuickTime) {\n      return box(\"ftyp\", [\n        ascii(\"qt  \"),\n        // Major brand\n        u32(minorVersion),\n        // Minor version\n        // Compatible brands\n        ascii(\"qt  \")\n      ]);\n    }\n    if (details.fragmented) {\n      return box(\"ftyp\", [\n        ascii(\"iso5\"),\n        // Major brand\n        u32(minorVersion),\n        // Minor version\n        // Compatible brands\n        ascii(\"iso5\"),\n        ascii(\"iso6\"),\n        ascii(\"mp41\")\n      ]);\n    }\n    return box(\"ftyp\", [\n      ascii(\"isom\"),\n      // Major brand\n      u32(minorVersion),\n      // Minor version\n      // Compatible brands\n      ascii(\"isom\"),\n      details.holdsAvc ? ascii(\"avc1\") : [],\n      ascii(\"mp41\")\n    ]);\n  };\n  var mdat = (reserveLargeSize) => ({ type: \"mdat\", largeSize: reserveLargeSize });\n  var free = (size) => ({ type: \"free\", size });\n  var moov = (muxer) => box(\"moov\", void 0, [\n    mvhd(muxer.creationTime, muxer.trackDatas),\n    ...muxer.trackDatas.map((x) => trak(x, muxer.creationTime)),\n    muxer.isFragmented ? mvex(muxer.trackDatas) : null,\n    udta(muxer)\n  ]);\n  var mvhd = (creationTime, trackDatas) => {\n    const duration = intoTimescale(Math.max(\n      0,\n      ...trackDatas.filter((x) => x.samples.length > 0).map((x) => {\n        const lastSample = lastPresentedSample(x.samples);\n        return lastSample.timestamp + lastSample.duration;\n      })\n    ), GLOBAL_TIMESCALE);\n    const nextTrackId = Math.max(0, ...trackDatas.map((x) => x.track.id)) + 1;\n    const needsU64 = !isU32(creationTime) || !isU32(duration);\n    const u32OrU64 = needsU64 ? u64 : u32;\n    return fullBox(\"mvhd\", +needsU64, 0, [\n      u32OrU64(creationTime),\n      // Creation time\n      u32OrU64(creationTime),\n      // Modification time\n      u32(GLOBAL_TIMESCALE),\n      // Timescale\n      u32OrU64(duration),\n      // Duration\n      fixed_16_16(1),\n      // Preferred rate\n      fixed_8_8(1),\n      // Preferred volume\n      Array(10).fill(0),\n      // Reserved\n      matrixToBytes(IDENTITY_MATRIX),\n      // Matrix\n      Array(24).fill(0),\n      // Pre-defined\n      u32(nextTrackId)\n      // Next track ID\n    ]);\n  };\n  var trak = (trackData, creationTime) => {\n    const trackMetadata = getTrackMetadata(trackData);\n    return box(\"trak\", void 0, [\n      tkhd(trackData, creationTime),\n      mdia(trackData, creationTime),\n      trackMetadata.name !== void 0 ? box(\"udta\", void 0, [\n        box(\"name\", [\n          // VLC (and Mediabunny) also recognize nam\n          ...textEncoder.encode(trackMetadata.name)\n        ])\n      ]) : null\n    ]);\n  };\n  var tkhd = (trackData, creationTime) => {\n    const lastSample = lastPresentedSample(trackData.samples);\n    const durationInGlobalTimescale = intoTimescale(\n      lastSample ? lastSample.timestamp + lastSample.duration : 0,\n      GLOBAL_TIMESCALE\n    );\n    const needsU64 = !isU32(creationTime) || !isU32(durationInGlobalTimescale);\n    const u32OrU64 = needsU64 ? u64 : u32;\n    let matrix;\n    if (trackData.type === \"video\") {\n      const rotation = trackData.track.metadata.rotation;\n      matrix = rotationMatrix(rotation ?? 0);\n    } else {\n      matrix = IDENTITY_MATRIX;\n    }\n    let flags = 2;\n    if (trackData.track.metadata.disposition?.default !== false) {\n      flags |= 1;\n    }\n    return fullBox(\"tkhd\", +needsU64, flags, [\n      u32OrU64(creationTime),\n      // Creation time\n      u32OrU64(creationTime),\n      // Modification time\n      u32(trackData.track.id),\n      // Track ID\n      u32(0),\n      // Reserved\n      u32OrU64(durationInGlobalTimescale),\n      // Duration\n      Array(8).fill(0),\n      // Reserved\n      u16(0),\n      // Layer\n      u16(trackData.track.id),\n      // Alternate group\n      fixed_8_8(trackData.type === \"audio\" ? 1 : 0),\n      // Volume\n      u16(0),\n      // Reserved\n      matrixToBytes(matrix),\n      // Matrix\n      fixed_16_16(trackData.type === \"video\" ? trackData.info.width : 0),\n      // Track width\n      fixed_16_16(trackData.type === \"video\" ? trackData.info.height : 0)\n      // Track height\n    ]);\n  };\n  var mdia = (trackData, creationTime) => box(\"mdia\", void 0, [\n    mdhd(trackData, creationTime),\n    hdlr(true, TRACK_TYPE_TO_COMPONENT_SUBTYPE[trackData.type], TRACK_TYPE_TO_HANDLER_NAME[trackData.type]),\n    minf(trackData)\n  ]);\n  var mdhd = (trackData, creationTime) => {\n    const lastSample = lastPresentedSample(trackData.samples);\n    const localDuration = intoTimescale(\n      lastSample ? lastSample.timestamp + lastSample.duration : 0,\n      trackData.timescale\n    );\n    const needsU64 = !isU32(creationTime) || !isU32(localDuration);\n    const u32OrU64 = needsU64 ? u64 : u32;\n    return fullBox(\"mdhd\", +needsU64, 0, [\n      u32OrU64(creationTime),\n      // Creation time\n      u32OrU64(creationTime),\n      // Modification time\n      u32(trackData.timescale),\n      // Timescale\n      u32OrU64(localDuration),\n      // Duration\n      u16(getLanguageCodeInt(trackData.track.metadata.languageCode ?? UNDETERMINED_LANGUAGE)),\n      // Language\n      u16(0)\n      // Quality\n    ]);\n  };\n  var TRACK_TYPE_TO_COMPONENT_SUBTYPE = {\n    video: \"vide\",\n    audio: \"soun\",\n    subtitle: \"text\"\n  };\n  var TRACK_TYPE_TO_HANDLER_NAME = {\n    video: \"MediabunnyVideoHandler\",\n    audio: \"MediabunnySoundHandler\",\n    subtitle: \"MediabunnyTextHandler\"\n  };\n  var hdlr = (hasComponentType, handlerType, name, manufacturer = \"\\0\\0\\0\\0\") => fullBox(\"hdlr\", 0, 0, [\n    hasComponentType ? ascii(\"mhlr\") : u32(0),\n    // Component type\n    ascii(handlerType),\n    // Component subtype\n    ascii(manufacturer),\n    // Component manufacturer\n    u32(0),\n    // Component flags\n    u32(0),\n    // Component flags mask\n    ascii(name, true)\n    // Component name\n  ]);\n  var minf = (trackData) => box(\"minf\", void 0, [\n    TRACK_TYPE_TO_HEADER_BOX[trackData.type](),\n    dinf(),\n    stbl(trackData)\n  ]);\n  var vmhd = () => fullBox(\"vmhd\", 0, 1, [\n    u16(0),\n    // Graphics mode\n    u16(0),\n    // Opcolor R\n    u16(0),\n    // Opcolor G\n    u16(0)\n    // Opcolor B\n  ]);\n  var smhd = () => fullBox(\"smhd\", 0, 0, [\n    u16(0),\n    // Balance\n    u16(0)\n    // Reserved\n  ]);\n  var nmhd = () => fullBox(\"nmhd\", 0, 0);\n  var TRACK_TYPE_TO_HEADER_BOX = {\n    video: vmhd,\n    audio: smhd,\n    subtitle: nmhd\n  };\n  var dinf = () => box(\"dinf\", void 0, [\n    dref()\n  ]);\n  var dref = () => fullBox(\"dref\", 0, 0, [\n    u32(1)\n    // Entry count\n  ], [\n    url()\n  ]);\n  var url = () => fullBox(\"url \", 0, 1);\n  var stbl = (trackData) => {\n    const needsCtts = trackData.compositionTimeOffsetTable.length > 1 || trackData.compositionTimeOffsetTable.some((x) => x.sampleCompositionTimeOffset !== 0);\n    return box(\"stbl\", void 0, [\n      stsd(trackData),\n      stts(trackData),\n      needsCtts ? ctts(trackData) : null,\n      needsCtts ? cslg(trackData) : null,\n      stsc(trackData),\n      stsz(trackData),\n      stco(trackData),\n      stss(trackData)\n    ]);\n  };\n  var stsd = (trackData) => {\n    let sampleDescription;\n    if (trackData.type === \"video\") {\n      sampleDescription = videoSampleDescription(\n        videoCodecToBoxName(trackData.track.source._codec, trackData.info.decoderConfig.codec),\n        trackData\n      );\n    } else if (trackData.type === \"audio\") {\n      const boxName = audioCodecToBoxName(trackData.track.source._codec, trackData.muxer.isQuickTime);\n      assert(boxName);\n      sampleDescription = soundSampleDescription(\n        boxName,\n        trackData\n      );\n    } else if (trackData.type === \"subtitle\") {\n      sampleDescription = subtitleSampleDescription(\n        SUBTITLE_CODEC_TO_BOX_NAME[trackData.track.source._codec],\n        trackData\n      );\n    }\n    assert(sampleDescription);\n    return fullBox(\"stsd\", 0, 0, [\n      u32(1)\n      // Entry count\n    ], [\n      sampleDescription\n    ]);\n  };\n  var videoSampleDescription = (compressionType, trackData) => box(compressionType, [\n    Array(6).fill(0),\n    // Reserved\n    u16(1),\n    // Data reference index\n    u16(0),\n    // Pre-defined\n    u16(0),\n    // Reserved\n    Array(12).fill(0),\n    // Pre-defined\n    u16(trackData.info.width),\n    // Width\n    u16(trackData.info.height),\n    // Height\n    u32(4718592),\n    // Horizontal resolution\n    u32(4718592),\n    // Vertical resolution\n    u32(0),\n    // Reserved\n    u16(1),\n    // Frame count\n    Array(32).fill(0),\n    // Compressor name\n    u16(24),\n    // Depth\n    i16(65535)\n    // Pre-defined\n  ], [\n    VIDEO_CODEC_TO_CONFIGURATION_BOX[trackData.track.source._codec](trackData),\n    colorSpaceIsComplete(trackData.info.decoderConfig.colorSpace) ? colr(trackData) : null\n  ]);\n  var colr = (trackData) => box(\"colr\", [\n    ascii(\"nclx\"),\n    // Colour type\n    u16(COLOR_PRIMARIES_MAP[trackData.info.decoderConfig.colorSpace.primaries]),\n    // Colour primaries\n    u16(TRANSFER_CHARACTERISTICS_MAP[trackData.info.decoderConfig.colorSpace.transfer]),\n    // Transfer characteristics\n    u16(MATRIX_COEFFICIENTS_MAP[trackData.info.decoderConfig.colorSpace.matrix]),\n    // Matrix coefficients\n    u8((trackData.info.decoderConfig.colorSpace.fullRange ? 1 : 0) << 7)\n    // Full range flag\n  ]);\n  var avcC = (trackData) => trackData.info.decoderConfig && box(\"avcC\", [\n    // For AVC, description is an AVCDecoderConfigurationRecord, so nothing else to do here\n    ...toUint8Array(trackData.info.decoderConfig.description)\n  ]);\n  var hvcC = (trackData) => trackData.info.decoderConfig && box(\"hvcC\", [\n    // For HEVC, description is an HEVCDecoderConfigurationRecord, so nothing else to do here\n    ...toUint8Array(trackData.info.decoderConfig.description)\n  ]);\n  var vpcC = (trackData) => {\n    if (!trackData.info.decoderConfig) {\n      return null;\n    }\n    const decoderConfig = trackData.info.decoderConfig;\n    const parts = decoderConfig.codec.split(\".\");\n    const profile = Number(parts[1]);\n    const level = Number(parts[2]);\n    const bitDepth = Number(parts[3]);\n    const chromaSubsampling = parts[4] ? Number(parts[4]) : 1;\n    const videoFullRangeFlag = parts[8] ? Number(parts[8]) : Number(decoderConfig.colorSpace?.fullRange ?? 0);\n    const thirdByte = (bitDepth << 4) + (chromaSubsampling << 1) + videoFullRangeFlag;\n    const colourPrimaries = parts[5] ? Number(parts[5]) : decoderConfig.colorSpace?.primaries ? COLOR_PRIMARIES_MAP[decoderConfig.colorSpace.primaries] : 2;\n    const transferCharacteristics = parts[6] ? Number(parts[6]) : decoderConfig.colorSpace?.transfer ? TRANSFER_CHARACTERISTICS_MAP[decoderConfig.colorSpace.transfer] : 2;\n    const matrixCoefficients = parts[7] ? Number(parts[7]) : decoderConfig.colorSpace?.matrix ? MATRIX_COEFFICIENTS_MAP[decoderConfig.colorSpace.matrix] : 2;\n    return fullBox(\"vpcC\", 1, 0, [\n      u8(profile),\n      // Profile\n      u8(level),\n      // Level\n      u8(thirdByte),\n      // Bit depth, chroma subsampling, full range\n      u8(colourPrimaries),\n      // Colour primaries\n      u8(transferCharacteristics),\n      // Transfer characteristics\n      u8(matrixCoefficients),\n      // Matrix coefficients\n      u16(0)\n      // Codec initialization data size\n    ]);\n  };\n  var av1C = (trackData) => {\n    return box(\"av1C\", generateAv1CodecConfigurationFromCodecString(trackData.info.decoderConfig.codec));\n  };\n  var soundSampleDescription = (compressionType, trackData) => {\n    let version = 0;\n    let contents;\n    let sampleSizeInBits = 16;\n    if (PCM_AUDIO_CODECS.includes(trackData.track.source._codec)) {\n      const codec = trackData.track.source._codec;\n      const { sampleSize } = parsePcmCodec(codec);\n      sampleSizeInBits = 8 * sampleSize;\n      if (sampleSizeInBits > 16) {\n        version = 1;\n      }\n    }\n    if (version === 0) {\n      contents = [\n        Array(6).fill(0),\n        // Reserved\n        u16(1),\n        // Data reference index\n        u16(version),\n        // Version\n        u16(0),\n        // Revision level\n        u32(0),\n        // Vendor\n        u16(trackData.info.numberOfChannels),\n        // Number of channels\n        u16(sampleSizeInBits),\n        // Sample size (bits)\n        u16(0),\n        // Compression ID\n        u16(0),\n        // Packet size\n        u16(trackData.info.sampleRate < 2 ** 16 ? trackData.info.sampleRate : 0),\n        // Sample rate (upper)\n        u16(0)\n        // Sample rate (lower)\n      ];\n    } else {\n      contents = [\n        Array(6).fill(0),\n        // Reserved\n        u16(1),\n        // Data reference index\n        u16(version),\n        // Version\n        u16(0),\n        // Revision level\n        u32(0),\n        // Vendor\n        u16(trackData.info.numberOfChannels),\n        // Number of channels\n        u16(Math.min(sampleSizeInBits, 16)),\n        // Sample size (bits)\n        u16(0),\n        // Compression ID\n        u16(0),\n        // Packet size\n        u16(trackData.info.sampleRate < 2 ** 16 ? trackData.info.sampleRate : 0),\n        // Sample rate (upper)\n        u16(0),\n        // Sample rate (lower)\n        u32(1),\n        // Samples per packet (must be 1 for uncompressed formats)\n        u32(sampleSizeInBits / 8),\n        // Bytes per packet\n        u32(trackData.info.numberOfChannels * sampleSizeInBits / 8),\n        // Bytes per frame\n        u32(2)\n        // Bytes per sample (constant in FFmpeg)\n      ];\n    }\n    return box(compressionType, contents, [\n      audioCodecToConfigurationBox(trackData.track.source._codec, trackData.muxer.isQuickTime)?.(trackData) ?? null\n    ]);\n  };\n  var esds = (trackData) => {\n    let objectTypeIndication;\n    switch (trackData.track.source._codec) {\n      case \"aac\":\n        {\n          objectTypeIndication = 64;\n        }\n        ;\n        break;\n      case \"mp3\":\n        {\n          objectTypeIndication = 107;\n        }\n        ;\n        break;\n      case \"vorbis\":\n        {\n          objectTypeIndication = 221;\n        }\n        ;\n        break;\n      default:\n        throw new Error(`Unhandled audio codec: ${trackData.track.source._codec}`);\n    }\n    let bytes2 = [\n      ...u8(objectTypeIndication),\n      // Object type indication\n      ...u8(21),\n      // stream type(6bits)=5 audio, flags(2bits)=1\n      ...u24(0),\n      // 24bit buffer size\n      ...u32(0),\n      // max bitrate\n      ...u32(0)\n      // avg bitrate\n    ];\n    if (trackData.info.decoderConfig.description) {\n      const description = toUint8Array(trackData.info.decoderConfig.description);\n      bytes2 = [\n        ...bytes2,\n        ...u8(5),\n        // TAG(5) = DecoderSpecificInfo\n        ...variableUnsignedInt(description.byteLength),\n        ...description\n      ];\n    }\n    bytes2 = [\n      ...u16(1),\n      // ES_ID = 1\n      ...u8(0),\n      // flags etc = 0\n      ...u8(4),\n      // TAG(4) = ES Descriptor\n      ...variableUnsignedInt(bytes2.length),\n      ...bytes2,\n      ...u8(6),\n      // TAG(6)\n      ...u8(1),\n      // length\n      ...u8(2)\n      // data\n    ];\n    bytes2 = [\n      ...u8(3),\n      // TAG(3) = Object Descriptor\n      ...variableUnsignedInt(bytes2.length),\n      ...bytes2\n    ];\n    return fullBox(\"esds\", 0, 0, bytes2);\n  };\n  var wave = (trackData) => {\n    return box(\"wave\", void 0, [\n      frma(trackData),\n      enda(trackData),\n      box(\"\\0\\0\\0\\0\")\n      // NULL tag at the end\n    ]);\n  };\n  var frma = (trackData) => {\n    return box(\"frma\", [\n      ascii(audioCodecToBoxName(trackData.track.source._codec, trackData.muxer.isQuickTime))\n    ]);\n  };\n  var enda = (trackData) => {\n    const { littleEndian } = parsePcmCodec(trackData.track.source._codec);\n    return box(\"enda\", [\n      u16(+littleEndian)\n    ]);\n  };\n  var dOps = (trackData) => {\n    let outputChannelCount = trackData.info.numberOfChannels;\n    let preSkip = 3840;\n    let inputSampleRate = trackData.info.sampleRate;\n    let outputGain = 0;\n    let channelMappingFamily = 0;\n    let channelMappingTable = new Uint8Array(0);\n    const description = trackData.info.decoderConfig?.description;\n    if (description) {\n      assert(description.byteLength >= 18);\n      const bytes2 = toUint8Array(description);\n      const header = parseOpusIdentificationHeader(bytes2);\n      outputChannelCount = header.outputChannelCount;\n      preSkip = header.preSkip;\n      inputSampleRate = header.inputSampleRate;\n      outputGain = header.outputGain;\n      channelMappingFamily = header.channelMappingFamily;\n      if (header.channelMappingTable) {\n        channelMappingTable = header.channelMappingTable;\n      }\n    }\n    return box(\"dOps\", [\n      u8(0),\n      // Version\n      u8(outputChannelCount),\n      // OutputChannelCount\n      u16(preSkip),\n      // PreSkip\n      u32(inputSampleRate),\n      // InputSampleRate\n      i16(outputGain),\n      // OutputGain\n      u8(channelMappingFamily),\n      // ChannelMappingFamily\n      ...channelMappingTable\n    ]);\n  };\n  var dfLa = (trackData) => {\n    const description = trackData.info.decoderConfig?.description;\n    assert(description);\n    const bytes2 = toUint8Array(description);\n    return fullBox(\"dfLa\", 0, 0, [\n      ...bytes2.subarray(4)\n    ]);\n  };\n  var pcmC = (trackData) => {\n    const { littleEndian, sampleSize } = parsePcmCodec(trackData.track.source._codec);\n    const formatFlags = +littleEndian;\n    return fullBox(\"pcmC\", 0, 0, [\n      u8(formatFlags),\n      u8(8 * sampleSize)\n    ]);\n  };\n  var subtitleSampleDescription = (compressionType, trackData) => box(compressionType, [\n    Array(6).fill(0),\n    // Reserved\n    u16(1)\n    // Data reference index\n  ], [\n    SUBTITLE_CODEC_TO_CONFIGURATION_BOX[trackData.track.source._codec](trackData)\n  ]);\n  var vttC = (trackData) => box(\"vttC\", [\n    ...textEncoder.encode(trackData.info.config.description)\n  ]);\n  var stts = (trackData) => {\n    return fullBox(\"stts\", 0, 0, [\n      u32(trackData.timeToSampleTable.length),\n      // Number of entries\n      trackData.timeToSampleTable.map((x) => [\n        // Time-to-sample table\n        u32(x.sampleCount),\n        // Sample count\n        u32(x.sampleDelta)\n        // Sample duration\n      ])\n    ]);\n  };\n  var stss = (trackData) => {\n    if (trackData.samples.every((x) => x.type === \"key\")) return null;\n    const keySamples = [...trackData.samples.entries()].filter(([, sample]) => sample.type === \"key\");\n    return fullBox(\"stss\", 0, 0, [\n      u32(keySamples.length),\n      // Number of entries\n      keySamples.map(([index]) => u32(index + 1))\n      // Sync sample table\n    ]);\n  };\n  var stsc = (trackData) => {\n    return fullBox(\"stsc\", 0, 0, [\n      u32(trackData.compactlyCodedChunkTable.length),\n      // Number of entries\n      trackData.compactlyCodedChunkTable.map((x) => [\n        // Sample-to-chunk table\n        u32(x.firstChunk),\n        // First chunk\n        u32(x.samplesPerChunk),\n        // Samples per chunk\n        u32(1)\n        // Sample description index\n      ])\n    ]);\n  };\n  var stsz = (trackData) => {\n    if (trackData.type === \"audio\" && trackData.info.requiresPcmTransformation) {\n      const { sampleSize } = parsePcmCodec(trackData.track.source._codec);\n      return fullBox(\"stsz\", 0, 0, [\n        u32(sampleSize * trackData.info.numberOfChannels),\n        // Sample size\n        u32(trackData.samples.reduce((acc, x) => acc + intoTimescale(x.duration, trackData.timescale), 0))\n      ]);\n    }\n    return fullBox(\"stsz\", 0, 0, [\n      u32(0),\n      // Sample size (0 means non-constant size)\n      u32(trackData.samples.length),\n      // Number of entries\n      trackData.samples.map((x) => u32(x.size))\n      // Sample size table\n    ]);\n  };\n  var stco = (trackData) => {\n    if (trackData.finalizedChunks.length > 0 && last(trackData.finalizedChunks).offset >= 2 ** 32) {\n      return fullBox(\"co64\", 0, 0, [\n        u32(trackData.finalizedChunks.length),\n        // Number of entries\n        trackData.finalizedChunks.map((x) => u64(x.offset))\n        // Chunk offset table\n      ]);\n    }\n    return fullBox(\"stco\", 0, 0, [\n      u32(trackData.finalizedChunks.length),\n      // Number of entries\n      trackData.finalizedChunks.map((x) => u32(x.offset))\n      // Chunk offset table\n    ]);\n  };\n  var ctts = (trackData) => {\n    return fullBox(\"ctts\", 1, 0, [\n      u32(trackData.compositionTimeOffsetTable.length),\n      // Number of entries\n      trackData.compositionTimeOffsetTable.map((x) => [\n        // Time-to-sample table\n        u32(x.sampleCount),\n        // Sample count\n        i32(x.sampleCompositionTimeOffset)\n        // Sample offset\n      ])\n    ]);\n  };\n  var cslg = (trackData) => {\n    let leastDecodeToDisplayDelta = Infinity;\n    let greatestDecodeToDisplayDelta = -Infinity;\n    let compositionStartTime = Infinity;\n    let compositionEndTime = -Infinity;\n    assert(trackData.compositionTimeOffsetTable.length > 0);\n    assert(trackData.samples.length > 0);\n    for (let i = 0; i < trackData.compositionTimeOffsetTable.length; i++) {\n      const entry = trackData.compositionTimeOffsetTable[i];\n      leastDecodeToDisplayDelta = Math.min(leastDecodeToDisplayDelta, entry.sampleCompositionTimeOffset);\n      greatestDecodeToDisplayDelta = Math.max(greatestDecodeToDisplayDelta, entry.sampleCompositionTimeOffset);\n    }\n    for (let i = 0; i < trackData.samples.length; i++) {\n      const sample = trackData.samples[i];\n      compositionStartTime = Math.min(\n        compositionStartTime,\n        intoTimescale(sample.timestamp, trackData.timescale)\n      );\n      compositionEndTime = Math.max(\n        compositionEndTime,\n        intoTimescale(sample.timestamp + sample.duration, trackData.timescale)\n      );\n    }\n    const compositionToDtsShift = Math.max(-leastDecodeToDisplayDelta, 0);\n    if (compositionEndTime >= 2 ** 31) {\n      return null;\n    }\n    return fullBox(\"cslg\", 0, 0, [\n      i32(compositionToDtsShift),\n      // Composition to DTS shift\n      i32(leastDecodeToDisplayDelta),\n      // Least decode to display delta\n      i32(greatestDecodeToDisplayDelta),\n      // Greatest decode to display delta\n      i32(compositionStartTime),\n      // Composition start time\n      i32(compositionEndTime)\n      // Composition end time\n    ]);\n  };\n  var mvex = (trackDatas) => {\n    return box(\"mvex\", void 0, trackDatas.map(trex));\n  };\n  var trex = (trackData) => {\n    return fullBox(\"trex\", 0, 0, [\n      u32(trackData.track.id),\n      // Track ID\n      u32(1),\n      // Default sample description index\n      u32(0),\n      // Default sample duration\n      u32(0),\n      // Default sample size\n      u32(0)\n      // Default sample flags\n    ]);\n  };\n  var moof = (sequenceNumber, trackDatas) => {\n    return box(\"moof\", void 0, [\n      mfhd(sequenceNumber),\n      ...trackDatas.map(traf)\n    ]);\n  };\n  var mfhd = (sequenceNumber) => {\n    return fullBox(\"mfhd\", 0, 0, [\n      u32(sequenceNumber)\n      // Sequence number\n    ]);\n  };\n  var fragmentSampleFlags = (sample) => {\n    let byte1 = 0;\n    let byte2 = 0;\n    const byte3 = 0;\n    const byte4 = 0;\n    const sampleIsDifferenceSample = sample.type === \"delta\";\n    byte2 |= +sampleIsDifferenceSample;\n    if (sampleIsDifferenceSample) {\n      byte1 |= 1;\n    } else {\n      byte1 |= 2;\n    }\n    return byte1 << 24 | byte2 << 16 | byte3 << 8 | byte4;\n  };\n  var traf = (trackData) => {\n    return box(\"traf\", void 0, [\n      tfhd(trackData),\n      tfdt(trackData),\n      trun(trackData)\n    ]);\n  };\n  var tfhd = (trackData) => {\n    assert(trackData.currentChunk);\n    let tfFlags = 0;\n    tfFlags |= 8;\n    tfFlags |= 16;\n    tfFlags |= 32;\n    tfFlags |= 131072;\n    const referenceSample = trackData.currentChunk.samples[1] ?? trackData.currentChunk.samples[0];\n    const referenceSampleInfo = {\n      duration: referenceSample.timescaleUnitsToNextSample,\n      size: referenceSample.size,\n      flags: fragmentSampleFlags(referenceSample)\n    };\n    return fullBox(\"tfhd\", 0, tfFlags, [\n      u32(trackData.track.id),\n      // Track ID\n      u32(referenceSampleInfo.duration),\n      // Default sample duration\n      u32(referenceSampleInfo.size),\n      // Default sample size\n      u32(referenceSampleInfo.flags)\n      // Default sample flags\n    ]);\n  };\n  var tfdt = (trackData) => {\n    assert(trackData.currentChunk);\n    return fullBox(\"tfdt\", 1, 0, [\n      u64(intoTimescale(trackData.currentChunk.startTimestamp, trackData.timescale))\n      // Base Media Decode Time\n    ]);\n  };\n  var trun = (trackData) => {\n    assert(trackData.currentChunk);\n    const allSampleDurations = trackData.currentChunk.samples.map((x) => x.timescaleUnitsToNextSample);\n    const allSampleSizes = trackData.currentChunk.samples.map((x) => x.size);\n    const allSampleFlags = trackData.currentChunk.samples.map(fragmentSampleFlags);\n    const allSampleCompositionTimeOffsets = trackData.currentChunk.samples.map((x) => intoTimescale(x.timestamp - x.decodeTimestamp, trackData.timescale));\n    const uniqueSampleDurations = new Set(allSampleDurations);\n    const uniqueSampleSizes = new Set(allSampleSizes);\n    const uniqueSampleFlags = new Set(allSampleFlags);\n    const uniqueSampleCompositionTimeOffsets = new Set(allSampleCompositionTimeOffsets);\n    const firstSampleFlagsPresent = uniqueSampleFlags.size === 2 && allSampleFlags[0] !== allSampleFlags[1];\n    const sampleDurationPresent = uniqueSampleDurations.size > 1;\n    const sampleSizePresent = uniqueSampleSizes.size > 1;\n    const sampleFlagsPresent = !firstSampleFlagsPresent && uniqueSampleFlags.size > 1;\n    const sampleCompositionTimeOffsetsPresent = uniqueSampleCompositionTimeOffsets.size > 1 || [...uniqueSampleCompositionTimeOffsets].some((x) => x !== 0);\n    let flags = 0;\n    flags |= 1;\n    flags |= 4 * +firstSampleFlagsPresent;\n    flags |= 256 * +sampleDurationPresent;\n    flags |= 512 * +sampleSizePresent;\n    flags |= 1024 * +sampleFlagsPresent;\n    flags |= 2048 * +sampleCompositionTimeOffsetsPresent;\n    return fullBox(\"trun\", 1, flags, [\n      u32(trackData.currentChunk.samples.length),\n      // Sample count\n      u32(trackData.currentChunk.offset - trackData.currentChunk.moofOffset || 0),\n      // Data offset\n      firstSampleFlagsPresent ? u32(allSampleFlags[0]) : [],\n      trackData.currentChunk.samples.map((_, i) => [\n        sampleDurationPresent ? u32(allSampleDurations[i]) : [],\n        // Sample duration\n        sampleSizePresent ? u32(allSampleSizes[i]) : [],\n        // Sample size\n        sampleFlagsPresent ? u32(allSampleFlags[i]) : [],\n        // Sample flags\n        // Sample composition time offsets\n        sampleCompositionTimeOffsetsPresent ? i32(allSampleCompositionTimeOffsets[i]) : []\n      ])\n    ]);\n  };\n  var mfra = (trackDatas) => {\n    return box(\"mfra\", void 0, [\n      ...trackDatas.map(tfra),\n      mfro()\n    ]);\n  };\n  var tfra = (trackData, trackIndex) => {\n    const version = 1;\n    return fullBox(\"tfra\", version, 0, [\n      u32(trackData.track.id),\n      // Track ID\n      u32(63),\n      // This specifies that traf number, trun number and sample number are 32-bit ints\n      u32(trackData.finalizedChunks.length),\n      // Number of entries\n      trackData.finalizedChunks.map((chunk) => [\n        u64(intoTimescale(chunk.samples[0].timestamp, trackData.timescale)),\n        // Time (in presentation time)\n        u64(chunk.moofOffset),\n        // moof offset\n        u32(trackIndex + 1),\n        // traf number\n        u32(1),\n        // trun number\n        u32(1)\n        // Sample number\n      ])\n    ]);\n  };\n  var mfro = () => {\n    return fullBox(\"mfro\", 0, 0, [\n      // This value needs to be overwritten manually from the outside, where the actual size of the enclosing mfra box\n      // is known\n      u32(0)\n      // Size\n    ]);\n  };\n  var vtte = () => box(\"vtte\");\n  var vttc = (payload, timestamp, identifier, settings, sourceId) => box(\"vttc\", void 0, [\n    sourceId !== null ? box(\"vsid\", [i32(sourceId)]) : null,\n    identifier !== null ? box(\"iden\", [...textEncoder.encode(identifier)]) : null,\n    timestamp !== null ? box(\"ctim\", [...textEncoder.encode(formatSubtitleTimestamp(timestamp))]) : null,\n    settings !== null ? box(\"sttg\", [...textEncoder.encode(settings)]) : null,\n    box(\"payl\", [...textEncoder.encode(payload)])\n  ]);\n  var vtta = (notes) => box(\"vtta\", [...textEncoder.encode(notes)]);\n  var udta = (muxer) => {\n    const boxes = [];\n    const metadataFormat = muxer.format._options.metadataFormat ?? \"auto\";\n    const metadataTags = muxer.output._metadataTags;\n    if (metadataFormat === \"mdir\" || metadataFormat === \"auto\" && !muxer.isQuickTime) {\n      const metaBox = metaMdir(metadataTags);\n      if (metaBox) boxes.push(metaBox);\n    } else if (metadataFormat === \"mdta\") {\n      const metaBox = metaMdta(metadataTags);\n      if (metaBox) boxes.push(metaBox);\n    } else if (metadataFormat === \"udta\" || metadataFormat === \"auto\" && muxer.isQuickTime) {\n      addQuickTimeMetadataTagBoxes(boxes, muxer.output._metadataTags);\n    }\n    if (boxes.length === 0) {\n      return null;\n    }\n    return box(\"udta\", void 0, boxes);\n  };\n  var addQuickTimeMetadataTagBoxes = (boxes, tags) => {\n    for (const { key, value } of keyValueIterator(tags)) {\n      switch (key) {\n        case \"title\":\n          {\n            boxes.push(metadataTagStringBoxShort(\"\\xA9nam\", value));\n          }\n          ;\n          break;\n        case \"description\":\n          {\n            boxes.push(metadataTagStringBoxShort(\"\\xA9des\", value));\n          }\n          ;\n          break;\n        case \"artist\":\n          {\n            boxes.push(metadataTagStringBoxShort(\"\\xA9ART\", value));\n          }\n          ;\n          break;\n        case \"album\":\n          {\n            boxes.push(metadataTagStringBoxShort(\"\\xA9alb\", value));\n          }\n          ;\n          break;\n        case \"albumArtist\":\n          {\n            boxes.push(metadataTagStringBoxShort(\"albr\", value));\n          }\n          ;\n          break;\n        case \"genre\":\n          {\n            boxes.push(metadataTagStringBoxShort(\"\\xA9gen\", value));\n          }\n          ;\n          break;\n        case \"date\":\n          {\n            boxes.push(metadataTagStringBoxShort(\"\\xA9day\", value.toISOString().slice(0, 10)));\n          }\n          ;\n          break;\n        case \"comment\":\n          {\n            boxes.push(metadataTagStringBoxShort(\"\\xA9cmt\", value));\n          }\n          ;\n          break;\n        case \"lyrics\":\n          {\n            boxes.push(metadataTagStringBoxShort(\"\\xA9lyr\", value));\n          }\n          ;\n          break;\n        case \"raw\":\n          {\n          }\n          ;\n          break;\n        case \"discNumber\":\n        case \"discsTotal\":\n        case \"trackNumber\":\n        case \"tracksTotal\":\n        case \"images\":\n          {\n          }\n          ;\n          break;\n        default:\n          assertNever(key);\n      }\n    }\n    if (tags.raw) {\n      for (const key in tags.raw) {\n        const value = tags.raw[key];\n        if (value == null || key.length !== 4 || boxes.some((x) => x.type === key)) {\n          continue;\n        }\n        if (typeof value === \"string\") {\n          boxes.push(metadataTagStringBoxShort(key, value));\n        } else if (value instanceof Uint8Array) {\n          boxes.push(box(key, Array.from(value)));\n        }\n      }\n    }\n  };\n  var metadataTagStringBoxShort = (name, value) => {\n    const encoded = textEncoder.encode(value);\n    return box(name, [\n      u16(encoded.length),\n      u16(getLanguageCodeInt(\"und\")),\n      Array.from(encoded)\n    ]);\n  };\n  var DATA_BOX_MIME_TYPE_MAP = {\n    \"image/jpeg\": 13,\n    \"image/png\": 14,\n    \"image/bmp\": 27\n  };\n  var generateMetadataPairs = (tags, isMdta) => {\n    const pairs = [];\n    for (const { key, value } of keyValueIterator(tags)) {\n      switch (key) {\n        case \"title\":\n          {\n            pairs.push({ key: isMdta ? \"title\" : \"\\xA9nam\", value: dataStringBoxLong(value) });\n          }\n          ;\n          break;\n        case \"description\":\n          {\n            pairs.push({ key: isMdta ? \"description\" : \"\\xA9des\", value: dataStringBoxLong(value) });\n          }\n          ;\n          break;\n        case \"artist\":\n          {\n            pairs.push({ key: isMdta ? \"artist\" : \"\\xA9ART\", value: dataStringBoxLong(value) });\n          }\n          ;\n          break;\n        case \"album\":\n          {\n            pairs.push({ key: isMdta ? \"album\" : \"\\xA9alb\", value: dataStringBoxLong(value) });\n          }\n          ;\n          break;\n        case \"albumArtist\":\n          {\n            pairs.push({ key: isMdta ? \"album_artist\" : \"aART\", value: dataStringBoxLong(value) });\n          }\n          ;\n          break;\n        case \"comment\":\n          {\n            pairs.push({ key: isMdta ? \"comment\" : \"\\xA9cmt\", value: dataStringBoxLong(value) });\n          }\n          ;\n          break;\n        case \"genre\":\n          {\n            pairs.push({ key: isMdta ? \"genre\" : \"\\xA9gen\", value: dataStringBoxLong(value) });\n          }\n          ;\n          break;\n        case \"lyrics\":\n          {\n            pairs.push({ key: isMdta ? \"lyrics\" : \"\\xA9lyr\", value: dataStringBoxLong(value) });\n          }\n          ;\n          break;\n        case \"date\":\n          {\n            pairs.push({\n              key: isMdta ? \"date\" : \"\\xA9day\",\n              value: dataStringBoxLong(value.toISOString().slice(0, 10))\n            });\n          }\n          ;\n          break;\n        case \"images\":\n          {\n            for (const image of value) {\n              if (image.kind !== \"coverFront\") {\n                continue;\n              }\n              pairs.push({ key: \"covr\", value: box(\"data\", [\n                u32(DATA_BOX_MIME_TYPE_MAP[image.mimeType] ?? 0),\n                // Type indicator\n                u32(0),\n                // Locale indicator\n                Array.from(image.data)\n                // Kinda slow, hopefully temp\n              ]) });\n            }\n          }\n          ;\n          break;\n        case \"trackNumber\":\n          {\n            if (isMdta) {\n              const string = tags.tracksTotal !== void 0 ? `${value}/${tags.tracksTotal}` : value.toString();\n              pairs.push({ key: \"track\", value: dataStringBoxLong(string) });\n            } else {\n              pairs.push({ key: \"trkn\", value: box(\"data\", [\n                u32(0),\n                // 8 bytes empty\n                u32(0),\n                u16(0),\n                // Empty\n                u16(value),\n                u16(tags.tracksTotal ?? 0),\n                u16(0)\n                // Empty\n              ]) });\n            }\n          }\n          ;\n          break;\n        case \"discNumber\":\n          {\n            if (!isMdta) {\n              pairs.push({ key: \"disc\", value: box(\"data\", [\n                u32(0),\n                // 8 bytes empty\n                u32(0),\n                u16(0),\n                // Empty\n                u16(value),\n                u16(tags.discsTotal ?? 0),\n                u16(0)\n                // Empty\n              ]) });\n            }\n          }\n          ;\n          break;\n        case \"tracksTotal\":\n        case \"discsTotal\":\n          {\n          }\n          ;\n          break;\n        case \"raw\":\n          {\n          }\n          ;\n          break;\n        default:\n          assertNever(key);\n      }\n    }\n    if (tags.raw) {\n      for (const key in tags.raw) {\n        const value = tags.raw[key];\n        if (value == null || !isMdta && key.length !== 4 || pairs.some((x) => x.key === key)) {\n          continue;\n        }\n        if (typeof value === \"string\") {\n          pairs.push({ key, value: dataStringBoxLong(value) });\n        } else if (value instanceof Uint8Array) {\n          pairs.push({ key, value: box(\"data\", [\n            u32(0),\n            // Type indicator\n            u32(0),\n            // Locale indicator\n            Array.from(value)\n          ]) });\n        } else if (value instanceof RichImageData) {\n          pairs.push({ key, value: box(\"data\", [\n            u32(DATA_BOX_MIME_TYPE_MAP[value.mimeType] ?? 0),\n            // Type indicator\n            u32(0),\n            // Locale indicator\n            Array.from(value.data)\n            // Kinda slow, hopefully temp\n          ]) });\n        }\n      }\n    }\n    return pairs;\n  };\n  var metaMdir = (tags) => {\n    const pairs = generateMetadataPairs(tags, false);\n    if (pairs.length === 0) {\n      return null;\n    }\n    return fullBox(\"meta\", 0, 0, void 0, [\n      hdlr(false, \"mdir\", \"\", \"appl\"),\n      // mdir handler\n      box(\"ilst\", void 0, pairs.map((pair) => box(pair.key, void 0, [pair.value])))\n      // Item list without keys box\n    ]);\n  };\n  var metaMdta = (tags) => {\n    const pairs = generateMetadataPairs(tags, true);\n    if (pairs.length === 0) {\n      return null;\n    }\n    return box(\"meta\", void 0, [\n      hdlr(false, \"mdta\", \"\"),\n      // mdta handler\n      fullBox(\"keys\", 0, 0, [\n        u32(pairs.length)\n      ], pairs.map((pair) => box(\"mdta\", [\n        // Hacky since these aren't boxes technically, but if not box why box-shaped?\n        ...textEncoder.encode(pair.key)\n      ]))),\n      box(\"ilst\", void 0, pairs.map((pair, i) => {\n        const boxName = String.fromCharCode(...u32(i + 1));\n        return box(boxName, void 0, [pair.value]);\n      }))\n    ]);\n  };\n  var dataStringBoxLong = (value) => {\n    return box(\"data\", [\n      u32(1),\n      // Type indicator (UTF-8)\n      u32(0),\n      // Locale indicator\n      ...textEncoder.encode(value)\n    ]);\n  };\n  var videoCodecToBoxName = (codec, fullCodecString) => {\n    switch (codec) {\n      case \"avc\":\n        return fullCodecString.startsWith(\"avc3\") ? \"avc3\" : \"avc1\";\n      case \"hevc\":\n        return \"hvc1\";\n      case \"vp8\":\n        return \"vp08\";\n      case \"vp9\":\n        return \"vp09\";\n      case \"av1\":\n        return \"av01\";\n    }\n  };\n  var VIDEO_CODEC_TO_CONFIGURATION_BOX = {\n    avc: avcC,\n    hevc: hvcC,\n    vp8: vpcC,\n    vp9: vpcC,\n    av1: av1C\n  };\n  var audioCodecToBoxName = (codec, isQuickTime) => {\n    switch (codec) {\n      case \"aac\":\n        return \"mp4a\";\n      case \"mp3\":\n        return \"mp4a\";\n      case \"opus\":\n        return \"Opus\";\n      case \"vorbis\":\n        return \"mp4a\";\n      case \"flac\":\n        return \"fLaC\";\n      case \"ulaw\":\n        return \"ulaw\";\n      case \"alaw\":\n        return \"alaw\";\n      case \"pcm-u8\":\n        return \"raw \";\n      case \"pcm-s8\":\n        return \"sowt\";\n    }\n    if (isQuickTime) {\n      switch (codec) {\n        case \"pcm-s16\":\n          return \"sowt\";\n        case \"pcm-s16be\":\n          return \"twos\";\n        case \"pcm-s24\":\n          return \"in24\";\n        case \"pcm-s24be\":\n          return \"in24\";\n        case \"pcm-s32\":\n          return \"in32\";\n        case \"pcm-s32be\":\n          return \"in32\";\n        case \"pcm-f32\":\n          return \"fl32\";\n        case \"pcm-f32be\":\n          return \"fl32\";\n        case \"pcm-f64\":\n          return \"fl64\";\n        case \"pcm-f64be\":\n          return \"fl64\";\n      }\n    } else {\n      switch (codec) {\n        case \"pcm-s16\":\n          return \"ipcm\";\n        case \"pcm-s16be\":\n          return \"ipcm\";\n        case \"pcm-s24\":\n          return \"ipcm\";\n        case \"pcm-s24be\":\n          return \"ipcm\";\n        case \"pcm-s32\":\n          return \"ipcm\";\n        case \"pcm-s32be\":\n          return \"ipcm\";\n        case \"pcm-f32\":\n          return \"fpcm\";\n        case \"pcm-f32be\":\n          return \"fpcm\";\n        case \"pcm-f64\":\n          return \"fpcm\";\n        case \"pcm-f64be\":\n          return \"fpcm\";\n      }\n    }\n  };\n  var audioCodecToConfigurationBox = (codec, isQuickTime) => {\n    switch (codec) {\n      case \"aac\":\n        return esds;\n      case \"mp3\":\n        return esds;\n      case \"opus\":\n        return dOps;\n      case \"vorbis\":\n        return esds;\n      case \"flac\":\n        return dfLa;\n    }\n    if (isQuickTime) {\n      switch (codec) {\n        case \"pcm-s24\":\n          return wave;\n        case \"pcm-s24be\":\n          return wave;\n        case \"pcm-s32\":\n          return wave;\n        case \"pcm-s32be\":\n          return wave;\n        case \"pcm-f32\":\n          return wave;\n        case \"pcm-f32be\":\n          return wave;\n        case \"pcm-f64\":\n          return wave;\n        case \"pcm-f64be\":\n          return wave;\n      }\n    } else {\n      switch (codec) {\n        case \"pcm-s16\":\n          return pcmC;\n        case \"pcm-s16be\":\n          return pcmC;\n        case \"pcm-s24\":\n          return pcmC;\n        case \"pcm-s24be\":\n          return pcmC;\n        case \"pcm-s32\":\n          return pcmC;\n        case \"pcm-s32be\":\n          return pcmC;\n        case \"pcm-f32\":\n          return pcmC;\n        case \"pcm-f32be\":\n          return pcmC;\n        case \"pcm-f64\":\n          return pcmC;\n        case \"pcm-f64be\":\n          return pcmC;\n      }\n    }\n    return null;\n  };\n  var SUBTITLE_CODEC_TO_BOX_NAME = {\n    webvtt: \"wvtt\"\n  };\n  var SUBTITLE_CODEC_TO_CONFIGURATION_BOX = {\n    webvtt: vttC\n  };\n  var getLanguageCodeInt = (code) => {\n    assert(code.length === 3);\n    ;\n    let language = 0;\n    for (let i = 0; i < 3; i++) {\n      language <<= 5;\n      language += code.charCodeAt(i) - 96;\n    }\n    return language;\n  };\n\n  // src/writer.ts\n  var Writer = class {\n    constructor() {\n      /** Setting this to true will cause the writer to ensure data is written in a strictly monotonic, streamable way. */\n      this.ensureMonotonicity = false;\n      this.trackedWrites = null;\n      this.trackedStart = -1;\n      this.trackedEnd = -1;\n    }\n    start() {\n    }\n    maybeTrackWrites(data) {\n      if (!this.trackedWrites) {\n        return;\n      }\n      let pos = this.getPos();\n      if (pos < this.trackedStart) {\n        if (pos + data.byteLength <= this.trackedStart) {\n          return;\n        }\n        data = data.subarray(this.trackedStart - pos);\n        pos = 0;\n      }\n      const neededSize = pos + data.byteLength - this.trackedStart;\n      let newLength = this.trackedWrites.byteLength;\n      while (newLength < neededSize) {\n        newLength *= 2;\n      }\n      if (newLength !== this.trackedWrites.byteLength) {\n        const copy = new Uint8Array(newLength);\n        copy.set(this.trackedWrites, 0);\n        this.trackedWrites = copy;\n      }\n      this.trackedWrites.set(data, pos - this.trackedStart);\n      this.trackedEnd = Math.max(this.trackedEnd, pos + data.byteLength);\n    }\n    startTrackingWrites() {\n      this.trackedWrites = new Uint8Array(2 ** 10);\n      this.trackedStart = this.getPos();\n      this.trackedEnd = this.trackedStart;\n    }\n    stopTrackingWrites() {\n      if (!this.trackedWrites) {\n        throw new Error(\"Internal error: Can't get tracked writes since nothing was tracked.\");\n      }\n      const slice = this.trackedWrites.subarray(0, this.trackedEnd - this.trackedStart);\n      const result = {\n        data: slice,\n        start: this.trackedStart,\n        end: this.trackedEnd\n      };\n      this.trackedWrites = null;\n      return result;\n    }\n  };\n  var ARRAY_BUFFER_INITIAL_SIZE = 2 ** 16;\n  var ARRAY_BUFFER_MAX_SIZE = 2 ** 32;\n  var BufferTargetWriter = class extends Writer {\n    constructor(target) {\n      super();\n      this.pos = 0;\n      this.maxPos = 0;\n      this.target = target;\n      this.supportsResize = \"resize\" in new ArrayBuffer(0);\n      if (this.supportsResize) {\n        try {\n          this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE, { maxByteLength: ARRAY_BUFFER_MAX_SIZE });\n        } catch {\n          this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE);\n          this.supportsResize = false;\n        }\n      } else {\n        this.buffer = new ArrayBuffer(ARRAY_BUFFER_INITIAL_SIZE);\n      }\n      this.bytes = new Uint8Array(this.buffer);\n    }\n    ensureSize(size) {\n      let newLength = this.buffer.byteLength;\n      while (newLength < size) newLength *= 2;\n      if (newLength === this.buffer.byteLength) return;\n      if (newLength > ARRAY_BUFFER_MAX_SIZE) {\n        throw new Error(\n          `ArrayBuffer exceeded maximum size of ${ARRAY_BUFFER_MAX_SIZE} bytes. Please consider using another target.`\n        );\n      }\n      if (this.supportsResize) {\n        this.buffer.resize(newLength);\n      } else {\n        const newBuffer = new ArrayBuffer(newLength);\n        const newBytes = new Uint8Array(newBuffer);\n        newBytes.set(this.bytes, 0);\n        this.buffer = newBuffer;\n        this.bytes = newBytes;\n      }\n    }\n    write(data) {\n      this.maybeTrackWrites(data);\n      this.ensureSize(this.pos + data.byteLength);\n      this.bytes.set(data, this.pos);\n      this.target.onwrite?.(this.pos, this.pos + data.byteLength);\n      this.pos += data.byteLength;\n      this.maxPos = Math.max(this.maxPos, this.pos);\n    }\n    seek(newPos) {\n      this.pos = newPos;\n    }\n    getPos() {\n      return this.pos;\n    }\n    async flush() {\n    }\n    async finalize() {\n      this.ensureSize(this.pos);\n      this.target.buffer = this.buffer.slice(0, Math.max(this.maxPos, this.pos));\n    }\n    async close() {\n    }\n    getSlice(start, end) {\n      return this.bytes.slice(start, end);\n    }\n  };\n  var DEFAULT_CHUNK_SIZE = 2 ** 24;\n  var MAX_CHUNKS_AT_ONCE = 2;\n  var StreamTargetWriter = class extends Writer {\n    constructor(target) {\n      super();\n      this.pos = 0;\n      this.sections = [];\n      this.lastWriteEnd = 0;\n      this.lastFlushEnd = 0;\n      this.writer = null;\n      /**\n       * The data is divided up into fixed-size chunks, whose contents are first filled in RAM and then flushed out.\n       * A chunk is flushed if all of its contents have been written.\n       */\n      this.chunks = [];\n      this.target = target;\n      this.chunked = target._options.chunked ?? false;\n      this.chunkSize = target._options.chunkSize ?? DEFAULT_CHUNK_SIZE;\n    }\n    start() {\n      this.writer = this.target._writable.getWriter();\n    }\n    write(data) {\n      if (this.pos > this.lastWriteEnd) {\n        const paddingBytesNeeded = this.pos - this.lastWriteEnd;\n        this.pos = this.lastWriteEnd;\n        this.write(new Uint8Array(paddingBytesNeeded));\n      }\n      this.maybeTrackWrites(data);\n      this.sections.push({\n        data: data.slice(),\n        start: this.pos\n      });\n      this.target.onwrite?.(this.pos, this.pos + data.byteLength);\n      this.pos += data.byteLength;\n      this.lastWriteEnd = Math.max(this.lastWriteEnd, this.pos);\n    }\n    seek(newPos) {\n      this.pos = newPos;\n    }\n    getPos() {\n      return this.pos;\n    }\n    async flush() {\n      if (this.pos > this.lastWriteEnd) {\n        const paddingBytesNeeded = this.pos - this.lastWriteEnd;\n        this.pos = this.lastWriteEnd;\n        this.write(new Uint8Array(paddingBytesNeeded));\n      }\n      assert(this.writer);\n      if (this.sections.length === 0) return;\n      const chunks = [];\n      const sorted = [...this.sections].sort((a, b) => a.start - b.start);\n      chunks.push({\n        start: sorted[0].start,\n        size: sorted[0].data.byteLength\n      });\n      for (let i = 1; i < sorted.length; i++) {\n        const lastChunk = chunks[chunks.length - 1];\n        const section = sorted[i];\n        if (section.start <= lastChunk.start + lastChunk.size) {\n          lastChunk.size = Math.max(lastChunk.size, section.start + section.data.byteLength - lastChunk.start);\n        } else {\n          chunks.push({\n            start: section.start,\n            size: section.data.byteLength\n          });\n        }\n      }\n      for (const chunk of chunks) {\n        chunk.data = new Uint8Array(chunk.size);\n        for (const section of this.sections) {\n          if (chunk.start <= section.start && section.start < chunk.start + chunk.size) {\n            chunk.data.set(section.data, section.start - chunk.start);\n          }\n        }\n        if (this.writer.desiredSize !== null && this.writer.desiredSize <= 0) {\n          await this.writer.ready;\n        }\n        if (this.chunked) {\n          this.writeDataIntoChunks(chunk.data, chunk.start);\n          this.tryToFlushChunks();\n        } else {\n          if (this.ensureMonotonicity && chunk.start !== this.lastFlushEnd) {\n            throw new Error(\"Internal error: Monotonicity violation.\");\n          }\n          void this.writer.write({\n            type: \"write\",\n            data: chunk.data,\n            position: chunk.start\n          });\n          this.lastFlushEnd = chunk.start + chunk.data.byteLength;\n        }\n      }\n      this.sections.length = 0;\n    }\n    writeDataIntoChunks(data, position) {\n      let chunkIndex = this.chunks.findIndex((x) => x.start <= position && position < x.start + this.chunkSize);\n      if (chunkIndex === -1) chunkIndex = this.createChunk(position);\n      const chunk = this.chunks[chunkIndex];\n      const relativePosition = position - chunk.start;\n      const toWrite = data.subarray(0, Math.min(this.chunkSize - relativePosition, data.byteLength));\n      chunk.data.set(toWrite, relativePosition);\n      const section = {\n        start: relativePosition,\n        end: relativePosition + toWrite.byteLength\n      };\n      this.insertSectionIntoChunk(chunk, section);\n      if (chunk.written[0].start === 0 && chunk.written[0].end === this.chunkSize) {\n        chunk.shouldFlush = true;\n      }\n      if (this.chunks.length > MAX_CHUNKS_AT_ONCE) {\n        for (let i = 0; i < this.chunks.length - 1; i++) {\n          this.chunks[i].shouldFlush = true;\n        }\n        this.tryToFlushChunks();\n      }\n      if (toWrite.byteLength < data.byteLength) {\n        this.writeDataIntoChunks(data.subarray(toWrite.byteLength), position + toWrite.byteLength);\n      }\n    }\n    insertSectionIntoChunk(chunk, section) {\n      let low = 0;\n      let high = chunk.written.length - 1;\n      let index = -1;\n      while (low <= high) {\n        const mid = Math.floor(low + (high - low + 1) / 2);\n        if (chunk.written[mid].start <= section.start) {\n          low = mid + 1;\n          index = mid;\n        } else {\n          high = mid - 1;\n        }\n      }\n      chunk.written.splice(index + 1, 0, section);\n      if (index === -1 || chunk.written[index].end < section.start) index++;\n      while (index < chunk.written.length - 1 && chunk.written[index].end >= chunk.written[index + 1].start) {\n        chunk.written[index].end = Math.max(chunk.written[index].end, chunk.written[index + 1].end);\n        chunk.written.splice(index + 1, 1);\n      }\n    }\n    createChunk(includesPosition) {\n      const start = Math.floor(includesPosition / this.chunkSize) * this.chunkSize;\n      const chunk = {\n        start,\n        data: new Uint8Array(this.chunkSize),\n        written: [],\n        shouldFlush: false\n      };\n      this.chunks.push(chunk);\n      this.chunks.sort((a, b) => a.start - b.start);\n      return this.chunks.indexOf(chunk);\n    }\n    tryToFlushChunks(force = false) {\n      assert(this.writer);\n      for (let i = 0; i < this.chunks.length; i++) {\n        const chunk = this.chunks[i];\n        if (!chunk.shouldFlush && !force) continue;\n        for (const section of chunk.written) {\n          const position = chunk.start + section.start;\n          if (this.ensureMonotonicity && position !== this.lastFlushEnd) {\n            throw new Error(\"Internal error: Monotonicity violation.\");\n          }\n          void this.writer.write({\n            type: \"write\",\n            data: chunk.data.subarray(section.start, section.end),\n            position\n          });\n          this.lastFlushEnd = chunk.start + section.end;\n        }\n        this.chunks.splice(i--, 1);\n      }\n    }\n    finalize() {\n      if (this.chunked) {\n        this.tryToFlushChunks(true);\n      }\n      assert(this.writer);\n      return this.writer.close();\n    }\n    async close() {\n      return this.writer?.close();\n    }\n  };\n  var NullTargetWriter = class extends Writer {\n    constructor(target) {\n      super();\n      this.target = target;\n      this.pos = 0;\n    }\n    write(data) {\n      this.maybeTrackWrites(data);\n      this.target.onwrite?.(this.pos, this.pos + data.byteLength);\n      this.pos += data.byteLength;\n    }\n    getPos() {\n      return this.pos;\n    }\n    seek(newPos) {\n      this.pos = newPos;\n    }\n    async flush() {\n    }\n    async finalize() {\n    }\n    async close() {\n    }\n  };\n\n  // src/target.ts\n  var nodeAlias2 = __toESM(require_node(), 1);\n  var node2 = typeof nodeAlias2 !== \"undefined\" ? nodeAlias2 : void 0;\n  var Target = class {\n    constructor() {\n      /** @internal */\n      this._output = null;\n      /**\n       * Called each time data is written to the target. Will be called with the byte range into which data was written.\n       *\n       * Use this callback to track the size of the output file as it grows. But be warned, this function is chatty and\n       * gets called *extremely* often.\n       */\n      this.onwrite = null;\n    }\n  };\n  var BufferTarget = class extends Target {\n    constructor() {\n      super(...arguments);\n      /** Stores the final output buffer. Until the output is finalized, this will be `null`. */\n      this.buffer = null;\n    }\n    /** @internal */\n    _createWriter() {\n      return new BufferTargetWriter(this);\n    }\n  };\n  var StreamTarget = class extends Target {\n    /** Creates a new {@link StreamTarget} which writes to the specified `writable`. */\n    constructor(writable, options = {}) {\n      super();\n      if (!(writable instanceof WritableStream)) {\n        throw new TypeError(\"StreamTarget requires a WritableStream instance.\");\n      }\n      if (options != null && typeof options !== \"object\") {\n        throw new TypeError(\"StreamTarget options, when provided, must be an object.\");\n      }\n      if (options.chunked !== void 0 && typeof options.chunked !== \"boolean\") {\n        throw new TypeError(\"options.chunked, when provided, must be a boolean.\");\n      }\n      if (options.chunkSize !== void 0 && (!Number.isInteger(options.chunkSize) || options.chunkSize < 1024)) {\n        throw new TypeError(\"options.chunkSize, when provided, must be an integer and not smaller than 1024.\");\n      }\n      this._writable = writable;\n      this._options = options;\n    }\n    /** @internal */\n    _createWriter() {\n      return new StreamTargetWriter(this);\n    }\n  };\n  var FilePathTarget = class extends Target {\n    /** Creates a new {@link FilePathTarget} that writes to the file at the specified file path. */\n    constructor(filePath, options = {}) {\n      if (typeof filePath !== \"string\") {\n        throw new TypeError(\"filePath must be a string.\");\n      }\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      super();\n      /** @internal */\n      this._fileHandle = null;\n      const writable = new WritableStream({\n        start: async () => {\n          this._fileHandle = await node2.fs.open(filePath, \"w\");\n        },\n        write: async (chunk) => {\n          assert(this._fileHandle);\n          await this._fileHandle.write(chunk.data, 0, chunk.data.byteLength, chunk.position);\n        },\n        close: async () => {\n          if (this._fileHandle) {\n            await this._fileHandle.close();\n            this._fileHandle = null;\n          }\n        }\n      });\n      this._streamTarget = new StreamTarget(writable, {\n        chunked: true,\n        ...options\n      });\n      this._streamTarget._output = this._output;\n    }\n    /** @internal */\n    _createWriter() {\n      return this._streamTarget._createWriter();\n    }\n  };\n  var NullTarget = class extends Target {\n    /** @internal */\n    _createWriter() {\n      return new NullTargetWriter(this);\n    }\n  };\n\n  // src/isobmff/isobmff-muxer.ts\n  var GLOBAL_TIMESCALE = 1e3;\n  var TIMESTAMP_OFFSET = 2082844800;\n  var getTrackMetadata = (trackData) => {\n    const metadata = {};\n    const track = trackData.track;\n    if (track.metadata.name !== void 0) {\n      metadata.name = track.metadata.name;\n    }\n    return metadata;\n  };\n  var intoTimescale = (timeInSeconds, timescale, round = true) => {\n    const value = timeInSeconds * timescale;\n    return round ? Math.round(value) : value;\n  };\n  var IsobmffMuxer2 = class extends Muxer {\n    constructor(output, format) {\n      super(output);\n      this.auxTarget = new BufferTarget();\n      this.auxWriter = this.auxTarget._createWriter();\n      this.auxBoxWriter = new IsobmffBoxWriter(this.auxWriter);\n      this.mdat = null;\n      this.ftypSize = null;\n      this.trackDatas = [];\n      this.allTracksKnown = promiseWithResolvers();\n      this.creationTime = Math.floor(Date.now() / 1e3) + TIMESTAMP_OFFSET;\n      this.finalizedChunks = [];\n      this.nextFragmentNumber = 1;\n      // Only relevant for fragmented files, to make sure new fragments start with the highest timestamp seen so far\n      this.maxWrittenTimestamp = -Infinity;\n      this.format = format;\n      this.writer = output._writer;\n      this.boxWriter = new IsobmffBoxWriter(this.writer);\n      this.isQuickTime = format instanceof MovOutputFormat;\n      const fastStartDefault = this.writer instanceof BufferTargetWriter ? \"in-memory\" : false;\n      this.fastStart = format._options.fastStart ?? fastStartDefault;\n      this.isFragmented = this.fastStart === \"fragmented\";\n      if (this.fastStart === \"in-memory\" || this.isFragmented) {\n        this.writer.ensureMonotonicity = true;\n      }\n      this.minimumFragmentDuration = format._options.minimumFragmentDuration ?? 1;\n    }\n    async start() {\n      const release = await this.mutex.acquire();\n      const holdsAvc = this.output._tracks.some((x) => x.type === \"video\" && x.source._codec === \"avc\");\n      {\n        if (this.format._options.onFtyp) {\n          this.writer.startTrackingWrites();\n        }\n        this.boxWriter.writeBox(ftyp({\n          isQuickTime: this.isQuickTime,\n          holdsAvc,\n          fragmented: this.isFragmented\n        }));\n        if (this.format._options.onFtyp) {\n          const { data, start } = this.writer.stopTrackingWrites();\n          this.format._options.onFtyp(data, start);\n        }\n      }\n      this.ftypSize = this.writer.getPos();\n      if (this.fastStart === \"in-memory\") {\n      } else if (this.fastStart === \"reserve\") {\n        for (const track of this.output._tracks) {\n          if (track.metadata.maximumPacketCount === void 0) {\n            throw new Error(\n              \"All tracks must specify maximumPacketCount in their metadata when using fastStart: 'reserve'.\"\n            );\n          }\n        }\n      } else if (this.isFragmented) {\n      } else {\n        if (this.format._options.onMdat) {\n          this.writer.startTrackingWrites();\n        }\n        this.mdat = mdat(true);\n        this.boxWriter.writeBox(this.mdat);\n      }\n      await this.writer.flush();\n      release();\n    }\n    allTracksAreKnown() {\n      for (const track of this.output._tracks) {\n        if (!track.source._closed && !this.trackDatas.some((x) => x.track === track)) {\n          return false;\n        }\n      }\n      return true;\n    }\n    async getMimeType() {\n      await this.allTracksKnown.promise;\n      const codecStrings = this.trackDatas.map((trackData) => {\n        if (trackData.type === \"video\") {\n          return trackData.info.decoderConfig.codec;\n        } else if (trackData.type === \"audio\") {\n          return trackData.info.decoderConfig.codec;\n        } else {\n          const map = {\n            webvtt: \"wvtt\"\n          };\n          return map[trackData.track.source._codec];\n        }\n      });\n      return buildIsobmffMimeType({\n        isQuickTime: this.isQuickTime,\n        hasVideo: this.trackDatas.some((x) => x.type === \"video\"),\n        hasAudio: this.trackDatas.some((x) => x.type === \"audio\"),\n        codecStrings\n      });\n    }\n    getVideoTrackData(track, packet, meta) {\n      const existingTrackData = this.trackDatas.find((x) => x.track === track);\n      if (existingTrackData) {\n        return existingTrackData;\n      }\n      validateVideoChunkMetadata(meta);\n      assert(meta);\n      assert(meta.decoderConfig);\n      const decoderConfig = { ...meta.decoderConfig };\n      assert(decoderConfig.codedWidth !== void 0);\n      assert(decoderConfig.codedHeight !== void 0);\n      let requiresAnnexBTransformation = false;\n      if (track.source._codec === \"avc\" && !decoderConfig.description) {\n        const decoderConfigurationRecord = extractAvcDecoderConfigurationRecord(packet.data);\n        if (!decoderConfigurationRecord) {\n          throw new Error(\n            \"Couldn't extract an AVCDecoderConfigurationRecord from the AVC packet. Make sure the packets are in Annex B format (as specified in ITU-T-REC-H.264) when not providing a description, or provide a description (must be an AVCDecoderConfigurationRecord as specified in ISO 14496-15) and ensure the packets are in AVCC format.\"\n          );\n        }\n        decoderConfig.description = serializeAvcDecoderConfigurationRecord(decoderConfigurationRecord);\n        requiresAnnexBTransformation = true;\n      } else if (track.source._codec === \"hevc\" && !decoderConfig.description) {\n        const decoderConfigurationRecord = extractHevcDecoderConfigurationRecord(packet.data);\n        if (!decoderConfigurationRecord) {\n          throw new Error(\n            \"Couldn't extract an HEVCDecoderConfigurationRecord from the HEVC packet. Make sure the packets are in Annex B format (as specified in ITU-T-REC-H.265) when not providing a description, or provide a description (must be an HEVCDecoderConfigurationRecord as specified in ISO 14496-15) and ensure the packets are in HEVC format.\"\n          );\n        }\n        decoderConfig.description = serializeHevcDecoderConfigurationRecord(decoderConfigurationRecord);\n        requiresAnnexBTransformation = true;\n      }\n      const timescale = computeRationalApproximation(1 / (track.metadata.frameRate ?? 57600), 1e6).denominator;\n      const newTrackData = {\n        muxer: this,\n        track,\n        type: \"video\",\n        info: {\n          width: decoderConfig.codedWidth,\n          height: decoderConfig.codedHeight,\n          decoderConfig,\n          requiresAnnexBTransformation\n        },\n        timescale,\n        samples: [],\n        sampleQueue: [],\n        timestampProcessingQueue: [],\n        timeToSampleTable: [],\n        compositionTimeOffsetTable: [],\n        lastTimescaleUnits: null,\n        lastSample: null,\n        finalizedChunks: [],\n        currentChunk: null,\n        compactlyCodedChunkTable: []\n      };\n      this.trackDatas.push(newTrackData);\n      this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      return newTrackData;\n    }\n    getAudioTrackData(track, packet, meta) {\n      const existingTrackData = this.trackDatas.find((x) => x.track === track);\n      if (existingTrackData) {\n        return existingTrackData;\n      }\n      validateAudioChunkMetadata(meta);\n      assert(meta);\n      assert(meta.decoderConfig);\n      const decoderConfig = { ...meta.decoderConfig };\n      let requiresAdtsStripping = false;\n      if (track.source._codec === \"aac\" && !decoderConfig.description) {\n        const adtsFrame = readAdtsFrameHeader(FileSlice4.tempFromBytes(packet.data));\n        if (!adtsFrame) {\n          throw new Error(\n            \"Couldn't parse ADTS header from the AAC packet. Make sure the packets are in ADTS format (as specified in ISO 13818-7) when not providing a description, or provide a description (must be an AudioSpecificConfig as specified in ISO 14496-3) and ensure the packets are raw AAC data.\"\n          );\n        }\n        const sampleRate = aacFrequencyTable[adtsFrame.samplingFrequencyIndex];\n        const numberOfChannels = aacChannelMap[adtsFrame.channelConfiguration];\n        if (sampleRate === void 0 || numberOfChannels === void 0) {\n          throw new Error(\"Invalid ADTS frame header.\");\n        }\n        decoderConfig.description = buildAacAudioSpecificConfig({\n          objectType: adtsFrame.objectType,\n          sampleRate,\n          numberOfChannels\n        });\n        requiresAdtsStripping = true;\n      }\n      const newTrackData = {\n        muxer: this,\n        track,\n        type: \"audio\",\n        info: {\n          numberOfChannels: meta.decoderConfig.numberOfChannels,\n          sampleRate: meta.decoderConfig.sampleRate,\n          decoderConfig,\n          requiresPcmTransformation: !this.isFragmented && PCM_AUDIO_CODECS.includes(track.source._codec),\n          requiresAdtsStripping\n        },\n        timescale: meta.decoderConfig.sampleRate,\n        samples: [],\n        sampleQueue: [],\n        timestampProcessingQueue: [],\n        timeToSampleTable: [],\n        compositionTimeOffsetTable: [],\n        lastTimescaleUnits: null,\n        lastSample: null,\n        finalizedChunks: [],\n        currentChunk: null,\n        compactlyCodedChunkTable: []\n      };\n      this.trackDatas.push(newTrackData);\n      this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      return newTrackData;\n    }\n    getSubtitleTrackData(track, meta) {\n      const existingTrackData = this.trackDatas.find((x) => x.track === track);\n      if (existingTrackData) {\n        return existingTrackData;\n      }\n      validateSubtitleMetadata(meta);\n      assert(meta);\n      assert(meta.config);\n      const newTrackData = {\n        muxer: this,\n        track,\n        type: \"subtitle\",\n        info: {\n          config: meta.config\n        },\n        timescale: 1e3,\n        // Reasonable\n        samples: [],\n        sampleQueue: [],\n        timestampProcessingQueue: [],\n        timeToSampleTable: [],\n        compositionTimeOffsetTable: [],\n        lastTimescaleUnits: null,\n        lastSample: null,\n        finalizedChunks: [],\n        currentChunk: null,\n        compactlyCodedChunkTable: [],\n        lastCueEndTimestamp: 0,\n        cueQueue: [],\n        nextSourceId: 0,\n        cueToSourceId: /* @__PURE__ */ new WeakMap()\n      };\n      this.trackDatas.push(newTrackData);\n      this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      return newTrackData;\n    }\n    async addEncodedVideoPacket(track, packet, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        const trackData = this.getVideoTrackData(track, packet, meta);\n        let packetData = packet.data;\n        if (trackData.info.requiresAnnexBTransformation) {\n          const nalUnits = [...iterateNalUnitsInAnnexB(packetData)].map((loc) => packetData.subarray(loc.offset, loc.offset + loc.length));\n          if (nalUnits.length === 0) {\n            throw new Error(\n              \"Failed to transform packet data. Make sure all packets are provided in Annex B format, as specified in ITU-T-REC-H.264 and ITU-T-REC-H.265.\"\n            );\n          }\n          packetData = concatNalUnitsInLengthPrefixed(nalUnits, 4);\n        }\n        const timestamp = this.validateAndNormalizeTimestamp(\n          trackData.track,\n          packet.timestamp,\n          packet.type === \"key\"\n        );\n        const internalSample = this.createSampleForTrack(\n          trackData,\n          packetData,\n          timestamp,\n          packet.duration,\n          packet.type\n        );\n        await this.registerSample(trackData, internalSample);\n      } finally {\n        release();\n      }\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        const trackData = this.getAudioTrackData(track, packet, meta);\n        let packetData = packet.data;\n        if (trackData.info.requiresAdtsStripping) {\n          const adtsFrame = readAdtsFrameHeader(FileSlice4.tempFromBytes(packetData));\n          if (!adtsFrame) {\n            throw new Error(\"Expected ADTS frame, didn't get one.\");\n          }\n          const headerLength = adtsFrame.crcCheck === null ? MIN_ADTS_FRAME_HEADER_SIZE : MAX_ADTS_FRAME_HEADER_SIZE;\n          packetData = packetData.subarray(headerLength);\n        }\n        const timestamp = this.validateAndNormalizeTimestamp(\n          trackData.track,\n          packet.timestamp,\n          packet.type === \"key\"\n        );\n        const internalSample = this.createSampleForTrack(\n          trackData,\n          packetData,\n          timestamp,\n          packet.duration,\n          packet.type\n        );\n        if (trackData.info.requiresPcmTransformation) {\n          await this.maybePadWithSilence(trackData, timestamp);\n        }\n        await this.registerSample(trackData, internalSample);\n      } finally {\n        release();\n      }\n    }\n    async maybePadWithSilence(trackData, untilTimestamp) {\n      const lastSample = last(trackData.samples);\n      const lastEndTimestamp = lastSample ? lastSample.timestamp + lastSample.duration : 0;\n      const delta = untilTimestamp - lastEndTimestamp;\n      const deltaInTimescale = intoTimescale(delta, trackData.timescale);\n      if (deltaInTimescale > 0) {\n        const { sampleSize, silentValue } = parsePcmCodec(\n          trackData.info.decoderConfig.codec\n        );\n        const samplesNeeded = deltaInTimescale * trackData.info.numberOfChannels;\n        const data = new Uint8Array(sampleSize * samplesNeeded).fill(silentValue);\n        const paddingSample = this.createSampleForTrack(\n          trackData,\n          new Uint8Array(data.buffer),\n          lastEndTimestamp,\n          delta,\n          \"key\"\n        );\n        await this.registerSample(trackData, paddingSample);\n      }\n    }\n    async addSubtitleCue(track, cue, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        const trackData = this.getSubtitleTrackData(track, meta);\n        this.validateAndNormalizeTimestamp(trackData.track, cue.timestamp, true);\n        if (track.source._codec === \"webvtt\") {\n          trackData.cueQueue.push(cue);\n          await this.processWebVTTCues(trackData, cue.timestamp);\n        } else {\n        }\n      } finally {\n        release();\n      }\n    }\n    async processWebVTTCues(trackData, until) {\n      while (trackData.cueQueue.length > 0) {\n        const timestamps = /* @__PURE__ */ new Set([]);\n        for (const cue of trackData.cueQueue) {\n          assert(cue.timestamp <= until);\n          assert(trackData.lastCueEndTimestamp <= cue.timestamp + cue.duration);\n          timestamps.add(Math.max(cue.timestamp, trackData.lastCueEndTimestamp));\n          timestamps.add(cue.timestamp + cue.duration);\n        }\n        const sortedTimestamps = [...timestamps].sort((a, b) => a - b);\n        const sampleStart = sortedTimestamps[0];\n        const sampleEnd = sortedTimestamps[1] ?? sampleStart;\n        if (until < sampleEnd) {\n          break;\n        }\n        if (trackData.lastCueEndTimestamp < sampleStart) {\n          this.auxWriter.seek(0);\n          const box2 = vtte();\n          this.auxBoxWriter.writeBox(box2);\n          const body2 = this.auxWriter.getSlice(0, this.auxWriter.getPos());\n          const sample2 = this.createSampleForTrack(\n            trackData,\n            body2,\n            trackData.lastCueEndTimestamp,\n            sampleStart - trackData.lastCueEndTimestamp,\n            \"key\"\n          );\n          await this.registerSample(trackData, sample2);\n          trackData.lastCueEndTimestamp = sampleStart;\n        }\n        this.auxWriter.seek(0);\n        for (let i = 0; i < trackData.cueQueue.length; i++) {\n          const cue = trackData.cueQueue[i];\n          if (cue.timestamp >= sampleEnd) {\n            break;\n          }\n          inlineTimestampRegex.lastIndex = 0;\n          const containsTimestamp = inlineTimestampRegex.test(cue.text);\n          const endTimestamp = cue.timestamp + cue.duration;\n          let sourceId = trackData.cueToSourceId.get(cue);\n          if (sourceId === void 0 && sampleEnd < endTimestamp) {\n            sourceId = trackData.nextSourceId++;\n            trackData.cueToSourceId.set(cue, sourceId);\n          }\n          if (cue.notes) {\n            const box3 = vtta(cue.notes);\n            this.auxBoxWriter.writeBox(box3);\n          }\n          const box2 = vttc(\n            cue.text,\n            containsTimestamp ? sampleStart : null,\n            cue.identifier ?? null,\n            cue.settings ?? null,\n            sourceId ?? null\n          );\n          this.auxBoxWriter.writeBox(box2);\n          if (endTimestamp === sampleEnd) {\n            trackData.cueQueue.splice(i--, 1);\n          }\n        }\n        const body = this.auxWriter.getSlice(0, this.auxWriter.getPos());\n        const sample = this.createSampleForTrack(trackData, body, sampleStart, sampleEnd - sampleStart, \"key\");\n        await this.registerSample(trackData, sample);\n        trackData.lastCueEndTimestamp = sampleEnd;\n      }\n    }\n    createSampleForTrack(trackData, data, timestamp, duration, type) {\n      const sample = {\n        timestamp,\n        decodeTimestamp: timestamp,\n        // This may be refined later\n        duration,\n        data,\n        size: data.byteLength,\n        type,\n        timescaleUnitsToNextSample: intoTimescale(duration, trackData.timescale)\n        // Will be refined\n      };\n      return sample;\n    }\n    processTimestamps(trackData, nextSample) {\n      if (trackData.timestampProcessingQueue.length === 0) {\n        return;\n      }\n      if (trackData.type === \"audio\" && trackData.info.requiresPcmTransformation) {\n        let totalDuration = 0;\n        for (let i = 0; i < trackData.timestampProcessingQueue.length; i++) {\n          const sample = trackData.timestampProcessingQueue[i];\n          const duration = intoTimescale(sample.duration, trackData.timescale);\n          totalDuration += duration;\n        }\n        if (trackData.timeToSampleTable.length === 0) {\n          trackData.timeToSampleTable.push({\n            sampleCount: totalDuration,\n            sampleDelta: 1\n          });\n        } else {\n          const lastEntry = last(trackData.timeToSampleTable);\n          lastEntry.sampleCount += totalDuration;\n        }\n        trackData.timestampProcessingQueue.length = 0;\n        return;\n      }\n      const sortedTimestamps = trackData.timestampProcessingQueue.map((x) => x.timestamp).sort((a, b) => a - b);\n      for (let i = 0; i < trackData.timestampProcessingQueue.length; i++) {\n        const sample = trackData.timestampProcessingQueue[i];\n        sample.decodeTimestamp = sortedTimestamps[i];\n        if (!this.isFragmented && trackData.lastTimescaleUnits === null) {\n          sample.decodeTimestamp = 0;\n        }\n        const sampleCompositionTimeOffset = intoTimescale(sample.timestamp - sample.decodeTimestamp, trackData.timescale);\n        const durationInTimescale = intoTimescale(sample.duration, trackData.timescale);\n        if (trackData.lastTimescaleUnits !== null) {\n          assert(trackData.lastSample);\n          const timescaleUnits = intoTimescale(sample.decodeTimestamp, trackData.timescale, false);\n          const delta = Math.round(timescaleUnits - trackData.lastTimescaleUnits);\n          assert(delta >= 0);\n          trackData.lastTimescaleUnits += delta;\n          trackData.lastSample.timescaleUnitsToNextSample = delta;\n          if (!this.isFragmented) {\n            let lastTableEntry = last(trackData.timeToSampleTable);\n            assert(lastTableEntry);\n            if (lastTableEntry.sampleCount === 1) {\n              lastTableEntry.sampleDelta = delta;\n              const entryBefore = trackData.timeToSampleTable[trackData.timeToSampleTable.length - 2];\n              if (entryBefore && entryBefore.sampleDelta === delta) {\n                entryBefore.sampleCount++;\n                trackData.timeToSampleTable.pop();\n                lastTableEntry = entryBefore;\n              }\n            } else if (lastTableEntry.sampleDelta !== delta) {\n              lastTableEntry.sampleCount--;\n              trackData.timeToSampleTable.push(lastTableEntry = {\n                sampleCount: 1,\n                sampleDelta: delta\n              });\n            }\n            if (lastTableEntry.sampleDelta === durationInTimescale) {\n              lastTableEntry.sampleCount++;\n            } else {\n              trackData.timeToSampleTable.push({\n                sampleCount: 1,\n                sampleDelta: durationInTimescale\n              });\n            }\n            const lastCompositionTimeOffsetTableEntry = last(trackData.compositionTimeOffsetTable);\n            assert(lastCompositionTimeOffsetTableEntry);\n            if (lastCompositionTimeOffsetTableEntry.sampleCompositionTimeOffset === sampleCompositionTimeOffset) {\n              lastCompositionTimeOffsetTableEntry.sampleCount++;\n            } else {\n              trackData.compositionTimeOffsetTable.push({\n                sampleCount: 1,\n                sampleCompositionTimeOffset\n              });\n            }\n          }\n        } else {\n          trackData.lastTimescaleUnits = intoTimescale(sample.decodeTimestamp, trackData.timescale, false);\n          if (!this.isFragmented) {\n            trackData.timeToSampleTable.push({\n              sampleCount: 1,\n              sampleDelta: durationInTimescale\n            });\n            trackData.compositionTimeOffsetTable.push({\n              sampleCount: 1,\n              sampleCompositionTimeOffset\n            });\n          }\n        }\n        trackData.lastSample = sample;\n      }\n      trackData.timestampProcessingQueue.length = 0;\n      assert(trackData.lastSample);\n      assert(trackData.lastTimescaleUnits !== null);\n      if (nextSample !== void 0 && trackData.lastSample.timescaleUnitsToNextSample === 0) {\n        assert(nextSample.type === \"key\");\n        const timescaleUnits = intoTimescale(nextSample.timestamp, trackData.timescale, false);\n        const delta = Math.round(timescaleUnits - trackData.lastTimescaleUnits);\n        trackData.lastSample.timescaleUnitsToNextSample = delta;\n      }\n    }\n    async registerSample(trackData, sample) {\n      if (sample.type === \"key\") {\n        this.processTimestamps(trackData, sample);\n      }\n      trackData.timestampProcessingQueue.push(sample);\n      if (this.isFragmented) {\n        trackData.sampleQueue.push(sample);\n        await this.interleaveSamples();\n      } else if (this.fastStart === \"reserve\") {\n        await this.registerSampleFastStartReserve(trackData, sample);\n      } else {\n        await this.addSampleToTrack(trackData, sample);\n      }\n    }\n    async addSampleToTrack(trackData, sample) {\n      if (!this.isFragmented) {\n        trackData.samples.push(sample);\n        if (this.fastStart === \"reserve\") {\n          const maximumPacketCount = trackData.track.metadata.maximumPacketCount;\n          assert(maximumPacketCount !== void 0);\n          if (trackData.samples.length > maximumPacketCount) {\n            throw new Error(\n              `Track #${trackData.track.id} has already reached the maximum packet count (${maximumPacketCount}). Either add less packets or increase the maximum packet count.`\n            );\n          }\n        }\n      }\n      let beginNewChunk = false;\n      if (!trackData.currentChunk) {\n        beginNewChunk = true;\n      } else {\n        trackData.currentChunk.startTimestamp = Math.min(\n          trackData.currentChunk.startTimestamp,\n          sample.timestamp\n        );\n        const currentChunkDuration = sample.timestamp - trackData.currentChunk.startTimestamp;\n        if (this.isFragmented) {\n          const keyFrameQueuedEverywhere = this.trackDatas.every((otherTrackData) => {\n            if (trackData === otherTrackData) {\n              return sample.type === \"key\";\n            }\n            const firstQueuedSample = otherTrackData.sampleQueue[0];\n            if (firstQueuedSample) {\n              return firstQueuedSample.type === \"key\";\n            }\n            return otherTrackData.track.source._closed;\n          });\n          if (currentChunkDuration >= this.minimumFragmentDuration && keyFrameQueuedEverywhere && sample.timestamp > this.maxWrittenTimestamp) {\n            beginNewChunk = true;\n            await this.finalizeFragment();\n          }\n        } else {\n          beginNewChunk = currentChunkDuration >= 0.5;\n        }\n      }\n      if (beginNewChunk) {\n        if (trackData.currentChunk) {\n          await this.finalizeCurrentChunk(trackData);\n        }\n        trackData.currentChunk = {\n          startTimestamp: sample.timestamp,\n          samples: [],\n          offset: null,\n          moofOffset: null\n        };\n      }\n      assert(trackData.currentChunk);\n      trackData.currentChunk.samples.push(sample);\n      if (this.isFragmented) {\n        this.maxWrittenTimestamp = Math.max(this.maxWrittenTimestamp, sample.timestamp);\n      }\n    }\n    async finalizeCurrentChunk(trackData) {\n      assert(!this.isFragmented);\n      if (!trackData.currentChunk) return;\n      trackData.finalizedChunks.push(trackData.currentChunk);\n      this.finalizedChunks.push(trackData.currentChunk);\n      let sampleCount = trackData.currentChunk.samples.length;\n      if (trackData.type === \"audio\" && trackData.info.requiresPcmTransformation) {\n        sampleCount = trackData.currentChunk.samples.reduce((acc, sample) => acc + intoTimescale(sample.duration, trackData.timescale), 0);\n      }\n      if (trackData.compactlyCodedChunkTable.length === 0 || last(trackData.compactlyCodedChunkTable).samplesPerChunk !== sampleCount) {\n        trackData.compactlyCodedChunkTable.push({\n          firstChunk: trackData.finalizedChunks.length,\n          // 1-indexed\n          samplesPerChunk: sampleCount\n        });\n      }\n      if (this.fastStart === \"in-memory\") {\n        trackData.currentChunk.offset = 0;\n        return;\n      }\n      trackData.currentChunk.offset = this.writer.getPos();\n      for (const sample of trackData.currentChunk.samples) {\n        assert(sample.data);\n        this.writer.write(sample.data);\n        sample.data = null;\n      }\n      await this.writer.flush();\n    }\n    async interleaveSamples(isFinalCall = false) {\n      assert(this.isFragmented);\n      if (!isFinalCall && !this.allTracksAreKnown()) {\n        return;\n      }\n      outer:\n        while (true) {\n          let trackWithMinTimestamp = null;\n          let minTimestamp = Infinity;\n          for (const trackData of this.trackDatas) {\n            if (!isFinalCall && trackData.sampleQueue.length === 0 && !trackData.track.source._closed) {\n              break outer;\n            }\n            if (trackData.sampleQueue.length > 0 && trackData.sampleQueue[0].timestamp < minTimestamp) {\n              trackWithMinTimestamp = trackData;\n              minTimestamp = trackData.sampleQueue[0].timestamp;\n            }\n          }\n          if (!trackWithMinTimestamp) {\n            break;\n          }\n          const sample = trackWithMinTimestamp.sampleQueue.shift();\n          await this.addSampleToTrack(trackWithMinTimestamp, sample);\n        }\n    }\n    async finalizeFragment(flushWriter = true) {\n      assert(this.isFragmented);\n      const fragmentNumber = this.nextFragmentNumber++;\n      if (fragmentNumber === 1) {\n        if (this.format._options.onMoov) {\n          this.writer.startTrackingWrites();\n        }\n        const movieBox = moov(this);\n        this.boxWriter.writeBox(movieBox);\n        if (this.format._options.onMoov) {\n          const { data, start } = this.writer.stopTrackingWrites();\n          this.format._options.onMoov(data, start);\n        }\n      }\n      const tracksInFragment = this.trackDatas.filter((x) => x.currentChunk);\n      const moofBox = moof(fragmentNumber, tracksInFragment);\n      const moofOffset = this.writer.getPos();\n      const mdatStartPos = moofOffset + this.boxWriter.measureBox(moofBox);\n      let currentPos = mdatStartPos + MIN_BOX_HEADER_SIZE;\n      let fragmentStartTimestamp = Infinity;\n      for (const trackData of tracksInFragment) {\n        trackData.currentChunk.offset = currentPos;\n        trackData.currentChunk.moofOffset = moofOffset;\n        for (const sample of trackData.currentChunk.samples) {\n          currentPos += sample.size;\n        }\n        fragmentStartTimestamp = Math.min(fragmentStartTimestamp, trackData.currentChunk.startTimestamp);\n      }\n      const mdatSize = currentPos - mdatStartPos;\n      const needsLargeMdatSize = mdatSize >= 2 ** 32;\n      if (needsLargeMdatSize) {\n        for (const trackData of tracksInFragment) {\n          trackData.currentChunk.offset += MAX_BOX_HEADER_SIZE - MIN_BOX_HEADER_SIZE;\n        }\n      }\n      if (this.format._options.onMoof) {\n        this.writer.startTrackingWrites();\n      }\n      const newMoofBox = moof(fragmentNumber, tracksInFragment);\n      this.boxWriter.writeBox(newMoofBox);\n      if (this.format._options.onMoof) {\n        const { data, start } = this.writer.stopTrackingWrites();\n        this.format._options.onMoof(data, start, fragmentStartTimestamp);\n      }\n      assert(this.writer.getPos() === mdatStartPos);\n      if (this.format._options.onMdat) {\n        this.writer.startTrackingWrites();\n      }\n      const mdatBox = mdat(needsLargeMdatSize);\n      mdatBox.size = mdatSize;\n      this.boxWriter.writeBox(mdatBox);\n      this.writer.seek(mdatStartPos + (needsLargeMdatSize ? MAX_BOX_HEADER_SIZE : MIN_BOX_HEADER_SIZE));\n      for (const trackData of tracksInFragment) {\n        for (const sample of trackData.currentChunk.samples) {\n          this.writer.write(sample.data);\n          sample.data = null;\n        }\n      }\n      if (this.format._options.onMdat) {\n        const { data, start } = this.writer.stopTrackingWrites();\n        this.format._options.onMdat(data, start);\n      }\n      for (const trackData of tracksInFragment) {\n        trackData.finalizedChunks.push(trackData.currentChunk);\n        this.finalizedChunks.push(trackData.currentChunk);\n        trackData.currentChunk = null;\n      }\n      if (flushWriter) {\n        await this.writer.flush();\n      }\n    }\n    async registerSampleFastStartReserve(trackData, sample) {\n      if (this.allTracksAreKnown()) {\n        if (!this.mdat) {\n          const moovBox = moov(this);\n          const moovSize = this.boxWriter.measureBox(moovBox);\n          const reservedSize = moovSize + this.computeSampleTableSizeUpperBound() + 4096;\n          assert(this.ftypSize !== null);\n          this.writer.seek(this.ftypSize + reservedSize);\n          if (this.format._options.onMdat) {\n            this.writer.startTrackingWrites();\n          }\n          this.mdat = mdat(true);\n          this.boxWriter.writeBox(this.mdat);\n          for (const trackData2 of this.trackDatas) {\n            for (const sample2 of trackData2.sampleQueue) {\n              await this.addSampleToTrack(trackData2, sample2);\n            }\n            trackData2.sampleQueue.length = 0;\n          }\n        }\n        await this.addSampleToTrack(trackData, sample);\n      } else {\n        trackData.sampleQueue.push(sample);\n      }\n    }\n    computeSampleTableSizeUpperBound() {\n      assert(this.fastStart === \"reserve\");\n      let upperBound = 0;\n      for (const trackData of this.trackDatas) {\n        const n = trackData.track.metadata.maximumPacketCount;\n        assert(n !== void 0);\n        upperBound += (4 + 4) * Math.ceil(2 / 3 * n);\n        upperBound += 4 * n;\n        upperBound += (4 + 4) * Math.ceil(2 / 3 * n);\n        upperBound += (4 + 4 + 4) * Math.ceil(2 / 3 * n);\n        upperBound += 4 * n;\n        upperBound += 8 * n;\n      }\n      return upperBound;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-misused-promises\n    async onTrackClose(track) {\n      const release = await this.mutex.acquire();\n      if (track.type === \"subtitle\" && track.source._codec === \"webvtt\") {\n        const trackData = this.trackDatas.find((x) => x.track === track);\n        if (trackData) {\n          await this.processWebVTTCues(trackData, Infinity);\n        }\n      }\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      if (this.isFragmented) {\n        await this.interleaveSamples();\n      }\n      release();\n    }\n    /** Finalizes the file, making it ready for use. Must be called after all video and audio chunks have been added. */\n    async finalize() {\n      const release = await this.mutex.acquire();\n      this.allTracksKnown.resolve();\n      for (const trackData of this.trackDatas) {\n        if (trackData.type === \"subtitle\" && trackData.track.source._codec === \"webvtt\") {\n          await this.processWebVTTCues(trackData, Infinity);\n        }\n      }\n      if (this.isFragmented) {\n        await this.interleaveSamples(true);\n        for (const trackData of this.trackDatas) {\n          this.processTimestamps(trackData);\n        }\n        await this.finalizeFragment(false);\n      } else {\n        for (const trackData of this.trackDatas) {\n          this.processTimestamps(trackData);\n          await this.finalizeCurrentChunk(trackData);\n        }\n      }\n      if (this.fastStart === \"in-memory\") {\n        this.mdat = mdat(false);\n        let mdatSize;\n        for (let i = 0; i < 2; i++) {\n          const movieBox2 = moov(this);\n          const movieBoxSize = this.boxWriter.measureBox(movieBox2);\n          mdatSize = this.boxWriter.measureBox(this.mdat);\n          let currentChunkPos = this.writer.getPos() + movieBoxSize + mdatSize;\n          for (const chunk of this.finalizedChunks) {\n            chunk.offset = currentChunkPos;\n            for (const { data } of chunk.samples) {\n              assert(data);\n              currentChunkPos += data.byteLength;\n              mdatSize += data.byteLength;\n            }\n          }\n          if (currentChunkPos < 2 ** 32) break;\n          if (mdatSize >= 2 ** 32) this.mdat.largeSize = true;\n        }\n        if (this.format._options.onMoov) {\n          this.writer.startTrackingWrites();\n        }\n        const movieBox = moov(this);\n        this.boxWriter.writeBox(movieBox);\n        if (this.format._options.onMoov) {\n          const { data, start } = this.writer.stopTrackingWrites();\n          this.format._options.onMoov(data, start);\n        }\n        if (this.format._options.onMdat) {\n          this.writer.startTrackingWrites();\n        }\n        this.mdat.size = mdatSize;\n        this.boxWriter.writeBox(this.mdat);\n        for (const chunk of this.finalizedChunks) {\n          for (const sample of chunk.samples) {\n            assert(sample.data);\n            this.writer.write(sample.data);\n            sample.data = null;\n          }\n        }\n        if (this.format._options.onMdat) {\n          const { data, start } = this.writer.stopTrackingWrites();\n          this.format._options.onMdat(data, start);\n        }\n      } else if (this.isFragmented) {\n        const startPos = this.writer.getPos();\n        const mfraBox = mfra(this.trackDatas);\n        this.boxWriter.writeBox(mfraBox);\n        const mfraBoxSize = this.writer.getPos() - startPos;\n        this.writer.seek(this.writer.getPos() - 4);\n        this.boxWriter.writeU32(mfraBoxSize);\n      } else {\n        assert(this.mdat);\n        const mdatPos = this.boxWriter.offsets.get(this.mdat);\n        assert(mdatPos !== void 0);\n        const mdatSize = this.writer.getPos() - mdatPos;\n        this.mdat.size = mdatSize;\n        this.mdat.largeSize = mdatSize >= 2 ** 32;\n        this.boxWriter.patchBox(this.mdat);\n        if (this.format._options.onMdat) {\n          const { data, start } = this.writer.stopTrackingWrites();\n          this.format._options.onMdat(data, start);\n        }\n        const movieBox = moov(this);\n        if (this.fastStart === \"reserve\") {\n          assert(this.ftypSize !== null);\n          this.writer.seek(this.ftypSize);\n          if (this.format._options.onMoov) {\n            this.writer.startTrackingWrites();\n          }\n          this.boxWriter.writeBox(movieBox);\n          const remainingSpace = this.boxWriter.offsets.get(this.mdat) - this.writer.getPos();\n          this.boxWriter.writeBox(free(remainingSpace));\n        } else {\n          if (this.format._options.onMoov) {\n            this.writer.startTrackingWrites();\n          }\n          this.boxWriter.writeBox(movieBox);\n        }\n        if (this.format._options.onMoov) {\n          const { data, start } = this.writer.stopTrackingWrites();\n          this.format._options.onMoov(data, start);\n        }\n      }\n      release();\n    }\n  };\n\n  // src/matroska/matroska-muxer.ts\n  var MIN_CLUSTER_TIMESTAMP_MS = -(2 ** 15);\n  var MAX_CLUSTER_TIMESTAMP_MS = 2 ** 15 - 1;\n  var APP_NAME = \"Mediabunny\";\n  var SEGMENT_SIZE_BYTES = 6;\n  var CLUSTER_SIZE_BYTES = 5;\n  var TRACK_TYPE_MAP = {\n    video: 1,\n    audio: 2,\n    subtitle: 17\n  };\n  var MatroskaMuxer = class extends Muxer {\n    constructor(output, format) {\n      super(output);\n      this.trackDatas = [];\n      this.allTracksKnown = promiseWithResolvers();\n      this.segment = null;\n      this.segmentInfo = null;\n      this.seekHead = null;\n      this.tracksElement = null;\n      this.tagsElement = null;\n      this.attachmentsElement = null;\n      this.segmentDuration = null;\n      this.cues = null;\n      this.currentCluster = null;\n      this.currentClusterStartMsTimestamp = null;\n      this.currentClusterMaxMsTimestamp = null;\n      this.trackDatasInCurrentCluster = /* @__PURE__ */ new Map();\n      this.duration = 0;\n      this.writer = output._writer;\n      this.format = format;\n      this.ebmlWriter = new EBMLWriter(this.writer);\n      if (this.format._options.appendOnly) {\n        this.writer.ensureMonotonicity = true;\n      }\n    }\n    async start() {\n      const release = await this.mutex.acquire();\n      this.writeEBMLHeader();\n      this.createSegmentInfo();\n      this.createCues();\n      await this.writer.flush();\n      release();\n    }\n    writeEBMLHeader() {\n      if (this.format._options.onEbmlHeader) {\n        this.writer.startTrackingWrites();\n      }\n      const ebmlHeader = { id: 440786851 /* EBML */, data: [\n        { id: 17030 /* EBMLVersion */, data: 1 },\n        { id: 17143 /* EBMLReadVersion */, data: 1 },\n        { id: 17138 /* EBMLMaxIDLength */, data: 4 },\n        { id: 17139 /* EBMLMaxSizeLength */, data: 8 },\n        { id: 17026 /* DocType */, data: this.format instanceof WebMOutputFormat ? \"webm\" : \"matroska\" },\n        { id: 17031 /* DocTypeVersion */, data: 2 },\n        { id: 17029 /* DocTypeReadVersion */, data: 2 }\n      ] };\n      this.ebmlWriter.writeEBML(ebmlHeader);\n      if (this.format._options.onEbmlHeader) {\n        const { data, start } = this.writer.stopTrackingWrites();\n        this.format._options.onEbmlHeader(data, start);\n      }\n    }\n    /**\n     * Creates a SeekHead element which is positioned near the start of the file and allows the media player to seek to\n     * relevant sections more easily. Since we don't know the positions of those sections yet, we'll set them later.\n     */\n    maybeCreateSeekHead(writeOffsets) {\n      if (this.format._options.appendOnly) {\n        return;\n      }\n      const kaxCues = new Uint8Array([28, 83, 187, 107]);\n      const kaxInfo = new Uint8Array([21, 73, 169, 102]);\n      const kaxTracks = new Uint8Array([22, 84, 174, 107]);\n      const kaxAttachments = new Uint8Array([25, 65, 164, 105]);\n      const kaxTags = new Uint8Array([18, 84, 195, 103]);\n      const seekHead = { id: 290298740 /* SeekHead */, data: [\n        { id: 19899 /* Seek */, data: [\n          { id: 21419 /* SeekID */, data: kaxCues },\n          {\n            id: 21420 /* SeekPosition */,\n            size: 5,\n            data: writeOffsets ? this.ebmlWriter.offsets.get(this.cues) - this.segmentDataOffset : 0\n          }\n        ] },\n        { id: 19899 /* Seek */, data: [\n          { id: 21419 /* SeekID */, data: kaxInfo },\n          {\n            id: 21420 /* SeekPosition */,\n            size: 5,\n            data: writeOffsets ? this.ebmlWriter.offsets.get(this.segmentInfo) - this.segmentDataOffset : 0\n          }\n        ] },\n        { id: 19899 /* Seek */, data: [\n          { id: 21419 /* SeekID */, data: kaxTracks },\n          {\n            id: 21420 /* SeekPosition */,\n            size: 5,\n            data: writeOffsets ? this.ebmlWriter.offsets.get(this.tracksElement) - this.segmentDataOffset : 0\n          }\n        ] },\n        this.attachmentsElement ? { id: 19899 /* Seek */, data: [\n          { id: 21419 /* SeekID */, data: kaxAttachments },\n          {\n            id: 21420 /* SeekPosition */,\n            size: 5,\n            data: writeOffsets ? this.ebmlWriter.offsets.get(this.attachmentsElement) - this.segmentDataOffset : 0\n          }\n        ] } : null,\n        this.tagsElement ? { id: 19899 /* Seek */, data: [\n          { id: 21419 /* SeekID */, data: kaxTags },\n          {\n            id: 21420 /* SeekPosition */,\n            size: 5,\n            data: writeOffsets ? this.ebmlWriter.offsets.get(this.tagsElement) - this.segmentDataOffset : 0\n          }\n        ] } : null\n      ] };\n      this.seekHead = seekHead;\n    }\n    createSegmentInfo() {\n      const segmentDuration = { id: 17545 /* Duration */, data: new EBMLFloat64(0) };\n      this.segmentDuration = segmentDuration;\n      const segmentInfo = { id: 357149030 /* Info */, data: [\n        { id: 2807729 /* TimestampScale */, data: 1e6 },\n        { id: 19840 /* MuxingApp */, data: APP_NAME },\n        { id: 22337 /* WritingApp */, data: APP_NAME },\n        !this.format._options.appendOnly ? segmentDuration : null\n      ] };\n      this.segmentInfo = segmentInfo;\n    }\n    createTracks() {\n      const tracksElement = { id: 374648427 /* Tracks */, data: [] };\n      this.tracksElement = tracksElement;\n      for (const trackData of this.trackDatas) {\n        const codecId = CODEC_STRING_MAP[trackData.track.source._codec];\n        assert(codecId);\n        let seekPreRollNs = 0;\n        if (trackData.type === \"audio\" && trackData.track.source._codec === \"opus\") {\n          seekPreRollNs = 1e6 * 80;\n          const description = trackData.info.decoderConfig.description;\n          if (description) {\n            const bytes2 = toUint8Array(description);\n            const header = parseOpusIdentificationHeader(bytes2);\n            seekPreRollNs = Math.round(1e9 * (header.preSkip / OPUS_SAMPLE_RATE));\n          }\n        }\n        tracksElement.data.push({ id: 174 /* TrackEntry */, data: [\n          { id: 215 /* TrackNumber */, data: trackData.track.id },\n          { id: 29637 /* TrackUID */, data: trackData.track.id },\n          { id: 131 /* TrackType */, data: TRACK_TYPE_MAP[trackData.type] },\n          trackData.track.metadata.disposition?.default === false ? { id: 136 /* FlagDefault */, data: 0 } : null,\n          trackData.track.metadata.disposition?.forced ? { id: 21930 /* FlagForced */, data: 1 } : null,\n          trackData.track.metadata.disposition?.hearingImpaired ? { id: 21931 /* FlagHearingImpaired */, data: 1 } : null,\n          trackData.track.metadata.disposition?.visuallyImpaired ? { id: 21932 /* FlagVisualImpaired */, data: 1 } : null,\n          trackData.track.metadata.disposition?.original ? { id: 21934 /* FlagOriginal */, data: 1 } : null,\n          trackData.track.metadata.disposition?.commentary ? { id: 21935 /* FlagCommentary */, data: 1 } : null,\n          { id: 156 /* FlagLacing */, data: 0 },\n          { id: 2274716 /* Language */, data: trackData.track.metadata.languageCode ?? UNDETERMINED_LANGUAGE },\n          { id: 134 /* CodecID */, data: codecId },\n          { id: 22186 /* CodecDelay */, data: 0 },\n          { id: 22203 /* SeekPreRoll */, data: seekPreRollNs },\n          trackData.track.metadata.name !== void 0 ? { id: 21358 /* Name */, data: new EBMLUnicodeString(trackData.track.metadata.name) } : null,\n          trackData.type === \"video\" ? this.videoSpecificTrackInfo(trackData) : null,\n          trackData.type === \"audio\" ? this.audioSpecificTrackInfo(trackData) : null,\n          trackData.type === \"subtitle\" ? this.subtitleSpecificTrackInfo(trackData) : null\n        ] });\n      }\n    }\n    videoSpecificTrackInfo(trackData) {\n      const { frameRate, rotation } = trackData.track.metadata;\n      const elements = [\n        trackData.info.decoderConfig.description ? {\n          id: 25506 /* CodecPrivate */,\n          data: toUint8Array(trackData.info.decoderConfig.description)\n        } : null,\n        frameRate ? {\n          id: 2352003 /* DefaultDuration */,\n          data: 1e9 / frameRate\n        } : null\n      ];\n      const flippedRotation = rotation ? normalizeRotation(-rotation) : 0;\n      const colorSpace = trackData.info.decoderConfig.colorSpace;\n      const videoElement = { id: 224 /* Video */, data: [\n        { id: 176 /* PixelWidth */, data: trackData.info.width },\n        { id: 186 /* PixelHeight */, data: trackData.info.height },\n        trackData.info.alphaMode ? { id: 21440 /* AlphaMode */, data: 1 } : null,\n        colorSpaceIsComplete(colorSpace) ? {\n          id: 21936 /* Colour */,\n          data: [\n            {\n              id: 21937 /* MatrixCoefficients */,\n              data: MATRIX_COEFFICIENTS_MAP[colorSpace.matrix]\n            },\n            {\n              id: 21946 /* TransferCharacteristics */,\n              data: TRANSFER_CHARACTERISTICS_MAP[colorSpace.transfer]\n            },\n            {\n              id: 21947 /* Primaries */,\n              data: COLOR_PRIMARIES_MAP[colorSpace.primaries]\n            },\n            {\n              id: 21945 /* Range */,\n              data: colorSpace.fullRange ? 2 : 1\n            }\n          ]\n        } : null,\n        flippedRotation ? {\n          id: 30320 /* Projection */,\n          data: [\n            {\n              id: 30321 /* ProjectionType */,\n              data: 0\n              // rectangular\n            },\n            {\n              id: 30325 /* ProjectionPoseRoll */,\n              data: new EBMLFloat32((flippedRotation + 180) % 360 - 180)\n              // [0, 270] -> [-180, 90]\n            }\n          ]\n        } : null\n      ] };\n      elements.push(videoElement);\n      return elements;\n    }\n    audioSpecificTrackInfo(trackData) {\n      const pcmInfo = PCM_AUDIO_CODECS.includes(trackData.track.source._codec) ? parsePcmCodec(trackData.track.source._codec) : null;\n      return [\n        trackData.info.decoderConfig.description ? {\n          id: 25506 /* CodecPrivate */,\n          data: toUint8Array(trackData.info.decoderConfig.description)\n        } : null,\n        { id: 225 /* Audio */, data: [\n          { id: 181 /* SamplingFrequency */, data: new EBMLFloat32(trackData.info.sampleRate) },\n          { id: 159 /* Channels */, data: trackData.info.numberOfChannels },\n          pcmInfo ? { id: 25188 /* BitDepth */, data: 8 * pcmInfo.sampleSize } : null\n        ] }\n      ];\n    }\n    subtitleSpecificTrackInfo(trackData) {\n      return [\n        { id: 25506 /* CodecPrivate */, data: textEncoder.encode(trackData.info.config.description) }\n      ];\n    }\n    maybeCreateTags() {\n      const simpleTags = [];\n      const addSimpleTag = (key, value) => {\n        simpleTags.push({ id: 26568 /* SimpleTag */, data: [\n          { id: 17827 /* TagName */, data: new EBMLUnicodeString(key) },\n          typeof value === \"string\" ? { id: 17543 /* TagString */, data: new EBMLUnicodeString(value) } : { id: 17541 /* TagBinary */, data: value }\n        ] });\n      };\n      const metadataTags = this.output._metadataTags;\n      const writtenTags = /* @__PURE__ */ new Set();\n      for (const { key, value } of keyValueIterator(metadataTags)) {\n        switch (key) {\n          case \"title\":\n            {\n              addSimpleTag(\"TITLE\", value);\n              writtenTags.add(\"TITLE\");\n            }\n            ;\n            break;\n          case \"description\":\n            {\n              addSimpleTag(\"DESCRIPTION\", value);\n              writtenTags.add(\"DESCRIPTION\");\n            }\n            ;\n            break;\n          case \"artist\":\n            {\n              addSimpleTag(\"ARTIST\", value);\n              writtenTags.add(\"ARTIST\");\n            }\n            ;\n            break;\n          case \"album\":\n            {\n              addSimpleTag(\"ALBUM\", value);\n              writtenTags.add(\"ALBUM\");\n            }\n            ;\n            break;\n          case \"albumArtist\":\n            {\n              addSimpleTag(\"ALBUM_ARTIST\", value);\n              writtenTags.add(\"ALBUM_ARTIST\");\n            }\n            ;\n            break;\n          case \"genre\":\n            {\n              addSimpleTag(\"GENRE\", value);\n              writtenTags.add(\"GENRE\");\n            }\n            ;\n            break;\n          case \"comment\":\n            {\n              addSimpleTag(\"COMMENT\", value);\n              writtenTags.add(\"COMMENT\");\n            }\n            ;\n            break;\n          case \"lyrics\":\n            {\n              addSimpleTag(\"LYRICS\", value);\n              writtenTags.add(\"LYRICS\");\n            }\n            ;\n            break;\n          case \"date\":\n            {\n              addSimpleTag(\"DATE\", value.toISOString().slice(0, 10));\n              writtenTags.add(\"DATE\");\n            }\n            ;\n            break;\n          case \"trackNumber\":\n            {\n              const string = metadataTags.tracksTotal !== void 0 ? `${value}/${metadataTags.tracksTotal}` : value.toString();\n              addSimpleTag(\"PART_NUMBER\", string);\n              writtenTags.add(\"PART_NUMBER\");\n            }\n            ;\n            break;\n          case \"discNumber\":\n            {\n              const string = metadataTags.discsTotal !== void 0 ? `${value}/${metadataTags.discsTotal}` : value.toString();\n              addSimpleTag(\"DISC\", string);\n              writtenTags.add(\"DISC\");\n            }\n            ;\n            break;\n          case \"tracksTotal\":\n          case \"discsTotal\":\n            {\n            }\n            ;\n            break;\n          case \"images\":\n          case \"raw\":\n            {\n            }\n            ;\n            break;\n          default:\n            assertNever(key);\n        }\n      }\n      if (metadataTags.raw) {\n        for (const key in metadataTags.raw) {\n          const value = metadataTags.raw[key];\n          if (value == null || writtenTags.has(key)) {\n            continue;\n          }\n          if (typeof value === \"string\" || value instanceof Uint8Array) {\n            addSimpleTag(key, value);\n          }\n        }\n      }\n      if (simpleTags.length === 0) {\n        return;\n      }\n      this.tagsElement = {\n        id: 307544935 /* Tags */,\n        data: [{ id: 29555 /* Tag */, data: [\n          { id: 25536 /* Targets */, data: [\n            { id: 26826 /* TargetTypeValue */, data: 50 },\n            { id: 25546 /* TargetType */, data: \"MOVIE\" }\n          ] },\n          ...simpleTags\n        ] }]\n      };\n    }\n    maybeCreateAttachments() {\n      const metadataTags = this.output._metadataTags;\n      const elements = [];\n      const existingFileUids = /* @__PURE__ */ new Set();\n      const images = metadataTags.images ?? [];\n      for (const image of images) {\n        let imageName = image.name;\n        if (imageName === void 0) {\n          const baseName = image.kind === \"coverFront\" ? \"cover\" : image.kind === \"coverBack\" ? \"back\" : \"image\";\n          imageName = baseName + (imageMimeTypeToExtension(image.mimeType) ?? \"\");\n        }\n        let fileUid;\n        while (true) {\n          fileUid = 0n;\n          for (let i = 0; i < 8; i++) {\n            fileUid <<= 8n;\n            fileUid |= BigInt(Math.floor(Math.random() * 256));\n          }\n          if (fileUid !== 0n && !existingFileUids.has(fileUid)) {\n            break;\n          }\n        }\n        existingFileUids.add(fileUid);\n        elements.push({\n          id: 24999 /* AttachedFile */,\n          data: [\n            image.description !== void 0 ? { id: 18046 /* FileDescription */, data: new EBMLUnicodeString(image.description) } : null,\n            { id: 18030 /* FileName */, data: new EBMLUnicodeString(imageName) },\n            { id: 18016 /* FileMediaType */, data: image.mimeType },\n            { id: 18012 /* FileData */, data: image.data },\n            { id: 18094 /* FileUID */, data: fileUid }\n          ]\n        });\n      }\n      for (const [key, value] of Object.entries(metadataTags.raw ?? {})) {\n        if (!(value instanceof AttachedFile)) {\n          continue;\n        }\n        const keyIsNumeric = /^\\d+$/.test(key);\n        if (!keyIsNumeric) {\n          continue;\n        }\n        if (images.find((x) => x.mimeType === value.mimeType && uint8ArraysAreEqual(x.data, value.data))) {\n          continue;\n        }\n        elements.push({\n          id: 24999 /* AttachedFile */,\n          data: [\n            value.description !== void 0 ? { id: 18046 /* FileDescription */, data: new EBMLUnicodeString(value.description) } : null,\n            { id: 18030 /* FileName */, data: new EBMLUnicodeString(value.name ?? \"\") },\n            { id: 18016 /* FileMediaType */, data: value.mimeType ?? \"\" },\n            { id: 18012 /* FileData */, data: value.data },\n            { id: 18094 /* FileUID */, data: BigInt(key) }\n          ]\n        });\n      }\n      if (elements.length === 0) {\n        return;\n      }\n      this.attachmentsElement = { id: 423732329 /* Attachments */, data: elements };\n    }\n    createSegment() {\n      this.createTracks();\n      this.maybeCreateTags();\n      this.maybeCreateAttachments();\n      this.maybeCreateSeekHead(false);\n      const segment = {\n        id: 408125543 /* Segment */,\n        size: this.format._options.appendOnly ? -1 : SEGMENT_SIZE_BYTES,\n        data: [\n          this.seekHead,\n          // null if append-only\n          this.segmentInfo,\n          this.tracksElement,\n          // Matroska spec says put this at the end of the file, but I think placing it before the first cluster\n          // makes more sense, and FFmpeg agrees (argumentum ad ffmpegum fallacy)\n          this.attachmentsElement,\n          this.tagsElement\n        ]\n      };\n      this.segment = segment;\n      if (this.format._options.onSegmentHeader) {\n        this.writer.startTrackingWrites();\n      }\n      this.ebmlWriter.writeEBML(segment);\n      if (this.format._options.onSegmentHeader) {\n        const { data, start } = this.writer.stopTrackingWrites();\n        this.format._options.onSegmentHeader(data, start);\n      }\n    }\n    createCues() {\n      this.cues = { id: 475249515 /* Cues */, data: [] };\n    }\n    get segmentDataOffset() {\n      assert(this.segment);\n      return this.ebmlWriter.dataOffsets.get(this.segment);\n    }\n    allTracksAreKnown() {\n      for (const track of this.output._tracks) {\n        if (!track.source._closed && !this.trackDatas.some((x) => x.track === track)) {\n          return false;\n        }\n      }\n      return true;\n    }\n    async getMimeType() {\n      await this.allTracksKnown.promise;\n      const codecStrings = this.trackDatas.map((trackData) => {\n        if (trackData.type === \"video\") {\n          return trackData.info.decoderConfig.codec;\n        } else if (trackData.type === \"audio\") {\n          return trackData.info.decoderConfig.codec;\n        } else {\n          const map = {\n            webvtt: \"wvtt\"\n          };\n          return map[trackData.track.source._codec];\n        }\n      });\n      return buildMatroskaMimeType({\n        isWebM: this.format instanceof WebMOutputFormat,\n        hasVideo: this.trackDatas.some((x) => x.type === \"video\"),\n        hasAudio: this.trackDatas.some((x) => x.type === \"audio\"),\n        codecStrings\n      });\n    }\n    getVideoTrackData(track, packet, meta) {\n      const existingTrackData = this.trackDatas.find((x) => x.track === track);\n      if (existingTrackData) {\n        return existingTrackData;\n      }\n      validateVideoChunkMetadata(meta);\n      assert(meta);\n      assert(meta.decoderConfig);\n      assert(meta.decoderConfig.codedWidth !== void 0);\n      assert(meta.decoderConfig.codedHeight !== void 0);\n      const newTrackData = {\n        track,\n        type: \"video\",\n        info: {\n          width: meta.decoderConfig.codedWidth,\n          height: meta.decoderConfig.codedHeight,\n          decoderConfig: meta.decoderConfig,\n          alphaMode: !!packet.sideData.alpha\n          // The first packet determines if this track has alpha or not\n        },\n        chunkQueue: [],\n        lastWrittenMsTimestamp: null\n      };\n      if (track.source._codec === \"vp9\") {\n        newTrackData.info.decoderConfig = {\n          ...newTrackData.info.decoderConfig,\n          description: new Uint8Array(\n            generateVp9CodecConfigurationFromCodecString(newTrackData.info.decoderConfig.codec)\n          )\n        };\n      } else if (track.source._codec === \"av1\") {\n        newTrackData.info.decoderConfig = {\n          ...newTrackData.info.decoderConfig,\n          description: new Uint8Array(\n            generateAv1CodecConfigurationFromCodecString(newTrackData.info.decoderConfig.codec)\n          )\n        };\n      }\n      this.trackDatas.push(newTrackData);\n      this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      return newTrackData;\n    }\n    getAudioTrackData(track, packet, meta) {\n      const existingTrackData = this.trackDatas.find((x) => x.track === track);\n      if (existingTrackData) {\n        return existingTrackData;\n      }\n      validateAudioChunkMetadata(meta);\n      assert(meta);\n      assert(meta.decoderConfig);\n      const decoderConfig = { ...meta.decoderConfig };\n      let requiresAdtsStripping = false;\n      if (track.source._codec === \"aac\" && !decoderConfig.description) {\n        const adtsFrame = readAdtsFrameHeader(FileSlice4.tempFromBytes(packet.data));\n        if (!adtsFrame) {\n          throw new Error(\n            \"Couldn't parse ADTS header from the AAC packet. Make sure the packets are in ADTS format (as specified in ISO 13818-7) when not providing a description, or provide a description (must be an AudioSpecificConfig as specified in ISO 14496-3) and ensure the packets are raw AAC data.\"\n          );\n        }\n        const sampleRate = aacFrequencyTable[adtsFrame.samplingFrequencyIndex];\n        const numberOfChannels = aacChannelMap[adtsFrame.channelConfiguration];\n        if (sampleRate === void 0 || numberOfChannels === void 0) {\n          throw new Error(\"Invalid ADTS frame header.\");\n        }\n        decoderConfig.description = buildAacAudioSpecificConfig({\n          objectType: adtsFrame.objectType,\n          sampleRate,\n          numberOfChannels\n        });\n        requiresAdtsStripping = true;\n      }\n      const newTrackData = {\n        track,\n        type: \"audio\",\n        info: {\n          numberOfChannels: meta.decoderConfig.numberOfChannels,\n          sampleRate: meta.decoderConfig.sampleRate,\n          decoderConfig,\n          requiresAdtsStripping\n        },\n        chunkQueue: [],\n        lastWrittenMsTimestamp: null\n      };\n      this.trackDatas.push(newTrackData);\n      this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      return newTrackData;\n    }\n    getSubtitleTrackData(track, meta) {\n      const existingTrackData = this.trackDatas.find((x) => x.track === track);\n      if (existingTrackData) {\n        return existingTrackData;\n      }\n      validateSubtitleMetadata(meta);\n      assert(meta);\n      assert(meta.config);\n      const newTrackData = {\n        track,\n        type: \"subtitle\",\n        info: {\n          config: meta.config\n        },\n        chunkQueue: [],\n        lastWrittenMsTimestamp: null\n      };\n      this.trackDatas.push(newTrackData);\n      this.trackDatas.sort((a, b) => a.track.id - b.track.id);\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      return newTrackData;\n    }\n    async addEncodedVideoPacket(track, packet, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        const trackData = this.getVideoTrackData(track, packet, meta);\n        const isKeyFrame = packet.type === \"key\";\n        let timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, isKeyFrame);\n        let duration = packet.duration;\n        if (track.metadata.frameRate !== void 0) {\n          timestamp = roundToMultiple(timestamp, 1 / track.metadata.frameRate);\n          duration = roundToMultiple(duration, 1 / track.metadata.frameRate);\n        }\n        const additions = trackData.info.alphaMode ? packet.sideData.alpha ?? null : null;\n        const videoChunk = this.createInternalChunk(packet.data, timestamp, duration, packet.type, additions);\n        if (track.source._codec === \"vp9\") this.fixVP9ColorSpace(trackData, videoChunk);\n        trackData.chunkQueue.push(videoChunk);\n        await this.interleaveChunks();\n      } finally {\n        release();\n      }\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        const trackData = this.getAudioTrackData(track, packet, meta);\n        let packetData = packet.data;\n        if (trackData.info.requiresAdtsStripping) {\n          const adtsFrame = readAdtsFrameHeader(FileSlice4.tempFromBytes(packetData));\n          if (!adtsFrame) {\n            throw new Error(\"Expected ADTS frame, didn't get one.\");\n          }\n          const headerLength = adtsFrame.crcCheck === null ? MIN_ADTS_FRAME_HEADER_SIZE : MAX_ADTS_FRAME_HEADER_SIZE;\n          packetData = packetData.subarray(headerLength);\n        }\n        const isKeyFrame = packet.type === \"key\";\n        const timestamp = this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, isKeyFrame);\n        const audioChunk = this.createInternalChunk(packetData, timestamp, packet.duration, packet.type);\n        trackData.chunkQueue.push(audioChunk);\n        await this.interleaveChunks();\n      } finally {\n        release();\n      }\n    }\n    async addSubtitleCue(track, cue, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        const trackData = this.getSubtitleTrackData(track, meta);\n        const timestamp = this.validateAndNormalizeTimestamp(trackData.track, cue.timestamp, true);\n        let bodyText = cue.text;\n        const timestampMs = Math.round(timestamp * 1e3);\n        inlineTimestampRegex.lastIndex = 0;\n        bodyText = bodyText.replace(inlineTimestampRegex, (match) => {\n          const time = parseSubtitleTimestamp(match.slice(1, -1));\n          const offsetTime = time - timestampMs;\n          return `<${formatSubtitleTimestamp(offsetTime)}>`;\n        });\n        const body = textEncoder.encode(bodyText);\n        const additions = `${cue.settings ?? \"\"}\n${cue.identifier ?? \"\"}\n${cue.notes ?? \"\"}`;\n        const subtitleChunk = this.createInternalChunk(\n          body,\n          timestamp,\n          cue.duration,\n          \"key\",\n          additions.trim() ? textEncoder.encode(additions) : null\n        );\n        trackData.chunkQueue.push(subtitleChunk);\n        await this.interleaveChunks();\n      } finally {\n        release();\n      }\n    }\n    async interleaveChunks(isFinalCall = false) {\n      if (!isFinalCall && !this.allTracksAreKnown()) {\n        return;\n      }\n      outer:\n        while (true) {\n          let trackWithMinTimestamp = null;\n          let minTimestamp = Infinity;\n          for (const trackData of this.trackDatas) {\n            if (!isFinalCall && trackData.chunkQueue.length === 0 && !trackData.track.source._closed) {\n              break outer;\n            }\n            if (trackData.chunkQueue.length > 0 && trackData.chunkQueue[0].timestamp < minTimestamp) {\n              trackWithMinTimestamp = trackData;\n              minTimestamp = trackData.chunkQueue[0].timestamp;\n            }\n          }\n          if (!trackWithMinTimestamp) {\n            break;\n          }\n          const chunk = trackWithMinTimestamp.chunkQueue.shift();\n          this.writeBlock(trackWithMinTimestamp, chunk);\n        }\n      if (!isFinalCall) {\n        await this.writer.flush();\n      }\n    }\n    /**\n     * Due to [a bug in Chromium](https://bugs.chromium.org/p/chromium/issues/detail?id=1377842), VP9 streams often\n    \t * lack color space information. This method patches in that information.\n     */\n    fixVP9ColorSpace(trackData, chunk) {\n      if (chunk.type !== \"key\") return;\n      if (!trackData.info.decoderConfig.colorSpace || !trackData.info.decoderConfig.colorSpace.matrix) return;\n      const bitstream = new Bitstream(chunk.data);\n      bitstream.skipBits(2);\n      const profileLowBit = bitstream.readBits(1);\n      const profileHighBit = bitstream.readBits(1);\n      const profile = (profileHighBit << 1) + profileLowBit;\n      if (profile === 3) bitstream.skipBits(1);\n      const showExistingFrame = bitstream.readBits(1);\n      if (showExistingFrame) return;\n      const frameType = bitstream.readBits(1);\n      if (frameType !== 0) return;\n      bitstream.skipBits(2);\n      const syncCode = bitstream.readBits(24);\n      if (syncCode !== 4817730) return;\n      if (profile >= 2) bitstream.skipBits(1);\n      const colorSpaceID = {\n        rgb: 7,\n        bt709: 2,\n        bt470bg: 1,\n        smpte170m: 3\n      }[trackData.info.decoderConfig.colorSpace.matrix];\n      writeBits(chunk.data, bitstream.pos, bitstream.pos + 3, colorSpaceID);\n    }\n    /** Converts a read-only external chunk into an internal one for easier use. */\n    createInternalChunk(data, timestamp, duration, type, additions = null) {\n      const internalChunk = {\n        data,\n        type,\n        timestamp,\n        duration,\n        additions\n      };\n      return internalChunk;\n    }\n    /** Writes a block containing media data to the file. */\n    writeBlock(trackData, chunk) {\n      if (!this.segment) {\n        this.createSegment();\n      }\n      const msTimestamp = Math.round(1e3 * chunk.timestamp);\n      const keyFrameQueuedEverywhere = this.trackDatas.every((otherTrackData) => {\n        if (trackData === otherTrackData) {\n          return chunk.type === \"key\";\n        }\n        const firstQueuedSample = otherTrackData.chunkQueue[0];\n        if (firstQueuedSample) {\n          return firstQueuedSample.type === \"key\";\n        }\n        return otherTrackData.track.source._closed;\n      });\n      let shouldCreateNewCluster = false;\n      if (!this.currentCluster) {\n        shouldCreateNewCluster = true;\n      } else {\n        assert(this.currentClusterStartMsTimestamp !== null);\n        assert(this.currentClusterMaxMsTimestamp !== null);\n        const relativeTimestamp2 = msTimestamp - this.currentClusterStartMsTimestamp;\n        shouldCreateNewCluster = keyFrameQueuedEverywhere && msTimestamp > this.currentClusterMaxMsTimestamp && relativeTimestamp2 >= 1e3 * (this.format._options.minimumClusterDuration ?? 1) || relativeTimestamp2 > MAX_CLUSTER_TIMESTAMP_MS;\n      }\n      if (shouldCreateNewCluster) {\n        this.createNewCluster(msTimestamp);\n      }\n      const relativeTimestamp = msTimestamp - this.currentClusterStartMsTimestamp;\n      if (relativeTimestamp < MIN_CLUSTER_TIMESTAMP_MS) {\n        return;\n      }\n      const prelude = new Uint8Array(4);\n      const view2 = new DataView(prelude.buffer);\n      view2.setUint8(0, 128 | trackData.track.id);\n      view2.setInt16(1, relativeTimestamp, false);\n      const msDuration = Math.round(1e3 * chunk.duration);\n      if (!chunk.additions) {\n        view2.setUint8(3, Number(chunk.type === \"key\") << 7);\n        const simpleBlock = { id: 163 /* SimpleBlock */, data: [\n          prelude,\n          chunk.data\n        ] };\n        this.ebmlWriter.writeEBML(simpleBlock);\n      } else {\n        const blockGroup = { id: 160 /* BlockGroup */, data: [\n          { id: 161 /* Block */, data: [\n            prelude,\n            chunk.data\n          ] },\n          chunk.type === \"delta\" ? {\n            id: 251 /* ReferenceBlock */,\n            data: new EBMLSignedInt(trackData.lastWrittenMsTimestamp - msTimestamp)\n          } : null,\n          chunk.additions ? { id: 30113 /* BlockAdditions */, data: [\n            { id: 166 /* BlockMore */, data: [\n              { id: 238 /* BlockAddID */, data: 1 },\n              // Some players expect BlockAddID to come first\n              { id: 165 /* BlockAdditional */, data: chunk.additions }\n            ] }\n          ] } : null,\n          msDuration > 0 ? { id: 155 /* BlockDuration */, data: msDuration } : null\n        ] };\n        this.ebmlWriter.writeEBML(blockGroup);\n      }\n      this.duration = Math.max(this.duration, msTimestamp + msDuration);\n      trackData.lastWrittenMsTimestamp = msTimestamp;\n      if (!this.trackDatasInCurrentCluster.has(trackData)) {\n        this.trackDatasInCurrentCluster.set(trackData, {\n          firstMsTimestamp: msTimestamp\n        });\n      }\n      this.currentClusterMaxMsTimestamp = Math.max(this.currentClusterMaxMsTimestamp, msTimestamp);\n    }\n    /** Creates a new Cluster element to contain media chunks. */\n    createNewCluster(msTimestamp) {\n      if (this.currentCluster) {\n        this.finalizeCurrentCluster();\n      }\n      if (this.format._options.onCluster) {\n        this.writer.startTrackingWrites();\n      }\n      this.currentCluster = {\n        id: 524531317 /* Cluster */,\n        size: this.format._options.appendOnly ? -1 : CLUSTER_SIZE_BYTES,\n        data: [\n          { id: 231 /* Timestamp */, data: msTimestamp }\n        ]\n      };\n      this.ebmlWriter.writeEBML(this.currentCluster);\n      this.currentClusterStartMsTimestamp = msTimestamp;\n      this.currentClusterMaxMsTimestamp = msTimestamp;\n      this.trackDatasInCurrentCluster.clear();\n    }\n    finalizeCurrentCluster() {\n      assert(this.currentCluster);\n      if (!this.format._options.appendOnly) {\n        const clusterSize = this.writer.getPos() - this.ebmlWriter.dataOffsets.get(this.currentCluster);\n        const endPos = this.writer.getPos();\n        this.writer.seek(this.ebmlWriter.offsets.get(this.currentCluster) + 4);\n        this.ebmlWriter.writeVarInt(clusterSize, CLUSTER_SIZE_BYTES);\n        this.writer.seek(endPos);\n      }\n      if (this.format._options.onCluster) {\n        assert(this.currentClusterStartMsTimestamp !== null);\n        const { data, start } = this.writer.stopTrackingWrites();\n        this.format._options.onCluster(data, start, this.currentClusterStartMsTimestamp / 1e3);\n      }\n      const clusterOffsetFromSegment = this.ebmlWriter.offsets.get(this.currentCluster) - this.segmentDataOffset;\n      const groupedByTimestamp = /* @__PURE__ */ new Map();\n      for (const [trackData, { firstMsTimestamp }] of this.trackDatasInCurrentCluster) {\n        if (!groupedByTimestamp.has(firstMsTimestamp)) {\n          groupedByTimestamp.set(firstMsTimestamp, []);\n        }\n        groupedByTimestamp.get(firstMsTimestamp).push(trackData);\n      }\n      const groupedAndSortedByTimestamp = [...groupedByTimestamp.entries()].sort((a, b) => a[0] - b[0]);\n      for (const [msTimestamp, trackDatas] of groupedAndSortedByTimestamp) {\n        assert(this.cues);\n        this.cues.data.push({ id: 187 /* CuePoint */, data: [\n          { id: 179 /* CueTime */, data: msTimestamp },\n          // Create CueTrackPositions for each track that starts at this timestamp\n          ...trackDatas.map((trackData) => {\n            return { id: 183 /* CueTrackPositions */, data: [\n              { id: 247 /* CueTrack */, data: trackData.track.id },\n              { id: 241 /* CueClusterPosition */, data: clusterOffsetFromSegment }\n            ] };\n          })\n        ] });\n      }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-misused-promises\n    async onTrackClose() {\n      const release = await this.mutex.acquire();\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      await this.interleaveChunks();\n      release();\n    }\n    /** Finalizes the file, making it ready for use. Must be called after all media chunks have been added. */\n    async finalize() {\n      const release = await this.mutex.acquire();\n      this.allTracksKnown.resolve();\n      if (!this.segment) {\n        this.createSegment();\n      }\n      await this.interleaveChunks(true);\n      if (this.currentCluster) {\n        this.finalizeCurrentCluster();\n      }\n      assert(this.cues);\n      this.ebmlWriter.writeEBML(this.cues);\n      if (!this.format._options.appendOnly) {\n        const endPos = this.writer.getPos();\n        const segmentSize = this.writer.getPos() - this.segmentDataOffset;\n        this.writer.seek(this.ebmlWriter.offsets.get(this.segment) + 4);\n        this.ebmlWriter.writeVarInt(segmentSize, SEGMENT_SIZE_BYTES);\n        this.segmentDuration.data = new EBMLFloat64(this.duration);\n        this.writer.seek(this.ebmlWriter.offsets.get(this.segmentDuration));\n        this.ebmlWriter.writeEBML(this.segmentDuration);\n        assert(this.seekHead);\n        this.writer.seek(this.ebmlWriter.offsets.get(this.seekHead));\n        this.maybeCreateSeekHead(true);\n        this.ebmlWriter.writeEBML(this.seekHead);\n        this.writer.seek(endPos);\n      }\n      release();\n    }\n  };\n\n  // src/mp3/mp3-writer.ts\n  var Mp3Writer = class {\n    constructor(writer) {\n      this.writer = writer;\n      this.helper = new Uint8Array(8);\n      this.helperView = new DataView(this.helper.buffer);\n    }\n    writeU32(value) {\n      this.helperView.setUint32(0, value, false);\n      this.writer.write(this.helper.subarray(0, 4));\n    }\n    writeXingFrame(data) {\n      const startPos = this.writer.getPos();\n      const firstByte = 255;\n      const secondByte = 224 | data.mpegVersionId << 3 | data.layer << 1;\n      let lowSamplingFrequency;\n      if (data.mpegVersionId & 2) {\n        lowSamplingFrequency = data.mpegVersionId & 1 ? 0 : 1;\n      } else {\n        lowSamplingFrequency = 1;\n      }\n      const padding = 0;\n      const neededBytes = 155;\n      let bitrateIndex = -1;\n      const bitrateOffset = lowSamplingFrequency * 16 * 4 + data.layer * 16;\n      for (let i = 0; i < 16; i++) {\n        const kbr = KILOBIT_RATES[bitrateOffset + i];\n        const size = computeMp3FrameSize(lowSamplingFrequency, data.layer, 1e3 * kbr, data.sampleRate, padding);\n        if (size >= neededBytes) {\n          bitrateIndex = i;\n          break;\n        }\n      }\n      if (bitrateIndex === -1) {\n        throw new Error(\"No suitable bitrate found.\");\n      }\n      const thirdByte = bitrateIndex << 4 | data.frequencyIndex << 2 | padding << 1;\n      const fourthByte = data.channel << 6 | data.modeExtension << 4 | data.copyright << 3 | data.original << 2 | data.emphasis;\n      this.helper[0] = firstByte;\n      this.helper[1] = secondByte;\n      this.helper[2] = thirdByte;\n      this.helper[3] = fourthByte;\n      this.writer.write(this.helper.subarray(0, 4));\n      const xingOffset = getXingOffset(data.mpegVersionId, data.channel);\n      this.writer.seek(startPos + xingOffset);\n      this.writeU32(XING);\n      let flags = 0;\n      if (data.frameCount !== null) {\n        flags |= 1;\n      }\n      if (data.fileSize !== null) {\n        flags |= 2;\n      }\n      if (data.toc !== null) {\n        flags |= 4;\n      }\n      this.writeU32(flags);\n      this.writeU32(data.frameCount ?? 0);\n      this.writeU32(data.fileSize ?? 0);\n      this.writer.write(data.toc ?? new Uint8Array(100));\n      const kilobitRate = KILOBIT_RATES[bitrateOffset + bitrateIndex];\n      const frameSize = computeMp3FrameSize(\n        lowSamplingFrequency,\n        data.layer,\n        1e3 * kilobitRate,\n        data.sampleRate,\n        padding\n      );\n      this.writer.seek(startPos + frameSize);\n    }\n  };\n\n  // src/mp3/mp3-muxer.ts\n  var Mp3Muxer = class extends Muxer {\n    constructor(output, format) {\n      super(output);\n      this.xingFrameData = null;\n      this.frameCount = 0;\n      this.framePositions = [];\n      this.xingFramePos = null;\n      this.format = format;\n      this.writer = output._writer;\n      this.mp3Writer = new Mp3Writer(output._writer);\n    }\n    async start() {\n      if (!metadataTagsAreEmpty(this.output._metadataTags)) {\n        const id3Writer = new Id3V2Writer(this.writer);\n        id3Writer.writeId3V2Tag(this.output._metadataTags);\n      }\n    }\n    async getMimeType() {\n      return \"audio/mpeg\";\n    }\n    async addEncodedVideoPacket() {\n      throw new Error(\"MP3 does not support video.\");\n    }\n    async addEncodedAudioPacket(track, packet) {\n      const release = await this.mutex.acquire();\n      try {\n        const writeXingHeader = this.format._options.xingHeader !== false;\n        if (!this.xingFrameData && writeXingHeader) {\n          const view2 = toDataView(packet.data);\n          if (view2.byteLength < 4) {\n            throw new Error(\"Invalid MP3 header in sample.\");\n          }\n          const word = view2.getUint32(0, false);\n          const header = readMp3FrameHeader(word, null).header;\n          if (!header) {\n            throw new Error(\"Invalid MP3 header in sample.\");\n          }\n          const xingOffset = getXingOffset(header.mpegVersionId, header.channel);\n          if (view2.byteLength >= xingOffset + 4) {\n            const word2 = view2.getUint32(xingOffset, false);\n            const isXing = word2 === XING || word2 === INFO;\n            if (isXing) {\n              return;\n            }\n          }\n          this.xingFrameData = {\n            mpegVersionId: header.mpegVersionId,\n            layer: header.layer,\n            frequencyIndex: header.frequencyIndex,\n            sampleRate: header.sampleRate,\n            channel: header.channel,\n            modeExtension: header.modeExtension,\n            copyright: header.copyright,\n            original: header.original,\n            emphasis: header.emphasis,\n            frameCount: null,\n            fileSize: null,\n            toc: null\n          };\n          this.xingFramePos = this.writer.getPos();\n          this.mp3Writer.writeXingFrame(this.xingFrameData);\n          this.frameCount++;\n        }\n        this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === \"key\");\n        this.writer.write(packet.data);\n        this.frameCount++;\n        await this.writer.flush();\n        if (writeXingHeader) {\n          this.framePositions.push(this.writer.getPos());\n        }\n      } finally {\n        release();\n      }\n    }\n    async addSubtitleCue() {\n      throw new Error(\"MP3 does not support subtitles.\");\n    }\n    async finalize() {\n      if (!this.xingFrameData || this.xingFramePos === null) {\n        return;\n      }\n      const release = await this.mutex.acquire();\n      const endPos = this.writer.getPos();\n      this.writer.seek(this.xingFramePos);\n      const toc = new Uint8Array(100);\n      for (let i = 0; i < 100; i++) {\n        const index = Math.floor(this.framePositions.length * (i / 100));\n        assert(index !== -1 && index < this.framePositions.length);\n        const byteOffset = this.framePositions[index];\n        toc[i] = 256 * (byteOffset / endPos);\n      }\n      this.xingFrameData.frameCount = this.frameCount;\n      this.xingFrameData.fileSize = endPos;\n      this.xingFrameData.toc = toc;\n      if (this.format._options.onXingFrame) {\n        this.writer.startTrackingWrites();\n      }\n      this.mp3Writer.writeXingFrame(this.xingFrameData);\n      if (this.format._options.onXingFrame) {\n        const { data, start } = this.writer.stopTrackingWrites();\n        this.format._options.onXingFrame(data, start);\n      }\n      this.writer.seek(endPos);\n      release();\n    }\n  };\n\n  // src/ogg/ogg-muxer.ts\n  var PAGE_SIZE_TARGET = 8192;\n  var OggMuxer = class extends Muxer {\n    constructor(output, format) {\n      super(output);\n      this.trackDatas = [];\n      this.bosPagesWritten = false;\n      this.allTracksKnown = promiseWithResolvers();\n      this.pageBytes = new Uint8Array(MAX_PAGE_SIZE);\n      this.pageView = new DataView(this.pageBytes.buffer);\n      this.format = format;\n      this.writer = output._writer;\n      this.writer.ensureMonotonicity = true;\n    }\n    async start() {\n    }\n    async getMimeType() {\n      await this.allTracksKnown.promise;\n      return buildOggMimeType({\n        codecStrings: this.trackDatas.map((x) => x.codecInfo.codec)\n      });\n    }\n    addEncodedVideoPacket() {\n      throw new Error(\"Video tracks are not supported.\");\n    }\n    getTrackData(track, meta) {\n      const existingTrackData = this.trackDatas.find((td) => td.track === track);\n      if (existingTrackData) {\n        return existingTrackData;\n      }\n      let serialNumber;\n      do {\n        serialNumber = Math.floor(2 ** 32 * Math.random());\n      } while (this.trackDatas.some((td) => td.serialNumber === serialNumber));\n      assert(track.source._codec === \"vorbis\" || track.source._codec === \"opus\");\n      validateAudioChunkMetadata(meta);\n      assert(meta);\n      assert(meta.decoderConfig);\n      const newTrackData = {\n        track,\n        serialNumber,\n        internalSampleRate: track.source._codec === \"opus\" ? OPUS_SAMPLE_RATE : meta.decoderConfig.sampleRate,\n        codecInfo: {\n          codec: track.source._codec,\n          vorbisInfo: null,\n          opusInfo: null\n        },\n        vorbisLastBlocksize: null,\n        packetQueue: [],\n        currentTimestampInSamples: 0,\n        pagesWritten: 0,\n        currentGranulePosition: 0,\n        currentLacingValues: [],\n        currentPageData: [],\n        currentPageSize: 27,\n        currentPageStartsWithFreshPacket: true,\n        currentPageStartTimestampInSamples: 0\n      };\n      this.queueHeaderPackets(newTrackData, meta);\n      this.trackDatas.push(newTrackData);\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      return newTrackData;\n    }\n    queueHeaderPackets(trackData, meta) {\n      assert(meta.decoderConfig);\n      if (trackData.track.source._codec === \"vorbis\") {\n        assert(meta.decoderConfig.description);\n        const bytes2 = toUint8Array(meta.decoderConfig.description);\n        if (bytes2[0] !== 2) {\n          throw new TypeError(\"First byte of Vorbis decoder description must be 2.\");\n        }\n        let pos = 1;\n        const readPacketLength = () => {\n          let length = 0;\n          while (true) {\n            const value = bytes2[pos++];\n            if (value === void 0) {\n              throw new TypeError(\"Vorbis decoder description is too short.\");\n            }\n            length += value;\n            if (value < 255) {\n              return length;\n            }\n          }\n        };\n        const identificationHeaderLength = readPacketLength();\n        const commentHeaderLength = readPacketLength();\n        const setupHeaderLength = bytes2.length - pos;\n        if (setupHeaderLength <= 0) {\n          throw new TypeError(\"Vorbis decoder description is too short.\");\n        }\n        const identificationHeader = bytes2.subarray(pos, pos += identificationHeaderLength);\n        pos += commentHeaderLength;\n        const setupHeader = bytes2.subarray(pos);\n        const commentHeaderHeader = new Uint8Array(7);\n        commentHeaderHeader[0] = 3;\n        commentHeaderHeader[1] = 118;\n        commentHeaderHeader[2] = 111;\n        commentHeaderHeader[3] = 114;\n        commentHeaderHeader[4] = 98;\n        commentHeaderHeader[5] = 105;\n        commentHeaderHeader[6] = 115;\n        const commentHeader = createVorbisComments(commentHeaderHeader, this.output._metadataTags, true);\n        trackData.packetQueue.push({\n          data: identificationHeader,\n          timestampInSamples: 0,\n          durationInSamples: 0,\n          forcePageFlush: true\n        }, {\n          data: commentHeader,\n          timestampInSamples: 0,\n          durationInSamples: 0,\n          forcePageFlush: false\n        }, {\n          data: setupHeader,\n          timestampInSamples: 0,\n          durationInSamples: 0,\n          forcePageFlush: true\n          // The last header packet must flush the page\n        });\n        const view2 = toDataView(identificationHeader);\n        const blockSizeByte = view2.getUint8(28);\n        trackData.codecInfo.vorbisInfo = {\n          blocksizes: [\n            1 << (blockSizeByte & 15),\n            1 << (blockSizeByte >> 4)\n          ],\n          modeBlockflags: parseModesFromVorbisSetupPacket(setupHeader).modeBlockflags\n        };\n      } else if (trackData.track.source._codec === \"opus\") {\n        if (!meta.decoderConfig.description) {\n          throw new TypeError(\"For Ogg, Opus decoder description is required.\");\n        }\n        const identificationHeader = toUint8Array(meta.decoderConfig.description);\n        const commentHeaderHeader = new Uint8Array(8);\n        const commentHeaderHeaderView = toDataView(commentHeaderHeader);\n        commentHeaderHeaderView.setUint32(0, 1332770163, false);\n        commentHeaderHeaderView.setUint32(4, 1415669619, false);\n        const commentHeader = createVorbisComments(commentHeaderHeader, this.output._metadataTags, true);\n        trackData.packetQueue.push({\n          data: identificationHeader,\n          timestampInSamples: 0,\n          durationInSamples: 0,\n          forcePageFlush: true\n        }, {\n          data: commentHeader,\n          timestampInSamples: 0,\n          durationInSamples: 0,\n          forcePageFlush: true\n          // The last header packet must flush the page\n        });\n        trackData.codecInfo.opusInfo = {\n          preSkip: parseOpusIdentificationHeader(identificationHeader).preSkip\n        };\n      }\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        const trackData = this.getTrackData(track, meta);\n        this.validateAndNormalizeTimestamp(trackData.track, packet.timestamp, packet.type === \"key\");\n        const currentTimestampInSamples = trackData.currentTimestampInSamples;\n        const { durationInSamples, vorbisBlockSize } = extractSampleMetadata(\n          packet.data,\n          trackData.codecInfo,\n          trackData.vorbisLastBlocksize\n        );\n        trackData.currentTimestampInSamples += durationInSamples;\n        trackData.vorbisLastBlocksize = vorbisBlockSize;\n        trackData.packetQueue.push({\n          data: packet.data,\n          timestampInSamples: currentTimestampInSamples,\n          durationInSamples,\n          forcePageFlush: false\n        });\n        await this.interleavePages();\n      } finally {\n        release();\n      }\n    }\n    addSubtitleCue() {\n      throw new Error(\"Subtitle tracks are not supported.\");\n    }\n    allTracksAreKnown() {\n      for (const track of this.output._tracks) {\n        if (!track.source._closed && !this.trackDatas.some((x) => x.track === track)) {\n          return false;\n        }\n      }\n      return true;\n    }\n    async interleavePages(isFinalCall = false) {\n      if (!this.bosPagesWritten) {\n        if (!this.allTracksAreKnown() && !isFinalCall) {\n          return;\n        }\n        for (const trackData of this.trackDatas) {\n          while (trackData.packetQueue.length > 0) {\n            const packet = trackData.packetQueue.shift();\n            this.writePacket(trackData, packet, false);\n            if (packet.forcePageFlush) {\n              break;\n            }\n          }\n        }\n        this.bosPagesWritten = true;\n      }\n      outer:\n        while (true) {\n          let trackWithMinTimestamp = null;\n          let minTimestamp = Infinity;\n          for (const trackData of this.trackDatas) {\n            if (!isFinalCall && trackData.packetQueue.length <= 1 && !trackData.track.source._closed) {\n              break outer;\n            }\n            if (trackData.packetQueue.length > 0 && trackData.packetQueue[0].timestampInSamples < minTimestamp) {\n              trackWithMinTimestamp = trackData;\n              minTimestamp = trackData.packetQueue[0].timestampInSamples;\n            }\n          }\n          if (!trackWithMinTimestamp) {\n            break;\n          }\n          const packet = trackWithMinTimestamp.packetQueue.shift();\n          const isFinalPacket = trackWithMinTimestamp.packetQueue.length === 0;\n          this.writePacket(trackWithMinTimestamp, packet, isFinalPacket);\n        }\n      if (!isFinalCall) {\n        await this.writer.flush();\n      }\n    }\n    writePacket(trackData, packet, isFinalPacket) {\n      const packetEndTimestampInSamples = packet.timestampInSamples + packet.durationInSamples;\n      if (this.format._options.maximumPageDuration !== void 0) {\n        const maxDurationInSamples = this.format._options.maximumPageDuration * trackData.internalSampleRate;\n        if (trackData.currentLacingValues.length > 0 && packetEndTimestampInSamples - trackData.currentPageStartTimestampInSamples > maxDurationInSamples) {\n          this.writePage(trackData, false);\n        }\n      }\n      let remainingLength = packet.data.length;\n      let dataStartOffset = 0;\n      let dataOffset = 0;\n      while (true) {\n        if (trackData.currentLacingValues.length === 0 && dataStartOffset > 0) {\n          trackData.currentPageStartsWithFreshPacket = false;\n        }\n        const segmentSize = Math.min(255, remainingLength);\n        trackData.currentLacingValues.push(segmentSize);\n        trackData.currentPageSize++;\n        dataOffset += segmentSize;\n        const segmentIsLastOfPacket = remainingLength < 255;\n        if (trackData.currentLacingValues.length === 255) {\n          const slice2 = packet.data.subarray(dataStartOffset, dataOffset);\n          dataStartOffset = dataOffset;\n          trackData.currentPageData.push(slice2);\n          trackData.currentPageSize += slice2.length;\n          this.writePage(trackData, isFinalPacket && segmentIsLastOfPacket);\n          if (segmentIsLastOfPacket) {\n            return;\n          }\n        }\n        if (segmentIsLastOfPacket) {\n          break;\n        }\n        remainingLength -= 255;\n      }\n      const slice = packet.data.subarray(dataStartOffset);\n      trackData.currentPageData.push(slice);\n      trackData.currentPageSize += slice.length;\n      trackData.currentGranulePosition = packetEndTimestampInSamples;\n      if (trackData.currentPageSize >= PAGE_SIZE_TARGET || packet.forcePageFlush) {\n        this.writePage(trackData, isFinalPacket);\n      }\n    }\n    writePage(trackData, isEos) {\n      this.pageView.setUint32(0, OGGS, true);\n      this.pageView.setUint8(4, 0);\n      let headerType = 0;\n      if (!trackData.currentPageStartsWithFreshPacket) {\n        headerType |= 1;\n      }\n      if (trackData.pagesWritten === 0) {\n        headerType |= 2;\n      }\n      if (isEos) {\n        headerType |= 4;\n      }\n      this.pageView.setUint8(5, headerType);\n      const granulePosition = trackData.currentLacingValues.every((x) => x === 255) ? -1 : trackData.currentGranulePosition;\n      setInt64(this.pageView, 6, granulePosition, true);\n      this.pageView.setUint32(14, trackData.serialNumber, true);\n      this.pageView.setUint32(18, trackData.pagesWritten, true);\n      this.pageView.setUint32(22, 0, true);\n      this.pageView.setUint8(26, trackData.currentLacingValues.length);\n      this.pageBytes.set(trackData.currentLacingValues, 27);\n      let pos = 27 + trackData.currentLacingValues.length;\n      for (const data of trackData.currentPageData) {\n        this.pageBytes.set(data, pos);\n        pos += data.length;\n      }\n      const slice = this.pageBytes.subarray(0, pos);\n      const crc = computeOggPageCrc(slice);\n      this.pageView.setUint32(22, crc, true);\n      trackData.pagesWritten++;\n      trackData.currentLacingValues.length = 0;\n      trackData.currentPageData.length = 0;\n      trackData.currentPageSize = 27;\n      trackData.currentPageStartsWithFreshPacket = true;\n      trackData.currentPageStartTimestampInSamples = trackData.currentGranulePosition;\n      if (this.format._options.onPage) {\n        this.writer.startTrackingWrites();\n      }\n      this.writer.write(slice);\n      if (this.format._options.onPage) {\n        const { data, start } = this.writer.stopTrackingWrites();\n        this.format._options.onPage(data, start, trackData.track.source);\n      }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-misused-promises\n    async onTrackClose() {\n      const release = await this.mutex.acquire();\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      await this.interleavePages();\n      release();\n    }\n    async finalize() {\n      const release = await this.mutex.acquire();\n      this.allTracksKnown.resolve();\n      await this.interleavePages(true);\n      for (const trackData of this.trackDatas) {\n        if (trackData.currentLacingValues.length > 0) {\n          this.writePage(trackData, true);\n        }\n      }\n      release();\n    }\n  };\n\n  // src/mpeg-ts/mpeg-ts-muxer.ts\n  var PAT_PID = 0;\n  var PMT_PID = 4096;\n  var FIRST_TRACK_PID = 256;\n  var VIDEO_STREAM_ID_BASE = 224;\n  var AUDIO_STREAM_ID_BASE = 192;\n  var AVC_AUD_NAL = new Uint8Array([9, 240]);\n  var HEVC_AUD_NAL = new Uint8Array([70, 1]);\n  var MpegTsMuxer = class extends Muxer {\n    constructor(output, format) {\n      super(output);\n      this.trackDatas = [];\n      this.tablesWritten = false;\n      this.continuityCounters = /* @__PURE__ */ new Map();\n      this.packetBuffer = new Uint8Array(TS_PACKET_SIZE);\n      this.packetView = toDataView(this.packetBuffer);\n      this.allTracksKnown = promiseWithResolvers();\n      this.videoTrackIndex = 0;\n      this.audioTrackIndex = 0;\n      this.pesHeaderBuffer = new Uint8Array(14);\n      this.pesHeaderView = toDataView(this.pesHeaderBuffer);\n      this.ptsBitstream = new Bitstream(this.pesHeaderBuffer.subarray(9, 14));\n      this.adaptationFieldBuffer = new Uint8Array(184);\n      this.payloadBuffer = new Uint8Array(184);\n      this.format = format;\n      this.writer = output._writer;\n      this.writer.ensureMonotonicity = true;\n    }\n    async start() {\n    }\n    async getMimeType() {\n      await this.allTracksKnown.promise;\n      return buildMpegTsMimeType(this.trackDatas.map((x) => x.codecString));\n    }\n    getVideoTrackData(track, meta) {\n      const existingTrackData = this.trackDatas.find((x) => x.track === track);\n      if (existingTrackData) {\n        return existingTrackData;\n      }\n      validateVideoChunkMetadata(meta);\n      assert(meta?.decoderConfig);\n      const codec = track.source._codec;\n      assert(codec === \"avc\" || codec === \"hevc\");\n      const streamType = codec === \"avc\" ? 27 /* AVC */ : 36 /* HEVC */;\n      const pid = FIRST_TRACK_PID + this.trackDatas.length;\n      const streamId = VIDEO_STREAM_ID_BASE + this.videoTrackIndex++;\n      const newTrackData = {\n        track,\n        pid,\n        streamType,\n        streamId,\n        codecString: meta.decoderConfig.codec,\n        packetQueue: [],\n        inputIsAnnexB: null,\n        inputIsAdts: null,\n        avcDecoderConfig: null,\n        hevcDecoderConfig: null,\n        adtsHeader: null,\n        adtsHeaderBitstream: null,\n        firstPacketWritten: false\n      };\n      this.trackDatas.push(newTrackData);\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      return newTrackData;\n    }\n    getAudioTrackData(track, meta) {\n      const existingTrackData = this.trackDatas.find((x) => x.track === track);\n      if (existingTrackData) {\n        return existingTrackData;\n      }\n      validateAudioChunkMetadata(meta);\n      assert(meta?.decoderConfig);\n      const codec = track.source._codec;\n      assert(codec === \"aac\" || codec === \"mp3\");\n      const streamType = codec === \"aac\" ? 15 /* AAC */ : 3 /* MP3_MPEG1 */;\n      const pid = FIRST_TRACK_PID + this.trackDatas.length;\n      const streamId = AUDIO_STREAM_ID_BASE + this.audioTrackIndex++;\n      const newTrackData = {\n        track,\n        pid,\n        streamType,\n        streamId,\n        codecString: meta.decoderConfig.codec,\n        packetQueue: [],\n        inputIsAnnexB: null,\n        inputIsAdts: null,\n        avcDecoderConfig: null,\n        hevcDecoderConfig: null,\n        adtsHeader: null,\n        adtsHeaderBitstream: null,\n        firstPacketWritten: false\n      };\n      this.trackDatas.push(newTrackData);\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      return newTrackData;\n    }\n    async addEncodedVideoPacket(track, packet, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        const trackData = this.getVideoTrackData(track, meta);\n        const timestamp = this.validateAndNormalizeTimestamp(\n          trackData.track,\n          packet.timestamp,\n          packet.type === \"key\"\n        );\n        const preparedData = this.prepareVideoPacket(trackData, packet, meta);\n        trackData.packetQueue.push({\n          data: preparedData,\n          timestamp,\n          isKeyframe: packet.type === \"key\"\n        });\n        await this.interleavePackets();\n      } finally {\n        release();\n      }\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        const trackData = this.getAudioTrackData(track, meta);\n        const timestamp = this.validateAndNormalizeTimestamp(\n          trackData.track,\n          packet.timestamp,\n          packet.type === \"key\"\n        );\n        const preparedData = this.prepareAudioPacket(trackData, packet, meta);\n        trackData.packetQueue.push({\n          data: preparedData,\n          timestamp,\n          isKeyframe: packet.type === \"key\"\n        });\n        await this.interleavePackets();\n      } finally {\n        release();\n      }\n    }\n    async addSubtitleCue() {\n      throw new Error(\"MPEG-TS does not support subtitles.\");\n    }\n    prepareVideoPacket(trackData, packet, meta) {\n      const codec = trackData.track.source._codec;\n      if (trackData.inputIsAnnexB === null) {\n        const description = meta?.decoderConfig?.description;\n        trackData.inputIsAnnexB = !description;\n        if (!trackData.inputIsAnnexB) {\n          const bytes2 = toUint8Array(description);\n          if (codec === \"avc\") {\n            trackData.avcDecoderConfig = deserializeAvcDecoderConfigurationRecord(bytes2);\n          } else {\n            trackData.hevcDecoderConfig = deserializeHevcDecoderConfigurationRecord(bytes2);\n          }\n        }\n      }\n      if (trackData.inputIsAnnexB) {\n        return this.prepareAnnexBVideoPacket(packet.data, codec);\n      } else {\n        return this.prepareLengthPrefixedVideoPacket(trackData, packet, codec);\n      }\n    }\n    prepareAnnexBVideoPacket(data, codec) {\n      const nalUnits = [];\n      for (const loc of iterateNalUnitsInAnnexB(data)) {\n        const nalUnit = data.subarray(loc.offset, loc.offset + loc.length);\n        const isAud = codec === \"avc\" ? extractNalUnitTypeForAvc(nalUnit[0]) === 9 /* AUD */ : extractNalUnitTypeForHevc(nalUnit[0]) === 35 /* AUD_NUT */;\n        if (!isAud) {\n          nalUnits.push(nalUnit);\n        }\n      }\n      const aud = codec === \"avc\" ? AVC_AUD_NAL : HEVC_AUD_NAL;\n      nalUnits.unshift(aud);\n      return concatNalUnitsInAnnexB(nalUnits);\n    }\n    prepareLengthPrefixedVideoPacket(trackData, packet, codec) {\n      const data = packet.data;\n      const lengthSize = codec === \"avc\" ? trackData.avcDecoderConfig.lengthSizeMinusOne + 1 : trackData.hevcDecoderConfig.lengthSizeMinusOne + 1;\n      const nalUnits = [];\n      for (const loc of iterateNalUnitsInLengthPrefixed(data, lengthSize)) {\n        const nalUnit = data.subarray(loc.offset, loc.offset + loc.length);\n        const isAud = codec === \"avc\" ? extractNalUnitTypeForAvc(nalUnit[0]) === 9 /* AUD */ : extractNalUnitTypeForHevc(nalUnit[0]) === 35 /* AUD_NUT */;\n        if (!isAud) {\n          nalUnits.push(nalUnit);\n        }\n      }\n      if (packet.type === \"key\") {\n        if (codec === \"avc\") {\n          const config = trackData.avcDecoderConfig;\n          for (const pps of config.pictureParameterSets) {\n            nalUnits.unshift(pps);\n          }\n          for (const sps of config.sequenceParameterSets) {\n            nalUnits.unshift(sps);\n          }\n        } else {\n          const config = trackData.hevcDecoderConfig;\n          for (const arr of config.arrays) {\n            if (arr.nalUnitType === 34 /* PPS_NUT */) {\n              for (const nal of arr.nalUnits) {\n                nalUnits.unshift(nal);\n              }\n            }\n          }\n          for (const arr of config.arrays) {\n            if (arr.nalUnitType === 33 /* SPS_NUT */) {\n              for (const nal of arr.nalUnits) {\n                nalUnits.unshift(nal);\n              }\n            }\n          }\n          for (const arr of config.arrays) {\n            if (arr.nalUnitType === 32 /* VPS_NUT */) {\n              for (const nal of arr.nalUnits) {\n                nalUnits.unshift(nal);\n              }\n            }\n          }\n        }\n      }\n      const aud = codec === \"avc\" ? AVC_AUD_NAL : HEVC_AUD_NAL;\n      nalUnits.unshift(aud);\n      return concatNalUnitsInAnnexB(nalUnits);\n    }\n    prepareAudioPacket(trackData, packet, meta) {\n      const codec = trackData.track.source._codec;\n      if (codec === \"mp3\") {\n        return packet.data;\n      }\n      if (trackData.inputIsAdts === null) {\n        const description = meta?.decoderConfig?.description;\n        trackData.inputIsAdts = !description;\n        if (!trackData.inputIsAdts) {\n          const config = parseAacAudioSpecificConfig(toUint8Array(description));\n          const template = buildAdtsHeaderTemplate(config);\n          trackData.adtsHeader = template.header;\n          trackData.adtsHeaderBitstream = template.bitstream;\n        }\n      }\n      if (trackData.inputIsAdts) {\n        return packet.data;\n      }\n      assert(trackData.adtsHeader);\n      assert(trackData.adtsHeaderBitstream);\n      const header = trackData.adtsHeader;\n      const frameLength = packet.data.byteLength + header.byteLength;\n      writeAdtsFrameLength(trackData.adtsHeaderBitstream, frameLength);\n      const result = new Uint8Array(frameLength);\n      result.set(header, 0);\n      result.set(packet.data, header.byteLength);\n      return result;\n    }\n    allTracksAreKnown() {\n      for (const track of this.output._tracks) {\n        if (!track.source._closed && !this.trackDatas.some((x) => x.track === track)) {\n          return false;\n        }\n      }\n      return true;\n    }\n    async interleavePackets(isFinalCall = false) {\n      if (!this.tablesWritten) {\n        if (!this.allTracksAreKnown() && !isFinalCall) {\n          return;\n        }\n        this.writeTables();\n      }\n      outer:\n        while (true) {\n          let trackWithMinTimestamp = null;\n          let minTimestamp = Infinity;\n          for (const trackData of this.trackDatas) {\n            if (!isFinalCall && trackData.packetQueue.length === 0 && !trackData.track.source._closed) {\n              break outer;\n            }\n            if (trackData.packetQueue.length > 0 && trackData.packetQueue[0].timestamp < minTimestamp) {\n              trackWithMinTimestamp = trackData;\n              minTimestamp = trackData.packetQueue[0].timestamp;\n            }\n          }\n          if (!trackWithMinTimestamp) {\n            break;\n          }\n          const queuedPacket = trackWithMinTimestamp.packetQueue.shift();\n          this.writePesPacket(trackWithMinTimestamp, queuedPacket);\n        }\n      if (!isFinalCall) {\n        await this.writer.flush();\n      }\n    }\n    writeTables() {\n      assert(!this.tablesWritten);\n      this.writePsiSection(PAT_PID, PAT_SECTION);\n      this.writePsiSection(PMT_PID, buildPmt(this.trackDatas));\n      this.tablesWritten = true;\n    }\n    writePsiSection(pid, section) {\n      let offset = 0;\n      let isFirst = true;\n      while (offset < section.length) {\n        const pointerFieldSize = isFirst ? 1 : 0;\n        const availablePayload = 184 - pointerFieldSize;\n        const remainingData = section.length - offset;\n        const chunkSize = Math.min(availablePayload, remainingData);\n        let payload;\n        if (isFirst) {\n          payload = this.payloadBuffer.subarray(0, 1 + chunkSize);\n          payload[0] = 0;\n          payload.set(section.subarray(offset, offset + chunkSize), 1);\n        } else {\n          payload = section.subarray(offset, offset + chunkSize);\n        }\n        this.writeTsPacket(pid, isFirst, null, payload);\n        offset += chunkSize;\n        isFirst = false;\n      }\n    }\n    writePesPacket(trackData, queuedPacket) {\n      const pesView = this.pesHeaderView;\n      setUint24(pesView, 0, 1, false);\n      this.pesHeaderBuffer[3] = trackData.streamId;\n      const pesPacketLength = trackData.track.type === \"video\" ? 0 : Math.min(8 + queuedPacket.data.length, 65535);\n      pesView.setUint16(4, pesPacketLength, false);\n      pesView.setUint8(6, 132);\n      pesView.setUint8(7, 128);\n      pesView.setUint8(8, 5);\n      const pts = Math.round(queuedPacket.timestamp * TIMESCALE);\n      this.ptsBitstream.pos = 0;\n      this.ptsBitstream.writeBits(4, 2);\n      this.ptsBitstream.writeBits(3, pts >>> 30 & 7);\n      this.ptsBitstream.writeBits(1, 1);\n      this.ptsBitstream.writeBits(15, pts >>> 15 & 32767);\n      this.ptsBitstream.writeBits(1, 1);\n      this.ptsBitstream.writeBits(15, pts & 32767);\n      this.ptsBitstream.writeBits(1, 1);\n      const totalLength = this.pesHeaderBuffer.length + queuedPacket.data.length;\n      let offset = 0;\n      let isFirstTsPacket = true;\n      while (offset < totalLength) {\n        const pusi = isFirstTsPacket;\n        const remainingData = totalLength - offset;\n        const randomAccessIndicator = isFirstTsPacket && queuedPacket.isKeyframe;\n        const discontinuityIndicator = isFirstTsPacket && !trackData.firstPacketWritten;\n        const basePaddingNeeded = Math.max(0, 184 - remainingData);\n        let adaptationFieldSize;\n        if (randomAccessIndicator || discontinuityIndicator) {\n          adaptationFieldSize = Math.max(2, basePaddingNeeded);\n        } else {\n          adaptationFieldSize = basePaddingNeeded;\n        }\n        let adaptationField = null;\n        if (adaptationFieldSize > 0) {\n          const buf = this.adaptationFieldBuffer;\n          if (adaptationFieldSize === 1) {\n            buf[0] = 0;\n          } else {\n            buf[0] = adaptationFieldSize - 1;\n            buf[1] = Number(discontinuityIndicator) << 7 | Number(randomAccessIndicator) << 6;\n            buf.fill(255, 2, adaptationFieldSize);\n          }\n          adaptationField = buf.subarray(0, adaptationFieldSize);\n        }\n        const payloadSize = Math.min(184 - adaptationFieldSize, remainingData);\n        const payload = this.payloadBuffer.subarray(0, payloadSize);\n        let payloadOffset = 0;\n        if (offset < this.pesHeaderBuffer.length) {\n          const headerBytes = Math.min(this.pesHeaderBuffer.length - offset, payloadSize);\n          payload.set(this.pesHeaderBuffer.subarray(offset, offset + headerBytes), 0);\n          payloadOffset = headerBytes;\n        }\n        const dataStart = Math.max(0, offset - this.pesHeaderBuffer.length);\n        const dataEnd = dataStart + (payloadSize - payloadOffset);\n        if (payloadOffset < payloadSize) {\n          payload.set(queuedPacket.data.subarray(dataStart, dataEnd), payloadOffset);\n        }\n        this.writeTsPacket(trackData.pid, pusi, adaptationField, payload);\n        offset += payloadSize;\n        isFirstTsPacket = false;\n      }\n      trackData.firstPacketWritten = true;\n    }\n    writeTsPacket(pid, pusi, adaptationField, payload) {\n      const cc = this.continuityCounters.get(pid) ?? 0;\n      const hasPayload = payload.length > 0;\n      const adaptCtrl = adaptationField ? hasPayload ? 3 : 2 : hasPayload ? 1 : 0;\n      this.packetBuffer[0] = 71;\n      this.packetView.setUint16(1, (pusi ? 16384 : 0) | pid & 8191, false);\n      this.packetBuffer[3] = adaptCtrl << 4 | cc & 15;\n      if (hasPayload) {\n        this.continuityCounters.set(pid, cc + 1 & 15);\n      }\n      let offset = 4;\n      if (adaptationField) {\n        this.packetBuffer.set(adaptationField, offset);\n        offset += adaptationField.length;\n      }\n      this.packetBuffer.set(payload, offset);\n      offset += payload.length;\n      if (offset < TS_PACKET_SIZE) {\n        this.packetBuffer.fill(255, offset);\n      }\n      const startPos = this.writer.getPos();\n      this.writer.write(this.packetBuffer);\n      if (this.format._options.onPacket) {\n        this.format._options.onPacket(this.packetBuffer.slice(), startPos);\n      }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-misused-promises\n    async onTrackClose() {\n      const release = await this.mutex.acquire();\n      if (this.allTracksAreKnown()) {\n        this.allTracksKnown.resolve();\n      }\n      await this.interleavePackets();\n      release();\n    }\n    async finalize() {\n      const release = await this.mutex.acquire();\n      this.allTracksKnown.resolve();\n      await this.interleavePackets(true);\n      release();\n    }\n  };\n  var MPEG_TS_CRC_POLYNOMIAL = 79764919;\n  var MPEG_TS_CRC_TABLE = new Uint32Array(256);\n  for (let n = 0; n < 256; n++) {\n    let crc = n << 24;\n    for (let k = 0; k < 8; k++) {\n      crc = crc & 2147483648 ? crc << 1 ^ MPEG_TS_CRC_POLYNOMIAL : crc << 1;\n    }\n    MPEG_TS_CRC_TABLE[n] = crc >>> 0 & 4294967295;\n  }\n  var computeMpegTsCrc32 = (data) => {\n    let crc = 4294967295;\n    for (let i = 0; i < data.length; i++) {\n      const byte = data[i];\n      crc = (crc << 8 ^ MPEG_TS_CRC_TABLE[crc >>> 24 ^ byte]) >>> 0;\n    }\n    return crc;\n  };\n  var PAT_SECTION = new Uint8Array(16);\n  {\n    const view2 = toDataView(PAT_SECTION);\n    PAT_SECTION[0] = 0;\n    view2.setUint16(1, 45069, false);\n    view2.setUint16(3, 1, false);\n    PAT_SECTION[5] = 193;\n    PAT_SECTION[6] = 0;\n    PAT_SECTION[7] = 0;\n    view2.setUint16(8, 1, false);\n    view2.setUint16(10, 57344 | PMT_PID & 8191, false);\n    view2.setUint32(12, computeMpegTsCrc32(PAT_SECTION.subarray(0, 12)), false);\n  }\n  var buildPmt = (trackDatas) => {\n    const sectionLength = 9 + trackDatas.length * 5 + 4;\n    const section = new Uint8Array(3 + sectionLength - 4);\n    const view2 = toDataView(section);\n    section[0] = 2;\n    view2.setUint16(1, 45056 | sectionLength & 4095, false);\n    view2.setUint16(3, 1, false);\n    section[5] = 193;\n    section[6] = 0;\n    section[7] = 0;\n    view2.setUint16(8, 57344 | 8191, false);\n    view2.setUint16(10, 61440, false);\n    let offset = 12;\n    for (const trackData of trackDatas) {\n      section[offset++] = trackData.streamType;\n      view2.setUint16(offset, 57344 | trackData.pid & 8191, false);\n      offset += 2;\n      view2.setUint16(offset, 61440, false);\n      offset += 2;\n    }\n    const crc = computeMpegTsCrc32(section);\n    const result = new Uint8Array(section.length + 4);\n    result.set(section, 0);\n    toDataView(result).setUint32(section.length, crc, false);\n    return result;\n  };\n\n  // src/wave/riff-writer.ts\n  var RiffWriter = class {\n    constructor(writer) {\n      this.writer = writer;\n      this.helper = new Uint8Array(8);\n      this.helperView = new DataView(this.helper.buffer);\n    }\n    writeU16(value) {\n      this.helperView.setUint16(0, value, true);\n      this.writer.write(this.helper.subarray(0, 2));\n    }\n    writeU32(value) {\n      this.helperView.setUint32(0, value, true);\n      this.writer.write(this.helper.subarray(0, 4));\n    }\n    writeU64(value) {\n      this.helperView.setUint32(0, value, true);\n      this.helperView.setUint32(4, Math.floor(value / 2 ** 32), true);\n      this.writer.write(this.helper);\n    }\n    writeAscii(text) {\n      this.writer.write(new TextEncoder().encode(text));\n    }\n  };\n\n  // src/wave/wave-muxer.ts\n  var WaveMuxer = class extends Muxer {\n    constructor(output, format) {\n      super(output);\n      this.headerWritten = false;\n      this.dataSize = 0;\n      this.sampleRate = null;\n      this.sampleCount = 0;\n      this.riffSizePos = null;\n      this.dataSizePos = null;\n      this.ds64RiffSizePos = null;\n      this.ds64DataSizePos = null;\n      this.ds64SampleCountPos = null;\n      this.format = format;\n      this.writer = output._writer;\n      this.riffWriter = new RiffWriter(output._writer);\n      this.isRf64 = !!format._options.large;\n    }\n    async start() {\n    }\n    async getMimeType() {\n      return \"audio/wav\";\n    }\n    async addEncodedVideoPacket() {\n      throw new Error(\"WAVE does not support video.\");\n    }\n    async addEncodedAudioPacket(track, packet, meta) {\n      const release = await this.mutex.acquire();\n      try {\n        if (!this.headerWritten) {\n          validateAudioChunkMetadata(meta);\n          assert(meta);\n          assert(meta.decoderConfig);\n          this.writeHeader(track, meta.decoderConfig);\n          this.sampleRate = meta.decoderConfig.sampleRate;\n          this.headerWritten = true;\n        }\n        this.validateAndNormalizeTimestamp(track, packet.timestamp, packet.type === \"key\");\n        if (!this.isRf64 && this.writer.getPos() + packet.data.byteLength >= 2 ** 32) {\n          throw new Error(\n            \"Adding more audio data would exceed the maximum RIFF size of 4 GiB. To write larger files, use RF64 by setting `large: true` in the WavOutputFormatOptions.\"\n          );\n        }\n        this.writer.write(packet.data);\n        this.dataSize += packet.data.byteLength;\n        this.sampleCount += Math.round(packet.duration * this.sampleRate);\n        await this.writer.flush();\n      } finally {\n        release();\n      }\n    }\n    async addSubtitleCue() {\n      throw new Error(\"WAVE does not support subtitles.\");\n    }\n    writeHeader(track, config) {\n      if (this.format._options.onHeader) {\n        this.writer.startTrackingWrites();\n      }\n      let format;\n      const codec = track.source._codec;\n      const pcmInfo = parsePcmCodec(codec);\n      if (pcmInfo.dataType === \"ulaw\") {\n        format = 7 /* MULAW */;\n      } else if (pcmInfo.dataType === \"alaw\") {\n        format = 6 /* ALAW */;\n      } else if (pcmInfo.dataType === \"float\") {\n        format = 3 /* IEEE_FLOAT */;\n      } else {\n        format = 1 /* PCM */;\n      }\n      const channels = config.numberOfChannels;\n      const sampleRate = config.sampleRate;\n      const blockSize = pcmInfo.sampleSize * channels;\n      this.riffWriter.writeAscii(this.isRf64 ? \"RF64\" : \"RIFF\");\n      if (this.isRf64) {\n        this.riffWriter.writeU32(4294967295);\n      } else {\n        this.riffSizePos = this.writer.getPos();\n        this.riffWriter.writeU32(0);\n      }\n      this.riffWriter.writeAscii(\"WAVE\");\n      if (this.isRf64) {\n        this.riffWriter.writeAscii(\"ds64\");\n        this.riffWriter.writeU32(28);\n        this.ds64RiffSizePos = this.writer.getPos();\n        this.riffWriter.writeU64(0);\n        this.ds64DataSizePos = this.writer.getPos();\n        this.riffWriter.writeU64(0);\n        this.ds64SampleCountPos = this.writer.getPos();\n        this.riffWriter.writeU64(0);\n        this.riffWriter.writeU32(0);\n      }\n      this.riffWriter.writeAscii(\"fmt \");\n      this.riffWriter.writeU32(16);\n      this.riffWriter.writeU16(format);\n      this.riffWriter.writeU16(channels);\n      this.riffWriter.writeU32(sampleRate);\n      this.riffWriter.writeU32(sampleRate * blockSize);\n      this.riffWriter.writeU16(blockSize);\n      this.riffWriter.writeU16(8 * pcmInfo.sampleSize);\n      if (!metadataTagsAreEmpty(this.output._metadataTags)) {\n        const metadataFormat = this.format._options.metadataFormat ?? \"info\";\n        if (metadataFormat === \"info\") {\n          this.writeInfoChunk(this.output._metadataTags);\n        } else if (metadataFormat === \"id3\") {\n          this.writeId3Chunk(this.output._metadataTags);\n        } else {\n          assertNever(metadataFormat);\n        }\n      }\n      this.riffWriter.writeAscii(\"data\");\n      if (this.isRf64) {\n        this.riffWriter.writeU32(4294967295);\n      } else {\n        this.dataSizePos = this.writer.getPos();\n        this.riffWriter.writeU32(0);\n      }\n      if (this.format._options.onHeader) {\n        const { data, start } = this.writer.stopTrackingWrites();\n        this.format._options.onHeader(data, start);\n      }\n    }\n    writeInfoChunk(metadata) {\n      const startPos = this.writer.getPos();\n      this.riffWriter.writeAscii(\"LIST\");\n      this.riffWriter.writeU32(0);\n      this.riffWriter.writeAscii(\"INFO\");\n      const writtenTags = /* @__PURE__ */ new Set();\n      const writeInfoTag = (tag, value) => {\n        if (!isIso88591Compatible(value)) {\n          console.warn(`Didn't write tag '${tag}' because '${value}' is not ISO 8859-1-compatible.`);\n          return;\n        }\n        const size = value.length + 1;\n        const bytes2 = new Uint8Array(size);\n        for (let i = 0; i < value.length; i++) {\n          bytes2[i] = value.charCodeAt(i);\n        }\n        this.riffWriter.writeAscii(tag);\n        this.riffWriter.writeU32(size);\n        this.writer.write(bytes2);\n        if (size & 1) {\n          this.writer.write(new Uint8Array(1));\n        }\n        writtenTags.add(tag);\n      };\n      for (const { key, value } of keyValueIterator(metadata)) {\n        switch (key) {\n          case \"title\":\n            {\n              writeInfoTag(\"INAM\", value);\n              writtenTags.add(\"INAM\");\n            }\n            ;\n            break;\n          case \"artist\":\n            {\n              writeInfoTag(\"IART\", value);\n              writtenTags.add(\"IART\");\n            }\n            ;\n            break;\n          case \"album\":\n            {\n              writeInfoTag(\"IPRD\", value);\n              writtenTags.add(\"IPRD\");\n            }\n            ;\n            break;\n          case \"trackNumber\":\n            {\n              const string = metadata.tracksTotal !== void 0 ? `${value}/${metadata.tracksTotal}` : value.toString();\n              writeInfoTag(\"ITRK\", string);\n              writtenTags.add(\"ITRK\");\n            }\n            ;\n            break;\n          case \"genre\":\n            {\n              writeInfoTag(\"IGNR\", value);\n              writtenTags.add(\"IGNR\");\n            }\n            ;\n            break;\n          case \"date\":\n            {\n              writeInfoTag(\"ICRD\", value.toISOString().slice(0, 10));\n              writtenTags.add(\"ICRD\");\n            }\n            ;\n            break;\n          case \"comment\":\n            {\n              writeInfoTag(\"ICMT\", value);\n              writtenTags.add(\"ICMT\");\n            }\n            ;\n            break;\n          case \"albumArtist\":\n          case \"discNumber\":\n          case \"tracksTotal\":\n          case \"discsTotal\":\n          case \"description\":\n          case \"lyrics\":\n          case \"images\":\n            {\n            }\n            ;\n            break;\n          case \"raw\":\n            {\n            }\n            ;\n            break;\n          default:\n            assertNever(key);\n        }\n      }\n      if (metadata.raw) {\n        for (const key in metadata.raw) {\n          const value = metadata.raw[key];\n          if (value == null || key.length !== 4 || writtenTags.has(key)) {\n            continue;\n          }\n          if (typeof value === \"string\") {\n            writeInfoTag(key, value);\n          }\n        }\n      }\n      const endPos = this.writer.getPos();\n      const chunkSize = endPos - startPos - 8;\n      this.writer.seek(startPos + 4);\n      this.riffWriter.writeU32(chunkSize);\n      this.writer.seek(endPos);\n      if (chunkSize & 1) {\n        this.writer.write(new Uint8Array(1));\n      }\n    }\n    writeId3Chunk(metadata) {\n      const startPos = this.writer.getPos();\n      this.riffWriter.writeAscii(\"ID3 \");\n      this.riffWriter.writeU32(0);\n      const id3Writer = new Id3V2Writer(this.writer);\n      const id3TagSize = id3Writer.writeId3V2Tag(metadata);\n      const endPos = this.writer.getPos();\n      this.writer.seek(startPos + 4);\n      this.riffWriter.writeU32(id3TagSize);\n      this.writer.seek(endPos);\n      if (id3TagSize & 1) {\n        this.writer.write(new Uint8Array(1));\n      }\n    }\n    async finalize() {\n      const release = await this.mutex.acquire();\n      const endPos = this.writer.getPos();\n      if (this.isRf64) {\n        assert(this.ds64RiffSizePos !== null);\n        this.writer.seek(this.ds64RiffSizePos);\n        this.riffWriter.writeU64(endPos - 8);\n        assert(this.ds64DataSizePos !== null);\n        this.writer.seek(this.ds64DataSizePos);\n        this.riffWriter.writeU64(this.dataSize);\n        assert(this.ds64SampleCountPos !== null);\n        this.writer.seek(this.ds64SampleCountPos);\n        this.riffWriter.writeU64(this.sampleCount);\n      } else {\n        assert(this.riffSizePos !== null);\n        this.writer.seek(this.riffSizePos);\n        this.riffWriter.writeU32(endPos - 8);\n        assert(this.dataSizePos !== null);\n        this.writer.seek(this.dataSizePos);\n        this.riffWriter.writeU32(this.dataSize);\n      }\n      this.writer.seek(endPos);\n      release();\n    }\n  };\n\n  // src/output-format.ts\n  var OutputFormat = class {\n    /** Returns a list of video codecs that this output format can contain. */\n    getSupportedVideoCodecs() {\n      return this.getSupportedCodecs().filter((codec) => VIDEO_CODECS.includes(codec));\n    }\n    /** Returns a list of audio codecs that this output format can contain. */\n    getSupportedAudioCodecs() {\n      return this.getSupportedCodecs().filter((codec) => AUDIO_CODECS.includes(codec));\n    }\n    /** Returns a list of subtitle codecs that this output format can contain. */\n    getSupportedSubtitleCodecs() {\n      return this.getSupportedCodecs().filter((codec) => SUBTITLE_CODECS.includes(codec));\n    }\n    /** @internal */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    _codecUnsupportedHint(codec) {\n      return \"\";\n    }\n  };\n  var IsobmffOutputFormat2 = class extends OutputFormat {\n    /** Internal constructor. */\n    constructor(options = {}) {\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.fastStart !== void 0 && ![false, \"in-memory\", \"reserve\", \"fragmented\"].includes(options.fastStart)) {\n        throw new TypeError(\n          \"options.fastStart, when provided, must be false, 'in-memory', 'reserve', or 'fragmented'.\"\n        );\n      }\n      if (options.minimumFragmentDuration !== void 0 && (!Number.isFinite(options.minimumFragmentDuration) || options.minimumFragmentDuration < 0)) {\n        throw new TypeError(\"options.minimumFragmentDuration, when provided, must be a non-negative number.\");\n      }\n      if (options.onFtyp !== void 0 && typeof options.onFtyp !== \"function\") {\n        throw new TypeError(\"options.onFtyp, when provided, must be a function.\");\n      }\n      if (options.onMoov !== void 0 && typeof options.onMoov !== \"function\") {\n        throw new TypeError(\"options.onMoov, when provided, must be a function.\");\n      }\n      if (options.onMdat !== void 0 && typeof options.onMdat !== \"function\") {\n        throw new TypeError(\"options.onMdat, when provided, must be a function.\");\n      }\n      if (options.onMoof !== void 0 && typeof options.onMoof !== \"function\") {\n        throw new TypeError(\"options.onMoof, when provided, must be a function.\");\n      }\n      if (options.metadataFormat !== void 0 && ![\"mdir\", \"mdta\", \"udta\", \"auto\"].includes(options.metadataFormat)) {\n        throw new TypeError(\n          \"options.metadataFormat, when provided, must be either 'auto', 'mdir', 'mdta', or 'udta'.\"\n        );\n      }\n      super();\n      this._options = options;\n    }\n    getSupportedTrackCounts() {\n      const max = 2 ** 32 - 1;\n      return {\n        video: { min: 0, max },\n        audio: { min: 0, max },\n        subtitle: { min: 0, max },\n        total: { min: 1, max }\n      };\n    }\n    get supportsVideoRotationMetadata() {\n      return true;\n    }\n    /** @internal */\n    _createMuxer(output) {\n      return new IsobmffMuxer2(output, this);\n    }\n  };\n  var Mp4OutputFormat = class extends IsobmffOutputFormat2 {\n    /** Creates a new {@link Mp4OutputFormat} configured with the specified `options`. */\n    constructor(options) {\n      super(options);\n    }\n    /** @internal */\n    get _name() {\n      return \"MP4\";\n    }\n    get fileExtension() {\n      return \".mp4\";\n    }\n    get mimeType() {\n      return \"video/mp4\";\n    }\n    getSupportedCodecs() {\n      return [\n        ...VIDEO_CODECS,\n        ...NON_PCM_AUDIO_CODECS,\n        // These are supported via ISO/IEC 23003-5\n        \"pcm-s16\",\n        \"pcm-s16be\",\n        \"pcm-s24\",\n        \"pcm-s24be\",\n        \"pcm-s32\",\n        \"pcm-s32be\",\n        \"pcm-f32\",\n        \"pcm-f32be\",\n        \"pcm-f64\",\n        \"pcm-f64be\",\n        ...SUBTITLE_CODECS\n      ];\n    }\n    /** @internal */\n    _codecUnsupportedHint(codec) {\n      if (new MovOutputFormat().getSupportedCodecs().includes(codec)) {\n        return \" Switching to MOV will grant support for this codec.\";\n      }\n      return \"\";\n    }\n  };\n  var MovOutputFormat = class extends IsobmffOutputFormat2 {\n    /** Creates a new {@link MovOutputFormat} configured with the specified `options`. */\n    constructor(options) {\n      super(options);\n    }\n    /** @internal */\n    get _name() {\n      return \"MOV\";\n    }\n    get fileExtension() {\n      return \".mov\";\n    }\n    get mimeType() {\n      return \"video/quicktime\";\n    }\n    getSupportedCodecs() {\n      return [\n        ...VIDEO_CODECS,\n        ...AUDIO_CODECS\n      ];\n    }\n    /** @internal */\n    _codecUnsupportedHint(codec) {\n      if (new Mp4OutputFormat().getSupportedCodecs().includes(codec)) {\n        return \" Switching to MP4 will grant support for this codec.\";\n      }\n      return \"\";\n    }\n  };\n  var MkvOutputFormat2 = class extends OutputFormat {\n    /** Creates a new {@link MkvOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.appendOnly !== void 0 && typeof options.appendOnly !== \"boolean\") {\n        throw new TypeError(\"options.appendOnly, when provided, must be a boolean.\");\n      }\n      if (options.minimumClusterDuration !== void 0 && (!Number.isFinite(options.minimumClusterDuration) || options.minimumClusterDuration < 0)) {\n        throw new TypeError(\"options.minimumClusterDuration, when provided, must be a non-negative number.\");\n      }\n      if (options.onEbmlHeader !== void 0 && typeof options.onEbmlHeader !== \"function\") {\n        throw new TypeError(\"options.onEbmlHeader, when provided, must be a function.\");\n      }\n      if (options.onSegmentHeader !== void 0 && typeof options.onSegmentHeader !== \"function\") {\n        throw new TypeError(\"options.onHeader, when provided, must be a function.\");\n      }\n      if (options.onCluster !== void 0 && typeof options.onCluster !== \"function\") {\n        throw new TypeError(\"options.onCluster, when provided, must be a function.\");\n      }\n      super();\n      this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n      return new MatroskaMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n      return \"Matroska\";\n    }\n    getSupportedTrackCounts() {\n      const max = 127;\n      return {\n        video: { min: 0, max },\n        audio: { min: 0, max },\n        subtitle: { min: 0, max },\n        total: { min: 1, max }\n      };\n    }\n    get fileExtension() {\n      return \".mkv\";\n    }\n    get mimeType() {\n      return \"video/x-matroska\";\n    }\n    getSupportedCodecs() {\n      return [\n        ...VIDEO_CODECS,\n        ...NON_PCM_AUDIO_CODECS,\n        ...PCM_AUDIO_CODECS.filter((codec) => ![\"pcm-s8\", \"pcm-f32be\", \"pcm-f64be\", \"ulaw\", \"alaw\"].includes(codec)),\n        ...SUBTITLE_CODECS\n      ];\n    }\n    get supportsVideoRotationMetadata() {\n      return false;\n    }\n  };\n  var WebMOutputFormat = class extends MkvOutputFormat2 {\n    /** Creates a new {@link WebMOutputFormat} configured with the specified `options`. */\n    constructor(options) {\n      super(options);\n    }\n    getSupportedCodecs() {\n      return [\n        ...VIDEO_CODECS.filter((codec) => [\"vp8\", \"vp9\", \"av1\"].includes(codec)),\n        ...AUDIO_CODECS.filter((codec) => [\"opus\", \"vorbis\"].includes(codec)),\n        ...SUBTITLE_CODECS\n      ];\n    }\n    /** @internal */\n    get _name() {\n      return \"WebM\";\n    }\n    get fileExtension() {\n      return \".webm\";\n    }\n    get mimeType() {\n      return \"video/webm\";\n    }\n    /** @internal */\n    _codecUnsupportedHint(codec) {\n      if (new MkvOutputFormat2().getSupportedCodecs().includes(codec)) {\n        return \" Switching to MKV will grant support for this codec.\";\n      }\n      return \"\";\n    }\n  };\n  var Mp3OutputFormat = class extends OutputFormat {\n    /** Creates a new {@link Mp3OutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.xingHeader !== void 0 && typeof options.xingHeader !== \"boolean\") {\n        throw new TypeError(\"options.xingHeader, when provided, must be a boolean.\");\n      }\n      if (options.onXingFrame !== void 0 && typeof options.onXingFrame !== \"function\") {\n        throw new TypeError(\"options.onXingFrame, when provided, must be a function.\");\n      }\n      super();\n      this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n      return new Mp3Muxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n      return \"MP3\";\n    }\n    getSupportedTrackCounts() {\n      return {\n        video: { min: 0, max: 0 },\n        audio: { min: 1, max: 1 },\n        subtitle: { min: 0, max: 0 },\n        total: { min: 1, max: 1 }\n      };\n    }\n    get fileExtension() {\n      return \".mp3\";\n    }\n    get mimeType() {\n      return \"audio/mpeg\";\n    }\n    getSupportedCodecs() {\n      return [\"mp3\"];\n    }\n    get supportsVideoRotationMetadata() {\n      return false;\n    }\n  };\n  var WavOutputFormat = class extends OutputFormat {\n    /** Creates a new {@link WavOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.large !== void 0 && typeof options.large !== \"boolean\") {\n        throw new TypeError(\"options.large, when provided, must be a boolean.\");\n      }\n      if (options.metadataFormat !== void 0 && ![\"info\", \"id3\"].includes(options.metadataFormat)) {\n        throw new TypeError(\"options.metadataFormat, when provided, must be either 'info' or 'id3'.\");\n      }\n      if (options.onHeader !== void 0 && typeof options.onHeader !== \"function\") {\n        throw new TypeError(\"options.onHeader, when provided, must be a function.\");\n      }\n      super();\n      this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n      return new WaveMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n      return \"WAVE\";\n    }\n    getSupportedTrackCounts() {\n      return {\n        video: { min: 0, max: 0 },\n        audio: { min: 1, max: 1 },\n        subtitle: { min: 0, max: 0 },\n        total: { min: 1, max: 1 }\n      };\n    }\n    get fileExtension() {\n      return \".wav\";\n    }\n    get mimeType() {\n      return \"audio/wav\";\n    }\n    getSupportedCodecs() {\n      return [\n        ...PCM_AUDIO_CODECS.filter(\n          (codec) => [\"pcm-s16\", \"pcm-s24\", \"pcm-s32\", \"pcm-f32\", \"pcm-u8\", \"ulaw\", \"alaw\"].includes(codec)\n        )\n      ];\n    }\n    get supportsVideoRotationMetadata() {\n      return false;\n    }\n  };\n  var OggOutputFormat = class extends OutputFormat {\n    /** Creates a new {@link OggOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.maximumPageDuration !== void 0 && (!Number.isFinite(options.maximumPageDuration) || options.maximumPageDuration <= 0)) {\n        throw new TypeError(\"options.maximumPageDuration, when provided, must be a positive number.\");\n      }\n      if (options.onPage !== void 0 && typeof options.onPage !== \"function\") {\n        throw new TypeError(\"options.onPage, when provided, must be a function.\");\n      }\n      super();\n      this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n      return new OggMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n      return \"Ogg\";\n    }\n    getSupportedTrackCounts() {\n      const max = 2 ** 32;\n      return {\n        video: { min: 0, max: 0 },\n        audio: { min: 0, max },\n        subtitle: { min: 0, max: 0 },\n        total: { min: 1, max }\n      };\n    }\n    get fileExtension() {\n      return \".ogg\";\n    }\n    get mimeType() {\n      return \"application/ogg\";\n    }\n    getSupportedCodecs() {\n      return [\n        ...AUDIO_CODECS.filter((codec) => [\"vorbis\", \"opus\"].includes(codec))\n      ];\n    }\n    get supportsVideoRotationMetadata() {\n      return false;\n    }\n  };\n  var AdtsOutputFormat = class extends OutputFormat {\n    /** Creates a new {@link AdtsOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.onFrame !== void 0 && typeof options.onFrame !== \"function\") {\n        throw new TypeError(\"options.onFrame, when provided, must be a function.\");\n      }\n      super();\n      this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n      return new AdtsMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n      return \"ADTS\";\n    }\n    getSupportedTrackCounts() {\n      return {\n        video: { min: 0, max: 0 },\n        audio: { min: 1, max: 1 },\n        subtitle: { min: 0, max: 0 },\n        total: { min: 1, max: 1 }\n      };\n    }\n    get fileExtension() {\n      return \".aac\";\n    }\n    get mimeType() {\n      return \"audio/aac\";\n    }\n    getSupportedCodecs() {\n      return [\"aac\"];\n    }\n    get supportsVideoRotationMetadata() {\n      return false;\n    }\n  };\n  var FlacOutputFormat = class extends OutputFormat {\n    /** Creates a new {@link FlacOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      super();\n      this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n      return new FlacMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n      return \"FLAC\";\n    }\n    getSupportedTrackCounts() {\n      return {\n        video: { min: 0, max: 0 },\n        audio: { min: 1, max: 1 },\n        subtitle: { min: 0, max: 0 },\n        total: { min: 1, max: 1 }\n      };\n    }\n    get fileExtension() {\n      return \".flac\";\n    }\n    get mimeType() {\n      return \"audio/flac\";\n    }\n    getSupportedCodecs() {\n      return [\"flac\"];\n    }\n    get supportsVideoRotationMetadata() {\n      return false;\n    }\n  };\n  var MpegTsOutputFormat = class extends OutputFormat {\n    /** Creates a new {@link MpegTsOutputFormat} configured with the specified `options`. */\n    constructor(options = {}) {\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (options.onPacket !== void 0 && typeof options.onPacket !== \"function\") {\n        throw new TypeError(\"options.onPacket, when provided, must be a function.\");\n      }\n      super();\n      this._options = options;\n    }\n    /** @internal */\n    _createMuxer(output) {\n      return new MpegTsMuxer(output, this);\n    }\n    /** @internal */\n    get _name() {\n      return \"MPEG-TS\";\n    }\n    getSupportedTrackCounts() {\n      const maxVideo = 16;\n      const maxAudio = 32;\n      const maxTotal = maxVideo + maxAudio;\n      return {\n        video: { min: 0, max: maxVideo },\n        audio: { min: 0, max: maxAudio },\n        subtitle: { min: 0, max: 0 },\n        total: { min: 1, max: maxTotal }\n      };\n    }\n    get fileExtension() {\n      return \".ts\";\n    }\n    get mimeType() {\n      return \"video/MP2T\";\n    }\n    getSupportedCodecs() {\n      return [\n        ...VIDEO_CODECS.filter((codec) => [\"avc\", \"hevc\"].includes(codec)),\n        ...AUDIO_CODECS.filter((codec) => [\"aac\", \"mp3\"].includes(codec))\n      ];\n    }\n    get supportsVideoRotationMetadata() {\n      return false;\n    }\n  };\n\n  // src/encode.ts\n  var validateVideoEncodingConfig = (config) => {\n    if (!config || typeof config !== \"object\") {\n      throw new TypeError(\"Encoding config must be an object.\");\n    }\n    if (!VIDEO_CODECS.includes(config.codec)) {\n      throw new TypeError(`Invalid video codec '${config.codec}'. Must be one of: ${VIDEO_CODECS.join(\", \")}.`);\n    }\n    if (!(config.bitrate instanceof Quality) && (!Number.isInteger(config.bitrate) || config.bitrate <= 0)) {\n      throw new TypeError(\"config.bitrate must be a positive integer or a quality.\");\n    }\n    if (config.keyFrameInterval !== void 0 && (!Number.isFinite(config.keyFrameInterval) || config.keyFrameInterval < 0)) {\n      throw new TypeError(\"config.keyFrameInterval, when provided, must be a non-negative number.\");\n    }\n    if (config.sizeChangeBehavior !== void 0 && ![\"deny\", \"passThrough\", \"fill\", \"contain\", \"cover\"].includes(config.sizeChangeBehavior)) {\n      throw new TypeError(\n        \"config.sizeChangeBehavior, when provided, must be 'deny', 'passThrough', 'fill', 'contain' or 'cover'.\"\n      );\n    }\n    if (config.onEncodedPacket !== void 0 && typeof config.onEncodedPacket !== \"function\") {\n      throw new TypeError(\"config.onEncodedChunk, when provided, must be a function.\");\n    }\n    if (config.onEncoderConfig !== void 0 && typeof config.onEncoderConfig !== \"function\") {\n      throw new TypeError(\"config.onEncoderConfig, when provided, must be a function.\");\n    }\n    validateVideoEncodingAdditionalOptions(config.codec, config);\n  };\n  var validateVideoEncodingAdditionalOptions = (codec, options) => {\n    if (!options || typeof options !== \"object\") {\n      throw new TypeError(\"Encoding options must be an object.\");\n    }\n    if (options.alpha !== void 0 && ![\"discard\", \"keep\"].includes(options.alpha)) {\n      throw new TypeError(\"options.alpha, when provided, must be 'discard' or 'keep'.\");\n    }\n    if (options.bitrateMode !== void 0 && ![\"constant\", \"variable\"].includes(options.bitrateMode)) {\n      throw new TypeError(\"bitrateMode, when provided, must be 'constant' or 'variable'.\");\n    }\n    if (options.latencyMode !== void 0 && ![\"quality\", \"realtime\"].includes(options.latencyMode)) {\n      throw new TypeError(\"latencyMode, when provided, must be 'quality' or 'realtime'.\");\n    }\n    if (options.fullCodecString !== void 0 && typeof options.fullCodecString !== \"string\") {\n      throw new TypeError(\"fullCodecString, when provided, must be a string.\");\n    }\n    if (options.fullCodecString !== void 0 && inferCodecFromCodecString(options.fullCodecString) !== codec) {\n      throw new TypeError(\n        `fullCodecString, when provided, must be a string that matches the specified codec (${codec}).`\n      );\n    }\n    if (options.hardwareAcceleration !== void 0 && ![\"no-preference\", \"prefer-hardware\", \"prefer-software\"].includes(options.hardwareAcceleration)) {\n      throw new TypeError(\n        \"hardwareAcceleration, when provided, must be 'no-preference', 'prefer-hardware' or 'prefer-software'.\"\n      );\n    }\n    if (options.scalabilityMode !== void 0 && typeof options.scalabilityMode !== \"string\") {\n      throw new TypeError(\"scalabilityMode, when provided, must be a string.\");\n    }\n    if (options.contentHint !== void 0 && typeof options.contentHint !== \"string\") {\n      throw new TypeError(\"contentHint, when provided, must be a string.\");\n    }\n  };\n  var buildVideoEncoderConfig = (options) => {\n    const resolvedBitrate = options.bitrate instanceof Quality ? options.bitrate._toVideoBitrate(options.codec, options.width, options.height) : options.bitrate;\n    return {\n      codec: options.fullCodecString ?? buildVideoCodecString(\n        options.codec,\n        options.width,\n        options.height,\n        resolvedBitrate\n      ),\n      width: options.width,\n      height: options.height,\n      bitrate: resolvedBitrate,\n      bitrateMode: options.bitrateMode,\n      alpha: options.alpha ?? \"discard\",\n      framerate: options.framerate,\n      latencyMode: options.latencyMode,\n      hardwareAcceleration: options.hardwareAcceleration,\n      scalabilityMode: options.scalabilityMode,\n      contentHint: options.contentHint,\n      ...getVideoEncoderConfigExtension(options.codec)\n    };\n  };\n  var validateAudioEncodingConfig = (config) => {\n    if (!config || typeof config !== \"object\") {\n      throw new TypeError(\"Encoding config must be an object.\");\n    }\n    if (!AUDIO_CODECS.includes(config.codec)) {\n      throw new TypeError(`Invalid audio codec '${config.codec}'. Must be one of: ${AUDIO_CODECS.join(\", \")}.`);\n    }\n    if (config.bitrate === void 0 && (!PCM_AUDIO_CODECS.includes(config.codec) || config.codec === \"flac\")) {\n      throw new TypeError(\"config.bitrate must be provided for compressed audio codecs.\");\n    }\n    if (config.bitrate !== void 0 && !(config.bitrate instanceof Quality) && (!Number.isInteger(config.bitrate) || config.bitrate <= 0)) {\n      throw new TypeError(\"config.bitrate, when provided, must be a positive integer or a quality.\");\n    }\n    if (config.onEncodedPacket !== void 0 && typeof config.onEncodedPacket !== \"function\") {\n      throw new TypeError(\"config.onEncodedChunk, when provided, must be a function.\");\n    }\n    if (config.onEncoderConfig !== void 0 && typeof config.onEncoderConfig !== \"function\") {\n      throw new TypeError(\"config.onEncoderConfig, when provided, must be a function.\");\n    }\n    validateAudioEncodingAdditionalOptions(config.codec, config);\n  };\n  var validateAudioEncodingAdditionalOptions = (codec, options) => {\n    if (!options || typeof options !== \"object\") {\n      throw new TypeError(\"Encoding options must be an object.\");\n    }\n    if (options.bitrateMode !== void 0 && ![\"constant\", \"variable\"].includes(options.bitrateMode)) {\n      throw new TypeError(\"bitrateMode, when provided, must be 'constant' or 'variable'.\");\n    }\n    if (options.fullCodecString !== void 0 && typeof options.fullCodecString !== \"string\") {\n      throw new TypeError(\"fullCodecString, when provided, must be a string.\");\n    }\n    if (options.fullCodecString !== void 0 && inferCodecFromCodecString(options.fullCodecString) !== codec) {\n      throw new TypeError(\n        `fullCodecString, when provided, must be a string that matches the specified codec (${codec}).`\n      );\n    }\n  };\n  var buildAudioEncoderConfig = (options) => {\n    const resolvedBitrate = options.bitrate instanceof Quality ? options.bitrate._toAudioBitrate(options.codec) : options.bitrate;\n    return {\n      codec: options.fullCodecString ?? buildAudioCodecString(\n        options.codec,\n        options.numberOfChannels,\n        options.sampleRate\n      ),\n      numberOfChannels: options.numberOfChannels,\n      sampleRate: options.sampleRate,\n      bitrate: resolvedBitrate,\n      bitrateMode: options.bitrateMode,\n      ...getAudioEncoderConfigExtension(options.codec)\n    };\n  };\n  var Quality = class {\n    /** @internal */\n    constructor(factor) {\n      this._factor = factor;\n    }\n    /** @internal */\n    _toVideoBitrate(codec, width, height) {\n      const pixels = width * height;\n      const codecEfficiencyFactors = {\n        avc: 1,\n        // H.264/AVC (baseline)\n        hevc: 0.6,\n        // H.265/HEVC (~40% more efficient than AVC)\n        vp9: 0.6,\n        // Similar to HEVC\n        av1: 0.4,\n        // ~60% more efficient than AVC\n        vp8: 1.2\n        // Slightly less efficient than AVC\n      };\n      const referencePixels = 1920 * 1080;\n      const referenceBitrate = 3e6;\n      const scaleFactor = Math.pow(pixels / referencePixels, 0.95);\n      const baseBitrate = referenceBitrate * scaleFactor;\n      const codecAdjustedBitrate = baseBitrate * codecEfficiencyFactors[codec];\n      const finalBitrate = codecAdjustedBitrate * this._factor;\n      return Math.ceil(finalBitrate / 1e3) * 1e3;\n    }\n    /** @internal */\n    _toAudioBitrate(codec) {\n      if (PCM_AUDIO_CODECS.includes(codec) || codec === \"flac\") {\n        return void 0;\n      }\n      const baseRates = {\n        aac: 128e3,\n        // 128kbps base for AAC\n        opus: 64e3,\n        // 64kbps base for Opus\n        mp3: 16e4,\n        // 160kbps base for MP3\n        vorbis: 64e3\n        // 64kbps base for Vorbis\n      };\n      const baseBitrate = baseRates[codec];\n      if (!baseBitrate) {\n        throw new Error(`Unhandled codec: ${codec}`);\n      }\n      let finalBitrate = baseBitrate * this._factor;\n      if (codec === \"aac\") {\n        const validRates = [96e3, 128e3, 16e4, 192e3];\n        finalBitrate = validRates.reduce(\n          (prev, curr) => Math.abs(curr - finalBitrate) < Math.abs(prev - finalBitrate) ? curr : prev\n        );\n      } else if (codec === \"opus\" || codec === \"vorbis\") {\n        finalBitrate = Math.max(6e3, finalBitrate);\n      } else if (codec === \"mp3\") {\n        const validRates = [\n          8e3,\n          16e3,\n          24e3,\n          32e3,\n          4e4,\n          48e3,\n          64e3,\n          8e4,\n          96e3,\n          112e3,\n          128e3,\n          16e4,\n          192e3,\n          224e3,\n          256e3,\n          32e4\n        ];\n        finalBitrate = validRates.reduce(\n          (prev, curr) => Math.abs(curr - finalBitrate) < Math.abs(prev - finalBitrate) ? curr : prev\n        );\n      }\n      return Math.round(finalBitrate / 1e3) * 1e3;\n    }\n  };\n  var QUALITY_VERY_LOW = /* @__PURE__ */ new Quality(0.3);\n  var QUALITY_LOW = /* @__PURE__ */ new Quality(0.6);\n  var QUALITY_MEDIUM = /* @__PURE__ */ new Quality(1);\n  var QUALITY_HIGH = /* @__PURE__ */ new Quality(2);\n  var QUALITY_VERY_HIGH = /* @__PURE__ */ new Quality(4);\n  var canEncode = (codec) => {\n    if (VIDEO_CODECS.includes(codec)) {\n      return canEncodeVideo(codec);\n    } else if (AUDIO_CODECS.includes(codec)) {\n      return canEncodeAudio(codec);\n    } else if (SUBTITLE_CODECS.includes(codec)) {\n      return canEncodeSubtitles(codec);\n    }\n    throw new TypeError(`Unknown codec '${codec}'.`);\n  };\n  var canEncodeVideo = async (codec, options = {}) => {\n    const {\n      width = 1280,\n      height = 720,\n      bitrate = 1e6,\n      ...restOptions\n    } = options;\n    if (!VIDEO_CODECS.includes(codec)) {\n      return false;\n    }\n    if (!Number.isInteger(width) || width <= 0) {\n      throw new TypeError(\"width must be a positive integer.\");\n    }\n    if (!Number.isInteger(height) || height <= 0) {\n      throw new TypeError(\"height must be a positive integer.\");\n    }\n    if (!(bitrate instanceof Quality) && (!Number.isInteger(bitrate) || bitrate <= 0)) {\n      throw new TypeError(\"bitrate must be a positive integer or a quality.\");\n    }\n    validateVideoEncodingAdditionalOptions(codec, restOptions);\n    let encoderConfig = null;\n    if (customVideoEncoders.length > 0) {\n      encoderConfig ??= buildVideoEncoderConfig({\n        codec,\n        width,\n        height,\n        bitrate,\n        framerate: void 0,\n        ...restOptions\n      });\n      if (customVideoEncoders.some((x) => x.supports(codec, encoderConfig))) {\n        return true;\n      }\n    }\n    if (typeof VideoEncoder === \"undefined\") {\n      return false;\n    }\n    const hasOddDimension = width % 2 === 1 || height % 2 === 1;\n    if (hasOddDimension && (codec === \"avc\" || codec === \"hevc\")) {\n      return false;\n    }\n    encoderConfig ??= buildVideoEncoderConfig({\n      codec,\n      width,\n      height,\n      bitrate,\n      framerate: void 0,\n      ...restOptions,\n      alpha: \"discard\"\n      // Since we handle alpha ourselves\n    });\n    const support = await VideoEncoder.isConfigSupported(encoderConfig);\n    if (!support.supported) {\n      return false;\n    }\n    if (isFirefox()) {\n      return new Promise(async (resolve) => {\n        try {\n          const encoder = new VideoEncoder({\n            output: () => {\n            },\n            error: () => resolve(false)\n          });\n          encoder.configure(encoderConfig);\n          const frameData = new Uint8Array(width * height * 4);\n          const frame = new VideoFrame(frameData, {\n            format: \"RGBA\",\n            codedWidth: width,\n            codedHeight: height,\n            timestamp: 0\n          });\n          encoder.encode(frame);\n          frame.close();\n          await encoder.flush();\n          resolve(true);\n        } catch {\n          resolve(false);\n        }\n      });\n    } else {\n      return true;\n    }\n  };\n  var canEncodeAudio = async (codec, options = {}) => {\n    const {\n      numberOfChannels = 2,\n      sampleRate = 48e3,\n      bitrate = 128e3,\n      ...restOptions\n    } = options;\n    if (!AUDIO_CODECS.includes(codec)) {\n      return false;\n    }\n    if (!Number.isInteger(numberOfChannels) || numberOfChannels <= 0) {\n      throw new TypeError(\"numberOfChannels must be a positive integer.\");\n    }\n    if (!Number.isInteger(sampleRate) || sampleRate <= 0) {\n      throw new TypeError(\"sampleRate must be a positive integer.\");\n    }\n    if (!(bitrate instanceof Quality) && (!Number.isInteger(bitrate) || bitrate <= 0)) {\n      throw new TypeError(\"bitrate must be a positive integer.\");\n    }\n    validateAudioEncodingAdditionalOptions(codec, restOptions);\n    let encoderConfig = null;\n    if (customAudioEncoders.length > 0) {\n      encoderConfig ??= buildAudioEncoderConfig({\n        codec,\n        numberOfChannels,\n        sampleRate,\n        bitrate,\n        ...restOptions\n      });\n      if (customAudioEncoders.some((x) => x.supports(codec, encoderConfig))) {\n        return true;\n      }\n    }\n    if (PCM_AUDIO_CODECS.includes(codec)) {\n      return true;\n    }\n    if (typeof AudioEncoder === \"undefined\") {\n      return false;\n    }\n    encoderConfig ??= buildAudioEncoderConfig({\n      codec,\n      numberOfChannels,\n      sampleRate,\n      bitrate,\n      ...restOptions\n    });\n    const support = await AudioEncoder.isConfigSupported(encoderConfig);\n    return support.supported === true;\n  };\n  var canEncodeSubtitles = async (codec) => {\n    if (!SUBTITLE_CODECS.includes(codec)) {\n      return false;\n    }\n    return true;\n  };\n  var getEncodableCodecs = async () => {\n    const [videoCodecs, audioCodecs, subtitleCodecs] = await Promise.all([\n      getEncodableVideoCodecs(),\n      getEncodableAudioCodecs(),\n      getEncodableSubtitleCodecs()\n    ]);\n    return [...videoCodecs, ...audioCodecs, ...subtitleCodecs];\n  };\n  var getEncodableVideoCodecs = async (checkedCodecs = VIDEO_CODECS, options) => {\n    const bools = await Promise.all(checkedCodecs.map((codec) => canEncodeVideo(codec, options)));\n    return checkedCodecs.filter((_, i) => bools[i]);\n  };\n  var getEncodableAudioCodecs = async (checkedCodecs = AUDIO_CODECS, options) => {\n    const bools = await Promise.all(checkedCodecs.map((codec) => canEncodeAudio(codec, options)));\n    return checkedCodecs.filter((_, i) => bools[i]);\n  };\n  var getEncodableSubtitleCodecs = async (checkedCodecs = SUBTITLE_CODECS) => {\n    const bools = await Promise.all(checkedCodecs.map(canEncodeSubtitles));\n    return checkedCodecs.filter((_, i) => bools[i]);\n  };\n  var getFirstEncodableVideoCodec = async (checkedCodecs, options) => {\n    for (const codec of checkedCodecs) {\n      if (await canEncodeVideo(codec, options)) {\n        return codec;\n      }\n    }\n    return null;\n  };\n  var getFirstEncodableAudioCodec = async (checkedCodecs, options) => {\n    for (const codec of checkedCodecs) {\n      if (await canEncodeAudio(codec, options)) {\n        return codec;\n      }\n    }\n    return null;\n  };\n  var getFirstEncodableSubtitleCodec = async (checkedCodecs) => {\n    for (const codec of checkedCodecs) {\n      if (await canEncodeSubtitles(codec)) {\n        return codec;\n      }\n    }\n    return null;\n  };\n\n  // src/media-source.ts\n  var MediaSource = class {\n    constructor() {\n      /** @internal */\n      this._connectedTrack = null;\n      /** @internal */\n      this._closingPromise = null;\n      /** @internal */\n      this._closed = false;\n      /**\n       * @internal\n       * A time offset in seconds that is added to all timestamps generated by this source.\n       */\n      this._timestampOffset = 0;\n    }\n    /** @internal */\n    _ensureValidAdd() {\n      if (!this._connectedTrack) {\n        throw new Error(\"Source is not connected to an output track.\");\n      }\n      if (this._connectedTrack.output.state === \"canceled\") {\n        throw new Error(\"Output has been canceled.\");\n      }\n      if (this._connectedTrack.output.state === \"finalizing\" || this._connectedTrack.output.state === \"finalized\") {\n        throw new Error(\"Output has been finalized.\");\n      }\n      if (this._connectedTrack.output.state === \"pending\") {\n        throw new Error(\"Output has not started.\");\n      }\n      if (this._closed) {\n        throw new Error(\"Source is closed.\");\n      }\n    }\n    /** @internal */\n    async _start() {\n    }\n    /** @internal */\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async _flushAndClose(forceClose) {\n    }\n    /**\n     * Closes this source. This prevents future samples from being added and signals to the output file that no further\n     * samples will come in for this track. Calling `.close()` is optional but recommended after adding the\n     * last sample - for improved performance and reduced memory usage.\n     */\n    close() {\n      if (this._closingPromise) {\n        return;\n      }\n      const connectedTrack = this._connectedTrack;\n      if (!connectedTrack) {\n        throw new Error(\"Cannot call close without connecting the source to an output track.\");\n      }\n      if (connectedTrack.output.state === \"pending\") {\n        throw new Error(\"Cannot call close before output has been started.\");\n      }\n      this._closingPromise = (async () => {\n        await this._flushAndClose(false);\n        this._closed = true;\n        if (connectedTrack.output.state === \"finalizing\" || connectedTrack.output.state === \"finalized\") {\n          return;\n        }\n        connectedTrack.output._muxer.onTrackClose(connectedTrack);\n      })();\n    }\n    /** @internal */\n    async _flushOrWaitForOngoingClose(forceClose) {\n      return this._closingPromise ??= (async () => {\n        await this._flushAndClose(forceClose);\n        this._closed = true;\n      })();\n    }\n  };\n  var VideoSource = class extends MediaSource {\n    /** Internal constructor. */\n    constructor(codec) {\n      super();\n      /** @internal */\n      this._connectedTrack = null;\n      if (!VIDEO_CODECS.includes(codec)) {\n        throw new TypeError(`Invalid video codec '${codec}'. Must be one of: ${VIDEO_CODECS.join(\", \")}.`);\n      }\n      this._codec = codec;\n    }\n  };\n  var EncodedVideoPacketSource = class extends VideoSource {\n    /** Creates a new {@link EncodedVideoPacketSource} whose packets are encoded using `codec`. */\n    constructor(codec) {\n      super(codec);\n    }\n    /**\n     * Adds an encoded packet to the output video track. Packets must be added in *decode order*, while a packet's\n     * timestamp must be its *presentation timestamp*. B-frames are handled automatically.\n     *\n     * @param meta - Additional metadata from the encoder. You should pass this for the first call, including a valid\n     * decoder config.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(packet, meta) {\n      if (!(packet instanceof EncodedPacket)) {\n        throw new TypeError(\"packet must be an EncodedPacket.\");\n      }\n      if (packet.isMetadataOnly) {\n        throw new TypeError(\"Metadata-only packets cannot be added.\");\n      }\n      if (meta !== void 0 && (!meta || typeof meta !== \"object\")) {\n        throw new TypeError(\"meta, when provided, must be an object.\");\n      }\n      this._ensureValidAdd();\n      return this._connectedTrack.output._muxer.addEncodedVideoPacket(this._connectedTrack, packet, meta);\n    }\n  };\n  var VideoEncoderWrapper = class {\n    constructor(source, encodingConfig) {\n      this.source = source;\n      this.encodingConfig = encodingConfig;\n      this.ensureEncoderPromise = null;\n      this.encoderInitialized = false;\n      this.encoder = null;\n      this.muxer = null;\n      this.lastMultipleOfKeyFrameInterval = -1;\n      this.codedWidth = null;\n      this.codedHeight = null;\n      this.resizeCanvas = null;\n      this.customEncoder = null;\n      this.customEncoderCallSerializer = new CallSerializer();\n      this.customEncoderQueueSize = 0;\n      // Alpha stuff\n      this.alphaEncoder = null;\n      this.splitter = null;\n      this.splitterCreationFailed = false;\n      this.alphaFrameQueue = [];\n      /**\n       * Encoders typically throw their errors \"out of band\", meaning asynchronously in some other execution context.\n       * However, we want to surface these errors to the user within the normal control flow, so they don't go uncaught.\n       * So, we keep track of the encoder error and throw it as soon as we get the chance.\n       */\n      this.error = null;\n      this.errorNeedsNewStack = true;\n    }\n    async add(videoSample, shouldClose, encodeOptions) {\n      try {\n        this.checkForEncoderError();\n        this.source._ensureValidAdd();\n        if (this.codedWidth !== null && this.codedHeight !== null) {\n          if (videoSample.codedWidth !== this.codedWidth || videoSample.codedHeight !== this.codedHeight) {\n            const sizeChangeBehavior = this.encodingConfig.sizeChangeBehavior ?? \"deny\";\n            if (sizeChangeBehavior === \"passThrough\") {\n            } else if (sizeChangeBehavior === \"deny\") {\n              throw new Error(\n                `Video sample size must remain constant. Expected ${this.codedWidth}x${this.codedHeight}, got ${videoSample.codedWidth}x${videoSample.codedHeight}. To allow the sample size to change over time, set \\`sizeChangeBehavior\\` to a value other than 'strict' in the encoding options.`\n              );\n            } else {\n              let canvasIsNew = false;\n              if (!this.resizeCanvas) {\n                if (typeof document !== \"undefined\") {\n                  this.resizeCanvas = document.createElement(\"canvas\");\n                  this.resizeCanvas.width = this.codedWidth;\n                  this.resizeCanvas.height = this.codedHeight;\n                } else {\n                  this.resizeCanvas = new OffscreenCanvas(this.codedWidth, this.codedHeight);\n                }\n                canvasIsNew = true;\n              }\n              const context = this.resizeCanvas.getContext(\"2d\", {\n                alpha: isFirefox()\n                // Firefox has VideoFrame glitches with opaque canvases\n              });\n              assert(context);\n              if (!canvasIsNew) {\n                if (isFirefox()) {\n                  context.fillStyle = \"black\";\n                  context.fillRect(0, 0, this.codedWidth, this.codedHeight);\n                } else {\n                  context.clearRect(0, 0, this.codedWidth, this.codedHeight);\n                }\n              }\n              videoSample.drawWithFit(context, { fit: sizeChangeBehavior });\n              if (shouldClose) {\n                videoSample.close();\n              }\n              videoSample = new VideoSample(this.resizeCanvas, {\n                timestamp: videoSample.timestamp,\n                duration: videoSample.duration,\n                rotation: videoSample.rotation\n              });\n              shouldClose = true;\n            }\n          }\n        } else {\n          this.codedWidth = videoSample.codedWidth;\n          this.codedHeight = videoSample.codedHeight;\n        }\n        if (!this.encoderInitialized) {\n          if (!this.ensureEncoderPromise) {\n            this.ensureEncoder(videoSample);\n          }\n          if (!this.encoderInitialized) {\n            await this.ensureEncoderPromise;\n          }\n        }\n        assert(this.encoderInitialized);\n        const keyFrameInterval = this.encodingConfig.keyFrameInterval ?? 5;\n        const multipleOfKeyFrameInterval = Math.floor(videoSample.timestamp / keyFrameInterval);\n        const finalEncodeOptions = {\n          ...encodeOptions,\n          keyFrame: encodeOptions?.keyFrame || keyFrameInterval === 0 || multipleOfKeyFrameInterval !== this.lastMultipleOfKeyFrameInterval\n        };\n        this.lastMultipleOfKeyFrameInterval = multipleOfKeyFrameInterval;\n        if (this.customEncoder) {\n          this.customEncoderQueueSize++;\n          const clonedSample = videoSample.clone();\n          const promise = this.customEncoderCallSerializer.call(() => this.customEncoder.encode(clonedSample, finalEncodeOptions)).then(() => this.customEncoderQueueSize--).catch((error) => this.error ??= error).finally(() => {\n            clonedSample.close();\n          });\n          if (this.customEncoderQueueSize >= 4) {\n            await promise;\n          }\n        } else {\n          assert(this.encoder);\n          const videoFrame = videoSample.toVideoFrame();\n          if (!this.alphaEncoder) {\n            this.encoder.encode(videoFrame, finalEncodeOptions);\n            videoFrame.close();\n          } else {\n            const frameDefinitelyHasNoAlpha = !!videoFrame.format && !videoFrame.format.includes(\"A\");\n            if (frameDefinitelyHasNoAlpha || this.splitterCreationFailed) {\n              this.alphaFrameQueue.push(null);\n              this.encoder.encode(videoFrame, finalEncodeOptions);\n              videoFrame.close();\n            } else {\n              const width = videoFrame.displayWidth;\n              const height = videoFrame.displayHeight;\n              if (!this.splitter) {\n                try {\n                  this.splitter = new ColorAlphaSplitter(width, height);\n                } catch (error) {\n                  console.error(\"Due to an error, only color data will be encoded.\", error);\n                  this.splitterCreationFailed = true;\n                  this.alphaFrameQueue.push(null);\n                  this.encoder.encode(videoFrame, finalEncodeOptions);\n                  videoFrame.close();\n                }\n              }\n              if (this.splitter) {\n                const colorFrame = this.splitter.extractColor(videoFrame);\n                const alphaFrame = this.splitter.extractAlpha(videoFrame);\n                this.alphaFrameQueue.push(alphaFrame);\n                this.encoder.encode(colorFrame, finalEncodeOptions);\n                colorFrame.close();\n                videoFrame.close();\n              }\n            }\n          }\n          if (shouldClose) {\n            videoSample.close();\n          }\n          if (this.encoder.encodeQueueSize >= 4) {\n            await new Promise((resolve) => this.encoder.addEventListener(\"dequeue\", resolve, { once: true }));\n          }\n        }\n        await this.muxer.mutex.currentPromise;\n      } finally {\n        if (shouldClose) {\n          videoSample.close();\n        }\n      }\n    }\n    ensureEncoder(videoSample) {\n      const encoderError = new Error();\n      this.ensureEncoderPromise = (async () => {\n        const encoderConfig = buildVideoEncoderConfig({\n          width: videoSample.codedWidth,\n          height: videoSample.codedHeight,\n          ...this.encodingConfig,\n          framerate: this.source._connectedTrack?.metadata.frameRate\n        });\n        this.encodingConfig.onEncoderConfig?.(encoderConfig);\n        const MatchingCustomEncoder = customVideoEncoders.find((x) => x.supports(\n          this.encodingConfig.codec,\n          encoderConfig\n        ));\n        if (MatchingCustomEncoder) {\n          this.customEncoder = new MatchingCustomEncoder();\n          this.customEncoder.codec = this.encodingConfig.codec;\n          this.customEncoder.config = encoderConfig;\n          this.customEncoder.onPacket = (packet, meta) => {\n            if (!(packet instanceof EncodedPacket)) {\n              throw new TypeError(\"The first argument passed to onPacket must be an EncodedPacket.\");\n            }\n            if (meta !== void 0 && (!meta || typeof meta !== \"object\")) {\n              throw new TypeError(\"The second argument passed to onPacket must be an object or undefined.\");\n            }\n            this.encodingConfig.onEncodedPacket?.(packet, meta);\n            void this.muxer.addEncodedVideoPacket(this.source._connectedTrack, packet, meta).catch((error) => {\n              this.error ??= error;\n              this.errorNeedsNewStack = false;\n            });\n          };\n          await this.customEncoder.init();\n        } else {\n          if (typeof VideoEncoder === \"undefined\") {\n            throw new Error(\"VideoEncoder is not supported by this browser.\");\n          }\n          encoderConfig.alpha = \"discard\";\n          if (this.encodingConfig.alpha === \"keep\") {\n            encoderConfig.latencyMode = \"quality\";\n          }\n          const hasOddDimension = encoderConfig.width % 2 === 1 || encoderConfig.height % 2 === 1;\n          if (hasOddDimension && (this.encodingConfig.codec === \"avc\" || this.encodingConfig.codec === \"hevc\")) {\n            throw new Error(\n              `The dimensions ${encoderConfig.width}x${encoderConfig.height} are not supported for codec '${this.encodingConfig.codec}'; both width and height must be even numbers. Make sure to round your dimensions to the nearest even number.`\n            );\n          }\n          const support = await VideoEncoder.isConfigSupported(encoderConfig);\n          if (!support.supported) {\n            throw new Error(\n              `This specific encoder configuration (${encoderConfig.codec}, ${encoderConfig.bitrate} bps, ${encoderConfig.width}x${encoderConfig.height}, hardware acceleration: ${encoderConfig.hardwareAcceleration ?? \"no-preference\"}) is not supported by this browser. Consider using another codec or changing your video parameters.`\n            );\n          }\n          const colorChunkQueue = [];\n          const nullAlphaChunkQueue = [];\n          let encodedAlphaChunkCount = 0;\n          let alphaEncoderQueue = 0;\n          const addPacket = (colorChunk, alphaChunk, meta) => {\n            const sideData = {};\n            if (alphaChunk) {\n              const alphaData = new Uint8Array(alphaChunk.byteLength);\n              alphaChunk.copyTo(alphaData);\n              sideData.alpha = alphaData;\n            }\n            const packet = EncodedPacket.fromEncodedChunk(colorChunk, sideData);\n            this.encodingConfig.onEncodedPacket?.(packet, meta);\n            void this.muxer.addEncodedVideoPacket(this.source._connectedTrack, packet, meta).catch((error) => {\n              this.error ??= error;\n              this.errorNeedsNewStack = false;\n            });\n          };\n          this.encoder = new VideoEncoder({\n            output: (chunk, meta) => {\n              if (!this.alphaEncoder) {\n                addPacket(chunk, null, meta);\n                return;\n              }\n              const alphaFrame = this.alphaFrameQueue.shift();\n              assert(alphaFrame !== void 0);\n              if (alphaFrame) {\n                this.alphaEncoder.encode(alphaFrame, {\n                  // Crucial: The alpha frame is forced to be a key frame whenever the color frame\n                  // also is. Without this, playback can glitch and even crash in some browsers.\n                  // This is the reason why the two encoders are wired in series and not in parallel.\n                  keyFrame: chunk.type === \"key\"\n                });\n                alphaEncoderQueue++;\n                alphaFrame.close();\n                colorChunkQueue.push({ chunk, meta });\n              } else {\n                if (alphaEncoderQueue === 0) {\n                  addPacket(chunk, null, meta);\n                } else {\n                  nullAlphaChunkQueue.push(encodedAlphaChunkCount + alphaEncoderQueue);\n                  colorChunkQueue.push({ chunk, meta });\n                }\n              }\n            },\n            error: (error) => {\n              error.stack = encoderError.stack;\n              this.error ??= error;\n            }\n          });\n          this.encoder.configure(encoderConfig);\n          if (this.encodingConfig.alpha === \"keep\") {\n            this.alphaEncoder = new VideoEncoder({\n              // We ignore the alpha chunk's metadata\n              // eslint-disable-next-line @typescript-eslint/no-unused-vars\n              output: (chunk, meta) => {\n                alphaEncoderQueue--;\n                const colorChunk = colorChunkQueue.shift();\n                assert(colorChunk !== void 0);\n                addPacket(colorChunk.chunk, chunk, colorChunk.meta);\n                encodedAlphaChunkCount++;\n                while (nullAlphaChunkQueue.length > 0 && nullAlphaChunkQueue[0] === encodedAlphaChunkCount) {\n                  nullAlphaChunkQueue.shift();\n                  const colorChunk2 = colorChunkQueue.shift();\n                  assert(colorChunk2 !== void 0);\n                  addPacket(colorChunk2.chunk, null, colorChunk2.meta);\n                }\n              },\n              error: (error) => {\n                error.stack = encoderError.stack;\n                this.error ??= error;\n              }\n            });\n            this.alphaEncoder.configure(encoderConfig);\n          }\n        }\n        assert(this.source._connectedTrack);\n        this.muxer = this.source._connectedTrack.output._muxer;\n        this.encoderInitialized = true;\n      })();\n    }\n    async flushAndClose(forceClose) {\n      if (!forceClose) this.checkForEncoderError();\n      if (this.customEncoder) {\n        if (!forceClose) {\n          void this.customEncoderCallSerializer.call(() => this.customEncoder.flush());\n        }\n        await this.customEncoderCallSerializer.call(() => this.customEncoder.close());\n      } else if (this.encoder) {\n        if (!forceClose) {\n          await this.encoder.flush();\n          await this.alphaEncoder?.flush();\n        }\n        if (this.encoder.state !== \"closed\") {\n          this.encoder.close();\n        }\n        if (this.alphaEncoder && this.alphaEncoder.state !== \"closed\") {\n          this.alphaEncoder.close();\n        }\n        this.alphaFrameQueue.forEach((x) => x?.close());\n        this.splitter?.close();\n      }\n      if (!forceClose) this.checkForEncoderError();\n    }\n    getQueueSize() {\n      if (this.customEncoder) {\n        return this.customEncoderQueueSize;\n      } else {\n        return this.encoder?.encodeQueueSize ?? 0;\n      }\n    }\n    checkForEncoderError() {\n      if (this.error) {\n        if (this.errorNeedsNewStack) {\n          this.error.stack = new Error().stack;\n        }\n        throw this.error;\n      }\n    }\n  };\n  var ColorAlphaSplitter = class {\n    constructor(initialWidth, initialHeight) {\n      this.lastFrame = null;\n      if (typeof OffscreenCanvas !== \"undefined\") {\n        this.canvas = new OffscreenCanvas(initialWidth, initialHeight);\n      } else {\n        this.canvas = document.createElement(\"canvas\");\n        this.canvas.width = initialWidth;\n        this.canvas.height = initialHeight;\n      }\n      const gl = this.canvas.getContext(\"webgl2\", {\n        alpha: true\n        // Needed due to the YUV thing we do for alpha\n      });\n      if (!gl) {\n        throw new Error(\"Couldn't acquire WebGL 2 context.\");\n      }\n      this.gl = gl;\n      this.colorProgram = this.createColorProgram();\n      this.alphaProgram = this.createAlphaProgram();\n      this.vao = this.createVAO();\n      this.sourceTexture = this.createTexture();\n      this.alphaResolutionLocation = this.gl.getUniformLocation(this.alphaProgram, \"u_resolution\");\n      this.gl.useProgram(this.colorProgram);\n      this.gl.uniform1i(this.gl.getUniformLocation(this.colorProgram, \"u_sourceTexture\"), 0);\n      this.gl.useProgram(this.alphaProgram);\n      this.gl.uniform1i(this.gl.getUniformLocation(this.alphaProgram, \"u_sourceTexture\"), 0);\n    }\n    createVertexShader() {\n      return this.createShader(this.gl.VERTEX_SHADER, `#version 300 es\n\t\t\tin vec2 a_position;\n\t\t\tin vec2 a_texCoord;\n\t\t\tout vec2 v_texCoord;\n\t\t\t\n\t\t\tvoid main() {\n\t\t\t\tgl_Position = vec4(a_position, 0.0, 1.0);\n\t\t\t\tv_texCoord = a_texCoord;\n\t\t\t}\n\t\t`);\n    }\n    createColorProgram() {\n      const vertexShader = this.createVertexShader();\n      const fragmentShader = this.createShader(this.gl.FRAGMENT_SHADER, `#version 300 es\n\t\t\tprecision highp float;\n\t\t\t\n\t\t\tuniform sampler2D u_sourceTexture;\n\t\t\tin vec2 v_texCoord;\n\t\t\tout vec4 fragColor;\n\t\t\t\n\t\t\tvoid main() {\n\t\t\t\tvec4 source = texture(u_sourceTexture, v_texCoord);\n\t\t\t\tfragColor = vec4(source.rgb, 1.0);\n\t\t\t}\n\t\t`);\n      const program = this.gl.createProgram();\n      this.gl.attachShader(program, vertexShader);\n      this.gl.attachShader(program, fragmentShader);\n      this.gl.linkProgram(program);\n      return program;\n    }\n    createAlphaProgram() {\n      const vertexShader = this.createVertexShader();\n      const fragmentShader = this.createShader(this.gl.FRAGMENT_SHADER, `#version 300 es\n\t\t\tprecision highp float;\n\t\t\t\n\t\t\tuniform sampler2D u_sourceTexture;\n\t\t\tuniform vec2 u_resolution; // The width and height of the canvas\n\t\t\tin vec2 v_texCoord;\n\t\t\tout vec4 fragColor;\n\n\t\t\t// This function determines the value for a single byte in the YUV stream\n\t\t\tfloat getByteValue(float byteOffset) {\n\t\t\t\tfloat width = u_resolution.x;\n\t\t\t\tfloat height = u_resolution.y;\n\n\t\t\t\tfloat yPlaneSize = width * height;\n\n\t\t\t\tif (byteOffset < yPlaneSize) {\n\t\t\t\t\t// This byte is in the luma plane. Find the corresponding pixel coordinates to sample from\n\t\t\t\t\tfloat y = floor(byteOffset / width);\n\t\t\t\t\tfloat x = mod(byteOffset, width);\n\t\t\t\t\t\n\t\t\t\t\t// Add 0.5 to sample the center of the texel\n\t\t\t\t\tvec2 sampleCoord = (vec2(x, y) + 0.5) / u_resolution;\n\t\t\t\t\t\n\t\t\t\t\t// The luma value is the alpha from the source texture\n\t\t\t\t\treturn texture(u_sourceTexture, sampleCoord).a;\n\t\t\t\t} else {\n\t\t\t\t\t// Write a fixed value for chroma and beyond\n\t\t\t\t\treturn 128.0 / 255.0;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tvoid main() {\n\t\t\t\t// Each fragment writes 4 bytes (R, G, B, A)\n\t\t\t\tfloat pixelIndex = floor(gl_FragCoord.y) * u_resolution.x + floor(gl_FragCoord.x);\n\t\t\t\tfloat baseByteOffset = pixelIndex * 4.0;\n\n\t\t\t\tvec4 result;\n\t\t\t\tfor (int i = 0; i < 4; i++) {\n\t\t\t\t\tfloat currentByteOffset = baseByteOffset + float(i);\n\t\t\t\t\tresult[i] = getByteValue(currentByteOffset);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tfragColor = result;\n\t\t\t}\n\t\t`);\n      const program = this.gl.createProgram();\n      this.gl.attachShader(program, vertexShader);\n      this.gl.attachShader(program, fragmentShader);\n      this.gl.linkProgram(program);\n      return program;\n    }\n    createShader(type, source) {\n      const shader = this.gl.createShader(type);\n      this.gl.shaderSource(shader, source);\n      this.gl.compileShader(shader);\n      if (!this.gl.getShaderParameter(shader, this.gl.COMPILE_STATUS)) {\n        console.error(\"Shader compile error:\", this.gl.getShaderInfoLog(shader));\n      }\n      return shader;\n    }\n    createVAO() {\n      const vao = this.gl.createVertexArray();\n      this.gl.bindVertexArray(vao);\n      const vertices = new Float32Array([\n        -1,\n        -1,\n        0,\n        1,\n        1,\n        -1,\n        1,\n        1,\n        -1,\n        1,\n        0,\n        0,\n        1,\n        1,\n        1,\n        0\n      ]);\n      const buffer = this.gl.createBuffer();\n      this.gl.bindBuffer(this.gl.ARRAY_BUFFER, buffer);\n      this.gl.bufferData(this.gl.ARRAY_BUFFER, vertices, this.gl.STATIC_DRAW);\n      const positionLocation = this.gl.getAttribLocation(this.colorProgram, \"a_position\");\n      const texCoordLocation = this.gl.getAttribLocation(this.colorProgram, \"a_texCoord\");\n      this.gl.enableVertexAttribArray(positionLocation);\n      this.gl.vertexAttribPointer(positionLocation, 2, this.gl.FLOAT, false, 16, 0);\n      this.gl.enableVertexAttribArray(texCoordLocation);\n      this.gl.vertexAttribPointer(texCoordLocation, 2, this.gl.FLOAT, false, 16, 8);\n      return vao;\n    }\n    createTexture() {\n      const texture = this.gl.createTexture();\n      this.gl.bindTexture(this.gl.TEXTURE_2D, texture);\n      this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);\n      this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);\n      this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR);\n      this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR);\n      return texture;\n    }\n    updateTexture(sourceFrame) {\n      if (this.lastFrame === sourceFrame) {\n        return;\n      }\n      if (sourceFrame.displayWidth !== this.canvas.width || sourceFrame.displayHeight !== this.canvas.height) {\n        this.canvas.width = sourceFrame.displayWidth;\n        this.canvas.height = sourceFrame.displayHeight;\n      }\n      this.gl.activeTexture(this.gl.TEXTURE0);\n      this.gl.bindTexture(this.gl.TEXTURE_2D, this.sourceTexture);\n      this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, sourceFrame);\n      this.lastFrame = sourceFrame;\n    }\n    extractColor(sourceFrame) {\n      this.updateTexture(sourceFrame);\n      this.gl.useProgram(this.colorProgram);\n      this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);\n      this.gl.clear(this.gl.COLOR_BUFFER_BIT);\n      this.gl.bindVertexArray(this.vao);\n      this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);\n      return new VideoFrame(this.canvas, {\n        timestamp: sourceFrame.timestamp,\n        duration: sourceFrame.duration ?? void 0,\n        alpha: \"discard\"\n      });\n    }\n    extractAlpha(sourceFrame) {\n      this.updateTexture(sourceFrame);\n      this.gl.useProgram(this.alphaProgram);\n      this.gl.uniform2f(this.alphaResolutionLocation, this.canvas.width, this.canvas.height);\n      this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);\n      this.gl.clear(this.gl.COLOR_BUFFER_BIT);\n      this.gl.bindVertexArray(this.vao);\n      this.gl.drawArrays(this.gl.TRIANGLE_STRIP, 0, 4);\n      const { width, height } = this.canvas;\n      const chromaSamples = Math.ceil(width / 2) * Math.ceil(height / 2);\n      const yuvSize = width * height + chromaSamples * 2;\n      const requiredHeight = Math.ceil(yuvSize / (width * 4));\n      let yuv = new Uint8Array(4 * width * requiredHeight);\n      this.gl.readPixels(0, 0, width, requiredHeight, this.gl.RGBA, this.gl.UNSIGNED_BYTE, yuv);\n      yuv = yuv.subarray(0, yuvSize);\n      assert(yuv[width * height] === 128);\n      assert(yuv[yuv.length - 1] === 128);\n      const init = {\n        format: \"I420\",\n        codedWidth: width,\n        codedHeight: height,\n        timestamp: sourceFrame.timestamp,\n        duration: sourceFrame.duration ?? void 0,\n        transfer: [yuv.buffer]\n      };\n      return new VideoFrame(yuv, init);\n    }\n    close() {\n      this.gl.getExtension(\"WEBGL_lose_context\")?.loseContext();\n      this.gl = null;\n    }\n  };\n  var VideoSampleSource = class extends VideoSource {\n    /**\n     * Creates a new {@link VideoSampleSource} whose samples are encoded according to the specified\n     * {@link VideoEncodingConfig}.\n     */\n    constructor(encodingConfig) {\n      validateVideoEncodingConfig(encodingConfig);\n      super(encodingConfig.codec);\n      this._encoder = new VideoEncoderWrapper(this, encodingConfig);\n    }\n    /**\n     * Encodes a video sample (frame) and then adds it to the output.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(videoSample, encodeOptions) {\n      if (!(videoSample instanceof VideoSample)) {\n        throw new TypeError(\"videoSample must be a VideoSample.\");\n      }\n      return this._encoder.add(videoSample, false, encodeOptions);\n    }\n    /** @internal */\n    _flushAndClose(forceClose) {\n      return this._encoder.flushAndClose(forceClose);\n    }\n  };\n  var CanvasSource = class extends VideoSource {\n    /**\n     * Creates a new {@link CanvasSource} from a canvas element or `OffscreenCanvas` whose samples are encoded\n     * according to the specified {@link VideoEncodingConfig}.\n     */\n    constructor(canvas, encodingConfig) {\n      if (!(typeof HTMLCanvasElement !== \"undefined\" && canvas instanceof HTMLCanvasElement) && !(typeof OffscreenCanvas !== \"undefined\" && canvas instanceof OffscreenCanvas)) {\n        throw new TypeError(\"canvas must be an HTMLCanvasElement or OffscreenCanvas.\");\n      }\n      validateVideoEncodingConfig(encodingConfig);\n      super(encodingConfig.codec);\n      this._encoder = new VideoEncoderWrapper(this, encodingConfig);\n      this._canvas = canvas;\n    }\n    /**\n     * Captures the current canvas state as a video sample (frame), encodes it and adds it to the output.\n     *\n     * @param timestamp - The timestamp of the sample, in seconds.\n     * @param duration - The duration of the sample, in seconds.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(timestamp, duration = 0, encodeOptions) {\n      if (!Number.isFinite(timestamp) || timestamp < 0) {\n        throw new TypeError(\"timestamp must be a non-negative number.\");\n      }\n      if (!Number.isFinite(duration) || duration < 0) {\n        throw new TypeError(\"duration must be a non-negative number.\");\n      }\n      const sample = new VideoSample(this._canvas, { timestamp, duration });\n      return this._encoder.add(sample, true, encodeOptions);\n    }\n    /** @internal */\n    _flushAndClose(forceClose) {\n      return this._encoder.flushAndClose(forceClose);\n    }\n  };\n  var MediaStreamVideoTrackSource = class extends VideoSource {\n    /**\n     * Creates a new {@link MediaStreamVideoTrackSource} from a\n     * [`MediaStreamVideoTrack`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack), which will pull\n     * video samples from the stream in real time and encode them according to {@link VideoEncodingConfig}.\n     */\n    constructor(track, encodingConfig) {\n      if (!(track instanceof MediaStreamTrack) || track.kind !== \"video\") {\n        throw new TypeError(\"track must be a video MediaStreamTrack.\");\n      }\n      validateVideoEncodingConfig(encodingConfig);\n      encodingConfig = {\n        ...encodingConfig,\n        latencyMode: \"realtime\"\n      };\n      super(encodingConfig.codec);\n      /** @internal */\n      this._abortController = null;\n      /** @internal */\n      this._workerTrackId = null;\n      /** @internal */\n      this._workerListener = null;\n      /** @internal */\n      this._promiseWithResolvers = promiseWithResolvers();\n      /** @internal */\n      this._errorPromiseAccessed = false;\n      /** @internal */\n      this._paused = false;\n      /** @internal */\n      this._lastSampleTimestamp = null;\n      /** @internal */\n      this._pauseOffset = 0;\n      this._encoder = new VideoEncoderWrapper(this, encodingConfig);\n      this._track = track;\n    }\n    /** A promise that rejects upon any error within this source. This promise never resolves. */\n    get errorPromise() {\n      this._errorPromiseAccessed = true;\n      return this._promiseWithResolvers.promise;\n    }\n    /** Whether this source is currently paused as a result of calling `.pause()`. */\n    get paused() {\n      return this._paused;\n    }\n    /** @internal */\n    async _start() {\n      if (!this._errorPromiseAccessed) {\n        console.warn(\n          \"Make sure not to ignore the `errorPromise` field on MediaStreamVideoTrackSource, so that any internal errors get bubbled up properly.\"\n        );\n      }\n      this._abortController = new AbortController();\n      let firstVideoFrameTimestamp = null;\n      let errored = false;\n      const onVideoFrame = (videoFrame) => {\n        if (errored) {\n          videoFrame.close();\n          return;\n        }\n        const currentTimestamp = videoFrame.timestamp / 1e6;\n        if (this._paused) {\n          const frameSeen = firstVideoFrameTimestamp !== null;\n          if (frameSeen) {\n            if (this._lastSampleTimestamp !== null) {\n              const timeDelta = currentTimestamp - this._lastSampleTimestamp;\n              this._pauseOffset -= timeDelta;\n            }\n            this._lastSampleTimestamp = currentTimestamp;\n          }\n          videoFrame.close();\n          return;\n        }\n        if (firstVideoFrameTimestamp === null) {\n          firstVideoFrameTimestamp = currentTimestamp;\n          const muxer = this._connectedTrack.output._muxer;\n          if (muxer.firstMediaStreamTimestamp === null) {\n            muxer.firstMediaStreamTimestamp = performance.now() / 1e3;\n            this._timestampOffset = -firstVideoFrameTimestamp;\n          } else {\n            this._timestampOffset = performance.now() / 1e3 - muxer.firstMediaStreamTimestamp - firstVideoFrameTimestamp;\n          }\n        }\n        this._lastSampleTimestamp = currentTimestamp;\n        if (this._encoder.getQueueSize() >= 4) {\n          videoFrame.close();\n          return;\n        }\n        const sample = new VideoSample(videoFrame, {\n          timestamp: currentTimestamp + this._pauseOffset\n        });\n        void this._encoder.add(sample, true).catch((error) => {\n          errored = true;\n          this._abortController?.abort();\n          this._promiseWithResolvers.reject(error);\n          if (this._workerTrackId !== null) {\n            sendMessageToMediaStreamTrackProcessorWorker({\n              type: \"stopTrack\",\n              trackId: this._workerTrackId\n            });\n          }\n        });\n      };\n      if (typeof MediaStreamTrackProcessor !== \"undefined\") {\n        const processor = new MediaStreamTrackProcessor({ track: this._track });\n        const consumer = new WritableStream({ write: onVideoFrame });\n        processor.readable.pipeTo(consumer, {\n          signal: this._abortController.signal\n        }).catch((error) => {\n          if (error instanceof DOMException && error.name === \"AbortError\") return;\n          this._promiseWithResolvers.reject(error);\n        });\n      } else {\n        const supportedInWorker = await mediaStreamTrackProcessorIsSupportedInWorker();\n        if (supportedInWorker) {\n          this._workerTrackId = nextMediaStreamTrackProcessorWorkerId++;\n          sendMessageToMediaStreamTrackProcessorWorker({\n            type: \"videoTrack\",\n            trackId: this._workerTrackId,\n            track: this._track\n          });\n          this._workerListener = (event) => {\n            const message = event.data;\n            if (message.type === \"videoFrame\" && message.trackId === this._workerTrackId) {\n              onVideoFrame(message.videoFrame);\n            } else if (message.type === \"error\" && message.trackId === this._workerTrackId) {\n              this._promiseWithResolvers.reject(message.error);\n            }\n          };\n          mediaStreamTrackProcessorWorker.addEventListener(\"message\", this._workerListener);\n        } else {\n          throw new Error(\"MediaStreamTrackProcessor is required but not supported by this browser.\");\n        }\n      }\n    }\n    /**\n     * Pauses the capture of video frames - any video frames emitted by the underlying media stream will be ignored\n     * while paused. This does *not* close the underlying `MediaStreamVideoTrack`, it just ignores its output.\n     */\n    pause() {\n      this._paused = true;\n    }\n    /** Resumes the capture of video frames after being paused. */\n    resume() {\n      this._paused = false;\n    }\n    /** @internal */\n    async _flushAndClose(forceClose) {\n      if (this._abortController) {\n        this._abortController.abort();\n        this._abortController = null;\n      }\n      if (this._workerTrackId !== null) {\n        assert(this._workerListener);\n        sendMessageToMediaStreamTrackProcessorWorker({\n          type: \"stopTrack\",\n          trackId: this._workerTrackId\n        });\n        await new Promise((resolve) => {\n          const listener = (event) => {\n            const message = event.data;\n            if (message.type === \"trackStopped\" && message.trackId === this._workerTrackId) {\n              assert(this._workerListener);\n              mediaStreamTrackProcessorWorker.removeEventListener(\"message\", this._workerListener);\n              mediaStreamTrackProcessorWorker.removeEventListener(\"message\", listener);\n              resolve();\n            }\n          };\n          mediaStreamTrackProcessorWorker.addEventListener(\"message\", listener);\n        });\n      }\n      await this._encoder.flushAndClose(forceClose);\n    }\n  };\n  var AudioSource = class extends MediaSource {\n    /** Internal constructor. */\n    constructor(codec) {\n      super();\n      /** @internal */\n      this._connectedTrack = null;\n      if (!AUDIO_CODECS.includes(codec)) {\n        throw new TypeError(`Invalid audio codec '${codec}'. Must be one of: ${AUDIO_CODECS.join(\", \")}.`);\n      }\n      this._codec = codec;\n    }\n  };\n  var EncodedAudioPacketSource = class extends AudioSource {\n    /** Creates a new {@link EncodedAudioPacketSource} whose packets are encoded using `codec`. */\n    constructor(codec) {\n      super(codec);\n    }\n    /**\n     * Adds an encoded packet to the output audio track. Packets must be added in *decode order*.\n     *\n     * @param meta - Additional metadata from the encoder. You should pass this for the first call, including a valid\n     * decoder config.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(packet, meta) {\n      if (!(packet instanceof EncodedPacket)) {\n        throw new TypeError(\"packet must be an EncodedPacket.\");\n      }\n      if (packet.isMetadataOnly) {\n        throw new TypeError(\"Metadata-only packets cannot be added.\");\n      }\n      if (meta !== void 0 && (!meta || typeof meta !== \"object\")) {\n        throw new TypeError(\"meta, when provided, must be an object.\");\n      }\n      this._ensureValidAdd();\n      return this._connectedTrack.output._muxer.addEncodedAudioPacket(this._connectedTrack, packet, meta);\n    }\n  };\n  var AudioEncoderWrapper = class {\n    constructor(source, encodingConfig) {\n      this.source = source;\n      this.encodingConfig = encodingConfig;\n      this.ensureEncoderPromise = null;\n      this.encoderInitialized = false;\n      this.encoder = null;\n      this.muxer = null;\n      this.lastNumberOfChannels = null;\n      this.lastSampleRate = null;\n      this.isPcmEncoder = false;\n      this.outputSampleSize = null;\n      this.writeOutputValue = null;\n      this.customEncoder = null;\n      this.customEncoderCallSerializer = new CallSerializer();\n      this.customEncoderQueueSize = 0;\n      this.lastEndSampleIndex = null;\n      /**\n       * Encoders typically throw their errors \"out of band\", meaning asynchronously in some other execution context.\n       * However, we want to surface these errors to the user within the normal control flow, so they don't go uncaught.\n       * So, we keep track of the encoder error and throw it as soon as we get the chance.\n       */\n      this.error = null;\n      this.errorNeedsNewStack = true;\n    }\n    async add(audioSample, shouldClose) {\n      try {\n        this.checkForEncoderError();\n        this.source._ensureValidAdd();\n        if (this.lastNumberOfChannels !== null && this.lastSampleRate !== null) {\n          if (audioSample.numberOfChannels !== this.lastNumberOfChannels || audioSample.sampleRate !== this.lastSampleRate) {\n            throw new Error(\n              `Audio parameters must remain constant. Expected ${this.lastNumberOfChannels} channels at ${this.lastSampleRate} Hz, got ${audioSample.numberOfChannels} channels at ${audioSample.sampleRate} Hz.`\n            );\n          }\n        } else {\n          this.lastNumberOfChannels = audioSample.numberOfChannels;\n          this.lastSampleRate = audioSample.sampleRate;\n        }\n        if (!this.encoderInitialized) {\n          if (!this.ensureEncoderPromise) {\n            this.ensureEncoder(audioSample);\n          }\n          if (!this.encoderInitialized) {\n            await this.ensureEncoderPromise;\n          }\n        }\n        assert(this.encoderInitialized);\n        {\n          const startSampleIndex = Math.round(\n            audioSample.timestamp * audioSample.sampleRate\n          );\n          const endSampleIndex = Math.round(\n            (audioSample.timestamp + audioSample.duration) * audioSample.sampleRate\n          );\n          if (this.lastEndSampleIndex === null) {\n            this.lastEndSampleIndex = endSampleIndex;\n          } else {\n            const sampleDiff = startSampleIndex - this.lastEndSampleIndex;\n            if (sampleDiff >= 64) {\n              const fillSample = new AudioSample({\n                data: new Float32Array(sampleDiff * audioSample.numberOfChannels),\n                format: \"f32-planar\",\n                sampleRate: audioSample.sampleRate,\n                numberOfChannels: audioSample.numberOfChannels,\n                numberOfFrames: sampleDiff,\n                timestamp: this.lastEndSampleIndex / audioSample.sampleRate\n              });\n              await this.add(fillSample, true);\n            }\n            this.lastEndSampleIndex += audioSample.numberOfFrames;\n          }\n        }\n        if (this.customEncoder) {\n          this.customEncoderQueueSize++;\n          const clonedSample = audioSample.clone();\n          const promise = this.customEncoderCallSerializer.call(() => this.customEncoder.encode(clonedSample)).then(() => this.customEncoderQueueSize--).catch((error) => this.error ??= error).finally(() => {\n            clonedSample.close();\n          });\n          if (this.customEncoderQueueSize >= 4) {\n            await promise;\n          }\n          await this.muxer.mutex.currentPromise;\n        } else if (this.isPcmEncoder) {\n          await this.doPcmEncoding(audioSample, shouldClose);\n        } else {\n          assert(this.encoder);\n          const audioData = audioSample.toAudioData();\n          this.encoder.encode(audioData);\n          audioData.close();\n          if (shouldClose) {\n            audioSample.close();\n          }\n          if (this.encoder.encodeQueueSize >= 4) {\n            await new Promise((resolve) => this.encoder.addEventListener(\"dequeue\", resolve, { once: true }));\n          }\n          await this.muxer.mutex.currentPromise;\n        }\n      } finally {\n        if (shouldClose) {\n          audioSample.close();\n        }\n      }\n    }\n    async doPcmEncoding(audioSample, shouldClose) {\n      assert(this.outputSampleSize);\n      assert(this.writeOutputValue);\n      const { numberOfChannels, numberOfFrames, sampleRate, timestamp } = audioSample;\n      const CHUNK_SIZE = 2048;\n      const outputs = [];\n      for (let frame = 0; frame < numberOfFrames; frame += CHUNK_SIZE) {\n        const frameCount = Math.min(CHUNK_SIZE, audioSample.numberOfFrames - frame);\n        const outputSize = frameCount * numberOfChannels * this.outputSampleSize;\n        const outputBuffer = new ArrayBuffer(outputSize);\n        const outputView = new DataView(outputBuffer);\n        outputs.push({ frameCount, view: outputView });\n      }\n      const allocationSize = audioSample.allocationSize({ planeIndex: 0, format: \"f32-planar\" });\n      const floats = new Float32Array(allocationSize / Float32Array.BYTES_PER_ELEMENT);\n      for (let i = 0; i < numberOfChannels; i++) {\n        audioSample.copyTo(floats, { planeIndex: i, format: \"f32-planar\" });\n        for (let j = 0; j < outputs.length; j++) {\n          const { frameCount, view: view2 } = outputs[j];\n          for (let k = 0; k < frameCount; k++) {\n            this.writeOutputValue(\n              view2,\n              (k * numberOfChannels + i) * this.outputSampleSize,\n              floats[j * CHUNK_SIZE + k]\n            );\n          }\n        }\n      }\n      if (shouldClose) {\n        audioSample.close();\n      }\n      const meta = {\n        decoderConfig: {\n          codec: this.encodingConfig.codec,\n          numberOfChannels,\n          sampleRate\n        }\n      };\n      for (let i = 0; i < outputs.length; i++) {\n        const { frameCount, view: view2 } = outputs[i];\n        const outputBuffer = view2.buffer;\n        const startFrame = i * CHUNK_SIZE;\n        const packet = new EncodedPacket(\n          new Uint8Array(outputBuffer),\n          \"key\",\n          timestamp + startFrame / sampleRate,\n          frameCount / sampleRate\n        );\n        this.encodingConfig.onEncodedPacket?.(packet, meta);\n        await this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta);\n      }\n    }\n    ensureEncoder(audioSample) {\n      const encoderError = new Error();\n      this.ensureEncoderPromise = (async () => {\n        const { numberOfChannels, sampleRate } = audioSample;\n        const encoderConfig = buildAudioEncoderConfig({\n          numberOfChannels,\n          sampleRate,\n          ...this.encodingConfig\n        });\n        this.encodingConfig.onEncoderConfig?.(encoderConfig);\n        const MatchingCustomEncoder = customAudioEncoders.find((x) => x.supports(\n          this.encodingConfig.codec,\n          encoderConfig\n        ));\n        if (MatchingCustomEncoder) {\n          this.customEncoder = new MatchingCustomEncoder();\n          this.customEncoder.codec = this.encodingConfig.codec;\n          this.customEncoder.config = encoderConfig;\n          this.customEncoder.onPacket = (packet, meta) => {\n            if (!(packet instanceof EncodedPacket)) {\n              throw new TypeError(\"The first argument passed to onPacket must be an EncodedPacket.\");\n            }\n            if (meta !== void 0 && (!meta || typeof meta !== \"object\")) {\n              throw new TypeError(\"The second argument passed to onPacket must be an object or undefined.\");\n            }\n            this.encodingConfig.onEncodedPacket?.(packet, meta);\n            void this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta).catch((error) => {\n              this.error ??= error;\n              this.errorNeedsNewStack = false;\n            });\n          };\n          await this.customEncoder.init();\n        } else if (PCM_AUDIO_CODECS.includes(this.encodingConfig.codec)) {\n          this.initPcmEncoder();\n        } else {\n          if (typeof AudioEncoder === \"undefined\") {\n            throw new Error(\"AudioEncoder is not supported by this browser.\");\n          }\n          const support = await AudioEncoder.isConfigSupported(encoderConfig);\n          if (!support.supported) {\n            throw new Error(\n              `This specific encoder configuration (${encoderConfig.codec}, ${encoderConfig.bitrate} bps, ${encoderConfig.numberOfChannels} channels, ${encoderConfig.sampleRate} Hz) is not supported by this browser. Consider using another codec or changing your audio parameters.`\n            );\n          }\n          this.encoder = new AudioEncoder({\n            output: (chunk, meta) => {\n              if (this.encodingConfig.codec === \"aac\" && meta?.decoderConfig) {\n                let needsDescriptionOverwrite = false;\n                if (!meta.decoderConfig.description || meta.decoderConfig.description.byteLength < 2) {\n                  needsDescriptionOverwrite = true;\n                } else {\n                  const audioSpecificConfig = parseAacAudioSpecificConfig(\n                    toUint8Array(meta.decoderConfig.description)\n                  );\n                  needsDescriptionOverwrite = audioSpecificConfig.objectType === 0;\n                }\n                if (needsDescriptionOverwrite) {\n                  const objectType = Number(last(encoderConfig.codec.split(\".\")));\n                  meta.decoderConfig.description = buildAacAudioSpecificConfig({\n                    objectType,\n                    numberOfChannels: meta.decoderConfig.numberOfChannels,\n                    sampleRate: meta.decoderConfig.sampleRate\n                  });\n                }\n              }\n              const packet = EncodedPacket.fromEncodedChunk(chunk);\n              this.encodingConfig.onEncodedPacket?.(packet, meta);\n              void this.muxer.addEncodedAudioPacket(this.source._connectedTrack, packet, meta).catch((error) => {\n                this.error ??= error;\n                this.errorNeedsNewStack = false;\n              });\n            },\n            error: (error) => {\n              error.stack = encoderError.stack;\n              this.error ??= error;\n            }\n          });\n          this.encoder.configure(encoderConfig);\n        }\n        assert(this.source._connectedTrack);\n        this.muxer = this.source._connectedTrack.output._muxer;\n        this.encoderInitialized = true;\n      })();\n    }\n    initPcmEncoder() {\n      this.isPcmEncoder = true;\n      const codec = this.encodingConfig.codec;\n      const { dataType, sampleSize, littleEndian } = parsePcmCodec(codec);\n      this.outputSampleSize = sampleSize;\n      switch (sampleSize) {\n        case 1:\n          {\n            if (dataType === \"unsigned\") {\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setUint8(byteOffset, clamp((value + 1) * 127.5, 0, 255));\n            } else if (dataType === \"signed\") {\n              this.writeOutputValue = (view2, byteOffset, value) => {\n                view2.setInt8(byteOffset, clamp(Math.round(value * 128), -128, 127));\n              };\n            } else if (dataType === \"ulaw\") {\n              this.writeOutputValue = (view2, byteOffset, value) => {\n                const int16 = clamp(Math.floor(value * 32767), -32768, 32767);\n                view2.setUint8(byteOffset, toUlaw(int16));\n              };\n            } else if (dataType === \"alaw\") {\n              this.writeOutputValue = (view2, byteOffset, value) => {\n                const int16 = clamp(Math.floor(value * 32767), -32768, 32767);\n                view2.setUint8(byteOffset, toAlaw(int16));\n              };\n            } else {\n              assert(false);\n            }\n          }\n          ;\n          break;\n        case 2:\n          {\n            if (dataType === \"unsigned\") {\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setUint16(byteOffset, clamp((value + 1) * 32767.5, 0, 65535), littleEndian);\n            } else if (dataType === \"signed\") {\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setInt16(byteOffset, clamp(Math.round(value * 32767), -32768, 32767), littleEndian);\n            } else {\n              assert(false);\n            }\n          }\n          ;\n          break;\n        case 3:\n          {\n            if (dataType === \"unsigned\") {\n              this.writeOutputValue = (view2, byteOffset, value) => setUint24(view2, byteOffset, clamp((value + 1) * 83886075e-1, 0, 16777215), littleEndian);\n            } else if (dataType === \"signed\") {\n              this.writeOutputValue = (view2, byteOffset, value) => setInt24(\n                view2,\n                byteOffset,\n                clamp(Math.round(value * 8388607), -8388608, 8388607),\n                littleEndian\n              );\n            } else {\n              assert(false);\n            }\n          }\n          ;\n          break;\n        case 4:\n          {\n            if (dataType === \"unsigned\") {\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setUint32(byteOffset, clamp((value + 1) * 21474836475e-1, 0, 4294967295), littleEndian);\n            } else if (dataType === \"signed\") {\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setInt32(\n                byteOffset,\n                clamp(Math.round(value * 2147483647), -2147483648, 2147483647),\n                littleEndian\n              );\n            } else if (dataType === \"float\") {\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setFloat32(byteOffset, value, littleEndian);\n            } else {\n              assert(false);\n            }\n          }\n          ;\n          break;\n        case 8:\n          {\n            if (dataType === \"float\") {\n              this.writeOutputValue = (view2, byteOffset, value) => view2.setFloat64(byteOffset, value, littleEndian);\n            } else {\n              assert(false);\n            }\n          }\n          ;\n          break;\n        default:\n          {\n            assertNever(sampleSize);\n            assert(false);\n          }\n          ;\n      }\n    }\n    async flushAndClose(forceClose) {\n      if (!forceClose) this.checkForEncoderError();\n      if (this.customEncoder) {\n        if (!forceClose) {\n          void this.customEncoderCallSerializer.call(() => this.customEncoder.flush());\n        }\n        await this.customEncoderCallSerializer.call(() => this.customEncoder.close());\n      } else if (this.encoder) {\n        if (!forceClose) {\n          await this.encoder.flush();\n        }\n        if (this.encoder.state !== \"closed\") {\n          this.encoder.close();\n        }\n      }\n      if (!forceClose) this.checkForEncoderError();\n    }\n    getQueueSize() {\n      if (this.customEncoder) {\n        return this.customEncoderQueueSize;\n      } else if (this.isPcmEncoder) {\n        return 0;\n      } else {\n        return this.encoder?.encodeQueueSize ?? 0;\n      }\n    }\n    checkForEncoderError() {\n      if (this.error) {\n        if (this.errorNeedsNewStack) {\n          this.error.stack = new Error().stack;\n        }\n        throw this.error;\n      }\n    }\n  };\n  var AudioSampleSource = class extends AudioSource {\n    /**\n     * Creates a new {@link AudioSampleSource} whose samples are encoded according to the specified\n     * {@link AudioEncodingConfig}.\n     */\n    constructor(encodingConfig) {\n      validateAudioEncodingConfig(encodingConfig);\n      super(encodingConfig.codec);\n      this._encoder = new AudioEncoderWrapper(this, encodingConfig);\n    }\n    /**\n     * Encodes an audio sample and then adds it to the output.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(audioSample) {\n      if (!(audioSample instanceof AudioSample)) {\n        throw new TypeError(\"audioSample must be an AudioSample.\");\n      }\n      return this._encoder.add(audioSample, false);\n    }\n    /** @internal */\n    _flushAndClose(forceClose) {\n      return this._encoder.flushAndClose(forceClose);\n    }\n  };\n  var AudioBufferSource = class extends AudioSource {\n    /**\n     * Creates a new {@link AudioBufferSource} whose `AudioBuffer` instances are encoded according to the specified\n     * {@link AudioEncodingConfig}.\n     */\n    constructor(encodingConfig) {\n      validateAudioEncodingConfig(encodingConfig);\n      super(encodingConfig.codec);\n      /** @internal */\n      this._accumulatedTime = 0;\n      this._encoder = new AudioEncoderWrapper(this, encodingConfig);\n    }\n    /**\n     * Converts an AudioBuffer to audio samples, encodes them and adds them to the output. The first AudioBuffer will\n     * be played at timestamp 0, and any subsequent AudioBuffer will have a timestamp equal to the total duration of\n     * all previous AudioBuffers.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    async add(audioBuffer) {\n      if (!(audioBuffer instanceof AudioBuffer)) {\n        throw new TypeError(\"audioBuffer must be an AudioBuffer.\");\n      }\n      const iterator = AudioSample._fromAudioBuffer(audioBuffer, this._accumulatedTime);\n      this._accumulatedTime += audioBuffer.duration;\n      for (const audioSample of iterator) {\n        await this._encoder.add(audioSample, true);\n      }\n    }\n    /** @internal */\n    _flushAndClose(forceClose) {\n      return this._encoder.flushAndClose(forceClose);\n    }\n  };\n  var MediaStreamAudioTrackSource = class extends AudioSource {\n    /**\n     * Creates a new {@link MediaStreamAudioTrackSource} from a `MediaStreamAudioTrack`, which will pull audio samples\n     * from the stream in real time and encode them according to {@link AudioEncodingConfig}.\n     */\n    constructor(track, encodingConfig) {\n      if (!(track instanceof MediaStreamTrack) || track.kind !== \"audio\") {\n        throw new TypeError(\"track must be an audio MediaStreamTrack.\");\n      }\n      validateAudioEncodingConfig(encodingConfig);\n      super(encodingConfig.codec);\n      /** @internal */\n      this._abortController = null;\n      /** @internal */\n      this._audioContext = null;\n      /** @internal */\n      this._scriptProcessorNode = null;\n      // Deprecated but goated\n      /** @internal */\n      this._promiseWithResolvers = promiseWithResolvers();\n      /** @internal */\n      this._errorPromiseAccessed = false;\n      /** @internal */\n      this._paused = false;\n      /** @internal */\n      this._lastSampleTimestamp = null;\n      /** @internal */\n      this._pauseOffset = 0;\n      this._encoder = new AudioEncoderWrapper(this, encodingConfig);\n      this._track = track;\n    }\n    /** A promise that rejects upon any error within this source. This promise never resolves. */\n    get errorPromise() {\n      this._errorPromiseAccessed = true;\n      return this._promiseWithResolvers.promise;\n    }\n    /** Whether this source is currently paused as a result of calling `.pause()`. */\n    get paused() {\n      return this._paused;\n    }\n    /** @internal */\n    async _start() {\n      if (!this._errorPromiseAccessed) {\n        console.warn(\n          \"Make sure not to ignore the `errorPromise` field on MediaStreamVideoTrackSource, so that any internal errors get bubbled up properly.\"\n        );\n      }\n      this._abortController = new AbortController();\n      let firstAudioDataTimestamp = null;\n      let errored = false;\n      const onAudioSample = (audioSample) => {\n        if (errored) {\n          audioSample.close();\n          return;\n        }\n        const currentTimestamp = audioSample.timestamp;\n        if (this._paused) {\n          const dataSeen = firstAudioDataTimestamp !== null;\n          if (dataSeen) {\n            if (this._lastSampleTimestamp !== null) {\n              const timeDelta = currentTimestamp - this._lastSampleTimestamp;\n              this._pauseOffset -= timeDelta;\n            }\n            this._lastSampleTimestamp = currentTimestamp;\n          }\n          audioSample.close();\n          return;\n        }\n        if (firstAudioDataTimestamp === null) {\n          firstAudioDataTimestamp = audioSample.timestamp;\n          const muxer = this._connectedTrack.output._muxer;\n          if (muxer.firstMediaStreamTimestamp === null) {\n            muxer.firstMediaStreamTimestamp = performance.now() / 1e3;\n            this._timestampOffset = -firstAudioDataTimestamp;\n          } else {\n            this._timestampOffset = performance.now() / 1e3 - muxer.firstMediaStreamTimestamp - firstAudioDataTimestamp;\n          }\n        }\n        this._lastSampleTimestamp = currentTimestamp;\n        if (this._encoder.getQueueSize() >= 4) {\n          audioSample.close();\n          return;\n        }\n        audioSample.setTimestamp(currentTimestamp + this._pauseOffset);\n        void this._encoder.add(audioSample, true).catch((error) => {\n          errored = true;\n          this._abortController?.abort();\n          this._promiseWithResolvers.reject(error);\n          void this._audioContext?.suspend();\n        });\n      };\n      if (typeof MediaStreamTrackProcessor !== \"undefined\") {\n        const processor = new MediaStreamTrackProcessor({ track: this._track });\n        const consumer = new WritableStream({\n          write: (audioData) => onAudioSample(new AudioSample(audioData))\n        });\n        processor.readable.pipeTo(consumer, {\n          signal: this._abortController.signal\n        }).catch((error) => {\n          if (error instanceof DOMException && error.name === \"AbortError\") return;\n          this._promiseWithResolvers.reject(error);\n        });\n      } else {\n        const AudioContext = window.AudioContext || window.webkitAudioContext;\n        this._audioContext = new AudioContext({ sampleRate: this._track.getSettings().sampleRate });\n        const sourceNode = this._audioContext.createMediaStreamSource(new MediaStream([this._track]));\n        this._scriptProcessorNode = this._audioContext.createScriptProcessor(4096);\n        if (this._audioContext.state === \"suspended\") {\n          await this._audioContext.resume();\n        }\n        sourceNode.connect(this._scriptProcessorNode);\n        this._scriptProcessorNode.connect(this._audioContext.destination);\n        let totalDuration = 0;\n        this._scriptProcessorNode.onaudioprocess = (event) => {\n          const iterator = AudioSample._fromAudioBuffer(event.inputBuffer, totalDuration);\n          totalDuration += event.inputBuffer.duration;\n          for (const audioSample of iterator) {\n            onAudioSample(audioSample);\n          }\n        };\n      }\n    }\n    /**\n     * Pauses the capture of audio data - any audio data emitted by the underlying media stream will be ignored\n     * while paused. This does *not* close the underlying `MediaStreamAudioTrack`, it just ignores its output.\n     */\n    pause() {\n      this._paused = true;\n    }\n    /** Resumes the capture of audio data after being paused. */\n    resume() {\n      this._paused = false;\n    }\n    /** @internal */\n    async _flushAndClose(forceClose) {\n      if (this._abortController) {\n        this._abortController.abort();\n        this._abortController = null;\n      }\n      if (this._audioContext) {\n        assert(this._scriptProcessorNode);\n        this._scriptProcessorNode.disconnect();\n        await this._audioContext.suspend();\n      }\n      await this._encoder.flushAndClose(forceClose);\n    }\n  };\n  var mediaStreamTrackProcessorWorkerCode = () => {\n    const sendMessage = (message, transfer) => {\n      if (transfer) {\n        self.postMessage(message, { transfer });\n      } else {\n        self.postMessage(message);\n      }\n    };\n    sendMessage({\n      type: \"support\",\n      supported: typeof MediaStreamTrackProcessor !== \"undefined\"\n    });\n    const abortControllers = /* @__PURE__ */ new Map();\n    const activeTracks = /* @__PURE__ */ new Map();\n    self.addEventListener(\"message\", (event) => {\n      const message = event.data;\n      switch (message.type) {\n        case \"videoTrack\":\n          {\n            activeTracks.set(message.trackId, message.track);\n            const processor = new MediaStreamTrackProcessor({ track: message.track });\n            const consumer = new WritableStream({\n              write: (videoFrame) => {\n                if (!activeTracks.has(message.trackId)) {\n                  videoFrame.close();\n                  return;\n                }\n                sendMessage({\n                  type: \"videoFrame\",\n                  trackId: message.trackId,\n                  videoFrame\n                }, [videoFrame]);\n              }\n            });\n            const abortController = new AbortController();\n            abortControllers.set(message.trackId, abortController);\n            processor.readable.pipeTo(consumer, {\n              signal: abortController.signal\n            }).catch((error) => {\n              if (error instanceof DOMException && error.name === \"AbortError\") return;\n              sendMessage({\n                type: \"error\",\n                trackId: message.trackId,\n                error\n              });\n            });\n          }\n          ;\n          break;\n        case \"stopTrack\":\n          {\n            const abortController = abortControllers.get(message.trackId);\n            if (abortController) {\n              abortController.abort();\n              abortControllers.delete(message.trackId);\n            }\n            const track = activeTracks.get(message.trackId);\n            track?.stop();\n            activeTracks.delete(message.trackId);\n            sendMessage({\n              type: \"trackStopped\",\n              trackId: message.trackId\n            });\n          }\n          ;\n          break;\n        default:\n          assertNever(message);\n      }\n    });\n  };\n  var nextMediaStreamTrackProcessorWorkerId = 0;\n  var mediaStreamTrackProcessorWorker = null;\n  var initMediaStreamTrackProcessorWorker = () => {\n    const blob = new Blob(\n      [`(${mediaStreamTrackProcessorWorkerCode.toString()})()`],\n      { type: \"application/javascript\" }\n    );\n    const url2 = URL.createObjectURL(blob);\n    mediaStreamTrackProcessorWorker = new Worker(url2);\n  };\n  var mediaStreamTrackProcessorIsSupportedInWorkerCache = null;\n  var mediaStreamTrackProcessorIsSupportedInWorker = async () => {\n    if (mediaStreamTrackProcessorIsSupportedInWorkerCache !== null) {\n      return mediaStreamTrackProcessorIsSupportedInWorkerCache;\n    }\n    if (!mediaStreamTrackProcessorWorker) {\n      initMediaStreamTrackProcessorWorker();\n    }\n    return new Promise((resolve) => {\n      assert(mediaStreamTrackProcessorWorker);\n      const listener = (event) => {\n        const message = event.data;\n        if (message.type === \"support\") {\n          mediaStreamTrackProcessorIsSupportedInWorkerCache = message.supported;\n          mediaStreamTrackProcessorWorker.removeEventListener(\"message\", listener);\n          resolve(message.supported);\n        }\n      };\n      mediaStreamTrackProcessorWorker.addEventListener(\"message\", listener);\n    });\n  };\n  var sendMessageToMediaStreamTrackProcessorWorker = (message, transfer) => {\n    assert(mediaStreamTrackProcessorWorker);\n    if (transfer) {\n      mediaStreamTrackProcessorWorker.postMessage(message, transfer);\n    } else {\n      mediaStreamTrackProcessorWorker.postMessage(message);\n    }\n  };\n  var SubtitleSource = class extends MediaSource {\n    /** Internal constructor. */\n    constructor(codec) {\n      super();\n      /** @internal */\n      this._connectedTrack = null;\n      if (!SUBTITLE_CODECS.includes(codec)) {\n        throw new TypeError(`Invalid subtitle codec '${codec}'. Must be one of: ${SUBTITLE_CODECS.join(\", \")}.`);\n      }\n      this._codec = codec;\n    }\n  };\n  var TextSubtitleSource = class extends SubtitleSource {\n    /** Creates a new {@link TextSubtitleSource} where added text chunks are in the specified `codec`. */\n    constructor(codec) {\n      super(codec);\n      /** @internal */\n      this._error = null;\n      this._parser = new SubtitleParser({\n        codec,\n        output: (cue, metadata) => {\n          void this._connectedTrack?.output._muxer.addSubtitleCue(this._connectedTrack, cue, metadata).catch((error) => {\n            this._error ??= error;\n          });\n        }\n      });\n    }\n    /**\n     * Parses the subtitle text according to the specified codec and adds it to the output track. You don't have to\n     * add the entire subtitle file at once here; you can provide it in chunks.\n     *\n     * @returns A Promise that resolves once the output is ready to receive more samples. You should await this Promise\n     * to respect writer and encoder backpressure.\n     */\n    add(text) {\n      if (typeof text !== \"string\") {\n        throw new TypeError(\"text must be a string.\");\n      }\n      this._checkForError();\n      this._ensureValidAdd();\n      this._parser.parse(text);\n      return this._connectedTrack.output._muxer.mutex.currentPromise;\n    }\n    /** @internal */\n    _checkForError() {\n      if (this._error) {\n        throw this._error;\n      }\n    }\n    /** @internal */\n    async _flushAndClose(forceClose) {\n      if (!forceClose) {\n        this._checkForError();\n      }\n    }\n  };\n\n  // src/output.ts\n  var ALL_TRACK_TYPES = [\"video\", \"audio\", \"subtitle\"];\n  var validateBaseTrackMetadata = (metadata) => {\n    if (!metadata || typeof metadata !== \"object\") {\n      throw new TypeError(\"metadata must be an object.\");\n    }\n    if (metadata.languageCode !== void 0 && !isIso639Dash2LanguageCode(metadata.languageCode)) {\n      throw new TypeError(\"metadata.languageCode, when provided, must be a three-letter, ISO 639-2/T language code.\");\n    }\n    if (metadata.name !== void 0 && typeof metadata.name !== \"string\") {\n      throw new TypeError(\"metadata.name, when provided, must be a string.\");\n    }\n    if (metadata.disposition !== void 0) {\n      validateTrackDisposition(metadata.disposition);\n    }\n    if (metadata.maximumPacketCount !== void 0 && (!Number.isInteger(metadata.maximumPacketCount) || metadata.maximumPacketCount < 0)) {\n      throw new TypeError(\"metadata.maximumPacketCount, when provided, must be a non-negative integer.\");\n    }\n  };\n  var Output = class {\n    /**\n     * Creates a new instance of {@link Output} which can then be used to create a new media file according to the\n     * specified {@link OutputOptions}.\n     */\n    constructor(options) {\n      /** The current state of the output. */\n      this.state = \"pending\";\n      /** @internal */\n      this._tracks = [];\n      /** @internal */\n      this._startPromise = null;\n      /** @internal */\n      this._cancelPromise = null;\n      /** @internal */\n      this._finalizePromise = null;\n      /** @internal */\n      this._mutex = new AsyncMutex();\n      /** @internal */\n      this._metadataTags = {};\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (!(options.format instanceof OutputFormat)) {\n        throw new TypeError(\"options.format must be an OutputFormat.\");\n      }\n      if (!(options.target instanceof Target)) {\n        throw new TypeError(\"options.target must be a Target.\");\n      }\n      if (options.target._output) {\n        throw new Error(\"Target is already used for another output.\");\n      }\n      options.target._output = this;\n      this.format = options.format;\n      this.target = options.target;\n      this._writer = options.target._createWriter();\n      this._muxer = options.format._createMuxer(this);\n    }\n    /** Adds a video track to the output with the given source. Can only be called before the output is started. */\n    addVideoTrack(source, metadata = {}) {\n      if (!(source instanceof VideoSource)) {\n        throw new TypeError(\"source must be a VideoSource.\");\n      }\n      validateBaseTrackMetadata(metadata);\n      if (metadata.rotation !== void 0 && ![0, 90, 180, 270].includes(metadata.rotation)) {\n        throw new TypeError(`Invalid video rotation: ${metadata.rotation}. Has to be 0, 90, 180 or 270.`);\n      }\n      if (!this.format.supportsVideoRotationMetadata && metadata.rotation) {\n        throw new Error(`${this.format._name} does not support video rotation metadata.`);\n      }\n      if (metadata.frameRate !== void 0 && (!Number.isFinite(metadata.frameRate) || metadata.frameRate <= 0)) {\n        throw new TypeError(\n          `Invalid video frame rate: ${metadata.frameRate}. Must be a positive number.`\n        );\n      }\n      this._addTrack(\"video\", source, metadata);\n    }\n    /** Adds an audio track to the output with the given source. Can only be called before the output is started. */\n    addAudioTrack(source, metadata = {}) {\n      if (!(source instanceof AudioSource)) {\n        throw new TypeError(\"source must be an AudioSource.\");\n      }\n      validateBaseTrackMetadata(metadata);\n      this._addTrack(\"audio\", source, metadata);\n    }\n    /** Adds a subtitle track to the output with the given source. Can only be called before the output is started. */\n    addSubtitleTrack(source, metadata = {}) {\n      if (!(source instanceof SubtitleSource)) {\n        throw new TypeError(\"source must be a SubtitleSource.\");\n      }\n      validateBaseTrackMetadata(metadata);\n      this._addTrack(\"subtitle\", source, metadata);\n    }\n    /**\n     * Sets descriptive metadata tags about the media file, such as title, author, date, or cover art. When called\n     * multiple times, only the metadata from the last call will be used.\n     *\n     * Can only be called before the output is started.\n     */\n    setMetadataTags(tags) {\n      validateMetadataTags(tags);\n      if (this.state !== \"pending\") {\n        throw new Error(\"Cannot set metadata tags after output has been started or canceled.\");\n      }\n      this._metadataTags = tags;\n    }\n    /** @internal */\n    _addTrack(type, source, metadata) {\n      if (this.state !== \"pending\") {\n        throw new Error(\"Cannot add track after output has been started or canceled.\");\n      }\n      if (source._connectedTrack) {\n        throw new Error(\"Source is already used for a track.\");\n      }\n      const supportedTrackCounts = this.format.getSupportedTrackCounts();\n      const presentTracksOfThisType = this._tracks.reduce(\n        (count, track2) => count + (track2.type === type ? 1 : 0),\n        0\n      );\n      const maxCount = supportedTrackCounts[type].max;\n      if (presentTracksOfThisType === maxCount) {\n        throw new Error(\n          maxCount === 0 ? `${this.format._name} does not support ${type} tracks.` : `${this.format._name} does not support more than ${maxCount} ${type} track${maxCount === 1 ? \"\" : \"s\"}.`\n        );\n      }\n      const maxTotalCount = supportedTrackCounts.total.max;\n      if (this._tracks.length === maxTotalCount) {\n        throw new Error(\n          `${this.format._name} does not support more than ${maxTotalCount} tracks${maxTotalCount === 1 ? \"\" : \"s\"} in total.`\n        );\n      }\n      const track = {\n        id: this._tracks.length + 1,\n        output: this,\n        type,\n        source,\n        metadata\n      };\n      if (track.type === \"video\") {\n        const supportedVideoCodecs = this.format.getSupportedVideoCodecs();\n        if (supportedVideoCodecs.length === 0) {\n          throw new Error(\n            `${this.format._name} does not support video tracks.` + this.format._codecUnsupportedHint(track.source._codec)\n          );\n        } else if (!supportedVideoCodecs.includes(track.source._codec)) {\n          throw new Error(\n            `Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported video codecs are: ${supportedVideoCodecs.map((codec) => `'${codec}'`).join(\", \")}.` + this.format._codecUnsupportedHint(track.source._codec)\n          );\n        }\n      } else if (track.type === \"audio\") {\n        const supportedAudioCodecs = this.format.getSupportedAudioCodecs();\n        if (supportedAudioCodecs.length === 0) {\n          throw new Error(\n            `${this.format._name} does not support audio tracks.` + this.format._codecUnsupportedHint(track.source._codec)\n          );\n        } else if (!supportedAudioCodecs.includes(track.source._codec)) {\n          throw new Error(\n            `Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported audio codecs are: ${supportedAudioCodecs.map((codec) => `'${codec}'`).join(\", \")}.` + this.format._codecUnsupportedHint(track.source._codec)\n          );\n        }\n      } else if (track.type === \"subtitle\") {\n        const supportedSubtitleCodecs = this.format.getSupportedSubtitleCodecs();\n        if (supportedSubtitleCodecs.length === 0) {\n          throw new Error(\n            `${this.format._name} does not support subtitle tracks.` + this.format._codecUnsupportedHint(track.source._codec)\n          );\n        } else if (!supportedSubtitleCodecs.includes(track.source._codec)) {\n          throw new Error(\n            `Codec '${track.source._codec}' cannot be contained within ${this.format._name}. Supported subtitle codecs are: ${supportedSubtitleCodecs.map((codec) => `'${codec}'`).join(\", \")}.` + this.format._codecUnsupportedHint(track.source._codec)\n          );\n        }\n      }\n      this._tracks.push(track);\n      source._connectedTrack = track;\n    }\n    /**\n     * Starts the creation of the output file. This method should be called after all tracks have been added. Only after\n     * the output has started can media samples be added to the tracks.\n     *\n     * @returns A promise that resolves when the output has successfully started and is ready to receive media samples.\n     */\n    async start() {\n      const supportedTrackCounts = this.format.getSupportedTrackCounts();\n      for (const trackType of ALL_TRACK_TYPES) {\n        const presentTracksOfThisType = this._tracks.reduce(\n          (count, track) => count + (track.type === trackType ? 1 : 0),\n          0\n        );\n        const minCount = supportedTrackCounts[trackType].min;\n        if (presentTracksOfThisType < minCount) {\n          throw new Error(\n            minCount === supportedTrackCounts[trackType].max ? `${this.format._name} requires exactly ${minCount} ${trackType} track${minCount === 1 ? \"\" : \"s\"}.` : `${this.format._name} requires at least ${minCount} ${trackType} track${minCount === 1 ? \"\" : \"s\"}.`\n          );\n        }\n      }\n      const totalMinCount = supportedTrackCounts.total.min;\n      if (this._tracks.length < totalMinCount) {\n        throw new Error(\n          totalMinCount === supportedTrackCounts.total.max ? `${this.format._name} requires exactly ${totalMinCount} track${totalMinCount === 1 ? \"\" : \"s\"}.` : `${this.format._name} requires at least ${totalMinCount} track${totalMinCount === 1 ? \"\" : \"s\"}.`\n        );\n      }\n      if (this.state === \"canceled\") {\n        throw new Error(\"Output has been canceled.\");\n      }\n      if (this._startPromise) {\n        console.warn(\"Output has already been started.\");\n        return this._startPromise;\n      }\n      return this._startPromise = (async () => {\n        this.state = \"started\";\n        this._writer.start();\n        const release = await this._mutex.acquire();\n        await this._muxer.start();\n        const promises = this._tracks.map((track) => track.source._start());\n        await Promise.all(promises);\n        release();\n      })();\n    }\n    /**\n     * Resolves with the full MIME type of the output file, including track codecs.\n     *\n     * The returned promise will resolve only once the precise codec strings of all tracks are known.\n     */\n    getMimeType() {\n      return this._muxer.getMimeType();\n    }\n    /**\n     * Cancels the creation of the output file, releasing internal resources like encoders and preventing further\n     * samples from being added.\n     *\n     * @returns A promise that resolves once all internal resources have been released.\n     */\n    async cancel() {\n      if (this._cancelPromise) {\n        console.warn(\"Output has already been canceled.\");\n        return this._cancelPromise;\n      } else if (this.state === \"finalizing\" || this.state === \"finalized\") {\n        console.warn(\"Output has already been finalized.\");\n        return;\n      }\n      return this._cancelPromise = (async () => {\n        this.state = \"canceled\";\n        const release = await this._mutex.acquire();\n        const promises = this._tracks.map((x) => x.source._flushOrWaitForOngoingClose(true));\n        await Promise.all(promises);\n        await this._writer.close();\n        release();\n      })();\n    }\n    /**\n     * Finalizes the output file. This method must be called after all media samples across all tracks have been added.\n     * Once the Promise returned by this method completes, the output file is ready.\n     */\n    async finalize() {\n      if (this.state === \"pending\") {\n        throw new Error(\"Cannot finalize before starting.\");\n      }\n      if (this.state === \"canceled\") {\n        throw new Error(\"Cannot finalize after canceling.\");\n      }\n      if (this._finalizePromise) {\n        console.warn(\"Output has already been finalized.\");\n        return this._finalizePromise;\n      }\n      return this._finalizePromise = (async () => {\n        this.state = \"finalizing\";\n        const release = await this._mutex.acquire();\n        const promises = this._tracks.map((x) => x.source._flushOrWaitForOngoingClose(false));\n        await Promise.all(promises);\n        await this._muxer.finalize();\n        await this._writer.flush();\n        await this._writer.finalize();\n        this.state = \"finalized\";\n        release();\n      })();\n    }\n  };\n\n  // src/conversion.ts\n  var validateVideoOptions = (videoOptions) => {\n    if (videoOptions !== void 0 && (!videoOptions || typeof videoOptions !== \"object\")) {\n      throw new TypeError(\"options.video, when provided, must be an object.\");\n    }\n    if (videoOptions?.discard !== void 0 && typeof videoOptions.discard !== \"boolean\") {\n      throw new TypeError(\"options.video.discard, when provided, must be a boolean.\");\n    }\n    if (videoOptions?.forceTranscode !== void 0 && typeof videoOptions.forceTranscode !== \"boolean\") {\n      throw new TypeError(\"options.video.forceTranscode, when provided, must be a boolean.\");\n    }\n    if (videoOptions?.codec !== void 0 && !VIDEO_CODECS.includes(videoOptions.codec)) {\n      throw new TypeError(\n        `options.video.codec, when provided, must be one of: ${VIDEO_CODECS.join(\", \")}.`\n      );\n    }\n    if (videoOptions?.bitrate !== void 0 && !(videoOptions.bitrate instanceof Quality) && (!Number.isInteger(videoOptions.bitrate) || videoOptions.bitrate <= 0)) {\n      throw new TypeError(\"options.video.bitrate, when provided, must be a positive integer or a quality.\");\n    }\n    if (videoOptions?.width !== void 0 && (!Number.isInteger(videoOptions.width) || videoOptions.width <= 0)) {\n      throw new TypeError(\"options.video.width, when provided, must be a positive integer.\");\n    }\n    if (videoOptions?.height !== void 0 && (!Number.isInteger(videoOptions.height) || videoOptions.height <= 0)) {\n      throw new TypeError(\"options.video.height, when provided, must be a positive integer.\");\n    }\n    if (videoOptions?.fit !== void 0 && ![\"fill\", \"contain\", \"cover\"].includes(videoOptions.fit)) {\n      throw new TypeError(\"options.video.fit, when provided, must be one of 'fill', 'contain', or 'cover'.\");\n    }\n    if (videoOptions?.width !== void 0 && videoOptions.height !== void 0 && videoOptions.fit === void 0) {\n      throw new TypeError(\n        \"When both options.video.width and options.video.height are provided, options.video.fit must also be provided.\"\n      );\n    }\n    if (videoOptions?.rotate !== void 0 && ![0, 90, 180, 270].includes(videoOptions.rotate)) {\n      throw new TypeError(\"options.video.rotate, when provided, must be 0, 90, 180 or 270.\");\n    }\n    if (videoOptions?.allowRotationMetadata !== void 0 && typeof videoOptions.allowRotationMetadata !== \"boolean\") {\n      throw new TypeError(\"options.video.allowRotationMetadata, when provided, must be a boolean.\");\n    }\n    if (videoOptions?.crop !== void 0) {\n      validateCropRectangle(videoOptions.crop, \"options.video.\");\n    }\n    if (videoOptions?.frameRate !== void 0 && (!Number.isFinite(videoOptions.frameRate) || videoOptions.frameRate <= 0)) {\n      throw new TypeError(\"options.video.frameRate, when provided, must be a finite positive number.\");\n    }\n    if (videoOptions?.alpha !== void 0 && ![\"discard\", \"keep\"].includes(videoOptions.alpha)) {\n      throw new TypeError(\"options.video.alpha, when provided, must be either 'discard' or 'keep'.\");\n    }\n    if (videoOptions?.keyFrameInterval !== void 0 && (!Number.isFinite(videoOptions.keyFrameInterval) || videoOptions.keyFrameInterval < 0)) {\n      throw new TypeError(\"options.video.keyFrameInterval, when provided, must be a non-negative number.\");\n    }\n    if (videoOptions?.process !== void 0 && typeof videoOptions.process !== \"function\") {\n      throw new TypeError(\"options.video.process, when provided, must be a function.\");\n    }\n    if (videoOptions?.processedWidth !== void 0 && (!Number.isInteger(videoOptions.processedWidth) || videoOptions.processedWidth <= 0)) {\n      throw new TypeError(\"options.video.processedWidth, when provided, must be a positive integer.\");\n    }\n    if (videoOptions?.processedHeight !== void 0 && (!Number.isInteger(videoOptions.processedHeight) || videoOptions.processedHeight <= 0)) {\n      throw new TypeError(\"options.video.processedHeight, when provided, must be a positive integer.\");\n    }\n    if (videoOptions?.hardwareAcceleration !== void 0 && ![\"no-preference\", \"prefer-hardware\", \"prefer-software\"].includes(videoOptions.hardwareAcceleration)) {\n      throw new TypeError(\n        \"options.video.hardwareAcceleration, when provided, must be 'no-preference', 'prefer-hardware' or 'prefer-software'.\"\n      );\n    }\n  };\n  var validateAudioOptions = (audioOptions) => {\n    if (audioOptions !== void 0 && (!audioOptions || typeof audioOptions !== \"object\")) {\n      throw new TypeError(\"options.audio, when provided, must be an object.\");\n    }\n    if (audioOptions?.discard !== void 0 && typeof audioOptions.discard !== \"boolean\") {\n      throw new TypeError(\"options.audio.discard, when provided, must be a boolean.\");\n    }\n    if (audioOptions?.forceTranscode !== void 0 && typeof audioOptions.forceTranscode !== \"boolean\") {\n      throw new TypeError(\"options.audio.forceTranscode, when provided, must be a boolean.\");\n    }\n    if (audioOptions?.codec !== void 0 && !AUDIO_CODECS.includes(audioOptions.codec)) {\n      throw new TypeError(\n        `options.audio.codec, when provided, must be one of: ${AUDIO_CODECS.join(\", \")}.`\n      );\n    }\n    if (audioOptions?.bitrate !== void 0 && !(audioOptions.bitrate instanceof Quality) && (!Number.isInteger(audioOptions.bitrate) || audioOptions.bitrate <= 0)) {\n      throw new TypeError(\"options.audio.bitrate, when provided, must be a positive integer or a quality.\");\n    }\n    if (audioOptions?.numberOfChannels !== void 0 && (!Number.isInteger(audioOptions.numberOfChannels) || audioOptions.numberOfChannels <= 0)) {\n      throw new TypeError(\"options.audio.numberOfChannels, when provided, must be a positive integer.\");\n    }\n    if (audioOptions?.sampleRate !== void 0 && (!Number.isInteger(audioOptions.sampleRate) || audioOptions.sampleRate <= 0)) {\n      throw new TypeError(\"options.audio.sampleRate, when provided, must be a positive integer.\");\n    }\n    if (audioOptions?.process !== void 0 && typeof audioOptions.process !== \"function\") {\n      throw new TypeError(\"options.audio.process, when provided, must be a function.\");\n    }\n    if (audioOptions?.processedNumberOfChannels !== void 0 && (!Number.isInteger(audioOptions.processedNumberOfChannels) || audioOptions.processedNumberOfChannels <= 0)) {\n      throw new TypeError(\"options.audio.processedNumberOfChannels, when provided, must be a positive integer.\");\n    }\n    if (audioOptions?.processedSampleRate !== void 0 && (!Number.isInteger(audioOptions.processedSampleRate) || audioOptions.processedSampleRate <= 0)) {\n      throw new TypeError(\"options.audio.processedSampleRate, when provided, must be a positive integer.\");\n    }\n  };\n  var FALLBACK_NUMBER_OF_CHANNELS = 2;\n  var FALLBACK_SAMPLE_RATE = 48e3;\n  var Conversion = class _Conversion {\n    /** Creates a new Conversion instance (duh). */\n    constructor(options) {\n      /** @internal */\n      this._addedCounts = {\n        video: 0,\n        audio: 0,\n        subtitle: 0\n      };\n      /** @internal */\n      this._totalTrackCount = 0;\n      /** @internal */\n      this._trackPromises = [];\n      /** @internal */\n      this._executed = false;\n      /** @internal */\n      this._synchronizer = new TrackSynchronizer();\n      /** @internal */\n      this._totalDuration = null;\n      /** @internal */\n      this._maxTimestamps = /* @__PURE__ */ new Map();\n      // Track ID -> timestamp\n      /** @internal */\n      this._canceled = false;\n      /**\n       * A callback that is fired whenever the conversion progresses. Returns a number between 0 and 1, indicating the\n       * completion of the conversion. Note that a progress of 1 doesn't necessarily mean the conversion is complete;\n       * the conversion is complete once `execute()` resolves.\n       *\n       * In order for progress to be computed, this property must be set before `execute` is called.\n       */\n      this.onProgress = void 0;\n      /** @internal */\n      this._computeProgress = false;\n      /** @internal */\n      this._lastProgress = 0;\n      /**\n       * Whether this conversion, as it has been configured, is valid and can be executed. If this field is `false`, check\n       * the `discardedTracks` field for reasons.\n       */\n      this.isValid = false;\n      /** The list of tracks that are included in the output file. */\n      this.utilizedTracks = [];\n      /** The list of tracks from the input file that have been discarded, alongside the discard reason. */\n      this.discardedTracks = [];\n      if (!options || typeof options !== \"object\") {\n        throw new TypeError(\"options must be an object.\");\n      }\n      if (!(options.input instanceof Input)) {\n        throw new TypeError(\"options.input must be an Input.\");\n      }\n      if (!(options.output instanceof Output)) {\n        throw new TypeError(\"options.output must be an Output.\");\n      }\n      if (options.output._tracks.length > 0 || Object.keys(options.output._metadataTags).length > 0 || options.output.state !== \"pending\") {\n        throw new TypeError(\"options.output must be fresh: no tracks or metadata tags added and not started.\");\n      }\n      if (typeof options.video !== \"function\") {\n        validateVideoOptions(options.video);\n      } else {\n      }\n      if (typeof options.audio !== \"function\") {\n        validateAudioOptions(options.audio);\n      } else {\n      }\n      if (options.trim !== void 0 && (!options.trim || typeof options.trim !== \"object\")) {\n        throw new TypeError(\"options.trim, when provided, must be an object.\");\n      }\n      if (options.trim?.start !== void 0 && (!Number.isFinite(options.trim.start) || options.trim.start < 0)) {\n        throw new TypeError(\"options.trim.start, when provided, must be a non-negative number.\");\n      }\n      if (options.trim?.end !== void 0 && (!Number.isFinite(options.trim.end) || options.trim.end < 0)) {\n        throw new TypeError(\"options.trim.end, when provided, must be a non-negative number.\");\n      }\n      if (options.trim?.start !== void 0 && options.trim.end !== void 0 && options.trim.start >= options.trim.end) {\n        throw new TypeError(\"options.trim.start must be less than options.trim.end.\");\n      }\n      if (options.tags !== void 0 && (typeof options.tags !== \"object\" || !options.tags) && typeof options.tags !== \"function\") {\n        throw new TypeError(\"options.tags, when provided, must be an object or a function.\");\n      }\n      if (typeof options.tags === \"object\") {\n        validateMetadataTags(options.tags);\n      }\n      if (options.showWarnings !== void 0 && typeof options.showWarnings !== \"boolean\") {\n        throw new TypeError(\"options.showWarnings, when provided, must be a boolean.\");\n      }\n      this._options = options;\n      this.input = options.input;\n      this.output = options.output;\n      const { promise: started, resolve: start } = promiseWithResolvers();\n      this._started = started;\n      this._start = start;\n    }\n    /** Initializes a new conversion process without starting the conversion. */\n    static async init(options) {\n      const conversion = new _Conversion(options);\n      await conversion._init();\n      return conversion;\n    }\n    /** @internal */\n    async _init() {\n      this._startTimestamp = this._options.trim?.start ?? Math.max(\n        await this.input.getFirstTimestamp(),\n        // Samples can also have negative timestamps, but the meaning typically is \"don't present me\", so let's cut\n        // those out by default.\n        0\n      );\n      this._endTimestamp = this._options.trim?.end ?? Infinity;\n      const inputTracks = await this.input.getTracks();\n      const outputTrackCounts = this.output.format.getSupportedTrackCounts();\n      let nVideo = 1;\n      let nAudio = 1;\n      for (const track of inputTracks) {\n        let trackOptions = void 0;\n        if (track.isVideoTrack()) {\n          if (this._options.video) {\n            if (typeof this._options.video === \"function\") {\n              trackOptions = await this._options.video(track, nVideo);\n              validateVideoOptions(trackOptions);\n              nVideo++;\n            } else {\n              trackOptions = this._options.video;\n            }\n          }\n        } else if (track.isAudioTrack()) {\n          if (this._options.audio) {\n            if (typeof this._options.audio === \"function\") {\n              trackOptions = await this._options.audio(track, nAudio);\n              validateAudioOptions(trackOptions);\n              nAudio++;\n            } else {\n              trackOptions = this._options.audio;\n            }\n          }\n        } else {\n          assert(false);\n        }\n        if (trackOptions?.discard) {\n          this.discardedTracks.push({\n            track,\n            reason: \"discarded_by_user\"\n          });\n          continue;\n        }\n        if (this._totalTrackCount === outputTrackCounts.total.max) {\n          this.discardedTracks.push({\n            track,\n            reason: \"max_track_count_reached\"\n          });\n          continue;\n        }\n        if (this._addedCounts[track.type] === outputTrackCounts[track.type].max) {\n          this.discardedTracks.push({\n            track,\n            reason: \"max_track_count_of_type_reached\"\n          });\n          continue;\n        }\n        if (track.isVideoTrack()) {\n          await this._processVideoTrack(track, trackOptions ?? {});\n        } else if (track.isAudioTrack()) {\n          await this._processAudioTrack(track, trackOptions ?? {});\n        }\n      }\n      const inputTags = await this.input.getMetadataTags();\n      let outputTags;\n      if (this._options.tags) {\n        const result = typeof this._options.tags === \"function\" ? await this._options.tags(inputTags) : this._options.tags;\n        validateMetadataTags(result);\n        outputTags = result;\n      } else {\n        outputTags = inputTags;\n      }\n      const inputAndOutputFormatMatch = (await this.input.getFormat()).mimeType === this.output.format.mimeType;\n      const rawTagsAreUnchanged = inputTags.raw === outputTags.raw;\n      if (inputTags.raw && rawTagsAreUnchanged && !inputAndOutputFormatMatch) {\n        delete outputTags.raw;\n      }\n      this.output.setMetadataTags(outputTags);\n      this.isValid = this._totalTrackCount >= outputTrackCounts.total.min && this._addedCounts.video >= outputTrackCounts.video.min && this._addedCounts.audio >= outputTrackCounts.audio.min && this._addedCounts.subtitle >= outputTrackCounts.subtitle.min;\n      if (this._options.showWarnings ?? true) {\n        const warnElements = [];\n        const unintentionallyDiscardedTracks = this.discardedTracks.filter((x) => x.reason !== \"discarded_by_user\");\n        if (unintentionallyDiscardedTracks.length > 0) {\n          warnElements.push(\n            \"Some tracks had to be discarded from the conversion:\",\n            unintentionallyDiscardedTracks\n          );\n        }\n        if (!this.isValid) {\n          warnElements.push(\"\\n\\n\" + this._getInvalidityExplanation().join(\"\"));\n        }\n        if (warnElements.length > 0) {\n          console.warn(...warnElements);\n        }\n      }\n    }\n    /** @internal */\n    _getInvalidityExplanation() {\n      const elements = [];\n      if (this.discardedTracks.length === 0) {\n        elements.push(\n          \"Due to missing tracks, this conversion cannot be executed.\"\n        );\n      } else {\n        const encodabilityIsTheProblem = this.discardedTracks.every(\n          (x) => x.reason === \"discarded_by_user\" || x.reason === \"no_encodable_target_codec\"\n        );\n        elements.push(\n          \"Due to discarded tracks, this conversion cannot be executed.\"\n        );\n        if (encodabilityIsTheProblem) {\n          const codecs = this.discardedTracks.flatMap((x) => {\n            if (x.reason === \"discarded_by_user\") return [];\n            if (x.track.type === \"video\") {\n              return this.output.format.getSupportedVideoCodecs();\n            } else if (x.track.type === \"audio\") {\n              return this.output.format.getSupportedAudioCodecs();\n            } else {\n              return this.output.format.getSupportedSubtitleCodecs();\n            }\n          });\n          if (codecs.length === 1) {\n            elements.push(\n              `\nTracks were discarded because your environment is not able to encode '${codecs[0]}'.`\n            );\n          } else {\n            elements.push(\n              `\nTracks were discarded because your environment is not able to encode any of the following codecs: ${codecs.map((x) => `'${x}'`).join(\", \")}.`\n            );\n          }\n          if (codecs.includes(\"mp3\")) {\n            elements.push(\n              `\nThe @mediabunny/mp3-encoder extension package provides support for encoding MP3.`\n            );\n          }\n        } else {\n          elements.push(\"\\nCheck the discardedTracks field for more info.\");\n        }\n      }\n      return elements;\n    }\n    /**\n     * Executes the conversion process. Resolves once conversion is complete.\n     *\n     * Will throw if `isValid` is `false`.\n     */\n    async execute() {\n      if (!this.isValid) {\n        throw new Error(\n          \"Cannot execute this conversion because its output configuration is invalid. Make sure to always check the isValid field before executing a conversion.\\n\" + this._getInvalidityExplanation().join(\"\")\n        );\n      }\n      if (this._executed) {\n        throw new Error(\"Conversion cannot be executed twice.\");\n      }\n      this._executed = true;\n      if (this.onProgress) {\n        this._computeProgress = true;\n        this._totalDuration = Math.min(\n          await this.input.computeDuration() - this._startTimestamp,\n          this._endTimestamp - this._startTimestamp\n        );\n        for (const track of this.utilizedTracks) {\n          this._maxTimestamps.set(track.id, 0);\n        }\n        this.onProgress?.(0);\n      }\n      await this.output.start();\n      this._start();\n      try {\n        await Promise.all(this._trackPromises);\n      } catch (error) {\n        if (!this._canceled) {\n          void this.cancel();\n        }\n        throw error;\n      }\n      if (this._canceled) {\n        throw new ConversionCanceledError();\n      }\n      await this.output.finalize();\n      if (this._computeProgress) {\n        this.onProgress?.(1);\n      }\n    }\n    /**\n     * Cancels the conversion process, causing any ongoing `execute` call to throw a `ConversionCanceledError`.\n     * Does nothing if the conversion is already complete.\n     */\n    async cancel() {\n      if (this.output.state === \"finalizing\" || this.output.state === \"finalized\") {\n        return;\n      }\n      if (this._canceled) {\n        console.warn(\"Conversion already canceled.\");\n        return;\n      }\n      this._canceled = true;\n      await this.output.cancel();\n    }\n    /** @internal */\n    async _processVideoTrack(track, trackOptions) {\n      const sourceCodec = track.codec;\n      if (!sourceCodec) {\n        this.discardedTracks.push({\n          track,\n          reason: \"unknown_source_codec\"\n        });\n        return;\n      }\n      let videoSource;\n      const totalRotation = normalizeRotation(track.rotation + (trackOptions.rotate ?? 0));\n      const canUseRotationMetadata = this.output.format.supportsVideoRotationMetadata && (trackOptions.allowRotationMetadata ?? true);\n      const [rotatedWidth, rotatedHeight] = totalRotation % 180 === 0 ? [track.codedWidth, track.codedHeight] : [track.codedHeight, track.codedWidth];\n      const crop = trackOptions.crop;\n      if (crop) {\n        clampCropRectangle(crop, rotatedWidth, rotatedHeight);\n      }\n      const [originalWidth, originalHeight] = crop ? [crop.width, crop.height] : [rotatedWidth, rotatedHeight];\n      let width = originalWidth;\n      let height = originalHeight;\n      const aspectRatio = width / height;\n      const ceilToMultipleOfTwo = (value) => Math.ceil(value / 2) * 2;\n      if (trackOptions.width !== void 0 && trackOptions.height === void 0) {\n        width = ceilToMultipleOfTwo(trackOptions.width);\n        height = ceilToMultipleOfTwo(Math.round(width / aspectRatio));\n      } else if (trackOptions.width === void 0 && trackOptions.height !== void 0) {\n        height = ceilToMultipleOfTwo(trackOptions.height);\n        width = ceilToMultipleOfTwo(Math.round(height * aspectRatio));\n      } else if (trackOptions.width !== void 0 && trackOptions.height !== void 0) {\n        width = ceilToMultipleOfTwo(trackOptions.width);\n        height = ceilToMultipleOfTwo(trackOptions.height);\n      }\n      const firstTimestamp = await track.getFirstTimestamp();\n      const needsTranscode = !!trackOptions.forceTranscode || firstTimestamp < this._startTimestamp || !!trackOptions.frameRate || trackOptions.keyFrameInterval !== void 0 || trackOptions.process !== void 0;\n      let needsRerender = width !== originalWidth || height !== originalHeight || totalRotation !== 0 && (!canUseRotationMetadata || trackOptions.process !== void 0) || !!crop;\n      const alpha = trackOptions.alpha ?? \"discard\";\n      let videoCodecs = this.output.format.getSupportedVideoCodecs();\n      if (!needsTranscode && !trackOptions.bitrate && !needsRerender && videoCodecs.includes(sourceCodec) && (!trackOptions.codec || trackOptions.codec === sourceCodec)) {\n        const source = new EncodedVideoPacketSource(sourceCodec);\n        videoSource = source;\n        this._trackPromises.push((async () => {\n          await this._started;\n          const sink = new EncodedPacketSink(track);\n          const decoderConfig = await track.getDecoderConfig();\n          const meta = { decoderConfig: decoderConfig ?? void 0 };\n          const endPacket = Number.isFinite(this._endTimestamp) ? await sink.getPacket(this._endTimestamp, { metadataOnly: true }) ?? void 0 : void 0;\n          for await (const packet of sink.packets(void 0, endPacket, { verifyKeyPackets: true })) {\n            if (this._canceled) {\n              return;\n            }\n            const modifiedPacket = packet.clone({\n              timestamp: packet.timestamp - this._startTimestamp,\n              sideData: alpha === \"discard\" ? {} : packet.sideData\n            });\n            assert(modifiedPacket.timestamp >= 0);\n            this._reportProgress(track.id, modifiedPacket.timestamp);\n            await source.add(modifiedPacket, meta);\n            if (this._synchronizer.shouldWait(track.id, modifiedPacket.timestamp)) {\n              await this._synchronizer.wait(modifiedPacket.timestamp);\n            }\n          }\n          source.close();\n          this._synchronizer.closeTrack(track.id);\n        })());\n      } else {\n        const canDecode = await track.canDecode();\n        if (!canDecode) {\n          this.discardedTracks.push({\n            track,\n            reason: \"undecodable_source_codec\"\n          });\n          return;\n        }\n        if (trackOptions.codec) {\n          videoCodecs = videoCodecs.filter((codec) => codec === trackOptions.codec);\n        }\n        const bitrate = trackOptions.bitrate ?? QUALITY_HIGH;\n        const encodableCodec = await getFirstEncodableVideoCodec(videoCodecs, {\n          width: trackOptions.process && trackOptions.processedWidth ? trackOptions.processedWidth : width,\n          height: trackOptions.process && trackOptions.processedHeight ? trackOptions.processedHeight : height,\n          bitrate\n        });\n        if (!encodableCodec) {\n          this.discardedTracks.push({\n            track,\n            reason: \"no_encodable_target_codec\"\n          });\n          return;\n        }\n        const encodingConfig = {\n          codec: encodableCodec,\n          bitrate,\n          keyFrameInterval: trackOptions.keyFrameInterval,\n          sizeChangeBehavior: trackOptions.fit ?? \"passThrough\",\n          alpha,\n          hardwareAcceleration: trackOptions.hardwareAcceleration\n        };\n        const source = new VideoSampleSource(encodingConfig);\n        videoSource = source;\n        if (!needsRerender) {\n          const tempOutput = new Output({\n            format: new Mp4OutputFormat(),\n            // Supports all video codecs\n            target: new NullTarget()\n          });\n          const tempSource = new VideoSampleSource(encodingConfig);\n          tempOutput.addVideoTrack(tempSource);\n          await tempOutput.start();\n          const sink = new VideoSampleSink(track);\n          const firstSample = await sink.getSample(firstTimestamp);\n          if (firstSample) {\n            try {\n              await tempSource.add(firstSample);\n              firstSample.close();\n              await tempOutput.finalize();\n            } catch (error) {\n              console.info(\"Error when probing encoder support. Falling back to rerender path.\", error);\n              needsRerender = true;\n              void tempOutput.cancel();\n            }\n          } else {\n            await tempOutput.cancel();\n          }\n        }\n        if (needsRerender) {\n          this._trackPromises.push((async () => {\n            await this._started;\n            const sink = new CanvasSink(track, {\n              width,\n              height,\n              fit: trackOptions.fit ?? \"fill\",\n              rotation: totalRotation,\n              // Bake the rotation into the output\n              crop: trackOptions.crop,\n              poolSize: 1,\n              alpha: alpha === \"keep\"\n            });\n            const iterator = sink.canvases(this._startTimestamp, this._endTimestamp);\n            const frameRate = trackOptions.frameRate;\n            let lastCanvas = null;\n            let lastCanvasTimestamp = null;\n            let lastCanvasEndTimestamp = null;\n            const padFrames = async (until) => {\n              assert(lastCanvas);\n              assert(frameRate !== void 0);\n              const frameDifference = Math.round((until - lastCanvasTimestamp) * frameRate);\n              for (let i = 1; i < frameDifference; i++) {\n                const sample = new VideoSample(lastCanvas, {\n                  timestamp: lastCanvasTimestamp + i / frameRate,\n                  duration: 1 / frameRate\n                });\n                await this._registerVideoSample(track, trackOptions, source, sample);\n                sample.close();\n              }\n            };\n            for await (const { canvas, timestamp, duration } of iterator) {\n              if (this._canceled) {\n                return;\n              }\n              let adjustedSampleTimestamp = Math.max(timestamp - this._startTimestamp, 0);\n              lastCanvasEndTimestamp = adjustedSampleTimestamp + duration;\n              if (frameRate !== void 0) {\n                const alignedTimestamp = Math.floor(adjustedSampleTimestamp * frameRate) / frameRate;\n                if (lastCanvas !== null) {\n                  if (alignedTimestamp <= lastCanvasTimestamp) {\n                    lastCanvas = canvas;\n                    lastCanvasTimestamp = alignedTimestamp;\n                    continue;\n                  } else {\n                    await padFrames(alignedTimestamp);\n                  }\n                }\n                adjustedSampleTimestamp = alignedTimestamp;\n              }\n              const sample = new VideoSample(canvas, {\n                timestamp: adjustedSampleTimestamp,\n                duration: frameRate !== void 0 ? 1 / frameRate : duration\n              });\n              await this._registerVideoSample(track, trackOptions, source, sample);\n              sample.close();\n              if (frameRate !== void 0) {\n                lastCanvas = canvas;\n                lastCanvasTimestamp = adjustedSampleTimestamp;\n              }\n            }\n            if (lastCanvas) {\n              assert(lastCanvasEndTimestamp !== null);\n              assert(frameRate !== void 0);\n              await padFrames(Math.floor(lastCanvasEndTimestamp * frameRate) / frameRate);\n            }\n            source.close();\n            this._synchronizer.closeTrack(track.id);\n          })());\n        } else {\n          this._trackPromises.push((async () => {\n            await this._started;\n            const sink = new VideoSampleSink(track);\n            const frameRate = trackOptions.frameRate;\n            let lastSample = null;\n            let lastSampleTimestamp = null;\n            let lastSampleEndTimestamp = null;\n            const padFrames = async (until) => {\n              assert(lastSample);\n              assert(frameRate !== void 0);\n              const frameDifference = Math.round((until - lastSampleTimestamp) * frameRate);\n              for (let i = 1; i < frameDifference; i++) {\n                lastSample.setTimestamp(lastSampleTimestamp + i / frameRate);\n                lastSample.setDuration(1 / frameRate);\n                await this._registerVideoSample(track, trackOptions, source, lastSample);\n              }\n              lastSample.close();\n            };\n            for await (const sample of sink.samples(this._startTimestamp, this._endTimestamp)) {\n              if (this._canceled) {\n                sample.close();\n                lastSample?.close();\n                return;\n              }\n              let adjustedSampleTimestamp = Math.max(sample.timestamp - this._startTimestamp, 0);\n              lastSampleEndTimestamp = adjustedSampleTimestamp + sample.duration;\n              if (frameRate !== void 0) {\n                const alignedTimestamp = Math.floor(adjustedSampleTimestamp * frameRate) / frameRate;\n                if (lastSample !== null) {\n                  if (alignedTimestamp <= lastSampleTimestamp) {\n                    lastSample.close();\n                    lastSample = sample;\n                    lastSampleTimestamp = alignedTimestamp;\n                    continue;\n                  } else {\n                    await padFrames(alignedTimestamp);\n                  }\n                }\n                adjustedSampleTimestamp = alignedTimestamp;\n                sample.setDuration(1 / frameRate);\n              }\n              sample.setTimestamp(adjustedSampleTimestamp);\n              await this._registerVideoSample(track, trackOptions, source, sample);\n              if (frameRate !== void 0) {\n                lastSample = sample;\n                lastSampleTimestamp = adjustedSampleTimestamp;\n              } else {\n                sample.close();\n              }\n            }\n            if (lastSample) {\n              assert(lastSampleEndTimestamp !== null);\n              assert(frameRate !== void 0);\n              await padFrames(Math.floor(lastSampleEndTimestamp * frameRate) / frameRate);\n            }\n            source.close();\n            this._synchronizer.closeTrack(track.id);\n          })());\n        }\n      }\n      this.output.addVideoTrack(videoSource, {\n        frameRate: trackOptions.frameRate,\n        // TODO: This condition can be removed when all demuxers properly homogenize to BCP47 in v2\n        languageCode: isIso639Dash2LanguageCode(track.languageCode) ? track.languageCode : void 0,\n        name: track.name ?? void 0,\n        disposition: track.disposition,\n        rotation: needsRerender ? 0 : totalRotation\n        // Rerendering will bake the rotation into the output\n      });\n      this._addedCounts.video++;\n      this._totalTrackCount++;\n      this.utilizedTracks.push(track);\n    }\n    /** @internal */\n    async _registerVideoSample(track, trackOptions, source, sample) {\n      if (this._canceled) {\n        return;\n      }\n      this._reportProgress(track.id, sample.timestamp);\n      let finalSamples;\n      if (!trackOptions.process) {\n        finalSamples = [sample];\n      } else {\n        let processed = trackOptions.process(sample);\n        if (processed instanceof Promise) processed = await processed;\n        if (!Array.isArray(processed)) {\n          processed = processed === null ? [] : [processed];\n        }\n        finalSamples = processed.map((x) => {\n          if (x instanceof VideoSample) {\n            return x;\n          }\n          if (typeof VideoFrame !== \"undefined\" && x instanceof VideoFrame) {\n            return new VideoSample(x);\n          }\n          return new VideoSample(x, {\n            timestamp: sample.timestamp,\n            duration: sample.duration\n          });\n        });\n      }\n      for (const finalSample of finalSamples) {\n        if (this._canceled) {\n          break;\n        }\n        await source.add(finalSample);\n        if (this._synchronizer.shouldWait(track.id, finalSample.timestamp)) {\n          await this._synchronizer.wait(finalSample.timestamp);\n        }\n      }\n      for (const finalSample of finalSamples) {\n        if (finalSample !== sample) {\n          finalSample.close();\n        }\n      }\n    }\n    /** @internal */\n    async _processAudioTrack(track, trackOptions) {\n      const sourceCodec = track.codec;\n      if (!sourceCodec) {\n        this.discardedTracks.push({\n          track,\n          reason: \"unknown_source_codec\"\n        });\n        return;\n      }\n      let audioSource;\n      const originalNumberOfChannels = track.numberOfChannels;\n      const originalSampleRate = track.sampleRate;\n      const firstTimestamp = await track.getFirstTimestamp();\n      let numberOfChannels = trackOptions.numberOfChannels ?? originalNumberOfChannels;\n      let sampleRate = trackOptions.sampleRate ?? originalSampleRate;\n      let needsResample = numberOfChannels !== originalNumberOfChannels || sampleRate !== originalSampleRate || firstTimestamp < this._startTimestamp;\n      let audioCodecs = this.output.format.getSupportedAudioCodecs();\n      if (!trackOptions.forceTranscode && !trackOptions.bitrate && !needsResample && audioCodecs.includes(sourceCodec) && (!trackOptions.codec || trackOptions.codec === sourceCodec) && !trackOptions.process) {\n        const source = new EncodedAudioPacketSource(sourceCodec);\n        audioSource = source;\n        this._trackPromises.push((async () => {\n          await this._started;\n          const sink = new EncodedPacketSink(track);\n          const decoderConfig = await track.getDecoderConfig();\n          const meta = { decoderConfig: decoderConfig ?? void 0 };\n          const endPacket = Number.isFinite(this._endTimestamp) ? await sink.getPacket(this._endTimestamp, { metadataOnly: true }) ?? void 0 : void 0;\n          for await (const packet of sink.packets(void 0, endPacket)) {\n            if (this._canceled) {\n              return;\n            }\n            const modifiedPacket = packet.clone({\n              timestamp: packet.timestamp - this._startTimestamp\n            });\n            assert(modifiedPacket.timestamp >= 0);\n            this._reportProgress(track.id, modifiedPacket.timestamp);\n            await source.add(modifiedPacket, meta);\n            if (this._synchronizer.shouldWait(track.id, modifiedPacket.timestamp)) {\n              await this._synchronizer.wait(modifiedPacket.timestamp);\n            }\n          }\n          source.close();\n          this._synchronizer.closeTrack(track.id);\n        })());\n      } else {\n        const canDecode = await track.canDecode();\n        if (!canDecode) {\n          this.discardedTracks.push({\n            track,\n            reason: \"undecodable_source_codec\"\n          });\n          return;\n        }\n        let codecOfChoice = null;\n        if (trackOptions.codec) {\n          audioCodecs = audioCodecs.filter((codec) => codec === trackOptions.codec);\n        }\n        const bitrate = trackOptions.bitrate ?? QUALITY_HIGH;\n        const encodableCodecs = await getEncodableAudioCodecs(audioCodecs, {\n          numberOfChannels: trackOptions.process && trackOptions.processedNumberOfChannels ? trackOptions.processedNumberOfChannels : numberOfChannels,\n          sampleRate: trackOptions.process && trackOptions.processedSampleRate ? trackOptions.processedSampleRate : sampleRate,\n          bitrate\n        });\n        if (!encodableCodecs.some((codec) => NON_PCM_AUDIO_CODECS.includes(codec)) && audioCodecs.some((codec) => NON_PCM_AUDIO_CODECS.includes(codec)) && (numberOfChannels !== FALLBACK_NUMBER_OF_CHANNELS || sampleRate !== FALLBACK_SAMPLE_RATE)) {\n          const encodableCodecsWithDefaultParams = await getEncodableAudioCodecs(audioCodecs, {\n            numberOfChannels: FALLBACK_NUMBER_OF_CHANNELS,\n            sampleRate: FALLBACK_SAMPLE_RATE,\n            bitrate\n          });\n          const nonPcmCodec = encodableCodecsWithDefaultParams.find((codec) => NON_PCM_AUDIO_CODECS.includes(codec));\n          if (nonPcmCodec) {\n            needsResample = true;\n            codecOfChoice = nonPcmCodec;\n            numberOfChannels = FALLBACK_NUMBER_OF_CHANNELS;\n            sampleRate = FALLBACK_SAMPLE_RATE;\n          }\n        } else {\n          codecOfChoice = encodableCodecs[0] ?? null;\n        }\n        if (codecOfChoice === null) {\n          this.discardedTracks.push({\n            track,\n            reason: \"no_encodable_target_codec\"\n          });\n          return;\n        }\n        if (needsResample) {\n          audioSource = this._resampleAudio(\n            track,\n            trackOptions,\n            codecOfChoice,\n            numberOfChannels,\n            sampleRate,\n            bitrate\n          );\n        } else {\n          const source = new AudioSampleSource({\n            codec: codecOfChoice,\n            bitrate\n          });\n          audioSource = source;\n          this._trackPromises.push((async () => {\n            await this._started;\n            const sink = new AudioSampleSink(track);\n            for await (const sample of sink.samples(void 0, this._endTimestamp)) {\n              if (this._canceled) {\n                sample.close();\n                return;\n              }\n              sample.setTimestamp(sample.timestamp - this._startTimestamp);\n              await this._registerAudioSample(track, trackOptions, source, sample);\n              sample.close();\n            }\n            source.close();\n            this._synchronizer.closeTrack(track.id);\n          })());\n        }\n      }\n      this.output.addAudioTrack(audioSource, {\n        // TODO: This condition can be removed when all demuxers properly homogenize to BCP47 in v2\n        languageCode: isIso639Dash2LanguageCode(track.languageCode) ? track.languageCode : void 0,\n        name: track.name ?? void 0,\n        disposition: track.disposition\n      });\n      this._addedCounts.audio++;\n      this._totalTrackCount++;\n      this.utilizedTracks.push(track);\n    }\n    /** @internal */\n    async _registerAudioSample(track, trackOptions, source, sample) {\n      if (this._canceled) {\n        return;\n      }\n      this._reportProgress(track.id, sample.timestamp);\n      let finalSamples;\n      if (!trackOptions.process) {\n        finalSamples = [sample];\n      } else {\n        let processed = trackOptions.process(sample);\n        if (processed instanceof Promise) processed = await processed;\n        if (!Array.isArray(processed)) {\n          processed = processed === null ? [] : [processed];\n        }\n        if (!processed.every((x) => x instanceof AudioSample)) {\n          throw new TypeError(\n            \"The audio process function must return an AudioSample, null, or an array of AudioSamples.\"\n          );\n        }\n        finalSamples = processed;\n      }\n      for (const finalSample of finalSamples) {\n        if (this._canceled) {\n          break;\n        }\n        await source.add(finalSample);\n        if (this._synchronizer.shouldWait(track.id, finalSample.timestamp)) {\n          await this._synchronizer.wait(finalSample.timestamp);\n        }\n      }\n      for (const finalSample of finalSamples) {\n        if (finalSample !== sample) {\n          finalSample.close();\n        }\n      }\n    }\n    /** @internal */\n    _resampleAudio(track, trackOptions, codec, targetNumberOfChannels, targetSampleRate, bitrate) {\n      const source = new AudioSampleSource({\n        codec,\n        bitrate\n      });\n      this._trackPromises.push((async () => {\n        await this._started;\n        const resampler = new AudioResampler({\n          targetNumberOfChannels,\n          targetSampleRate,\n          startTime: this._startTimestamp,\n          endTime: this._endTimestamp,\n          onSample: async (sample) => {\n            await this._registerAudioSample(track, trackOptions, source, sample);\n            sample.close();\n          }\n        });\n        const sink = new AudioSampleSink(track);\n        const iterator = sink.samples(this._startTimestamp, this._endTimestamp);\n        for await (const sample of iterator) {\n          if (this._canceled) {\n            sample.close();\n            return;\n          }\n          await resampler.add(sample);\n          sample.close();\n        }\n        await resampler.finalize();\n        source.close();\n        this._synchronizer.closeTrack(track.id);\n      })());\n      return source;\n    }\n    /** @internal */\n    _reportProgress(trackId, endTimestamp) {\n      if (!this._computeProgress) {\n        return;\n      }\n      assert(this._totalDuration !== null);\n      this._maxTimestamps.set(\n        trackId,\n        Math.max(endTimestamp, this._maxTimestamps.get(trackId))\n      );\n      const minTimestamp = Math.min(...this._maxTimestamps.values());\n      const newProgress = clamp(minTimestamp / this._totalDuration, 0, 1);\n      if (newProgress !== this._lastProgress) {\n        this._lastProgress = newProgress;\n        this.onProgress?.(newProgress);\n      }\n    }\n  };\n  var ConversionCanceledError = class extends Error {\n    /** Creates a new {@link ConversionCanceledError}. */\n    constructor(message = \"Conversion has been canceled.\") {\n      super(message);\n      this.name = \"ConversionCanceledError\";\n    }\n  };\n  var MAX_TIMESTAMP_GAP = 5;\n  var TrackSynchronizer = class {\n    constructor() {\n      this.maxTimestamps = /* @__PURE__ */ new Map();\n      // Track ID -> timestamp\n      this.resolvers = [];\n    }\n    computeMinAndMaybeResolve() {\n      let newMin = Infinity;\n      for (const [, timestamp] of this.maxTimestamps) {\n        newMin = Math.min(newMin, timestamp);\n      }\n      for (let i = 0; i < this.resolvers.length; i++) {\n        const entry = this.resolvers[i];\n        if (entry.timestamp - newMin < MAX_TIMESTAMP_GAP) {\n          entry.resolve();\n          this.resolvers.splice(i, 1);\n          i--;\n        }\n      }\n      return newMin;\n    }\n    shouldWait(trackId, timestamp) {\n      this.maxTimestamps.set(trackId, Math.max(timestamp, this.maxTimestamps.get(trackId) ?? -Infinity));\n      const newMin = this.computeMinAndMaybeResolve();\n      return timestamp - newMin >= MAX_TIMESTAMP_GAP;\n    }\n    wait(timestamp) {\n      const { promise, resolve } = promiseWithResolvers();\n      this.resolvers.push({\n        timestamp,\n        resolve\n      });\n      return promise;\n    }\n    closeTrack(trackId) {\n      this.maxTimestamps.delete(trackId);\n      this.computeMinAndMaybeResolve();\n    }\n  };\n  var AudioResampler = class {\n    constructor(options) {\n      this.sourceSampleRate = null;\n      this.sourceNumberOfChannels = null;\n      this.targetSampleRate = options.targetSampleRate;\n      this.targetNumberOfChannels = options.targetNumberOfChannels;\n      this.startTime = options.startTime;\n      this.endTime = options.endTime;\n      this.onSample = options.onSample;\n      this.bufferSizeInFrames = Math.floor(this.targetSampleRate * 5);\n      this.bufferSizeInSamples = this.bufferSizeInFrames * this.targetNumberOfChannels;\n      this.outputBuffer = new Float32Array(this.bufferSizeInSamples);\n      this.bufferStartFrame = 0;\n      this.maxWrittenFrame = -1;\n    }\n    /**\n     * Sets up the channel mixer to handle up/downmixing in the case where input and output channel counts don't match.\n     */\n    doChannelMixerSetup() {\n      assert(this.sourceNumberOfChannels !== null);\n      const sourceNum = this.sourceNumberOfChannels;\n      const targetNum = this.targetNumberOfChannels;\n      if (sourceNum === 1 && targetNum === 2) {\n        this.channelMixer = (sourceData, sourceFrameIndex) => {\n          return sourceData[sourceFrameIndex * sourceNum];\n        };\n      } else if (sourceNum === 1 && targetNum === 4) {\n        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {\n          return sourceData[sourceFrameIndex * sourceNum] * +(targetChannelIndex < 2);\n        };\n      } else if (sourceNum === 1 && targetNum === 6) {\n        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {\n          return sourceData[sourceFrameIndex * sourceNum] * +(targetChannelIndex === 2);\n        };\n      } else if (sourceNum === 2 && targetNum === 1) {\n        this.channelMixer = (sourceData, sourceFrameIndex) => {\n          const baseIdx = sourceFrameIndex * sourceNum;\n          return 0.5 * (sourceData[baseIdx] + sourceData[baseIdx + 1]);\n        };\n      } else if (sourceNum === 2 && targetNum === 4) {\n        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {\n          return sourceData[sourceFrameIndex * sourceNum + targetChannelIndex] * +(targetChannelIndex < 2);\n        };\n      } else if (sourceNum === 2 && targetNum === 6) {\n        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {\n          return sourceData[sourceFrameIndex * sourceNum + targetChannelIndex] * +(targetChannelIndex < 2);\n        };\n      } else if (sourceNum === 4 && targetNum === 1) {\n        this.channelMixer = (sourceData, sourceFrameIndex) => {\n          const baseIdx = sourceFrameIndex * sourceNum;\n          return 0.25 * (sourceData[baseIdx] + sourceData[baseIdx + 1] + sourceData[baseIdx + 2] + sourceData[baseIdx + 3]);\n        };\n      } else if (sourceNum === 4 && targetNum === 2) {\n        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {\n          const baseIdx = sourceFrameIndex * sourceNum;\n          return 0.5 * (sourceData[baseIdx + targetChannelIndex] + sourceData[baseIdx + targetChannelIndex + 2]);\n        };\n      } else if (sourceNum === 4 && targetNum === 6) {\n        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {\n          const baseIdx = sourceFrameIndex * sourceNum;\n          if (targetChannelIndex < 2) return sourceData[baseIdx + targetChannelIndex];\n          if (targetChannelIndex === 2 || targetChannelIndex === 3) return 0;\n          return sourceData[baseIdx + targetChannelIndex - 2];\n        };\n      } else if (sourceNum === 6 && targetNum === 1) {\n        this.channelMixer = (sourceData, sourceFrameIndex) => {\n          const baseIdx = sourceFrameIndex * sourceNum;\n          return Math.SQRT1_2 * (sourceData[baseIdx] + sourceData[baseIdx + 1]) + sourceData[baseIdx + 2] + 0.5 * (sourceData[baseIdx + 4] + sourceData[baseIdx + 5]);\n        };\n      } else if (sourceNum === 6 && targetNum === 2) {\n        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {\n          const baseIdx = sourceFrameIndex * sourceNum;\n          return sourceData[baseIdx + targetChannelIndex] + Math.SQRT1_2 * (sourceData[baseIdx + 2] + sourceData[baseIdx + targetChannelIndex + 4]);\n        };\n      } else if (sourceNum === 6 && targetNum === 4) {\n        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {\n          const baseIdx = sourceFrameIndex * sourceNum;\n          if (targetChannelIndex < 2) {\n            return sourceData[baseIdx + targetChannelIndex] + Math.SQRT1_2 * sourceData[baseIdx + 2];\n          }\n          return sourceData[baseIdx + targetChannelIndex + 2];\n        };\n      } else {\n        this.channelMixer = (sourceData, sourceFrameIndex, targetChannelIndex) => {\n          return targetChannelIndex < sourceNum ? sourceData[sourceFrameIndex * sourceNum + targetChannelIndex] : 0;\n        };\n      }\n    }\n    ensureTempBufferSize(requiredSamples) {\n      let length = this.tempSourceBuffer.length;\n      while (length < requiredSamples) {\n        length *= 2;\n      }\n      if (length !== this.tempSourceBuffer.length) {\n        const newBuffer = new Float32Array(length);\n        newBuffer.set(this.tempSourceBuffer);\n        this.tempSourceBuffer = newBuffer;\n      }\n    }\n    async add(audioSample) {\n      if (this.sourceSampleRate === null) {\n        this.sourceSampleRate = audioSample.sampleRate;\n        this.sourceNumberOfChannels = audioSample.numberOfChannels;\n        this.tempSourceBuffer = new Float32Array(this.sourceSampleRate * this.sourceNumberOfChannels);\n        this.doChannelMixerSetup();\n      }\n      const requiredSamples = audioSample.numberOfFrames * audioSample.numberOfChannels;\n      this.ensureTempBufferSize(requiredSamples);\n      const sourceDataSize = audioSample.allocationSize({ planeIndex: 0, format: \"f32\" });\n      const sourceView = new Float32Array(this.tempSourceBuffer.buffer, 0, sourceDataSize / 4);\n      audioSample.copyTo(sourceView, { planeIndex: 0, format: \"f32\" });\n      const inputStartTime = audioSample.timestamp - this.startTime;\n      const inputDuration = audioSample.numberOfFrames / this.sourceSampleRate;\n      const inputEndTime = Math.min(inputStartTime + inputDuration, this.endTime - this.startTime);\n      const outputStartFrame = Math.floor(inputStartTime * this.targetSampleRate);\n      const outputEndFrame = Math.ceil(inputEndTime * this.targetSampleRate);\n      for (let outputFrame = outputStartFrame; outputFrame < outputEndFrame; outputFrame++) {\n        if (outputFrame < this.bufferStartFrame) {\n          continue;\n        }\n        while (outputFrame >= this.bufferStartFrame + this.bufferSizeInFrames) {\n          await this.finalizeCurrentBuffer();\n          this.bufferStartFrame += this.bufferSizeInFrames;\n        }\n        const bufferFrameIndex = outputFrame - this.bufferStartFrame;\n        assert(bufferFrameIndex < this.bufferSizeInFrames);\n        const outputTime = outputFrame / this.targetSampleRate;\n        const inputTime = outputTime - inputStartTime;\n        const sourcePosition = inputTime * this.sourceSampleRate;\n        const sourceLowerFrame = Math.floor(sourcePosition);\n        const sourceUpperFrame = Math.ceil(sourcePosition);\n        const fraction = sourcePosition - sourceLowerFrame;\n        for (let targetChannel = 0; targetChannel < this.targetNumberOfChannels; targetChannel++) {\n          let lowerSample = 0;\n          let upperSample = 0;\n          if (sourceLowerFrame >= 0 && sourceLowerFrame < audioSample.numberOfFrames) {\n            lowerSample = this.channelMixer(sourceView, sourceLowerFrame, targetChannel);\n          }\n          if (sourceUpperFrame >= 0 && sourceUpperFrame < audioSample.numberOfFrames) {\n            upperSample = this.channelMixer(sourceView, sourceUpperFrame, targetChannel);\n          }\n          const outputSample = lowerSample + fraction * (upperSample - lowerSample);\n          const outputIndex = bufferFrameIndex * this.targetNumberOfChannels + targetChannel;\n          this.outputBuffer[outputIndex] += outputSample;\n        }\n        this.maxWrittenFrame = Math.max(this.maxWrittenFrame, bufferFrameIndex);\n      }\n    }\n    async finalizeCurrentBuffer() {\n      if (this.maxWrittenFrame < 0) {\n        return;\n      }\n      const samplesWritten = (this.maxWrittenFrame + 1) * this.targetNumberOfChannels;\n      const outputData = new Float32Array(samplesWritten);\n      outputData.set(this.outputBuffer.subarray(0, samplesWritten));\n      const timestampSeconds = this.bufferStartFrame / this.targetSampleRate;\n      const audioSample = new AudioSample({\n        format: \"f32\",\n        sampleRate: this.targetSampleRate,\n        numberOfChannels: this.targetNumberOfChannels,\n        timestamp: timestampSeconds,\n        data: outputData\n      });\n      await this.onSample(audioSample);\n      this.outputBuffer.fill(0);\n      this.maxWrittenFrame = -1;\n    }\n    finalize() {\n      return this.finalizeCurrentBuffer();\n    }\n  };\n  return __toCommonJS(index_exports);\n})();\nif (typeof module === \"object\" && typeof module.exports === \"object\") Object.assign(module.exports, Mediabunny)\n"],"names":[],"sourceRoot":""}